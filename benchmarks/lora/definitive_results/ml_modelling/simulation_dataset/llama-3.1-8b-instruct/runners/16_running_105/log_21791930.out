INFO 05-31 19:30:52 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 05-31 19:30:52 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.8_size_8-8-8/adapters_32_slots_32_rate_3.2-1.6-0.8_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.8_size_8-8-8/adapters_32_slots_32_rate_3.2-1.6-0.8_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 8640, 8640, 17280, 8640, 34560, 17280, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 17280, 17280, 17280, 34560, 34560, 8640, 34560, 34560, 34560, 34560, 17280, 8640, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 656640 . Total input tokens: 146660716 . Total output tokens: 128957705
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 7.434518706984818,
    "estimated_duration": 3600.017919598862,
    "input_throughput": 7202.058039446931,
    "output_throughput": 6281.0837348608475,
    "total_throughput": 13483.141774307778,
    "itl": 96.26575490260986,
    "ttft": 1454206.0257485325,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2115970890223979,
    "arrivals": 218245,
    "finished_requests": 104996,
    "scheduler_time": 54.253408341141956
}
#Debug simulation 
Total elapsed time: 7.434628049028106. Arrivals time: 0.2777472333982587 Scheduler time: 7.007913416833617 Scheduler overhead time: 0.05522209207993001 Adapter cache time: 0.009547818568535149 Engine time: 0.05802366498392075 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.8_size_8-8-16/adapters_32_slots_32_rate_3.2-1.6-0.8_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.8_size_8-8-16/adapters_32_slots_32_rate_3.2-1.6-0.8_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 8640, 8640, 17280, 8640, 34560, 17280, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 17280, 17280, 17280, 34560, 34560, 8640, 34560, 34560, 34560, 34560, 17280, 8640, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 656640 . Total input tokens: 146660716 . Total output tokens: 128957705
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 7.599982517072931,
    "estimated_duration": 3600.095540476696,
    "input_throughput": 7130.25465890859,
    "output_throughput": 6223.032069041564,
    "total_throughput": 13353.286727950153,
    "itl": 93.59312675828505,
    "ttft": 1464030.8240330978,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23482633151113994,
    "arrivals": 218245,
    "finished_requests": 103987,
    "scheduler_time": 52.248847069256065
}
#Debug simulation 
Total elapsed time: 7.600064486963674. Arrivals time: 0.2855239440687001 Scheduler time: 7.163251801626757 Scheduler overhead time: 0.05629712517838925 Adapter cache time: 0.009654274326749146 Engine time: 0.05865765793714672 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.8_size_8-8-32/adapters_32_slots_32_rate_3.2-1.6-0.8_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.8_size_8-8-32/adapters_32_slots_32_rate_3.2-1.6-0.8_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 8640, 8640, 17280, 8640, 34560, 17280, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 17280, 17280, 17280, 34560, 34560, 8640, 34560, 34560, 34560, 34560, 17280, 8640, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 656640 . Total input tokens: 146660716 . Total output tokens: 128957705
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 7.2914798349374905,
    "estimated_duration": 3600.011477503219,
    "input_throughput": 6950.968672287414,
    "output_throughput": 6068.560652243216,
    "total_throughput": 13019.529324530631,
    "itl": 87.26176728626436,
    "ttft": 1492383.442844995,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.24134628401137886,
    "arrivals": 218245,
    "finished_requests": 101334,
    "scheduler_time": 47.02117445406666
}
#Debug simulation 
Total elapsed time: 7.2915801459457725. Arrivals time: 0.28631062898784876 Scheduler time: 6.844103680574335 Scheduler overhead time: 0.06011244049295783 Adapter cache time: 0.010342276655137539 Engine time: 0.06258195044938475 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.8_size_8-16-16/adapters_32_slots_32_rate_3.2-1.6-0.8_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.8_size_8-16-16/adapters_32_slots_32_rate_3.2-1.6-0.8_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 8640, 8640, 17280, 8640, 34560, 17280, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 17280, 17280, 17280, 34560, 34560, 8640, 34560, 34560, 34560, 34560, 17280, 8640, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 656640 . Total input tokens: 146660716 . Total output tokens: 128957705
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 7.412970187026076,
    "estimated_duration": 3600.0027391882622,
    "input_throughput": 7130.063741503636,
    "output_throughput": 6222.583043103768,
    "total_throughput": 13352.646784607405,
    "itl": 93.59088686334445,
    "ttft": 1464069.6055407142,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21955590080469845,
    "arrivals": 218245,
    "finished_requests": 103979,
    "scheduler_time": 52.246902312945124
}
#Debug simulation 
Total elapsed time: 7.4130683350376785. Arrivals time: 0.2904217364266515 Scheduler time: 6.971000059391372 Scheduler overhead time: 0.05653200566302985 Adapter cache time: 0.009641758631914854 Engine time: 0.05874818540178239 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.8_size_8-16-32/adapters_32_slots_32_rate_3.2-1.6-0.8_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.8_size_8-16-32/adapters_32_slots_32_rate_3.2-1.6-0.8_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 8640, 8640, 17280, 8640, 34560, 17280, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 17280, 17280, 17280, 34560, 34560, 8640, 34560, 34560, 34560, 34560, 17280, 8640, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 656640 . Total input tokens: 146660716 . Total output tokens: 128957705
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 7.49956775107421,
    "estimated_duration": 3600.0412683730815,
    "input_throughput": 6950.9111520014785,
    "output_throughput": 6068.510434013156,
    "total_throughput": 13019.421586014634,
    "itl": 87.26294648915471,
    "ttft": 1492364.4089435132,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23906799506861715,
    "arrivals": 218245,
    "finished_requests": 101334,
    "scheduler_time": 47.02222778129031
}
#Debug simulation 
Total elapsed time: 7.499640361056663. Arrivals time: 0.5062121048104018 Scheduler time: 6.832647472037934 Scheduler overhead time: 0.05992873047944158 Adapter cache time: 0.010285497410222888 Engine time: 0.062322322628460824 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.8_size_16-16-16/adapters_32_slots_32_rate_3.2-1.6-0.8_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.8_size_16-16-16/adapters_32_slots_32_rate_3.2-1.6-0.8_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 8640, 8640, 17280, 8640, 34560, 17280, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 17280, 17280, 17280, 34560, 34560, 8640, 34560, 34560, 34560, 34560, 17280, 8640, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 656640 . Total input tokens: 146660716 . Total output tokens: 128957705
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 7.456537542049773,
    "estimated_duration": 3600.022941961302,
    "input_throughput": 7129.939840332249,
    "output_throughput": 6222.421734844821,
    "total_throughput": 13352.36157517707,
    "itl": 93.59307731228209,
    "ttft": 1464029.6996359807,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20428547009825704,
    "arrivals": 218245,
    "finished_requests": 103979,
    "scheduler_time": 52.24855560935673
}
#Debug simulation 
Total elapsed time: 7.456636092043482. Arrivals time: 0.29710374120622873 Scheduler time: 7.007392216473818 Scheduler overhead time: 0.05683655885513872 Adapter cache time: 0.00980935140978545 Engine time: 0.058704343158751726 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.8_size_16-16-32/adapters_32_slots_32_rate_3.2-1.6-0.8_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.8_size_16-16-32/adapters_32_slots_32_rate_3.2-1.6-0.8_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 8640, 8640, 17280, 8640, 34560, 17280, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 17280, 17280, 17280, 34560, 34560, 8640, 34560, 34560, 34560, 34560, 17280, 8640, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 656640 . Total input tokens: 146660716 . Total output tokens: 128957705
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 7.287969408091158,
    "estimated_duration": 3600.081700607546,
    "input_throughput": 6950.9669727153605,
    "output_throughput": 6068.491166829107,
    "total_throughput": 13019.458139544467,
    "itl": 87.26160445291328,
    "ttft": 1492386.0657904346,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23678970612585543,
    "arrivals": 218245,
    "finished_requests": 101335,
    "scheduler_time": 47.02183265113068
}
#Debug simulation 
Total elapsed time: 7.288147223065607. Arrivals time: 0.2926043870393187 Scheduler time: 6.834726250031963 Scheduler overhead time: 0.05990379338618368 Adapter cache time: 0.01035270094871521 Engine time: 0.062304508057422936 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.4_size_8-8-8/adapters_32_slots_32_rate_3.2-1.6-0.4_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.4_size_8-8-8/adapters_32_slots_32_rate_3.2-1.6-0.4_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 4320, 4320, 17280, 4320, 34560, 17280, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 17280, 17280, 17280, 34560, 34560, 4320, 34560, 34560, 34560, 34560, 17280, 4320, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 613440 . Total input tokens: 136961208 . Total output tokens: 120482857
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 7.430801823968068,
    "estimated_duration": 3600.001166597544,
    "input_throughput": 7195.3493349786495,
    "output_throughput": 6280.430742573589,
    "total_throughput": 13475.78007755224,
    "itl": 96.22400317447139,
    "ttft": 1408484.2480369427,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2115970890223979,
    "arrivals": 203816,
    "finished_requests": 104606,
    "scheduler_time": 54.7309952848946
}
#Debug simulation 
Total elapsed time: 7.430898353923112. Arrivals time: 0.2964407564140856 Scheduler time: 6.986024213489145 Scheduler overhead time: 0.05520717427134514 Adapter cache time: 0.009756596176885068 Engine time: 0.057347863214090466 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.4_size_8-8-16/adapters_32_slots_32_rate_3.2-1.6-0.4_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.4_size_8-8-16/adapters_32_slots_32_rate_3.2-1.6-0.4_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 4320, 4320, 17280, 4320, 34560, 17280, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 17280, 17280, 17280, 34560, 34560, 4320, 34560, 34560, 34560, 34560, 17280, 4320, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 613440 . Total input tokens: 136961208 . Total output tokens: 120482857
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 7.432357397978194,
    "estimated_duration": 3600.051809927959,
    "input_throughput": 7125.685227433808,
    "output_throughput": 6220.4913102203745,
    "total_throughput": 13346.176537654183,
    "itl": 93.55593811158332,
    "ttft": 1419275.6195874063,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2348263315111399,
    "arrivals": 203816,
    "finished_requests": 103591,
    "scheduler_time": 52.7420771797502
}
#Debug simulation 
Total elapsed time: 7.4324502039235085. Arrivals time: 0.2987755290232599 Scheduler time: 6.979972615954466 Scheduler overhead time: 0.05658492574002594 Adapter cache time: 0.010113924043253064 Engine time: 0.06002256157808006 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.4_size_8-8-32/adapters_32_slots_32_rate_3.2-1.6-0.4_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.4_size_8-8-32/adapters_32_slots_32_rate_3.2-1.6-0.4_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 4320, 4320, 17280, 4320, 34560, 17280, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 17280, 17280, 17280, 34560, 34560, 4320, 34560, 34560, 34560, 34560, 17280, 4320, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 613440 . Total input tokens: 136961208 . Total output tokens: 120482857
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 7.4883345869602636,
    "estimated_duration": 3600.033769034781,
    "input_throughput": 6952.210619599384,
    "output_throughput": 6067.960303010411,
    "total_throughput": 13020.170922609794,
    "itl": 87.1849364281465,
    "ttft": 1448752.7562671313,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2413462840113789,
    "arrivals": 203816,
    "finished_requests": 101040,
    "scheduler_time": 47.52915805035094
}
#Debug simulation 
Total elapsed time: 7.488401549984701. Arrivals time: 0.5119512001983821 Scheduler time: 6.814366831444204 Scheduler overhead time: 0.06003858149051666 Adapter cache time: 0.011026149615645409 Engine time: 0.06270689086522907 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.4_size_8-16-16/adapters_32_slots_32_rate_3.2-1.6-0.4_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.4_size_8-16-16/adapters_32_slots_32_rate_3.2-1.6-0.4_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 4320, 4320, 17280, 4320, 34560, 17280, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 17280, 17280, 17280, 34560, 34560, 4320, 34560, 34560, 34560, 34560, 17280, 4320, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 613440 . Total input tokens: 136961208 . Total output tokens: 120482857
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 7.698785677901469,
    "estimated_duration": 3600.026194969123,
    "input_throughput": 7125.595095904578,
    "output_throughput": 6220.535014799267,
    "total_throughput": 13346.130110703843,
    "itl": 93.55734582390473,
    "ttft": 1419148.013639372,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21955590080469845,
    "arrivals": 203816,
    "finished_requests": 103590,
    "scheduler_time": 52.74237976796713
}
#Debug simulation 
Total elapsed time: 7.698849424952641. Arrivals time: 0.5426345263840631 Scheduler time: 7.003384191077203 Scheduler overhead time: 0.05695196194574237 Adapter cache time: 0.010175508097745478 Engine time: 0.05901462829206139 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.4_size_8-16-32/adapters_32_slots_32_rate_3.2-1.6-0.4_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.4_size_8-16-32/adapters_32_slots_32_rate_3.2-1.6-0.4_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 4320, 4320, 17280, 4320, 34560, 17280, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 17280, 17280, 17280, 34560, 34560, 4320, 34560, 34560, 34560, 34560, 17280, 4320, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 613440 . Total input tokens: 136961208 . Total output tokens: 120482857
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 7.517870440962724,
    "estimated_duration": 3600.015498744576,
    "input_throughput": 6952.051736646071,
    "output_throughput": 6067.908320844118,
    "total_throughput": 13019.960057490189,
    "itl": 87.18246476037785,
    "ttft": 1448661.9147610953,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23906799506861717,
    "arrivals": 203816,
    "finished_requests": 101038,
    "scheduler_time": 47.527222363276564
}
#Debug simulation 
Total elapsed time: 7.517938842996955. Arrivals time: 0.5149543123552576 Scheduler time: 6.840673899627291 Scheduler overhead time: 0.060054086381569505 Adapter cache time: 0.010914678103290498 Engine time: 0.06288116658106446 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.4_size_16-16-16/adapters_32_slots_32_rate_3.2-1.6-0.4_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.4_size_16-16-16/adapters_32_slots_32_rate_3.2-1.6-0.4_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 4320, 4320, 17280, 4320, 34560, 17280, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 17280, 17280, 17280, 34560, 34560, 4320, 34560, 34560, 34560, 34560, 17280, 4320, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 613440 . Total input tokens: 136961208 . Total output tokens: 120482857
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 7.6341809229925275,
    "estimated_duration": 3600.0876515549935,
    "input_throughput": 7125.658729147788,
    "output_throughput": 6220.42993601205,
    "total_throughput": 13346.088665159838,
    "itl": 93.55635279201356,
    "ttft": 1419175.2964567547,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20428547009825704,
    "arrivals": 203816,
    "finished_requests": 103592,
    "scheduler_time": 52.743689589006024
}
#Debug simulation 
Total elapsed time: 7.634249311988242. Arrivals time: 0.2983532778453082 Scheduler time: 7.183574071736075 Scheduler overhead time: 0.056554177310317755 Adapter cache time: 0.010224191821180284 Engine time: 0.058847371372394264 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.4_size_16-16-32/adapters_32_slots_32_rate_3.2-1.6-0.4_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.4_size_16-16-32/adapters_32_slots_32_rate_3.2-1.6-0.4_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 4320, 4320, 17280, 4320, 34560, 17280, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 17280, 17280, 17280, 34560, 34560, 4320, 34560, 34560, 34560, 34560, 17280, 4320, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 613440 . Total input tokens: 136961208 . Total output tokens: 120482857
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 7.478037246968597,
    "estimated_duration": 3600.097785317783,
    "input_throughput": 6952.301713046574,
    "output_throughput": 6067.925179446679,
    "total_throughput": 13020.226892493254,
    "itl": 87.1822835460593,
    "ttft": 1448746.9817091168,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23678970612585545,
    "arrivals": 203816,
    "finished_requests": 101042,
    "scheduler_time": 47.5279690219259
}
#Debug simulation 
Total elapsed time: 7.478158185957. Arrivals time: 0.29043647448997945 Scheduler time: 7.026380989002064 Scheduler overhead time: 0.059907346148975194 Adapter cache time: 0.010904176975600421 Engine time: 0.06221972149796784 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.1_size_8-8-8/adapters_32_slots_32_rate_3.2-1.6-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.1_size_8-8-8/adapters_32_slots_32_rate_3.2-1.6-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 1080, 1080, 17280, 1080, 34560, 17280, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 17280, 17280, 17280, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 17280, 1080, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 581040 . Total input tokens: 129766786 . Total output tokens: 114164316
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 7.585664035985246,
    "estimated_duration": 3600.0825368561946,
    "input_throughput": 7412.762826072394,
    "output_throughput": 6408.005862039353,
    "total_throughput": 13820.768688111748,
    "itl": 94.12428182096875,
    "ttft": 1331401.9687675259,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2115970890223979,
    "arrivals": 193289,
    "finished_requests": 107608,
    "scheduler_time": 56.53884738682418
}
#Debug simulation 
Total elapsed time: 7.585757149965502. Arrivals time: 0.2941556057194248 Scheduler time: 7.1373457974987105 Scheduler overhead time: 0.05609429778996855 Adapter cache time: 0.012902773334644735 Engine time: 0.058639621594920754 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.1_size_8-8-16/adapters_32_slots_32_rate_3.2-1.6-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.1_size_8-8-16/adapters_32_slots_32_rate_3.2-1.6-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 1080, 1080, 17280, 1080, 34560, 17280, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 17280, 17280, 17280, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 17280, 1080, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 581040 . Total input tokens: 129766786 . Total output tokens: 114164316
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 7.545518841012381,
    "estimated_duration": 3600.002233972004,
    "input_throughput": 7354.244047451302,
    "output_throughput": 6356.249944532104,
    "total_throughput": 13710.493991983405,
    "itl": 91.39608066727207,
    "ttft": 1342924.0636140066,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23482633151113985,
    "arrivals": 193289,
    "finished_requests": 106719,
    "scheduler_time": 54.554035383894785
}
#Debug simulation 
Total elapsed time: 7.545615360024385. Arrivals time: 0.2947490919614211 Scheduler time: 7.092412940924987 Scheduler overhead time: 0.05764433275908232 Adapter cache time: 0.013348877662792802 Engine time: 0.060117893503047526 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.1_size_8-8-32/adapters_32_slots_32_rate_3.2-1.6-0.1_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.1_size_8-8-32/adapters_32_slots_32_rate_3.2-1.6-0.1_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 1080, 1080, 17280, 1080, 34560, 17280, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 17280, 17280, 17280, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 17280, 1080, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 581040 . Total input tokens: 129766786 . Total output tokens: 114164316
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 7.6253245630068704,
    "estimated_duration": 3600.0620148228995,
    "input_throughput": 7191.158344885777,
    "output_throughput": 6211.912991476657,
    "total_throughput": 13403.071336362435,
    "itl": 85.03211256168035,
    "ttft": 1370271.1720266652,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2413462840113789,
    "arrivals": 193289,
    "finished_requests": 104300,
    "scheduler_time": 49.34233800888847
}
#Debug simulation 
Total elapsed time: 7.625392131041735. Arrivals time: 0.2987372617935762 Scheduler time: 7.1568042592843994 Scheduler overhead time: 0.06125977332703769 Adapter cache time: 0.014378826483152807 Engine time: 0.0652852492639795 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.1_size_8-16-16/adapters_32_slots_32_rate_3.2-1.6-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.1_size_8-16-16/adapters_32_slots_32_rate_3.2-1.6-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 1080, 1080, 17280, 1080, 34560, 17280, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 17280, 17280, 17280, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 17280, 1080, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 581040 . Total input tokens: 129766786 . Total output tokens: 114164316
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 7.588020263006911,
    "estimated_duration": 3600.0193957279366,
    "input_throughput": 7353.930934765645,
    "output_throughput": 6356.187421421683,
    "total_throughput": 13710.11835618733,
    "itl": 91.39513328357086,
    "ttft": 1342922.2690243265,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2195559008046984,
    "arrivals": 193289,
    "finished_requests": 106717,
    "scheduler_time": 54.55329420908465
}
#Debug simulation 
Total elapsed time: 7.588113358011469. Arrivals time: 0.2964260937878862 Scheduler time: 7.129737196024507 Scheduler overhead time: 0.05786076083313674 Adapter cache time: 0.01347359293140471 Engine time: 0.06143664557021111 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.1_size_8-16-32/adapters_32_slots_32_rate_3.2-1.6-0.1_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.1_size_8-16-32/adapters_32_slots_32_rate_3.2-1.6-0.1_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 1080, 1080, 17280, 1080, 34560, 17280, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 17280, 17280, 17280, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 17280, 1080, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 581040 . Total input tokens: 129766786 . Total output tokens: 114164316
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 7.410441174986772,
    "estimated_duration": 3600.0648207520226,
    "input_throughput": 7191.539399724419,
    "output_throughput": 6212.147589978206,
    "total_throughput": 13403.686989702626,
    "itl": 85.03182002977657,
    "ttft": 1370216.3309338714,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23906799506861717,
    "arrivals": 193289,
    "finished_requests": 104304,
    "scheduler_time": 49.34399825349131
}
#Debug simulation 
Total elapsed time: 7.410536692943424. Arrivals time: 0.2951351187657565 Scheduler time: 6.947212779545225 Scheduler overhead time: 0.06112556962762028 Adapter cache time: 0.014272618922404945 Engine time: 0.06382697622757405 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.1_size_16-16-16/adapters_32_slots_32_rate_3.2-1.6-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.1_size_16-16-16/adapters_32_slots_32_rate_3.2-1.6-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 1080, 1080, 17280, 1080, 34560, 17280, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 17280, 17280, 17280, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 17280, 1080, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 581040 . Total input tokens: 129766786 . Total output tokens: 114164316
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 7.74929785891436,
    "estimated_duration": 3600.065169937235,
    "input_throughput": 7353.898263031046,
    "output_throughput": 6356.107159137605,
    "total_throughput": 13710.005422168651,
    "itl": 91.39527947063877,
    "ttft": 1342845.9861354842,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20428547009825704,
    "arrivals": 193289,
    "finished_requests": 106718,
    "scheduler_time": 54.55501709229118
}
#Debug simulation 
Total elapsed time: 7.749366867938079. Arrivals time: 0.29993624426424503 Scheduler time: 7.290927018155344 Scheduler overhead time: 0.057654500124044716 Adapter cache time: 0.013378428877331316 Engine time: 0.06020601070486009 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.1_size_16-16-32/adapters_32_slots_32_rate_3.2-1.6-0.1_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.1_size_16-16-32/adapters_32_slots_32_rate_3.2-1.6-0.1_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 1080, 1080, 17280, 1080, 34560, 17280, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 17280, 17280, 17280, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 17280, 1080, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 581040 . Total input tokens: 129766786 . Total output tokens: 114164316
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 7.390881438041106,
    "estimated_duration": 3600.058191570904,
    "input_throughput": 7191.643196384728,
    "output_throughput": 6212.088474670296,
    "total_throughput": 13403.731671055024,
    "itl": 85.03198632652585,
    "ttft": 1370197.9851367404,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23678970612585545,
    "arrivals": 193289,
    "finished_requests": 104305,
    "scheduler_time": 49.34288421038108
}
#Debug simulation 
Total elapsed time: 7.391043587005697. Arrivals time: 0.2911733944201842 Scheduler time: 6.930010789074004 Scheduler overhead time: 0.06138695823028684 Adapter cache time: 0.014418225036934018 Engine time: 0.06514854542911053 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.05_size_8-8-8/adapters_32_slots_32_rate_3.2-1.6-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.05_size_8-8-8/adapters_32_slots_32_rate_3.2-1.6-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 540, 540, 17280, 540, 34560, 17280, 540, 540, 540, 34560, 34560, 540, 540, 17280, 17280, 17280, 34560, 34560, 540, 34560, 34560, 34560, 34560, 17280, 540, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 575640 . Total input tokens: 128559279 . Total output tokens: 113095279
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 7.64083525701426,
    "estimated_duration": 3600.0067946622803,
    "input_throughput": 7527.555792444609,
    "output_throughput": 6521.2565806288585,
    "total_throughput": 14048.812373073468,
    "itl": 92.65369313360571,
    "ttft": 1312010.0234861984,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2115970890223979,
    "arrivals": 191429,
    "finished_requests": 109372,
    "scheduler_time": 57.71911954125403
}
#Debug simulation 
Total elapsed time: 7.640953514026478. Arrivals time: 0.29916559625416994 Scheduler time: 7.18522334494628 Scheduler overhead time: 0.05710207379888743 Adapter cache time: 0.01306690345518291 Engine time: 0.05924507265444845 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.05_size_8-8-16/adapters_32_slots_32_rate_3.2-1.6-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.05_size_8-8-16/adapters_32_slots_32_rate_3.2-1.6-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 540, 540, 17280, 540, 34560, 17280, 540, 540, 540, 34560, 34560, 540, 540, 17280, 17280, 17280, 34560, 34560, 540, 34560, 34560, 34560, 34560, 17280, 540, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 575640 . Total input tokens: 128559279 . Total output tokens: 113095279
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 7.671854302054271,
    "estimated_duration": 3600.0755260498368,
    "input_throughput": 7464.111740312421,
    "output_throughput": 6464.130774926928,
    "total_throughput": 13928.242515239348,
    "itl": 89.8498258802186,
    "ttft": 1323545.2409618786,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23482633151113985,
    "arrivals": 191429,
    "finished_requests": 108431,
    "scheduler_time": 55.60400146930702
}
#Debug simulation 
Total elapsed time: 7.671948190080002. Arrivals time: 0.29758292180486023 Scheduler time: 7.2132608202518895 Scheduler overhead time: 0.05878246063366532 Adapter cache time: 0.013334197807125747 Engine time: 0.06134230620227754 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.05_size_8-8-32/adapters_32_slots_32_rate_3.2-1.6-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.05_size_8-8-32/adapters_32_slots_32_rate_3.2-1.6-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 540, 540, 17280, 540, 34560, 17280, 540, 540, 540, 34560, 34560, 540, 540, 17280, 17280, 17280, 34560, 34560, 540, 34560, 34560, 34560, 34560, 17280, 540, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 575640 . Total input tokens: 128559279 . Total output tokens: 113095279
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 7.5608510740567,
    "estimated_duration": 3600.0690194403724,
    "input_throughput": 7294.151544928438,
    "output_throughput": 6318.949963780488,
    "total_throughput": 13613.101508708927,
    "itl": 83.56411661252987,
    "ttft": 1351881.0751013518,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.24134628401137892,
    "arrivals": 191429,
    "finished_requests": 105975,
    "scheduler_time": 50.30087686677348
}
#Debug simulation 
Total elapsed time: 7.560965909040533. Arrivals time: 0.2991950244177133 Scheduler time: 7.089954260387458 Scheduler overhead time: 0.06272962433286011 Adapter cache time: 0.014406875125132501 Engine time: 0.06514413456898183 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.05_size_8-16-16/adapters_32_slots_32_rate_3.2-1.6-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.05_size_8-16-16/adapters_32_slots_32_rate_3.2-1.6-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 540, 540, 17280, 540, 34560, 17280, 540, 540, 540, 34560, 34560, 540, 540, 17280, 17280, 17280, 34560, 34560, 540, 34560, 34560, 34560, 34560, 17280, 540, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 575640 . Total input tokens: 128559279 . Total output tokens: 113095279
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 7.650112330913544,
    "estimated_duration": 3600.043103424928,
    "input_throughput": 7464.257018043882,
    "output_throughput": 6464.224547161809,
    "total_throughput": 13928.481565205691,
    "itl": 89.85024569506199,
    "ttft": 1323605.900546349,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21955590080469842,
    "arrivals": 191429,
    "finished_requests": 108432,
    "scheduler_time": 55.60517430605889
}
#Debug simulation 
Total elapsed time: 7.650232468964532. Arrivals time: 0.29677486419677734 Scheduler time: 7.192494000541046 Scheduler overhead time: 0.058661307441070676 Adapter cache time: 0.01337476132903248 Engine time: 0.06122939067427069 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.05_size_8-16-32/adapters_32_slots_32_rate_3.2-1.6-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.05_size_8-16-32/adapters_32_slots_32_rate_3.2-1.6-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 540, 540, 17280, 540, 34560, 17280, 540, 540, 540, 34560, 34560, 540, 540, 17280, 17280, 17280, 34560, 34560, 540, 34560, 34560, 34560, 34560, 17280, 540, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 575640 . Total input tokens: 128559279 . Total output tokens: 113095279
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 7.526468549971469,
    "estimated_duration": 3600.001345229388,
    "input_throughput": 7294.1058854873345,
    "output_throughput": 6319.090138715067,
    "total_throughput": 13613.196024202402,
    "itl": 83.56360221789829,
    "ttft": 1351791.3267915922,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2390679950686172,
    "arrivals": 191429,
    "finished_requests": 105972,
    "scheduler_time": 50.29846647752359
}
#Debug simulation 
Total elapsed time: 7.526586731895804. Arrivals time: 0.29369799059350044 Scheduler time: 7.061740096425638 Scheduler overhead time: 0.06237776146735996 Adapter cache time: 0.01424902817234397 Engine time: 0.06492893758695573 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.05_size_16-16-16/adapters_32_slots_32_rate_3.2-1.6-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.05_size_16-16-16/adapters_32_slots_32_rate_3.2-1.6-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 540, 540, 17280, 540, 34560, 17280, 540, 540, 540, 34560, 34560, 540, 540, 17280, 17280, 17280, 34560, 34560, 540, 34560, 34560, 34560, 34560, 17280, 540, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 575640 . Total input tokens: 128559279 . Total output tokens: 113095279
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 7.649102282943204,
    "estimated_duration": 3600.077041123648,
    "input_throughput": 7467.655189848099,
    "output_throughput": 6466.833552187971,
    "total_throughput": 13934.48874203607,
    "itl": 89.97472299701855,
    "ttft": 1322952.6112364426,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20428547009825704,
    "arrivals": 191429,
    "finished_requests": 108482,
    "scheduler_time": 55.7050092021792
}
#Debug simulation 
Total elapsed time: 7.649219730985351. Arrivals time: 0.29967060044873506 Scheduler time: 7.18899427622091 Scheduler overhead time: 0.058472174452617764 Adapter cache time: 0.013360209297388792 Engine time: 0.06090878730174154 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.05_size_16-16-32/adapters_32_slots_32_rate_3.2-1.6-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.05_size_16-16-32/adapters_32_slots_32_rate_3.2-1.6-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 540, 540, 17280, 540, 34560, 17280, 540, 540, 540, 34560, 34560, 540, 540, 17280, 17280, 17280, 34560, 34560, 540, 34560, 34560, 34560, 34560, 17280, 540, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 575640 . Total input tokens: 128559279 . Total output tokens: 113095279
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 7.613150713033974,
    "estimated_duration": 3600.0365797690706,
    "input_throughput": 7294.2464383749275,
    "output_throughput": 6319.071069399873,
    "total_throughput": 13613.3175077748,
    "itl": 83.56139205421891,
    "ttft": 1351767.3131846795,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23678970612585548,
    "arrivals": 191429,
    "finished_requests": 105976,
    "scheduler_time": 50.2990727531909
}
#Debug simulation 
Total elapsed time: 7.613329368992709. Arrivals time: 0.2961598087567836 Scheduler time: 7.144519113469869 Scheduler overhead time: 0.06289339112117887 Adapter cache time: 0.014461448299698532 Engine time: 0.06554960377980024 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.025_size_8-8-8/adapters_32_slots_32_rate_3.2-1.6-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.025_size_8-8-8/adapters_32_slots_32_rate_3.2-1.6-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 270, 270, 17280, 270, 34560, 17280, 270, 270, 270, 34560, 34560, 270, 270, 17280, 17280, 17280, 34560, 34560, 270, 34560, 34560, 34560, 34560, 17280, 270, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 572940 . Total input tokens: 127961315 . Total output tokens: 112566747
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 7.802197454031557,
    "estimated_duration": 3600.0727601110784,
    "input_throughput": 7575.356337842056,
    "output_throughput": 6631.312918037635,
    "total_throughput": 14206.669255879691,
    "itl": 91.15092859911636,
    "ttft": 1287523.2689824577,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2115970890223979,
    "arrivals": 190474,
    "finished_requests": 110801,
    "scheduler_time": 58.96065288916909
}
#Debug simulation 
Total elapsed time: 7.8023277160245925. Arrivals time: 0.2995774506125599 Scheduler time: 7.343282891553827 Scheduler overhead time: 0.05839275103062391 Adapter cache time: 0.012323858099989593 Engine time: 0.061210008105263114 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.025_size_8-8-16/adapters_32_slots_32_rate_3.2-1.6-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.025_size_8-8-16/adapters_32_slots_32_rate_3.2-1.6-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 270, 270, 17280, 270, 34560, 17280, 270, 270, 270, 34560, 34560, 270, 270, 17280, 17280, 17280, 34560, 34560, 270, 34560, 34560, 34560, 34560, 17280, 270, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 572940 . Total input tokens: 127961315 . Total output tokens: 112566747
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 8.020862767007202,
    "estimated_duration": 3600.0547474499685,
    "input_throughput": 7512.7313047552125,
    "output_throughput": 6573.673085600454,
    "total_throughput": 14086.404390355667,
    "itl": 88.53155775483023,
    "ttft": 1299222.7304522006,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23482633151113985,
    "arrivals": 190474,
    "finished_requests": 109858,
    "scheduler_time": 56.891537828278715
}
#Debug simulation 
Total elapsed time: 8.02097174199298. Arrivals time: 0.5230467042420059 Scheduler time: 7.335133674670942 Scheduler overhead time: 0.05977607739623636 Adapter cache time: 0.012593598803505301 Engine time: 0.06211049819830805 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.025_size_8-8-32/adapters_32_slots_32_rate_3.2-1.6-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.025_size_8-8-32/adapters_32_slots_32_rate_3.2-1.6-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 270, 270, 17280, 270, 34560, 17280, 270, 270, 270, 34560, 34560, 270, 270, 17280, 17280, 17280, 34560, 34560, 270, 34560, 34560, 34560, 34560, 17280, 270, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 572940 . Total input tokens: 127961315 . Total output tokens: 112566747
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 7.601035774918273,
    "estimated_duration": 3600.014095930505,
    "input_throughput": 7343.4426353730405,
    "output_throughput": 6421.198190899039,
    "total_throughput": 13764.64082627208,
    "itl": 82.4103981939394,
    "ttft": 1329311.194519385,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.24134628401137892,
    "arrivals": 190474,
    "finished_requests": 107359,
    "scheduler_time": 51.485201638312574
}
#Debug simulation 
Total elapsed time: 7.601162442006171. Arrivals time: 0.2987407388864085 Scheduler time: 7.129229701706208 Scheduler overhead time: 0.06336989800911397 Adapter cache time: 0.013258821447379887 Engine time: 0.06666178477462381 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.025_size_8-16-16/adapters_32_slots_32_rate_3.2-1.6-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.025_size_8-16-16/adapters_32_slots_32_rate_3.2-1.6-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 270, 270, 17280, 270, 34560, 17280, 270, 270, 270, 34560, 34560, 270, 270, 17280, 17280, 17280, 34560, 34560, 270, 34560, 34560, 34560, 34560, 17280, 270, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 572940 . Total input tokens: 127961315 . Total output tokens: 112566747
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 7.750848195981234,
    "estimated_duration": 3600.0755941048174,
    "input_throughput": 7512.77613289265,
    "output_throughput": 6574.052233446219,
    "total_throughput": 14086.82836633887,
    "itl": 88.5334210248762,
    "ttft": 1299126.0050968167,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2195559008046984,
    "arrivals": 190474,
    "finished_requests": 109862,
    "scheduler_time": 56.89294572903539
}
#Debug simulation 
Total elapsed time: 7.7509713399922475. Arrivals time: 0.29820027539972216 Scheduler time: 7.290551670477726 Scheduler overhead time: 0.05961666419170797 Adapter cache time: 0.012496476178057492 Engine time: 0.06175387732218951 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.025_size_8-16-32/adapters_32_slots_32_rate_3.2-1.6-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.025_size_8-16-32/adapters_32_slots_32_rate_3.2-1.6-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 270, 270, 17280, 270, 34560, 17280, 270, 270, 270, 34560, 34560, 270, 270, 17280, 17280, 17280, 34560, 34560, 270, 34560, 34560, 34560, 34560, 17280, 270, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 572940 . Total input tokens: 127961315 . Total output tokens: 112566747
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 7.828011221950874,
    "estimated_duration": 3600.036653153794,
    "input_throughput": 7343.479121758435,
    "output_throughput": 6421.2729555818905,
    "total_throughput": 13764.752077340327,
    "itl": 82.41078002446848,
    "ttft": 1329315.259634813,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2390679950686172,
    "arrivals": 190474,
    "finished_requests": 107361,
    "scheduler_time": 51.485461694299524
}
#Debug simulation 
Total elapsed time: 7.828120783902705. Arrivals time: 0.2998751866398379 Scheduler time: 7.356010009651072 Scheduler overhead time: 0.06313586991745979 Adapter cache time: 0.01333830482326448 Engine time: 0.06578288634773344 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.025_size_16-16-16/adapters_32_slots_32_rate_3.2-1.6-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.025_size_16-16-16/adapters_32_slots_32_rate_3.2-1.6-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 270, 270, 17280, 270, 34560, 17280, 270, 270, 270, 34560, 34560, 270, 270, 17280, 17280, 17280, 34560, 34560, 270, 34560, 34560, 34560, 34560, 17280, 270, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 572940 . Total input tokens: 127961315 . Total output tokens: 112566747
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 7.779916657018475,
    "estimated_duration": 3600.0560631067374,
    "input_throughput": 7512.785780524692,
    "output_throughput": 6573.785681431021,
    "total_throughput": 14086.571461955713,
    "itl": 88.53193252562187,
    "ttft": 1299120.0988475173,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20428547009825704,
    "arrivals": 190474,
    "finished_requests": 109859,
    "scheduler_time": 56.89195344841164
}
#Debug simulation 
Total elapsed time: 7.780045254039578. Arrivals time: 0.29946010024286807 Scheduler time: 7.316735258093104 Scheduler overhead time: 0.05991860758513212 Adapter cache time: 0.01257800858002156 Engine time: 0.0629550782032311 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.025_size_16-16-32/adapters_32_slots_32_rate_3.2-1.6-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.025_size_16-16-32/adapters_32_slots_32_rate_3.2-1.6-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 270, 270, 17280, 270, 34560, 17280, 270, 270, 270, 34560, 34560, 270, 270, 17280, 17280, 17280, 34560, 34560, 270, 34560, 34560, 34560, 34560, 17280, 270, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 572940 . Total input tokens: 127961315 . Total output tokens: 112566747
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 7.671742675011046,
    "estimated_duration": 3600.040996486941,
    "input_throughput": 7343.404707279115,
    "output_throughput": 6421.188820504549,
    "total_throughput": 13764.593527783663,
    "itl": 82.41129697766435,
    "ttft": 1329281.0821368396,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23678970612585548,
    "arrivals": 190474,
    "finished_requests": 107360,
    "scheduler_time": 51.486659378853865
}
#Debug simulation 
Total elapsed time: 7.671922778012231. Arrivals time: 0.2999357662629336 Scheduler time: 7.198908246355131 Scheduler overhead time: 0.06349134352058172 Adapter cache time: 0.013349820976145566 Engine time: 0.06605027662590146 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-8/adapters_32_slots_32_rate_3.2-1.6-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-8/adapters_32_slots_32_rate_3.2-1.6-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 135, 135, 17280, 135, 34560, 17280, 135, 135, 135, 34560, 34560, 135, 135, 17280, 17280, 17280, 34560, 34560, 135, 34560, 34560, 34560, 34560, 17280, 135, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 571590 . Total input tokens: 127634182 . Total output tokens: 112310632
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 7.919425231986679,
    "estimated_duration": 3600.093748269787,
    "input_throughput": 7682.552714993173,
    "output_throughput": 6682.239319895961,
    "total_throughput": 14364.792034889133,
    "itl": 90.22391695092625,
    "ttft": 1280275.8898736972,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2115970890223979,
    "arrivals": 190041,
    "finished_requests": 111624,
    "scheduler_time": 59.40333744674934
}
#Debug simulation 
Total elapsed time: 7.919553258921951. Arrivals time: 0.3035926189040765 Scheduler time: 7.456408480764367 Scheduler overhead time: 0.058795514050871134 Adapter cache time: 0.011499913409352303 Engine time: 0.061225007637403905 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-16/adapters_32_slots_32_rate_3.2-1.6-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-16/adapters_32_slots_32_rate_3.2-1.6-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 135, 135, 17280, 135, 34560, 17280, 135, 135, 135, 34560, 34560, 135, 135, 17280, 17280, 17280, 34560, 34560, 135, 34560, 34560, 34560, 34560, 17280, 135, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 571590 . Total input tokens: 127634182 . Total output tokens: 112310632
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 7.895476655103266,
    "estimated_duration": 3600.022893833296,
    "input_throughput": 7612.4115896439125,
    "output_throughput": 6622.662050521955,
    "total_throughput": 14235.073640165867,
    "itl": 87.67145776234987,
    "ttft": 1293357.6046187405,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23482633151113982,
    "arrivals": 190041,
    "finished_requests": 110572,
    "scheduler_time": 57.30229694138163
}
#Debug simulation 
Total elapsed time: 7.895602821023203. Arrivals time: 0.3012034605490044 Scheduler time: 7.430251282756217 Scheduler overhead time: 0.06045957806054503 Adapter cache time: 0.011916509945876896 Engine time: 0.06308960681781173 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-32/adapters_32_slots_32_rate_3.2-1.6-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-32/adapters_32_slots_32_rate_3.2-1.6-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 135, 135, 17280, 135, 34560, 17280, 135, 135, 135, 34560, 34560, 135, 135, 17280, 17280, 17280, 34560, 34560, 135, 34560, 34560, 34560, 34560, 17280, 135, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 571590 . Total input tokens: 127634182 . Total output tokens: 112310632
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 7.682763822027482,
    "estimated_duration": 3600.0526458739637,
    "input_throughput": 7422.335345741353,
    "output_throughput": 6465.176565313719,
    "total_throughput": 13887.511911055073,
    "itl": 81.67935255509819,
    "ttft": 1323331.7525780376,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.24134628401137895,
    "arrivals": 190041,
    "finished_requests": 107887,
    "scheduler_time": 51.819938030851326
}
#Debug simulation 
Total elapsed time: 7.682886751019396. Arrivals time: 0.3022651937790215 Scheduler time: 7.207265569828451 Scheduler overhead time: 0.06399731105193496 Adapter cache time: 0.012438184581696987 Engine time: 0.06655541225336492 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.0125_size_8-16-16/adapters_32_slots_32_rate_3.2-1.6-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.0125_size_8-16-16/adapters_32_slots_32_rate_3.2-1.6-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 135, 135, 17280, 135, 34560, 17280, 135, 135, 135, 34560, 34560, 135, 135, 17280, 17280, 17280, 34560, 34560, 135, 34560, 34560, 34560, 34560, 17280, 135, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 571590 . Total input tokens: 127634182 . Total output tokens: 112310632
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 7.879605751018971,
    "estimated_duration": 3600.024888815686,
    "input_throughput": 7612.407371165558,
    "output_throughput": 6622.658380521171,
    "total_throughput": 14235.065751686729,
    "itl": 87.67304296651213,
    "ttft": 1293392.3845187097,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21955590080469842,
    "arrivals": 190041,
    "finished_requests": 110572,
    "scheduler_time": 57.302984157857665
}
#Debug simulation 
Total elapsed time: 7.879729859996587. Arrivals time: 0.32117708842270076 Scheduler time: 7.394620791892521 Scheduler overhead time: 0.060424624010920525 Adapter cache time: 0.012001769850030541 Engine time: 0.06288428546395153 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.0125_size_8-16-32/adapters_32_slots_32_rate_3.2-1.6-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.0125_size_8-16-32/adapters_32_slots_32_rate_3.2-1.6-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 135, 135, 17280, 135, 34560, 17280, 135, 135, 135, 34560, 34560, 135, 135, 17280, 17280, 17280, 34560, 34560, 135, 34560, 34560, 34560, 34560, 17280, 135, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 571590 . Total input tokens: 127634182 . Total output tokens: 112310632
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 7.716225425014272,
    "estimated_duration": 3600.0819190519665,
    "input_throughput": 7422.506654247686,
    "output_throughput": 6465.544541311314,
    "total_throughput": 13888.051195559,
    "itl": 81.67815650039489,
    "ttft": 1323376.7323408173,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23906799506861723,
    "arrivals": 190041,
    "finished_requests": 107892,
    "scheduler_time": 51.81907014384547
}
#Debug simulation 
Total elapsed time: 7.716345290071331. Arrivals time: 0.2971754742320627 Scheduler time: 7.245904474752024 Scheduler overhead time: 0.06381489254999906 Adapter cache time: 0.012489378917962313 Engine time: 0.06663044367451221 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.0125_size_16-16-16/adapters_32_slots_32_rate_3.2-1.6-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.0125_size_16-16-16/adapters_32_slots_32_rate_3.2-1.6-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 135, 135, 17280, 135, 34560, 17280, 135, 135, 135, 34560, 34560, 135, 135, 17280, 17280, 17280, 34560, 34560, 135, 34560, 34560, 34560, 34560, 17280, 135, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 571590 . Total input tokens: 127634182 . Total output tokens: 112310632
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 7.8674133259337395,
    "estimated_duration": 3600.062109219853,
    "input_throughput": 7612.247002577039,
    "output_throughput": 6622.49157839294,
    "total_throughput": 14234.738580969979,
    "itl": 87.67077083573419,
    "ttft": 1293419.1119756477,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20428547009825704,
    "arrivals": 190041,
    "finished_requests": 110571,
    "scheduler_time": 57.30191152203782
}
#Debug simulation 
Total elapsed time: 7.867522938991897. Arrivals time: 0.3099655285477638 Scheduler time: 7.393898225971498 Scheduler overhead time: 0.06024772650562227 Adapter cache time: 0.011947605176828802 Engine time: 0.06271722912788391 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.0125_size_16-16-32/adapters_32_slots_32_rate_3.2-1.6-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.0125_size_16-16-32/adapters_32_slots_32_rate_3.2-1.6-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 135, 135, 17280, 135, 34560, 17280, 135, 135, 135, 34560, 34560, 135, 135, 17280, 17280, 17280, 34560, 34560, 135, 34560, 34560, 34560, 34560, 17280, 135, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 571590 . Total input tokens: 127634182 . Total output tokens: 112310632
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 7.709227991988882,
    "estimated_duration": 3600.0335563169915,
    "input_throughput": 7422.463591516352,
    "output_throughput": 6465.275846987289,
    "total_throughput": 13887.73943850364,
    "itl": 81.67924393064942,
    "ttft": 1323331.5793310753,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2367897061258555,
    "arrivals": 190041,
    "finished_requests": 107889,
    "scheduler_time": 51.818885871491865
}
#Debug simulation 
Total elapsed time: 7.70940306596458. Arrivals time: 0.29873552883509547 Scheduler time: 7.237023967085406 Scheduler overhead time: 0.06393671641126275 Adapter cache time: 0.01256687962450087 Engine time: 0.06659703550394624 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-8/adapters_32_slots_32_rate_3.2-1.6-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-8/adapters_32_slots_32_rate_3.2-1.6-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 66, 66, 17280, 66, 34560, 17280, 66, 66, 66, 34560, 34560, 66, 66, 17280, 17280, 17280, 34560, 34560, 66, 34560, 34560, 34560, 34560, 17280, 66, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 570900 . Total input tokens: 127485006 . Total output tokens: 112169169
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 7.988796826917678,
    "estimated_duration": 3600.0259825090557,
    "input_throughput": 7790.80738202129,
    "output_throughput": 6724.19396904703,
    "total_throughput": 14515.00135106832,
    "itl": 89.33782157086559,
    "ttft": 1266827.7012595725,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2115970890223979,
    "arrivals": 189807,
    "finished_requests": 112741,
    "scheduler_time": 59.774656664810585
}
#Debug simulation 
Total elapsed time: 7.9889120269799605. Arrivals time: 0.3068937270436436 Scheduler time: 7.522195274243131 Scheduler overhead time: 0.05925627052783966 Adapter cache time: 0.010896932450123131 Engine time: 0.061727486667223275 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-16/adapters_32_slots_32_rate_3.2-1.6-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-16/adapters_32_slots_32_rate_3.2-1.6-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 66, 66, 17280, 66, 34560, 17280, 66, 66, 66, 34560, 34560, 66, 66, 17280, 17280, 17280, 34560, 34560, 66, 34560, 34560, 34560, 34560, 17280, 66, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 570900 . Total input tokens: 127485006 . Total output tokens: 112169169
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 7.891510236077011,
    "estimated_duration": 3600.0622884828513,
    "input_throughput": 7713.458761210063,
    "output_throughput": 6664.483577619157,
    "total_throughput": 14377.94233882922,
    "itl": 86.9122475341198,
    "ttft": 1278973.734674455,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23482633151113985,
    "arrivals": 189807,
    "finished_requests": 111677,
    "scheduler_time": 57.71114577139683
}
#Debug simulation 
Total elapsed time: 7.891626641037874. Arrivals time: 0.3219134859973565 Scheduler time: 7.405769057688303 Scheduler overhead time: 0.060756287653930485 Adapter cache time: 0.01112649799324572 Engine time: 0.06340476160403341 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-32/adapters_32_slots_32_rate_3.2-1.6-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-32/adapters_32_slots_32_rate_3.2-1.6-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 66, 66, 17280, 66, 34560, 17280, 66, 66, 66, 34560, 34560, 66, 66, 17280, 17280, 17280, 34560, 34560, 66, 34560, 34560, 34560, 34560, 17280, 66, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 570900 . Total input tokens: 127485006 . Total output tokens: 112169169
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 7.831631492939778,
    "estimated_duration": 3600.015229359272,
    "input_throughput": 7523.005952622096,
    "output_throughput": 6502.050827203319,
    "total_throughput": 14025.056779825414,
    "itl": 81.00621082903928,
    "ttft": 1311101.0155871578,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.24134628401137892,
    "arrivals": 189807,
    "finished_requests": 108874,
    "scheduler_time": 52.132148453183056
}
#Debug simulation 
Total elapsed time: 7.831726911012083. Arrivals time: 0.3222838413203135 Scheduler time: 7.335070517612621 Scheduler overhead time: 0.06488984706811607 Adapter cache time: 0.011844264576211572 Engine time: 0.06720607541501522 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.00625_size_8-16-16/adapters_32_slots_32_rate_3.2-1.6-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.00625_size_8-16-16/adapters_32_slots_32_rate_3.2-1.6-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 66, 66, 17280, 66, 34560, 17280, 66, 66, 66, 34560, 34560, 66, 66, 17280, 17280, 17280, 34560, 34560, 66, 34560, 34560, 34560, 34560, 17280, 66, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 570900 . Total input tokens: 127485006 . Total output tokens: 112169169
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 7.921679197927006,
    "estimated_duration": 3600.0575183775995,
    "input_throughput": 7713.612312648429,
    "output_throughput": 6664.614072836445,
    "total_throughput": 14378.226385484875,
    "itl": 86.90886150946358,
    "ttft": 1278908.7551914623,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21955590080469842,
    "arrivals": 189807,
    "finished_requests": 111679,
    "scheduler_time": 57.70840295177107
}
#Debug simulation 
Total elapsed time: 7.9217975969659165. Arrivals time: 0.32197297329548746 Scheduler time: 7.435511097428389 Scheduler overhead time: 0.060994828469119966 Adapter cache time: 0.011183234862983227 Engine time: 0.06332784902770072 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.00625_size_8-16-32/adapters_32_slots_32_rate_3.2-1.6-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.00625_size_8-16-32/adapters_32_slots_32_rate_3.2-1.6-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 66, 66, 17280, 66, 34560, 17280, 66, 66, 66, 34560, 34560, 66, 66, 17280, 17280, 17280, 34560, 34560, 66, 34560, 34560, 34560, 34560, 17280, 66, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 570900 . Total input tokens: 127485006 . Total output tokens: 112169169
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 7.758409493020736,
    "estimated_duration": 3600.077248581709,
    "input_throughput": 7522.986349992847,
    "output_throughput": 6502.052423797796,
    "total_throughput": 14025.038773790642,
    "itl": 81.00796870407409,
    "ttft": 1310996.7087367848,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2390679950686172,
    "arrivals": 189807,
    "finished_requests": 108875,
    "scheduler_time": 52.13457978100084
}
#Debug simulation 
Total elapsed time: 7.758533129002899. Arrivals time: 0.3163081997772679 Scheduler time: 7.267998616909608 Scheduler overhead time: 0.0645779223414138 Adapter cache time: 0.011787826078943908 Engine time: 0.06742616556584835 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.00625_size_16-16-16/adapters_32_slots_32_rate_3.2-1.6-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.00625_size_16-16-16/adapters_32_slots_32_rate_3.2-1.6-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 66, 66, 17280, 66, 34560, 17280, 66, 66, 66, 34560, 34560, 66, 66, 17280, 17280, 17280, 34560, 34560, 66, 34560, 34560, 34560, 34560, 17280, 66, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 570900 . Total input tokens: 127485006 . Total output tokens: 112169169
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 7.902829968952574,
    "estimated_duration": 3600.039295970366,
    "input_throughput": 7710.566668277972,
    "output_throughput": 6662.696717463121,
    "total_throughput": 14373.263385741093,
    "itl": 86.84267611048864,
    "ttft": 1279154.6106458153,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20428547009825704,
    "arrivals": 189807,
    "finished_requests": 111643,
    "scheduler_time": 57.649248821431144
}
#Debug simulation 
Total elapsed time: 7.902960681007244. Arrivals time: 0.3201317497296259 Scheduler time: 7.419120034086518 Scheduler overhead time: 0.060679979040287435 Adapter cache time: 0.011111852014437318 Engine time: 0.063257229863666 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.00625_size_16-16-32/adapters_32_slots_32_rate_3.2-1.6-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.00625_size_16-16-32/adapters_32_slots_32_rate_3.2-1.6-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 66, 66, 17280, 66, 34560, 17280, 66, 66, 66, 34560, 34560, 66, 66, 17280, 17280, 17280, 34560, 34560, 66, 34560, 34560, 34560, 34560, 17280, 66, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 570900 . Total input tokens: 127485006 . Total output tokens: 112169169
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 7.723900965065695,
    "estimated_duration": 3600.0332526111974,
    "input_throughput": 7523.063566247838,
    "output_throughput": 6502.033830665843,
    "total_throughput": 14025.097396913681,
    "itl": 81.00861813223712,
    "ttft": 1311100.7231478747,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23678970612585548,
    "arrivals": 189807,
    "finished_requests": 108874,
    "scheduler_time": 52.134567755169876
}
#Debug simulation 
Total elapsed time: 7.724079402978532. Arrivals time: 0.3010478802025318 Scheduler time: 7.249190655304119 Scheduler overhead time: 0.0644278860418126 Adapter cache time: 0.011681073694489896 Engine time: 0.06721540784928948 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.003125_size_8-8-8/adapters_32_slots_32_rate_3.2-1.6-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.003125_size_8-8-8/adapters_32_slots_32_rate_3.2-1.6-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 33, 33, 17280, 33, 34560, 17280, 33, 33, 33, 34560, 34560, 33, 33, 17280, 17280, 17280, 34560, 34560, 33, 34560, 34560, 34560, 34560, 17280, 33, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 570570 . Total input tokens: 127408721 . Total output tokens: 112106331
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 7.940949317999184,
    "estimated_duration": 3600.06195922771,
    "input_throughput": 7720.534900450017,
    "output_throughput": 6739.550395184001,
    "total_throughput": 14460.085295634019,
    "itl": 89.48684133450188,
    "ttft": 1267129.494857402,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2115970890223979,
    "arrivals": 189688,
    "finished_requests": 112346,
    "scheduler_time": 60.00823208461266
}
#Debug simulation 
Total elapsed time: 7.941070475033484. Arrivals time: 0.3050529344473034 Scheduler time: 7.476648681215011 Scheduler overhead time: 0.05913866264745593 Adapter cache time: 0.010586606455035508 Engine time: 0.061681902036070824 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.003125_size_8-8-16/adapters_32_slots_32_rate_3.2-1.6-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.003125_size_8-8-16/adapters_32_slots_32_rate_3.2-1.6-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 33, 33, 17280, 33, 34560, 17280, 33, 33, 33, 34560, 34560, 33, 33, 17280, 17280, 17280, 34560, 34560, 33, 34560, 34560, 34560, 34560, 17280, 33, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 570570 . Total input tokens: 127408721 . Total output tokens: 112106331
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 7.9400594549952075,
    "estimated_duration": 3600.0654943469463,
    "input_throughput": 7647.17948693709,
    "output_throughput": 6675.929934535744,
    "total_throughput": 14323.109421472833,
    "itl": 86.98810955558999,
    "ttft": 1279118.777442793,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23482633151113985,
    "arrivals": 189688,
    "finished_requests": 111277,
    "scheduler_time": 57.87124165398664
}
#Debug simulation 
Total elapsed time: 7.94018000701908. Arrivals time: 0.3184825296048075 Scheduler time: 7.45814879226964 Scheduler overhead time: 0.06081494863610715 Adapter cache time: 0.010948080103844404 Engine time: 0.06309074745513499 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.003125_size_8-8-32/adapters_32_slots_32_rate_3.2-1.6-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.003125_size_8-8-32/adapters_32_slots_32_rate_3.2-1.6-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 33, 33, 17280, 33, 34560, 17280, 33, 33, 33, 34560, 34560, 33, 33, 17280, 17280, 17280, 34560, 34560, 33, 34560, 34560, 34560, 34560, 17280, 33, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 570570 . Total input tokens: 127408721 . Total output tokens: 112106331
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 7.756526262033731,
    "estimated_duration": 3600.050948336925,
    "input_throughput": 7463.742704089442,
    "output_throughput": 6513.456986166367,
    "total_throughput": 13977.19969025581,
    "itl": 81.07681236994291,
    "ttft": 1311122.8728608098,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.24134628401137892,
    "arrivals": 189688,
    "finished_requests": 108598,
    "scheduler_time": 52.30874453719205
}
#Debug simulation 
Total elapsed time: 7.756620196974836. Arrivals time: 0.318113035755232 Scheduler time: 7.26538887002971 Scheduler overhead time: 0.06438971648458391 Adapter cache time: 0.011487266630865633 Engine time: 0.0667899891268462 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.003125_size_8-16-16/adapters_32_slots_32_rate_3.2-1.6-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.003125_size_8-16-16/adapters_32_slots_32_rate_3.2-1.6-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 33, 33, 17280, 33, 34560, 17280, 33, 33, 33, 34560, 34560, 33, 33, 17280, 17280, 17280, 34560, 34560, 33, 34560, 34560, 34560, 34560, 17280, 33, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 570570 . Total input tokens: 127408721 . Total output tokens: 112106331
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 8.157012887997553,
    "estimated_duration": 3600.0374293959007,
    "input_throughput": 7647.155214333325,
    "output_throughput": 6675.981422791195,
    "total_throughput": 14323.136637124519,
    "itl": 86.98834341045267,
    "ttft": 1279185.163847511,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21955590080469842,
    "arrivals": 189688,
    "finished_requests": 111276,
    "scheduler_time": 57.87121306852494
}
#Debug simulation 
Total elapsed time: 8.157106727012433. Arrivals time: 0.5298672869103029 Scheduler time: 7.463795174728148 Scheduler overhead time: 0.06077193806413561 Adapter cache time: 0.010938082472421229 Engine time: 0.06298832839820534 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.003125_size_8-16-32/adapters_32_slots_32_rate_3.2-1.6-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.003125_size_8-16-32/adapters_32_slots_32_rate_3.2-1.6-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 33, 33, 17280, 33, 34560, 17280, 33, 33, 33, 34560, 34560, 33, 33, 17280, 17280, 17280, 34560, 34560, 33, 34560, 34560, 34560, 34560, 17280, 33, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 570570 . Total input tokens: 127408721 . Total output tokens: 112106331
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 7.760430344962515,
    "estimated_duration": 3600.0814351286976,
    "input_throughput": 7463.781162783455,
    "output_throughput": 6513.605712133485,
    "total_throughput": 13977.38687491694,
    "itl": 81.07642034552813,
    "ttft": 1311116.8334795334,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2390679950686172,
    "arrivals": 189688,
    "finished_requests": 108599,
    "scheduler_time": 52.308208195852906
}
#Debug simulation 
Total elapsed time: 7.760549032012932. Arrivals time: 0.3140387007733807 Scheduler time: 7.272730061900802 Scheduler overhead time: 0.0645383185474202 Adapter cache time: 0.011596534051932395 Engine time: 0.06730496429372579 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.003125_size_16-16-16/adapters_32_slots_32_rate_3.2-1.6-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.003125_size_16-16-16/adapters_32_slots_32_rate_3.2-1.6-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 33, 33, 17280, 33, 34560, 17280, 33, 33, 33, 34560, 34560, 33, 33, 17280, 17280, 17280, 34560, 34560, 33, 34560, 34560, 34560, 34560, 17280, 33, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 570570 . Total input tokens: 127408721 . Total output tokens: 112106331
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 7.977575034019537,
    "estimated_duration": 3600.0815303536983,
    "input_throughput": 7647.189867195925,
    "output_throughput": 6676.124081456196,
    "total_throughput": 14323.313948652121,
    "itl": 86.98827166023213,
    "ttft": 1279109.5041024943,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20428547009825704,
    "arrivals": 189688,
    "finished_requests": 111279,
    "scheduler_time": 57.872063698315024
}
#Debug simulation 
Total elapsed time: 7.9776966699864715. Arrivals time: 0.3041366736870259 Scheduler time: 7.508099828031845 Scheduler overhead time: 0.06145521462894976 Adapter cache time: 0.011066916398704052 Engine time: 0.06363957829307765 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.003125_size_16-16-32/adapters_32_slots_32_rate_3.2-1.6-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.003125_size_16-16-32/adapters_32_slots_32_rate_3.2-1.6-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 17280, 33, 33, 17280, 33, 34560, 17280, 33, 33, 33, 34560, 34560, 33, 33, 17280, 17280, 17280, 34560, 34560, 33, 34560, 34560, 34560, 34560, 17280, 33, 17280, 17280, 17280, 17280, 34560]
Prompts retrieved: 570570 . Total input tokens: 127408721 . Total output tokens: 112106331
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 7.755580927943811,
    "estimated_duration": 3600.02447043217,
    "input_throughput": 7463.3059360217585,
    "output_throughput": 6513.196283131151,
    "total_throughput": 13976.50221915291,
    "itl": 81.07644303063023,
    "ttft": 1311211.5750153086,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2367897061258555,
    "arrivals": 189688,
    "finished_requests": 108592,
    "scheduler_time": 52.30799076878707
}
#Debug simulation 
Total elapsed time: 7.755755626014434. Arrivals time: 0.294077564147301 Scheduler time: 7.286804892588407 Scheduler overhead time: 0.0648074921919033 Adapter cache time: 0.01162330771330744 Engine time: 0.0676316455937922 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.4_size_8-8-8/adapters_32_slots_32_rate_3.2-0.8-0.4_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.4_size_8-8-8/adapters_32_slots_32_rate_3.2-0.8-0.4_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 4320, 4320, 8640, 4320, 34560, 8640, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 8640, 8640, 8640, 34560, 34560, 4320, 34560, 34560, 34560, 34560, 8640, 4320, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 518400 . Total input tokens: 115643427 . Total output tokens: 101855273
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 7.378496484947391,
    "estimated_duration": 3600.045089349516,
    "input_throughput": 7183.246142251121,
    "output_throughput": 6270.34313175193,
    "total_throughput": 13453.58927400305,
    "itl": 96.11174202147747,
    "ttft": 1275089.2532347916,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2115970890223979,
    "arrivals": 172540,
    "finished_requests": 104586,
    "scheduler_time": 56.74121714812348
}
#Debug simulation 
Total elapsed time: 7.378611097927205. Arrivals time: 0.2880018688738346 Scheduler time: 6.942287621088326 Scheduler overhead time: 0.055135627975687385 Adapter cache time: 0.009642968303523958 Engine time: 0.057372835697606206 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.4_size_8-8-16/adapters_32_slots_32_rate_3.2-0.8-0.4_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.4_size_8-8-16/adapters_32_slots_32_rate_3.2-0.8-0.4_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 4320, 4320, 8640, 4320, 34560, 8640, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 8640, 8640, 8640, 34560, 34560, 4320, 34560, 34560, 34560, 34560, 8640, 4320, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 518400 . Total input tokens: 115643427 . Total output tokens: 101855273
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 7.40751061309129,
    "estimated_duration": 3600.0663526637113,
    "input_throughput": 7115.5866282981515,
    "output_throughput": 6214.1229656635,
    "total_throughput": 13329.70959396165,
    "itl": 93.44431284627962,
    "ttft": 1287329.665695378,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23482633151113985,
    "arrivals": 172540,
    "finished_requests": 103628,
    "scheduler_time": 54.74718346422694
}
#Debug simulation 
Total elapsed time: 7.407603879109956. Arrivals time: 0.2844099613139406 Scheduler time: 6.970660724211484 Scheduler overhead time: 0.056781145045533776 Adapter cache time: 0.009974339161999524 Engine time: 0.05902944190893322 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.4_size_8-8-32/adapters_32_slots_32_rate_3.2-0.8-0.4_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.4_size_8-8-32/adapters_32_slots_32_rate_3.2-0.8-0.4_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 4320, 4320, 8640, 4320, 34560, 8640, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 8640, 8640, 8640, 34560, 34560, 4320, 34560, 34560, 34560, 34560, 8640, 4320, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 518400 . Total input tokens: 115643427 . Total output tokens: 101855273
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 7.40416748507414,
    "estimated_duration": 3600.0168142259254,
    "input_throughput": 6943.409236652334,
    "output_throughput": 6061.491689085915,
    "total_throughput": 13004.90092573825,
    "itl": 87.13179512526042,
    "ttft": 1320634.8893892742,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.24134628401137892,
    "arrivals": 172540,
    "finished_requests": 101065,
    "scheduler_time": 49.57191169943044
}
#Debug simulation 
Total elapsed time: 7.404278272064403. Arrivals time: 0.2891293668653816 Scheduler time: 6.953627096838318 Scheduler overhead time: 0.05990997643675655 Adapter cache time: 0.010623792768456042 Engine time: 0.06265525426715612 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.4_size_8-16-16/adapters_32_slots_32_rate_3.2-0.8-0.4_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.4_size_8-16-16/adapters_32_slots_32_rate_3.2-0.8-0.4_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 4320, 4320, 8640, 4320, 34560, 8640, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 8640, 8640, 8640, 34560, 34560, 4320, 34560, 34560, 34560, 34560, 8640, 4320, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 518400 . Total input tokens: 115643427 . Total output tokens: 101855273
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 7.356295712990686,
    "estimated_duration": 3600.0976381508267,
    "input_throughput": 7115.416184422608,
    "output_throughput": 6214.134517610198,
    "total_throughput": 13329.550702032806,
    "itl": 93.44439633874461,
    "ttft": 1287345.1431777405,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21955590080469845,
    "arrivals": 172540,
    "finished_requests": 103627,
    "scheduler_time": 54.74743195031688
}
#Debug simulation 
Total elapsed time: 7.356420248979703. Arrivals time: 0.28879554686136544 Scheduler time: 6.915491836844012 Scheduler overhead time: 0.05653601896483451 Adapter cache time: 0.009888903237879276 Engine time: 0.05912984802853316 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.4_size_8-16-32/adapters_32_slots_32_rate_3.2-0.8-0.4_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.4_size_8-16-32/adapters_32_slots_32_rate_3.2-0.8-0.4_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 4320, 4320, 8640, 4320, 34560, 8640, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 8640, 8640, 8640, 34560, 34560, 4320, 34560, 34560, 34560, 34560, 8640, 4320, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 518400 . Total input tokens: 115643427 . Total output tokens: 101855273
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 7.257344131008722,
    "estimated_duration": 3600.012041709461,
    "input_throughput": 6942.827332358452,
    "output_throughput": 6061.158337025641,
    "total_throughput": 13003.985669384094,
    "itl": 87.13219058579791,
    "ttft": 1320609.7541381083,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2390679950686172,
    "arrivals": 172540,
    "finished_requests": 101057,
    "scheduler_time": 49.571874833689286
}
#Debug simulation 
Total elapsed time: 7.257467860006727. Arrivals time: 0.2806822962593287 Scheduler time: 6.814615746377967 Scheduler overhead time: 0.060224882792681456 Adapter cache time: 0.0107374555664137 Engine time: 0.06275368854403496 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.4_size_16-16-16/adapters_32_slots_32_rate_3.2-0.8-0.4_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.4_size_16-16-16/adapters_32_slots_32_rate_3.2-0.8-0.4_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 4320, 4320, 8640, 4320, 34560, 8640, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 8640, 8640, 8640, 34560, 34560, 4320, 34560, 34560, 34560, 34560, 8640, 4320, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 518400 . Total input tokens: 115643427 . Total output tokens: 101855273
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 7.387353166937828,
    "estimated_duration": 3600.047774049765,
    "input_throughput": 7115.651960135874,
    "output_throughput": 6214.306977052562,
    "total_throughput": 13329.958937188436,
    "itl": 93.44387015638587,
    "ttft": 1287282.0203019797,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20428547009825704,
    "arrivals": 172540,
    "finished_requests": 103629,
    "scheduler_time": 54.74690217746744
}
#Debug simulation 
Total elapsed time: 7.38747842295561. Arrivals time: 0.2922318852506578 Scheduler time: 6.943043855484575 Scheduler overhead time: 0.056679217144846916 Adapter cache time: 0.00994743884075433 Engine time: 0.05875875987112522 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.4_size_16-16-32/adapters_32_slots_32_rate_3.2-0.8-0.4_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.4_size_16-16-32/adapters_32_slots_32_rate_3.2-0.8-0.4_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 4320, 4320, 8640, 4320, 34560, 8640, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 8640, 8640, 8640, 34560, 34560, 4320, 34560, 34560, 34560, 34560, 8640, 4320, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 518400 . Total input tokens: 115643427 . Total output tokens: 101855273
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 7.184882665984333,
    "estimated_duration": 3600.0004082416544,
    "input_throughput": 6942.759212687914,
    "output_throughput": 6061.149590440628,
    "total_throughput": 13003.908803128543,
    "itl": 87.1340704266273,
    "ttft": 1320606.455952739,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23678970612585548,
    "arrivals": 172540,
    "finished_requests": 101056,
    "scheduler_time": 49.57375256482889
}
#Debug simulation 
Total elapsed time: 7.1850558769656345. Arrivals time: 0.28232208837289363 Scheduler time: 6.7421074610902 Scheduler overhead time: 0.05957495991606265 Adapter cache time: 0.010613477323204279 Engine time: 0.06210642296355218 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.1_size_8-8-8/adapters_32_slots_32_rate_3.2-0.8-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.1_size_8-8-8/adapters_32_slots_32_rate_3.2-0.8-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 1080, 1080, 8640, 1080, 34560, 8640, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 8640, 8640, 8640, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 8640, 1080, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 486000 . Total input tokens: 108409730 . Total output tokens: 95518396
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 7.588931918027811,
    "estimated_duration": 3600.0917006142586,
    "input_throughput": 7330.179393901932,
    "output_throughput": 6371.209098947794,
    "total_throughput": 13701.388492849725,
    "itl": 94.29172331148487,
    "ttft": 1194421.5431430337,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2115970890223979,
    "arrivals": 161835,
    "finished_requests": 106250,
    "scheduler_time": 59.07039971421339
}
#Debug simulation 
Total elapsed time: 7.589038486941718. Arrivals time: 0.2934474088251591 Scheduler time: 7.140270847128704 Scheduler overhead time: 0.05650835344567895 Adapter cache time: 0.013297847239300609 Engine time: 0.058778673759661615 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.1_size_8-8-16/adapters_32_slots_32_rate_3.2-0.8-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.1_size_8-8-16/adapters_32_slots_32_rate_3.2-0.8-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 1080, 1080, 8640, 1080, 34560, 8640, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 8640, 8640, 8640, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 8640, 1080, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 486000 . Total input tokens: 108409730 . Total output tokens: 95518396
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 7.479959138901904,
    "estimated_duration": 3600.0390423476797,
    "input_throughput": 7266.876190025901,
    "output_throughput": 6315.575118089012,
    "total_throughput": 13582.451308114913,
    "itl": 91.56972486416056,
    "ttft": 1206163.089383843,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23482633151113985,
    "arrivals": 161835,
    "finished_requests": 105322,
    "scheduler_time": 57.10139664424336
}
#Debug simulation 
Total elapsed time: 7.480076839914545. Arrivals time: 0.28753456310369074 Scheduler time: 7.03395071986597 Scheduler overhead time: 0.05762182630132884 Adapter cache time: 0.013577274279668927 Engine time: 0.0601291845086962 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.1_size_8-8-32/adapters_32_slots_32_rate_3.2-0.8-0.1_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.1_size_8-8-32/adapters_32_slots_32_rate_3.2-0.8-0.1_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 1080, 1080, 8640, 1080, 34560, 8640, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 8640, 8640, 8640, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 8640, 1080, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 486000 . Total input tokens: 108409730 . Total output tokens: 95518396
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 7.357137138955295,
    "estimated_duration": 3600.008124885328,
    "input_throughput": 7110.919506831786,
    "output_throughput": 6177.744946258535,
    "total_throughput": 13288.664453090321,
    "itl": 85.15820876618851,
    "ttft": 1238393.2438597686,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.24134628401137892,
    "arrivals": 161835,
    "finished_requests": 103014,
    "scheduler_time": 51.95287994584792
}
#Debug simulation 
Total elapsed time: 7.357252401998267. Arrivals time: 0.2882504345616326 Scheduler time: 6.900050579337403 Scheduler overhead time: 0.06116444547660649 Adapter cache time: 0.014704815577715635 Engine time: 0.06396127305924892 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.1_size_8-16-16/adapters_32_slots_32_rate_3.2-0.8-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.1_size_8-16-16/adapters_32_slots_32_rate_3.2-0.8-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 1080, 1080, 8640, 1080, 34560, 8640, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 8640, 8640, 8640, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 8640, 1080, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 486000 . Total input tokens: 108409730 . Total output tokens: 95518396
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 7.537413774058223,
    "estimated_duration": 3600.018421631845,
    "input_throughput": 7266.768370630104,
    "output_throughput": 6315.5324048853145,
    "total_throughput": 13582.30077551542,
    "itl": 91.56720905036016,
    "ttft": 1206185.8438516282,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21955590080469842,
    "arrivals": 161835,
    "finished_requests": 105321,
    "scheduler_time": 57.101371242620644
}
#Debug simulation 
Total elapsed time: 7.537535020033829. Arrivals time: 0.30517086246982217 Scheduler time: 7.072906655957922 Scheduler overhead time: 0.05796539259608835 Adapter cache time: 0.013641812722198665 Engine time: 0.06062990881036967 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.1_size_8-16-32/adapters_32_slots_32_rate_3.2-0.8-0.1_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.1_size_8-16-32/adapters_32_slots_32_rate_3.2-0.8-0.1_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 1080, 1080, 8640, 1080, 34560, 8640, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 8640, 8640, 8640, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 8640, 1080, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 486000 . Total input tokens: 108409730 . Total output tokens: 95518396
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 7.386730285943486,
    "estimated_duration": 3600.0428678042413,
    "input_throughput": 7110.731716262438,
    "output_throughput": 6177.526717498327,
    "total_throughput": 13288.258433760766,
    "itl": 85.1590692323669,
    "ttft": 1238419.129528038,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2390679950686172,
    "arrivals": 161835,
    "finished_requests": 103013,
    "scheduler_time": 51.952698497178346
}
#Debug simulation 
Total elapsed time: 7.386854758951813. Arrivals time: 0.28600345994345844 Scheduler time: 6.932100351899862 Scheduler overhead time: 0.06136534339748323 Adapter cache time: 0.014727786765433848 Engine time: 0.06366553017869592 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.1_size_16-16-16/adapters_32_slots_32_rate_3.2-0.8-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.1_size_16-16-16/adapters_32_slots_32_rate_3.2-0.8-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 1080, 1080, 8640, 1080, 34560, 8640, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 8640, 8640, 8640, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 8640, 1080, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 486000 . Total input tokens: 108409730 . Total output tokens: 95518396
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 7.484385125921108,
    "estimated_duration": 3600.0867121876818,
    "input_throughput": 7266.8363546450455,
    "output_throughput": 6315.540934896983,
    "total_throughput": 13582.37728954203,
    "itl": 91.56858204773852,
    "ttft": 1206152.4467721027,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20428547009825704,
    "arrivals": 161835,
    "finished_requests": 105322,
    "scheduler_time": 57.1020436053689
}
#Debug simulation 
Total elapsed time: 7.484513553907163. Arrivals time: 0.2876648996025324 Scheduler time: 7.0383875095285475 Scheduler overhead time: 0.05758595000952482 Adapter cache time: 0.013565115979872644 Engine time: 0.06011851935181767 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.1_size_16-16-32/adapters_32_slots_32_rate_3.2-0.8-0.1_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.1_size_16-16-32/adapters_32_slots_32_rate_3.2-0.8-0.1_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 1080, 1080, 8640, 1080, 34560, 8640, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 8640, 8640, 8640, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 8640, 1080, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 486000 . Total input tokens: 108409730 . Total output tokens: 95518396
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 7.409792163991369,
    "estimated_duration": 3600.0189651149794,
    "input_throughput": 7110.720873433625,
    "output_throughput": 6177.529956231692,
    "total_throughput": 13288.250829665316,
    "itl": 85.15675062653315,
    "ttft": 1238422.7727982602,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23678970612585548,
    "arrivals": 161835,
    "finished_requests": 103013,
    "scheduler_time": 51.951700924784895
}
#Debug simulation 
Total elapsed time: 7.409946078085341. Arrivals time: 0.2837419448187575 Scheduler time: 6.956967492820695 Scheduler overhead time: 0.06137790053617209 Adapter cache time: 0.014543750556185842 Engine time: 0.06418492260854691 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.05_size_8-8-8/adapters_32_slots_32_rate_3.2-0.8-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.05_size_8-8-8/adapters_32_slots_32_rate_3.2-0.8-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 540, 540, 8640, 540, 34560, 8640, 540, 540, 540, 34560, 34560, 540, 540, 8640, 8640, 8640, 34560, 34560, 540, 34560, 34560, 34560, 34560, 8640, 540, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 480600 . Total input tokens: 107207044 . Total output tokens: 94440961
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 7.708380013005808,
    "estimated_duration": 3600.0542460744578,
    "input_throughput": 7464.68140842681,
    "output_throughput": 6488.217233245797,
    "total_throughput": 13952.898641672606,
    "itl": 92.85649829518924,
    "ttft": 1150824.1421817206,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2115970890223979,
    "arrivals": 160041,
    "finished_requests": 108561,
    "scheduler_time": 61.08497857621055
}
#Debug simulation 
Total elapsed time: 7.708474968094379. Arrivals time: 0.29575824178755283 Scheduler time: 7.2555411354405805 Scheduler overhead time: 0.05723292310722172 Adapter cache time: 0.013313148519955575 Engine time: 0.05957183672580868 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.05_size_8-8-16/adapters_32_slots_32_rate_3.2-0.8-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.05_size_8-8-16/adapters_32_slots_32_rate_3.2-0.8-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 540, 540, 8640, 540, 34560, 8640, 540, 540, 540, 34560, 34560, 540, 540, 8640, 8640, 8640, 34560, 34560, 540, 34560, 34560, 34560, 34560, 8640, 540, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 480600 . Total input tokens: 107207044 . Total output tokens: 94440961
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 7.599679213017225,
    "estimated_duration": 3600.0641926497237,
    "input_throughput": 7396.091729242861,
    "output_throughput": 6431.869755899359,
    "total_throughput": 13827.96148514222,
    "itl": 90.21832753637756,
    "ttft": 1162905.9012957863,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23482633151113985,
    "arrivals": 160041,
    "finished_requests": 107587,
    "scheduler_time": 59.076986185823266
}
#Debug simulation 
Total elapsed time: 7.5997715999837965. Arrivals time: 0.31245151814073324 Scheduler time: 7.126462368061766 Scheduler overhead time: 0.05846703110728413 Adapter cache time: 0.013668669969774783 Engine time: 0.06111564254388213 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.05_size_8-8-32/adapters_32_slots_32_rate_3.2-0.8-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.05_size_8-8-32/adapters_32_slots_32_rate_3.2-0.8-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 540, 540, 8640, 540, 34560, 8640, 540, 540, 540, 34560, 34560, 540, 540, 8640, 8640, 8640, 34560, 34560, 540, 34560, 34560, 34560, 34560, 8640, 540, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 480600 . Total input tokens: 107207044 . Total output tokens: 94440961
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 7.476940317079425,
    "estimated_duration": 3600.0718790133114,
    "input_throughput": 7228.584004587253,
    "output_throughput": 6287.308076249748,
    "total_throughput": 13515.892080837002,
    "itl": 83.94699107224002,
    "ttft": 1196395.4049828276,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.24134628401137895,
    "arrivals": 160041,
    "finished_requests": 105146,
    "scheduler_time": 53.814301975765524
}
#Debug simulation 
Total elapsed time: 7.477034990093671. Arrivals time: 0.2938621810171753 Scheduler time: 7.0122283913660794 Scheduler overhead time: 0.062191350501962006 Adapter cache time: 0.01455588301178068 Engine time: 0.06464204005897045 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.05_size_8-16-16/adapters_32_slots_32_rate_3.2-0.8-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.05_size_8-16-16/adapters_32_slots_32_rate_3.2-0.8-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 540, 540, 8640, 540, 34560, 8640, 540, 540, 540, 34560, 34560, 540, 540, 8640, 8640, 8640, 34560, 34560, 540, 34560, 34560, 34560, 34560, 8640, 540, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 480600 . Total input tokens: 107207044 . Total output tokens: 94440961
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 7.674695361987688,
    "estimated_duration": 3600.086595443717,
    "input_throughput": 7395.819321040067,
    "output_throughput": 6431.7375113434255,
    "total_throughput": 13827.556832383492,
    "itl": 90.21973667305922,
    "ttft": 1162973.353105895,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2195559008046984,
    "arrivals": 160041,
    "finished_requests": 107586,
    "scheduler_time": 59.07816658520679
}
#Debug simulation 
Total elapsed time: 7.674787539988756. Arrivals time: 0.2930360744940117 Scheduler time: 7.22005508816801 Scheduler overhead time: 0.05866177729330957 Adapter cache time: 0.013684364734217525 Engine time: 0.06156862364150584 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.05_size_8-16-32/adapters_32_slots_32_rate_3.2-0.8-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.05_size_8-16-32/adapters_32_slots_32_rate_3.2-0.8-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 540, 540, 8640, 540, 34560, 8640, 540, 540, 540, 34560, 34560, 540, 540, 8640, 8640, 8640, 34560, 34560, 540, 34560, 34560, 34560, 34560, 8640, 540, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 480600 . Total input tokens: 107207044 . Total output tokens: 94440961
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 7.464011305011809,
    "estimated_duration": 3600.068341865523,
    "input_throughput": 7228.59110683296,
    "output_throughput": 6287.314253670771,
    "total_throughput": 13515.90536050373,
    "itl": 83.94678870626274,
    "ttft": 1196333.8671266052,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2390679950686172,
    "arrivals": 160041,
    "finished_requests": 105146,
    "scheduler_time": 53.815161319530056
}
#Debug simulation 
Total elapsed time: 7.464105089078657. Arrivals time: 0.29192825383506715 Scheduler time: 7.00224149657879 Scheduler overhead time: 0.0618268238613382 Adapter cache time: 0.014490359579212964 Engine time: 0.06435184308793396 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.05_size_16-16-16/adapters_32_slots_32_rate_3.2-0.8-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.05_size_16-16-16/adapters_32_slots_32_rate_3.2-0.8-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 540, 540, 8640, 540, 34560, 8640, 540, 540, 540, 34560, 34560, 540, 540, 8640, 8640, 8640, 34560, 34560, 540, 34560, 34560, 34560, 34560, 8640, 540, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 480600 . Total input tokens: 107207044 . Total output tokens: 94440961
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 7.612379098893143,
    "estimated_duration": 3600.081728217494,
    "input_throughput": 7395.829320014663,
    "output_throughput": 6431.746206901982,
    "total_throughput": 13827.575526916646,
    "itl": 90.21875287379807,
    "ttft": 1162950.66919776,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20428547009825704,
    "arrivals": 160041,
    "finished_requests": 107586,
    "scheduler_time": 59.076770920982305
}
#Debug simulation 
Total elapsed time: 7.612472306005657. Arrivals time: 0.2919723792001605 Scheduler time: 7.160117678111419 Scheduler overhead time: 0.058399195899255574 Adapter cache time: 0.013568539055995643 Engine time: 0.06082265835721046 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.05_size_16-16-32/adapters_32_slots_32_rate_3.2-0.8-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.05_size_16-16-32/adapters_32_slots_32_rate_3.2-0.8-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 540, 540, 8640, 540, 34560, 8640, 540, 540, 540, 34560, 34560, 540, 540, 8640, 8640, 8640, 34560, 34560, 540, 34560, 34560, 34560, 34560, 8640, 540, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 480600 . Total input tokens: 107207044 . Total output tokens: 94440961
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 7.466798073030077,
    "estimated_duration": 3600.0505552971777,
    "input_throughput": 7228.626820728581,
    "output_throughput": 6287.345317052511,
    "total_throughput": 13515.972137781091,
    "itl": 83.94709870822426,
    "ttft": 1196360.5406118361,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23678970612585548,
    "arrivals": 160041,
    "finished_requests": 105146,
    "scheduler_time": 53.81458995357734
}
#Debug simulation 
Total elapsed time: 7.466971031972207. Arrivals time: 0.2966226686257869 Scheduler time: 6.999832202796824 Scheduler overhead time: 0.06205316155683249 Adapter cache time: 0.014484184212051332 Engine time: 0.06462628662120551 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.025_size_8-8-8/adapters_32_slots_32_rate_3.2-0.8-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.025_size_8-8-8/adapters_32_slots_32_rate_3.2-0.8-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 270, 270, 8640, 270, 34560, 8640, 270, 270, 270, 34560, 34560, 270, 270, 8640, 8640, 8640, 34560, 34560, 270, 34560, 34560, 34560, 34560, 8640, 270, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 477900 . Total input tokens: 106609668 . Total output tokens: 93900804
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 7.780596302007325,
    "estimated_duration": 3600.0152846017777,
    "input_throughput": 7527.445262776876,
    "output_throughput": 6588.160917384425,
    "total_throughput": 14115.606180161301,
    "itl": 91.31897374006749,
    "ttft": 1136921.66635259,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2115970890223979,
    "arrivals": 159140,
    "finished_requests": 109396,
    "scheduler_time": 62.00597114898442
}
#Debug simulation 
Total elapsed time: 7.780714888009243. Arrivals time: 0.3082795614609495 Scheduler time: 7.31383851042483 Scheduler overhead time: 0.05812942364718765 Adapter cache time: 0.012737034470774233 Engine time: 0.06024845317006111 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.025_size_8-8-16/adapters_32_slots_32_rate_3.2-0.8-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.025_size_8-8-16/adapters_32_slots_32_rate_3.2-0.8-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 270, 270, 8640, 270, 34560, 8640, 270, 270, 270, 34560, 34560, 270, 270, 8640, 8640, 8640, 34560, 34560, 270, 34560, 34560, 34560, 34560, 8640, 270, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 477900 . Total input tokens: 106609668 . Total output tokens: 93900804
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 7.836745362030342,
    "estimated_duration": 3600.031041111826,
    "input_throughput": 7463.617311394558,
    "output_throughput": 6530.844243148203,
    "total_throughput": 13994.46155454276,
    "itl": 88.70705918907943,
    "ttft": 1149615.677516478,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23482633151113985,
    "arrivals": 159140,
    "finished_requests": 108472,
    "scheduler_time": 59.941478275286414
}
#Debug simulation 
Total elapsed time: 7.836860406096093. Arrivals time: 0.30863113910891116 Scheduler time: 7.364014723803848 Scheduler overhead time: 0.06005119904875755 Adapter cache time: 0.013150652288459241 Engine time: 0.06263941642828286 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.025_size_8-8-32/adapters_32_slots_32_rate_3.2-0.8-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.025_size_8-8-32/adapters_32_slots_32_rate_3.2-0.8-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 270, 270, 8640, 270, 34560, 8640, 270, 270, 270, 34560, 34560, 270, 270, 8640, 8640, 8640, 34560, 34560, 270, 34560, 34560, 34560, 34560, 8640, 270, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 477900 . Total input tokens: 106609668 . Total output tokens: 93900804
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 7.640082160010934,
    "estimated_duration": 3600.0807002219863,
    "input_throughput": 7287.739966046378,
    "output_throughput": 6381.054179864216,
    "total_throughput": 13668.794145910595,
    "itl": 82.61900173812863,
    "ttft": 1184243.8217652375,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.24134628401137892,
    "arrivals": 159140,
    "finished_requests": 105956,
    "scheduler_time": 54.540659250869005
}
#Debug simulation 
Total elapsed time: 7.6401968960417435. Arrivals time: 0.3062095692148432 Scheduler time: 7.16068976779934 Scheduler overhead time: 0.06353034183848649 Adapter cache time: 0.013658896088600159 Engine time: 0.06613872747402638 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.025_size_8-16-16/adapters_32_slots_32_rate_3.2-0.8-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.025_size_8-16-16/adapters_32_slots_32_rate_3.2-0.8-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 270, 270, 8640, 270, 34560, 8640, 270, 270, 270, 34560, 34560, 270, 270, 8640, 8640, 8640, 34560, 34560, 270, 34560, 34560, 34560, 34560, 8640, 270, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 477900 . Total input tokens: 106609668 . Total output tokens: 93900804
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 7.812985925935209,
    "estimated_duration": 3600.067444179193,
    "input_throughput": 7463.497119600795,
    "output_throughput": 6530.704039451807,
    "total_throughput": 13994.201159052602,
    "itl": 88.70661790046202,
    "ttft": 1149601.2549292152,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2195559008046984,
    "arrivals": 159140,
    "finished_requests": 108471,
    "scheduler_time": 59.9427714489206
}
#Debug simulation 
Total elapsed time: 7.813109059934504. Arrivals time: 0.30712310469243675 Scheduler time: 7.34227242495399 Scheduler overhead time: 0.060144562157802284 Adapter cache time: 0.013070777175016701 Engine time: 0.062232880387455225 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.025_size_8-16-32/adapters_32_slots_32_rate_3.2-0.8-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.025_size_8-16-32/adapters_32_slots_32_rate_3.2-0.8-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 270, 270, 8640, 270, 34560, 8640, 270, 270, 270, 34560, 34560, 270, 270, 8640, 8640, 8640, 34560, 34560, 270, 34560, 34560, 34560, 34560, 8640, 270, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 477900 . Total input tokens: 106609668 . Total output tokens: 93900804
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 7.606829585973173,
    "estimated_duration": 3600.014089405763,
    "input_throughput": 7287.8748106040675,
    "output_throughput": 6381.172248076376,
    "total_throughput": 13669.047058680442,
    "itl": 82.61938500001244,
    "ttft": 1184227.2262819577,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2390679950686172,
    "arrivals": 159140,
    "finished_requests": 105956,
    "scheduler_time": 54.5410642156089
}
#Debug simulation 
Total elapsed time: 7.606955113937147. Arrivals time: 0.3038358020130545 Scheduler time: 7.129932243027724 Scheduler overhead time: 0.06355186190921813 Adapter cache time: 0.013657281175255775 Engine time: 0.06609897303860635 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.025_size_16-16-16/adapters_32_slots_32_rate_3.2-0.8-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.025_size_16-16-16/adapters_32_slots_32_rate_3.2-0.8-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 270, 270, 8640, 270, 34560, 8640, 270, 270, 270, 34560, 34560, 270, 270, 8640, 8640, 8640, 34560, 34560, 270, 34560, 34560, 34560, 34560, 8640, 270, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 477900 . Total input tokens: 106609668 . Total output tokens: 93900804
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 7.758622060995549,
    "estimated_duration": 3600.039496734487,
    "input_throughput": 7463.695613443351,
    "output_throughput": 6530.85612569712,
    "total_throughput": 13994.551739140472,
    "itl": 88.7050366934501,
    "ttft": 1149565.1615852078,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20428547009825704,
    "arrivals": 159140,
    "finished_requests": 108473,
    "scheduler_time": 59.94114253525538
}
#Debug simulation 
Total elapsed time: 7.758747849962674. Arrivals time: 0.31849210837390274 Scheduler time: 7.27666091278661 Scheduler overhead time: 0.059663967113010585 Adapter cache time: 0.013045633677393198 Engine time: 0.06269114185124636 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.025_size_16-16-32/adapters_32_slots_32_rate_3.2-0.8-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.025_size_16-16-32/adapters_32_slots_32_rate_3.2-0.8-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 270, 270, 8640, 270, 34560, 8640, 270, 270, 270, 34560, 34560, 270, 270, 8640, 8640, 8640, 34560, 34560, 270, 34560, 34560, 34560, 34560, 8640, 270, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 477900 . Total input tokens: 106609668 . Total output tokens: 93900804
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 7.625625831075013,
    "estimated_duration": 3600.0619947950945,
    "input_throughput": 7287.835331150545,
    "output_throughput": 6381.175111210144,
    "total_throughput": 13669.01044236069,
    "itl": 82.6189619636877,
    "ttft": 1184268.3047427875,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23678970612585548,
    "arrivals": 159140,
    "finished_requests": 105957,
    "scheduler_time": 54.54064268540119
}
#Debug simulation 
Total elapsed time: 7.625798747059889. Arrivals time: 0.2992755555314943 Scheduler time: 7.152401682687923 Scheduler overhead time: 0.06372117658611387 Adapter cache time: 0.013761236565187573 Engine time: 0.06644274725113064 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.0125_size_8-8-8/adapters_32_slots_32_rate_3.2-0.8-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.0125_size_8-8-8/adapters_32_slots_32_rate_3.2-0.8-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 135, 135, 8640, 135, 34560, 8640, 135, 135, 135, 34560, 34560, 135, 135, 8640, 8640, 8640, 34560, 34560, 135, 34560, 34560, 34560, 34560, 8640, 135, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 476550 . Total input tokens: 106305212 . Total output tokens: 93638864
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 7.863494332996197,
    "estimated_duration": 3600.0426234223473,
    "input_throughput": 7679.4090770287585,
    "output_throughput": 6667.396336874994,
    "total_throughput": 14346.805413903752,
    "itl": 90.38119276027125,
    "ttft": 1100249.3592659489,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2115970890223979,
    "arrivals": 158673,
    "finished_requests": 111676,
    "scheduler_time": 63.5690676661979
}
#Debug simulation 
Total elapsed time: 7.863591753994115. Arrivals time: 0.3054339855443686 Scheduler time: 7.3991125136381015 Scheduler overhead time: 0.058533309609629214 Adapter cache time: 0.011640785611234605 Engine time: 0.06133890256751329 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.0125_size_8-8-16/adapters_32_slots_32_rate_3.2-0.8-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.0125_size_8-8-16/adapters_32_slots_32_rate_3.2-0.8-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 135, 135, 8640, 135, 34560, 8640, 135, 135, 135, 34560, 34560, 135, 135, 8640, 8640, 8640, 34560, 34560, 135, 34560, 34560, 34560, 34560, 8640, 135, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 476550 . Total input tokens: 106305212 . Total output tokens: 93638864
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 7.816785037983209,
    "estimated_duration": 3600.0843578770873,
    "input_throughput": 7611.180815817847,
    "output_throughput": 6607.629609553766,
    "total_throughput": 14218.810425371614,
    "itl": 87.84506628054741,
    "ttft": 1113928.1478920653,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23482633151113988,
    "arrivals": 158673,
    "finished_requests": 110672,
    "scheduler_time": 61.45731275452357
}
#Debug simulation 
Total elapsed time: 7.81688245292753. Arrivals time: 0.30432936432771385 Scheduler time: 7.348832500050776 Scheduler overhead time: 0.060264105442911386 Adapter cache time: 0.012226165155880153 Engine time: 0.06284108245745301 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.0125_size_8-8-32/adapters_32_slots_32_rate_3.2-0.8-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.0125_size_8-8-32/adapters_32_slots_32_rate_3.2-0.8-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 135, 135, 8640, 135, 34560, 8640, 135, 135, 135, 34560, 34560, 135, 135, 8640, 8640, 8640, 34560, 34560, 135, 34560, 34560, 34560, 34560, 8640, 135, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 476550 . Total input tokens: 106305212 . Total output tokens: 93638864
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 7.667996859992854,
    "estimated_duration": 3600.0895971901523,
    "input_throughput": 7428.517062706717,
    "output_throughput": 6451.803315708749,
    "total_throughput": 13880.320378415467,
    "itl": 81.82489572619843,
    "ttft": 1149406.9586147396,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.24134628401137892,
    "arrivals": 158673,
    "finished_requests": 108037,
    "scheduler_time": 55.9062489122754
}
#Debug simulation 
Total elapsed time: 7.668120595044456. Arrivals time: 0.3053463918622583 Scheduler time: 7.189200695371255 Scheduler overhead time: 0.06376898044254631 Adapter cache time: 0.012802349403500557 Engine time: 0.06641437090002 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.0125_size_8-16-16/adapters_32_slots_32_rate_3.2-0.8-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.0125_size_8-16-16/adapters_32_slots_32_rate_3.2-0.8-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 135, 135, 8640, 135, 34560, 8640, 135, 135, 135, 34560, 34560, 135, 135, 8640, 8640, 8640, 34560, 34560, 135, 34560, 34560, 34560, 34560, 8640, 135, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 476550 . Total input tokens: 106305212 . Total output tokens: 93638864
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 7.881393890012987,
    "estimated_duration": 3600.026832368933,
    "input_throughput": 7610.686052017783,
    "output_throughput": 6607.54269554907,
    "total_throughput": 14218.228747566853,
    "itl": 87.84813858606735,
    "ttft": 1113846.8634835994,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21955590080469842,
    "arrivals": 158673,
    "finished_requests": 110666,
    "scheduler_time": 61.45873678813355
}
#Debug simulation 
Total elapsed time: 7.881512614083476. Arrivals time: 0.29786336270626634 Scheduler time: 7.419668274465948 Scheduler overhead time: 0.060217214399017394 Adapter cache time: 0.012197422329336405 Engine time: 0.06305515544954687 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.0125_size_8-16-32/adapters_32_slots_32_rate_3.2-0.8-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.0125_size_8-16-32/adapters_32_slots_32_rate_3.2-0.8-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 135, 135, 8640, 135, 34560, 8640, 135, 135, 135, 34560, 34560, 135, 135, 8640, 8640, 8640, 34560, 34560, 135, 34560, 34560, 34560, 34560, 8640, 135, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 476550 . Total input tokens: 106305212 . Total output tokens: 93638864
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 7.701941920910031,
    "estimated_duration": 3600.0844626111757,
    "input_throughput": 7428.434881942479,
    "output_throughput": 6451.627799630475,
    "total_throughput": 13880.062681572954,
    "itl": 81.82536308514979,
    "ttft": 1149390.4874064706,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2390679950686172,
    "arrivals": 158673,
    "finished_requests": 108035,
    "scheduler_time": 55.90660592674783
}
#Debug simulation 
Total elapsed time: 7.7020715969847515. Arrivals time: 0.3026245931396261 Scheduler time: 7.225518666789867 Scheduler overhead time: 0.06411240750458091 Adapter cache time: 0.012836335459724069 Engine time: 0.06674015137832612 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.0125_size_16-16-16/adapters_32_slots_32_rate_3.2-0.8-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.0125_size_16-16-16/adapters_32_slots_32_rate_3.2-0.8-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 135, 135, 8640, 135, 34560, 8640, 135, 135, 135, 34560, 34560, 135, 135, 8640, 8640, 8640, 34560, 34560, 135, 34560, 34560, 34560, 34560, 8640, 135, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 476550 . Total input tokens: 106305212 . Total output tokens: 93638864
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 7.879342432948761,
    "estimated_duration": 3600.0169508889244,
    "input_throughput": 7610.76027523554,
    "output_throughput": 6607.494999190611,
    "total_throughput": 14218.255274426152,
    "itl": 87.84623450606588,
    "ttft": 1113840.591225903,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20428547009825704,
    "arrivals": 158673,
    "finished_requests": 110666,
    "scheduler_time": 61.4570844719673
}
#Debug simulation 
Total elapsed time: 7.879450076958165. Arrivals time: 0.30724771204404533 Scheduler time: 7.408308012178168 Scheduler overhead time: 0.06018391530960798 Adapter cache time: 0.012253594002686441 Engine time: 0.06289381033275276 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.0125_size_16-16-32/adapters_32_slots_32_rate_3.2-0.8-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.0125_size_16-16-32/adapters_32_slots_32_rate_3.2-0.8-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 135, 135, 8640, 135, 34560, 8640, 135, 135, 135, 34560, 34560, 135, 135, 8640, 8640, 8640, 34560, 34560, 135, 34560, 34560, 34560, 34560, 8640, 135, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 476550 . Total input tokens: 106305212 . Total output tokens: 93638864
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 7.709808746003546,
    "estimated_duration": 3600.0038970028168,
    "input_throughput": 7428.601125200136,
    "output_throughput": 6451.7721826182305,
    "total_throughput": 13880.373307818367,
    "itl": 81.82525229110311,
    "ttft": 1149346.3925651596,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23678970612585548,
    "arrivals": 158673,
    "finished_requests": 108035,
    "scheduler_time": 55.905774748550705
}
#Debug simulation 
Total elapsed time: 7.709936884930357. Arrivals time: 0.2939085230464116 Scheduler time: 7.2425107533345 Scheduler overhead time: 0.06388544349465519 Adapter cache time: 0.012812053202651441 Engine time: 0.06652534112799913 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-8/adapters_32_slots_32_rate_3.2-0.8-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-8/adapters_32_slots_32_rate_3.2-0.8-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 66, 66, 8640, 66, 34560, 8640, 66, 66, 66, 34560, 34560, 66, 66, 8640, 8640, 8640, 34560, 34560, 66, 34560, 34560, 34560, 34560, 8640, 66, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 475860 . Total input tokens: 106146780 . Total output tokens: 93512102
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 7.948883254081011,
    "estimated_duration": 3600.0028175121497,
    "input_throughput": 7680.673433224802,
    "output_throughput": 6710.576136908389,
    "total_throughput": 14391.24957013319,
    "itl": 90.10650583386915,
    "ttft": 1094718.7348664936,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2115970890223979,
    "arrivals": 158470,
    "finished_requests": 112079,
    "scheduler_time": 64.17849513882186
}
#Debug simulation 
Total elapsed time: 7.949005156988278. Arrivals time: 0.30096497014164925 Scheduler time: 7.487713935086504 Scheduler overhead time: 0.05908433289732784 Adapter cache time: 0.011127820936962962 Engine time: 0.06209444208070636 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-16/adapters_32_slots_32_rate_3.2-0.8-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-16/adapters_32_slots_32_rate_3.2-0.8-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 66, 66, 8640, 66, 34560, 8640, 66, 66, 66, 34560, 34560, 66, 66, 8640, 8640, 8640, 34560, 34560, 66, 34560, 34560, 34560, 34560, 8640, 66, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 475860 . Total input tokens: 106146780 . Total output tokens: 93512102
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 7.8541815229691565,
    "estimated_duration": 3600.0053940290372,
    "input_throughput": 7608.409711115859,
    "output_throughput": 6649.426148000633,
    "total_throughput": 14257.83585911649,
    "itl": 87.5840652979824,
    "ttft": 1107966.3881401657,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23482633151113982,
    "arrivals": 158470,
    "finished_requests": 111030,
    "scheduler_time": 62.02211705964839
}
#Debug simulation 
Total elapsed time: 7.85429812502116. Arrivals time: 0.3002860712585971 Scheduler time: 7.390865969355218 Scheduler overhead time: 0.060436159605160356 Adapter cache time: 0.011288148816674948 Engine time: 0.06299034599214792 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-32/adapters_32_slots_32_rate_3.2-0.8-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-32/adapters_32_slots_32_rate_3.2-0.8-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 66, 66, 8640, 66, 34560, 8640, 66, 66, 66, 34560, 34560, 66, 66, 8640, 8640, 8640, 34560, 34560, 66, 34560, 34560, 34560, 34560, 8640, 66, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 475860 . Total input tokens: 106146780 . Total output tokens: 93512102
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 7.720887952949852,
    "estimated_duration": 3600.0274101858586,
    "input_throughput": 7429.95398432788,
    "output_throughput": 6490.220583846537,
    "total_throughput": 13920.174568174418,
    "itl": 81.6310222141037,
    "ttft": 1144635.2581853257,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.24134628401137892,
    "arrivals": 158470,
    "finished_requests": 108443,
    "scheduler_time": 56.44291025616958
}
#Debug simulation 
Total elapsed time: 7.720991191919893. Arrivals time: 0.30245157494209707 Scheduler time: 7.245352714788169 Scheduler overhead time: 0.06407278217375278 Adapter cache time: 0.011943559045903385 Engine time: 0.0669844908406958 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.00625_size_8-16-16/adapters_32_slots_32_rate_3.2-0.8-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.00625_size_8-16-16/adapters_32_slots_32_rate_3.2-0.8-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 66, 66, 8640, 66, 34560, 8640, 66, 66, 66, 34560, 34560, 66, 66, 8640, 8640, 8640, 34560, 34560, 66, 34560, 34560, 34560, 34560, 8640, 66, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 475860 . Total input tokens: 106146780 . Total output tokens: 93512102
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 7.851625307928771,
    "estimated_duration": 3600.0269391914235,
    "input_throughput": 7608.440009660596,
    "output_throughput": 6649.5094076647765,
    "total_throughput": 14257.949417325372,
    "itl": 87.58320508136617,
    "ttft": 1107932.3869329072,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21955590080469836,
    "arrivals": 158470,
    "finished_requests": 111031,
    "scheduler_time": 62.02182347729953
}
#Debug simulation 
Total elapsed time: 7.851771766901948. Arrivals time: 0.29986519273370504 Scheduler time: 7.388741867500357 Scheduler overhead time: 0.06029022508300841 Adapter cache time: 0.011382355471141636 Engine time: 0.06301989266648889 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.00625_size_8-16-32/adapters_32_slots_32_rate_3.2-0.8-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.00625_size_8-16-32/adapters_32_slots_32_rate_3.2-0.8-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 66, 66, 8640, 66, 34560, 8640, 66, 66, 66, 34560, 34560, 66, 66, 8640, 8640, 8640, 34560, 34560, 66, 34560, 34560, 34560, 34560, 8640, 66, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 475860 . Total input tokens: 106146780 . Total output tokens: 93512102
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 7.703291838988662,
    "estimated_duration": 3600.0274980284576,
    "input_throughput": 7429.81269299976,
    "output_throughput": 6490.119315142883,
    "total_throughput": 13919.932008142643,
    "itl": 81.62951928746028,
    "ttft": 1144539.0574714458,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2390679950686172,
    "arrivals": 158470,
    "finished_requests": 108442,
    "scheduler_time": 56.440718265303055
}
#Debug simulation 
Total elapsed time: 7.703409938956611. Arrivals time: 0.296833572210744 Scheduler time: 7.233690539840609 Scheduler overhead time: 0.06385056185536087 Adapter cache time: 0.01194482808932662 Engine time: 0.06684056203812361 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.00625_size_16-16-16/adapters_32_slots_32_rate_3.2-0.8-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.00625_size_16-16-16/adapters_32_slots_32_rate_3.2-0.8-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 66, 66, 8640, 66, 34560, 8640, 66, 66, 66, 34560, 34560, 66, 66, 8640, 8640, 8640, 34560, 34560, 66, 34560, 34560, 34560, 34560, 8640, 66, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 475860 . Total input tokens: 106146780 . Total output tokens: 93512102
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 7.908868734026328,
    "estimated_duration": 3600.010385571276,
    "input_throughput": 7608.18582906772,
    "output_throughput": 6649.416372781199,
    "total_throughput": 14257.602201848918,
    "itl": 87.58407096706186,
    "ttft": 1107851.4628076567,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20428547009825704,
    "arrivals": 158470,
    "finished_requests": 111029,
    "scheduler_time": 62.02240483543962
}
#Debug simulation 
Total elapsed time: 7.908984403940849. Arrivals time: 0.3002225945238024 Scheduler time: 7.444409801973961 Scheduler overhead time: 0.06089338904712349 Adapter cache time: 0.011412640917114913 Engine time: 0.06330150191206485 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.00625_size_16-16-32/adapters_32_slots_32_rate_3.2-0.8-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.00625_size_16-16-32/adapters_32_slots_32_rate_3.2-0.8-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 66, 66, 8640, 66, 34560, 8640, 66, 66, 66, 34560, 34560, 66, 66, 8640, 8640, 8640, 34560, 34560, 66, 34560, 34560, 34560, 34560, 8640, 66, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 475860 . Total input tokens: 106146780 . Total output tokens: 93512102
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 7.717956039006822,
    "estimated_duration": 3600.026579842116,
    "input_throughput": 7429.819032384214,
    "output_throughput": 6490.219858605795,
    "total_throughput": 13920.038890990008,
    "itl": 81.63191045831356,
    "ttft": 1144606.7249961293,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23678970612585548,
    "arrivals": 158470,
    "finished_requests": 108441,
    "scheduler_time": 56.44279615866495
}
#Debug simulation 
Total elapsed time: 7.718099664081819. Arrivals time: 0.29689909738954157 Scheduler time: 7.247560182819143 Scheduler overhead time: 0.06438643066212535 Adapter cache time: 0.011994688655249774 Engine time: 0.06689430575352162 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.003125_size_8-8-8/adapters_32_slots_32_rate_3.2-0.8-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.003125_size_8-8-8/adapters_32_slots_32_rate_3.2-0.8-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 33, 33, 8640, 33, 34560, 8640, 33, 33, 33, 34560, 34560, 33, 33, 8640, 8640, 8640, 34560, 34560, 33, 34560, 34560, 34560, 34560, 8640, 33, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 475530 . Total input tokens: 106074198 . Total output tokens: 93448812
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 7.957052947953343,
    "estimated_duration": 3600.015673367086,
    "input_throughput": 7703.384795006195,
    "output_throughput": 6723.703504701887,
    "total_throughput": 14427.088299708083,
    "itl": 89.72443776773557,
    "ttft": 1085769.3455780437,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2115970890223979,
    "arrivals": 158357,
    "finished_requests": 112501,
    "scheduler_time": 64.5125154686622
}
#Debug simulation 
Total elapsed time: 7.957158498931676. Arrivals time: 0.3080916224280372 Scheduler time: 7.4891668955096975 Scheduler overhead time: 0.05935276113450527 Adapter cache time: 0.010775033384561539 Engine time: 0.06188235024455935 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.003125_size_8-8-16/adapters_32_slots_32_rate_3.2-0.8-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.003125_size_8-8-16/adapters_32_slots_32_rate_3.2-0.8-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 33, 33, 8640, 33, 34560, 8640, 33, 33, 33, 34560, 34560, 33, 33, 8640, 8640, 8640, 34560, 34560, 33, 34560, 34560, 34560, 34560, 8640, 33, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 475530 . Total input tokens: 106074198 . Total output tokens: 93448812
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 7.96541374293156,
    "estimated_duration": 3600.003101272295,
    "input_throughput": 7633.017313315244,
    "output_throughput": 6664.065370255193,
    "total_throughput": 14297.082683570436,
    "itl": 87.22009605043128,
    "ttft": 1099650.3688577586,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23482633151113985,
    "arrivals": 158357,
    "finished_requests": 111497,
    "scheduler_time": 62.35514875707719
}
#Debug simulation 
Total elapsed time: 7.965520452009514. Arrivals time: 0.3034313782118261 Scheduler time: 7.497995652724057 Scheduler overhead time: 0.060939027345739305 Adapter cache time: 0.010969601455144584 Engine time: 0.0634853127412498 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.003125_size_8-8-32/adapters_32_slots_32_rate_3.2-0.8-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.003125_size_8-8-32/adapters_32_slots_32_rate_3.2-0.8-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 33, 33, 8640, 33, 34560, 8640, 33, 33, 33, 34560, 34560, 33, 33, 8640, 8640, 8640, 34560, 34560, 33, 34560, 34560, 34560, 34560, 8640, 33, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 475530 . Total input tokens: 106074198 . Total output tokens: 93448812
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 7.699528583092615,
    "estimated_duration": 3600.061009184783,
    "input_throughput": 7446.596858110078,
    "output_throughput": 6503.901445076369,
    "total_throughput": 13950.498303186447,
    "itl": 81.30944914845335,
    "ttft": 1136448.790636011,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.24134628401137892,
    "arrivals": 158357,
    "finished_requests": 108742,
    "scheduler_time": 56.71348829901272
}
#Debug simulation 
Total elapsed time: 7.6996377820614725. Arrivals time: 0.3032212764956057 Scheduler time: 7.223574599716812 Scheduler overhead time: 0.0642362714279443 Adapter cache time: 0.011541440733708441 Engine time: 0.06681052932981402 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.003125_size_8-16-16/adapters_32_slots_32_rate_3.2-0.8-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.003125_size_8-16-16/adapters_32_slots_32_rate_3.2-0.8-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 33, 33, 8640, 33, 34560, 8640, 33, 33, 33, 34560, 34560, 33, 33, 8640, 8640, 8640, 34560, 34560, 33, 34560, 34560, 34560, 34560, 8640, 33, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 475530 . Total input tokens: 106074198 . Total output tokens: 93448812
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 7.901865784078836,
    "estimated_duration": 3600.0349020118083,
    "input_throughput": 7632.7940555921505,
    "output_throughput": 6663.857060550607,
    "total_throughput": 14296.651116142757,
    "itl": 87.22002576518513,
    "ttft": 1099617.3662974257,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21955590080469836,
    "arrivals": 158357,
    "finished_requests": 111495,
    "scheduler_time": 62.35534138260954
}
#Debug simulation 
Total elapsed time: 7.901969399070367. Arrivals time: 0.30246155243366957 Scheduler time: 7.436049514799379 Scheduler overhead time: 0.06073261552955955 Adapter cache time: 0.01100424281321466 Engine time: 0.06305028614588082 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.003125_size_8-16-32/adapters_32_slots_32_rate_3.2-0.8-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.003125_size_8-16-32/adapters_32_slots_32_rate_3.2-0.8-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 33, 33, 8640, 33, 34560, 8640, 33, 33, 33, 34560, 34560, 33, 33, 8640, 8640, 8640, 34560, 34560, 33, 34560, 34560, 34560, 34560, 8640, 33, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 475530 . Total input tokens: 106074198 . Total output tokens: 93448812
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 7.7319500090088695,
    "estimated_duration": 3600.086828446763,
    "input_throughput": 7446.409288846525,
    "output_throughput": 6503.823967518578,
    "total_throughput": 13950.233256365103,
    "itl": 81.31016685429162,
    "ttft": 1136490.4237135418,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2390679950686172,
    "arrivals": 158357,
    "finished_requests": 108741,
    "scheduler_time": 56.71376833287874
}
#Debug simulation 
Total elapsed time: 7.732041476061568. Arrivals time: 0.3022477487102151 Scheduler time: 7.256125280400738 Scheduler overhead time: 0.06441450153943151 Adapter cache time: 0.01171083515509963 Engine time: 0.06707323843147606 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.003125_size_16-16-16/adapters_32_slots_32_rate_3.2-0.8-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.003125_size_16-16-16/adapters_32_slots_32_rate_3.2-0.8-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 33, 33, 8640, 33, 34560, 8640, 33, 33, 33, 34560, 34560, 33, 33, 8640, 8640, 8640, 34560, 34560, 33, 34560, 34560, 34560, 34560, 8640, 33, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 475530 . Total input tokens: 106074198 . Total output tokens: 93448812
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 7.905264507047832,
    "estimated_duration": 3600.005595237164,
    "input_throughput": 7632.856192322046,
    "output_throughput": 6663.911309398829,
    "total_throughput": 14296.767501720875,
    "itl": 87.22252740262286,
    "ttft": 1099647.1246028934,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20428547009825704,
    "arrivals": 158357,
    "finished_requests": 111495,
    "scheduler_time": 62.35698156460449
}
#Debug simulation 
Total elapsed time: 7.90535934001673. Arrivals time: 0.30750240886118263 Scheduler time: 7.433270848006941 Scheduler overhead time: 0.06198207347188145 Adapter cache time: 0.010942427441477776 Engine time: 0.06307641661260277 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.003125_size_16-16-32/adapters_32_slots_32_rate_3.2-0.8-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.003125_size_16-16-32/adapters_32_slots_32_rate_3.2-0.8-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [10 11 11]
Adapter prompts. [34560, 8640, 33, 33, 8640, 33, 34560, 8640, 33, 33, 33, 34560, 34560, 33, 33, 8640, 8640, 8640, 34560, 34560, 33, 34560, 34560, 34560, 34560, 8640, 33, 8640, 8640, 8640, 8640, 34560]
Prompts retrieved: 475530 . Total input tokens: 106074198 . Total output tokens: 93448812
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 7.756572386017069,
    "estimated_duration": 3600.0438210112175,
    "input_throughput": 7446.498246365782,
    "output_throughput": 6503.901664570056,
    "total_throughput": 13950.399910935837,
    "itl": 81.30939972559773,
    "ttft": 1136501.1559526005,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23678970612585548,
    "arrivals": 158357,
    "finished_requests": 108741,
    "scheduler_time": 56.71306857550293
}
#Debug simulation 
Total elapsed time: 7.756719627068378. Arrivals time: 0.3023934526136145 Scheduler time: 7.281209437409416 Scheduler overhead time: 0.06408720766194165 Adapter cache time: 0.011716057313606143 Engine time: 0.06688754248898476 
