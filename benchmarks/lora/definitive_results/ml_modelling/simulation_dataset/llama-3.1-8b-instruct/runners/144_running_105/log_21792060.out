INFO 05-31 19:30:52 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 05-31 19:30:52 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-16-16/adapters_160_slots_96_rate_1.6-0.1-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-16-16/adapters_160_slots_96_rate_1.6-0.1-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [53 53 54]
Adapter prompts. [135, 17280, 135, 135, 1080, 135, 135, 135, 17280, 135, 1080, 17280, 1080, 135, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 135, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 135, 1080, 1080, 1080, 17280, 135, 135, 17280, 135, 17280, 135, 135, 1080, 135, 1080, 17280, 135, 135, 1080, 135, 135, 135, 135, 135, 17280, 1080, 1080, 17280, 1080, 135, 17280, 17280, 17280, 1080, 1080, 135, 135, 135, 17280, 135, 1080, 1080, 135, 17280, 17280, 17280, 135, 135, 17280, 1080, 17280, 17280, 135, 17280, 135, 1080, 135, 135, 1080, 1080, 17280, 17280, 17280, 135, 17280, 1080, 1080, 135, 135, 135, 135, 17280, 1080, 17280, 1080, 17280, 17280, 17280, 135, 1080, 1080, 17280, 1080, 17280, 135, 135, 135, 1080, 1080, 1080, 17280, 17280, 1080, 17280, 135, 1080, 1080, 135, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 17280, 135, 17280, 135, 17280, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 17280, 1080, 135, 135]
Prompts retrieved: 997515 . Total input tokens: 222433513 . Total output tokens: 196181963
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 5.102083425968885,
    "estimated_duration": 3600.1170660370326,
    "input_throughput": 4846.416291458597,
    "output_throughput": 4241.357355861864,
    "total_throughput": 9087.77364732046,
    "itl": 114.10832452147345,
    "ttft": 1991975.3120721837,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1880,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.929102978445766,
    "arrivals": 332795,
    "finished_requests": 70467,
    "scheduler_time": 102.54252455153171
}
#Debug simulation 
Total elapsed time: 5.102190221194178. Arrivals time: 0.2325363797135651 Scheduler time: 4.709756587166339 Scheduler overhead time: 0.045161446556448936 Adapter cache time: 0.046263815369457006 Engine time: 0.04693958815187216 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-16-32/adapters_160_slots_96_rate_1.6-0.1-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-16-32/adapters_160_slots_96_rate_1.6-0.1-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [53 53 54]
Adapter prompts. [135, 17280, 135, 135, 1080, 135, 135, 135, 17280, 135, 1080, 17280, 1080, 135, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 135, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 135, 1080, 1080, 1080, 17280, 135, 135, 17280, 135, 17280, 135, 135, 1080, 135, 1080, 17280, 135, 135, 1080, 135, 135, 135, 135, 135, 17280, 1080, 1080, 17280, 1080, 135, 17280, 17280, 17280, 1080, 1080, 135, 135, 135, 17280, 135, 1080, 1080, 135, 17280, 17280, 17280, 135, 135, 17280, 1080, 17280, 17280, 135, 17280, 135, 1080, 135, 135, 1080, 1080, 17280, 17280, 17280, 135, 17280, 1080, 1080, 135, 135, 135, 135, 17280, 1080, 17280, 1080, 17280, 17280, 17280, 135, 1080, 1080, 17280, 1080, 17280, 135, 135, 135, 1080, 1080, 1080, 17280, 17280, 1080, 17280, 135, 1080, 1080, 135, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 17280, 135, 17280, 135, 17280, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 17280, 1080, 135, 135]
Prompts retrieved: 997515 . Total input tokens: 222433513 . Total output tokens: 196181963
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 4.816165633965284,
    "estimated_duration": 3600.0202843476413,
    "input_throughput": 4450.151314328801,
    "output_throughput": 3909.531860471285,
    "total_throughput": 8359.683174800086,
    "itl": 88.54311162902118,
    "ttft": 2051591.3173396785,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1756,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.074646764583685,
    "arrivals": 332795,
    "finished_requests": 64733,
    "scheduler_time": 109.415319744661
}
#Debug simulation 
Total elapsed time: 4.81627597194165. Arrivals time: 0.21850805636495352 Scheduler time: 4.403732735197991 Scheduler overhead time: 0.055826368276029825 Adapter cache time: 0.05389652634039521 Engine time: 0.057649682741612196 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_16-16-16/adapters_160_slots_96_rate_1.6-0.1-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_16-16-16/adapters_160_slots_96_rate_1.6-0.1-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [53 53 54]
Adapter prompts. [135, 17280, 135, 135, 1080, 135, 135, 135, 17280, 135, 1080, 17280, 1080, 135, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 135, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 135, 1080, 1080, 1080, 17280, 135, 135, 17280, 135, 17280, 135, 135, 1080, 135, 1080, 17280, 135, 135, 1080, 135, 135, 135, 135, 135, 17280, 1080, 1080, 17280, 1080, 135, 17280, 17280, 17280, 1080, 1080, 135, 135, 135, 17280, 135, 1080, 1080, 135, 17280, 17280, 17280, 135, 135, 17280, 1080, 17280, 17280, 135, 17280, 135, 1080, 135, 135, 1080, 1080, 17280, 17280, 17280, 135, 17280, 1080, 1080, 135, 135, 135, 135, 17280, 1080, 17280, 1080, 17280, 17280, 17280, 135, 1080, 1080, 17280, 1080, 17280, 135, 135, 135, 1080, 1080, 1080, 17280, 17280, 1080, 17280, 135, 1080, 1080, 135, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 17280, 135, 17280, 135, 17280, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 17280, 1080, 135, 135]
Prompts retrieved: 997515 . Total input tokens: 222433513 . Total output tokens: 196181963
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.13071917090565,
    "estimated_duration": 3600.0823755678935,
    "input_throughput": 4848.512666948784,
    "output_throughput": 4242.813471064126,
    "total_throughput": 9091.32613801291,
    "itl": 114.07937968361692,
    "ttft": 1991956.3235548874,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1885,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.033690972975952,
    "arrivals": 332795,
    "finished_requests": 70491,
    "scheduler_time": 102.56712737304703
}
#Debug simulation 
Total elapsed time: 5.130811447277665. Arrivals time: 0.2350329179316759 Scheduler time: 4.735545844305307 Scheduler overhead time: 0.04515876900404692 Adapter cache time: 0.04657201189547777 Engine time: 0.04686838760972023 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_16-16-32/adapters_160_slots_96_rate_1.6-0.1-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_16-16-32/adapters_160_slots_96_rate_1.6-0.1-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [53 53 54]
Adapter prompts. [135, 17280, 135, 135, 1080, 135, 135, 135, 17280, 135, 1080, 17280, 1080, 135, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 135, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 135, 1080, 1080, 1080, 17280, 135, 135, 17280, 135, 17280, 135, 135, 1080, 135, 1080, 17280, 135, 135, 1080, 135, 135, 135, 135, 135, 17280, 1080, 1080, 17280, 1080, 135, 17280, 17280, 17280, 1080, 1080, 135, 135, 135, 17280, 135, 1080, 1080, 135, 17280, 17280, 17280, 135, 135, 17280, 1080, 17280, 17280, 135, 17280, 135, 1080, 135, 135, 1080, 1080, 17280, 17280, 17280, 135, 17280, 1080, 1080, 135, 135, 135, 135, 17280, 1080, 17280, 1080, 17280, 17280, 17280, 135, 1080, 1080, 17280, 1080, 17280, 135, 135, 135, 1080, 1080, 1080, 17280, 17280, 1080, 17280, 135, 1080, 1080, 135, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 17280, 135, 17280, 135, 17280, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 17280, 1080, 135, 135]
Prompts retrieved: 997515 . Total input tokens: 222433513 . Total output tokens: 196181963
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 4.820019750390202,
    "estimated_duration": 3600.0298917784357,
    "input_throughput": 4450.192215511193,
    "output_throughput": 3909.6336483603386,
    "total_throughput": 8359.825863871532,
    "itl": 88.54118058901676,
    "ttft": 2051494.130479041,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1751,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.910565933044804,
    "arrivals": 332795,
    "finished_requests": 64736,
    "scheduler_time": 109.41939860231473
}
#Debug simulation 
Total elapsed time: 4.82011069310829. Arrivals time: 0.22809010138735175 Scheduler time: 4.401104049291462 Scheduler overhead time: 0.05533378338441253 Adapter cache time: 0.05145206535235047 Engine time: 0.05760689917951822 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-8/adapters_160_slots_96_rate_1.6-0.1-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-8/adapters_160_slots_96_rate_1.6-0.1-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 1080, 66, 66, 66, 17280, 66, 1080, 17280, 1080, 66, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 66, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 66, 1080, 1080, 1080, 17280, 66, 66, 17280, 66, 17280, 66, 66, 1080, 66, 1080, 17280, 66, 66, 1080, 66, 66, 66, 66, 66, 17280, 1080, 1080, 17280, 1080, 66, 17280, 17280, 17280, 1080, 1080, 66, 66, 66, 17280, 66, 1080, 1080, 66, 17280, 17280, 17280, 66, 66, 17280, 1080, 17280, 17280, 66, 17280, 66, 1080, 66, 66, 1080, 1080, 17280, 17280, 17280, 66, 17280, 1080, 1080, 66, 66, 66, 66, 17280, 1080, 17280, 1080, 17280, 17280, 17280, 66, 1080, 1080, 17280, 1080, 17280, 66, 66, 66, 1080, 1080, 1080, 17280, 17280, 1080, 17280, 66, 1080, 1080, 66, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 17280, 66, 17280, 66, 17280, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 17280, 1080, 66, 66]
Prompts retrieved: 993858 . Total input tokens: 221622877 . Total output tokens: 195469147
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.30397541821003,
    "estimated_duration": 3600.026219162303,
    "input_throughput": 5050.561271809526,
    "output_throughput": 4397.689082298943,
    "total_throughput": 9448.25035410847,
    "itl": 125.05141197922204,
    "ttft": 1952086.3363975321,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1513,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.00457486534051,
    "arrivals": 331579,
    "finished_requests": 73405,
    "scheduler_time": 101.15535943347558
}
#Debug simulation 
Total elapsed time: 5.30406850297004. Arrivals time: 0.2722818274050951 Scheduler time: 4.886569080874324 Scheduler overhead time: 0.041677897330373526 Adapter cache time: 0.04017685307189822 Engine time: 0.04337768303230405 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-16/adapters_160_slots_96_rate_1.6-0.1-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-16/adapters_160_slots_96_rate_1.6-0.1-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 1080, 66, 66, 66, 17280, 66, 1080, 17280, 1080, 66, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 66, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 66, 1080, 1080, 1080, 17280, 66, 66, 17280, 66, 17280, 66, 66, 1080, 66, 1080, 17280, 66, 66, 1080, 66, 66, 66, 66, 66, 17280, 1080, 1080, 17280, 1080, 66, 17280, 17280, 17280, 1080, 1080, 66, 66, 66, 17280, 66, 1080, 1080, 66, 17280, 17280, 17280, 66, 66, 17280, 1080, 17280, 17280, 66, 17280, 66, 1080, 66, 66, 1080, 1080, 17280, 17280, 17280, 66, 17280, 1080, 1080, 66, 66, 66, 66, 17280, 1080, 17280, 1080, 17280, 17280, 17280, 66, 1080, 1080, 17280, 1080, 17280, 66, 66, 66, 1080, 1080, 1080, 17280, 17280, 1080, 17280, 66, 1080, 1080, 66, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 17280, 66, 17280, 66, 17280, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 17280, 1080, 66, 66]
Prompts retrieved: 993858 . Total input tokens: 221622877 . Total output tokens: 195469147
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.233232473023236,
    "estimated_duration": 3600.1060636289076,
    "input_throughput": 4931.049165286447,
    "output_throughput": 4289.304739103855,
    "total_throughput": 9220.353904390302,
    "itl": 112.64792241252954,
    "ttft": 1971512.0057000306,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1479,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.807828508843574,
    "arrivals": 331579,
    "finished_requests": 71636,
    "scheduler_time": 103.60575299891225
}
#Debug simulation 
Total elapsed time: 5.233321458101273. Arrivals time: 0.2675644946284592 Scheduler time: 4.808105099480599 Scheduler overhead time: 0.045573767740279436 Adapter cache time: 0.04271168215200305 Engine time: 0.04756590072065592 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-32/adapters_160_slots_96_rate_1.6-0.1-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-32/adapters_160_slots_96_rate_1.6-0.1-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 1080, 66, 66, 66, 17280, 66, 1080, 17280, 1080, 66, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 66, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 66, 1080, 1080, 1080, 17280, 66, 66, 17280, 66, 17280, 66, 66, 1080, 66, 1080, 17280, 66, 66, 1080, 66, 66, 66, 66, 66, 17280, 1080, 1080, 17280, 1080, 66, 17280, 17280, 17280, 1080, 1080, 66, 66, 66, 17280, 66, 1080, 1080, 66, 17280, 17280, 17280, 66, 66, 17280, 1080, 17280, 17280, 66, 17280, 66, 1080, 66, 66, 1080, 1080, 17280, 17280, 17280, 66, 17280, 1080, 1080, 66, 66, 66, 66, 17280, 1080, 17280, 1080, 17280, 17280, 17280, 66, 1080, 1080, 17280, 1080, 17280, 66, 66, 66, 1080, 1080, 1080, 17280, 17280, 1080, 17280, 66, 1080, 1080, 66, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 17280, 66, 17280, 66, 17280, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 17280, 1080, 66, 66]
Prompts retrieved: 993858 . Total input tokens: 221622877 . Total output tokens: 195469147
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 4.877613962162286,
    "estimated_duration": 3600.041312201586,
    "input_throughput": 4538.745415120684,
    "output_throughput": 3943.95835177709,
    "total_throughput": 8482.703766897774,
    "itl": 87.5512161260758,
    "ttft": 2033306.779917268,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1361,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.210611339230022,
    "arrivals": 331579,
    "finished_requests": 65835,
    "scheduler_time": 110.28041054680287
}
#Debug simulation 
Total elapsed time: 4.877706000115722. Arrivals time: 0.22725867200642824 Scheduler time: 4.460848941467702 Scheduler overhead time: 0.05617297859862447 Adapter cache time: 0.04824013030156493 Engine time: 0.05823212442919612 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-16-16/adapters_160_slots_96_rate_1.6-0.1-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-16-16/adapters_160_slots_96_rate_1.6-0.1-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 1080, 66, 66, 66, 17280, 66, 1080, 17280, 1080, 66, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 66, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 66, 1080, 1080, 1080, 17280, 66, 66, 17280, 66, 17280, 66, 66, 1080, 66, 1080, 17280, 66, 66, 1080, 66, 66, 66, 66, 66, 17280, 1080, 1080, 17280, 1080, 66, 17280, 17280, 17280, 1080, 1080, 66, 66, 66, 17280, 66, 1080, 1080, 66, 17280, 17280, 17280, 66, 66, 17280, 1080, 17280, 17280, 66, 17280, 66, 1080, 66, 66, 1080, 1080, 17280, 17280, 17280, 66, 17280, 1080, 1080, 66, 66, 66, 66, 17280, 1080, 17280, 1080, 17280, 17280, 17280, 66, 1080, 1080, 17280, 1080, 17280, 66, 66, 66, 1080, 1080, 1080, 17280, 17280, 1080, 17280, 66, 1080, 1080, 66, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 17280, 66, 17280, 66, 17280, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 17280, 1080, 66, 66]
Prompts retrieved: 993858 . Total input tokens: 221622877 . Total output tokens: 195469147
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 5.230954811908305,
    "estimated_duration": 3600.0555082284195,
    "input_throughput": 4931.96034322742,
    "output_throughput": 4290.39301330128,
    "total_throughput": 9222.3533565287,
    "itl": 112.6228836305214,
    "ttft": 1971563.710001294,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1475,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.118723199837907,
    "arrivals": 331579,
    "finished_requests": 71652,
    "scheduler_time": 103.62454923302914
}
#Debug simulation 
Total elapsed time: 5.231052027083933. Arrivals time: 0.2389303664676845 Scheduler time: 4.834673018194735 Scheduler overhead time: 0.045847025234252214 Adapter cache time: 0.04211186431348324 Engine time: 0.047535732854157686 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-16-32/adapters_160_slots_96_rate_1.6-0.1-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-16-32/adapters_160_slots_96_rate_1.6-0.1-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 1080, 66, 66, 66, 17280, 66, 1080, 17280, 1080, 66, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 66, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 66, 1080, 1080, 1080, 17280, 66, 66, 17280, 66, 17280, 66, 66, 1080, 66, 1080, 17280, 66, 66, 1080, 66, 66, 66, 66, 66, 17280, 1080, 1080, 17280, 1080, 66, 17280, 17280, 17280, 1080, 1080, 66, 66, 66, 17280, 66, 1080, 1080, 66, 17280, 17280, 17280, 66, 66, 17280, 1080, 17280, 17280, 66, 17280, 66, 1080, 66, 66, 1080, 1080, 17280, 17280, 17280, 66, 17280, 1080, 1080, 66, 66, 66, 66, 17280, 1080, 17280, 1080, 17280, 17280, 17280, 66, 1080, 1080, 17280, 1080, 17280, 66, 66, 66, 1080, 1080, 1080, 17280, 17280, 1080, 17280, 66, 1080, 1080, 66, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 17280, 66, 17280, 66, 17280, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 17280, 1080, 66, 66]
Prompts retrieved: 993858 . Total input tokens: 221622877 . Total output tokens: 195469147
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 4.896020513959229,
    "estimated_duration": 3600.042851597623,
    "input_throughput": 4538.819028987024,
    "output_throughput": 3943.991664904485,
    "total_throughput": 8482.810693891508,
    "itl": 87.551499867187,
    "ttft": 2033259.8498889245,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1361,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.119013678184643,
    "arrivals": 331579,
    "finished_requests": 65836,
    "scheduler_time": 110.28264486643106
}
#Debug simulation 
Total elapsed time: 4.896110984962434. Arrivals time: 0.22658145753666759 Scheduler time: 4.479221283923835 Scheduler overhead time: 0.05629261489957571 Adapter cache time: 0.04844952654093504 Engine time: 0.058750624768435955 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_16-16-16/adapters_160_slots_96_rate_1.6-0.1-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_16-16-16/adapters_160_slots_96_rate_1.6-0.1-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 1080, 66, 66, 66, 17280, 66, 1080, 17280, 1080, 66, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 66, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 66, 1080, 1080, 1080, 17280, 66, 66, 17280, 66, 17280, 66, 66, 1080, 66, 1080, 17280, 66, 66, 1080, 66, 66, 66, 66, 66, 17280, 1080, 1080, 17280, 1080, 66, 17280, 17280, 17280, 1080, 1080, 66, 66, 66, 17280, 66, 1080, 1080, 66, 17280, 17280, 17280, 66, 66, 17280, 1080, 17280, 17280, 66, 17280, 66, 1080, 66, 66, 1080, 1080, 17280, 17280, 17280, 66, 17280, 1080, 1080, 66, 66, 66, 66, 17280, 1080, 17280, 1080, 17280, 17280, 17280, 66, 1080, 1080, 17280, 1080, 17280, 66, 66, 66, 1080, 1080, 1080, 17280, 17280, 1080, 17280, 66, 1080, 1080, 66, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 17280, 66, 17280, 66, 17280, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 17280, 1080, 66, 66]
Prompts retrieved: 993858 . Total input tokens: 221622877 . Total output tokens: 195469147
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.22198254102841,
    "estimated_duration": 3600.061509145511,
    "input_throughput": 4933.005715287125,
    "output_throughput": 4291.088349672861,
    "total_throughput": 9224.094064959987,
    "itl": 112.59956261858368,
    "ttft": 1971540.5873324932,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1477,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.429051229222827,
    "arrivals": 331579,
    "finished_requests": 71666,
    "scheduler_time": 103.64268770780791
}
#Debug simulation 
Total elapsed time: 5.222074282821268. Arrivals time: 0.2699120114557445 Scheduler time: 4.794137707911432 Scheduler overhead time: 0.045617671217769384 Adapter cache time: 0.04324219888076186 Engine time: 0.047312323935329914 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_16-16-32/adapters_160_slots_96_rate_1.6-0.1-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_16-16-32/adapters_160_slots_96_rate_1.6-0.1-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 1080, 66, 66, 66, 17280, 66, 1080, 17280, 1080, 66, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 66, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 66, 1080, 1080, 1080, 17280, 66, 66, 17280, 66, 17280, 66, 66, 1080, 66, 1080, 17280, 66, 66, 1080, 66, 66, 66, 66, 66, 17280, 1080, 1080, 17280, 1080, 66, 17280, 17280, 17280, 1080, 1080, 66, 66, 66, 17280, 66, 1080, 1080, 66, 17280, 17280, 17280, 66, 66, 17280, 1080, 17280, 17280, 66, 17280, 66, 1080, 66, 66, 1080, 1080, 17280, 17280, 17280, 66, 17280, 1080, 1080, 66, 66, 66, 66, 17280, 1080, 17280, 1080, 17280, 17280, 17280, 66, 1080, 1080, 17280, 1080, 17280, 66, 66, 66, 1080, 1080, 1080, 17280, 17280, 1080, 17280, 66, 1080, 1080, 66, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 17280, 66, 17280, 66, 17280, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 17280, 1080, 66, 66]
Prompts retrieved: 993858 . Total input tokens: 221622877 . Total output tokens: 195469147
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 4.858727422077209,
    "estimated_duration": 3600.037838341825,
    "input_throughput": 4538.749794787168,
    "output_throughput": 3943.9621575032606,
    "total_throughput": 8482.711952290429,
    "itl": 87.54738897367984,
    "ttft": 2033214.3027947994,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1364,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.042479212507542,
    "arrivals": 331579,
    "finished_requests": 65835,
    "scheduler_time": 110.28339702180307
}
#Debug simulation 
Total elapsed time: 4.858842291869223. Arrivals time: 0.2555291657336056 Scheduler time: 4.415017888881266 Scheduler overhead time: 0.055550653487443924 Adapter cache time: 0.0484429057687521 Engine time: 0.057637854013592005 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-8/adapters_160_slots_96_rate_1.6-0.1-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-8/adapters_160_slots_96_rate_1.6-0.1-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 1080, 33, 33, 33, 17280, 33, 1080, 17280, 1080, 33, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 33, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 33, 1080, 1080, 1080, 17280, 33, 33, 17280, 33, 17280, 33, 33, 1080, 33, 1080, 17280, 33, 33, 1080, 33, 33, 33, 33, 33, 17280, 1080, 1080, 17280, 1080, 33, 17280, 17280, 17280, 1080, 1080, 33, 33, 33, 17280, 33, 1080, 1080, 33, 17280, 17280, 17280, 33, 33, 17280, 1080, 17280, 17280, 33, 17280, 33, 1080, 33, 33, 1080, 1080, 17280, 17280, 17280, 33, 17280, 1080, 1080, 33, 33, 33, 33, 17280, 1080, 17280, 1080, 17280, 17280, 17280, 33, 1080, 1080, 17280, 1080, 17280, 33, 33, 33, 1080, 1080, 1080, 17280, 17280, 1080, 17280, 33, 1080, 1080, 33, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 17280, 33, 17280, 33, 17280, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 17280, 1080, 33, 33]
Prompts retrieved: 992109 . Total input tokens: 221209647 . Total output tokens: 195121829
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.331008770968765,
    "estimated_duration": 3600.1268402255564,
    "input_throughput": 5085.2344410323585,
    "output_throughput": 4418.908751282576,
    "total_throughput": 9504.143192314936,
    "itl": 123.79304702337274,
    "ttft": 1954201.9546366858,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1263,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.351472607352973,
    "arrivals": 330904,
    "finished_requests": 73752,
    "scheduler_time": 101.82306797465195
}
#Debug simulation 
Total elapsed time: 5.331129053141922. Arrivals time: 0.24542593955993652 Scheduler time: 4.940398110542446 Scheduler overhead time: 0.04222232103347778 Adapter cache time: 0.03900797385722399 Engine time: 0.043846752028912306 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-16/adapters_160_slots_96_rate_1.6-0.1-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-16/adapters_160_slots_96_rate_1.6-0.1-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 1080, 33, 33, 33, 17280, 33, 1080, 17280, 1080, 33, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 33, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 33, 1080, 1080, 1080, 17280, 33, 33, 17280, 33, 17280, 33, 33, 1080, 33, 1080, 17280, 33, 33, 1080, 33, 33, 33, 33, 33, 17280, 1080, 1080, 17280, 1080, 33, 17280, 17280, 17280, 1080, 1080, 33, 33, 33, 17280, 33, 1080, 1080, 33, 17280, 17280, 17280, 33, 33, 17280, 1080, 17280, 17280, 33, 17280, 33, 1080, 33, 33, 1080, 1080, 17280, 17280, 17280, 33, 17280, 1080, 1080, 33, 33, 33, 33, 17280, 1080, 17280, 1080, 17280, 17280, 17280, 33, 1080, 1080, 17280, 1080, 17280, 33, 33, 33, 1080, 1080, 1080, 17280, 17280, 1080, 17280, 33, 1080, 1080, 33, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 17280, 33, 17280, 33, 17280, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 17280, 1080, 33, 33]
Prompts retrieved: 992109 . Total input tokens: 221209647 . Total output tokens: 195121829
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.204804078210145,
    "estimated_duration": 3600.022979406038,
    "input_throughput": 4952.839218526821,
    "output_throughput": 4306.708065112968,
    "total_throughput": 9259.54728363979,
    "itl": 111.6253919614907,
    "ttft": 1972203.4350826582,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1232,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.003331796899406,
    "arrivals": 330904,
    "finished_requests": 71813,
    "scheduler_time": 104.22183366141158
}
#Debug simulation 
Total elapsed time: 5.204894060268998. Arrivals time: 0.2456588577479124 Scheduler time: 4.802735657431185 Scheduler overhead time: 0.04589285980910063 Adapter cache time: 0.04131029872223735 Engine time: 0.047396293841302395 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-32/adapters_160_slots_96_rate_1.6-0.1-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-32/adapters_160_slots_96_rate_1.6-0.1-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 1080, 33, 33, 33, 17280, 33, 1080, 17280, 1080, 33, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 33, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 33, 1080, 1080, 1080, 17280, 33, 33, 17280, 33, 17280, 33, 33, 1080, 33, 1080, 17280, 33, 33, 1080, 33, 33, 33, 33, 33, 17280, 1080, 1080, 17280, 1080, 33, 17280, 17280, 17280, 1080, 1080, 33, 33, 33, 17280, 33, 1080, 1080, 33, 17280, 17280, 17280, 33, 33, 17280, 1080, 17280, 17280, 33, 17280, 33, 1080, 33, 33, 1080, 1080, 17280, 17280, 17280, 33, 17280, 1080, 1080, 33, 33, 33, 33, 17280, 1080, 17280, 1080, 17280, 17280, 17280, 33, 1080, 1080, 17280, 1080, 17280, 33, 33, 33, 1080, 1080, 1080, 17280, 17280, 1080, 17280, 33, 1080, 1080, 33, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 17280, 33, 17280, 33, 17280, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 17280, 1080, 33, 33]
Prompts retrieved: 992109 . Total input tokens: 221209647 . Total output tokens: 195121829
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 4.870004990603775,
    "estimated_duration": 3600.0808139083874,
    "input_throughput": 4529.220271113318,
    "output_throughput": 3946.589461300231,
    "total_throughput": 8475.809732413549,
    "itl": 86.60601202163821,
    "ttft": 2036758.547785085,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1143,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.586731855338426,
    "arrivals": 330904,
    "finished_requests": 65694,
    "scheduler_time": 110.93870703444728
}
#Debug simulation 
Total elapsed time: 4.870101382024586. Arrivals time: 0.22728103632107377 Scheduler time: 4.453002948779613 Scheduler overhead time: 0.05621327366679907 Adapter cache time: 0.04796013701707125 Engine time: 0.05859546875581145 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-16-16/adapters_160_slots_96_rate_1.6-0.1-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-16-16/adapters_160_slots_96_rate_1.6-0.1-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 1080, 33, 33, 33, 17280, 33, 1080, 17280, 1080, 33, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 33, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 33, 1080, 1080, 1080, 17280, 33, 33, 17280, 33, 17280, 33, 33, 1080, 33, 1080, 17280, 33, 33, 1080, 33, 33, 33, 33, 33, 17280, 1080, 1080, 17280, 1080, 33, 17280, 17280, 17280, 1080, 1080, 33, 33, 33, 17280, 33, 1080, 1080, 33, 17280, 17280, 17280, 33, 33, 17280, 1080, 17280, 17280, 33, 17280, 33, 1080, 33, 33, 1080, 1080, 17280, 17280, 17280, 33, 17280, 1080, 1080, 33, 33, 33, 33, 17280, 1080, 17280, 1080, 17280, 17280, 17280, 33, 1080, 1080, 17280, 1080, 17280, 33, 33, 33, 1080, 1080, 1080, 17280, 17280, 1080, 17280, 33, 1080, 1080, 33, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 17280, 33, 17280, 33, 17280, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 17280, 1080, 33, 33]
Prompts retrieved: 992109 . Total input tokens: 221209647 . Total output tokens: 195121829
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 5.27500753197819,
    "estimated_duration": 3600.044644931348,
    "input_throughput": 4953.745788988704,
    "output_throughput": 4307.2968613964795,
    "total_throughput": 9261.042650385183,
    "itl": 111.61250141296162,
    "ttft": 1972210.6078266182,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1234,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.478858122108502,
    "arrivals": 330904,
    "finished_requests": 71824,
    "scheduler_time": 104.23631408049042
}
#Debug simulation 
Total elapsed time: 5.2751280576922. Arrivals time: 0.24732254724949598 Scheduler time: 4.869557925499976 Scheduler overhead time: 0.04624246060848236 Adapter cache time: 0.04191309539601207 Engine time: 0.048004199750721455 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-16-32/adapters_160_slots_96_rate_1.6-0.1-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-16-32/adapters_160_slots_96_rate_1.6-0.1-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 1080, 33, 33, 33, 17280, 33, 1080, 17280, 1080, 33, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 33, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 33, 1080, 1080, 1080, 17280, 33, 33, 17280, 33, 17280, 33, 33, 1080, 33, 1080, 17280, 33, 33, 1080, 33, 33, 33, 33, 33, 17280, 1080, 1080, 17280, 1080, 33, 17280, 17280, 17280, 1080, 1080, 33, 33, 33, 17280, 33, 1080, 1080, 33, 17280, 17280, 17280, 33, 33, 17280, 1080, 17280, 17280, 33, 17280, 33, 1080, 33, 33, 1080, 1080, 17280, 17280, 17280, 33, 17280, 1080, 1080, 33, 33, 33, 33, 17280, 1080, 17280, 1080, 17280, 17280, 17280, 33, 1080, 1080, 17280, 1080, 17280, 33, 33, 33, 1080, 1080, 1080, 17280, 17280, 1080, 17280, 33, 1080, 1080, 33, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 17280, 33, 17280, 33, 17280, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 17280, 1080, 33, 33]
Prompts retrieved: 992109 . Total input tokens: 221209647 . Total output tokens: 195121829
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 4.9056100603193045,
    "estimated_duration": 3600.085396719043,
    "input_throughput": 4529.633662262993,
    "output_throughput": 3947.086925479663,
    "total_throughput": 8476.720587742657,
    "itl": 86.61873248555017,
    "ttft": 2036586.0804539758,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1144,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.518588807717887,
    "arrivals": 330904,
    "finished_requests": 65702,
    "scheduler_time": 110.93468408200107
}
#Debug simulation 
Total elapsed time: 4.905736638233066. Arrivals time: 0.2608264614827931 Scheduler time: 4.45521233137697 Scheduler overhead time: 0.05645997216925025 Adapter cache time: 0.0471250438131392 Engine time: 0.05901537649333477 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_16-16-16/adapters_160_slots_96_rate_1.6-0.1-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_16-16-16/adapters_160_slots_96_rate_1.6-0.1-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 1080, 33, 33, 33, 17280, 33, 1080, 17280, 1080, 33, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 33, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 33, 1080, 1080, 1080, 17280, 33, 33, 17280, 33, 17280, 33, 33, 1080, 33, 1080, 17280, 33, 33, 1080, 33, 33, 33, 33, 33, 17280, 1080, 1080, 17280, 1080, 33, 17280, 17280, 17280, 1080, 1080, 33, 33, 33, 17280, 33, 1080, 1080, 33, 17280, 17280, 17280, 33, 33, 17280, 1080, 17280, 17280, 33, 17280, 33, 1080, 33, 33, 1080, 1080, 17280, 17280, 17280, 33, 17280, 1080, 1080, 33, 33, 33, 33, 17280, 1080, 17280, 1080, 17280, 17280, 17280, 33, 1080, 1080, 17280, 1080, 17280, 33, 33, 33, 1080, 1080, 1080, 17280, 17280, 1080, 17280, 33, 1080, 1080, 33, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 17280, 33, 17280, 33, 17280, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 17280, 1080, 33, 33]
Prompts retrieved: 992109 . Total input tokens: 221209647 . Total output tokens: 195121829
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.245461882092059,
    "estimated_duration": 3600.087306573451,
    "input_throughput": 4954.210962449088,
    "output_throughput": 4308.052744076853,
    "total_throughput": 9262.26370652594,
    "itl": 111.59254976641247,
    "ttft": 1972044.6804360428,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1234,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.877758440663998,
    "arrivals": 330904,
    "finished_requests": 71833,
    "scheduler_time": 104.25335883990671
}
#Debug simulation 
Total elapsed time: 5.245551305823028. Arrivals time: 0.24091578787192702 Scheduler time: 4.846761343535036 Scheduler overhead time: 0.046046826522797346 Adapter cache time: 0.041598877403885126 Engine time: 0.048235959373414516 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_16-16-32/adapters_160_slots_96_rate_1.6-0.1-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_16-16-32/adapters_160_slots_96_rate_1.6-0.1-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 1080, 33, 33, 33, 17280, 33, 1080, 17280, 1080, 33, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 33, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 33, 1080, 1080, 1080, 17280, 33, 33, 17280, 33, 17280, 33, 33, 1080, 33, 1080, 17280, 33, 33, 1080, 33, 33, 33, 33, 33, 17280, 1080, 1080, 17280, 1080, 33, 17280, 17280, 17280, 1080, 1080, 33, 33, 33, 17280, 33, 1080, 1080, 33, 17280, 17280, 17280, 33, 33, 17280, 1080, 17280, 17280, 33, 17280, 33, 1080, 33, 33, 1080, 1080, 17280, 17280, 17280, 33, 17280, 1080, 1080, 33, 33, 33, 33, 17280, 1080, 17280, 1080, 17280, 17280, 17280, 33, 1080, 1080, 17280, 1080, 17280, 33, 33, 33, 1080, 1080, 1080, 17280, 17280, 1080, 17280, 33, 1080, 1080, 33, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 17280, 33, 17280, 33, 17280, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 17280, 1080, 33, 33]
Prompts retrieved: 992109 . Total input tokens: 221209647 . Total output tokens: 195121829
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 4.8664588537067175,
    "estimated_duration": 3600.068614223825,
    "input_throughput": 4532.187507631093,
    "output_throughput": 3950.415262589714,
    "total_throughput": 8482.602770220807,
    "itl": 86.78609415796325,
    "ttft": 2035828.9067424524,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1143,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.428080098051572,
    "arrivals": 330904,
    "finished_requests": 65749,
    "scheduler_time": 110.87996033766042
}
#Debug simulation 
Total elapsed time: 4.866577552631497. Arrivals time: 0.2600268181413412 Scheduler time: 4.417574739083648 Scheduler overhead time: 0.05606138054281473 Adapter cache time: 0.04759889468550682 Engine time: 0.05838653910905123 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-8-8/adapters_160_slots_96_rate_1.6-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-8-8/adapters_160_slots_96_rate_1.6-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [53 53 54]
Adapter prompts. [270, 17280, 270, 270, 540, 270, 270, 270, 17280, 270, 540, 17280, 540, 270, 540, 540, 540, 540, 17280, 17280, 17280, 540, 540, 540, 17280, 17280, 270, 17280, 540, 17280, 17280, 17280, 540, 17280, 270, 540, 540, 540, 17280, 270, 270, 17280, 270, 17280, 270, 270, 540, 270, 540, 17280, 270, 270, 540, 270, 270, 270, 270, 270, 17280, 540, 540, 17280, 540, 270, 17280, 17280, 17280, 540, 540, 270, 270, 270, 17280, 270, 540, 540, 270, 17280, 17280, 17280, 270, 270, 17280, 540, 17280, 17280, 270, 17280, 270, 540, 270, 270, 540, 540, 17280, 17280, 17280, 270, 17280, 540, 540, 270, 270, 270, 270, 17280, 540, 17280, 540, 17280, 17280, 17280, 270, 540, 540, 17280, 540, 17280, 270, 270, 270, 540, 540, 540, 17280, 17280, 540, 17280, 270, 540, 540, 270, 17280, 17280, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 540, 17280, 270, 17280, 270, 17280, 540, 270, 540, 270, 270, 540, 540, 540, 17280, 540, 270, 270]
Prompts retrieved: 976050 . Total input tokens: 217623164 . Total output tokens: 191983283
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.388308978173882,
    "estimated_duration": 3600.108808221146,
    "input_throughput": 5176.314381788896,
    "output_throughput": 4495.182190895023,
    "total_throughput": 9671.496572683918,
    "itl": 121.69352578483723,
    "ttft": 1934503.3457777014,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2010,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.290942154219735,
    "arrivals": 325545,
    "finished_requests": 75059,
    "scheduler_time": 103.56915237261961
}
#Debug simulation 
Total elapsed time: 5.3884229538962245. Arrivals time: 0.24546446278691292 Scheduler time: 4.993783830665052 Scheduler overhead time: 0.04286627611145377 Adapter cache time: 0.04150329623371363 Engine time: 0.04432358220219612 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-8-16/adapters_160_slots_96_rate_1.6-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-8-16/adapters_160_slots_96_rate_1.6-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [53 53 54]
Adapter prompts. [270, 17280, 270, 270, 540, 270, 270, 270, 17280, 270, 540, 17280, 540, 270, 540, 540, 540, 540, 17280, 17280, 17280, 540, 540, 540, 17280, 17280, 270, 17280, 540, 17280, 17280, 17280, 540, 17280, 270, 540, 540, 540, 17280, 270, 270, 17280, 270, 17280, 270, 270, 540, 270, 540, 17280, 270, 270, 540, 270, 270, 270, 270, 270, 17280, 540, 540, 17280, 540, 270, 17280, 17280, 17280, 540, 540, 270, 270, 270, 17280, 270, 540, 540, 270, 17280, 17280, 17280, 270, 270, 17280, 540, 17280, 17280, 270, 17280, 270, 540, 270, 270, 540, 540, 17280, 17280, 17280, 270, 17280, 540, 540, 270, 270, 270, 270, 17280, 540, 17280, 540, 17280, 17280, 17280, 270, 540, 540, 17280, 540, 17280, 270, 270, 270, 540, 540, 540, 17280, 17280, 540, 17280, 270, 540, 540, 270, 17280, 17280, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 540, 17280, 270, 17280, 270, 17280, 540, 270, 540, 270, 270, 540, 540, 540, 17280, 540, 270, 270]
Prompts retrieved: 976050 . Total input tokens: 217623164 . Total output tokens: 191983283
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.260379995685071,
    "estimated_duration": 3600.11555215338,
    "input_throughput": 5047.862141294336,
    "output_throughput": 4384.686483343043,
    "total_throughput": 9432.548624637378,
    "itl": 109.66358013832901,
    "ttft": 1954128.865373945,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1967,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.349365766648916,
    "arrivals": 325545,
    "finished_requests": 73207,
    "scheduler_time": 106.06992133501197
}
#Debug simulation 
Total elapsed time: 5.260471573565155. Arrivals time: 0.24432946043089032 Scheduler time: 4.856517836917192 Scheduler overhead time: 0.04649812960997224 Adapter cache time: 0.0426532169803977 Engine time: 0.04824380297213793 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-8-32/adapters_160_slots_96_rate_1.6-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-8-32/adapters_160_slots_96_rate_1.6-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [53 53 54]
Adapter prompts. [270, 17280, 270, 270, 540, 270, 270, 270, 17280, 270, 540, 17280, 540, 270, 540, 540, 540, 540, 17280, 17280, 17280, 540, 540, 540, 17280, 17280, 270, 17280, 540, 17280, 17280, 17280, 540, 17280, 270, 540, 540, 540, 17280, 270, 270, 17280, 270, 17280, 270, 270, 540, 270, 540, 17280, 270, 270, 540, 270, 270, 270, 270, 270, 17280, 540, 540, 17280, 540, 270, 17280, 17280, 17280, 540, 540, 270, 270, 270, 17280, 270, 540, 540, 270, 17280, 17280, 17280, 270, 270, 17280, 540, 17280, 17280, 270, 17280, 270, 540, 270, 270, 540, 540, 17280, 17280, 17280, 270, 17280, 540, 540, 270, 270, 270, 270, 17280, 540, 17280, 540, 17280, 17280, 17280, 270, 540, 540, 17280, 540, 17280, 270, 270, 270, 540, 540, 540, 17280, 17280, 540, 17280, 270, 540, 540, 270, 17280, 17280, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 540, 17280, 270, 17280, 270, 17280, 540, 270, 540, 270, 270, 540, 540, 540, 17280, 540, 270, 270]
Prompts retrieved: 976050 . Total input tokens: 217623164 . Total output tokens: 191983283
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 4.912114948965609,
    "estimated_duration": 3600.035848880497,
    "input_throughput": 4634.273574022349,
    "output_throughput": 4023.4716008464998,
    "total_throughput": 8657.745174868849,
    "itl": 85.47878619562482,
    "ttft": 2019415.5307286005,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1793,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.420939594334717,
    "arrivals": 325545,
    "finished_requests": 67162,
    "scheduler_time": 112.68462547132731
}
#Debug simulation 
Total elapsed time: 4.912205142900348. Arrivals time: 0.2294252822175622 Scheduler time: 4.494228843599558 Scheduler overhead time: 0.05674106953665614 Adapter cache time: 0.04508446389809251 Engine time: 0.05933509161695838 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-16-16/adapters_160_slots_96_rate_1.6-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-16-16/adapters_160_slots_96_rate_1.6-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [53 53 54]
Adapter prompts. [270, 17280, 270, 270, 540, 270, 270, 270, 17280, 270, 540, 17280, 540, 270, 540, 540, 540, 540, 17280, 17280, 17280, 540, 540, 540, 17280, 17280, 270, 17280, 540, 17280, 17280, 17280, 540, 17280, 270, 540, 540, 540, 17280, 270, 270, 17280, 270, 17280, 270, 270, 540, 270, 540, 17280, 270, 270, 540, 270, 270, 270, 270, 270, 17280, 540, 540, 17280, 540, 270, 17280, 17280, 17280, 540, 540, 270, 270, 270, 17280, 270, 540, 540, 270, 17280, 17280, 17280, 270, 270, 17280, 540, 17280, 17280, 270, 17280, 270, 540, 270, 270, 540, 540, 17280, 17280, 17280, 270, 17280, 540, 540, 270, 270, 270, 270, 17280, 540, 17280, 540, 17280, 17280, 17280, 270, 540, 540, 17280, 540, 17280, 270, 270, 270, 540, 540, 540, 17280, 17280, 540, 17280, 270, 540, 540, 270, 17280, 17280, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 540, 17280, 270, 17280, 270, 17280, 540, 270, 540, 270, 270, 540, 540, 540, 17280, 540, 270, 270]
Prompts retrieved: 976050 . Total input tokens: 217623164 . Total output tokens: 191983283
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 5.285845316015184,
    "estimated_duration": 3600.03014993055,
    "input_throughput": 5049.283823456499,
    "output_throughput": 4385.999100675478,
    "total_throughput": 9435.282924131976,
    "itl": 109.64087870480991,
    "ttft": 1954007.486966327,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1968,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.475617590509572,
    "arrivals": 325545,
    "finished_requests": 73224,
    "scheduler_time": 106.09212104719306
}
#Debug simulation 
Total elapsed time: 5.285956011153758. Arrivals time: 0.2517572087235749 Scheduler time: 4.874457732308656 Scheduler overhead time: 0.04644528729841113 Adapter cache time: 0.04287131363525987 Engine time: 0.04813671577721834 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-16-32/adapters_160_slots_96_rate_1.6-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-16-32/adapters_160_slots_96_rate_1.6-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [53 53 54]
Adapter prompts. [270, 17280, 270, 270, 540, 270, 270, 270, 17280, 270, 540, 17280, 540, 270, 540, 540, 540, 540, 17280, 17280, 17280, 540, 540, 540, 17280, 17280, 270, 17280, 540, 17280, 17280, 17280, 540, 17280, 270, 540, 540, 540, 17280, 270, 270, 17280, 270, 17280, 270, 270, 540, 270, 540, 17280, 270, 270, 540, 270, 270, 270, 270, 270, 17280, 540, 540, 17280, 540, 270, 17280, 17280, 17280, 540, 540, 270, 270, 270, 17280, 270, 540, 540, 270, 17280, 17280, 17280, 270, 270, 17280, 540, 17280, 17280, 270, 17280, 270, 540, 270, 270, 540, 540, 17280, 17280, 17280, 270, 17280, 540, 540, 270, 270, 270, 270, 17280, 540, 17280, 540, 17280, 17280, 17280, 270, 540, 540, 17280, 540, 17280, 270, 270, 270, 540, 540, 540, 17280, 17280, 540, 17280, 270, 540, 540, 270, 17280, 17280, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 540, 17280, 270, 17280, 270, 17280, 540, 270, 540, 270, 270, 540, 540, 540, 17280, 540, 270, 270]
Prompts retrieved: 976050 . Total input tokens: 217623164 . Total output tokens: 191983283
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 4.961690905038267,
    "estimated_duration": 3600.0544009848663,
    "input_throughput": 4634.53968791016,
    "output_throughput": 4023.760862068399,
    "total_throughput": 8658.30054997856,
    "itl": 85.47526491912909,
    "ttft": 2019272.312052423,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1792,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.293978261584217,
    "arrivals": 325545,
    "finished_requests": 67167,
    "scheduler_time": 112.6906869664944
}
#Debug simulation 
Total elapsed time: 4.961780501063913. Arrivals time: 0.24789298325777054 Scheduler time: 4.523633607197553 Scheduler overhead time: 0.05727848783135414 Adapter cache time: 0.04584993654862046 Engine time: 0.05960194393992424 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_16-16-16/adapters_160_slots_96_rate_1.6-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_16-16-16/adapters_160_slots_96_rate_1.6-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [53 53 54]
Adapter prompts. [270, 17280, 270, 270, 540, 270, 270, 270, 17280, 270, 540, 17280, 540, 270, 540, 540, 540, 540, 17280, 17280, 17280, 540, 540, 540, 17280, 17280, 270, 17280, 540, 17280, 17280, 17280, 540, 17280, 270, 540, 540, 540, 17280, 270, 270, 17280, 270, 17280, 270, 270, 540, 270, 540, 17280, 270, 270, 540, 270, 270, 270, 270, 270, 17280, 540, 540, 17280, 540, 270, 17280, 17280, 17280, 540, 540, 270, 270, 270, 17280, 270, 540, 540, 270, 17280, 17280, 17280, 270, 270, 17280, 540, 17280, 17280, 270, 17280, 270, 540, 270, 270, 540, 540, 17280, 17280, 17280, 270, 17280, 540, 540, 270, 270, 270, 270, 17280, 540, 17280, 540, 17280, 17280, 17280, 270, 540, 540, 17280, 540, 17280, 270, 270, 270, 540, 540, 540, 17280, 17280, 540, 17280, 270, 540, 540, 270, 17280, 17280, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 540, 17280, 270, 17280, 270, 17280, 540, 270, 540, 270, 270, 540, 540, 540, 17280, 540, 270, 270]
Prompts retrieved: 976050 . Total input tokens: 217623164 . Total output tokens: 191983283
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.341514016035944,
    "estimated_duration": 3600.0793054219357,
    "input_throughput": 5051.6214941738735,
    "output_throughput": 4387.882504757376,
    "total_throughput": 9439.50399893125,
    "itl": 109.60723970563973,
    "ttft": 1954017.4057568575,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1966,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.550788569162235,
    "arrivals": 325545,
    "finished_requests": 73255,
    "scheduler_time": 106.1190854059974
}
#Debug simulation 
Total elapsed time: 5.341604946181178. Arrivals time: 0.24321662029251456 Scheduler time: 4.937577959150076 Scheduler overhead time: 0.04685467015951872 Adapter cache time: 0.04272809764370322 Engine time: 0.048801567405462265 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_16-16-32/adapters_160_slots_96_rate_1.6-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_16-16-32/adapters_160_slots_96_rate_1.6-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [53 53 54]
Adapter prompts. [270, 17280, 270, 270, 540, 270, 270, 270, 17280, 270, 540, 17280, 540, 270, 540, 540, 540, 540, 17280, 17280, 17280, 540, 540, 540, 17280, 17280, 270, 17280, 540, 17280, 17280, 17280, 540, 17280, 270, 540, 540, 540, 17280, 270, 270, 17280, 270, 17280, 270, 270, 540, 270, 540, 17280, 270, 270, 540, 270, 270, 270, 270, 270, 17280, 540, 540, 17280, 540, 270, 17280, 17280, 17280, 540, 540, 270, 270, 270, 17280, 270, 540, 540, 270, 17280, 17280, 17280, 270, 270, 17280, 540, 17280, 17280, 270, 17280, 270, 540, 270, 270, 540, 540, 17280, 17280, 17280, 270, 17280, 540, 540, 270, 270, 270, 270, 17280, 540, 17280, 540, 17280, 17280, 17280, 270, 540, 540, 17280, 540, 17280, 270, 270, 270, 540, 540, 540, 17280, 17280, 540, 17280, 270, 540, 540, 270, 17280, 17280, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 540, 17280, 270, 17280, 270, 17280, 540, 270, 540, 270, 270, 540, 540, 540, 17280, 540, 270, 270]
Prompts retrieved: 976050 . Total input tokens: 217623164 . Total output tokens: 191983283
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 4.914879844058305,
    "estimated_duration": 3600.087719629606,
    "input_throughput": 4634.565682670815,
    "output_throughput": 4023.8172311785775,
    "total_throughput": 8658.382913849391,
    "itl": 85.47283635679266,
    "ttft": 2019290.7604706895,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1791,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.162253233771573,
    "arrivals": 325545,
    "finished_requests": 67169,
    "scheduler_time": 112.69363121973234
}
#Debug simulation 
Total elapsed time: 4.914971217978746. Arrivals time: 0.23035999527201056 Scheduler time: 4.49487669300288 Scheduler overhead time: 0.05702274991199374 Adapter cache time: 0.045786379370838404 Engine time: 0.059673331677913666 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-8/adapters_160_slots_96_rate_1.6-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-8/adapters_160_slots_96_rate_1.6-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [53 53 54]
Adapter prompts. [135, 17280, 135, 135, 540, 135, 135, 135, 17280, 135, 540, 17280, 540, 135, 540, 540, 540, 540, 17280, 17280, 17280, 540, 540, 540, 17280, 17280, 135, 17280, 540, 17280, 17280, 17280, 540, 17280, 135, 540, 540, 540, 17280, 135, 135, 17280, 135, 17280, 135, 135, 540, 135, 540, 17280, 135, 135, 540, 135, 135, 135, 135, 135, 17280, 540, 540, 17280, 540, 135, 17280, 17280, 17280, 540, 540, 135, 135, 135, 17280, 135, 540, 540, 135, 17280, 17280, 17280, 135, 135, 17280, 540, 17280, 17280, 135, 17280, 135, 540, 135, 135, 540, 540, 17280, 17280, 17280, 135, 17280, 540, 540, 135, 135, 135, 135, 17280, 540, 17280, 540, 17280, 17280, 17280, 135, 540, 540, 17280, 540, 17280, 135, 135, 135, 540, 540, 540, 17280, 17280, 540, 17280, 135, 540, 540, 135, 17280, 17280, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 540, 17280, 135, 17280, 135, 17280, 540, 135, 540, 135, 135, 540, 540, 540, 17280, 540, 135, 135]
Prompts retrieved: 968895 . Total input tokens: 216027269 . Total output tokens: 190582552
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.5083018178120255,
    "estimated_duration": 3600.1310467765916,
    "input_throughput": 5234.289739778294,
    "output_throughput": 4586.6999799312325,
    "total_throughput": 9820.989719709525,
    "itl": 119.9403967385324,
    "ttft": 1920982.7656838407,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1505,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.951675593084909,
    "arrivals": 323217,
    "finished_requests": 76458,
    "scheduler_time": 105.36603092917605
}
#Debug simulation 
Total elapsed time: 5.508391554933041. Arrivals time: 0.2535436684265733 Scheduler time: 5.107727025169879 Scheduler overhead time: 0.04344783537089825 Adapter cache time: 0.03708059946075082 Engine time: 0.04563599731773138 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-16/adapters_160_slots_96_rate_1.6-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-16/adapters_160_slots_96_rate_1.6-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [53 53 54]
Adapter prompts. [135, 17280, 135, 135, 540, 135, 135, 135, 17280, 135, 540, 17280, 540, 135, 540, 540, 540, 540, 17280, 17280, 17280, 540, 540, 540, 17280, 17280, 135, 17280, 540, 17280, 17280, 17280, 540, 17280, 135, 540, 540, 540, 17280, 135, 135, 17280, 135, 17280, 135, 135, 540, 135, 540, 17280, 135, 135, 540, 135, 135, 135, 135, 135, 17280, 540, 540, 17280, 540, 135, 17280, 17280, 17280, 540, 540, 135, 135, 135, 17280, 135, 540, 540, 135, 17280, 17280, 17280, 135, 135, 17280, 540, 17280, 17280, 135, 17280, 135, 540, 135, 135, 540, 540, 17280, 17280, 17280, 135, 17280, 540, 540, 135, 135, 135, 135, 17280, 540, 17280, 540, 17280, 17280, 17280, 135, 540, 540, 17280, 540, 17280, 135, 135, 135, 540, 540, 540, 17280, 17280, 540, 17280, 135, 540, 540, 135, 17280, 17280, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 540, 17280, 135, 17280, 135, 17280, 540, 135, 540, 135, 135, 540, 540, 540, 17280, 540, 135, 135]
Prompts retrieved: 968895 . Total input tokens: 216027269 . Total output tokens: 190582552
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.370191723108292,
    "estimated_duration": 3600.0415598551745,
    "input_throughput": 5086.746832093986,
    "output_throughput": 4464.069853862052,
    "total_throughput": 9550.816685956037,
    "itl": 108.3514211587935,
    "ttft": 1940311.48185197,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1461,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.67764750120687,
    "arrivals": 323217,
    "finished_requests": 74329,
    "scheduler_time": 107.69566274580038
}
#Debug simulation 
Total elapsed time: 5.370308119803667. Arrivals time: 0.2769608376547694 Scheduler time: 4.935965448152274 Scheduler overhead time: 0.04722440056502819 Adapter cache time: 0.03850773721933365 Engine time: 0.04900560108944774 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-32/adapters_160_slots_96_rate_1.6-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-32/adapters_160_slots_96_rate_1.6-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [53 53 54]
Adapter prompts. [135, 17280, 135, 135, 540, 135, 135, 135, 17280, 135, 540, 17280, 540, 135, 540, 540, 540, 540, 17280, 17280, 17280, 540, 540, 540, 17280, 17280, 135, 17280, 540, 17280, 17280, 17280, 540, 17280, 135, 540, 540, 540, 17280, 135, 135, 17280, 135, 17280, 135, 135, 540, 135, 540, 17280, 135, 135, 540, 135, 135, 135, 135, 135, 17280, 540, 540, 17280, 540, 135, 17280, 17280, 17280, 540, 540, 135, 135, 135, 17280, 135, 540, 540, 135, 17280, 17280, 17280, 135, 135, 17280, 540, 17280, 17280, 135, 17280, 135, 540, 135, 135, 540, 540, 17280, 17280, 17280, 135, 17280, 540, 540, 135, 135, 135, 135, 17280, 540, 17280, 540, 17280, 17280, 17280, 135, 540, 540, 17280, 540, 17280, 135, 135, 135, 540, 540, 540, 17280, 17280, 540, 17280, 135, 540, 540, 135, 17280, 17280, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 540, 17280, 135, 17280, 135, 17280, 540, 135, 540, 135, 135, 540, 540, 540, 17280, 540, 135, 135]
Prompts retrieved: 968895 . Total input tokens: 216027269 . Total output tokens: 190582552
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.0049295532517135,
    "estimated_duration": 3600.0248785112776,
    "input_throughput": 4646.373168097983,
    "output_throughput": 4085.0484361323365,
    "total_throughput": 8731.42160423032,
    "itl": 84.65855091371161,
    "ttft": 2007129.5720587429,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1322,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.91615015439217,
    "arrivals": 323217,
    "finished_requests": 67921,
    "scheduler_time": 114.0821392446999
}
#Debug simulation 
Total elapsed time: 5.0050444840453565. Arrivals time: 0.25757657596841455 Scheduler time: 4.561675004661083 Scheduler overhead time: 0.05747005669400096 Adapter cache time: 0.040736830327659845 Engine time: 0.0600806619040668 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-16-16/adapters_160_slots_96_rate_1.6-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-16-16/adapters_160_slots_96_rate_1.6-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [53 53 54]
Adapter prompts. [135, 17280, 135, 135, 540, 135, 135, 135, 17280, 135, 540, 17280, 540, 135, 540, 540, 540, 540, 17280, 17280, 17280, 540, 540, 540, 17280, 17280, 135, 17280, 540, 17280, 17280, 17280, 540, 17280, 135, 540, 540, 540, 17280, 135, 135, 17280, 135, 17280, 135, 135, 540, 135, 540, 17280, 135, 135, 540, 135, 135, 135, 135, 135, 17280, 540, 540, 17280, 540, 135, 17280, 17280, 17280, 540, 540, 135, 135, 135, 17280, 135, 540, 540, 135, 17280, 17280, 17280, 135, 135, 17280, 540, 17280, 17280, 135, 17280, 135, 540, 135, 135, 540, 540, 17280, 17280, 17280, 135, 17280, 540, 540, 135, 135, 135, 135, 17280, 540, 17280, 540, 17280, 17280, 17280, 135, 540, 540, 17280, 540, 17280, 135, 135, 135, 540, 540, 540, 17280, 17280, 540, 17280, 135, 540, 540, 135, 17280, 17280, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 540, 17280, 135, 17280, 135, 17280, 540, 135, 540, 135, 135, 540, 540, 540, 17280, 540, 135, 135]
Prompts retrieved: 968895 . Total input tokens: 216027269 . Total output tokens: 190582552
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 5.3725994839333,
    "estimated_duration": 3600.0805234110903,
    "input_throughput": 5088.901173421893,
    "output_throughput": 4466.100659539062,
    "total_throughput": 9555.001832960954,
    "itl": 108.32984953121309,
    "ttft": 1940330.906252115,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1463,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.043504369524372,
    "arrivals": 323217,
    "finished_requests": 74363,
    "scheduler_time": 107.71384476107539
}
#Debug simulation 
Total elapsed time: 5.372690888121724. Arrivals time: 0.27749673649668694 Scheduler time: 4.938257623463869 Scheduler overhead time: 0.04710731841623783 Adapter cache time: 0.03826875425875187 Engine time: 0.04906372493132949 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-16-32/adapters_160_slots_96_rate_1.6-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-16-32/adapters_160_slots_96_rate_1.6-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [53 53 54]
Adapter prompts. [135, 17280, 135, 135, 540, 135, 135, 135, 17280, 135, 540, 17280, 540, 135, 540, 540, 540, 540, 17280, 17280, 17280, 540, 540, 540, 17280, 17280, 135, 17280, 540, 17280, 17280, 17280, 540, 17280, 135, 540, 540, 540, 17280, 135, 135, 17280, 135, 17280, 135, 135, 540, 135, 540, 17280, 135, 135, 540, 135, 135, 135, 135, 135, 17280, 540, 540, 17280, 540, 135, 17280, 17280, 17280, 540, 540, 135, 135, 135, 17280, 135, 540, 540, 135, 17280, 17280, 17280, 135, 135, 17280, 540, 17280, 17280, 135, 17280, 135, 540, 135, 135, 540, 540, 17280, 17280, 17280, 135, 17280, 540, 540, 135, 135, 135, 135, 17280, 540, 17280, 540, 17280, 17280, 17280, 135, 540, 540, 17280, 540, 17280, 135, 135, 135, 540, 540, 540, 17280, 17280, 540, 17280, 135, 540, 540, 135, 17280, 17280, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 540, 17280, 135, 17280, 135, 17280, 540, 135, 540, 135, 135, 540, 540, 540, 17280, 540, 135, 135]
Prompts retrieved: 968895 . Total input tokens: 216027269 . Total output tokens: 190582552
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 4.99169372394681,
    "estimated_duration": 3600.0582213371476,
    "input_throughput": 4646.065416627492,
    "output_throughput": 4084.8167156968916,
    "total_throughput": 8730.882132324383,
    "itl": 84.66132716667026,
    "ttft": 2007091.3159960273,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1323,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.835321090016453,
    "arrivals": 323217,
    "finished_requests": 67918,
    "scheduler_time": 114.08537880798984
}
#Debug simulation 
Total elapsed time: 4.991785380989313. Arrivals time: 0.26163692865520716 Scheduler time: 4.5450865644961596 Scheduler overhead time: 0.05713657382875681 Adapter cache time: 0.04068418825045228 Engine time: 0.059803133830428123 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_16-16-16/adapters_160_slots_96_rate_1.6-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_16-16-16/adapters_160_slots_96_rate_1.6-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [53 53 54]
Adapter prompts. [135, 17280, 135, 135, 540, 135, 135, 135, 17280, 135, 540, 17280, 540, 135, 540, 540, 540, 540, 17280, 17280, 17280, 540, 540, 540, 17280, 17280, 135, 17280, 540, 17280, 17280, 17280, 540, 17280, 135, 540, 540, 540, 17280, 135, 135, 17280, 135, 17280, 135, 135, 540, 135, 540, 17280, 135, 135, 540, 135, 135, 135, 135, 135, 17280, 540, 540, 17280, 540, 135, 17280, 17280, 17280, 540, 540, 135, 135, 135, 17280, 135, 540, 540, 135, 17280, 17280, 17280, 135, 135, 17280, 540, 17280, 17280, 135, 17280, 135, 540, 135, 135, 540, 540, 17280, 17280, 17280, 135, 17280, 540, 540, 135, 135, 135, 135, 17280, 540, 17280, 540, 17280, 17280, 17280, 135, 540, 540, 17280, 540, 17280, 135, 135, 135, 540, 540, 540, 17280, 17280, 540, 17280, 135, 540, 540, 135, 17280, 17280, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 540, 17280, 135, 17280, 135, 17280, 540, 135, 540, 135, 135, 540, 540, 540, 17280, 540, 135, 135]
Prompts retrieved: 968895 . Total input tokens: 216027269 . Total output tokens: 190582552
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.354713094886392,
    "estimated_duration": 3600.0310769160264,
    "input_throughput": 5091.035773974657,
    "output_throughput": 4466.967272342551,
    "total_throughput": 9558.003046317208,
    "itl": 108.3046288487389,
    "ttft": 1940434.5520929405,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1468,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.371595940757684,
    "arrivals": 323217,
    "finished_requests": 74386,
    "scheduler_time": 107.73336358796338
}
#Debug simulation 
Total elapsed time: 5.354842978995293. Arrivals time: 0.2760579213500023 Scheduler time: 4.9213623707182705 Scheduler overhead time: 0.04704897338524461 Adapter cache time: 0.03837090637534857 Engine time: 0.049316488672047853 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_16-16-32/adapters_160_slots_96_rate_1.6-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_16-16-32/adapters_160_slots_96_rate_1.6-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [53 53 54]
Adapter prompts. [135, 17280, 135, 135, 540, 135, 135, 135, 17280, 135, 540, 17280, 540, 135, 540, 540, 540, 540, 17280, 17280, 17280, 540, 540, 540, 17280, 17280, 135, 17280, 540, 17280, 17280, 17280, 540, 17280, 135, 540, 540, 540, 17280, 135, 135, 17280, 135, 17280, 135, 135, 540, 135, 540, 17280, 135, 135, 540, 135, 135, 135, 135, 135, 17280, 540, 540, 17280, 540, 135, 17280, 17280, 17280, 540, 540, 135, 135, 135, 17280, 135, 540, 540, 135, 17280, 17280, 17280, 135, 135, 17280, 540, 17280, 17280, 135, 17280, 135, 540, 135, 135, 540, 540, 17280, 17280, 17280, 135, 17280, 540, 540, 135, 135, 135, 135, 17280, 540, 17280, 540, 17280, 17280, 17280, 135, 540, 540, 17280, 540, 17280, 135, 135, 135, 540, 540, 540, 17280, 17280, 540, 17280, 135, 540, 540, 135, 17280, 17280, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 540, 17280, 135, 17280, 135, 17280, 540, 135, 540, 135, 135, 540, 540, 540, 17280, 540, 135, 135]
Prompts retrieved: 968895 . Total input tokens: 216027269 . Total output tokens: 190582552
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.088553325738758,
    "estimated_duration": 3600.0156063307218,
    "input_throughput": 4646.385135271366,
    "output_throughput": 4085.058957560803,
    "total_throughput": 8731.44409283217,
    "itl": 84.65556572328968,
    "ttft": 2007015.8717646564,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1322,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.7330067012831,
    "arrivals": 323217,
    "finished_requests": 67921,
    "scheduler_time": 114.0887102996509
}
#Debug simulation 
Total elapsed time: 5.088658447843045. Arrivals time: 0.24099789885804057 Scheduler time: 4.6601908365264535 Scheduler overhead time: 0.05802192445844412 Adapter cache time: 0.04070102423429489 Engine time: 0.06087118526920676 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-8/adapters_160_slots_96_rate_1.6-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-8/adapters_160_slots_96_rate_1.6-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 540, 66, 66, 66, 17280, 66, 540, 17280, 540, 66, 540, 540, 540, 540, 17280, 17280, 17280, 540, 540, 540, 17280, 17280, 66, 17280, 540, 17280, 17280, 17280, 540, 17280, 66, 540, 540, 540, 17280, 66, 66, 17280, 66, 17280, 66, 66, 540, 66, 540, 17280, 66, 66, 540, 66, 66, 66, 66, 66, 17280, 540, 540, 17280, 540, 66, 17280, 17280, 17280, 540, 540, 66, 66, 66, 17280, 66, 540, 540, 66, 17280, 17280, 17280, 66, 66, 17280, 540, 17280, 17280, 66, 17280, 66, 540, 66, 66, 540, 540, 17280, 17280, 17280, 66, 17280, 540, 540, 66, 66, 66, 66, 17280, 540, 17280, 540, 17280, 17280, 17280, 66, 540, 540, 17280, 540, 17280, 66, 66, 66, 540, 540, 540, 17280, 17280, 540, 17280, 66, 540, 540, 66, 17280, 17280, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 540, 17280, 66, 17280, 66, 17280, 540, 66, 540, 66, 66, 540, 540, 540, 17280, 540, 66, 66]
Prompts retrieved: 965238 . Total input tokens: 215208942 . Total output tokens: 189862100
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.585881295148283,
    "estimated_duration": 3600.114809554744,
    "input_throughput": 5338.839736163067,
    "output_throughput": 4660.416094362024,
    "total_throughput": 9999.25583052509,
    "itl": 117.57326379293514,
    "ttft": 1912762.7899925974,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1093,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.227363071921447,
    "arrivals": 321998,
    "finished_requests": 77551,
    "scheduler_time": 107.20778484862893
}
#Debug simulation 
Total elapsed time: 5.585986732039601. Arrivals time: 0.25619260780513287 Scheduler time: 5.185204833280295 Scheduler overhead time: 0.044276836793869734 Adapter cache time: 0.03275437839329243 Engine time: 0.0462034372612834 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-16/adapters_160_slots_96_rate_1.6-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-16/adapters_160_slots_96_rate_1.6-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 540, 66, 66, 66, 17280, 66, 540, 17280, 540, 66, 540, 540, 540, 540, 17280, 17280, 17280, 540, 540, 540, 17280, 17280, 66, 17280, 540, 17280, 17280, 17280, 540, 17280, 66, 540, 540, 540, 17280, 66, 66, 17280, 66, 17280, 66, 66, 540, 66, 540, 17280, 66, 66, 540, 66, 66, 66, 66, 66, 17280, 540, 540, 17280, 540, 66, 17280, 17280, 17280, 540, 540, 66, 66, 66, 17280, 66, 540, 540, 66, 17280, 17280, 17280, 66, 66, 17280, 540, 17280, 17280, 66, 17280, 66, 540, 66, 66, 540, 540, 17280, 17280, 17280, 66, 17280, 540, 540, 66, 66, 66, 66, 17280, 540, 17280, 540, 17280, 17280, 17280, 66, 540, 540, 17280, 540, 17280, 66, 66, 66, 540, 540, 540, 17280, 17280, 540, 17280, 66, 540, 540, 66, 17280, 17280, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 540, 17280, 66, 17280, 66, 17280, 540, 66, 540, 66, 66, 540, 540, 540, 17280, 540, 66, 66]
Prompts retrieved: 965238 . Total input tokens: 215208942 . Total output tokens: 189862100
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.47496870206669,
    "estimated_duration": 3600.0782919522817,
    "input_throughput": 5189.306588626719,
    "output_throughput": 4529.533437217854,
    "total_throughput": 9718.840025844573,
    "itl": 106.31010364872188,
    "ttft": 1934339.9590642708,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1062,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.769525592857984,
    "arrivals": 321998,
    "finished_requests": 75329,
    "scheduler_time": 109.44432374887913
}
#Debug simulation 
Total elapsed time: 5.475058908108622. Arrivals time: 0.24915613746270537 Scheduler time: 5.070464997086674 Scheduler overhead time: 0.04797782236710191 Adapter cache time: 0.034111049957573414 Engine time: 0.050207335501909256 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-32/adapters_160_slots_96_rate_1.6-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-32/adapters_160_slots_96_rate_1.6-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 540, 66, 66, 66, 17280, 66, 540, 17280, 540, 66, 540, 540, 540, 540, 17280, 17280, 17280, 540, 540, 540, 17280, 17280, 66, 17280, 540, 17280, 17280, 17280, 540, 17280, 66, 540, 540, 540, 17280, 66, 66, 17280, 66, 17280, 66, 66, 540, 66, 540, 17280, 66, 66, 540, 66, 66, 66, 66, 66, 17280, 540, 540, 17280, 540, 66, 17280, 17280, 17280, 540, 540, 66, 66, 66, 17280, 66, 540, 540, 66, 17280, 17280, 17280, 66, 66, 17280, 540, 17280, 17280, 66, 17280, 66, 540, 66, 66, 540, 540, 17280, 17280, 17280, 66, 17280, 540, 540, 66, 66, 66, 66, 17280, 540, 17280, 540, 17280, 17280, 17280, 66, 540, 540, 17280, 540, 17280, 66, 66, 66, 540, 540, 540, 17280, 17280, 540, 17280, 66, 540, 540, 66, 17280, 17280, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 540, 17280, 66, 17280, 66, 17280, 540, 66, 540, 66, 66, 540, 540, 540, 17280, 540, 66, 66]
Prompts retrieved: 965238 . Total input tokens: 215208942 . Total output tokens: 189862100
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.028405516874045,
    "estimated_duration": 3600.0938699535645,
    "input_throughput": 4713.16932639283,
    "output_throughput": 4117.712352925733,
    "total_throughput": 8830.881679318563,
    "itl": 83.56894706697274,
    "ttft": 2004215.473810578,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 984,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.391494121444433,
    "arrivals": 321998,
    "finished_requests": 68409,
    "scheduler_time": 115.24334639687207
}
#Debug simulation 
Total elapsed time: 5.028512343764305. Arrivals time: 0.23811632161960006 Scheduler time: 4.604029098525643 Scheduler overhead time: 0.058157903142273426 Adapter cache time: 0.03951553022488952 Engine time: 0.06070398399606347 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_8-16-16/adapters_160_slots_96_rate_1.6-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_8-16-16/adapters_160_slots_96_rate_1.6-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 540, 66, 66, 66, 17280, 66, 540, 17280, 540, 66, 540, 540, 540, 540, 17280, 17280, 17280, 540, 540, 540, 17280, 17280, 66, 17280, 540, 17280, 17280, 17280, 540, 17280, 66, 540, 540, 540, 17280, 66, 66, 17280, 66, 17280, 66, 66, 540, 66, 540, 17280, 66, 66, 540, 66, 66, 66, 66, 66, 17280, 540, 540, 17280, 540, 66, 17280, 17280, 17280, 540, 540, 66, 66, 66, 17280, 66, 540, 540, 66, 17280, 17280, 17280, 66, 66, 17280, 540, 17280, 17280, 66, 17280, 66, 540, 66, 66, 540, 540, 17280, 17280, 17280, 66, 17280, 540, 540, 66, 66, 66, 66, 17280, 540, 17280, 540, 17280, 17280, 17280, 66, 540, 540, 17280, 540, 17280, 66, 66, 66, 540, 540, 540, 17280, 17280, 540, 17280, 66, 540, 540, 66, 17280, 17280, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 540, 17280, 66, 17280, 66, 17280, 540, 66, 540, 66, 66, 540, 540, 540, 17280, 540, 66, 66]
Prompts retrieved: 965238 . Total input tokens: 215208942 . Total output tokens: 189862100
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 5.451951866038144,
    "estimated_duration": 3600.098133355561,
    "input_throughput": 5189.810196252977,
    "output_throughput": 4529.92123989675,
    "total_throughput": 9719.731436149728,
    "itl": 106.2963773098085,
    "ttft": 1934223.5656000606,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1063,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.295585057032284,
    "arrivals": 321998,
    "finished_requests": 75338,
    "scheduler_time": 109.45829259902523
}
#Debug simulation 
Total elapsed time: 5.4520569001324475. Arrivals time: 0.2538761021569371 Scheduler time: 5.042285340372473 Scheduler overhead time: 0.04811239754781127 Adapter cache time: 0.03433538228273392 Engine time: 0.05035329842939973 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_8-16-32/adapters_160_slots_96_rate_1.6-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_8-16-32/adapters_160_slots_96_rate_1.6-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 540, 66, 66, 66, 17280, 66, 540, 17280, 540, 66, 540, 540, 540, 540, 17280, 17280, 17280, 540, 540, 540, 17280, 17280, 66, 17280, 540, 17280, 17280, 17280, 540, 17280, 66, 540, 540, 540, 17280, 66, 66, 17280, 66, 17280, 66, 66, 540, 66, 540, 17280, 66, 66, 540, 66, 66, 66, 66, 66, 17280, 540, 540, 17280, 540, 66, 17280, 17280, 17280, 540, 540, 66, 66, 66, 17280, 66, 540, 540, 66, 17280, 17280, 17280, 66, 66, 17280, 540, 17280, 17280, 66, 17280, 66, 540, 66, 66, 540, 540, 17280, 17280, 17280, 66, 17280, 540, 540, 66, 66, 66, 66, 17280, 540, 17280, 540, 17280, 17280, 17280, 66, 540, 540, 17280, 540, 17280, 66, 66, 66, 540, 540, 540, 17280, 17280, 540, 17280, 66, 540, 540, 66, 17280, 17280, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 540, 17280, 66, 17280, 66, 17280, 540, 66, 540, 66, 66, 540, 540, 540, 17280, 540, 66, 66]
Prompts retrieved: 965238 . Total input tokens: 215208942 . Total output tokens: 189862100
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 5.014711011201143,
    "estimated_duration": 3600.0530039577775,
    "input_throughput": 4713.433380382256,
    "output_throughput": 4117.9274259857175,
    "total_throughput": 8831.360806367973,
    "itl": 83.56762259021757,
    "ttft": 2004196.2647125698,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 982,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.310980401751607,
    "arrivals": 321998,
    "finished_requests": 68413,
    "scheduler_time": 115.24408145141922
}
#Debug simulation 
Total elapsed time: 5.014801258221269. Arrivals time: 0.230514841619879 Scheduler time: 4.600126266013831 Scheduler overhead time: 0.058009393978863955 Adapter cache time: 0.037591805681586266 Engine time: 0.06061665806919336 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_16-16-16/adapters_160_slots_96_rate_1.6-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_16-16-16/adapters_160_slots_96_rate_1.6-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 540, 66, 66, 66, 17280, 66, 540, 17280, 540, 66, 540, 540, 540, 540, 17280, 17280, 17280, 540, 540, 540, 17280, 17280, 66, 17280, 540, 17280, 17280, 17280, 540, 17280, 66, 540, 540, 540, 17280, 66, 66, 17280, 66, 17280, 66, 66, 540, 66, 540, 17280, 66, 66, 540, 66, 66, 66, 66, 66, 17280, 540, 540, 17280, 540, 66, 17280, 17280, 17280, 540, 540, 66, 66, 66, 17280, 66, 540, 540, 66, 17280, 17280, 17280, 66, 66, 17280, 540, 17280, 17280, 66, 17280, 66, 540, 66, 66, 540, 540, 17280, 17280, 17280, 66, 17280, 540, 540, 66, 66, 66, 66, 17280, 540, 17280, 540, 17280, 17280, 17280, 66, 540, 540, 17280, 540, 17280, 66, 66, 66, 540, 540, 540, 17280, 17280, 540, 17280, 66, 540, 540, 66, 17280, 17280, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 540, 17280, 66, 17280, 66, 17280, 540, 66, 540, 66, 66, 540, 540, 540, 17280, 540, 66, 66]
Prompts retrieved: 965238 . Total input tokens: 215208942 . Total output tokens: 189862100
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.433643538039178,
    "estimated_duration": 3600.067979376962,
    "input_throughput": 5191.508912349624,
    "output_throughput": 4531.08249439863,
    "total_throughput": 9722.591406748254,
    "itl": 106.27648908154201,
    "ttft": 1934031.869485468,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1062,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.779724038885872,
    "arrivals": 321998,
    "finished_requests": 75356,
    "scheduler_time": 109.47484462006071
}
#Debug simulation 
Total elapsed time: 5.433733559213579. Arrivals time: 0.25018179416656494 Scheduler time: 5.02868089126423 Scheduler overhead time: 0.0479169525206089 Adapter cache time: 0.033918135799467564 Engine time: 0.050063855946063995 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_16-16-32/adapters_160_slots_96_rate_1.6-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_16-16-32/adapters_160_slots_96_rate_1.6-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 540, 66, 66, 66, 17280, 66, 540, 17280, 540, 66, 540, 540, 540, 540, 17280, 17280, 17280, 540, 540, 540, 17280, 17280, 66, 17280, 540, 17280, 17280, 17280, 540, 17280, 66, 540, 540, 540, 17280, 66, 66, 17280, 66, 17280, 66, 66, 540, 66, 540, 17280, 66, 66, 540, 66, 66, 66, 66, 66, 17280, 540, 540, 17280, 540, 66, 17280, 17280, 17280, 540, 540, 66, 66, 66, 17280, 66, 540, 540, 66, 17280, 17280, 17280, 66, 66, 17280, 540, 17280, 17280, 66, 17280, 66, 540, 66, 66, 540, 540, 17280, 17280, 17280, 66, 17280, 540, 540, 66, 66, 66, 66, 17280, 540, 17280, 540, 17280, 17280, 17280, 66, 540, 540, 17280, 540, 17280, 66, 66, 66, 540, 540, 540, 17280, 17280, 540, 17280, 66, 540, 540, 66, 17280, 17280, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 540, 17280, 66, 17280, 66, 17280, 540, 66, 540, 66, 66, 540, 540, 540, 17280, 540, 66, 66]
Prompts retrieved: 965238 . Total input tokens: 215208942 . Total output tokens: 189862100
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.078449917025864,
    "estimated_duration": 3600.0290938685707,
    "input_throughput": 4713.545240203966,
    "output_throughput": 4117.882831905027,
    "total_throughput": 8831.428072108994,
    "itl": 83.56548928328415,
    "ttft": 2004272.7926970178,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 981,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.234400411900157,
    "arrivals": 321998,
    "finished_requests": 68412,
    "scheduler_time": 115.24701710959526
}
#Debug simulation 
Total elapsed time: 5.0785560556687415. Arrivals time: 0.23680852446705103 Scheduler time: 4.655990437604487 Scheduler overhead time: 0.05884715635329485 Adapter cache time: 0.03755370061844587 Engine time: 0.06121022766456008 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-8/adapters_160_slots_96_rate_1.6-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-8/adapters_160_slots_96_rate_1.6-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 540, 33, 33, 33, 17280, 33, 540, 17280, 540, 33, 540, 540, 540, 540, 17280, 17280, 17280, 540, 540, 540, 17280, 17280, 33, 17280, 540, 17280, 17280, 17280, 540, 17280, 33, 540, 540, 540, 17280, 33, 33, 17280, 33, 17280, 33, 33, 540, 33, 540, 17280, 33, 33, 540, 33, 33, 33, 33, 33, 17280, 540, 540, 17280, 540, 33, 17280, 17280, 17280, 540, 540, 33, 33, 33, 17280, 33, 540, 540, 33, 17280, 17280, 17280, 33, 33, 17280, 540, 17280, 17280, 33, 17280, 33, 540, 33, 33, 540, 540, 17280, 17280, 17280, 33, 17280, 540, 540, 33, 33, 33, 33, 17280, 540, 17280, 540, 17280, 17280, 17280, 33, 540, 540, 17280, 540, 17280, 33, 33, 33, 540, 540, 540, 17280, 17280, 540, 17280, 33, 540, 540, 33, 17280, 17280, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 540, 17280, 33, 17280, 33, 17280, 540, 33, 540, 33, 33, 540, 540, 540, 17280, 540, 33, 33]
Prompts retrieved: 963489 . Total input tokens: 214807685 . Total output tokens: 189517768
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.639901251997799,
    "estimated_duration": 3600.0182109001435,
    "input_throughput": 5392.684942875833,
    "output_throughput": 4690.675716270257,
    "total_throughput": 10083.36065914609,
    "itl": 117.00321822124947,
    "ttft": 1908186.8097921184,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 848,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.60732285909366,
    "arrivals": 321377,
    "finished_requests": 78169,
    "scheduler_time": 107.87954167169164
}
#Debug simulation 
Total elapsed time: 5.639998458791524. Arrivals time: 0.2601707982830703 Scheduler time: 5.236504787579179 Scheduler overhead time: 0.04447914520278573 Adapter cache time: 0.030992061365395784 Engine time: 0.04657132085412741 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-16/adapters_160_slots_96_rate_1.6-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-16/adapters_160_slots_96_rate_1.6-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 540, 33, 33, 33, 17280, 33, 540, 17280, 540, 33, 540, 540, 540, 540, 17280, 17280, 17280, 540, 540, 540, 17280, 17280, 33, 17280, 540, 17280, 17280, 17280, 540, 17280, 33, 540, 540, 540, 17280, 33, 33, 17280, 33, 17280, 33, 33, 540, 33, 540, 17280, 33, 33, 540, 33, 33, 33, 33, 33, 17280, 540, 540, 17280, 540, 33, 17280, 17280, 17280, 540, 540, 33, 33, 33, 17280, 33, 540, 540, 33, 17280, 17280, 17280, 33, 33, 17280, 540, 17280, 17280, 33, 17280, 33, 540, 33, 33, 540, 540, 17280, 17280, 17280, 33, 17280, 540, 540, 33, 33, 33, 33, 17280, 540, 17280, 540, 17280, 17280, 17280, 33, 540, 540, 17280, 540, 17280, 33, 33, 33, 540, 540, 540, 17280, 17280, 540, 17280, 33, 540, 540, 33, 17280, 17280, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 540, 17280, 33, 17280, 33, 17280, 540, 33, 540, 33, 33, 540, 540, 540, 17280, 540, 33, 33]
Prompts retrieved: 963489 . Total input tokens: 214807685 . Total output tokens: 189517768
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.451502103358507,
    "estimated_duration": 3600.0263510600143,
    "input_throughput": 5237.940826307482,
    "output_throughput": 4559.22468322132,
    "total_throughput": 9797.165509528802,
    "itl": 105.82131667024844,
    "ttft": 1930769.30341443,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 831,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.064395174016253,
    "arrivals": 321377,
    "finished_requests": 75973,
    "scheduler_time": 110.10839910195799
}
#Debug simulation 
Total elapsed time: 5.451592653058469. Arrivals time: 0.2475761086679995 Scheduler time: 5.051526225171983 Scheduler overhead time: 0.04784758202731609 Adapter cache time: 0.031787107698619366 Engine time: 0.0498408954590559 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-32/adapters_160_slots_96_rate_1.6-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-32/adapters_160_slots_96_rate_1.6-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 540, 33, 33, 33, 17280, 33, 540, 17280, 540, 33, 540, 540, 540, 540, 17280, 17280, 17280, 540, 540, 540, 17280, 17280, 33, 17280, 540, 17280, 17280, 17280, 540, 17280, 33, 540, 540, 540, 17280, 33, 33, 17280, 33, 17280, 33, 33, 540, 33, 540, 17280, 33, 33, 540, 33, 33, 33, 33, 33, 17280, 540, 540, 17280, 540, 33, 17280, 17280, 17280, 540, 540, 33, 33, 33, 17280, 33, 540, 540, 33, 17280, 17280, 17280, 33, 33, 17280, 540, 17280, 17280, 33, 17280, 33, 540, 33, 33, 540, 540, 17280, 17280, 17280, 33, 17280, 540, 540, 33, 33, 33, 33, 17280, 540, 17280, 540, 17280, 17280, 17280, 33, 540, 540, 17280, 540, 17280, 33, 33, 33, 540, 540, 540, 17280, 17280, 540, 17280, 33, 540, 540, 33, 17280, 17280, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 540, 17280, 33, 17280, 33, 17280, 540, 33, 540, 33, 33, 540, 540, 540, 17280, 540, 33, 33]
Prompts retrieved: 963489 . Total input tokens: 214807685 . Total output tokens: 189517768
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.0469080451875925,
    "estimated_duration": 3600.0223803240715,
    "input_throughput": 4748.661034285318,
    "output_throughput": 4135.523734899613,
    "total_throughput": 8884.184769184933,
    "itl": 83.15885968908339,
    "ttft": 2002138.4162493446,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 762,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.713095860928324,
    "arrivals": 321377,
    "finished_requests": 68877,
    "scheduler_time": 115.84487491725024
}
#Debug simulation 
Total elapsed time: 5.046995235141367. Arrivals time: 0.2649404867552221 Scheduler time: 4.600813925731927 Scheduler overhead time: 0.05815394315868616 Adapter cache time: 0.034437368623912334 Engine time: 0.06072614528238773 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_8-16-16/adapters_160_slots_96_rate_1.6-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_8-16-16/adapters_160_slots_96_rate_1.6-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 540, 33, 33, 33, 17280, 33, 540, 17280, 540, 33, 540, 540, 540, 540, 17280, 17280, 17280, 540, 540, 540, 17280, 17280, 33, 17280, 540, 17280, 17280, 17280, 540, 17280, 33, 540, 540, 540, 17280, 33, 33, 17280, 33, 17280, 33, 33, 540, 33, 540, 17280, 33, 33, 540, 33, 33, 33, 33, 33, 17280, 540, 540, 17280, 540, 33, 17280, 17280, 17280, 540, 540, 33, 33, 33, 17280, 33, 540, 540, 33, 17280, 17280, 17280, 33, 33, 17280, 540, 17280, 17280, 33, 17280, 33, 540, 33, 33, 540, 540, 17280, 17280, 17280, 33, 17280, 540, 540, 33, 33, 33, 33, 17280, 540, 17280, 540, 17280, 17280, 17280, 33, 540, 540, 17280, 540, 17280, 33, 33, 33, 540, 540, 540, 17280, 17280, 540, 17280, 33, 540, 540, 33, 17280, 17280, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 540, 17280, 33, 17280, 33, 17280, 540, 33, 540, 33, 33, 540, 540, 540, 17280, 540, 33, 33]
Prompts retrieved: 963489 . Total input tokens: 214807685 . Total output tokens: 189517768
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 5.730062278918922,
    "estimated_duration": 3600.1045170822135,
    "input_throughput": 5238.144590114231,
    "output_throughput": 4559.7042869478255,
    "total_throughput": 9797.848877062055,
    "itl": 105.81022777550193,
    "ttft": 1930606.8432766309,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 829,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.6670901225274335,
    "arrivals": 321377,
    "finished_requests": 75982,
    "scheduler_time": 110.12270214664117
}
#Debug simulation 
Total elapsed time: 5.730143030639738. Arrivals time: 0.5171021977439523 Scheduler time: 5.060082238167524 Scheduler overhead time: 0.048022393602877855 Adapter cache time: 0.03173982724547386 Engine time: 0.05004323413595557 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_8-16-32/adapters_160_slots_96_rate_1.6-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_8-16-32/adapters_160_slots_96_rate_1.6-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 540, 33, 33, 33, 17280, 33, 540, 17280, 540, 33, 540, 540, 540, 540, 17280, 17280, 17280, 540, 540, 540, 17280, 17280, 33, 17280, 540, 17280, 17280, 17280, 540, 17280, 33, 540, 540, 540, 17280, 33, 33, 17280, 33, 17280, 33, 33, 540, 33, 540, 17280, 33, 33, 540, 33, 33, 33, 33, 33, 17280, 540, 540, 17280, 540, 33, 17280, 17280, 17280, 540, 540, 33, 33, 33, 17280, 33, 540, 540, 33, 17280, 17280, 17280, 33, 33, 17280, 540, 17280, 17280, 33, 17280, 33, 540, 33, 33, 540, 540, 17280, 17280, 17280, 33, 17280, 540, 540, 33, 33, 33, 33, 17280, 540, 17280, 540, 17280, 17280, 17280, 33, 540, 540, 17280, 540, 17280, 33, 33, 33, 540, 540, 540, 17280, 17280, 540, 17280, 33, 540, 540, 33, 17280, 17280, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 540, 17280, 33, 17280, 33, 17280, 540, 33, 540, 33, 33, 540, 540, 540, 17280, 540, 33, 33]
Prompts retrieved: 963489 . Total input tokens: 214807685 . Total output tokens: 189517768
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 5.101936561986804,
    "estimated_duration": 3600.0326037143486,
    "input_throughput": 4753.083619949828,
    "output_throughput": 4139.680564177053,
    "total_throughput": 8892.764184126881,
    "itl": 83.29345921134794,
    "ttft": 2001945.841463996,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 765,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.68362886332444,
    "arrivals": 321377,
    "finished_requests": 68943,
    "scheduler_time": 115.8030302138961
}
#Debug simulation 
Total elapsed time: 5.102024903986603. Arrivals time: 0.2649208358488977 Scheduler time: 4.654410965740681 Scheduler overhead time: 0.058507985435426235 Adapter cache time: 0.035077267326414585 Engine time: 0.06103121256455779 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_16-16-16/adapters_160_slots_96_rate_1.6-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_16-16-16/adapters_160_slots_96_rate_1.6-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 540, 33, 33, 33, 17280, 33, 540, 17280, 540, 33, 540, 540, 540, 540, 17280, 17280, 17280, 540, 540, 540, 17280, 17280, 33, 17280, 540, 17280, 17280, 17280, 540, 17280, 33, 540, 540, 540, 17280, 33, 33, 17280, 33, 17280, 33, 33, 540, 33, 540, 17280, 33, 33, 540, 33, 33, 33, 33, 33, 17280, 540, 540, 17280, 540, 33, 17280, 17280, 17280, 540, 540, 33, 33, 33, 17280, 33, 540, 540, 33, 17280, 17280, 17280, 33, 33, 17280, 540, 17280, 17280, 33, 17280, 33, 540, 33, 33, 540, 540, 17280, 17280, 17280, 33, 17280, 540, 540, 33, 33, 33, 33, 17280, 540, 17280, 540, 17280, 17280, 17280, 33, 540, 540, 17280, 540, 17280, 33, 33, 33, 540, 540, 540, 17280, 17280, 540, 17280, 33, 540, 540, 33, 17280, 17280, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 540, 17280, 33, 17280, 33, 17280, 540, 33, 540, 33, 33, 540, 540, 540, 17280, 540, 33, 33]
Prompts retrieved: 963489 . Total input tokens: 214807685 . Total output tokens: 189517768
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.474331384059042,
    "estimated_duration": 3600.0861536514067,
    "input_throughput": 5238.355471263551,
    "output_throughput": 4559.956706410969,
    "total_throughput": 9798.31217767452,
    "itl": 105.7978426070987,
    "ttft": 1930527.872463898,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 830,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.298654380673517,
    "arrivals": 321377,
    "finished_requests": 75985,
    "scheduler_time": 110.13249820175005
}
#Debug simulation 
Total elapsed time: 5.474423965904862. Arrivals time: 0.2542475345544517 Scheduler time: 5.067307967226952 Scheduler overhead time: 0.04799575684592128 Adapter cache time: 0.03178391372784972 Engine time: 0.050027914345264435 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_16-16-32/adapters_160_slots_96_rate_1.6-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_16-16-32/adapters_160_slots_96_rate_1.6-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 540, 33, 33, 33, 17280, 33, 540, 17280, 540, 33, 540, 540, 540, 540, 17280, 17280, 17280, 540, 540, 540, 17280, 17280, 33, 17280, 540, 17280, 17280, 17280, 540, 17280, 33, 540, 540, 540, 17280, 33, 33, 17280, 33, 17280, 33, 33, 540, 33, 540, 17280, 33, 33, 540, 33, 33, 33, 33, 33, 17280, 540, 540, 17280, 540, 33, 17280, 17280, 17280, 540, 540, 33, 33, 33, 17280, 33, 540, 540, 33, 17280, 17280, 17280, 33, 33, 17280, 540, 17280, 17280, 33, 17280, 33, 540, 33, 33, 540, 540, 17280, 17280, 17280, 33, 17280, 540, 540, 33, 33, 33, 33, 17280, 540, 17280, 540, 17280, 17280, 17280, 33, 540, 540, 17280, 540, 17280, 33, 33, 33, 540, 540, 540, 17280, 17280, 540, 17280, 33, 540, 540, 33, 17280, 17280, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 540, 17280, 33, 17280, 33, 17280, 540, 33, 540, 33, 33, 540, 540, 540, 17280, 540, 33, 33]
Prompts retrieved: 963489 . Total input tokens: 214807685 . Total output tokens: 189517768
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.059056913014501,
    "estimated_duration": 3600.078058659234,
    "input_throughput": 4752.569450222444,
    "output_throughput": 4139.044419928353,
    "total_throughput": 8891.613870150797,
    "itl": 83.26086512115424,
    "ttft": 2001954.0966799539,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 766,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.637181250266759,
    "arrivals": 321377,
    "finished_requests": 68935,
    "scheduler_time": 115.81677217521651
}
#Debug simulation 
Total elapsed time: 5.059147743042558. Arrivals time: 0.238025339320302 Scheduler time: 4.639798265416175 Scheduler overhead time: 0.058056344743818045 Adapter cache time: 0.03448684327304363 Engine time: 0.06087926495820284 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-8/adapters_160_slots_96_rate_1.6-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-8/adapters_160_slots_96_rate_1.6-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [53 53 54]
Adapter prompts. [135, 17280, 135, 135, 270, 135, 135, 135, 17280, 135, 270, 17280, 270, 135, 270, 270, 270, 270, 17280, 17280, 17280, 270, 270, 270, 17280, 17280, 135, 17280, 270, 17280, 17280, 17280, 270, 17280, 135, 270, 270, 270, 17280, 135, 135, 17280, 135, 17280, 135, 135, 270, 135, 270, 17280, 135, 135, 270, 135, 135, 135, 135, 135, 17280, 270, 270, 17280, 270, 135, 17280, 17280, 17280, 270, 270, 135, 135, 135, 17280, 135, 270, 270, 135, 17280, 17280, 17280, 135, 135, 17280, 270, 17280, 17280, 135, 17280, 135, 270, 135, 135, 270, 270, 17280, 17280, 17280, 135, 17280, 270, 270, 135, 135, 135, 135, 17280, 270, 17280, 270, 17280, 17280, 17280, 135, 270, 270, 17280, 270, 17280, 135, 135, 135, 270, 270, 270, 17280, 17280, 270, 17280, 135, 270, 270, 135, 17280, 17280, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 270, 17280, 135, 17280, 135, 17280, 270, 135, 270, 135, 135, 270, 270, 270, 17280, 270, 135, 135]
Prompts retrieved: 954585 . Total input tokens: 212848812 . Total output tokens: 187739450
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.634263608139008,
    "estimated_duration": 3600.1177535387355,
    "input_throughput": 5441.1692452962525,
    "output_throughput": 4769.21344673324,
    "total_throughput": 10210.382692029492,
    "itl": 115.14452138154118,
    "ttft": 1892140.8277564438,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1064,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.035603209994893,
    "arrivals": 318402,
    "finished_requests": 79159,
    "scheduler_time": 109.63360777287393
}
#Debug simulation 
Total elapsed time: 5.634351429063827. Arrivals time: 0.2527750264853239 Scheduler time: 5.237811639904976 Scheduler overhead time: 0.04481240035966039 Adapter cache time: 0.028390302788466215 Engine time: 0.04655814915895462 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-16/adapters_160_slots_96_rate_1.6-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-16/adapters_160_slots_96_rate_1.6-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [53 53 54]
Adapter prompts. [135, 17280, 135, 135, 270, 135, 135, 135, 17280, 135, 270, 17280, 270, 135, 270, 270, 270, 270, 17280, 17280, 17280, 270, 270, 270, 17280, 17280, 135, 17280, 270, 17280, 17280, 17280, 270, 17280, 135, 270, 270, 270, 17280, 135, 135, 17280, 135, 17280, 135, 135, 270, 135, 270, 17280, 135, 135, 270, 135, 135, 135, 135, 135, 17280, 270, 270, 17280, 270, 135, 17280, 17280, 17280, 270, 270, 135, 135, 135, 17280, 135, 270, 270, 135, 17280, 17280, 17280, 135, 135, 17280, 270, 17280, 17280, 135, 17280, 135, 270, 135, 135, 270, 270, 17280, 17280, 17280, 135, 17280, 270, 270, 135, 135, 135, 135, 17280, 270, 17280, 270, 17280, 17280, 17280, 135, 270, 270, 17280, 270, 17280, 135, 135, 135, 270, 270, 270, 17280, 17280, 270, 17280, 135, 270, 270, 135, 17280, 17280, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 270, 17280, 135, 17280, 135, 17280, 270, 135, 270, 135, 135, 270, 270, 270, 17280, 270, 135, 135]
Prompts retrieved: 954585 . Total input tokens: 212848812 . Total output tokens: 187739450
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.548543062061071,
    "estimated_duration": 3600.090875654736,
    "input_throughput": 5286.296278990144,
    "output_throughput": 4628.563437851972,
    "total_throughput": 9914.859716842117,
    "itl": 104.31157850940862,
    "ttft": 1916361.135722219,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1031,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.539694961314101,
    "arrivals": 318402,
    "finished_requests": 76842,
    "scheduler_time": 111.69834926408377
}
#Debug simulation 
Total elapsed time: 5.548633803147823. Arrivals time: 0.252460396848619 Scheduler time: 5.143579933326691 Scheduler overhead time: 0.04893360333517194 Adapter cache time: 0.028980956878513098 Engine time: 0.05115652130916715 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-32/adapters_160_slots_96_rate_1.6-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-32/adapters_160_slots_96_rate_1.6-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [53 53 54]
Adapter prompts. [135, 17280, 135, 135, 270, 135, 135, 135, 17280, 135, 270, 17280, 270, 135, 270, 270, 270, 270, 17280, 17280, 17280, 270, 270, 270, 17280, 17280, 135, 17280, 270, 17280, 17280, 17280, 270, 17280, 135, 270, 270, 270, 17280, 135, 135, 17280, 135, 17280, 135, 135, 270, 135, 270, 17280, 135, 135, 270, 135, 135, 135, 135, 135, 17280, 270, 270, 17280, 270, 135, 17280, 17280, 17280, 270, 270, 135, 135, 135, 17280, 135, 270, 270, 135, 17280, 17280, 17280, 135, 135, 17280, 270, 17280, 17280, 135, 17280, 135, 270, 135, 135, 270, 270, 17280, 17280, 17280, 135, 17280, 270, 270, 135, 135, 135, 135, 17280, 270, 17280, 270, 17280, 17280, 17280, 135, 270, 270, 17280, 270, 17280, 135, 135, 135, 270, 270, 270, 17280, 17280, 270, 17280, 135, 270, 270, 135, 17280, 17280, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 270, 17280, 135, 17280, 135, 17280, 270, 135, 270, 135, 135, 270, 270, 270, 17280, 270, 135, 135]
Prompts retrieved: 954585 . Total input tokens: 212848812 . Total output tokens: 187739450
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.086628200951964,
    "estimated_duration": 3600.016572739261,
    "input_throughput": 4789.724616984108,
    "output_throughput": 4192.186812216953,
    "total_throughput": 8981.91142920106,
    "itl": 82.22189006432093,
    "ttft": 1990059.3587187557,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 947,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.102932244986316,
    "arrivals": 318402,
    "finished_requests": 69470,
    "scheduler_time": 117.21362316070606
}
#Debug simulation 
Total elapsed time: 5.086717294063419. Arrivals time: 0.23657527100294828 Scheduler time: 4.670313350390643 Scheduler overhead time: 0.059001412242650986 Adapter cache time: 0.031187493819743395 Engine time: 0.06138433050364256 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-16-16/adapters_160_slots_96_rate_1.6-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-16-16/adapters_160_slots_96_rate_1.6-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [53 53 54]
Adapter prompts. [135, 17280, 135, 135, 270, 135, 135, 135, 17280, 135, 270, 17280, 270, 135, 270, 270, 270, 270, 17280, 17280, 17280, 270, 270, 270, 17280, 17280, 135, 17280, 270, 17280, 17280, 17280, 270, 17280, 135, 270, 270, 270, 17280, 135, 135, 17280, 135, 17280, 135, 135, 270, 135, 270, 17280, 135, 135, 270, 135, 135, 135, 135, 135, 17280, 270, 270, 17280, 270, 135, 17280, 17280, 17280, 270, 270, 135, 135, 135, 17280, 135, 270, 270, 135, 17280, 17280, 17280, 135, 135, 17280, 270, 17280, 17280, 135, 17280, 135, 270, 135, 135, 270, 270, 17280, 17280, 17280, 135, 17280, 270, 270, 135, 135, 135, 135, 17280, 270, 17280, 270, 17280, 17280, 17280, 135, 270, 270, 17280, 270, 17280, 135, 135, 135, 270, 270, 270, 17280, 17280, 270, 17280, 135, 270, 270, 135, 17280, 17280, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 270, 17280, 135, 17280, 135, 17280, 270, 135, 270, 135, 135, 270, 270, 270, 17280, 270, 135, 135]
Prompts retrieved: 954585 . Total input tokens: 212848812 . Total output tokens: 187739450
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 5.582108996342868,
    "estimated_duration": 3600.0634735629724,
    "input_throughput": 5286.750675305026,
    "output_throughput": 4629.040882856117,
    "total_throughput": 9915.791558161141,
    "itl": 104.29990361281179,
    "ttft": 1916233.135305164,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1030,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.077974561126894,
    "arrivals": 318402,
    "finished_requests": 76847,
    "scheduler_time": 111.70963120910959
}
#Debug simulation 
Total elapsed time: 5.582200984004885. Arrivals time: 0.25640412513166666 Scheduler time: 5.172459574881941 Scheduler overhead time: 0.04911812720820308 Adapter cache time: 0.029165703803300858 Engine time: 0.051484542433172464 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-16-32/adapters_160_slots_96_rate_1.6-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-16-32/adapters_160_slots_96_rate_1.6-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [53 53 54]
Adapter prompts. [135, 17280, 135, 135, 270, 135, 135, 135, 17280, 135, 270, 17280, 270, 135, 270, 270, 270, 270, 17280, 17280, 17280, 270, 270, 270, 17280, 17280, 135, 17280, 270, 17280, 17280, 17280, 270, 17280, 135, 270, 270, 270, 17280, 135, 135, 17280, 135, 17280, 135, 135, 270, 135, 270, 17280, 135, 135, 270, 135, 135, 135, 135, 135, 17280, 270, 270, 17280, 270, 135, 17280, 17280, 17280, 270, 270, 135, 135, 135, 17280, 135, 270, 270, 135, 17280, 17280, 17280, 135, 135, 17280, 270, 17280, 17280, 135, 17280, 135, 270, 135, 135, 270, 270, 17280, 17280, 17280, 135, 17280, 270, 270, 135, 135, 135, 135, 17280, 270, 17280, 270, 17280, 17280, 17280, 135, 270, 270, 17280, 270, 17280, 135, 135, 135, 270, 270, 270, 17280, 17280, 270, 17280, 135, 270, 270, 135, 17280, 17280, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 270, 17280, 135, 17280, 135, 17280, 270, 135, 270, 135, 135, 270, 270, 270, 17280, 270, 135, 135]
Prompts retrieved: 954585 . Total input tokens: 212848812 . Total output tokens: 187739450
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 5.074733414687216,
    "estimated_duration": 3600.069433548192,
    "input_throughput": 4784.617718615293,
    "output_throughput": 4187.886172278787,
    "total_throughput": 8972.50389089408,
    "itl": 82.0342307735111,
    "ttft": 1990711.329583755,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 947,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.041625560708364,
    "arrivals": 318402,
    "finished_requests": 69400,
    "scheduler_time": 117.28188119422856
}
#Debug simulation 
Total elapsed time: 5.074849086813629. Arrivals time: 0.2345328340306878 Scheduler time: 4.660199738107622 Scheduler overhead time: 0.05921458313241601 Adapter cache time: 0.03102418128401041 Engine time: 0.061493104323744774 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_16-16-16/adapters_160_slots_96_rate_1.6-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_16-16-16/adapters_160_slots_96_rate_1.6-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [53 53 54]
Adapter prompts. [135, 17280, 135, 135, 270, 135, 135, 135, 17280, 135, 270, 17280, 270, 135, 270, 270, 270, 270, 17280, 17280, 17280, 270, 270, 270, 17280, 17280, 135, 17280, 270, 17280, 17280, 17280, 270, 17280, 135, 270, 270, 270, 17280, 135, 135, 17280, 135, 17280, 135, 135, 270, 135, 270, 17280, 135, 135, 270, 135, 135, 135, 135, 135, 17280, 270, 270, 17280, 270, 135, 17280, 17280, 17280, 270, 270, 135, 135, 135, 17280, 135, 270, 270, 135, 17280, 17280, 17280, 135, 135, 17280, 270, 17280, 17280, 135, 17280, 135, 270, 135, 135, 270, 270, 17280, 17280, 17280, 135, 17280, 270, 270, 135, 135, 135, 135, 17280, 270, 17280, 270, 17280, 17280, 17280, 135, 270, 270, 17280, 270, 17280, 135, 135, 135, 270, 270, 270, 17280, 17280, 270, 17280, 135, 270, 270, 135, 17280, 17280, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 270, 17280, 135, 17280, 135, 17280, 270, 135, 270, 135, 135, 270, 270, 270, 17280, 270, 135, 135]
Prompts retrieved: 954585 . Total input tokens: 212848812 . Total output tokens: 187739450
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.580998538993299,
    "estimated_duration": 3600.018119632734,
    "input_throughput": 5287.094222165129,
    "output_throughput": 4629.449198911321,
    "total_throughput": 9916.54342107645,
    "itl": 104.28378181394241,
    "ttft": 1916134.6550428898,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1031,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.581822489728187,
    "arrivals": 318402,
    "finished_requests": 76854,
    "scheduler_time": 111.72215626135333
}
#Debug simulation 
Total elapsed time: 5.581120429094881. Arrivals time: 0.251987686380744 Scheduler time: 5.17464246833697 Scheduler overhead time: 0.049391512759029865 Adapter cache time: 0.029893628787249327 Engine time: 0.05139481369405985 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_16-16-32/adapters_160_slots_96_rate_1.6-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_16-16-32/adapters_160_slots_96_rate_1.6-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [53 53 54]
Adapter prompts. [135, 17280, 135, 135, 270, 135, 135, 135, 17280, 135, 270, 17280, 270, 135, 270, 270, 270, 270, 17280, 17280, 17280, 270, 270, 270, 17280, 17280, 135, 17280, 270, 17280, 17280, 17280, 270, 17280, 135, 270, 270, 270, 17280, 135, 135, 17280, 135, 17280, 135, 135, 270, 135, 270, 17280, 135, 135, 270, 135, 135, 135, 135, 135, 17280, 270, 270, 17280, 270, 135, 17280, 17280, 17280, 270, 270, 135, 135, 135, 17280, 135, 270, 270, 135, 17280, 17280, 17280, 135, 135, 17280, 270, 17280, 17280, 135, 17280, 135, 270, 135, 135, 270, 270, 17280, 17280, 17280, 135, 17280, 270, 270, 135, 135, 135, 135, 17280, 270, 17280, 270, 17280, 17280, 17280, 135, 270, 270, 17280, 270, 17280, 135, 135, 135, 270, 270, 270, 17280, 17280, 270, 17280, 135, 270, 270, 135, 17280, 17280, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 270, 17280, 135, 17280, 135, 17280, 270, 135, 270, 135, 135, 270, 270, 270, 17280, 270, 135, 135]
Prompts retrieved: 954585 . Total input tokens: 212848812 . Total output tokens: 187739450
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.1079264329746366,
    "estimated_duration": 3600.0672325979217,
    "input_throughput": 4787.209762069694,
    "output_throughput": 4189.719531742033,
    "total_throughput": 8976.929293811727,
    "itl": 82.10593234768798,
    "ttft": 1990574.8864184539,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 948,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.9822333034873205,
    "arrivals": 318402,
    "finished_requests": 69437,
    "scheduler_time": 117.25798098654535
}
#Debug simulation 
Total elapsed time: 5.108051639981568. Arrivals time: 0.23649907065555453 Scheduler time: 4.691306084394455 Scheduler overhead time: 0.059013486839830875 Adapter cache time: 0.03134883288294077 Engine time: 0.06153349485248327 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-8/adapters_160_slots_96_rate_1.6-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-8/adapters_160_slots_96_rate_1.6-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 270, 66, 66, 66, 17280, 66, 270, 17280, 270, 66, 270, 270, 270, 270, 17280, 17280, 17280, 270, 270, 270, 17280, 17280, 66, 17280, 270, 17280, 17280, 17280, 270, 17280, 66, 270, 270, 270, 17280, 66, 66, 17280, 66, 17280, 66, 66, 270, 66, 270, 17280, 66, 66, 270, 66, 66, 66, 66, 66, 17280, 270, 270, 17280, 270, 66, 17280, 17280, 17280, 270, 270, 66, 66, 66, 17280, 66, 270, 270, 66, 17280, 17280, 17280, 66, 66, 17280, 270, 17280, 17280, 66, 17280, 66, 270, 66, 66, 270, 270, 17280, 17280, 17280, 66, 17280, 270, 270, 66, 66, 66, 66, 17280, 270, 17280, 270, 17280, 17280, 17280, 66, 270, 270, 17280, 270, 17280, 66, 66, 66, 270, 270, 270, 17280, 17280, 270, 17280, 66, 270, 270, 66, 17280, 17280, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 270, 17280, 66, 17280, 66, 17280, 270, 66, 270, 66, 66, 270, 270, 270, 17280, 270, 66, 66]
Prompts retrieved: 950928 . Total input tokens: 212056530 . Total output tokens: 187021572
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.742921250872314,
    "estimated_duration": 3600.1191226502197,
    "input_throughput": 5535.327115878923,
    "output_throughput": 4831.828172172979,
    "total_throughput": 10367.155288051903,
    "itl": 113.73477199306744,
    "ttft": 1873930.692759153,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 808,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.342826497815654,
    "arrivals": 317160,
    "finished_requests": 80696,
    "scheduler_time": 110.94954822427835
}
#Debug simulation 
Total elapsed time: 5.743012844119221. Arrivals time: 0.2624192680232227 Scheduler time: 5.340179501567036 Scheduler overhead time: 0.04563744319602847 Adapter cache time: 0.025515956338495016 Engine time: 0.04740151856094599 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-16/adapters_160_slots_96_rate_1.6-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-16/adapters_160_slots_96_rate_1.6-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 270, 66, 66, 66, 17280, 66, 270, 17280, 270, 66, 270, 270, 270, 270, 17280, 17280, 17280, 270, 270, 270, 17280, 17280, 66, 17280, 270, 17280, 17280, 17280, 270, 17280, 66, 270, 270, 270, 17280, 66, 66, 17280, 66, 17280, 66, 66, 270, 66, 270, 17280, 66, 66, 270, 66, 66, 66, 66, 66, 17280, 270, 270, 17280, 270, 66, 17280, 17280, 17280, 270, 270, 66, 66, 66, 17280, 66, 270, 270, 66, 17280, 17280, 17280, 66, 66, 17280, 270, 17280, 17280, 66, 17280, 66, 270, 66, 66, 270, 270, 17280, 17280, 17280, 66, 17280, 270, 270, 66, 66, 66, 66, 17280, 270, 17280, 270, 17280, 17280, 17280, 66, 270, 270, 17280, 270, 17280, 66, 66, 66, 270, 270, 270, 17280, 17280, 270, 17280, 66, 270, 270, 66, 17280, 17280, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 270, 17280, 66, 17280, 66, 17280, 270, 66, 270, 66, 66, 270, 270, 270, 17280, 270, 66, 66]
Prompts retrieved: 950928 . Total input tokens: 212056530 . Total output tokens: 187021572
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.599097738973796,
    "estimated_duration": 3600.003250218695,
    "input_throughput": 5359.07405051037,
    "output_throughput": 4679.514108487711,
    "total_throughput": 10038.588158998082,
    "itl": 103.01081594257494,
    "ttft": 1898030.440040859,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 781,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.702164276815028,
    "arrivals": 317160,
    "finished_requests": 78067,
    "scheduler_time": 112.94242816361441
}
#Debug simulation 
Total elapsed time: 5.599224043078721. Arrivals time: 0.28182336827740073 Scheduler time: 5.164941179100424 Scheduler overhead time: 0.0492950901389122 Adapter cache time: 0.026355518028140068 Engine time: 0.05308501794934273 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-32/adapters_160_slots_96_rate_1.6-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-32/adapters_160_slots_96_rate_1.6-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 270, 66, 66, 66, 17280, 66, 270, 17280, 270, 66, 270, 270, 270, 270, 17280, 17280, 17280, 270, 270, 270, 17280, 17280, 66, 17280, 270, 17280, 17280, 17280, 270, 17280, 66, 270, 270, 270, 17280, 66, 66, 17280, 66, 17280, 66, 66, 270, 66, 270, 17280, 66, 66, 270, 66, 66, 66, 66, 66, 17280, 270, 270, 17280, 270, 66, 17280, 17280, 17280, 270, 270, 66, 66, 66, 17280, 66, 270, 270, 66, 17280, 17280, 17280, 66, 66, 17280, 270, 17280, 17280, 66, 17280, 66, 270, 66, 66, 270, 270, 17280, 17280, 17280, 66, 17280, 270, 270, 66, 66, 66, 66, 17280, 270, 17280, 270, 17280, 17280, 17280, 66, 270, 270, 17280, 270, 17280, 66, 66, 66, 270, 270, 270, 17280, 17280, 270, 17280, 66, 270, 270, 66, 17280, 17280, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 270, 17280, 66, 17280, 66, 17280, 270, 66, 270, 66, 66, 270, 270, 270, 17280, 270, 66, 66]
Prompts retrieved: 950928 . Total input tokens: 212056530 . Total output tokens: 187021572
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.190411277115345,
    "estimated_duration": 3600.039264192811,
    "input_throughput": 4840.3774851347625,
    "output_throughput": 4228.314160738202,
    "total_throughput": 9068.691645872965,
    "itl": 81.38013011364161,
    "ttft": 1974150.0290665526,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 708,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.304328801063848,
    "arrivals": 317160,
    "finished_requests": 70504,
    "scheduler_time": 118.24574059882578
}
#Debug simulation 
Total elapsed time: 5.190520239062607. Arrivals time: 0.2742107189260423 Scheduler time: 4.738274154718965 Scheduler overhead time: 0.059451097156852484 Adapter cache time: 0.02793171862140298 Engine time: 0.0619349405169487 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-16-16/adapters_160_slots_96_rate_1.6-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-16-16/adapters_160_slots_96_rate_1.6-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 270, 66, 66, 66, 17280, 66, 270, 17280, 270, 66, 270, 270, 270, 270, 17280, 17280, 17280, 270, 270, 270, 17280, 17280, 66, 17280, 270, 17280, 17280, 17280, 270, 17280, 66, 270, 270, 270, 17280, 66, 66, 17280, 66, 17280, 66, 66, 270, 66, 270, 17280, 66, 66, 270, 66, 66, 66, 66, 66, 17280, 270, 270, 17280, 270, 66, 17280, 17280, 17280, 270, 270, 66, 66, 66, 17280, 66, 270, 270, 66, 17280, 17280, 17280, 66, 66, 17280, 270, 17280, 17280, 66, 17280, 66, 270, 66, 66, 270, 270, 17280, 17280, 17280, 66, 17280, 270, 270, 66, 66, 66, 66, 17280, 270, 17280, 270, 17280, 17280, 17280, 66, 270, 270, 17280, 270, 17280, 66, 66, 66, 270, 270, 270, 17280, 17280, 270, 17280, 66, 270, 270, 66, 17280, 17280, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 270, 17280, 66, 17280, 66, 17280, 270, 66, 270, 66, 66, 270, 270, 270, 17280, 270, 66, 66]
Prompts retrieved: 950928 . Total input tokens: 212056530 . Total output tokens: 187021572
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 5.611081732902676,
    "estimated_duration": 3600.001259416478,
    "input_throughput": 5359.3078473331625,
    "output_throughput": 4679.592807345474,
    "total_throughput": 10038.900654678637,
    "itl": 102.9999237097042,
    "ttft": 1897908.4585573538,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 781,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.345391486673607,
    "arrivals": 317160,
    "finished_requests": 78069,
    "scheduler_time": 112.95184192895586
}
#Debug simulation 
Total elapsed time: 5.611172779928893. Arrivals time: 0.3007755749858916 Scheduler time: 5.159745271783322 Scheduler overhead time: 0.049263115506619215 Adapter cache time: 0.026350241620093584 Engine time: 0.051431854255497456 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-16-32/adapters_160_slots_96_rate_1.6-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-16-32/adapters_160_slots_96_rate_1.6-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 270, 66, 66, 66, 17280, 66, 270, 17280, 270, 66, 270, 270, 270, 270, 17280, 17280, 17280, 270, 270, 270, 17280, 17280, 66, 17280, 270, 17280, 17280, 17280, 270, 17280, 66, 270, 270, 270, 17280, 66, 66, 17280, 66, 17280, 66, 66, 270, 66, 270, 17280, 66, 66, 270, 66, 66, 66, 66, 66, 17280, 270, 270, 17280, 270, 66, 17280, 17280, 17280, 270, 270, 66, 66, 66, 17280, 66, 270, 270, 66, 17280, 17280, 17280, 66, 66, 17280, 270, 17280, 17280, 66, 17280, 66, 270, 66, 66, 270, 270, 17280, 17280, 17280, 66, 17280, 270, 270, 66, 66, 66, 66, 17280, 270, 17280, 270, 17280, 17280, 17280, 66, 270, 270, 17280, 270, 17280, 66, 66, 66, 270, 270, 270, 17280, 17280, 270, 17280, 66, 270, 270, 66, 17280, 17280, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 270, 17280, 66, 17280, 66, 17280, 270, 66, 270, 66, 66, 270, 270, 270, 17280, 270, 66, 66]
Prompts retrieved: 950928 . Total input tokens: 212056530 . Total output tokens: 187021572
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 5.177802949678153,
    "estimated_duration": 3600.0819726753316,
    "input_throughput": 4840.453670850773,
    "output_throughput": 4228.315942675009,
    "total_throughput": 9068.769613525781,
    "itl": 81.38214648669798,
    "ttft": 1974161.6823367942,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 708,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.256484733265852,
    "arrivals": 317160,
    "finished_requests": 70505,
    "scheduler_time": 118.24615195795668
}
#Debug simulation 
Total elapsed time: 5.177897860761732. Arrivals time: 0.2664232412353158 Scheduler time: 4.732634624931961 Scheduler overhead time: 0.059790407307446 Adapter cache time: 0.02845790609717369 Engine time: 0.06201694533228874 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_16-16-16/adapters_160_slots_96_rate_1.6-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_16-16-16/adapters_160_slots_96_rate_1.6-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 270, 66, 66, 66, 17280, 66, 270, 17280, 270, 66, 270, 270, 270, 270, 17280, 17280, 17280, 270, 270, 270, 17280, 17280, 66, 17280, 270, 17280, 17280, 17280, 270, 17280, 66, 270, 270, 270, 17280, 66, 66, 17280, 66, 17280, 66, 66, 270, 66, 270, 17280, 66, 66, 270, 66, 66, 66, 66, 66, 17280, 270, 270, 17280, 270, 66, 17280, 17280, 17280, 270, 270, 66, 66, 66, 17280, 66, 270, 270, 66, 17280, 17280, 17280, 66, 66, 17280, 270, 17280, 17280, 66, 17280, 66, 270, 66, 66, 270, 270, 17280, 17280, 17280, 66, 17280, 270, 270, 66, 66, 66, 66, 17280, 270, 17280, 270, 17280, 17280, 17280, 66, 270, 270, 17280, 270, 17280, 66, 66, 66, 270, 270, 270, 17280, 17280, 270, 17280, 66, 270, 270, 66, 17280, 17280, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 270, 17280, 66, 17280, 66, 17280, 270, 66, 270, 66, 66, 270, 270, 270, 17280, 270, 66, 66]
Prompts retrieved: 950928 . Total input tokens: 212056530 . Total output tokens: 187021572
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.609326456207782,
    "estimated_duration": 3600.0204117424773,
    "input_throughput": 5362.186541230335,
    "output_throughput": 4683.163724574465,
    "total_throughput": 10045.3502658048,
    "itl": 103.10171023987675,
    "ttft": 1897609.8807056425,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 782,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.992226175526133,
    "arrivals": 317160,
    "finished_requests": 78124,
    "scheduler_time": 112.9426585816327
}
#Debug simulation 
Total elapsed time: 5.609415314160287. Arrivals time: 0.2794051985256374 Scheduler time: 5.179085699375719 Scheduler overhead time: 0.04945344477891922 Adapter cache time: 0.026326533406972885 Engine time: 0.05149220209568739 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_16-16-32/adapters_160_slots_96_rate_1.6-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_16-16-32/adapters_160_slots_96_rate_1.6-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 270, 66, 66, 66, 17280, 66, 270, 17280, 270, 66, 270, 270, 270, 270, 17280, 17280, 17280, 270, 270, 270, 17280, 17280, 66, 17280, 270, 17280, 17280, 17280, 270, 17280, 66, 270, 270, 270, 17280, 66, 66, 17280, 66, 17280, 66, 66, 270, 66, 270, 17280, 66, 66, 270, 66, 66, 66, 66, 66, 17280, 270, 270, 17280, 270, 66, 17280, 17280, 17280, 270, 270, 66, 66, 66, 17280, 66, 270, 270, 66, 17280, 17280, 17280, 66, 66, 17280, 270, 17280, 17280, 66, 17280, 66, 270, 66, 66, 270, 270, 17280, 17280, 17280, 66, 17280, 270, 270, 66, 66, 66, 66, 17280, 270, 17280, 270, 17280, 17280, 17280, 66, 270, 270, 17280, 270, 17280, 66, 66, 66, 270, 270, 270, 17280, 17280, 270, 17280, 66, 270, 270, 66, 17280, 17280, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 270, 17280, 66, 17280, 66, 17280, 270, 66, 270, 66, 66, 270, 270, 270, 17280, 270, 66, 66]
Prompts retrieved: 950928 . Total input tokens: 212056530 . Total output tokens: 187021572
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.218482464086264,
    "estimated_duration": 3600.061404057422,
    "input_throughput": 4839.9480020986,
    "output_throughput": 4228.137604221045,
    "total_throughput": 9068.085606319646,
    "itl": 81.38465226538563,
    "ttft": 1974100.3167927745,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 708,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.206310507543412,
    "arrivals": 317160,
    "finished_requests": 70500,
    "scheduler_time": 118.2453021598456
}
#Debug simulation 
Total elapsed time: 5.218571325298399. Arrivals time: 0.26618535863235593 Scheduler time: 4.772111976519227 Scheduler overhead time: 0.0598460859619081 Adapter cache time: 0.02904459973797202 Engine time: 0.06263890536502004 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-8/adapters_160_slots_96_rate_1.6-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-8/adapters_160_slots_96_rate_1.6-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 270, 33, 33, 33, 17280, 33, 270, 17280, 270, 33, 270, 270, 270, 270, 17280, 17280, 17280, 270, 270, 270, 17280, 17280, 33, 17280, 270, 17280, 17280, 17280, 270, 17280, 33, 270, 270, 270, 17280, 33, 33, 17280, 33, 17280, 33, 33, 270, 33, 270, 17280, 33, 33, 270, 33, 33, 33, 33, 33, 17280, 270, 270, 17280, 270, 33, 17280, 17280, 17280, 270, 270, 33, 33, 33, 17280, 33, 270, 270, 33, 17280, 17280, 17280, 33, 33, 17280, 270, 17280, 17280, 33, 17280, 33, 270, 33, 33, 270, 270, 17280, 17280, 17280, 33, 17280, 270, 270, 33, 33, 33, 33, 17280, 270, 17280, 270, 17280, 17280, 17280, 33, 270, 270, 17280, 270, 17280, 33, 33, 33, 270, 270, 270, 17280, 17280, 270, 17280, 33, 270, 270, 33, 17280, 17280, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 270, 17280, 33, 17280, 33, 17280, 270, 33, 270, 33, 33, 270, 270, 270, 17280, 270, 33, 33]
Prompts retrieved: 949179 . Total input tokens: 211679878 . Total output tokens: 186680714
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.785501493141055,
    "estimated_duration": 3600.1207177810998,
    "input_throughput": 5584.44968267379,
    "output_throughput": 4872.358561023831,
    "total_throughput": 10456.80824369762,
    "itl": 113.1382911078072,
    "ttft": 1869174.8029638047,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 624,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.126143235936826,
    "arrivals": 316555,
    "finished_requests": 81455,
    "scheduler_time": 111.70513219680421
}
#Debug simulation 
Total elapsed time: 5.7855901680886745. Arrivals time: 0.2584168426692486 Scheduler time: 5.388442436698824 Scheduler overhead time: 0.04587266128510237 Adapter cache time: 0.023201496805995703 Engine time: 0.047764542512595654 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-16/adapters_160_slots_96_rate_1.6-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-16/adapters_160_slots_96_rate_1.6-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 270, 33, 33, 33, 17280, 33, 270, 17280, 270, 33, 270, 270, 270, 270, 17280, 17280, 17280, 270, 270, 270, 17280, 17280, 33, 17280, 270, 17280, 17280, 17280, 270, 17280, 33, 270, 270, 270, 17280, 33, 33, 17280, 33, 17280, 33, 33, 270, 33, 270, 17280, 33, 33, 270, 33, 33, 33, 33, 33, 17280, 270, 270, 17280, 270, 33, 17280, 17280, 17280, 270, 270, 33, 33, 33, 17280, 33, 270, 270, 33, 17280, 17280, 17280, 33, 33, 17280, 270, 17280, 17280, 33, 17280, 33, 270, 33, 33, 270, 270, 17280, 17280, 17280, 33, 17280, 270, 270, 33, 33, 33, 33, 17280, 270, 17280, 270, 17280, 17280, 17280, 33, 270, 270, 17280, 270, 17280, 33, 33, 33, 270, 270, 270, 17280, 17280, 270, 17280, 33, 270, 270, 33, 17280, 17280, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 270, 17280, 33, 17280, 33, 17280, 270, 33, 270, 33, 33, 270, 270, 270, 17280, 270, 33, 33]
Prompts retrieved: 949179 . Total input tokens: 211679878 . Total output tokens: 186680714
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.639337725006044,
    "estimated_duration": 3600.017888287979,
    "input_throughput": 5408.834512558502,
    "output_throughput": 4719.73738110515,
    "total_throughput": 10128.571893663653,
    "itl": 102.67856244591556,
    "ttft": 1894335.1446194232,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 610,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.460585930859676,
    "arrivals": 316555,
    "finished_requests": 78880,
    "scheduler_time": 113.59521794922918
}
#Debug simulation 
Total elapsed time: 5.639427751302719. Arrivals time: 0.28601809591054916 Scheduler time: 5.202914483845234 Scheduler overhead time: 0.04920672671869397 Adapter cache time: 0.023815267253667116 Engine time: 0.05378363095223904 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-32/adapters_160_slots_96_rate_1.6-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-32/adapters_160_slots_96_rate_1.6-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 270, 33, 33, 33, 17280, 33, 270, 17280, 270, 33, 270, 270, 270, 270, 17280, 17280, 17280, 270, 270, 270, 17280, 17280, 33, 17280, 270, 17280, 17280, 17280, 270, 17280, 33, 270, 270, 270, 17280, 33, 33, 17280, 33, 17280, 33, 33, 270, 33, 270, 17280, 33, 33, 270, 33, 33, 33, 33, 33, 17280, 270, 270, 17280, 270, 33, 17280, 17280, 17280, 270, 270, 33, 33, 33, 17280, 33, 270, 270, 33, 17280, 17280, 17280, 33, 33, 17280, 270, 17280, 17280, 33, 17280, 33, 270, 33, 33, 270, 270, 17280, 17280, 17280, 33, 17280, 270, 270, 33, 33, 33, 33, 17280, 270, 17280, 270, 17280, 17280, 17280, 33, 270, 270, 17280, 270, 17280, 33, 33, 33, 270, 270, 270, 17280, 17280, 270, 17280, 33, 270, 270, 33, 17280, 17280, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 270, 17280, 33, 17280, 33, 17280, 270, 33, 270, 33, 33, 270, 270, 270, 17280, 270, 33, 33]
Prompts retrieved: 949179 . Total input tokens: 211679878 . Total output tokens: 186680714
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.21737527474761,
    "estimated_duration": 3600.0566444827314,
    "input_throughput": 4872.569165511124,
    "output_throughput": 4257.643285555121,
    "total_throughput": 9130.212451066245,
    "itl": 81.26516593096034,
    "ttft": 1971464.495476215,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 569,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.2723213410377845,
    "arrivals": 316555,
    "finished_requests": 70989,
    "scheduler_time": 118.67358700035417
}
#Debug simulation 
Total elapsed time: 5.217491863761097. Arrivals time: 0.2838538782671094 Scheduler time: 4.756058779545128 Scheduler overhead time: 0.06026354571804404 Adapter cache time: 0.026197015307843685 Engine time: 0.06233965093269944 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_8-16-16/adapters_160_slots_96_rate_1.6-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_8-16-16/adapters_160_slots_96_rate_1.6-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 270, 33, 33, 33, 17280, 33, 270, 17280, 270, 33, 270, 270, 270, 270, 17280, 17280, 17280, 270, 270, 270, 17280, 17280, 33, 17280, 270, 17280, 17280, 17280, 270, 17280, 33, 270, 270, 270, 17280, 33, 33, 17280, 33, 17280, 33, 33, 270, 33, 270, 17280, 33, 33, 270, 33, 33, 33, 33, 33, 17280, 270, 270, 17280, 270, 33, 17280, 17280, 17280, 270, 270, 33, 33, 33, 17280, 33, 270, 270, 33, 17280, 17280, 17280, 33, 33, 17280, 270, 17280, 17280, 33, 17280, 33, 270, 33, 33, 270, 270, 17280, 17280, 17280, 33, 17280, 270, 270, 33, 33, 33, 33, 17280, 270, 17280, 270, 17280, 17280, 17280, 33, 270, 270, 17280, 270, 17280, 33, 33, 33, 270, 270, 270, 17280, 17280, 270, 17280, 33, 270, 270, 33, 17280, 17280, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 270, 17280, 33, 17280, 33, 17280, 270, 33, 270, 33, 33, 270, 270, 270, 17280, 270, 33, 33]
Prompts retrieved: 949179 . Total input tokens: 211679878 . Total output tokens: 186680714
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 5.9430334828794,
    "estimated_duration": 3600.0943363950223,
    "input_throughput": 5409.094090434214,
    "output_throughput": 4719.789375579178,
    "total_throughput": 10128.883466013393,
    "itl": 102.67219428737647,
    "ttft": 1894336.6585682067,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 611,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.185160994217725,
    "arrivals": 316555,
    "finished_requests": 78885,
    "scheduler_time": 113.60535970731948
}
#Debug simulation 
Total elapsed time: 5.943102358840406. Arrivals time: 0.25730923330411315 Scheduler time: 5.536995245143771 Scheduler overhead time: 0.04953072313219309 Adapter cache time: 0.023786727339029312 Engine time: 0.05166875012218952 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_8-16-32/adapters_160_slots_96_rate_1.6-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_8-16-32/adapters_160_slots_96_rate_1.6-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 270, 33, 33, 33, 17280, 33, 270, 17280, 270, 33, 270, 270, 270, 270, 17280, 17280, 17280, 270, 270, 270, 17280, 17280, 33, 17280, 270, 17280, 17280, 17280, 270, 17280, 33, 270, 270, 270, 17280, 33, 33, 17280, 33, 17280, 33, 33, 270, 33, 270, 17280, 33, 33, 270, 33, 33, 33, 33, 33, 17280, 270, 270, 17280, 270, 33, 17280, 17280, 17280, 270, 270, 33, 33, 33, 17280, 33, 270, 270, 33, 17280, 17280, 17280, 33, 33, 17280, 270, 17280, 17280, 33, 17280, 33, 270, 33, 33, 270, 270, 17280, 17280, 17280, 33, 17280, 270, 270, 33, 33, 33, 33, 17280, 270, 17280, 270, 17280, 17280, 17280, 33, 270, 270, 17280, 270, 17280, 33, 33, 33, 270, 270, 270, 17280, 17280, 270, 17280, 33, 270, 270, 33, 17280, 17280, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 270, 17280, 33, 17280, 33, 17280, 270, 33, 270, 33, 33, 270, 270, 270, 17280, 270, 33, 33]
Prompts retrieved: 949179 . Total input tokens: 211679878 . Total output tokens: 186680714
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 5.213250021915883,
    "estimated_duration": 3600.013681247264,
    "input_throughput": 4872.398149865596,
    "output_throughput": 4257.5518753833485,
    "total_throughput": 9129.950025248943,
    "itl": 81.26385231792067,
    "ttft": 1971412.5999685735,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 569,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.2327619603043765,
    "arrivals": 316555,
    "finished_requests": 70987,
    "scheduler_time": 118.67363466340602
}
#Debug simulation 
Total elapsed time: 5.2133694919757545. Arrivals time: 0.2380071748048067 Scheduler time: 4.7980854185298085 Scheduler overhead time: 0.06007831543684006 Adapter cache time: 0.02593530062586069 Engine time: 0.06252639647573233 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_16-16-16/adapters_160_slots_96_rate_1.6-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_16-16-16/adapters_160_slots_96_rate_1.6-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 270, 33, 33, 33, 17280, 33, 270, 17280, 270, 33, 270, 270, 270, 270, 17280, 17280, 17280, 270, 270, 270, 17280, 17280, 33, 17280, 270, 17280, 17280, 17280, 270, 17280, 33, 270, 270, 270, 17280, 33, 33, 17280, 33, 17280, 33, 33, 270, 33, 270, 17280, 33, 33, 270, 33, 33, 33, 33, 33, 17280, 270, 270, 17280, 270, 33, 17280, 17280, 17280, 270, 270, 33, 33, 33, 17280, 33, 270, 270, 33, 17280, 17280, 17280, 33, 33, 17280, 270, 17280, 17280, 33, 17280, 33, 270, 33, 33, 270, 270, 17280, 17280, 17280, 33, 17280, 270, 270, 33, 33, 33, 33, 17280, 270, 17280, 270, 17280, 17280, 17280, 33, 270, 270, 17280, 270, 17280, 33, 33, 33, 270, 270, 270, 17280, 17280, 270, 17280, 33, 270, 270, 33, 17280, 17280, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 270, 17280, 33, 17280, 33, 17280, 270, 33, 270, 33, 33, 270, 270, 270, 17280, 270, 33, 33]
Prompts retrieved: 949179 . Total input tokens: 211679878 . Total output tokens: 186680714
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.666304411366582,
    "estimated_duration": 3600.0364606658923,
    "input_throughput": 5409.389102797567,
    "output_throughput": 4720.01525141692,
    "total_throughput": 10129.404354214486,
    "itl": 102.66321715248081,
    "ttft": 1894241.0947505906,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 611,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.9005756946885777,
    "arrivals": 316555,
    "finished_requests": 78888,
    "scheduler_time": 113.61072266298324
}
#Debug simulation 
Total elapsed time: 5.666420678142458. Arrivals time: 0.2609781688079238 Scheduler time: 5.255684563424438 Scheduler overhead time: 0.049897872377187014 Adapter cache time: 0.023991134483367205 Engine time: 0.05197704955935478 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_16-16-32/adapters_160_slots_96_rate_1.6-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_16-16-32/adapters_160_slots_96_rate_1.6-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 270, 33, 33, 33, 17280, 33, 270, 17280, 270, 33, 270, 270, 270, 270, 17280, 17280, 17280, 270, 270, 270, 17280, 17280, 33, 17280, 270, 17280, 17280, 17280, 270, 17280, 33, 270, 270, 270, 17280, 33, 33, 17280, 33, 17280, 33, 33, 270, 33, 270, 17280, 33, 33, 270, 33, 33, 33, 33, 33, 17280, 270, 270, 17280, 270, 33, 17280, 17280, 17280, 270, 270, 33, 33, 33, 17280, 33, 270, 270, 33, 17280, 17280, 17280, 33, 33, 17280, 270, 17280, 17280, 33, 17280, 33, 270, 33, 33, 270, 270, 17280, 17280, 17280, 33, 17280, 270, 270, 33, 33, 33, 33, 17280, 270, 17280, 270, 17280, 17280, 17280, 33, 270, 270, 17280, 270, 17280, 33, 33, 33, 270, 270, 270, 17280, 17280, 270, 17280, 33, 270, 270, 33, 17280, 17280, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 270, 17280, 33, 17280, 33, 17280, 270, 33, 270, 33, 33, 270, 270, 270, 17280, 270, 33, 33]
Prompts retrieved: 949179 . Total input tokens: 211679878 . Total output tokens: 186680714
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.203173640184104,
    "estimated_duration": 3600.024828432191,
    "input_throughput": 4871.675012207584,
    "output_throughput": 4257.018695805548,
    "total_throughput": 9128.693708013132,
    "itl": 81.23396851375999,
    "ttft": 1971264.9766265133,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 569,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.193616813924199,
    "arrivals": 316555,
    "finished_requests": 70978,
    "scheduler_time": 118.68449637857161
}
#Debug simulation 
Total elapsed time: 5.203287014272064. Arrivals time: 0.2364755873568356 Scheduler time: 4.789384447038174 Scheduler overhead time: 0.06009344756603241 Adapter cache time: 0.02625814499333501 Engine time: 0.062468357384204865 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-8/adapters_160_slots_96_rate_1.6-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-8/adapters_160_slots_96_rate_1.6-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 135, 66, 66, 66, 17280, 66, 135, 17280, 135, 66, 135, 135, 135, 135, 17280, 17280, 17280, 135, 135, 135, 17280, 17280, 66, 17280, 135, 17280, 17280, 17280, 135, 17280, 66, 135, 135, 135, 17280, 66, 66, 17280, 66, 17280, 66, 66, 135, 66, 135, 17280, 66, 66, 135, 66, 66, 66, 66, 66, 17280, 135, 135, 17280, 135, 66, 17280, 17280, 17280, 135, 135, 66, 66, 66, 17280, 66, 135, 135, 66, 17280, 17280, 17280, 66, 66, 17280, 135, 17280, 17280, 66, 17280, 66, 135, 66, 66, 135, 135, 17280, 17280, 17280, 66, 17280, 135, 135, 66, 66, 66, 66, 17280, 135, 17280, 135, 17280, 17280, 17280, 66, 135, 135, 17280, 135, 17280, 66, 66, 66, 135, 135, 135, 17280, 17280, 135, 17280, 66, 135, 135, 66, 17280, 17280, 17280, 17280, 17280, 17280, 135, 135, 135, 135, 135, 17280, 66, 17280, 66, 17280, 135, 66, 135, 66, 66, 135, 135, 135, 17280, 135, 66, 66]
Prompts retrieved: 943773 . Total input tokens: 210485266 . Total output tokens: 185624437
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 6.184996746946126,
    "estimated_duration": 3600.115424877793,
    "input_throughput": 5704.942085488046,
    "output_throughput": 4968.167374968858,
    "total_throughput": 10673.109460456904,
    "itl": 110.45450895717201,
    "ttft": 1851570.1337124992,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 593,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.921158555946372,
    "arrivals": 314729,
    "finished_requests": 82789,
    "scheduler_time": 114.08197985887715
}
#Debug simulation 
Total elapsed time: 6.1851149862632155. Arrivals time: 0.5291860452853143 Scheduler time: 5.517694256734103 Scheduler overhead time: 0.04688494838774204 Adapter cache time: 0.020037371665239334 Engine time: 0.04886113898828626 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-16/adapters_160_slots_96_rate_1.6-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-16/adapters_160_slots_96_rate_1.6-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 135, 66, 66, 66, 17280, 66, 135, 17280, 135, 66, 135, 135, 135, 135, 17280, 17280, 17280, 135, 135, 135, 17280, 17280, 66, 17280, 135, 17280, 17280, 17280, 135, 17280, 66, 135, 135, 135, 17280, 66, 66, 17280, 66, 17280, 66, 66, 135, 66, 135, 17280, 66, 66, 135, 66, 66, 66, 66, 66, 17280, 135, 135, 17280, 135, 66, 17280, 17280, 17280, 135, 135, 66, 66, 66, 17280, 66, 135, 135, 66, 17280, 17280, 17280, 66, 66, 17280, 135, 17280, 17280, 66, 17280, 66, 135, 66, 66, 135, 135, 17280, 17280, 17280, 66, 17280, 135, 135, 66, 66, 66, 66, 17280, 135, 17280, 135, 17280, 17280, 17280, 66, 135, 135, 17280, 135, 17280, 66, 66, 66, 135, 135, 135, 17280, 17280, 135, 17280, 66, 135, 135, 66, 17280, 17280, 17280, 17280, 17280, 17280, 135, 135, 135, 135, 135, 17280, 66, 17280, 66, 17280, 135, 66, 135, 66, 66, 135, 135, 135, 17280, 135, 66, 66]
Prompts retrieved: 943773 . Total input tokens: 210485266 . Total output tokens: 185624437
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.777270100079477,
    "estimated_duration": 3600.0392386553685,
    "input_throughput": 5513.964622067356,
    "output_throughput": 4803.51319905584,
    "total_throughput": 10317.477821123195,
    "itl": 100.43164896577268,
    "ttft": 1878847.0713511833,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 571,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.1866250366577935,
    "arrivals": 314729,
    "finished_requests": 80037,
    "scheduler_time": 115.82315001561227
}
#Debug simulation 
Total elapsed time: 5.777370528783649. Arrivals time: 0.2662944379262626 Scheduler time: 5.363154566846788 Scheduler overhead time: 0.05055562173947692 Adapter cache time: 0.020217418670654297 Engine time: 0.052878583781421185 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-32/adapters_160_slots_96_rate_1.6-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-32/adapters_160_slots_96_rate_1.6-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 135, 66, 66, 66, 17280, 66, 135, 17280, 135, 66, 135, 135, 135, 135, 17280, 17280, 17280, 135, 135, 135, 17280, 17280, 66, 17280, 135, 17280, 17280, 17280, 135, 17280, 66, 135, 135, 135, 17280, 66, 66, 17280, 66, 17280, 66, 66, 135, 66, 135, 17280, 66, 66, 135, 66, 66, 66, 66, 66, 17280, 135, 135, 17280, 135, 66, 17280, 17280, 17280, 135, 135, 66, 66, 66, 17280, 66, 135, 135, 66, 17280, 17280, 17280, 66, 66, 17280, 135, 17280, 17280, 66, 17280, 66, 135, 66, 66, 135, 135, 17280, 17280, 17280, 66, 17280, 135, 135, 66, 66, 66, 66, 17280, 135, 17280, 135, 17280, 17280, 17280, 66, 135, 135, 17280, 135, 17280, 66, 66, 66, 135, 135, 135, 17280, 17280, 135, 17280, 66, 135, 135, 66, 17280, 17280, 17280, 17280, 17280, 17280, 135, 135, 135, 135, 135, 17280, 66, 17280, 66, 17280, 135, 66, 135, 66, 66, 135, 135, 135, 17280, 135, 66, 66]
Prompts retrieved: 943773 . Total input tokens: 210485266 . Total output tokens: 185624437
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.329058066941798,
    "estimated_duration": 3600.0850540113925,
    "input_throughput": 4960.001147779409,
    "output_throughput": 4314.207794255866,
    "total_throughput": 9274.208942035275,
    "itl": 79.96871091582405,
    "ttft": 1963911.2985080008,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 497,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.745525862760873,
    "arrivals": 314729,
    "finished_requests": 71937,
    "scheduler_time": 120.44269046398136
}
#Debug simulation 
Total elapsed time: 5.329164132010192. Arrivals time: 0.2755176401697099 Scheduler time: 4.877673592418432 Scheduler overhead time: 0.06088005565106869 Adapter cache time: 0.021980805788189173 Engine time: 0.06378691177815199 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_8-16-16/adapters_160_slots_96_rate_1.6-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_8-16-16/adapters_160_slots_96_rate_1.6-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 135, 66, 66, 66, 17280, 66, 135, 17280, 135, 66, 135, 135, 135, 135, 17280, 17280, 17280, 135, 135, 135, 17280, 17280, 66, 17280, 135, 17280, 17280, 17280, 135, 17280, 66, 135, 135, 135, 17280, 66, 66, 17280, 66, 17280, 66, 66, 135, 66, 135, 17280, 66, 66, 135, 66, 66, 66, 66, 66, 17280, 135, 135, 17280, 135, 66, 17280, 17280, 17280, 135, 135, 66, 66, 66, 17280, 66, 135, 135, 66, 17280, 17280, 17280, 66, 66, 17280, 135, 17280, 17280, 66, 17280, 66, 135, 66, 66, 135, 135, 17280, 17280, 17280, 66, 17280, 135, 135, 66, 66, 66, 66, 17280, 135, 17280, 135, 17280, 17280, 17280, 66, 135, 135, 17280, 135, 17280, 66, 66, 66, 135, 135, 135, 17280, 17280, 135, 17280, 66, 135, 135, 66, 17280, 17280, 17280, 17280, 17280, 17280, 135, 135, 135, 135, 135, 17280, 66, 17280, 66, 17280, 135, 66, 135, 66, 66, 135, 135, 135, 17280, 135, 66, 66]
Prompts retrieved: 943773 . Total input tokens: 210485266 . Total output tokens: 185624437
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 5.785485195927322,
    "estimated_duration": 3600.0337604902716,
    "input_throughput": 5514.10301143859,
    "output_throughput": 4803.555508225277,
    "total_throughput": 10317.658519663868,
    "itl": 100.42923071738538,
    "ttft": 1878807.3420417374,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 572,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.925082309748973,
    "arrivals": 314729,
    "finished_requests": 80038,
    "scheduler_time": 115.82969054218725
}
#Debug simulation 
Total elapsed time: 5.785589836072177. Arrivals time: 0.2689687046222389 Scheduler time: 5.3686605780385435 Scheduler overhead time: 0.05060361372306943 Adapter cache time: 0.020285981707274914 Engine time: 0.05285202292725444 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_8-16-32/adapters_160_slots_96_rate_1.6-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_8-16-32/adapters_160_slots_96_rate_1.6-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 135, 66, 66, 66, 17280, 66, 135, 17280, 135, 66, 135, 135, 135, 135, 17280, 17280, 17280, 135, 135, 135, 17280, 17280, 66, 17280, 135, 17280, 17280, 17280, 135, 17280, 66, 135, 135, 135, 17280, 66, 66, 17280, 66, 17280, 66, 66, 135, 66, 135, 17280, 66, 66, 135, 66, 66, 66, 66, 66, 17280, 135, 135, 17280, 135, 66, 17280, 17280, 17280, 135, 135, 66, 66, 66, 17280, 66, 135, 135, 66, 17280, 17280, 17280, 66, 66, 17280, 135, 17280, 17280, 66, 17280, 66, 135, 66, 66, 135, 135, 17280, 17280, 17280, 66, 17280, 135, 135, 66, 66, 66, 66, 17280, 135, 17280, 135, 17280, 17280, 17280, 66, 135, 135, 17280, 135, 17280, 66, 66, 66, 135, 135, 135, 17280, 17280, 135, 17280, 66, 135, 135, 66, 17280, 17280, 17280, 17280, 17280, 17280, 135, 135, 135, 135, 135, 17280, 66, 17280, 66, 17280, 135, 66, 135, 66, 66, 135, 135, 135, 17280, 135, 66, 66]
Prompts retrieved: 943773 . Total input tokens: 210485266 . Total output tokens: 185624437
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 5.257515050005168,
    "estimated_duration": 3600.0718340138965,
    "input_throughput": 4959.3649302529675,
    "output_throughput": 4313.833366676108,
    "total_throughput": 9273.198296929077,
    "itl": 79.96015874773437,
    "ttft": 1963787.281104272,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 497,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.710730177089603,
    "arrivals": 314729,
    "finished_requests": 71929,
    "scheduler_time": 120.44558392923881
}
#Debug simulation 
Total elapsed time: 5.2576191467233. Arrivals time: 0.275288057513535 Scheduler time: 4.808543462771922 Scheduler overhead time: 0.06032998068258166 Adapter cache time: 0.02162880590185523 Engine time: 0.06281934445723891 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_16-16-16/adapters_160_slots_96_rate_1.6-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_16-16-16/adapters_160_slots_96_rate_1.6-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 135, 66, 66, 66, 17280, 66, 135, 17280, 135, 66, 135, 135, 135, 135, 17280, 17280, 17280, 135, 135, 135, 17280, 17280, 66, 17280, 135, 17280, 17280, 17280, 135, 17280, 66, 135, 135, 135, 17280, 66, 66, 17280, 66, 17280, 66, 66, 135, 66, 135, 17280, 66, 66, 135, 66, 66, 66, 66, 66, 17280, 135, 135, 17280, 135, 66, 17280, 17280, 17280, 135, 135, 66, 66, 66, 17280, 66, 135, 135, 66, 17280, 17280, 17280, 66, 66, 17280, 135, 17280, 17280, 66, 17280, 66, 135, 66, 66, 135, 135, 17280, 17280, 17280, 66, 17280, 135, 135, 66, 66, 66, 66, 17280, 135, 17280, 135, 17280, 17280, 17280, 66, 135, 135, 17280, 135, 17280, 66, 66, 66, 135, 135, 135, 17280, 17280, 135, 17280, 66, 135, 135, 66, 17280, 17280, 17280, 17280, 17280, 17280, 135, 135, 135, 135, 135, 17280, 66, 17280, 66, 17280, 135, 66, 135, 66, 66, 135, 135, 135, 17280, 135, 66, 66]
Prompts retrieved: 943773 . Total input tokens: 210485266 . Total output tokens: 185624437
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.744720652233809,
    "estimated_duration": 3600.0768368943404,
    "input_throughput": 5514.080920874138,
    "output_throughput": 4803.693305312516,
    "total_throughput": 10317.774226186653,
    "itl": 100.41872996144954,
    "ttft": 1878715.9640979315,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 573,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.6579866989468988,
    "arrivals": 314729,
    "finished_requests": 80041,
    "scheduler_time": 115.83850523335025
}
#Debug simulation 
Total elapsed time: 5.744810404255986. Arrivals time: 0.288880430161953 Scheduler time: 5.307876576669514 Scheduler overhead time: 0.050665488466620445 Adapter cache time: 0.020123377442359924 Engine time: 0.053020024206489325 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_16-16-32/adapters_160_slots_96_rate_1.6-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_16-16-32/adapters_160_slots_96_rate_1.6-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 135, 66, 66, 66, 17280, 66, 135, 17280, 135, 66, 135, 135, 135, 135, 17280, 17280, 17280, 135, 135, 135, 17280, 17280, 66, 17280, 135, 17280, 17280, 17280, 135, 17280, 66, 135, 135, 135, 17280, 66, 66, 17280, 66, 17280, 66, 66, 135, 66, 135, 17280, 66, 66, 135, 66, 66, 66, 66, 66, 17280, 135, 135, 17280, 135, 66, 17280, 17280, 17280, 135, 135, 66, 66, 66, 17280, 66, 135, 135, 66, 17280, 17280, 17280, 66, 66, 17280, 135, 17280, 17280, 66, 17280, 66, 135, 66, 66, 135, 135, 17280, 17280, 17280, 66, 17280, 135, 135, 66, 66, 66, 66, 17280, 135, 17280, 135, 17280, 17280, 17280, 66, 135, 135, 17280, 135, 17280, 66, 66, 66, 135, 135, 135, 17280, 17280, 135, 17280, 66, 135, 135, 66, 17280, 17280, 17280, 17280, 17280, 17280, 135, 135, 135, 135, 135, 17280, 66, 17280, 66, 17280, 135, 66, 135, 66, 66, 135, 135, 135, 17280, 135, 66, 66]
Prompts retrieved: 943773 . Total input tokens: 210485266 . Total output tokens: 185624437
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.248329011257738,
    "estimated_duration": 3600.006511889186,
    "input_throughput": 4960.1710277544225,
    "output_throughput": 4314.308307139552,
    "total_throughput": 9274.479334893975,
    "itl": 79.96719756834312,
    "ttft": 1963822.334521578,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 497,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.675106022711874,
    "arrivals": 314729,
    "finished_requests": 71938,
    "scheduler_time": 120.44153063775477
}
#Debug simulation 
Total elapsed time: 5.248418229166418. Arrivals time: 0.2699085050262511 Scheduler time: 4.803661113139242 Scheduler overhead time: 0.060663314536213875 Adapter cache time: 0.021736773662269115 Engine time: 0.06329925218597054 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-8/adapters_160_slots_96_rate_1.6-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-8/adapters_160_slots_96_rate_1.6-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 135, 33, 33, 33, 17280, 33, 135, 17280, 135, 33, 135, 135, 135, 135, 17280, 17280, 17280, 135, 135, 135, 17280, 17280, 33, 17280, 135, 17280, 17280, 17280, 135, 17280, 33, 135, 135, 135, 17280, 33, 33, 17280, 33, 17280, 33, 33, 135, 33, 135, 17280, 33, 33, 135, 33, 33, 33, 33, 33, 17280, 135, 135, 17280, 135, 33, 17280, 17280, 17280, 135, 135, 33, 33, 33, 17280, 33, 135, 135, 33, 17280, 17280, 17280, 33, 33, 17280, 135, 17280, 17280, 33, 17280, 33, 135, 33, 33, 135, 135, 17280, 17280, 17280, 33, 17280, 135, 135, 33, 33, 33, 33, 17280, 135, 17280, 135, 17280, 17280, 17280, 33, 135, 135, 17280, 135, 17280, 33, 33, 33, 135, 135, 135, 17280, 17280, 135, 17280, 33, 135, 135, 33, 17280, 17280, 17280, 17280, 17280, 17280, 135, 135, 135, 135, 135, 17280, 33, 17280, 33, 17280, 135, 33, 135, 33, 33, 135, 135, 135, 17280, 135, 33, 33]
Prompts retrieved: 942024 . Total input tokens: 210077244 . Total output tokens: 185294656
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.952306494582444,
    "estimated_duration": 3600.0717642012887,
    "input_throughput": 5662.688228250598,
    "output_throughput": 4991.683271065824,
    "total_throughput": 10654.371499316421,
    "itl": 110.25133035288546,
    "ttft": 1846711.007705798,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 455,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.0086461095372514,
    "arrivals": 314142,
    "finished_requests": 82993,
    "scheduler_time": 114.46762046773404
}
#Debug simulation 
Total elapsed time: 5.952398693654686. Arrivals time: 0.297353554982692 Scheduler time: 5.517638090066612 Scheduler overhead time: 0.04728929931297898 Adapter cache time: 0.018349038902670145 Engine time: 0.04919911362230778 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-16/adapters_160_slots_96_rate_1.6-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-16/adapters_160_slots_96_rate_1.6-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 135, 33, 33, 33, 17280, 33, 135, 17280, 135, 33, 135, 135, 135, 135, 17280, 17280, 17280, 135, 135, 135, 17280, 17280, 33, 17280, 135, 17280, 17280, 17280, 135, 17280, 33, 135, 135, 135, 17280, 33, 33, 17280, 33, 17280, 33, 33, 135, 33, 135, 17280, 33, 33, 135, 33, 33, 33, 33, 33, 17280, 135, 135, 17280, 135, 33, 17280, 17280, 17280, 135, 135, 33, 33, 33, 17280, 33, 135, 135, 33, 17280, 17280, 17280, 33, 33, 17280, 135, 17280, 17280, 33, 17280, 33, 135, 33, 33, 135, 135, 17280, 17280, 17280, 33, 17280, 135, 135, 33, 33, 33, 33, 17280, 135, 17280, 135, 17280, 17280, 17280, 33, 135, 135, 17280, 135, 17280, 33, 33, 33, 135, 135, 135, 17280, 17280, 135, 17280, 33, 135, 135, 33, 17280, 17280, 17280, 17280, 17280, 17280, 135, 135, 135, 135, 135, 17280, 33, 17280, 33, 17280, 135, 33, 135, 33, 33, 135, 135, 135, 17280, 135, 33, 33]
Prompts retrieved: 942024 . Total input tokens: 210077244 . Total output tokens: 185294656
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.7708939192816615,
    "estimated_duration": 3600.053506157725,
    "input_throughput": 5471.3645134187145,
    "output_throughput": 4824.308852713781,
    "total_throughput": 10295.673366132496,
    "itl": 100.30960548228153,
    "ttft": 1873808.500038367,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 443,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.238990384773355,
    "arrivals": 314142,
    "finished_requests": 80182,
    "scheduler_time": 116.16147809591266
}
#Debug simulation 
Total elapsed time: 5.770989538170397. Arrivals time: 0.26610195031389594 Scheduler time: 5.35786289582029 Scheduler overhead time: 0.050674180034548044 Adapter cache time: 0.018806247040629387 Engine time: 0.05322741996496916 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-32/adapters_160_slots_96_rate_1.6-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-32/adapters_160_slots_96_rate_1.6-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 135, 33, 33, 33, 17280, 33, 135, 17280, 135, 33, 135, 135, 135, 135, 17280, 17280, 17280, 135, 135, 135, 17280, 17280, 33, 17280, 135, 17280, 17280, 17280, 135, 17280, 33, 135, 135, 135, 17280, 33, 33, 17280, 33, 17280, 33, 33, 135, 33, 135, 17280, 33, 33, 135, 33, 33, 33, 33, 33, 17280, 135, 135, 17280, 135, 33, 17280, 17280, 17280, 135, 135, 33, 33, 33, 17280, 33, 135, 135, 33, 17280, 17280, 17280, 33, 33, 17280, 135, 17280, 17280, 33, 17280, 33, 135, 33, 33, 135, 135, 17280, 17280, 17280, 33, 17280, 135, 135, 33, 33, 33, 33, 17280, 135, 17280, 135, 17280, 17280, 17280, 33, 135, 135, 17280, 135, 17280, 33, 33, 33, 135, 135, 135, 17280, 17280, 135, 17280, 33, 135, 135, 33, 17280, 17280, 17280, 17280, 17280, 17280, 135, 135, 135, 135, 135, 17280, 33, 17280, 33, 17280, 135, 33, 135, 33, 33, 135, 135, 135, 17280, 135, 33, 33]
Prompts retrieved: 942024 . Total input tokens: 210077244 . Total output tokens: 185294656
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.2830863748677075,
    "estimated_duration": 3600.015624718199,
    "input_throughput": 4910.580353768272,
    "output_throughput": 4328.96815585902,
    "total_throughput": 9239.548509627291,
    "itl": 79.93686890008766,
    "ttft": 1957108.865133073,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 397,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.978929878864457,
    "arrivals": 314142,
    "finished_requests": 71930,
    "scheduler_time": 120.68939786722665
}
#Debug simulation 
Total elapsed time: 5.283175962045789. Arrivals time: 0.24491425324231386 Scheduler time: 4.8648522407747805 Scheduler overhead time: 0.0603077681735158 Adapter cache time: 0.02072831429541111 Engine time: 0.06326062604784966 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_8-16-16/adapters_160_slots_96_rate_1.6-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_8-16-16/adapters_160_slots_96_rate_1.6-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 135, 33, 33, 33, 17280, 33, 135, 17280, 135, 33, 135, 135, 135, 135, 17280, 17280, 17280, 135, 135, 135, 17280, 17280, 33, 17280, 135, 17280, 17280, 17280, 135, 17280, 33, 135, 135, 135, 17280, 33, 33, 17280, 33, 17280, 33, 33, 135, 33, 135, 17280, 33, 33, 135, 33, 33, 33, 33, 33, 17280, 135, 135, 17280, 135, 33, 17280, 17280, 17280, 135, 135, 33, 33, 33, 17280, 33, 135, 135, 33, 17280, 17280, 17280, 33, 33, 17280, 135, 17280, 17280, 33, 17280, 33, 135, 33, 33, 135, 135, 17280, 17280, 17280, 33, 17280, 135, 135, 33, 33, 33, 33, 17280, 135, 17280, 135, 17280, 17280, 17280, 33, 135, 135, 17280, 135, 17280, 33, 33, 33, 135, 135, 135, 17280, 17280, 135, 17280, 33, 135, 135, 33, 17280, 17280, 17280, 17280, 17280, 17280, 135, 135, 135, 135, 135, 17280, 33, 17280, 33, 17280, 135, 33, 135, 33, 33, 135, 135, 135, 17280, 135, 33, 33]
Prompts retrieved: 942024 . Total input tokens: 210077244 . Total output tokens: 185294656
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 5.772539927158505,
    "estimated_duration": 3600.0474298583404,
    "input_throughput": 5472.041794953565,
    "output_throughput": 4824.915320819397,
    "total_throughput": 10296.957115772962,
    "itl": 100.30205377344652,
    "ttft": 1873769.508014412,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 441,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.031871606628407,
    "arrivals": 314142,
    "finished_requests": 80189,
    "scheduler_time": 116.16671774279865
}
#Debug simulation 
Total elapsed time: 5.77263063704595. Arrivals time: 0.26319060381501913 Scheduler time: 5.360890693496913 Scheduler overhead time: 0.05126917455345392 Adapter cache time: 0.018916046246886253 Engine time: 0.05366317182779312 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_8-16-32/adapters_160_slots_96_rate_1.6-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_8-16-32/adapters_160_slots_96_rate_1.6-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 135, 33, 33, 33, 17280, 33, 135, 17280, 135, 33, 135, 135, 135, 135, 17280, 17280, 17280, 135, 135, 135, 17280, 17280, 33, 17280, 135, 17280, 17280, 17280, 135, 17280, 33, 135, 135, 135, 17280, 33, 33, 17280, 33, 17280, 33, 33, 135, 33, 135, 17280, 33, 33, 135, 33, 33, 33, 33, 33, 17280, 135, 135, 17280, 135, 33, 17280, 17280, 17280, 135, 135, 33, 33, 33, 17280, 33, 135, 135, 33, 17280, 17280, 17280, 33, 33, 17280, 135, 17280, 17280, 33, 17280, 33, 135, 33, 33, 135, 135, 17280, 17280, 17280, 33, 17280, 135, 135, 33, 33, 33, 33, 17280, 135, 17280, 135, 17280, 17280, 17280, 33, 135, 135, 17280, 135, 17280, 33, 33, 33, 135, 135, 135, 17280, 17280, 135, 17280, 33, 135, 135, 33, 17280, 17280, 17280, 17280, 17280, 17280, 135, 135, 135, 135, 135, 17280, 33, 17280, 33, 17280, 135, 33, 135, 33, 33, 135, 135, 135, 17280, 135, 33, 33]
Prompts retrieved: 942024 . Total input tokens: 210077244 . Total output tokens: 185294656
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 5.292611636221409,
    "estimated_duration": 3600.008899782731,
    "input_throughput": 4910.67258224471,
    "output_throughput": 4329.0192979635585,
    "total_throughput": 9239.691880208267,
    "itl": 79.93450746616088,
    "ttft": 1957092.138356286,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 397,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.952418880257775,
    "arrivals": 314142,
    "finished_requests": 71931,
    "scheduler_time": 120.69120738030901
}
#Debug simulation 
Total elapsed time: 5.292703594081104. Arrivals time: 0.24430693872272968 Scheduler time: 4.873516759369522 Scheduler overhead time: 0.06112981680780649 Adapter cache time: 0.02059117006137967 Engine time: 0.06400202261283994 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_16-16-16/adapters_160_slots_96_rate_1.6-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_16-16-16/adapters_160_slots_96_rate_1.6-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 135, 33, 33, 33, 17280, 33, 135, 17280, 135, 33, 135, 135, 135, 135, 17280, 17280, 17280, 135, 135, 135, 17280, 17280, 33, 17280, 135, 17280, 17280, 17280, 135, 17280, 33, 135, 135, 135, 17280, 33, 33, 17280, 33, 17280, 33, 33, 135, 33, 135, 17280, 33, 33, 135, 33, 33, 33, 33, 33, 17280, 135, 135, 17280, 135, 33, 17280, 17280, 17280, 135, 135, 33, 33, 33, 17280, 33, 135, 135, 33, 17280, 17280, 17280, 33, 33, 17280, 135, 17280, 17280, 33, 17280, 33, 135, 33, 33, 135, 135, 17280, 17280, 17280, 33, 17280, 135, 135, 33, 33, 33, 33, 17280, 135, 17280, 135, 17280, 17280, 17280, 33, 135, 135, 17280, 135, 17280, 33, 33, 33, 135, 135, 135, 17280, 17280, 135, 17280, 33, 135, 135, 33, 17280, 17280, 17280, 17280, 17280, 17280, 135, 135, 135, 135, 135, 17280, 33, 17280, 33, 17280, 135, 33, 135, 33, 33, 135, 135, 135, 17280, 135, 33, 33]
Prompts retrieved: 942024 . Total input tokens: 210077244 . Total output tokens: 185294656
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.745882546063513,
    "estimated_duration": 3600.0808837568156,
    "input_throughput": 5472.508711926715,
    "output_throughput": 4825.301864293735,
    "total_throughput": 10297.81057622045,
    "itl": 100.29614338839716,
    "ttft": 1873739.6755372467,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 441,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.815309134791593,
    "arrivals": 314142,
    "finished_requests": 80197,
    "scheduler_time": 116.1740001718297
}
#Debug simulation 
Total elapsed time: 5.745973043143749. Arrivals time: 0.2608285779133439 Scheduler time: 5.33826043875888 Scheduler overhead time: 0.05059889703989029 Adapter cache time: 0.018909017089754343 Engine time: 0.05299409152939916 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_16-16-32/adapters_160_slots_96_rate_1.6-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_16-16-32/adapters_160_slots_96_rate_1.6-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 135, 33, 33, 33, 17280, 33, 135, 17280, 135, 33, 135, 135, 135, 135, 17280, 17280, 17280, 135, 135, 135, 17280, 17280, 33, 17280, 135, 17280, 17280, 17280, 135, 17280, 33, 135, 135, 135, 17280, 33, 33, 17280, 33, 17280, 33, 33, 135, 33, 135, 17280, 33, 33, 135, 33, 33, 33, 33, 33, 17280, 135, 135, 17280, 135, 33, 17280, 17280, 17280, 135, 135, 33, 33, 33, 17280, 33, 135, 135, 33, 17280, 17280, 17280, 33, 33, 17280, 135, 17280, 17280, 33, 17280, 33, 135, 33, 33, 135, 135, 17280, 17280, 17280, 33, 17280, 135, 135, 33, 33, 33, 33, 17280, 135, 17280, 135, 17280, 17280, 17280, 33, 135, 135, 17280, 135, 17280, 33, 33, 33, 135, 135, 135, 17280, 17280, 135, 17280, 33, 135, 135, 33, 17280, 17280, 17280, 17280, 17280, 17280, 135, 135, 135, 135, 135, 17280, 33, 17280, 33, 17280, 135, 33, 135, 33, 33, 135, 135, 135, 17280, 135, 33, 33]
Prompts retrieved: 942024 . Total input tokens: 210077244 . Total output tokens: 185294656
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.27941855089739,
    "estimated_duration": 3600.0363803281703,
    "input_throughput": 4910.63509707879,
    "output_throughput": 4328.9862527943,
    "total_throughput": 9239.62134987309,
    "itl": 79.93342812156438,
    "ttft": 1957020.596134178,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 397,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.924250944238175,
    "arrivals": 314142,
    "finished_requests": 71931,
    "scheduler_time": 120.69258745565931
}
#Debug simulation 
Total elapsed time: 5.279506871011108. Arrivals time: 0.2706024833023548 Scheduler time: 4.834973127581179 Scheduler overhead time: 0.06093689380213618 Adapter cache time: 0.020214843563735485 Engine time: 0.06356706283986568 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-8/adapters_160_slots_96_rate_1.6-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-8/adapters_160_slots_96_rate_1.6-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 66, 33, 33, 33, 17280, 33, 66, 17280, 66, 33, 66, 66, 66, 66, 17280, 17280, 17280, 66, 66, 66, 17280, 17280, 33, 17280, 66, 17280, 17280, 17280, 66, 17280, 33, 66, 66, 66, 17280, 33, 33, 17280, 33, 17280, 33, 33, 66, 33, 66, 17280, 33, 33, 66, 33, 33, 33, 33, 33, 17280, 66, 66, 17280, 66, 33, 17280, 17280, 17280, 66, 66, 33, 33, 33, 17280, 33, 66, 66, 33, 17280, 17280, 17280, 33, 33, 17280, 66, 17280, 17280, 33, 17280, 33, 66, 33, 33, 66, 66, 17280, 17280, 17280, 33, 17280, 66, 66, 33, 33, 33, 33, 17280, 66, 17280, 66, 17280, 17280, 17280, 33, 66, 66, 17280, 66, 17280, 33, 33, 33, 66, 66, 66, 17280, 17280, 66, 17280, 33, 66, 66, 33, 17280, 17280, 17280, 17280, 17280, 17280, 66, 66, 66, 66, 66, 17280, 33, 17280, 33, 17280, 66, 33, 66, 33, 33, 66, 66, 66, 17280, 66, 33, 33]
Prompts retrieved: 938367 . Total input tokens: 209260215 . Total output tokens: 184571794
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.969858692958951,
    "estimated_duration": 3600.084407338425,
    "input_throughput": 5803.010050935208,
    "output_throughput": 5066.945642390106,
    "total_throughput": 10869.955693325313,
    "itl": 108.55849220009316,
    "ttft": 1834264.8469521964,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 350,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3143431611824856,
    "arrivals": 312976,
    "finished_requests": 84695,
    "scheduler_time": 116.09179481550183
}
#Debug simulation 
Total elapsed time: 5.969953783787787. Arrivals time: 0.2964794631116092 Scheduler time: 5.539206218440086 Scheduler overhead time: 0.0471583129838109 Adapter cache time: 0.015164002310484648 Engine time: 0.0492365937680006 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-16/adapters_160_slots_96_rate_1.6-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-16/adapters_160_slots_96_rate_1.6-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 66, 33, 33, 33, 17280, 33, 66, 17280, 66, 33, 66, 66, 66, 66, 17280, 17280, 17280, 66, 66, 66, 17280, 17280, 33, 17280, 66, 17280, 17280, 17280, 66, 17280, 33, 66, 66, 66, 17280, 33, 33, 17280, 33, 17280, 33, 33, 66, 33, 66, 17280, 33, 33, 66, 33, 33, 33, 33, 33, 17280, 66, 66, 17280, 66, 33, 17280, 17280, 17280, 66, 66, 33, 33, 33, 17280, 33, 66, 66, 33, 17280, 17280, 17280, 33, 33, 17280, 66, 17280, 17280, 33, 17280, 33, 66, 33, 33, 66, 66, 17280, 17280, 17280, 33, 17280, 66, 66, 33, 33, 33, 33, 17280, 66, 17280, 66, 17280, 17280, 17280, 33, 66, 66, 17280, 66, 17280, 33, 33, 33, 66, 66, 66, 17280, 17280, 66, 17280, 33, 66, 66, 33, 17280, 17280, 17280, 17280, 17280, 17280, 66, 66, 66, 66, 66, 17280, 33, 17280, 33, 17280, 66, 33, 66, 33, 33, 66, 66, 66, 17280, 66, 33, 33]
Prompts retrieved: 938367 . Total input tokens: 209260215 . Total output tokens: 184571794
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.882405119948089,
    "estimated_duration": 3600.0085530906676,
    "input_throughput": 5594.142264665001,
    "output_throughput": 4884.7528389628,
    "total_throughput": 10478.895103627801,
    "itl": 98.8096022756742,
    "ttft": 1863318.0806244,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 336,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.4587353760004067,
    "arrivals": 312976,
    "finished_requests": 81607,
    "scheduler_time": 117.61340057361414
}
#Debug simulation 
Total elapsed time: 5.882497245911509. Arrivals time: 0.3008099691942334 Scheduler time: 5.434754598885775 Scheduler overhead time: 0.05206322530284524 Adapter cache time: 0.015837365295737982 Engine time: 0.05429812613874674 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-32/adapters_160_slots_96_rate_1.6-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-32/adapters_160_slots_96_rate_1.6-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 66, 33, 33, 33, 17280, 33, 66, 17280, 66, 33, 66, 66, 66, 66, 17280, 17280, 17280, 66, 66, 66, 17280, 17280, 33, 17280, 66, 17280, 17280, 17280, 66, 17280, 33, 66, 66, 66, 17280, 33, 33, 17280, 33, 17280, 33, 33, 66, 33, 66, 17280, 33, 33, 66, 33, 33, 33, 33, 33, 17280, 66, 66, 17280, 66, 33, 17280, 17280, 17280, 66, 66, 33, 33, 33, 17280, 33, 66, 66, 33, 17280, 17280, 17280, 33, 33, 17280, 66, 17280, 17280, 33, 17280, 33, 66, 33, 33, 66, 66, 17280, 17280, 17280, 33, 17280, 66, 66, 33, 33, 33, 33, 17280, 66, 17280, 66, 17280, 17280, 17280, 33, 66, 66, 17280, 66, 17280, 33, 33, 33, 66, 66, 66, 17280, 17280, 66, 17280, 33, 66, 66, 33, 17280, 17280, 17280, 17280, 17280, 17280, 66, 66, 66, 66, 66, 17280, 33, 17280, 33, 17280, 66, 33, 66, 33, 33, 66, 66, 66, 17280, 66, 33, 33]
Prompts retrieved: 938367 . Total input tokens: 209260215 . Total output tokens: 184571794
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.3195107989013195,
    "estimated_duration": 3600.080657574809,
    "input_throughput": 5003.159015924276,
    "output_throughput": 4361.295619020096,
    "total_throughput": 9364.454634944372,
    "itl": 79.00069074308269,
    "ttft": 1949457.7251681224,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 307,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.305056273466917,
    "arrivals": 312976,
    "finished_requests": 72931,
    "scheduler_time": 121.698838653054
}
#Debug simulation 
Total elapsed time: 5.319601997733116. Arrivals time: 0.246045112144202 Scheduler time: 4.901268926914781 Scheduler overhead time: 0.061122324783355 Adapter cache time: 0.017997584771364927 Engine time: 0.06387795228511095 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_8-16-16/adapters_160_slots_96_rate_1.6-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_8-16-16/adapters_160_slots_96_rate_1.6-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 66, 33, 33, 33, 17280, 33, 66, 17280, 66, 33, 66, 66, 66, 66, 17280, 17280, 17280, 66, 66, 66, 17280, 17280, 33, 17280, 66, 17280, 17280, 17280, 66, 17280, 33, 66, 66, 66, 17280, 33, 33, 17280, 33, 17280, 33, 33, 66, 33, 66, 17280, 33, 33, 66, 33, 33, 33, 33, 33, 17280, 66, 66, 17280, 66, 33, 17280, 17280, 17280, 66, 66, 33, 33, 33, 17280, 33, 66, 66, 33, 17280, 17280, 17280, 33, 33, 17280, 66, 17280, 17280, 33, 17280, 33, 66, 33, 33, 66, 66, 17280, 17280, 17280, 33, 17280, 66, 66, 33, 33, 33, 33, 17280, 66, 17280, 66, 17280, 17280, 17280, 33, 66, 66, 17280, 66, 17280, 33, 33, 33, 66, 66, 66, 17280, 17280, 66, 17280, 33, 66, 66, 33, 17280, 17280, 17280, 17280, 17280, 17280, 66, 66, 66, 66, 66, 17280, 33, 17280, 33, 17280, 66, 33, 66, 33, 33, 66, 66, 66, 17280, 66, 33, 33]
Prompts retrieved: 938367 . Total input tokens: 209260215 . Total output tokens: 184571794
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 5.871009182184935,
    "estimated_duration": 3600.005762645086,
    "input_throughput": 5595.777431533523,
    "output_throughput": 4886.441900324888,
    "total_throughput": 10482.21933185841,
    "itl": 98.88119619962846,
    "ttft": 1862853.0836760865,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 336,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3088075108826134,
    "arrivals": 312976,
    "finished_requests": 81634,
    "scheduler_time": 117.60468921957944
}
#Debug simulation 
Total elapsed time: 5.871103461366147. Arrivals time: 0.26105033652856946 Scheduler time: 5.4637106214649975 Scheduler overhead time: 0.05178009904921055 Adapter cache time: 0.01585592469200492 Engine time: 0.05391877610236406 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_8-16-32/adapters_160_slots_96_rate_1.6-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_8-16-32/adapters_160_slots_96_rate_1.6-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 66, 33, 33, 33, 17280, 33, 66, 17280, 66, 33, 66, 66, 66, 66, 17280, 17280, 17280, 66, 66, 66, 17280, 17280, 33, 17280, 66, 17280, 17280, 17280, 66, 17280, 33, 66, 66, 66, 17280, 33, 33, 17280, 33, 17280, 33, 33, 66, 33, 66, 17280, 33, 33, 66, 33, 33, 33, 33, 33, 17280, 66, 66, 17280, 66, 33, 17280, 17280, 17280, 66, 66, 33, 33, 33, 17280, 33, 66, 66, 33, 17280, 17280, 17280, 33, 33, 17280, 66, 17280, 17280, 33, 17280, 33, 66, 33, 33, 66, 66, 17280, 17280, 17280, 33, 17280, 66, 66, 33, 33, 33, 33, 17280, 66, 17280, 66, 17280, 17280, 17280, 33, 66, 66, 17280, 66, 17280, 33, 33, 33, 66, 66, 66, 17280, 17280, 66, 17280, 33, 66, 66, 33, 17280, 17280, 17280, 17280, 17280, 17280, 66, 66, 66, 66, 66, 17280, 33, 17280, 33, 17280, 66, 33, 66, 33, 33, 66, 66, 66, 17280, 66, 33, 33]
Prompts retrieved: 938367 . Total input tokens: 209260215 . Total output tokens: 184571794
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 5.326791541650891,
    "estimated_duration": 3600.0360487506973,
    "input_throughput": 5003.0285130756665,
    "output_throughput": 4361.164940403421,
    "total_throughput": 9364.193453479087,
    "itl": 79.00170819689586,
    "ttft": 1949453.0523630804,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 307,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.284758790158676,
    "arrivals": 312976,
    "finished_requests": 72928,
    "scheduler_time": 121.69666408915944
}
#Debug simulation 
Total elapsed time: 5.32688158005476. Arrivals time: 0.2729491596110165 Scheduler time: 4.881074038799852 Scheduler overhead time: 0.0615377863869071 Adapter cache time: 0.018043206073343754 Engine time: 0.06393338181078434 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_16-16-16/adapters_160_slots_96_rate_1.6-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_16-16-16/adapters_160_slots_96_rate_1.6-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 66, 33, 33, 33, 17280, 33, 66, 17280, 66, 33, 66, 66, 66, 66, 17280, 17280, 17280, 66, 66, 66, 17280, 17280, 33, 17280, 66, 17280, 17280, 17280, 66, 17280, 33, 66, 66, 66, 17280, 33, 33, 17280, 33, 17280, 33, 33, 66, 33, 66, 17280, 33, 33, 66, 33, 33, 33, 33, 33, 17280, 66, 66, 17280, 66, 33, 17280, 17280, 17280, 66, 66, 33, 33, 33, 17280, 33, 66, 66, 33, 17280, 17280, 17280, 33, 33, 17280, 66, 17280, 17280, 33, 17280, 33, 66, 33, 33, 66, 66, 17280, 17280, 17280, 33, 17280, 66, 66, 33, 33, 33, 33, 17280, 66, 17280, 66, 17280, 17280, 17280, 33, 66, 66, 17280, 66, 17280, 33, 33, 33, 66, 66, 66, 17280, 17280, 66, 17280, 33, 66, 66, 33, 17280, 17280, 17280, 17280, 17280, 17280, 66, 66, 66, 66, 66, 17280, 33, 17280, 33, 17280, 66, 33, 66, 33, 33, 66, 66, 66, 17280, 66, 33, 33]
Prompts retrieved: 938367 . Total input tokens: 209260215 . Total output tokens: 184571794
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.820499722845852,
    "estimated_duration": 3600.0392657039893,
    "input_throughput": 5595.782299352401,
    "output_throughput": 4886.884753619399,
    "total_throughput": 10482.6670529718,
    "itl": 98.87508329757924,
    "ttft": 1862769.7799897762,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 336,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.144997436031691,
    "arrivals": 312976,
    "finished_requests": 81642,
    "scheduler_time": 117.6105093997053
}
#Debug simulation 
Total elapsed time: 5.820591695141047. Arrivals time: 0.269555046223104 Scheduler time: 5.406130827963352 Scheduler overhead time: 0.05123128229752183 Adapter cache time: 0.015713762491941452 Engine time: 0.05345624499022961 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_16-16-32/adapters_160_slots_96_rate_1.6-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_16-16-32/adapters_160_slots_96_rate_1.6-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 66, 33, 33, 33, 17280, 33, 66, 17280, 66, 33, 66, 66, 66, 66, 17280, 17280, 17280, 66, 66, 66, 17280, 17280, 33, 17280, 66, 17280, 17280, 17280, 66, 17280, 33, 66, 66, 66, 17280, 33, 33, 17280, 33, 17280, 33, 33, 66, 33, 66, 17280, 33, 33, 66, 33, 33, 33, 33, 33, 17280, 66, 66, 17280, 66, 33, 17280, 17280, 17280, 66, 66, 33, 33, 33, 17280, 33, 66, 66, 33, 17280, 17280, 17280, 33, 33, 17280, 66, 17280, 17280, 33, 17280, 33, 66, 33, 33, 66, 66, 17280, 17280, 17280, 33, 17280, 66, 66, 33, 33, 33, 33, 17280, 66, 17280, 66, 17280, 17280, 17280, 33, 66, 66, 17280, 66, 17280, 33, 33, 33, 66, 66, 66, 17280, 17280, 66, 17280, 33, 66, 66, 33, 17280, 17280, 17280, 17280, 17280, 17280, 66, 66, 66, 66, 66, 17280, 33, 17280, 33, 17280, 66, 33, 66, 33, 33, 66, 66, 66, 17280, 66, 33, 33]
Prompts retrieved: 938367 . Total input tokens: 209260215 . Total output tokens: 184571794
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.293824192136526,
    "estimated_duration": 3600.026317072353,
    "input_throughput": 5003.102314720665,
    "output_throughput": 4361.249229080136,
    "total_throughput": 9364.351543800802,
    "itl": 79.00165147151753,
    "ttft": 1949404.1518968022,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 307,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.262597252260903,
    "arrivals": 312976,
    "finished_requests": 72929,
    "scheduler_time": 121.69713864905528
}
#Debug simulation 
Total elapsed time: 5.293922023847699. Arrivals time: 0.24669751804322004 Scheduler time: 4.875562347937375 Scheduler overhead time: 0.06102467607706785 Adapter cache time: 0.017645059619098902 Engine time: 0.06369910901412368 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_8-8-8/adapters_160_slots_96_rate_0.8-0.4-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_8-8-8/adapters_160_slots_96_rate_0.8-0.4-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [53 53 54]
Adapter prompts. [1080, 8640, 1080, 1080, 4320, 1080, 1080, 1080, 8640, 1080, 4320, 8640, 4320, 1080, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 1080, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 1080, 4320, 4320, 4320, 8640, 1080, 1080, 8640, 1080, 8640, 1080, 1080, 4320, 1080, 4320, 8640, 1080, 1080, 4320, 1080, 1080, 1080, 1080, 1080, 8640, 4320, 4320, 8640, 4320, 1080, 8640, 8640, 8640, 4320, 4320, 1080, 1080, 1080, 8640, 1080, 4320, 4320, 1080, 8640, 8640, 8640, 1080, 1080, 8640, 4320, 8640, 8640, 1080, 8640, 1080, 4320, 1080, 1080, 4320, 4320, 8640, 8640, 8640, 1080, 8640, 4320, 4320, 1080, 1080, 1080, 1080, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 1080, 4320, 4320, 8640, 4320, 8640, 1080, 1080, 1080, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 1080, 4320, 4320, 1080, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 1080, 8640, 1080, 8640, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 8640, 4320, 1080, 1080]
Prompts retrieved: 752760 . Total input tokens: 167863645 . Total output tokens: 147998204
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 7.850094512104988,
    "estimated_duration": 3600.0585666817105,
    "input_throughput": 4695.674997193618,
    "output_throughput": 4093.2870193783297,
    "total_throughput": 8788.962016571946,
    "itl": 133.51570673679714,
    "ttft": 1917765.559230814,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 845,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.58748563199781,
    "arrivals": 250580,
    "finished_requests": 68459,
    "scheduler_time": 93.51069798174831
}
#Debug simulation 
Total elapsed time: 7.850162212271243. Arrivals time: 0.28407403640449047 Scheduler time: 7.443684863392264 Scheduler overhead time: 0.04091407498344779 Adapter cache time: 0.020306101068854332 Engine time: 0.04211633512750268 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_8-8-16/adapters_160_slots_96_rate_0.8-0.4-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_8-8-16/adapters_160_slots_96_rate_0.8-0.4-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [53 53 54]
Adapter prompts. [1080, 8640, 1080, 1080, 4320, 1080, 1080, 1080, 8640, 1080, 4320, 8640, 4320, 1080, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 1080, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 1080, 4320, 4320, 4320, 8640, 1080, 1080, 8640, 1080, 8640, 1080, 1080, 4320, 1080, 4320, 8640, 1080, 1080, 4320, 1080, 1080, 1080, 1080, 1080, 8640, 4320, 4320, 8640, 4320, 1080, 8640, 8640, 8640, 4320, 4320, 1080, 1080, 1080, 8640, 1080, 4320, 4320, 1080, 8640, 8640, 8640, 1080, 1080, 8640, 4320, 8640, 8640, 1080, 8640, 1080, 4320, 1080, 1080, 4320, 4320, 8640, 8640, 8640, 1080, 8640, 4320, 4320, 1080, 1080, 1080, 1080, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 1080, 4320, 4320, 8640, 4320, 8640, 1080, 1080, 1080, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 1080, 4320, 4320, 1080, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 1080, 8640, 1080, 8640, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 8640, 4320, 1080, 1080]
Prompts retrieved: 752760 . Total input tokens: 167863645 . Total output tokens: 147998204
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 6.665173945948482,
    "estimated_duration": 3600.0329489238784,
    "input_throughput": 4507.477634295151,
    "output_throughput": 3934.5848221289452,
    "total_throughput": 8442.062456424097,
    "itl": 121.92313311807406,
    "ttft": 1949908.2122995043,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1139,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.316616344214413,
    "arrivals": 250580,
    "finished_requests": 65753,
    "scheduler_time": 94.42132236682008
}
#Debug simulation 
Total elapsed time: 6.665266954340041. Arrivals time: 0.2424756959080696 Scheduler time: 6.287138272076845 Scheduler overhead time: 0.044043127447366714 Adapter cache time: 0.025912384502589703 Engine time: 0.04506537597626448 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_8-8-32/adapters_160_slots_96_rate_0.8-0.4-0.1_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_8-8-32/adapters_160_slots_96_rate_0.8-0.4-0.1_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [53 53 54]
Adapter prompts. [1080, 8640, 1080, 1080, 4320, 1080, 1080, 1080, 8640, 1080, 4320, 8640, 4320, 1080, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 1080, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 1080, 4320, 4320, 4320, 8640, 1080, 1080, 8640, 1080, 8640, 1080, 1080, 4320, 1080, 4320, 8640, 1080, 1080, 4320, 1080, 1080, 1080, 1080, 1080, 8640, 4320, 4320, 8640, 4320, 1080, 8640, 8640, 8640, 4320, 4320, 1080, 1080, 1080, 8640, 1080, 4320, 4320, 1080, 8640, 8640, 8640, 1080, 1080, 8640, 4320, 8640, 8640, 1080, 8640, 1080, 4320, 1080, 1080, 4320, 4320, 8640, 8640, 8640, 1080, 8640, 4320, 4320, 1080, 1080, 1080, 1080, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 1080, 4320, 4320, 8640, 4320, 8640, 1080, 1080, 1080, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 1080, 4320, 4320, 1080, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 1080, 8640, 1080, 8640, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 8640, 4320, 1080, 1080]
Prompts retrieved: 752760 . Total input tokens: 167863645 . Total output tokens: 147998204
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.192201158963144,
    "estimated_duration": 3600.089457648711,
    "input_throughput": 3999.4253391147136,
    "output_throughput": 3492.182110444314,
    "total_throughput": 7491.607449559027,
    "itl": 98.19382399055543,
    "ttft": 2045730.7574387563,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2325,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.423495929254983,
    "arrivals": 250580,
    "finished_requests": 58305,
    "scheduler_time": 96.94190304502463
}
#Debug simulation 
Total elapsed time: 5.192289540078491. Arrivals time: 0.24256353545933962 Scheduler time: 4.775237801950425 Scheduler overhead time: 0.0520145813934505 Adapter cache time: 0.04510180093348026 Engine time: 0.05285574169829488 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_8-16-16/adapters_160_slots_96_rate_0.8-0.4-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_8-16-16/adapters_160_slots_96_rate_0.8-0.4-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [53 53 54]
Adapter prompts. [1080, 8640, 1080, 1080, 4320, 1080, 1080, 1080, 8640, 1080, 4320, 8640, 4320, 1080, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 1080, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 1080, 4320, 4320, 4320, 8640, 1080, 1080, 8640, 1080, 8640, 1080, 1080, 4320, 1080, 4320, 8640, 1080, 1080, 4320, 1080, 1080, 1080, 1080, 1080, 8640, 4320, 4320, 8640, 4320, 1080, 8640, 8640, 8640, 4320, 4320, 1080, 1080, 1080, 8640, 1080, 4320, 4320, 1080, 8640, 8640, 8640, 1080, 1080, 8640, 4320, 8640, 8640, 1080, 8640, 1080, 4320, 1080, 1080, 4320, 4320, 8640, 8640, 8640, 1080, 8640, 4320, 4320, 1080, 1080, 1080, 1080, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 1080, 4320, 4320, 8640, 4320, 8640, 1080, 1080, 1080, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 1080, 4320, 4320, 1080, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 1080, 8640, 1080, 8640, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 8640, 4320, 1080, 1080]
Prompts retrieved: 752760 . Total input tokens: 167863645 . Total output tokens: 147998204
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 6.62288469215855,
    "estimated_duration": 3600.0085894670087,
    "input_throughput": 4510.157850041095,
    "output_throughput": 3934.4097793102783,
    "total_throughput": 8444.567629351373,
    "itl": 121.81033548958563,
    "ttft": 1950370.9342645279,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1148,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.870147419366974,
    "arrivals": 250580,
    "finished_requests": 65779,
    "scheduler_time": 94.44304305855732
}
#Debug simulation 
Total elapsed time: 6.6230169190093875. Arrivals time: 0.26529781660065055 Scheduler time: 6.221485314425081 Scheduler overhead time: 0.04404478846117854 Adapter cache time: 0.025821504183113575 Engine time: 0.04570880113169551 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_8-16-32/adapters_160_slots_96_rate_0.8-0.4-0.1_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_8-16-32/adapters_160_slots_96_rate_0.8-0.4-0.1_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [53 53 54]
Adapter prompts. [1080, 8640, 1080, 1080, 4320, 1080, 1080, 1080, 8640, 1080, 4320, 8640, 4320, 1080, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 1080, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 1080, 4320, 4320, 4320, 8640, 1080, 1080, 8640, 1080, 8640, 1080, 1080, 4320, 1080, 4320, 8640, 1080, 1080, 4320, 1080, 1080, 1080, 1080, 1080, 8640, 4320, 4320, 8640, 4320, 1080, 8640, 8640, 8640, 4320, 4320, 1080, 1080, 1080, 8640, 1080, 4320, 4320, 1080, 8640, 8640, 8640, 1080, 1080, 8640, 4320, 8640, 8640, 1080, 8640, 1080, 4320, 1080, 1080, 4320, 4320, 8640, 8640, 8640, 1080, 8640, 4320, 4320, 1080, 1080, 1080, 1080, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 1080, 4320, 4320, 8640, 4320, 8640, 1080, 1080, 1080, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 1080, 4320, 4320, 1080, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 1080, 8640, 1080, 8640, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 8640, 4320, 1080, 1080]
Prompts retrieved: 752760 . Total input tokens: 167863645 . Total output tokens: 147998204
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 5.1126178009435534,
    "estimated_duration": 3600.051442617922,
    "input_throughput": 3986.8730291150164,
    "output_throughput": 3482.0024657437643,
    "total_throughput": 7468.875494858781,
    "itl": 97.753664701294,
    "ttft": 2047474.3820841864,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2352,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.46819175726718,
    "arrivals": 250580,
    "finished_requests": 58125,
    "scheduler_time": 97.00956970928752
}
#Debug simulation 
Total elapsed time: 5.112723211757839. Arrivals time: 0.24141050595790148 Scheduler time: 4.696326427627355 Scheduler overhead time: 0.05169199639931321 Adapter cache time: 0.04586099926382303 Engine time: 0.05299904150888324 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_16-16-16/adapters_160_slots_96_rate_0.8-0.4-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_16-16-16/adapters_160_slots_96_rate_0.8-0.4-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [53 53 54]
Adapter prompts. [1080, 8640, 1080, 1080, 4320, 1080, 1080, 1080, 8640, 1080, 4320, 8640, 4320, 1080, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 1080, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 1080, 4320, 4320, 4320, 8640, 1080, 1080, 8640, 1080, 8640, 1080, 1080, 4320, 1080, 4320, 8640, 1080, 1080, 4320, 1080, 1080, 1080, 1080, 1080, 8640, 4320, 4320, 8640, 4320, 1080, 8640, 8640, 8640, 4320, 4320, 1080, 1080, 1080, 8640, 1080, 4320, 4320, 1080, 8640, 8640, 8640, 1080, 1080, 8640, 4320, 8640, 8640, 1080, 8640, 1080, 4320, 1080, 1080, 4320, 4320, 8640, 8640, 8640, 1080, 8640, 4320, 4320, 1080, 1080, 1080, 1080, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 1080, 4320, 4320, 8640, 4320, 8640, 1080, 1080, 1080, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 1080, 4320, 4320, 1080, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 1080, 8640, 1080, 8640, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 8640, 4320, 1080, 1080]
Prompts retrieved: 752760 . Total input tokens: 167863645 . Total output tokens: 147998204
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 6.705622921697795,
    "estimated_duration": 3600.067596425145,
    "input_throughput": 4514.156349768948,
    "output_throughput": 3938.475770310391,
    "total_throughput": 8452.632120079337,
    "itl": 121.97606245523143,
    "ttft": 1949436.6181840666,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1081,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.901018536756712,
    "arrivals": 250580,
    "finished_requests": 65823,
    "scheduler_time": 94.44471478168008
}
#Debug simulation 
Total elapsed time: 6.705715251155198. Arrivals time: 0.26121111027896404 Scheduler time: 6.311698795761913 Scheduler overhead time: 0.043713029474020004 Adapter cache time: 0.02411304460838437 Engine time: 0.04454406630247831 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_16-16-32/adapters_160_slots_96_rate_0.8-0.4-0.1_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_16-16-32/adapters_160_slots_96_rate_0.8-0.4-0.1_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [53 53 54]
Adapter prompts. [1080, 8640, 1080, 1080, 4320, 1080, 1080, 1080, 8640, 1080, 4320, 8640, 4320, 1080, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 1080, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 1080, 4320, 4320, 4320, 8640, 1080, 1080, 8640, 1080, 8640, 1080, 1080, 4320, 1080, 4320, 8640, 1080, 1080, 4320, 1080, 1080, 1080, 1080, 1080, 8640, 4320, 4320, 8640, 4320, 1080, 8640, 8640, 8640, 4320, 4320, 1080, 1080, 1080, 8640, 1080, 4320, 4320, 1080, 8640, 8640, 8640, 1080, 1080, 8640, 4320, 8640, 8640, 1080, 8640, 1080, 4320, 1080, 1080, 4320, 4320, 8640, 8640, 8640, 1080, 8640, 4320, 4320, 1080, 1080, 1080, 1080, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 1080, 4320, 4320, 8640, 4320, 8640, 1080, 1080, 1080, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 1080, 4320, 4320, 1080, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 1080, 8640, 1080, 8640, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 8640, 4320, 1080, 1080]
Prompts retrieved: 752760 . Total input tokens: 167863645 . Total output tokens: 147998204
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.112999488133937,
    "estimated_duration": 3600.079494477654,
    "input_throughput": 4001.9902399656385,
    "output_throughput": 3494.1833976988814,
    "total_throughput": 7496.173637664519,
    "itl": 98.2794842191823,
    "ttft": 2045109.0350037932,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2321,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.06549933740848,
    "arrivals": 250580,
    "finished_requests": 58329,
    "scheduler_time": 96.93806978113912
}
#Debug simulation 
Total elapsed time: 5.113090716302395. Arrivals time: 0.2424569451250136 Scheduler time: 4.696524136699736 Scheduler overhead time: 0.0515642655082047 Adapter cache time: 0.04563260776922107 Engine time: 0.052572653628885746 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_8-8-8/adapters_160_slots_96_rate_0.8-0.4-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_8-8-8/adapters_160_slots_96_rate_0.8-0.4-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [53 53 54]
Adapter prompts. [540, 8640, 540, 540, 4320, 540, 540, 540, 8640, 540, 4320, 8640, 4320, 540, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 540, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 540, 4320, 4320, 4320, 8640, 540, 540, 8640, 540, 8640, 540, 540, 4320, 540, 4320, 8640, 540, 540, 4320, 540, 540, 540, 540, 540, 8640, 4320, 4320, 8640, 4320, 540, 8640, 8640, 8640, 4320, 4320, 540, 540, 540, 8640, 540, 4320, 4320, 540, 8640, 8640, 8640, 540, 540, 8640, 4320, 8640, 8640, 540, 8640, 540, 4320, 540, 540, 4320, 4320, 8640, 8640, 8640, 540, 8640, 4320, 4320, 540, 540, 540, 540, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 540, 4320, 4320, 8640, 4320, 8640, 540, 540, 540, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 540, 4320, 4320, 540, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 540, 8640, 540, 8640, 4320, 540, 4320, 540, 540, 4320, 4320, 4320, 8640, 4320, 540, 540]
Prompts retrieved: 724140 . Total input tokens: 161466883 . Total output tokens: 142426645
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 6.98024589382112,
    "estimated_duration": 3600.1250708733787,
    "input_throughput": 4721.883730521619,
    "output_throughput": 4102.211648001778,
    "total_throughput": 8824.095378523398,
    "itl": 134.00209109400075,
    "ttft": 1901426.0413710317,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 771,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.0981673636334985,
    "arrivals": 240851,
    "finished_requests": 68862,
    "scheduler_time": 93.32402332760203
}
#Debug simulation 
Total elapsed time: 6.980378638021648. Arrivals time: 0.24602433713153005 Scheduler time: 6.613897040486336 Scheduler overhead time: 0.04061927134171128 Adapter cache time: 0.01876951241865754 Engine time: 0.04197447746992111 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_8-8-16/adapters_160_slots_96_rate_0.8-0.4-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_8-8-16/adapters_160_slots_96_rate_0.8-0.4-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [53 53 54]
Adapter prompts. [540, 8640, 540, 540, 4320, 540, 540, 540, 8640, 540, 4320, 8640, 4320, 540, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 540, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 540, 4320, 4320, 4320, 8640, 540, 540, 8640, 540, 8640, 540, 540, 4320, 540, 4320, 8640, 540, 540, 4320, 540, 540, 540, 540, 540, 8640, 4320, 4320, 8640, 4320, 540, 8640, 8640, 8640, 4320, 4320, 540, 540, 540, 8640, 540, 4320, 4320, 540, 8640, 8640, 8640, 540, 540, 8640, 4320, 8640, 8640, 540, 8640, 540, 4320, 540, 540, 4320, 4320, 8640, 8640, 8640, 540, 8640, 4320, 4320, 540, 540, 540, 540, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 540, 4320, 4320, 8640, 4320, 8640, 540, 540, 540, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 540, 4320, 4320, 540, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 540, 8640, 540, 8640, 4320, 540, 4320, 540, 540, 4320, 4320, 4320, 8640, 4320, 540, 540]
Prompts retrieved: 724140 . Total input tokens: 161466883 . Total output tokens: 142426645
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 6.198163327295333,
    "estimated_duration": 3600.0290633836203,
    "input_throughput": 4535.5139396162385,
    "output_throughput": 3940.385410851998,
    "total_throughput": 8475.899350468237,
    "itl": 121.951090932634,
    "ttft": 1935780.0126961858,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1042,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.594647660953934,
    "arrivals": 240851,
    "finished_requests": 66154,
    "scheduler_time": 94.26783738131877
}
#Debug simulation 
Total elapsed time: 6.198264595121145. Arrivals time: 0.2395859370008111 Scheduler time: 5.82631165208295 Scheduler overhead time: 0.04389063734561205 Adapter cache time: 0.023597932886332273 Engine time: 0.04436117131263018 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_8-8-32/adapters_160_slots_96_rate_0.8-0.4-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_8-8-32/adapters_160_slots_96_rate_0.8-0.4-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [53 53 54]
Adapter prompts. [540, 8640, 540, 540, 4320, 540, 540, 540, 8640, 540, 4320, 8640, 4320, 540, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 540, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 540, 4320, 4320, 4320, 8640, 540, 540, 8640, 540, 8640, 540, 540, 4320, 540, 4320, 8640, 540, 540, 4320, 540, 540, 540, 540, 540, 8640, 4320, 4320, 8640, 4320, 540, 8640, 8640, 8640, 4320, 4320, 540, 540, 540, 8640, 540, 4320, 4320, 540, 8640, 8640, 8640, 540, 540, 8640, 4320, 8640, 8640, 540, 8640, 540, 4320, 540, 540, 4320, 4320, 8640, 8640, 8640, 540, 8640, 4320, 4320, 540, 540, 540, 540, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 540, 4320, 4320, 8640, 4320, 8640, 540, 540, 540, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 540, 4320, 4320, 540, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 540, 8640, 540, 8640, 4320, 540, 4320, 540, 540, 4320, 4320, 4320, 8640, 4320, 540, 540]
Prompts retrieved: 724140 . Total input tokens: 161466883 . Total output tokens: 142426645
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.087532489094883,
    "estimated_duration": 3600.0389910845147,
    "input_throughput": 4002.7399802297614,
    "output_throughput": 3492.016067362886,
    "total_throughput": 7494.7560475926475,
    "itl": 98.06028240021867,
    "ttft": 2031471.337700901,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2245,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.826965444804884,
    "arrivals": 240851,
    "finished_requests": 58365,
    "scheduler_time": 96.79454453367674
}
#Debug simulation 
Total elapsed time: 5.087600274011493. Arrivals time: 0.21599600417539477 Scheduler time: 4.698869651183486 Scheduler overhead time: 0.051515099592506886 Adapter cache time: 0.043840378522872925 Engine time: 0.05301339039579034 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_8-16-16/adapters_160_slots_96_rate_0.8-0.4-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_8-16-16/adapters_160_slots_96_rate_0.8-0.4-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [53 53 54]
Adapter prompts. [540, 8640, 540, 540, 4320, 540, 540, 540, 8640, 540, 4320, 8640, 4320, 540, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 540, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 540, 4320, 4320, 4320, 8640, 540, 540, 8640, 540, 8640, 540, 540, 4320, 540, 4320, 8640, 540, 540, 4320, 540, 540, 540, 540, 540, 8640, 4320, 4320, 8640, 4320, 540, 8640, 8640, 8640, 4320, 4320, 540, 540, 540, 8640, 540, 4320, 4320, 540, 8640, 8640, 8640, 540, 540, 8640, 4320, 8640, 8640, 540, 8640, 540, 4320, 540, 540, 4320, 4320, 8640, 8640, 8640, 540, 8640, 4320, 4320, 540, 540, 540, 540, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 540, 4320, 4320, 8640, 4320, 8640, 540, 540, 540, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 540, 4320, 4320, 540, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 540, 8640, 540, 8640, 4320, 540, 4320, 540, 540, 4320, 4320, 4320, 8640, 4320, 540, 540]
Prompts retrieved: 724140 . Total input tokens: 161466883 . Total output tokens: 142426645
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 6.244850101880729,
    "estimated_duration": 3600.0468229298504,
    "input_throughput": 4542.1906448127975,
    "output_throughput": 3944.4470303981657,
    "total_throughput": 8486.637675210963,
    "itl": 122.23453843713384,
    "ttft": 1935047.4168632487,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1014,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.949455627584819,
    "arrivals": 240851,
    "finished_requests": 66228,
    "scheduler_time": 94.25018192206333
}
#Debug simulation 
Total elapsed time: 6.244939224794507. Arrivals time: 0.240894319023937 Scheduler time: 5.870085381437093 Scheduler overhead time: 0.04422436747699976 Adapter cache time: 0.023641569074243307 Engine time: 0.045547330286353827 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_8-16-32/adapters_160_slots_96_rate_0.8-0.4-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_8-16-32/adapters_160_slots_96_rate_0.8-0.4-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [53 53 54]
Adapter prompts. [540, 8640, 540, 540, 4320, 540, 540, 540, 8640, 540, 4320, 8640, 4320, 540, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 540, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 540, 4320, 4320, 4320, 8640, 540, 540, 8640, 540, 8640, 540, 540, 4320, 540, 4320, 8640, 540, 540, 4320, 540, 540, 540, 540, 540, 8640, 4320, 4320, 8640, 4320, 540, 8640, 8640, 8640, 4320, 4320, 540, 540, 540, 8640, 540, 4320, 4320, 540, 8640, 8640, 8640, 540, 540, 8640, 4320, 8640, 8640, 540, 8640, 540, 4320, 540, 540, 4320, 4320, 8640, 8640, 8640, 540, 8640, 4320, 4320, 540, 540, 540, 540, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 540, 4320, 4320, 8640, 4320, 8640, 540, 540, 540, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 540, 4320, 4320, 540, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 540, 8640, 540, 8640, 4320, 540, 4320, 540, 540, 4320, 4320, 4320, 8640, 4320, 540, 540]
Prompts retrieved: 724140 . Total input tokens: 161466883 . Total output tokens: 142426645
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 4.884251898154616,
    "estimated_duration": 3600.1080189099553,
    "input_throughput": 4017.0933549873903,
    "output_throughput": 3503.934030240416,
    "total_throughput": 7521.027385227807,
    "itl": 98.55181299011282,
    "ttft": 2029990.1775752632,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2225,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.514869431182483,
    "arrivals": 240851,
    "finished_requests": 58576,
    "scheduler_time": 96.7191604868385
}
#Debug simulation 
Total elapsed time: 4.884346839040518. Arrivals time: 0.21457695495337248 Scheduler time: 4.497115577571094 Scheduler overhead time: 0.05150222918018699 Adapter cache time: 0.044004861265420914 Engine time: 0.052905133459717035 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_16-16-16/adapters_160_slots_96_rate_0.8-0.4-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_16-16-16/adapters_160_slots_96_rate_0.8-0.4-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [53 53 54]
Adapter prompts. [540, 8640, 540, 540, 4320, 540, 540, 540, 8640, 540, 4320, 8640, 4320, 540, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 540, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 540, 4320, 4320, 4320, 8640, 540, 540, 8640, 540, 8640, 540, 540, 4320, 540, 4320, 8640, 540, 540, 4320, 540, 540, 540, 540, 540, 8640, 4320, 4320, 8640, 4320, 540, 8640, 8640, 8640, 4320, 4320, 540, 540, 540, 8640, 540, 4320, 4320, 540, 8640, 8640, 8640, 540, 540, 8640, 4320, 8640, 8640, 540, 8640, 540, 4320, 540, 540, 4320, 4320, 8640, 8640, 8640, 540, 8640, 4320, 4320, 540, 540, 540, 540, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 540, 4320, 4320, 8640, 4320, 8640, 540, 540, 540, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 540, 4320, 4320, 540, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 540, 8640, 540, 8640, 4320, 540, 4320, 540, 540, 4320, 4320, 4320, 8640, 4320, 540, 540]
Prompts retrieved: 724140 . Total input tokens: 161466883 . Total output tokens: 142426645
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 6.269061121158302,
    "estimated_duration": 3600.1210933507364,
    "input_throughput": 4544.190757976315,
    "output_throughput": 3947.1519517067504,
    "total_throughput": 8491.342709683066,
    "itl": 122.35558819561152,
    "ttft": 1934428.8004009775,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1017,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.4924475965602,
    "arrivals": 240851,
    "finished_requests": 66268,
    "scheduler_time": 94.24907246120576
}
#Debug simulation 
Total elapsed time: 6.269151567015797. Arrivals time: 0.24463496822863817 Scheduler time: 5.891505151055753 Scheduler overhead time: 0.04390853876248002 Adapter cache time: 0.023577438201755285 Engine time: 0.04493598127737641 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_16-16-32/adapters_160_slots_96_rate_0.8-0.4-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_16-16-32/adapters_160_slots_96_rate_0.8-0.4-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [53 53 54]
Adapter prompts. [540, 8640, 540, 540, 4320, 540, 540, 540, 8640, 540, 4320, 8640, 4320, 540, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 540, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 540, 4320, 4320, 4320, 8640, 540, 540, 8640, 540, 8640, 540, 540, 4320, 540, 4320, 8640, 540, 540, 4320, 540, 540, 540, 540, 540, 8640, 4320, 4320, 8640, 4320, 540, 8640, 8640, 8640, 4320, 4320, 540, 540, 540, 8640, 540, 4320, 4320, 540, 8640, 8640, 8640, 540, 540, 8640, 4320, 8640, 8640, 540, 8640, 540, 4320, 540, 540, 4320, 4320, 8640, 8640, 8640, 540, 8640, 4320, 4320, 540, 540, 540, 540, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 540, 4320, 4320, 8640, 4320, 8640, 540, 540, 540, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 540, 4320, 4320, 540, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 540, 8640, 540, 8640, 4320, 540, 4320, 540, 540, 4320, 4320, 4320, 8640, 4320, 540, 540]
Prompts retrieved: 724140 . Total input tokens: 161466883 . Total output tokens: 142426645
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 4.888114238157868,
    "estimated_duration": 3600.0402110737627,
    "input_throughput": 4010.950476492925,
    "output_throughput": 3499.4998003764986,
    "total_throughput": 7510.450276869424,
    "itl": 98.35993353401372,
    "ttft": 2030294.5429974117,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2228,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.37723539840403,
    "arrivals": 240851,
    "finished_requests": 58498,
    "scheduler_time": 96.75441847310466
}
#Debug simulation 
Total elapsed time: 4.888203262817115. Arrivals time: 0.21844996698200703 Scheduler time: 4.496565278619528 Scheduler overhead time: 0.051757038570940495 Adapter cache time: 0.04406874533742666 Engine time: 0.05294224200770259 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_8-8-8/adapters_160_slots_96_rate_0.8-0.4-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_8-8-8/adapters_160_slots_96_rate_0.8-0.4-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [53 53 54]
Adapter prompts. [270, 8640, 270, 270, 4320, 270, 270, 270, 8640, 270, 4320, 8640, 4320, 270, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 270, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 270, 4320, 4320, 4320, 8640, 270, 270, 8640, 270, 8640, 270, 270, 4320, 270, 4320, 8640, 270, 270, 4320, 270, 270, 270, 270, 270, 8640, 4320, 4320, 8640, 4320, 270, 8640, 8640, 8640, 4320, 4320, 270, 270, 270, 8640, 270, 4320, 4320, 270, 8640, 8640, 8640, 270, 270, 8640, 4320, 8640, 8640, 270, 8640, 270, 4320, 270, 270, 4320, 4320, 8640, 8640, 8640, 270, 8640, 4320, 4320, 270, 270, 270, 270, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 270, 4320, 4320, 8640, 4320, 8640, 270, 270, 270, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 270, 4320, 4320, 270, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 270, 8640, 270, 8640, 4320, 270, 4320, 270, 270, 4320, 4320, 4320, 8640, 4320, 270, 270]
Prompts retrieved: 709830 . Total input tokens: 158244851 . Total output tokens: 139627461
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 6.486284949351102,
    "estimated_duration": 3600.015395758838,
    "input_throughput": 4714.247061274761,
    "output_throughput": 4096.264426361321,
    "total_throughput": 8810.511487636082,
    "itl": 133.4247020228649,
    "ttft": 1899291.1163538275,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 796,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.263477589432252,
    "arrivals": 236027,
    "finished_requests": 68657,
    "scheduler_time": 93.2730969988341
}
#Debug simulation 
Total elapsed time: 6.486376343294978. Arrivals time: 0.2464999295771122 Scheduler time: 6.119310581125319 Scheduler overhead time: 0.04080436611548066 Adapter cache time: 0.019221439957618713 Engine time: 0.04139853687956929 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_8-8-16/adapters_160_slots_96_rate_0.8-0.4-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_8-8-16/adapters_160_slots_96_rate_0.8-0.4-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [53 53 54]
Adapter prompts. [270, 8640, 270, 270, 4320, 270, 270, 270, 8640, 270, 4320, 8640, 4320, 270, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 270, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 270, 4320, 4320, 4320, 8640, 270, 270, 8640, 270, 8640, 270, 270, 4320, 270, 4320, 8640, 270, 270, 4320, 270, 270, 270, 270, 270, 8640, 4320, 4320, 8640, 4320, 270, 8640, 8640, 8640, 4320, 4320, 270, 270, 270, 8640, 270, 4320, 4320, 270, 8640, 8640, 8640, 270, 270, 8640, 4320, 8640, 8640, 270, 8640, 270, 4320, 270, 270, 4320, 4320, 8640, 8640, 8640, 270, 8640, 4320, 4320, 270, 270, 270, 270, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 270, 4320, 4320, 8640, 4320, 8640, 270, 270, 270, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 270, 4320, 4320, 270, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 270, 8640, 270, 8640, 4320, 270, 4320, 270, 270, 4320, 4320, 4320, 8640, 4320, 270, 270]
Prompts retrieved: 709830 . Total input tokens: 158244851 . Total output tokens: 139627461
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.742058574222028,
    "estimated_duration": 3600.105174786613,
    "input_throughput": 4529.161012904703,
    "output_throughput": 3941.835671742878,
    "total_throughput": 8470.996684647582,
    "itl": 122.03117169316803,
    "ttft": 1932296.9247866077,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1096,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.992131788730632,
    "arrivals": 236027,
    "finished_requests": 66017,
    "scheduler_time": 94.152214203945
}
#Debug simulation 
Total elapsed time: 5.742148105055094. Arrivals time: 0.22356033977121115 Scheduler time: 5.3853174285031855 Scheduler overhead time: 0.04370728554204106 Adapter cache time: 0.02465975284576416 Engine time: 0.044331402983516455 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_8-8-32/adapters_160_slots_96_rate_0.8-0.4-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_8-8-32/adapters_160_slots_96_rate_0.8-0.4-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [53 53 54]
Adapter prompts. [270, 8640, 270, 270, 4320, 270, 270, 270, 8640, 270, 4320, 8640, 4320, 270, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 270, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 270, 4320, 4320, 4320, 8640, 270, 270, 8640, 270, 8640, 270, 270, 4320, 270, 4320, 8640, 270, 270, 4320, 270, 270, 270, 270, 270, 8640, 4320, 4320, 8640, 4320, 270, 8640, 8640, 8640, 4320, 4320, 270, 270, 270, 8640, 270, 4320, 4320, 270, 8640, 8640, 8640, 270, 270, 8640, 4320, 8640, 8640, 270, 8640, 270, 4320, 270, 270, 4320, 4320, 8640, 8640, 8640, 270, 8640, 4320, 4320, 270, 270, 270, 270, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 270, 4320, 4320, 8640, 4320, 8640, 270, 270, 270, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 270, 4320, 4320, 270, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 270, 8640, 270, 8640, 4320, 270, 4320, 270, 270, 4320, 4320, 4320, 8640, 4320, 270, 270]
Prompts retrieved: 709830 . Total input tokens: 158244851 . Total output tokens: 139627461
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 4.678372920956463,
    "estimated_duration": 3600.0724645132827,
    "input_throughput": 4014.686410473134,
    "output_throughput": 3498.2298617988095,
    "total_throughput": 7512.916272271943,
    "itl": 98.18496239536464,
    "ttft": 2031090.6627146727,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2097,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.732526162783303,
    "arrivals": 236027,
    "finished_requests": 58481,
    "scheduler_time": 96.67913795842797
}
#Debug simulation 
Total elapsed time: 4.67845200188458. Arrivals time: 0.19699241034686565 Scheduler time: 4.309424605220556 Scheduler overhead time: 0.051825796253979206 Adapter cache time: 0.04222699627280235 Engine time: 0.05342348851263523 
