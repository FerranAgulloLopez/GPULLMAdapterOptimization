INFO 05-31 19:31:05 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 05-31 19:31:05 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_8-8-32/adapters_256_slots_96_rate_0.8-0.4-0.1_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_8-8-32/adapters_256_slots_96_rate_0.8-0.4-0.1_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 1080, 8640, 8640, 1080, 8640, 4320, 8640, 1080, 4320, 1080, 8640, 4320, 4320, 4320, 4320, 8640, 1080, 1080, 1080, 4320, 8640, 1080, 8640, 8640, 4320, 4320, 4320, 1080, 8640, 1080, 4320, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 8640, 4320, 1080, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 1080, 8640, 8640, 4320, 1080, 1080, 8640, 4320, 1080, 4320, 4320, 8640, 4320, 1080, 1080, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 4320, 1080, 4320, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 8640, 8640, 1080, 8640, 1080, 4320, 8640, 8640, 8640, 4320, 1080, 8640, 4320, 1080, 1080, 1080, 1080, 1080, 8640, 4320, 1080, 8640, 1080, 8640, 1080, 1080, 4320, 4320, 8640, 4320, 8640, 1080, 4320, 1080, 8640, 8640, 1080, 8640, 4320, 1080, 8640, 1080, 1080, 8640, 8640, 4320, 8640, 8640, 1080, 8640, 4320, 4320, 1080, 4320, 8640, 8640, 1080, 8640, 4320, 1080, 4320, 8640, 1080, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 1080, 1080, 8640, 1080, 4320, 8640, 8640, 4320, 1080, 8640, 1080, 4320, 4320, 1080, 4320, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 8640, 4320, 8640, 4320, 1080, 4320, 8640, 4320, 8640, 1080, 8640, 1080, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 1080, 8640, 1080, 8640, 4320, 4320, 1080, 4320, 8640, 4320, 4320, 8640, 1080, 8640, 8640, 4320, 1080, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 1080, 8640, 4320, 8640, 8640, 1080, 8640, 4320, 4320, 8640, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 1080, 1080, 1080, 1080]
Prompts retrieved: 1202040 . Total input tokens: 267683845 . Total output tokens: 236075847
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 6.299866821151227,
    "estimated_duration": 3600.015446443697,
    "input_throughput": 3960.7132836292403,
    "output_throughput": 3441.276067923048,
    "total_throughput": 7401.989351552288,
    "itl": 100.12986198581984,
    "ttft": 2165663.862245895,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3843,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 28.859330628287235,
    "arrivals": 401058,
    "finished_requests": 57579,
    "scheduler_time": 145.03308317123577
}
#Debug simulation 
Total elapsed time: 6.300007713958621. Arrivals time: 0.24981769872829318 Scheduler time: 5.855765709653497 Scheduler overhead time: 0.052261007484048605 Adapter cache time: 0.06689947517588735 Engine time: 0.05133267678320408 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_8-16-16/adapters_256_slots_96_rate_0.8-0.4-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_8-16-16/adapters_256_slots_96_rate_0.8-0.4-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 1080, 8640, 8640, 1080, 8640, 4320, 8640, 1080, 4320, 1080, 8640, 4320, 4320, 4320, 4320, 8640, 1080, 1080, 1080, 4320, 8640, 1080, 8640, 8640, 4320, 4320, 4320, 1080, 8640, 1080, 4320, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 8640, 4320, 1080, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 1080, 8640, 8640, 4320, 1080, 1080, 8640, 4320, 1080, 4320, 4320, 8640, 4320, 1080, 1080, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 4320, 1080, 4320, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 8640, 8640, 1080, 8640, 1080, 4320, 8640, 8640, 8640, 4320, 1080, 8640, 4320, 1080, 1080, 1080, 1080, 1080, 8640, 4320, 1080, 8640, 1080, 8640, 1080, 1080, 4320, 4320, 8640, 4320, 8640, 1080, 4320, 1080, 8640, 8640, 1080, 8640, 4320, 1080, 8640, 1080, 1080, 8640, 8640, 4320, 8640, 8640, 1080, 8640, 4320, 4320, 1080, 4320, 8640, 8640, 1080, 8640, 4320, 1080, 4320, 8640, 1080, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 1080, 1080, 8640, 1080, 4320, 8640, 8640, 4320, 1080, 8640, 1080, 4320, 4320, 1080, 4320, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 8640, 4320, 8640, 4320, 1080, 4320, 8640, 4320, 8640, 1080, 8640, 1080, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 1080, 8640, 1080, 8640, 4320, 4320, 1080, 4320, 8640, 4320, 4320, 8640, 1080, 8640, 8640, 4320, 1080, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 1080, 8640, 4320, 8640, 8640, 1080, 8640, 4320, 4320, 8640, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 1080, 1080, 1080, 1080]
Prompts retrieved: 1202040 . Total input tokens: 267683845 . Total output tokens: 236075847
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 8.952460586559027,
    "estimated_duration": 3600.0306300502425,
    "input_throughput": 4478.009677316277,
    "output_throughput": 3892.362993534985,
    "total_throughput": 8370.372670851262,
    "itl": 124.04756428500586,
    "ttft": 2086060.1615387064,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2263,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.499084586282548,
    "arrivals": 401058,
    "finished_requests": 65217,
    "scheduler_time": 133.33905755636073
}
#Debug simulation 
Total elapsed time: 8.952565685845912. Arrivals time: 0.2610520231537521 Scheduler time: 8.538315174169838 Scheduler overhead time: 0.04554814659059048 Adapter cache time: 0.04264446161687374 Engine time: 0.0445939009077847 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_8-16-32/adapters_256_slots_96_rate_0.8-0.4-0.1_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_8-16-32/adapters_256_slots_96_rate_0.8-0.4-0.1_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 1080, 8640, 8640, 1080, 8640, 4320, 8640, 1080, 4320, 1080, 8640, 4320, 4320, 4320, 4320, 8640, 1080, 1080, 1080, 4320, 8640, 1080, 8640, 8640, 4320, 4320, 4320, 1080, 8640, 1080, 4320, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 8640, 4320, 1080, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 1080, 8640, 8640, 4320, 1080, 1080, 8640, 4320, 1080, 4320, 4320, 8640, 4320, 1080, 1080, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 4320, 1080, 4320, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 8640, 8640, 1080, 8640, 1080, 4320, 8640, 8640, 8640, 4320, 1080, 8640, 4320, 1080, 1080, 1080, 1080, 1080, 8640, 4320, 1080, 8640, 1080, 8640, 1080, 1080, 4320, 4320, 8640, 4320, 8640, 1080, 4320, 1080, 8640, 8640, 1080, 8640, 4320, 1080, 8640, 1080, 1080, 8640, 8640, 4320, 8640, 8640, 1080, 8640, 4320, 4320, 1080, 4320, 8640, 8640, 1080, 8640, 4320, 1080, 4320, 8640, 1080, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 1080, 1080, 8640, 1080, 4320, 8640, 8640, 4320, 1080, 8640, 1080, 4320, 4320, 1080, 4320, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 8640, 4320, 8640, 4320, 1080, 4320, 8640, 4320, 8640, 1080, 8640, 1080, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 1080, 8640, 1080, 8640, 4320, 4320, 1080, 4320, 8640, 4320, 4320, 8640, 1080, 8640, 8640, 4320, 1080, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 1080, 8640, 4320, 8640, 8640, 1080, 8640, 4320, 4320, 8640, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 1080, 1080, 1080, 1080]
Prompts retrieved: 1202040 . Total input tokens: 267683845 . Total output tokens: 236075847
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 6.337635900825262,
    "estimated_duration": 3600.0731504411083,
    "input_throughput": 3956.380996940245,
    "output_throughput": 3436.0624029220976,
    "total_throughput": 7392.443399862343,
    "itl": 99.92287190063067,
    "ttft": 2165901.352843617,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3775,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 28.074407499158884,
    "arrivals": 401058,
    "finished_requests": 57521,
    "scheduler_time": 145.1858311565015
}
#Debug simulation 
Total elapsed time: 6.337723902892321. Arrivals time: 0.22549238801002502 Scheduler time: 5.918992506805807 Scheduler overhead time: 0.052276852540671825 Adapter cache time: 0.06549450056627393 Engine time: 0.05163442017510533 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_16-16-16/adapters_256_slots_96_rate_0.8-0.4-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_16-16-16/adapters_256_slots_96_rate_0.8-0.4-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 1080, 8640, 8640, 1080, 8640, 4320, 8640, 1080, 4320, 1080, 8640, 4320, 4320, 4320, 4320, 8640, 1080, 1080, 1080, 4320, 8640, 1080, 8640, 8640, 4320, 4320, 4320, 1080, 8640, 1080, 4320, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 8640, 4320, 1080, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 1080, 8640, 8640, 4320, 1080, 1080, 8640, 4320, 1080, 4320, 4320, 8640, 4320, 1080, 1080, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 4320, 1080, 4320, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 8640, 8640, 1080, 8640, 1080, 4320, 8640, 8640, 8640, 4320, 1080, 8640, 4320, 1080, 1080, 1080, 1080, 1080, 8640, 4320, 1080, 8640, 1080, 8640, 1080, 1080, 4320, 4320, 8640, 4320, 8640, 1080, 4320, 1080, 8640, 8640, 1080, 8640, 4320, 1080, 8640, 1080, 1080, 8640, 8640, 4320, 8640, 8640, 1080, 8640, 4320, 4320, 1080, 4320, 8640, 8640, 1080, 8640, 4320, 1080, 4320, 8640, 1080, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 1080, 1080, 8640, 1080, 4320, 8640, 8640, 4320, 1080, 8640, 1080, 4320, 4320, 1080, 4320, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 8640, 4320, 8640, 4320, 1080, 4320, 8640, 4320, 8640, 1080, 8640, 1080, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 1080, 8640, 1080, 8640, 4320, 4320, 1080, 4320, 8640, 4320, 4320, 8640, 1080, 8640, 8640, 4320, 1080, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 1080, 8640, 4320, 8640, 8640, 1080, 8640, 4320, 4320, 8640, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 1080, 1080, 1080, 1080]
Prompts retrieved: 1202040 . Total input tokens: 267683845 . Total output tokens: 236075847
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 9.31575102219358,
    "estimated_duration": 3600.126821548177,
    "input_throughput": 4484.962558362454,
    "output_throughput": 3892.1503865172904,
    "total_throughput": 8377.112944879744,
    "itl": 123.72997722398222,
    "ttft": 2087870.1192386756,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2139,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.655206891881084,
    "arrivals": 401058,
    "finished_requests": 65335,
    "scheduler_time": 133.5088711779939
}
#Debug simulation 
Total elapsed time: 9.315847023855895. Arrivals time: 0.25930942688137293 Scheduler time: 8.904268677346408 Scheduler overhead time: 0.04560832818970084 Adapter cache time: 0.04099261946976185 Engine time: 0.045063283294439316 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_16-16-32/adapters_256_slots_96_rate_0.8-0.4-0.1_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_16-16-32/adapters_256_slots_96_rate_0.8-0.4-0.1_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 1080, 8640, 8640, 1080, 8640, 4320, 8640, 1080, 4320, 1080, 8640, 4320, 4320, 4320, 4320, 8640, 1080, 1080, 1080, 4320, 8640, 1080, 8640, 8640, 4320, 4320, 4320, 1080, 8640, 1080, 4320, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 8640, 4320, 1080, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 1080, 8640, 8640, 4320, 1080, 1080, 8640, 4320, 1080, 4320, 4320, 8640, 4320, 1080, 1080, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 4320, 1080, 4320, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 8640, 8640, 1080, 8640, 1080, 4320, 8640, 8640, 8640, 4320, 1080, 8640, 4320, 1080, 1080, 1080, 1080, 1080, 8640, 4320, 1080, 8640, 1080, 8640, 1080, 1080, 4320, 4320, 8640, 4320, 8640, 1080, 4320, 1080, 8640, 8640, 1080, 8640, 4320, 1080, 8640, 1080, 1080, 8640, 8640, 4320, 8640, 8640, 1080, 8640, 4320, 4320, 1080, 4320, 8640, 8640, 1080, 8640, 4320, 1080, 4320, 8640, 1080, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 1080, 1080, 8640, 1080, 4320, 8640, 8640, 4320, 1080, 8640, 1080, 4320, 4320, 1080, 4320, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 8640, 4320, 8640, 4320, 1080, 4320, 8640, 4320, 8640, 1080, 8640, 1080, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 1080, 8640, 1080, 8640, 4320, 4320, 1080, 4320, 8640, 4320, 4320, 8640, 1080, 8640, 8640, 4320, 1080, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 1080, 8640, 4320, 8640, 8640, 1080, 8640, 4320, 4320, 8640, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 1080, 1080, 1080, 1080]
Prompts retrieved: 1202040 . Total input tokens: 267683845 . Total output tokens: 236075847
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 6.346844109706581,
    "estimated_duration": 3600.0974152670688,
    "input_throughput": 3956.220167709939,
    "output_throughput": 3437.6766993906203,
    "total_throughput": 7393.896867100559,
    "itl": 99.99890664301137,
    "ttft": 2164714.5324406815,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3751,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 27.625827969704822,
    "arrivals": 401058,
    "finished_requests": 57522,
    "scheduler_time": 145.15803028333403
}
#Debug simulation 
Total elapsed time: 6.346934332046658. Arrivals time: 0.22527908300980926 Scheduler time: 5.92781926272437 Scheduler overhead time: 0.05258625186979771 Adapter cache time: 0.06548044830560684 Engine time: 0.05183393135666847 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_8-8-8/adapters_256_slots_96_rate_0.8-0.4-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_8-8-8/adapters_256_slots_96_rate_0.8-0.4-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 540, 8640, 8640, 540, 8640, 4320, 8640, 540, 4320, 540, 8640, 4320, 4320, 4320, 4320, 8640, 540, 540, 540, 4320, 8640, 540, 8640, 8640, 4320, 4320, 4320, 540, 8640, 540, 4320, 4320, 540, 4320, 540, 540, 4320, 4320, 8640, 4320, 540, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 540, 8640, 8640, 4320, 540, 540, 8640, 4320, 540, 4320, 4320, 8640, 4320, 540, 540, 8640, 8640, 8640, 8640, 8640, 8640, 540, 4320, 540, 4320, 540, 540, 540, 4320, 4320, 4320, 540, 540, 8640, 8640, 540, 8640, 540, 4320, 8640, 8640, 8640, 4320, 540, 8640, 4320, 540, 540, 540, 540, 540, 8640, 4320, 540, 8640, 540, 8640, 540, 540, 4320, 4320, 8640, 4320, 8640, 540, 4320, 540, 8640, 8640, 540, 8640, 4320, 540, 8640, 540, 540, 8640, 8640, 4320, 8640, 8640, 540, 8640, 4320, 4320, 540, 4320, 8640, 8640, 540, 8640, 4320, 540, 4320, 8640, 540, 540, 540, 540, 540, 540, 8640, 540, 540, 540, 8640, 540, 4320, 8640, 8640, 4320, 540, 8640, 540, 4320, 4320, 540, 4320, 540, 8640, 540, 540, 8640, 540, 8640, 8640, 4320, 8640, 4320, 540, 4320, 8640, 4320, 8640, 540, 8640, 540, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 540, 8640, 540, 8640, 4320, 4320, 540, 4320, 8640, 4320, 4320, 8640, 540, 8640, 8640, 4320, 540, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 540, 8640, 4320, 8640, 8640, 540, 8640, 4320, 4320, 8640, 540, 4320, 540, 540, 540, 540, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 540, 540, 540, 540]
Prompts retrieved: 1156140 . Total input tokens: 257510080 . Total output tokens: 227106040
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 11.36953290225938,
    "estimated_duration": 3600.1179257433273,
    "input_throughput": 4642.415705465861,
    "output_throughput": 4053.0836214169935,
    "total_throughput": 8695.499326882855,
    "itl": 135.69245913370946,
    "ttft": 2050638.585048071,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1857,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.279243572331362,
    "arrivals": 385672,
    "finished_requests": 67830,
    "scheduler_time": 128.91204946179533
}
#Debug simulation 
Total elapsed time: 11.369640726130456. Arrivals time: 0.2854038802906871 Scheduler time: 10.943421627394855 Scheduler overhead time: 0.04391640052199364 Adapter cache time: 0.03492689272388816 Engine time: 0.042709264904260635 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_8-8-16/adapters_256_slots_96_rate_0.8-0.4-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_8-8-16/adapters_256_slots_96_rate_0.8-0.4-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 540, 8640, 8640, 540, 8640, 4320, 8640, 540, 4320, 540, 8640, 4320, 4320, 4320, 4320, 8640, 540, 540, 540, 4320, 8640, 540, 8640, 8640, 4320, 4320, 4320, 540, 8640, 540, 4320, 4320, 540, 4320, 540, 540, 4320, 4320, 8640, 4320, 540, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 540, 8640, 8640, 4320, 540, 540, 8640, 4320, 540, 4320, 4320, 8640, 4320, 540, 540, 8640, 8640, 8640, 8640, 8640, 8640, 540, 4320, 540, 4320, 540, 540, 540, 4320, 4320, 4320, 540, 540, 8640, 8640, 540, 8640, 540, 4320, 8640, 8640, 8640, 4320, 540, 8640, 4320, 540, 540, 540, 540, 540, 8640, 4320, 540, 8640, 540, 8640, 540, 540, 4320, 4320, 8640, 4320, 8640, 540, 4320, 540, 8640, 8640, 540, 8640, 4320, 540, 8640, 540, 540, 8640, 8640, 4320, 8640, 8640, 540, 8640, 4320, 4320, 540, 4320, 8640, 8640, 540, 8640, 4320, 540, 4320, 8640, 540, 540, 540, 540, 540, 540, 8640, 540, 540, 540, 8640, 540, 4320, 8640, 8640, 4320, 540, 8640, 540, 4320, 4320, 540, 4320, 540, 8640, 540, 540, 8640, 540, 8640, 8640, 4320, 8640, 4320, 540, 4320, 8640, 4320, 8640, 540, 8640, 540, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 540, 8640, 540, 8640, 4320, 4320, 540, 4320, 8640, 4320, 4320, 8640, 540, 8640, 8640, 4320, 540, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 540, 8640, 4320, 8640, 8640, 540, 8640, 4320, 4320, 8640, 540, 4320, 540, 540, 540, 540, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 540, 540, 540, 540]
Prompts retrieved: 1156140 . Total input tokens: 257510080 . Total output tokens: 227106040
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 8.85168416891247,
    "estimated_duration": 3600.1144444057854,
    "input_throughput": 4457.932170722692,
    "output_throughput": 3894.900069576651,
    "total_throughput": 8352.832240299344,
    "itl": 124.19078564366951,
    "ttft": 2079477.0275711704,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2390,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.48844215207696,
    "arrivals": 385672,
    "finished_requests": 65168,
    "scheduler_time": 133.0276291655133
}
#Debug simulation 
Total elapsed time: 8.851799779105932. Arrivals time: 0.2604438387788832 Scheduler time: 8.437788168434054 Scheduler overhead time: 0.045139922760427 Adapter cache time: 0.043786575086414814 Engine time: 0.0442892131395638 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_8-8-32/adapters_256_slots_96_rate_0.8-0.4-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_8-8-32/adapters_256_slots_96_rate_0.8-0.4-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 540, 8640, 8640, 540, 8640, 4320, 8640, 540, 4320, 540, 8640, 4320, 4320, 4320, 4320, 8640, 540, 540, 540, 4320, 8640, 540, 8640, 8640, 4320, 4320, 4320, 540, 8640, 540, 4320, 4320, 540, 4320, 540, 540, 4320, 4320, 8640, 4320, 540, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 540, 8640, 8640, 4320, 540, 540, 8640, 4320, 540, 4320, 4320, 8640, 4320, 540, 540, 8640, 8640, 8640, 8640, 8640, 8640, 540, 4320, 540, 4320, 540, 540, 540, 4320, 4320, 4320, 540, 540, 8640, 8640, 540, 8640, 540, 4320, 8640, 8640, 8640, 4320, 540, 8640, 4320, 540, 540, 540, 540, 540, 8640, 4320, 540, 8640, 540, 8640, 540, 540, 4320, 4320, 8640, 4320, 8640, 540, 4320, 540, 8640, 8640, 540, 8640, 4320, 540, 8640, 540, 540, 8640, 8640, 4320, 8640, 8640, 540, 8640, 4320, 4320, 540, 4320, 8640, 8640, 540, 8640, 4320, 540, 4320, 8640, 540, 540, 540, 540, 540, 540, 8640, 540, 540, 540, 8640, 540, 4320, 8640, 8640, 4320, 540, 8640, 540, 4320, 4320, 540, 4320, 540, 8640, 540, 540, 8640, 540, 8640, 8640, 4320, 8640, 4320, 540, 4320, 8640, 4320, 8640, 540, 8640, 540, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 540, 8640, 540, 8640, 4320, 4320, 540, 4320, 8640, 4320, 4320, 8640, 540, 8640, 8640, 4320, 540, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 540, 8640, 4320, 8640, 8640, 540, 8640, 4320, 4320, 8640, 540, 4320, 540, 540, 540, 540, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 540, 540, 540, 540]
Prompts retrieved: 1156140 . Total input tokens: 257510080 . Total output tokens: 227106040
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 6.133218684233725,
    "estimated_duration": 3600.0915727003367,
    "input_throughput": 3937.3990115945016,
    "output_throughput": 3448.4406158280162,
    "total_throughput": 7385.839627422518,
    "itl": 100.32870297453768,
    "ttft": 2159149.1935753603,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3632,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 27.276604400459686,
    "arrivals": 385672,
    "finished_requests": 57601,
    "scheduler_time": 144.7355391005
}
#Debug simulation 
Total elapsed time: 6.133308520074934. Arrivals time: 0.22257331339642406 Scheduler time: 5.720434358343482 Scheduler overhead time: 0.0523433038033545 Adapter cache time: 0.06262494390830398 Engine time: 0.051555503625422716 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_8-16-16/adapters_256_slots_96_rate_0.8-0.4-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_8-16-16/adapters_256_slots_96_rate_0.8-0.4-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 540, 8640, 8640, 540, 8640, 4320, 8640, 540, 4320, 540, 8640, 4320, 4320, 4320, 4320, 8640, 540, 540, 540, 4320, 8640, 540, 8640, 8640, 4320, 4320, 4320, 540, 8640, 540, 4320, 4320, 540, 4320, 540, 540, 4320, 4320, 8640, 4320, 540, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 540, 8640, 8640, 4320, 540, 540, 8640, 4320, 540, 4320, 4320, 8640, 4320, 540, 540, 8640, 8640, 8640, 8640, 8640, 8640, 540, 4320, 540, 4320, 540, 540, 540, 4320, 4320, 4320, 540, 540, 8640, 8640, 540, 8640, 540, 4320, 8640, 8640, 8640, 4320, 540, 8640, 4320, 540, 540, 540, 540, 540, 8640, 4320, 540, 8640, 540, 8640, 540, 540, 4320, 4320, 8640, 4320, 8640, 540, 4320, 540, 8640, 8640, 540, 8640, 4320, 540, 8640, 540, 540, 8640, 8640, 4320, 8640, 8640, 540, 8640, 4320, 4320, 540, 4320, 8640, 8640, 540, 8640, 4320, 540, 4320, 8640, 540, 540, 540, 540, 540, 540, 8640, 540, 540, 540, 8640, 540, 4320, 8640, 8640, 4320, 540, 8640, 540, 4320, 4320, 540, 4320, 540, 8640, 540, 540, 8640, 540, 8640, 8640, 4320, 8640, 4320, 540, 4320, 8640, 4320, 8640, 540, 8640, 540, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 540, 8640, 540, 8640, 4320, 4320, 540, 4320, 8640, 4320, 4320, 8640, 540, 8640, 8640, 4320, 540, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 540, 8640, 4320, 8640, 8640, 540, 8640, 4320, 4320, 8640, 540, 4320, 540, 540, 540, 540, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 540, 540, 540, 540]
Prompts retrieved: 1156140 . Total input tokens: 257510080 . Total output tokens: 227106040
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 8.721616002731025,
    "estimated_duration": 3600.1153553596823,
    "input_throughput": 4458.9165666876825,
    "output_throughput": 3896.0101595407555,
    "total_throughput": 8354.926726228437,
    "itl": 124.1465190722567,
    "ttft": 2079791.3537556443,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2335,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.01564395390946,
    "arrivals": 385672,
    "finished_requests": 65187,
    "scheduler_time": 133.06979854967145
}
#Debug simulation 
Total elapsed time: 8.721702733077109. Arrivals time: 0.2619440886192024 Scheduler time: 8.306814305949956 Scheduler overhead time: 0.04539876105263829 Adapter cache time: 0.04263785760849714 Engine time: 0.04459849279373884 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_8-16-32/adapters_256_slots_96_rate_0.8-0.4-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_8-16-32/adapters_256_slots_96_rate_0.8-0.4-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 540, 8640, 8640, 540, 8640, 4320, 8640, 540, 4320, 540, 8640, 4320, 4320, 4320, 4320, 8640, 540, 540, 540, 4320, 8640, 540, 8640, 8640, 4320, 4320, 4320, 540, 8640, 540, 4320, 4320, 540, 4320, 540, 540, 4320, 4320, 8640, 4320, 540, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 540, 8640, 8640, 4320, 540, 540, 8640, 4320, 540, 4320, 4320, 8640, 4320, 540, 540, 8640, 8640, 8640, 8640, 8640, 8640, 540, 4320, 540, 4320, 540, 540, 540, 4320, 4320, 4320, 540, 540, 8640, 8640, 540, 8640, 540, 4320, 8640, 8640, 8640, 4320, 540, 8640, 4320, 540, 540, 540, 540, 540, 8640, 4320, 540, 8640, 540, 8640, 540, 540, 4320, 4320, 8640, 4320, 8640, 540, 4320, 540, 8640, 8640, 540, 8640, 4320, 540, 8640, 540, 540, 8640, 8640, 4320, 8640, 8640, 540, 8640, 4320, 4320, 540, 4320, 8640, 8640, 540, 8640, 4320, 540, 4320, 8640, 540, 540, 540, 540, 540, 540, 8640, 540, 540, 540, 8640, 540, 4320, 8640, 8640, 4320, 540, 8640, 540, 4320, 4320, 540, 4320, 540, 8640, 540, 540, 8640, 540, 8640, 8640, 4320, 8640, 4320, 540, 4320, 8640, 4320, 8640, 540, 8640, 540, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 540, 8640, 540, 8640, 4320, 4320, 540, 4320, 8640, 4320, 4320, 8640, 540, 8640, 8640, 4320, 540, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 540, 8640, 4320, 8640, 8640, 540, 8640, 4320, 4320, 8640, 540, 4320, 540, 540, 540, 540, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 540, 540, 540, 540]
Prompts retrieved: 1156140 . Total input tokens: 257510080 . Total output tokens: 227106040
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 6.165431547444314,
    "estimated_duration": 3600.0272423567612,
    "input_throughput": 3936.4060452839326,
    "output_throughput": 3448.0380742546263,
    "total_throughput": 7384.444119538559,
    "itl": 100.31231784447235,
    "ttft": 2158567.748534148,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3543,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 26.346990019409834,
    "arrivals": 385672,
    "finished_requests": 57590,
    "scheduler_time": 144.78987211528644
}
#Debug simulation 
Total elapsed time: 6.165552157443017. Arrivals time: 0.22831655852496624 Scheduler time: 5.745226701255888 Scheduler overhead time: 0.05248746881261468 Adapter cache time: 0.06382591230794787 Engine time: 0.05175098776817322 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_16-16-16/adapters_256_slots_96_rate_0.8-0.4-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_16-16-16/adapters_256_slots_96_rate_0.8-0.4-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 540, 8640, 8640, 540, 8640, 4320, 8640, 540, 4320, 540, 8640, 4320, 4320, 4320, 4320, 8640, 540, 540, 540, 4320, 8640, 540, 8640, 8640, 4320, 4320, 4320, 540, 8640, 540, 4320, 4320, 540, 4320, 540, 540, 4320, 4320, 8640, 4320, 540, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 540, 8640, 8640, 4320, 540, 540, 8640, 4320, 540, 4320, 4320, 8640, 4320, 540, 540, 8640, 8640, 8640, 8640, 8640, 8640, 540, 4320, 540, 4320, 540, 540, 540, 4320, 4320, 4320, 540, 540, 8640, 8640, 540, 8640, 540, 4320, 8640, 8640, 8640, 4320, 540, 8640, 4320, 540, 540, 540, 540, 540, 8640, 4320, 540, 8640, 540, 8640, 540, 540, 4320, 4320, 8640, 4320, 8640, 540, 4320, 540, 8640, 8640, 540, 8640, 4320, 540, 8640, 540, 540, 8640, 8640, 4320, 8640, 8640, 540, 8640, 4320, 4320, 540, 4320, 8640, 8640, 540, 8640, 4320, 540, 4320, 8640, 540, 540, 540, 540, 540, 540, 8640, 540, 540, 540, 8640, 540, 4320, 8640, 8640, 4320, 540, 8640, 540, 4320, 4320, 540, 4320, 540, 8640, 540, 540, 8640, 540, 8640, 8640, 4320, 8640, 4320, 540, 4320, 8640, 4320, 8640, 540, 8640, 540, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 540, 8640, 540, 8640, 4320, 4320, 540, 4320, 8640, 4320, 4320, 8640, 540, 8640, 8640, 4320, 540, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 540, 8640, 4320, 8640, 8640, 540, 8640, 4320, 4320, 8640, 540, 4320, 540, 540, 540, 540, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 540, 540, 540, 540]
Prompts retrieved: 1156140 . Total input tokens: 257510080 . Total output tokens: 227106040
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 8.766657040920109,
    "estimated_duration": 3600.0133117229207,
    "input_throughput": 4454.10186339726,
    "output_throughput": 3896.6283692118955,
    "total_throughput": 8350.730232609156,
    "itl": 124.11066035271276,
    "ttft": 2078333.2439115357,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2275,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.523420139798793,
    "arrivals": 385672,
    "finished_requests": 65170,
    "scheduler_time": 133.12590645736103
}
#Debug simulation 
Total elapsed time: 8.766777138691396. Arrivals time: 0.2605985119007528 Scheduler time: 8.353463819716126 Scheduler overhead time: 0.0452582067809999 Adapter cache time: 0.042458321899175644 Engine time: 0.04456734098494053 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_16-16-32/adapters_256_slots_96_rate_0.8-0.4-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_16-16-32/adapters_256_slots_96_rate_0.8-0.4-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 540, 8640, 8640, 540, 8640, 4320, 8640, 540, 4320, 540, 8640, 4320, 4320, 4320, 4320, 8640, 540, 540, 540, 4320, 8640, 540, 8640, 8640, 4320, 4320, 4320, 540, 8640, 540, 4320, 4320, 540, 4320, 540, 540, 4320, 4320, 8640, 4320, 540, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 540, 8640, 8640, 4320, 540, 540, 8640, 4320, 540, 4320, 4320, 8640, 4320, 540, 540, 8640, 8640, 8640, 8640, 8640, 8640, 540, 4320, 540, 4320, 540, 540, 540, 4320, 4320, 4320, 540, 540, 8640, 8640, 540, 8640, 540, 4320, 8640, 8640, 8640, 4320, 540, 8640, 4320, 540, 540, 540, 540, 540, 8640, 4320, 540, 8640, 540, 8640, 540, 540, 4320, 4320, 8640, 4320, 8640, 540, 4320, 540, 8640, 8640, 540, 8640, 4320, 540, 8640, 540, 540, 8640, 8640, 4320, 8640, 8640, 540, 8640, 4320, 4320, 540, 4320, 8640, 8640, 540, 8640, 4320, 540, 4320, 8640, 540, 540, 540, 540, 540, 540, 8640, 540, 540, 540, 8640, 540, 4320, 8640, 8640, 4320, 540, 8640, 540, 4320, 4320, 540, 4320, 540, 8640, 540, 540, 8640, 540, 8640, 8640, 4320, 8640, 4320, 540, 4320, 8640, 4320, 8640, 540, 8640, 540, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 540, 8640, 540, 8640, 4320, 4320, 540, 4320, 8640, 4320, 4320, 8640, 540, 8640, 8640, 4320, 540, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 540, 8640, 4320, 8640, 8640, 540, 8640, 4320, 4320, 8640, 540, 4320, 540, 540, 540, 540, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 540, 540, 540, 540]
Prompts retrieved: 1156140 . Total input tokens: 257510080 . Total output tokens: 227106040
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 6.139916791114956,
    "estimated_duration": 3600.0263397259637,
    "input_throughput": 3935.997313030384,
    "output_throughput": 3447.8681066941417,
    "total_throughput": 7383.865419724525,
    "itl": 100.32746839193004,
    "ttft": 2158853.185675013,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3656,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 26.94284976735803,
    "arrivals": 385672,
    "finished_requests": 57600,
    "scheduler_time": 144.76228080172956
}
#Debug simulation 
Total elapsed time: 6.140008634887636. Arrivals time: 0.22258099634200335 Scheduler time: 5.72547711012885 Scheduler overhead time: 0.05238166078925133 Adapter cache time: 0.06394644500687718 Engine time: 0.05174797121435404 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_8-8-8/adapters_256_slots_96_rate_0.8-0.4-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_8-8-8/adapters_256_slots_96_rate_0.8-0.4-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 270, 8640, 8640, 270, 8640, 4320, 8640, 270, 4320, 270, 8640, 4320, 4320, 4320, 4320, 8640, 270, 270, 270, 4320, 8640, 270, 8640, 8640, 4320, 4320, 4320, 270, 8640, 270, 4320, 4320, 270, 4320, 270, 270, 4320, 4320, 8640, 4320, 270, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 270, 8640, 8640, 4320, 270, 270, 8640, 4320, 270, 4320, 4320, 8640, 4320, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 270, 4320, 270, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 270, 8640, 8640, 270, 8640, 270, 4320, 8640, 8640, 8640, 4320, 270, 8640, 4320, 270, 270, 270, 270, 270, 8640, 4320, 270, 8640, 270, 8640, 270, 270, 4320, 4320, 8640, 4320, 8640, 270, 4320, 270, 8640, 8640, 270, 8640, 4320, 270, 8640, 270, 270, 8640, 8640, 4320, 8640, 8640, 270, 8640, 4320, 4320, 270, 4320, 8640, 8640, 270, 8640, 4320, 270, 4320, 8640, 270, 270, 270, 270, 270, 270, 8640, 270, 270, 270, 8640, 270, 4320, 8640, 8640, 4320, 270, 8640, 270, 4320, 4320, 270, 4320, 270, 8640, 270, 270, 8640, 270, 8640, 8640, 4320, 8640, 4320, 270, 4320, 8640, 4320, 8640, 270, 8640, 270, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 270, 8640, 270, 8640, 4320, 4320, 270, 4320, 8640, 4320, 4320, 8640, 270, 8640, 8640, 4320, 270, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 270, 8640, 4320, 8640, 8640, 270, 8640, 4320, 4320, 8640, 270, 4320, 270, 270, 270, 270, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 270, 270, 270, 270]
Prompts retrieved: 1133190 . Total input tokens: 252353794 . Total output tokens: 222596229
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 10.805481490679085,
    "estimated_duration": 3600.0882277250516,
    "input_throughput": 4686.881801966952,
    "output_throughput": 4055.589495712514,
    "total_throughput": 8742.471297679465,
    "itl": 136.01170752820997,
    "ttft": 2043971.726617794,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1748,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.558490987848796,
    "arrivals": 378122,
    "finished_requests": 68221,
    "scheduler_time": 128.91102015400833
}
#Debug simulation 
Total elapsed time: 10.80560121499002. Arrivals time: 0.27613840671256185 Scheduler time: 10.391584309283644 Scheduler overhead time: 0.04314394760876894 Adapter cache time: 0.033320299815386534 Engine time: 0.04237871477380395 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_8-8-16/adapters_256_slots_96_rate_0.8-0.4-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_8-8-16/adapters_256_slots_96_rate_0.8-0.4-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 270, 8640, 8640, 270, 8640, 4320, 8640, 270, 4320, 270, 8640, 4320, 4320, 4320, 4320, 8640, 270, 270, 270, 4320, 8640, 270, 8640, 8640, 4320, 4320, 4320, 270, 8640, 270, 4320, 4320, 270, 4320, 270, 270, 4320, 4320, 8640, 4320, 270, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 270, 8640, 8640, 4320, 270, 270, 8640, 4320, 270, 4320, 4320, 8640, 4320, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 270, 4320, 270, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 270, 8640, 8640, 270, 8640, 270, 4320, 8640, 8640, 8640, 4320, 270, 8640, 4320, 270, 270, 270, 270, 270, 8640, 4320, 270, 8640, 270, 8640, 270, 270, 4320, 4320, 8640, 4320, 8640, 270, 4320, 270, 8640, 8640, 270, 8640, 4320, 270, 8640, 270, 270, 8640, 8640, 4320, 8640, 8640, 270, 8640, 4320, 4320, 270, 4320, 8640, 8640, 270, 8640, 4320, 270, 4320, 8640, 270, 270, 270, 270, 270, 270, 8640, 270, 270, 270, 8640, 270, 4320, 8640, 8640, 4320, 270, 8640, 270, 4320, 4320, 270, 4320, 270, 8640, 270, 270, 8640, 270, 8640, 8640, 4320, 8640, 4320, 270, 4320, 8640, 4320, 8640, 270, 8640, 270, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 270, 8640, 270, 8640, 4320, 4320, 270, 4320, 8640, 4320, 4320, 8640, 270, 8640, 8640, 4320, 270, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 270, 8640, 4320, 8640, 8640, 270, 8640, 4320, 4320, 8640, 270, 4320, 270, 270, 270, 270, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 270, 270, 270, 270]
Prompts retrieved: 1133190 . Total input tokens: 252353794 . Total output tokens: 222596229
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 9.011279184836894,
    "estimated_duration": 3600.099066863981,
    "input_throughput": 4502.681648180447,
    "output_throughput": 3899.7929610392152,
    "total_throughput": 8402.474609219662,
    "itl": 124.0351360709668,
    "ttft": 2071453.0027168244,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1988,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.53895694533338,
    "arrivals": 378122,
    "finished_requests": 65560,
    "scheduler_time": 133.3708862417212
}
#Debug simulation 
Total elapsed time: 9.011369646992534. Arrivals time: 0.2569003631360829 Scheduler time: 8.605957890860736 Scheduler overhead time: 0.04543827660381794 Adapter cache time: 0.03811380872502923 Engine time: 0.044560486916452646 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_8-8-32/adapters_256_slots_96_rate_0.8-0.4-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_8-8-32/adapters_256_slots_96_rate_0.8-0.4-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 270, 8640, 8640, 270, 8640, 4320, 8640, 270, 4320, 270, 8640, 4320, 4320, 4320, 4320, 8640, 270, 270, 270, 4320, 8640, 270, 8640, 8640, 4320, 4320, 4320, 270, 8640, 270, 4320, 4320, 270, 4320, 270, 270, 4320, 4320, 8640, 4320, 270, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 270, 8640, 8640, 4320, 270, 270, 8640, 4320, 270, 4320, 4320, 8640, 4320, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 270, 4320, 270, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 270, 8640, 8640, 270, 8640, 270, 4320, 8640, 8640, 8640, 4320, 270, 8640, 4320, 270, 270, 270, 270, 270, 8640, 4320, 270, 8640, 270, 8640, 270, 270, 4320, 4320, 8640, 4320, 8640, 270, 4320, 270, 8640, 8640, 270, 8640, 4320, 270, 8640, 270, 270, 8640, 8640, 4320, 8640, 8640, 270, 8640, 4320, 4320, 270, 4320, 8640, 8640, 270, 8640, 4320, 270, 4320, 8640, 270, 270, 270, 270, 270, 270, 8640, 270, 270, 270, 8640, 270, 4320, 8640, 8640, 4320, 270, 8640, 270, 4320, 4320, 270, 4320, 270, 8640, 270, 270, 8640, 270, 8640, 8640, 4320, 8640, 4320, 270, 4320, 8640, 4320, 8640, 270, 8640, 270, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 270, 8640, 270, 8640, 4320, 4320, 270, 4320, 8640, 4320, 4320, 8640, 270, 8640, 8640, 4320, 270, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 270, 8640, 4320, 8640, 8640, 270, 8640, 4320, 4320, 8640, 270, 4320, 270, 270, 270, 270, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 270, 270, 270, 270]
Prompts retrieved: 1133190 . Total input tokens: 252353794 . Total output tokens: 222596229
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.9244308290071785,
    "estimated_duration": 3600.0974732735945,
    "input_throughput": 3972.181060696862,
    "output_throughput": 3449.00994825269,
    "total_throughput": 7421.191008949552,
    "itl": 100.4661533494261,
    "ttft": 2151775.4328418933,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3437,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 25.850436248924424,
    "arrivals": 378122,
    "finished_requests": 57885,
    "scheduler_time": 144.79383325070125
}
#Debug simulation 
Total elapsed time: 5.924519489053637. Arrivals time: 0.22718110587447882 Scheduler time: 5.509665866848081 Scheduler overhead time: 0.05229149106889963 Adapter cache time: 0.05996948154643178 Engine time: 0.05152849340811372 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_8-16-16/adapters_256_slots_96_rate_0.8-0.4-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_8-16-16/adapters_256_slots_96_rate_0.8-0.4-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 270, 8640, 8640, 270, 8640, 4320, 8640, 270, 4320, 270, 8640, 4320, 4320, 4320, 4320, 8640, 270, 270, 270, 4320, 8640, 270, 8640, 8640, 4320, 4320, 4320, 270, 8640, 270, 4320, 4320, 270, 4320, 270, 270, 4320, 4320, 8640, 4320, 270, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 270, 8640, 8640, 4320, 270, 270, 8640, 4320, 270, 4320, 4320, 8640, 4320, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 270, 4320, 270, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 270, 8640, 8640, 270, 8640, 270, 4320, 8640, 8640, 8640, 4320, 270, 8640, 4320, 270, 270, 270, 270, 270, 8640, 4320, 270, 8640, 270, 8640, 270, 270, 4320, 4320, 8640, 4320, 8640, 270, 4320, 270, 8640, 8640, 270, 8640, 4320, 270, 8640, 270, 270, 8640, 8640, 4320, 8640, 8640, 270, 8640, 4320, 4320, 270, 4320, 8640, 8640, 270, 8640, 4320, 270, 4320, 8640, 270, 270, 270, 270, 270, 270, 8640, 270, 270, 270, 8640, 270, 4320, 8640, 8640, 4320, 270, 8640, 270, 4320, 4320, 270, 4320, 270, 8640, 270, 270, 8640, 270, 8640, 8640, 4320, 8640, 4320, 270, 4320, 8640, 4320, 8640, 270, 8640, 270, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 270, 8640, 270, 8640, 4320, 4320, 270, 4320, 8640, 4320, 4320, 8640, 270, 8640, 8640, 4320, 270, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 270, 8640, 4320, 8640, 8640, 270, 8640, 4320, 4320, 8640, 270, 4320, 270, 270, 270, 270, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 270, 270, 270, 270]
Prompts retrieved: 1133190 . Total input tokens: 252353794 . Total output tokens: 222596229
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 8.379631030838937,
    "estimated_duration": 3600.130167623339,
    "input_throughput": 4498.849554290488,
    "output_throughput": 3899.0490194599597,
    "total_throughput": 8397.898573750448,
    "itl": 124.36488930591916,
    "ttft": 2070927.9225325563,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2246,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.372511057639798,
    "arrivals": 378122,
    "finished_requests": 65483,
    "scheduler_time": 133.1494721130035
}
#Debug simulation 
Total elapsed time: 8.379720680881292. Arrivals time: 0.2527603693306446 Scheduler time: 7.975480440072715 Scheduler overhead time: 0.04527691379189491 Adapter cache time: 0.04173699487000704 Engine time: 0.044143503066152334 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_8-16-32/adapters_256_slots_96_rate_0.8-0.4-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_8-16-32/adapters_256_slots_96_rate_0.8-0.4-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 270, 8640, 8640, 270, 8640, 4320, 8640, 270, 4320, 270, 8640, 4320, 4320, 4320, 4320, 8640, 270, 270, 270, 4320, 8640, 270, 8640, 8640, 4320, 4320, 4320, 270, 8640, 270, 4320, 4320, 270, 4320, 270, 270, 4320, 4320, 8640, 4320, 270, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 270, 8640, 8640, 4320, 270, 270, 8640, 4320, 270, 4320, 4320, 8640, 4320, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 270, 4320, 270, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 270, 8640, 8640, 270, 8640, 270, 4320, 8640, 8640, 8640, 4320, 270, 8640, 4320, 270, 270, 270, 270, 270, 8640, 4320, 270, 8640, 270, 8640, 270, 270, 4320, 4320, 8640, 4320, 8640, 270, 4320, 270, 8640, 8640, 270, 8640, 4320, 270, 8640, 270, 270, 8640, 8640, 4320, 8640, 8640, 270, 8640, 4320, 4320, 270, 4320, 8640, 8640, 270, 8640, 4320, 270, 4320, 8640, 270, 270, 270, 270, 270, 270, 8640, 270, 270, 270, 8640, 270, 4320, 8640, 8640, 4320, 270, 8640, 270, 4320, 4320, 270, 4320, 270, 8640, 270, 270, 8640, 270, 8640, 8640, 4320, 8640, 4320, 270, 4320, 8640, 4320, 8640, 270, 8640, 270, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 270, 8640, 270, 8640, 4320, 4320, 270, 4320, 8640, 4320, 4320, 8640, 270, 8640, 8640, 4320, 270, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 270, 8640, 4320, 8640, 8640, 270, 8640, 4320, 4320, 8640, 270, 4320, 270, 270, 270, 270, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 270, 270, 270, 270]
Prompts retrieved: 1133190 . Total input tokens: 252353794 . Total output tokens: 222596229
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 5.974643272347748,
    "estimated_duration": 3600.0979834361087,
    "input_throughput": 3977.561462461271,
    "output_throughput": 3453.3807294138724,
    "total_throughput": 7430.942191875143,
    "itl": 100.61848649478556,
    "ttft": 2150960.3511973126,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3291,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.530028416687315,
    "arrivals": 378122,
    "finished_requests": 57924,
    "scheduler_time": 144.74700413595306
}
#Debug simulation 
Total elapsed time: 5.974730420392007. Arrivals time: 0.22561557032167912 Scheduler time: 5.561636251863092 Scheduler overhead time: 0.05249019851908088 Adapter cache time: 0.05935322493314743 Engine time: 0.051759904716163874 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_16-16-16/adapters_256_slots_96_rate_0.8-0.4-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_16-16-16/adapters_256_slots_96_rate_0.8-0.4-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 270, 8640, 8640, 270, 8640, 4320, 8640, 270, 4320, 270, 8640, 4320, 4320, 4320, 4320, 8640, 270, 270, 270, 4320, 8640, 270, 8640, 8640, 4320, 4320, 4320, 270, 8640, 270, 4320, 4320, 270, 4320, 270, 270, 4320, 4320, 8640, 4320, 270, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 270, 8640, 8640, 4320, 270, 270, 8640, 4320, 270, 4320, 4320, 8640, 4320, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 270, 4320, 270, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 270, 8640, 8640, 270, 8640, 270, 4320, 8640, 8640, 8640, 4320, 270, 8640, 4320, 270, 270, 270, 270, 270, 8640, 4320, 270, 8640, 270, 8640, 270, 270, 4320, 4320, 8640, 4320, 8640, 270, 4320, 270, 8640, 8640, 270, 8640, 4320, 270, 8640, 270, 270, 8640, 8640, 4320, 8640, 8640, 270, 8640, 4320, 4320, 270, 4320, 8640, 8640, 270, 8640, 4320, 270, 4320, 8640, 270, 270, 270, 270, 270, 270, 8640, 270, 270, 270, 8640, 270, 4320, 8640, 8640, 4320, 270, 8640, 270, 4320, 4320, 270, 4320, 270, 8640, 270, 270, 8640, 270, 8640, 8640, 4320, 8640, 4320, 270, 4320, 8640, 4320, 8640, 270, 8640, 270, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 270, 8640, 270, 8640, 4320, 4320, 270, 4320, 8640, 4320, 4320, 8640, 270, 8640, 8640, 4320, 270, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 270, 8640, 4320, 8640, 8640, 270, 8640, 4320, 4320, 8640, 270, 4320, 270, 270, 270, 270, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 270, 270, 270, 270]
Prompts retrieved: 1133190 . Total input tokens: 252353794 . Total output tokens: 222596229
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 8.350030331872404,
    "estimated_duration": 3600.130040462617,
    "input_throughput": 4485.8187950135225,
    "output_throughput": 3887.141809522453,
    "total_throughput": 8372.960604535976,
    "itl": 123.70971945490176,
    "ttft": 2072322.4337217154,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2285,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.587259349204507,
    "arrivals": 378122,
    "finished_requests": 65311,
    "scheduler_time": 133.41318428714786
}
#Debug simulation 
Total elapsed time: 8.350122617091984. Arrivals time: 0.2520407526753843 Scheduler time: 7.945862226653844 Scheduler overhead time: 0.04539366997778416 Adapter cache time: 0.042250874917954206 Engine time: 0.04421584727242589 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_16-16-32/adapters_256_slots_96_rate_0.8-0.4-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_16-16-32/adapters_256_slots_96_rate_0.8-0.4-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 270, 8640, 8640, 270, 8640, 4320, 8640, 270, 4320, 270, 8640, 4320, 4320, 4320, 4320, 8640, 270, 270, 270, 4320, 8640, 270, 8640, 8640, 4320, 4320, 4320, 270, 8640, 270, 4320, 4320, 270, 4320, 270, 270, 4320, 4320, 8640, 4320, 270, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 270, 8640, 8640, 4320, 270, 270, 8640, 4320, 270, 4320, 4320, 8640, 4320, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 270, 4320, 270, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 270, 8640, 8640, 270, 8640, 270, 4320, 8640, 8640, 8640, 4320, 270, 8640, 4320, 270, 270, 270, 270, 270, 8640, 4320, 270, 8640, 270, 8640, 270, 270, 4320, 4320, 8640, 4320, 8640, 270, 4320, 270, 8640, 8640, 270, 8640, 4320, 270, 8640, 270, 270, 8640, 8640, 4320, 8640, 8640, 270, 8640, 4320, 4320, 270, 4320, 8640, 8640, 270, 8640, 4320, 270, 4320, 8640, 270, 270, 270, 270, 270, 270, 8640, 270, 270, 270, 8640, 270, 4320, 8640, 8640, 4320, 270, 8640, 270, 4320, 4320, 270, 4320, 270, 8640, 270, 270, 8640, 270, 8640, 8640, 4320, 8640, 4320, 270, 4320, 8640, 4320, 8640, 270, 8640, 270, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 270, 8640, 270, 8640, 4320, 4320, 270, 4320, 8640, 4320, 4320, 8640, 270, 8640, 8640, 4320, 270, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 270, 8640, 4320, 8640, 8640, 270, 8640, 4320, 4320, 8640, 270, 4320, 270, 270, 270, 270, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 270, 270, 270, 270]
Prompts retrieved: 1133190 . Total input tokens: 252353794 . Total output tokens: 222596229
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.941162210889161,
    "estimated_duration": 3600.0227483566605,
    "input_throughput": 3970.657409463631,
    "output_throughput": 3448.5968194693255,
    "total_throughput": 7419.254228932957,
    "itl": 100.39511894394123,
    "ttft": 2151565.079698079,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3276,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.19441837657303,
    "arrivals": 378122,
    "finished_requests": 57882,
    "scheduler_time": 144.8808248333163
}
#Debug simulation 
Total elapsed time: 5.941248943097889. Arrivals time: 0.2256692131049931 Scheduler time: 5.529276290442795 Scheduler overhead time: 0.052163224667310715 Adapter cache time: 0.05866914475336671 Engine time: 0.0515531855635345 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-8/adapters_256_slots_96_rate_0.8-0.4-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-8/adapters_256_slots_96_rate_0.8-0.4-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 135, 8640, 8640, 135, 8640, 4320, 8640, 135, 4320, 135, 8640, 4320, 4320, 4320, 4320, 8640, 135, 135, 135, 4320, 8640, 135, 8640, 8640, 4320, 4320, 4320, 135, 8640, 135, 4320, 4320, 135, 4320, 135, 135, 4320, 4320, 8640, 4320, 135, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 135, 8640, 8640, 4320, 135, 135, 8640, 4320, 135, 4320, 4320, 8640, 4320, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 135, 4320, 135, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 135, 8640, 8640, 135, 8640, 135, 4320, 8640, 8640, 8640, 4320, 135, 8640, 4320, 135, 135, 135, 135, 135, 8640, 4320, 135, 8640, 135, 8640, 135, 135, 4320, 4320, 8640, 4320, 8640, 135, 4320, 135, 8640, 8640, 135, 8640, 4320, 135, 8640, 135, 135, 8640, 8640, 4320, 8640, 8640, 135, 8640, 4320, 4320, 135, 4320, 8640, 8640, 135, 8640, 4320, 135, 4320, 8640, 135, 135, 135, 135, 135, 135, 8640, 135, 135, 135, 8640, 135, 4320, 8640, 8640, 4320, 135, 8640, 135, 4320, 4320, 135, 4320, 135, 8640, 135, 135, 8640, 135, 8640, 8640, 4320, 8640, 4320, 135, 4320, 8640, 4320, 8640, 135, 8640, 135, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 135, 8640, 135, 8640, 4320, 4320, 135, 4320, 8640, 4320, 4320, 8640, 135, 8640, 8640, 4320, 135, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 135, 8640, 4320, 8640, 8640, 135, 8640, 4320, 4320, 8640, 135, 4320, 135, 135, 135, 135, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 135, 135, 135, 135]
Prompts retrieved: 1121715 . Total input tokens: 249759382 . Total output tokens: 220336548
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 10.34403774002567,
    "estimated_duration": 3600.0947292600945,
    "input_throughput": 4684.574231596996,
    "output_throughput": 4066.6291031205506,
    "total_throughput": 8751.203334717546,
    "itl": 134.26854432310193,
    "ttft": 2037855.7183160582,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1645,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.87741285755793,
    "arrivals": 374287,
    "finished_requests": 67995,
    "scheduler_time": 129.7658792083371
}
#Debug simulation 
Total elapsed time: 10.344125802163035. Arrivals time: 0.3153706472367048 Scheduler time: 9.890982618555427 Scheduler overhead time: 0.043122231028974056 Adapter cache time: 0.03313660342246294 Engine time: 0.042398640885949135 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-16/adapters_256_slots_96_rate_0.8-0.4-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-16/adapters_256_slots_96_rate_0.8-0.4-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 135, 8640, 8640, 135, 8640, 4320, 8640, 135, 4320, 135, 8640, 4320, 4320, 4320, 4320, 8640, 135, 135, 135, 4320, 8640, 135, 8640, 8640, 4320, 4320, 4320, 135, 8640, 135, 4320, 4320, 135, 4320, 135, 135, 4320, 4320, 8640, 4320, 135, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 135, 8640, 8640, 4320, 135, 135, 8640, 4320, 135, 4320, 4320, 8640, 4320, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 135, 4320, 135, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 135, 8640, 8640, 135, 8640, 135, 4320, 8640, 8640, 8640, 4320, 135, 8640, 4320, 135, 135, 135, 135, 135, 8640, 4320, 135, 8640, 135, 8640, 135, 135, 4320, 4320, 8640, 4320, 8640, 135, 4320, 135, 8640, 8640, 135, 8640, 4320, 135, 8640, 135, 135, 8640, 8640, 4320, 8640, 8640, 135, 8640, 4320, 4320, 135, 4320, 8640, 8640, 135, 8640, 4320, 135, 4320, 8640, 135, 135, 135, 135, 135, 135, 8640, 135, 135, 135, 8640, 135, 4320, 8640, 8640, 4320, 135, 8640, 135, 4320, 4320, 135, 4320, 135, 8640, 135, 135, 8640, 135, 8640, 8640, 4320, 8640, 4320, 135, 4320, 8640, 4320, 8640, 135, 8640, 135, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 135, 8640, 135, 8640, 4320, 4320, 135, 4320, 8640, 4320, 4320, 8640, 135, 8640, 8640, 4320, 135, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 135, 8640, 4320, 8640, 8640, 135, 8640, 4320, 4320, 8640, 135, 4320, 135, 135, 135, 135, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 135, 135, 135, 135]
Prompts retrieved: 1121715 . Total input tokens: 249759382 . Total output tokens: 220336548
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 8.197976829949766,
    "estimated_duration": 3600.0112527799924,
    "input_throughput": 4473.386850544986,
    "output_throughput": 3878.909819855885,
    "total_throughput": 8352.29667040087,
    "itl": 122.36535375275736,
    "ttft": 2070308.4012208993,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1973,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.455692119984626,
    "arrivals": 374287,
    "finished_requests": 64836,
    "scheduler_time": 133.83915976790564
}
#Debug simulation 
Total elapsed time: 8.198063414078206. Arrivals time: 0.2514871461316943 Scheduler time: 7.798126484733075 Scheduler overhead time: 0.045628034975379705 Adapter cache time: 0.0376200033351779 Engine time: 0.044763960875570774 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-32/adapters_256_slots_96_rate_0.8-0.4-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-32/adapters_256_slots_96_rate_0.8-0.4-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 135, 8640, 8640, 135, 8640, 4320, 8640, 135, 4320, 135, 8640, 4320, 4320, 4320, 4320, 8640, 135, 135, 135, 4320, 8640, 135, 8640, 8640, 4320, 4320, 4320, 135, 8640, 135, 4320, 4320, 135, 4320, 135, 135, 4320, 4320, 8640, 4320, 135, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 135, 8640, 8640, 4320, 135, 135, 8640, 4320, 135, 4320, 4320, 8640, 4320, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 135, 4320, 135, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 135, 8640, 8640, 135, 8640, 135, 4320, 8640, 8640, 8640, 4320, 135, 8640, 4320, 135, 135, 135, 135, 135, 8640, 4320, 135, 8640, 135, 8640, 135, 135, 4320, 4320, 8640, 4320, 8640, 135, 4320, 135, 8640, 8640, 135, 8640, 4320, 135, 8640, 135, 135, 8640, 8640, 4320, 8640, 8640, 135, 8640, 4320, 4320, 135, 4320, 8640, 8640, 135, 8640, 4320, 135, 4320, 8640, 135, 135, 135, 135, 135, 135, 8640, 135, 135, 135, 8640, 135, 4320, 8640, 8640, 4320, 135, 8640, 135, 4320, 4320, 135, 4320, 135, 8640, 135, 135, 8640, 135, 8640, 8640, 4320, 8640, 4320, 135, 4320, 8640, 4320, 8640, 135, 8640, 135, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 135, 8640, 135, 8640, 4320, 4320, 135, 4320, 8640, 4320, 4320, 8640, 135, 8640, 8640, 4320, 135, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 135, 8640, 4320, 8640, 8640, 135, 8640, 4320, 4320, 8640, 135, 4320, 135, 135, 135, 135, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 135, 135, 135, 135]
Prompts retrieved: 1121715 . Total input tokens: 249759382 . Total output tokens: 220336548
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.824530285783112,
    "estimated_duration": 3600.0118021554777,
    "input_throughput": 3963.8553383230574,
    "output_throughput": 3434.327907646687,
    "total_throughput": 7398.183245969744,
    "itl": 99.43800324564195,
    "ttft": 2150587.162401624,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3099,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 23.31723618400332,
    "arrivals": 374287,
    "finished_requests": 57450,
    "scheduler_time": 145.18288787904115
}
#Debug simulation 
Total elapsed time: 5.824620435014367. Arrivals time: 0.2571291131898761 Scheduler time: 5.382269223686308 Scheduler overhead time: 0.052710444666445255 Adapter cache time: 0.05614240653812885 Engine time: 0.052324126940220594 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_8-16-16/adapters_256_slots_96_rate_0.8-0.4-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_8-16-16/adapters_256_slots_96_rate_0.8-0.4-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 135, 8640, 8640, 135, 8640, 4320, 8640, 135, 4320, 135, 8640, 4320, 4320, 4320, 4320, 8640, 135, 135, 135, 4320, 8640, 135, 8640, 8640, 4320, 4320, 4320, 135, 8640, 135, 4320, 4320, 135, 4320, 135, 135, 4320, 4320, 8640, 4320, 135, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 135, 8640, 8640, 4320, 135, 135, 8640, 4320, 135, 4320, 4320, 8640, 4320, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 135, 4320, 135, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 135, 8640, 8640, 135, 8640, 135, 4320, 8640, 8640, 8640, 4320, 135, 8640, 4320, 135, 135, 135, 135, 135, 8640, 4320, 135, 8640, 135, 8640, 135, 135, 4320, 4320, 8640, 4320, 8640, 135, 4320, 135, 8640, 8640, 135, 8640, 4320, 135, 8640, 135, 135, 8640, 8640, 4320, 8640, 8640, 135, 8640, 4320, 4320, 135, 4320, 8640, 8640, 135, 8640, 4320, 135, 4320, 8640, 135, 135, 135, 135, 135, 135, 8640, 135, 135, 135, 8640, 135, 4320, 8640, 8640, 4320, 135, 8640, 135, 4320, 4320, 135, 4320, 135, 8640, 135, 135, 8640, 135, 8640, 8640, 4320, 8640, 4320, 135, 4320, 8640, 4320, 8640, 135, 8640, 135, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 135, 8640, 135, 8640, 4320, 4320, 135, 4320, 8640, 4320, 4320, 8640, 135, 8640, 8640, 4320, 135, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 135, 8640, 4320, 8640, 8640, 135, 8640, 4320, 4320, 8640, 135, 4320, 135, 135, 135, 135, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 135, 135, 135, 135]
Prompts retrieved: 1121715 . Total input tokens: 249759382 . Total output tokens: 220336548
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 8.270925578661263,
    "estimated_duration": 3600.0710255993276,
    "input_throughput": 4480.645210969033,
    "output_throughput": 3888.3157861224763,
    "total_throughput": 8368.960997091508,
    "itl": 122.98153367126802,
    "ttft": 2069005.6882103048,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2030,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.928337748730762,
    "arrivals": 374287,
    "finished_requests": 65001,
    "scheduler_time": 133.59056922685713
}
#Debug simulation 
Total elapsed time: 8.271022582892329. Arrivals time: 0.25403047585859895 Scheduler time: 7.866809616796672 Scheduler overhead time: 0.04592846753075719 Adapter cache time: 0.038498548325151205 Engine time: 0.04518019873648882 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_8-16-32/adapters_256_slots_96_rate_0.8-0.4-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_8-16-32/adapters_256_slots_96_rate_0.8-0.4-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 135, 8640, 8640, 135, 8640, 4320, 8640, 135, 4320, 135, 8640, 4320, 4320, 4320, 4320, 8640, 135, 135, 135, 4320, 8640, 135, 8640, 8640, 4320, 4320, 4320, 135, 8640, 135, 4320, 4320, 135, 4320, 135, 135, 4320, 4320, 8640, 4320, 135, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 135, 8640, 8640, 4320, 135, 135, 8640, 4320, 135, 4320, 4320, 8640, 4320, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 135, 4320, 135, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 135, 8640, 8640, 135, 8640, 135, 4320, 8640, 8640, 8640, 4320, 135, 8640, 4320, 135, 135, 135, 135, 135, 8640, 4320, 135, 8640, 135, 8640, 135, 135, 4320, 4320, 8640, 4320, 8640, 135, 4320, 135, 8640, 8640, 135, 8640, 4320, 135, 8640, 135, 135, 8640, 8640, 4320, 8640, 8640, 135, 8640, 4320, 4320, 135, 4320, 8640, 8640, 135, 8640, 4320, 135, 4320, 8640, 135, 135, 135, 135, 135, 135, 8640, 135, 135, 135, 8640, 135, 4320, 8640, 8640, 4320, 135, 8640, 135, 4320, 4320, 135, 4320, 135, 8640, 135, 135, 8640, 135, 8640, 8640, 4320, 8640, 4320, 135, 4320, 8640, 4320, 8640, 135, 8640, 135, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 135, 8640, 135, 8640, 4320, 4320, 135, 4320, 8640, 4320, 4320, 8640, 135, 8640, 8640, 4320, 135, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 135, 8640, 4320, 8640, 8640, 135, 8640, 4320, 4320, 8640, 135, 4320, 135, 135, 135, 135, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 135, 135, 135, 135]
Prompts retrieved: 1121715 . Total input tokens: 249759382 . Total output tokens: 220336548
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 5.812624325044453,
    "estimated_duration": 3600.014611475656,
    "input_throughput": 3964.91418520914,
    "output_throughput": 3436.8310507852134,
    "total_throughput": 7401.745235994354,
    "itl": 99.4963889367439,
    "ttft": 2149369.9335741443,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3069,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 22.799328943449506,
    "arrivals": 374287,
    "finished_requests": 57457,
    "scheduler_time": 145.17667408399862
}
#Debug simulation 
Total elapsed time: 5.812710310332477. Arrivals time: 0.2566697485744953 Scheduler time: 5.371134666260332 Scheduler overhead time: 0.05257888650521636 Adapter cache time: 0.056389021687209606 Engine time: 0.05196918221190572 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_16-16-16/adapters_256_slots_96_rate_0.8-0.4-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_16-16-16/adapters_256_slots_96_rate_0.8-0.4-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 135, 8640, 8640, 135, 8640, 4320, 8640, 135, 4320, 135, 8640, 4320, 4320, 4320, 4320, 8640, 135, 135, 135, 4320, 8640, 135, 8640, 8640, 4320, 4320, 4320, 135, 8640, 135, 4320, 4320, 135, 4320, 135, 135, 4320, 4320, 8640, 4320, 135, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 135, 8640, 8640, 4320, 135, 135, 8640, 4320, 135, 4320, 4320, 8640, 4320, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 135, 4320, 135, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 135, 8640, 8640, 135, 8640, 135, 4320, 8640, 8640, 8640, 4320, 135, 8640, 4320, 135, 135, 135, 135, 135, 8640, 4320, 135, 8640, 135, 8640, 135, 135, 4320, 4320, 8640, 4320, 8640, 135, 4320, 135, 8640, 8640, 135, 8640, 4320, 135, 8640, 135, 135, 8640, 8640, 4320, 8640, 8640, 135, 8640, 4320, 4320, 135, 4320, 8640, 8640, 135, 8640, 4320, 135, 4320, 8640, 135, 135, 135, 135, 135, 135, 8640, 135, 135, 135, 8640, 135, 4320, 8640, 8640, 4320, 135, 8640, 135, 4320, 4320, 135, 4320, 135, 8640, 135, 135, 8640, 135, 8640, 8640, 4320, 8640, 4320, 135, 4320, 8640, 4320, 8640, 135, 8640, 135, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 135, 8640, 135, 8640, 4320, 4320, 135, 4320, 8640, 4320, 4320, 8640, 135, 8640, 8640, 4320, 135, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 135, 8640, 4320, 8640, 8640, 135, 8640, 4320, 4320, 8640, 135, 4320, 135, 135, 135, 135, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 135, 135, 135, 135]
Prompts retrieved: 1121715 . Total input tokens: 249759382 . Total output tokens: 220336548
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 8.393963736947626,
    "estimated_duration": 3600.111992108078,
    "input_throughput": 4494.711007733067,
    "output_throughput": 3902.7399788673574,
    "total_throughput": 8397.450986600425,
    "itl": 122.92034428537403,
    "ttft": 2065725.0380973546,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2056,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.12534145381366,
    "arrivals": 374287,
    "finished_requests": 65226,
    "scheduler_time": 133.85903328707056
}
#Debug simulation 
Total elapsed time: 8.394048909191042. Arrivals time: 0.2509386194869876 Scheduler time: 7.993601009249687 Scheduler overhead time: 0.04582917084917426 Adapter cache time: 0.03847642382606864 Engine time: 0.04464814439415932 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_16-16-32/adapters_256_slots_96_rate_0.8-0.4-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_16-16-32/adapters_256_slots_96_rate_0.8-0.4-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 135, 8640, 8640, 135, 8640, 4320, 8640, 135, 4320, 135, 8640, 4320, 4320, 4320, 4320, 8640, 135, 135, 135, 4320, 8640, 135, 8640, 8640, 4320, 4320, 4320, 135, 8640, 135, 4320, 4320, 135, 4320, 135, 135, 4320, 4320, 8640, 4320, 135, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 135, 8640, 8640, 4320, 135, 135, 8640, 4320, 135, 4320, 4320, 8640, 4320, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 135, 4320, 135, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 135, 8640, 8640, 135, 8640, 135, 4320, 8640, 8640, 8640, 4320, 135, 8640, 4320, 135, 135, 135, 135, 135, 8640, 4320, 135, 8640, 135, 8640, 135, 135, 4320, 4320, 8640, 4320, 8640, 135, 4320, 135, 8640, 8640, 135, 8640, 4320, 135, 8640, 135, 135, 8640, 8640, 4320, 8640, 8640, 135, 8640, 4320, 4320, 135, 4320, 8640, 8640, 135, 8640, 4320, 135, 4320, 8640, 135, 135, 135, 135, 135, 135, 8640, 135, 135, 135, 8640, 135, 4320, 8640, 8640, 4320, 135, 8640, 135, 4320, 4320, 135, 4320, 135, 8640, 135, 135, 8640, 135, 8640, 8640, 4320, 8640, 4320, 135, 4320, 8640, 4320, 8640, 135, 8640, 135, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 135, 8640, 135, 8640, 4320, 4320, 135, 4320, 8640, 4320, 4320, 8640, 135, 8640, 8640, 4320, 135, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 135, 8640, 4320, 8640, 8640, 135, 8640, 4320, 4320, 8640, 135, 4320, 135, 135, 135, 135, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 135, 135, 135, 135]
Prompts retrieved: 1121715 . Total input tokens: 249759382 . Total output tokens: 220336548
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.837059460114688,
    "estimated_duration": 3600.0942363472354,
    "input_throughput": 3965.240647279303,
    "output_throughput": 3435.4217384455987,
    "total_throughput": 7400.6623857249015,
    "itl": 99.50740565948634,
    "ttft": 2149694.306261517,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3059,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 22.540915693659752,
    "arrivals": 374287,
    "finished_requests": 57459,
    "scheduler_time": 145.16807868031285
}
#Debug simulation 
Total elapsed time: 5.837148068007082. Arrivals time: 0.22159970831125975 Scheduler time: 5.431101236958057 Scheduler overhead time: 0.05248832842335105 Adapter cache time: 0.05626544915139675 Engine time: 0.05176480859518051 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-8/adapters_256_slots_96_rate_0.8-0.4-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-8/adapters_256_slots_96_rate_0.8-0.4-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 66, 8640, 8640, 66, 8640, 4320, 8640, 66, 4320, 66, 8640, 4320, 4320, 4320, 4320, 8640, 66, 66, 66, 4320, 8640, 66, 8640, 8640, 4320, 4320, 4320, 66, 8640, 66, 4320, 4320, 66, 4320, 66, 66, 4320, 4320, 8640, 4320, 66, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 66, 8640, 8640, 4320, 66, 66, 8640, 4320, 66, 4320, 4320, 8640, 4320, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 66, 4320, 66, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 66, 8640, 8640, 66, 8640, 66, 4320, 8640, 8640, 8640, 4320, 66, 8640, 4320, 66, 66, 66, 66, 66, 8640, 4320, 66, 8640, 66, 8640, 66, 66, 4320, 4320, 8640, 4320, 8640, 66, 4320, 66, 8640, 8640, 66, 8640, 4320, 66, 8640, 66, 66, 8640, 8640, 4320, 8640, 8640, 66, 8640, 4320, 4320, 66, 4320, 8640, 8640, 66, 8640, 4320, 66, 4320, 8640, 66, 66, 66, 66, 66, 66, 8640, 66, 66, 66, 8640, 66, 4320, 8640, 8640, 4320, 66, 8640, 66, 4320, 4320, 66, 4320, 66, 8640, 66, 66, 8640, 66, 8640, 8640, 4320, 8640, 4320, 66, 4320, 8640, 4320, 8640, 66, 8640, 66, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 66, 8640, 66, 8640, 4320, 4320, 66, 4320, 8640, 4320, 4320, 8640, 66, 8640, 8640, 4320, 66, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 66, 8640, 4320, 8640, 8640, 66, 8640, 4320, 4320, 8640, 66, 4320, 66, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 66, 66, 66, 66]
Prompts retrieved: 1115850 . Total input tokens: 248489857 . Total output tokens: 219174347
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 10.035774187650532,
    "estimated_duration": 3600.1212425058784,
    "input_throughput": 4668.380831613772,
    "output_throughput": 4095.2720774864088,
    "total_throughput": 8763.652909100181,
    "itl": 133.8372810608878,
    "ttft": 2043821.745226012,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1483,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.806202594382006,
    "arrivals": 372356,
    "finished_requests": 68061,
    "scheduler_time": 130.491648335214
}
#Debug simulation 
Total elapsed time: 10.035867067985237. Arrivals time: 0.267827408388257 Scheduler time: 9.63432604400441 Scheduler overhead time: 0.04305990785360336 Adapter cache time: 0.029344625771045685 Engine time: 0.042134630493819714 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-16/adapters_256_slots_96_rate_0.8-0.4-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-16/adapters_256_slots_96_rate_0.8-0.4-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 66, 8640, 8640, 66, 8640, 4320, 8640, 66, 4320, 66, 8640, 4320, 4320, 4320, 4320, 8640, 66, 66, 66, 4320, 8640, 66, 8640, 8640, 4320, 4320, 4320, 66, 8640, 66, 4320, 4320, 66, 4320, 66, 66, 4320, 4320, 8640, 4320, 66, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 66, 8640, 8640, 4320, 66, 66, 8640, 4320, 66, 4320, 4320, 8640, 4320, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 66, 4320, 66, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 66, 8640, 8640, 66, 8640, 66, 4320, 8640, 8640, 8640, 4320, 66, 8640, 4320, 66, 66, 66, 66, 66, 8640, 4320, 66, 8640, 66, 8640, 66, 66, 4320, 4320, 8640, 4320, 8640, 66, 4320, 66, 8640, 8640, 66, 8640, 4320, 66, 8640, 66, 66, 8640, 8640, 4320, 8640, 8640, 66, 8640, 4320, 4320, 66, 4320, 8640, 8640, 66, 8640, 4320, 66, 4320, 8640, 66, 66, 66, 66, 66, 66, 8640, 66, 66, 66, 8640, 66, 4320, 8640, 8640, 4320, 66, 8640, 66, 4320, 4320, 66, 4320, 66, 8640, 66, 66, 8640, 66, 8640, 8640, 4320, 8640, 4320, 66, 4320, 8640, 4320, 8640, 66, 8640, 66, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 66, 8640, 66, 8640, 4320, 4320, 66, 4320, 8640, 4320, 4320, 8640, 66, 8640, 8640, 4320, 66, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 66, 8640, 4320, 8640, 8640, 66, 8640, 4320, 4320, 8640, 66, 4320, 66, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 66, 66, 66, 66]
Prompts retrieved: 1115850 . Total input tokens: 248489857 . Total output tokens: 219174347
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 7.973460346926004,
    "estimated_duration": 3600.083518151312,
    "input_throughput": 4447.092107524573,
    "output_throughput": 3901.3172692205535,
    "total_throughput": 8348.409376745127,
    "itl": 123.43785640585752,
    "ttft": 2072449.3562772637,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1941,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.19726603192718,
    "arrivals": 372356,
    "finished_requests": 64825,
    "scheduler_time": 133.62302631015226
}
#Debug simulation 
Total elapsed time: 7.973547383211553. Arrivals time: 0.2466494762338698 Scheduler time: 7.580575410276651 Scheduler overhead time: 0.04519697418436408 Adapter cache time: 0.03642909601330757 Engine time: 0.04432418430224061 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-32/adapters_256_slots_96_rate_0.8-0.4-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-32/adapters_256_slots_96_rate_0.8-0.4-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 66, 8640, 8640, 66, 8640, 4320, 8640, 66, 4320, 66, 8640, 4320, 4320, 4320, 4320, 8640, 66, 66, 66, 4320, 8640, 66, 8640, 8640, 4320, 4320, 4320, 66, 8640, 66, 4320, 4320, 66, 4320, 66, 66, 4320, 4320, 8640, 4320, 66, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 66, 8640, 8640, 4320, 66, 66, 8640, 4320, 66, 4320, 4320, 8640, 4320, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 66, 4320, 66, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 66, 8640, 8640, 66, 8640, 66, 4320, 8640, 8640, 8640, 4320, 66, 8640, 4320, 66, 66, 66, 66, 66, 8640, 4320, 66, 8640, 66, 8640, 66, 66, 4320, 4320, 8640, 4320, 8640, 66, 4320, 66, 8640, 8640, 66, 8640, 4320, 66, 8640, 66, 66, 8640, 8640, 4320, 8640, 8640, 66, 8640, 4320, 4320, 66, 4320, 8640, 8640, 66, 8640, 4320, 66, 4320, 8640, 66, 66, 66, 66, 66, 66, 8640, 66, 66, 66, 8640, 66, 4320, 8640, 8640, 4320, 66, 8640, 66, 4320, 4320, 66, 4320, 66, 8640, 66, 66, 8640, 66, 8640, 8640, 4320, 8640, 4320, 66, 4320, 8640, 4320, 8640, 66, 8640, 66, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 66, 8640, 66, 8640, 4320, 4320, 66, 4320, 8640, 4320, 4320, 8640, 66, 8640, 8640, 4320, 66, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 66, 8640, 4320, 8640, 8640, 66, 8640, 4320, 4320, 8640, 66, 4320, 66, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 66, 66, 66, 66]
Prompts retrieved: 1115850 . Total input tokens: 248489857 . Total output tokens: 219174347
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.692781490273774,
    "estimated_duration": 3600.034145527401,
    "input_throughput": 3936.4315523523796,
    "output_throughput": 3448.6300679743104,
    "total_throughput": 7385.06162032669,
    "itl": 100.06625383710389,
    "ttft": 2155014.6047468507,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2845,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 21.359897898794433,
    "arrivals": 372356,
    "finished_requests": 57362,
    "scheduler_time": 144.8917472591552
}
#Debug simulation 
Total elapsed time: 5.692873040214181. Arrivals time: 0.227495520375669 Scheduler time: 5.284877568949014 Scheduler overhead time: 0.0524061843752861 Adapter cache time: 0.052865416277199984 Engine time: 0.05133691942319274 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_8-16-16/adapters_256_slots_96_rate_0.8-0.4-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_8-16-16/adapters_256_slots_96_rate_0.8-0.4-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 66, 8640, 8640, 66, 8640, 4320, 8640, 66, 4320, 66, 8640, 4320, 4320, 4320, 4320, 8640, 66, 66, 66, 4320, 8640, 66, 8640, 8640, 4320, 4320, 4320, 66, 8640, 66, 4320, 4320, 66, 4320, 66, 66, 4320, 4320, 8640, 4320, 66, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 66, 8640, 8640, 4320, 66, 66, 8640, 4320, 66, 4320, 4320, 8640, 4320, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 66, 4320, 66, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 66, 8640, 8640, 66, 8640, 66, 4320, 8640, 8640, 8640, 4320, 66, 8640, 4320, 66, 66, 66, 66, 66, 8640, 4320, 66, 8640, 66, 8640, 66, 66, 4320, 4320, 8640, 4320, 8640, 66, 4320, 66, 8640, 8640, 66, 8640, 4320, 66, 8640, 66, 66, 8640, 8640, 4320, 8640, 8640, 66, 8640, 4320, 4320, 66, 4320, 8640, 8640, 66, 8640, 4320, 66, 4320, 8640, 66, 66, 66, 66, 66, 66, 8640, 66, 66, 66, 8640, 66, 4320, 8640, 8640, 4320, 66, 8640, 66, 4320, 4320, 66, 4320, 66, 8640, 66, 66, 8640, 66, 8640, 8640, 4320, 8640, 4320, 66, 4320, 8640, 4320, 8640, 66, 8640, 66, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 66, 8640, 66, 8640, 4320, 4320, 66, 4320, 8640, 4320, 4320, 8640, 66, 8640, 8640, 4320, 66, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 66, 8640, 4320, 8640, 8640, 66, 8640, 4320, 4320, 8640, 66, 4320, 66, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 66, 66, 66, 66]
Prompts retrieved: 1115850 . Total input tokens: 248489857 . Total output tokens: 219174347
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 7.877247244119644,
    "estimated_duration": 3600.0721732436436,
    "input_throughput": 4459.04393787096,
    "output_throughput": 3910.603821954879,
    "total_throughput": 8369.647759825839,
    "itl": 123.52883641269226,
    "ttft": 2070650.8162982583,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2013,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.790658452301503,
    "arrivals": 372356,
    "finished_requests": 64995,
    "scheduler_time": 133.6956527878531
}
#Debug simulation 
Total elapsed time: 7.877337330952287. Arrivals time: 0.25069509726017714 Scheduler time: 7.47985349688679 Scheduler overhead time: 0.0453053112141788 Adapter cache time: 0.036925737746059895 Engine time: 0.04417415056377649 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_8-16-32/adapters_256_slots_96_rate_0.8-0.4-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_8-16-32/adapters_256_slots_96_rate_0.8-0.4-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 66, 8640, 8640, 66, 8640, 4320, 8640, 66, 4320, 66, 8640, 4320, 4320, 4320, 4320, 8640, 66, 66, 66, 4320, 8640, 66, 8640, 8640, 4320, 4320, 4320, 66, 8640, 66, 4320, 4320, 66, 4320, 66, 66, 4320, 4320, 8640, 4320, 66, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 66, 8640, 8640, 4320, 66, 66, 8640, 4320, 66, 4320, 4320, 8640, 4320, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 66, 4320, 66, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 66, 8640, 8640, 66, 8640, 66, 4320, 8640, 8640, 8640, 4320, 66, 8640, 4320, 66, 66, 66, 66, 66, 8640, 4320, 66, 8640, 66, 8640, 66, 66, 4320, 4320, 8640, 4320, 8640, 66, 4320, 66, 8640, 8640, 66, 8640, 4320, 66, 8640, 66, 66, 8640, 8640, 4320, 8640, 8640, 66, 8640, 4320, 4320, 66, 4320, 8640, 8640, 66, 8640, 4320, 66, 4320, 8640, 66, 66, 66, 66, 66, 66, 8640, 66, 66, 66, 8640, 66, 4320, 8640, 8640, 4320, 66, 8640, 66, 4320, 4320, 66, 4320, 66, 8640, 66, 66, 8640, 66, 8640, 8640, 4320, 8640, 4320, 66, 4320, 8640, 4320, 8640, 66, 8640, 66, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 66, 8640, 66, 8640, 4320, 4320, 66, 4320, 8640, 4320, 4320, 8640, 66, 8640, 8640, 4320, 66, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 66, 8640, 4320, 8640, 8640, 66, 8640, 4320, 4320, 8640, 66, 4320, 66, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 66, 66, 66, 66]
Prompts retrieved: 1115850 . Total input tokens: 248489857 . Total output tokens: 219174347
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 5.693148368038237,
    "estimated_duration": 3600.0914563300676,
    "input_throughput": 3935.7569583645973,
    "output_throughput": 3446.74577035588,
    "total_throughput": 7382.5027287204775,
    "itl": 100.01313031800657,
    "ttft": 2155193.8983468106,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2856,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 21.244982555597367,
    "arrivals": 372356,
    "finished_requests": 57354,
    "scheduler_time": 144.93315367199085
}
#Debug simulation 
Total elapsed time: 5.6932382779195905. Arrivals time: 0.2209631074219942 Scheduler time: 5.292284779716283 Scheduler overhead time: 0.052165459375828505 Adapter cache time: 0.05247490853071213 Engine time: 0.051481439266353846 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_16-16-16/adapters_256_slots_96_rate_0.8-0.4-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_16-16-16/adapters_256_slots_96_rate_0.8-0.4-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 66, 8640, 8640, 66, 8640, 4320, 8640, 66, 4320, 66, 8640, 4320, 4320, 4320, 4320, 8640, 66, 66, 66, 4320, 8640, 66, 8640, 8640, 4320, 4320, 4320, 66, 8640, 66, 4320, 4320, 66, 4320, 66, 66, 4320, 4320, 8640, 4320, 66, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 66, 8640, 8640, 4320, 66, 66, 8640, 4320, 66, 4320, 4320, 8640, 4320, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 66, 4320, 66, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 66, 8640, 8640, 66, 8640, 66, 4320, 8640, 8640, 8640, 4320, 66, 8640, 4320, 66, 66, 66, 66, 66, 8640, 4320, 66, 8640, 66, 8640, 66, 66, 4320, 4320, 8640, 4320, 8640, 66, 4320, 66, 8640, 8640, 66, 8640, 4320, 66, 8640, 66, 66, 8640, 8640, 4320, 8640, 8640, 66, 8640, 4320, 4320, 66, 4320, 8640, 8640, 66, 8640, 4320, 66, 4320, 8640, 66, 66, 66, 66, 66, 66, 8640, 66, 66, 66, 8640, 66, 4320, 8640, 8640, 4320, 66, 8640, 66, 4320, 4320, 66, 4320, 66, 8640, 66, 66, 8640, 66, 8640, 8640, 4320, 8640, 4320, 66, 4320, 8640, 4320, 8640, 66, 8640, 66, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 66, 8640, 66, 8640, 4320, 4320, 66, 4320, 8640, 4320, 4320, 8640, 66, 8640, 8640, 4320, 66, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 66, 8640, 4320, 8640, 8640, 66, 8640, 4320, 4320, 8640, 66, 4320, 66, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 66, 66, 66, 66]
Prompts retrieved: 1115850 . Total input tokens: 248489857 . Total output tokens: 219174347
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 7.994380808901042,
    "estimated_duration": 3600.035847367038,
    "input_throughput": 4445.260180312983,
    "output_throughput": 3899.607280374032,
    "total_throughput": 8344.867460687015,
    "itl": 122.93532765885736,
    "ttft": 2072369.8616196972,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1893,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.084762340500523,
    "arrivals": 372356,
    "finished_requests": 64787,
    "scheduler_time": 133.9098703567081
}
#Debug simulation 
Total elapsed time: 7.994468508753926. Arrivals time: 0.2472520675510168 Scheduler time: 7.601329687051475 Scheduler overhead time: 0.04522397043183446 Adapter cache time: 0.03595270588994026 Engine time: 0.04427413595840335 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_16-16-32/adapters_256_slots_96_rate_0.8-0.4-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_16-16-32/adapters_256_slots_96_rate_0.8-0.4-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 66, 8640, 8640, 66, 8640, 4320, 8640, 66, 4320, 66, 8640, 4320, 4320, 4320, 4320, 8640, 66, 66, 66, 4320, 8640, 66, 8640, 8640, 4320, 4320, 4320, 66, 8640, 66, 4320, 4320, 66, 4320, 66, 66, 4320, 4320, 8640, 4320, 66, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 66, 8640, 8640, 4320, 66, 66, 8640, 4320, 66, 4320, 4320, 8640, 4320, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 66, 4320, 66, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 66, 8640, 8640, 66, 8640, 66, 4320, 8640, 8640, 8640, 4320, 66, 8640, 4320, 66, 66, 66, 66, 66, 8640, 4320, 66, 8640, 66, 8640, 66, 66, 4320, 4320, 8640, 4320, 8640, 66, 4320, 66, 8640, 8640, 66, 8640, 4320, 66, 8640, 66, 66, 8640, 8640, 4320, 8640, 8640, 66, 8640, 4320, 4320, 66, 4320, 8640, 8640, 66, 8640, 4320, 66, 4320, 8640, 66, 66, 66, 66, 66, 66, 8640, 66, 66, 66, 8640, 66, 4320, 8640, 8640, 4320, 66, 8640, 66, 4320, 4320, 66, 4320, 66, 8640, 66, 66, 8640, 66, 8640, 8640, 4320, 8640, 4320, 66, 4320, 8640, 4320, 8640, 66, 8640, 66, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 66, 8640, 66, 8640, 4320, 4320, 66, 4320, 8640, 4320, 4320, 8640, 66, 8640, 8640, 4320, 66, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 66, 8640, 4320, 8640, 8640, 66, 8640, 4320, 4320, 8640, 66, 4320, 66, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 66, 66, 66, 66]
Prompts retrieved: 1115850 . Total input tokens: 248489857 . Total output tokens: 219174347
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.773633439093828,
    "estimated_duration": 3600.0715727086176,
    "input_throughput": 3932.1837674880494,
    "output_throughput": 3446.6045325494642,
    "total_throughput": 7378.788300037514,
    "itl": 99.89360122979899,
    "ttft": 2154638.0109504345,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2693,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.845585499350086,
    "arrivals": 372356,
    "finished_requests": 57309,
    "scheduler_time": 145.05321422357403
}
#Debug simulation 
Total elapsed time: 5.7737555098719895. Arrivals time: 0.21850729873403907 Scheduler time: 5.376818589866161 Scheduler overhead time: 0.05224316148087382 Adapter cache time: 0.050942030269652605 Engine time: 0.05139975156635046 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-8/adapters_256_slots_96_rate_0.8-0.4-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-8/adapters_256_slots_96_rate_0.8-0.4-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 33, 8640, 8640, 33, 8640, 4320, 8640, 33, 4320, 33, 8640, 4320, 4320, 4320, 4320, 8640, 33, 33, 33, 4320, 8640, 33, 8640, 8640, 4320, 4320, 4320, 33, 8640, 33, 4320, 4320, 33, 4320, 33, 33, 4320, 4320, 8640, 4320, 33, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 33, 8640, 8640, 4320, 33, 33, 8640, 4320, 33, 4320, 4320, 8640, 4320, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 4320, 33, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 33, 8640, 8640, 33, 8640, 33, 4320, 8640, 8640, 8640, 4320, 33, 8640, 4320, 33, 33, 33, 33, 33, 8640, 4320, 33, 8640, 33, 8640, 33, 33, 4320, 4320, 8640, 4320, 8640, 33, 4320, 33, 8640, 8640, 33, 8640, 4320, 33, 8640, 33, 33, 8640, 8640, 4320, 8640, 8640, 33, 8640, 4320, 4320, 33, 4320, 8640, 8640, 33, 8640, 4320, 33, 4320, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 4320, 8640, 8640, 4320, 33, 8640, 33, 4320, 4320, 33, 4320, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 4320, 8640, 4320, 33, 4320, 8640, 4320, 8640, 33, 8640, 33, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 33, 8640, 33, 8640, 4320, 4320, 33, 4320, 8640, 4320, 4320, 8640, 33, 8640, 8640, 4320, 33, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 33, 8640, 4320, 8640, 8640, 33, 8640, 4320, 4320, 8640, 33, 4320, 33, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 33, 33, 33, 33]
Prompts retrieved: 1113045 . Total input tokens: 247844840 . Total output tokens: 218638540
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 10.45341033814475,
    "estimated_duration": 3600.1089975579507,
    "input_throughput": 4716.074155398319,
    "output_throughput": 4105.858742062173,
    "total_throughput": 8821.932897460492,
    "itl": 132.4743729383355,
    "ttft": 2031173.5986403192,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1297,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.576294514439278,
    "arrivals": 371350,
    "finished_requests": 68835,
    "scheduler_time": 131.250913447164
}
#Debug simulation 
Total elapsed time: 10.453526718076319. Arrivals time: 0.2747660567983985 Scheduler time: 10.046821399126202 Scheduler overhead time: 0.04335433151572943 Adapter cache time: 0.02650295989587903 Engine time: 0.04265630431473255 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-16/adapters_256_slots_96_rate_0.8-0.4-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-16/adapters_256_slots_96_rate_0.8-0.4-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 33, 8640, 8640, 33, 8640, 4320, 8640, 33, 4320, 33, 8640, 4320, 4320, 4320, 4320, 8640, 33, 33, 33, 4320, 8640, 33, 8640, 8640, 4320, 4320, 4320, 33, 8640, 33, 4320, 4320, 33, 4320, 33, 33, 4320, 4320, 8640, 4320, 33, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 33, 8640, 8640, 4320, 33, 33, 8640, 4320, 33, 4320, 4320, 8640, 4320, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 4320, 33, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 33, 8640, 8640, 33, 8640, 33, 4320, 8640, 8640, 8640, 4320, 33, 8640, 4320, 33, 33, 33, 33, 33, 8640, 4320, 33, 8640, 33, 8640, 33, 33, 4320, 4320, 8640, 4320, 8640, 33, 4320, 33, 8640, 8640, 33, 8640, 4320, 33, 8640, 33, 33, 8640, 8640, 4320, 8640, 8640, 33, 8640, 4320, 4320, 33, 4320, 8640, 8640, 33, 8640, 4320, 33, 4320, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 4320, 8640, 8640, 4320, 33, 8640, 33, 4320, 4320, 33, 4320, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 4320, 8640, 4320, 33, 4320, 8640, 4320, 8640, 33, 8640, 33, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 33, 8640, 33, 8640, 4320, 4320, 33, 4320, 8640, 4320, 4320, 8640, 33, 8640, 8640, 4320, 33, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 33, 8640, 4320, 8640, 8640, 33, 8640, 4320, 4320, 8640, 33, 4320, 33, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 33, 33, 33, 33]
Prompts retrieved: 1113045 . Total input tokens: 247844840 . Total output tokens: 218638540
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 8.306307781022042,
    "estimated_duration": 3600.1159140423483,
    "input_throughput": 4508.380670936663,
    "output_throughput": 3924.7305746149914,
    "total_throughput": 8433.111245551654,
    "itl": 121.57371267585643,
    "ttft": 2059395.8135144785,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1714,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.526000622687704,
    "arrivals": 371350,
    "finished_requests": 65815,
    "scheduler_time": 134.96908096005734
}
#Debug simulation 
Total elapsed time: 8.306399450171739. Arrivals time: 0.2568599786609411 Scheduler time: 7.905908554326743 Scheduler overhead time: 0.04572453862056136 Adapter cache time: 0.03220202587544918 Engine time: 0.04499836824834347 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-32/adapters_256_slots_96_rate_0.8-0.4-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-32/adapters_256_slots_96_rate_0.8-0.4-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 33, 8640, 8640, 33, 8640, 4320, 8640, 33, 4320, 33, 8640, 4320, 4320, 4320, 4320, 8640, 33, 33, 33, 4320, 8640, 33, 8640, 8640, 4320, 4320, 4320, 33, 8640, 33, 4320, 4320, 33, 4320, 33, 33, 4320, 4320, 8640, 4320, 33, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 33, 8640, 8640, 4320, 33, 33, 8640, 4320, 33, 4320, 4320, 8640, 4320, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 4320, 33, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 33, 8640, 8640, 33, 8640, 33, 4320, 8640, 8640, 8640, 4320, 33, 8640, 4320, 33, 33, 33, 33, 33, 8640, 4320, 33, 8640, 33, 8640, 33, 33, 4320, 4320, 8640, 4320, 8640, 33, 4320, 33, 8640, 8640, 33, 8640, 4320, 33, 8640, 33, 33, 8640, 8640, 4320, 8640, 8640, 33, 8640, 4320, 4320, 33, 4320, 8640, 8640, 33, 8640, 4320, 33, 4320, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 4320, 8640, 8640, 4320, 33, 8640, 33, 4320, 4320, 33, 4320, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 4320, 8640, 4320, 33, 4320, 8640, 4320, 8640, 33, 8640, 33, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 33, 8640, 33, 8640, 4320, 4320, 33, 4320, 8640, 4320, 4320, 8640, 33, 8640, 8640, 4320, 33, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 33, 8640, 4320, 8640, 8640, 33, 8640, 4320, 4320, 8640, 33, 4320, 33, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 33, 33, 33, 33]
Prompts retrieved: 1113045 . Total input tokens: 247844840 . Total output tokens: 218638540
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.6627913089469075,
    "estimated_duration": 3600.008640547152,
    "input_throughput": 3945.669418682595,
    "output_throughput": 3433.8712026316553,
    "total_throughput": 7379.5406213142505,
    "itl": 99.26125755668681,
    "ttft": 2147259.8240246517,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2821,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 21.22417155524274,
    "arrivals": 371350,
    "finished_requests": 57553,
    "scheduler_time": 145.33323948805827
}
#Debug simulation 
Total elapsed time: 5.662878799252212. Arrivals time: 0.21999173471704125 Scheduler time: 5.262944905553013 Scheduler overhead time: 0.05225785728543997 Adapter cache time: 0.05208834493532777 Engine time: 0.05171298189088702 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_8-16-16/adapters_256_slots_96_rate_0.8-0.4-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_8-16-16/adapters_256_slots_96_rate_0.8-0.4-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 33, 8640, 8640, 33, 8640, 4320, 8640, 33, 4320, 33, 8640, 4320, 4320, 4320, 4320, 8640, 33, 33, 33, 4320, 8640, 33, 8640, 8640, 4320, 4320, 4320, 33, 8640, 33, 4320, 4320, 33, 4320, 33, 33, 4320, 4320, 8640, 4320, 33, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 33, 8640, 8640, 4320, 33, 33, 8640, 4320, 33, 4320, 4320, 8640, 4320, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 4320, 33, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 33, 8640, 8640, 33, 8640, 33, 4320, 8640, 8640, 8640, 4320, 33, 8640, 4320, 33, 33, 33, 33, 33, 8640, 4320, 33, 8640, 33, 8640, 33, 33, 4320, 4320, 8640, 4320, 8640, 33, 4320, 33, 8640, 8640, 33, 8640, 4320, 33, 8640, 33, 33, 8640, 8640, 4320, 8640, 8640, 33, 8640, 4320, 4320, 33, 4320, 8640, 8640, 33, 8640, 4320, 33, 4320, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 4320, 8640, 8640, 4320, 33, 8640, 33, 4320, 4320, 33, 4320, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 4320, 8640, 4320, 33, 4320, 8640, 4320, 8640, 33, 8640, 33, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 33, 8640, 33, 8640, 4320, 4320, 33, 4320, 8640, 4320, 4320, 8640, 33, 8640, 8640, 4320, 33, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 33, 8640, 4320, 8640, 8640, 33, 8640, 4320, 4320, 8640, 33, 4320, 33, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 33, 33, 33, 33]
Prompts retrieved: 1113045 . Total input tokens: 247844840 . Total output tokens: 218638540
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 8.299207079224288,
    "estimated_duration": 3600.1135111296953,
    "input_throughput": 4515.725670799365,
    "output_throughput": 3928.6294602310595,
    "total_throughput": 8444.355131030425,
    "itl": 121.89136307748069,
    "ttft": 2057530.0251088615,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1713,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.750542282532107,
    "arrivals": 371350,
    "finished_requests": 65875,
    "scheduler_time": 134.8088708133807
}
#Debug simulation 
Total elapsed time: 8.29930108692497. Arrivals time: 0.25807302352041006 Scheduler time: 7.896600647363812 Scheduler overhead time: 0.04559524077922106 Adapter cache time: 0.03330468246713281 Engine time: 0.04503517551347613 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_8-16-32/adapters_256_slots_96_rate_0.8-0.4-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_8-16-32/adapters_256_slots_96_rate_0.8-0.4-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 33, 8640, 8640, 33, 8640, 4320, 8640, 33, 4320, 33, 8640, 4320, 4320, 4320, 4320, 8640, 33, 33, 33, 4320, 8640, 33, 8640, 8640, 4320, 4320, 4320, 33, 8640, 33, 4320, 4320, 33, 4320, 33, 33, 4320, 4320, 8640, 4320, 33, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 33, 8640, 8640, 4320, 33, 33, 8640, 4320, 33, 4320, 4320, 8640, 4320, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 4320, 33, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 33, 8640, 8640, 33, 8640, 33, 4320, 8640, 8640, 8640, 4320, 33, 8640, 4320, 33, 33, 33, 33, 33, 8640, 4320, 33, 8640, 33, 8640, 33, 33, 4320, 4320, 8640, 4320, 8640, 33, 4320, 33, 8640, 8640, 33, 8640, 4320, 33, 8640, 33, 33, 8640, 8640, 4320, 8640, 8640, 33, 8640, 4320, 4320, 33, 4320, 8640, 8640, 33, 8640, 4320, 33, 4320, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 4320, 8640, 8640, 4320, 33, 8640, 33, 4320, 4320, 33, 4320, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 4320, 8640, 4320, 33, 4320, 8640, 4320, 8640, 33, 8640, 33, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 33, 8640, 33, 8640, 4320, 4320, 33, 4320, 8640, 4320, 4320, 8640, 33, 8640, 8640, 4320, 33, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 33, 8640, 4320, 8640, 8640, 33, 8640, 4320, 4320, 8640, 33, 4320, 33, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 33, 33, 33, 33]
Prompts retrieved: 1113045 . Total input tokens: 247844840 . Total output tokens: 218638540
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 5.707111529540271,
    "estimated_duration": 3600.0393091266737,
    "input_throughput": 3959.1281583693626,
    "output_throughput": 3445.3193243072915,
    "total_throughput": 7404.447482676654,
    "itl": 99.72371888959691,
    "ttft": 2146441.9061610196,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2874,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 21.42318192194244,
    "arrivals": 371350,
    "finished_requests": 57749,
    "scheduler_time": 145.02603340211814
}
#Debug simulation 
Total elapsed time: 5.707225765567273. Arrivals time: 0.21996617643162608 Scheduler time: 5.306547936517745 Scheduler overhead time: 0.052335566375404596 Adapter cache time: 0.05248426320031285 Engine time: 0.05193433165550232 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_16-16-16/adapters_256_slots_96_rate_0.8-0.4-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_16-16-16/adapters_256_slots_96_rate_0.8-0.4-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 33, 8640, 8640, 33, 8640, 4320, 8640, 33, 4320, 33, 8640, 4320, 4320, 4320, 4320, 8640, 33, 33, 33, 4320, 8640, 33, 8640, 8640, 4320, 4320, 4320, 33, 8640, 33, 4320, 4320, 33, 4320, 33, 33, 4320, 4320, 8640, 4320, 33, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 33, 8640, 8640, 4320, 33, 33, 8640, 4320, 33, 4320, 4320, 8640, 4320, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 4320, 33, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 33, 8640, 8640, 33, 8640, 33, 4320, 8640, 8640, 8640, 4320, 33, 8640, 4320, 33, 33, 33, 33, 33, 8640, 4320, 33, 8640, 33, 8640, 33, 33, 4320, 4320, 8640, 4320, 8640, 33, 4320, 33, 8640, 8640, 33, 8640, 4320, 33, 8640, 33, 33, 8640, 8640, 4320, 8640, 8640, 33, 8640, 4320, 4320, 33, 4320, 8640, 8640, 33, 8640, 4320, 33, 4320, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 4320, 8640, 8640, 4320, 33, 8640, 33, 4320, 4320, 33, 4320, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 4320, 8640, 4320, 33, 4320, 8640, 4320, 8640, 33, 8640, 33, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 33, 8640, 33, 8640, 4320, 4320, 33, 4320, 8640, 4320, 4320, 8640, 33, 8640, 8640, 4320, 33, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 33, 8640, 4320, 8640, 8640, 33, 8640, 4320, 4320, 8640, 33, 4320, 33, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 33, 33, 33, 33]
Prompts retrieved: 1113045 . Total input tokens: 247844840 . Total output tokens: 218638540
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 8.205799578223377,
    "estimated_duration": 3600.0550807822838,
    "input_throughput": 4500.446697743128,
    "output_throughput": 3917.305619928336,
    "total_throughput": 8417.752317671464,
    "itl": 121.92893223082956,
    "ttft": 2058066.7538061826,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1778,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.350611432334814,
    "arrivals": 371350,
    "finished_requests": 65652,
    "scheduler_time": 134.61082320258578
}
#Debug simulation 
Total elapsed time: 8.205891525372863. Arrivals time: 0.25690654944628477 Scheduler time: 7.804610499646515 Scheduler overhead time: 0.04545271676033735 Adapter cache time: 0.03365243412554264 Engine time: 0.044730558060109615 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_16-16-32/adapters_256_slots_96_rate_0.8-0.4-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_16-16-32/adapters_256_slots_96_rate_0.8-0.4-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 33, 8640, 8640, 33, 8640, 4320, 8640, 33, 4320, 33, 8640, 4320, 4320, 4320, 4320, 8640, 33, 33, 33, 4320, 8640, 33, 8640, 8640, 4320, 4320, 4320, 33, 8640, 33, 4320, 4320, 33, 4320, 33, 33, 4320, 4320, 8640, 4320, 33, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 33, 8640, 8640, 4320, 33, 33, 8640, 4320, 33, 4320, 4320, 8640, 4320, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 4320, 33, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 33, 8640, 8640, 33, 8640, 33, 4320, 8640, 8640, 8640, 4320, 33, 8640, 4320, 33, 33, 33, 33, 33, 8640, 4320, 33, 8640, 33, 8640, 33, 33, 4320, 4320, 8640, 4320, 8640, 33, 4320, 33, 8640, 8640, 33, 8640, 4320, 33, 8640, 33, 33, 8640, 8640, 4320, 8640, 8640, 33, 8640, 4320, 4320, 33, 4320, 8640, 8640, 33, 8640, 4320, 33, 4320, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 4320, 8640, 8640, 4320, 33, 8640, 33, 4320, 4320, 33, 4320, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 4320, 8640, 4320, 33, 4320, 8640, 4320, 8640, 33, 8640, 33, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 33, 8640, 33, 8640, 4320, 4320, 33, 4320, 8640, 4320, 4320, 8640, 33, 8640, 8640, 4320, 33, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 33, 8640, 4320, 8640, 8640, 33, 8640, 4320, 4320, 8640, 33, 4320, 33, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 33, 33, 33, 33]
Prompts retrieved: 1113045 . Total input tokens: 247844840 . Total output tokens: 218638540
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.669713398907334,
    "estimated_duration": 3600.03647703028,
    "input_throughput": 3959.4732139376897,
    "output_throughput": 3445.294257193627,
    "total_throughput": 7404.767471131317,
    "itl": 99.68693161809124,
    "ttft": 2145696.841818558,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2737,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.197826328892404,
    "arrivals": 371350,
    "finished_requests": 57764,
    "scheduler_time": 145.0806014410983
}
#Debug simulation 
Total elapsed time: 5.669803304132074. Arrivals time: 0.22161844046786427 Scheduler time: 5.269903466105461 Scheduler overhead time: 0.05219169147312641 Adapter cache time: 0.050721658393740654 Engine time: 0.051454728934913874 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_8-8-8/adapters_256_slots_96_rate_0.8-0.1-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_8-8-8/adapters_256_slots_96_rate_0.8-0.1-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 540, 8640, 8640, 540, 8640, 1080, 8640, 540, 1080, 540, 8640, 1080, 1080, 1080, 1080, 8640, 540, 540, 540, 1080, 8640, 540, 8640, 8640, 1080, 1080, 1080, 540, 8640, 540, 1080, 1080, 540, 1080, 540, 540, 1080, 1080, 8640, 1080, 540, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 540, 8640, 8640, 1080, 540, 540, 8640, 1080, 540, 1080, 1080, 8640, 1080, 540, 540, 8640, 8640, 8640, 8640, 8640, 8640, 540, 1080, 540, 1080, 540, 540, 540, 1080, 1080, 1080, 540, 540, 8640, 8640, 540, 8640, 540, 1080, 8640, 8640, 8640, 1080, 540, 8640, 1080, 540, 540, 540, 540, 540, 8640, 1080, 540, 8640, 540, 8640, 540, 540, 1080, 1080, 8640, 1080, 8640, 540, 1080, 540, 8640, 8640, 540, 8640, 1080, 540, 8640, 540, 540, 8640, 8640, 1080, 8640, 8640, 540, 8640, 1080, 1080, 540, 1080, 8640, 8640, 540, 8640, 1080, 540, 1080, 8640, 540, 540, 540, 540, 540, 540, 8640, 540, 540, 540, 8640, 540, 1080, 8640, 8640, 1080, 540, 8640, 540, 1080, 1080, 540, 1080, 540, 8640, 540, 540, 8640, 540, 8640, 8640, 1080, 8640, 1080, 540, 1080, 8640, 1080, 8640, 540, 8640, 540, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 540, 8640, 540, 8640, 1080, 1080, 540, 1080, 8640, 1080, 1080, 8640, 540, 8640, 8640, 1080, 540, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 540, 8640, 1080, 8640, 8640, 540, 8640, 1080, 1080, 8640, 540, 1080, 540, 540, 540, 540, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 540, 540, 540, 540]
Prompts retrieved: 880740 . Total input tokens: 196131426 . Total output tokens: 172959159
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 10.005725756287575,
    "estimated_duration": 3600.1469833840924,
    "input_throughput": 4626.348334351618,
    "output_throughput": 4057.9648740528564,
    "total_throughput": 8684.313208404476,
    "itl": 135.59312294511867,
    "ttft": 1976826.3266756695,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1232,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.146487927362518,
    "arrivals": 293562,
    "finished_requests": 67737,
    "scheduler_time": 127.7771809758952
}
#Debug simulation 
Total elapsed time: 10.005846087355167. Arrivals time: 0.26165838446468115 Scheduler time: 9.61334847798571 Scheduler overhead time: 0.04279399663209915 Adapter cache time: 0.026887259911745787 Engine time: 0.04200118547305465 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_8-8-16/adapters_256_slots_96_rate_0.8-0.1-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_8-8-16/adapters_256_slots_96_rate_0.8-0.1-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 540, 8640, 8640, 540, 8640, 1080, 8640, 540, 1080, 540, 8640, 1080, 1080, 1080, 1080, 8640, 540, 540, 540, 1080, 8640, 540, 8640, 8640, 1080, 1080, 1080, 540, 8640, 540, 1080, 1080, 540, 1080, 540, 540, 1080, 1080, 8640, 1080, 540, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 540, 8640, 8640, 1080, 540, 540, 8640, 1080, 540, 1080, 1080, 8640, 1080, 540, 540, 8640, 8640, 8640, 8640, 8640, 8640, 540, 1080, 540, 1080, 540, 540, 540, 1080, 1080, 1080, 540, 540, 8640, 8640, 540, 8640, 540, 1080, 8640, 8640, 8640, 1080, 540, 8640, 1080, 540, 540, 540, 540, 540, 8640, 1080, 540, 8640, 540, 8640, 540, 540, 1080, 1080, 8640, 1080, 8640, 540, 1080, 540, 8640, 8640, 540, 8640, 1080, 540, 8640, 540, 540, 8640, 8640, 1080, 8640, 8640, 540, 8640, 1080, 1080, 540, 1080, 8640, 8640, 540, 8640, 1080, 540, 1080, 8640, 540, 540, 540, 540, 540, 540, 8640, 540, 540, 540, 8640, 540, 1080, 8640, 8640, 1080, 540, 8640, 540, 1080, 1080, 540, 1080, 540, 8640, 540, 540, 8640, 540, 8640, 8640, 1080, 8640, 1080, 540, 1080, 8640, 1080, 8640, 540, 8640, 540, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 540, 8640, 540, 8640, 1080, 1080, 540, 1080, 8640, 1080, 1080, 8640, 540, 8640, 8640, 1080, 540, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 540, 8640, 1080, 8640, 8640, 540, 8640, 1080, 1080, 8640, 540, 1080, 540, 540, 540, 540, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 540, 540, 540, 540]
Prompts retrieved: 880740 . Total input tokens: 196131426 . Total output tokens: 172959159
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 7.808134229388088,
    "estimated_duration": 3600.121044327597,
    "input_throughput": 4429.339681543486,
    "output_throughput": 3888.278151662673,
    "total_throughput": 8317.617833206159,
    "itl": 123.57035038121904,
    "ttft": 2009555.607523983,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2013,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.719378283447327,
    "arrivals": 293562,
    "finished_requests": 64831,
    "scheduler_time": 132.0025431480912
}
#Debug simulation 
Total elapsed time: 7.808252822142094. Arrivals time: 0.24705753847956657 Scheduler time: 7.41223891498521 Scheduler overhead time: 0.045359001494944096 Adapter cache time: 0.03886521980166435 Engine time: 0.04433307470753789 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_8-8-32/adapters_256_slots_96_rate_0.8-0.1-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_8-8-32/adapters_256_slots_96_rate_0.8-0.1-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 540, 8640, 8640, 540, 8640, 1080, 8640, 540, 1080, 540, 8640, 1080, 1080, 1080, 1080, 8640, 540, 540, 540, 1080, 8640, 540, 8640, 8640, 1080, 1080, 1080, 540, 8640, 540, 1080, 1080, 540, 1080, 540, 540, 1080, 1080, 8640, 1080, 540, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 540, 8640, 8640, 1080, 540, 540, 8640, 1080, 540, 1080, 1080, 8640, 1080, 540, 540, 8640, 8640, 8640, 8640, 8640, 8640, 540, 1080, 540, 1080, 540, 540, 540, 1080, 1080, 1080, 540, 540, 8640, 8640, 540, 8640, 540, 1080, 8640, 8640, 8640, 1080, 540, 8640, 1080, 540, 540, 540, 540, 540, 8640, 1080, 540, 8640, 540, 8640, 540, 540, 1080, 1080, 8640, 1080, 8640, 540, 1080, 540, 8640, 8640, 540, 8640, 1080, 540, 8640, 540, 540, 8640, 8640, 1080, 8640, 8640, 540, 8640, 1080, 1080, 540, 1080, 8640, 8640, 540, 8640, 1080, 540, 1080, 8640, 540, 540, 540, 540, 540, 540, 8640, 540, 540, 540, 8640, 540, 1080, 8640, 8640, 1080, 540, 8640, 540, 1080, 1080, 540, 1080, 540, 8640, 540, 540, 8640, 540, 8640, 8640, 1080, 8640, 1080, 540, 1080, 8640, 1080, 8640, 540, 8640, 540, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 540, 8640, 540, 8640, 1080, 1080, 540, 1080, 8640, 1080, 1080, 8640, 540, 8640, 8640, 1080, 540, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 540, 8640, 1080, 8640, 8640, 540, 8640, 1080, 1080, 8640, 540, 1080, 540, 540, 540, 540, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 540, 540, 540, 540]
Prompts retrieved: 880740 . Total input tokens: 196131426 . Total output tokens: 172959159
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.7528092777356505,
    "estimated_duration": 3600.0864814107263,
    "input_throughput": 3909.331365419034,
    "output_throughput": 3440.9592836074726,
    "total_throughput": 7350.290649026507,
    "itl": 99.94052744927393,
    "ttft": 2098970.414132202,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3366,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 25.256529362658753,
    "arrivals": 293562,
    "finished_requests": 57285,
    "scheduler_time": 143.443647931642
}
#Debug simulation 
Total elapsed time: 5.7528993296436965. Arrivals time: 0.2216123240068555 Scheduler time: 5.341742231044918 Scheduler overhead time: 0.052511416375637054 Adapter cache time: 0.06118795368820429 Engine time: 0.05186349852010608 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_8-16-16/adapters_256_slots_96_rate_0.8-0.1-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_8-16-16/adapters_256_slots_96_rate_0.8-0.1-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 540, 8640, 8640, 540, 8640, 1080, 8640, 540, 1080, 540, 8640, 1080, 1080, 1080, 1080, 8640, 540, 540, 540, 1080, 8640, 540, 8640, 8640, 1080, 1080, 1080, 540, 8640, 540, 1080, 1080, 540, 1080, 540, 540, 1080, 1080, 8640, 1080, 540, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 540, 8640, 8640, 1080, 540, 540, 8640, 1080, 540, 1080, 1080, 8640, 1080, 540, 540, 8640, 8640, 8640, 8640, 8640, 8640, 540, 1080, 540, 1080, 540, 540, 540, 1080, 1080, 1080, 540, 540, 8640, 8640, 540, 8640, 540, 1080, 8640, 8640, 8640, 1080, 540, 8640, 1080, 540, 540, 540, 540, 540, 8640, 1080, 540, 8640, 540, 8640, 540, 540, 1080, 1080, 8640, 1080, 8640, 540, 1080, 540, 8640, 8640, 540, 8640, 1080, 540, 8640, 540, 540, 8640, 8640, 1080, 8640, 8640, 540, 8640, 1080, 1080, 540, 1080, 8640, 8640, 540, 8640, 1080, 540, 1080, 8640, 540, 540, 540, 540, 540, 540, 8640, 540, 540, 540, 8640, 540, 1080, 8640, 8640, 1080, 540, 8640, 540, 1080, 1080, 540, 1080, 540, 8640, 540, 540, 8640, 540, 8640, 8640, 1080, 8640, 1080, 540, 1080, 8640, 1080, 8640, 540, 8640, 540, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 540, 8640, 540, 8640, 1080, 1080, 540, 1080, 8640, 1080, 1080, 8640, 540, 8640, 8640, 1080, 540, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 540, 8640, 1080, 8640, 8640, 540, 8640, 1080, 1080, 8640, 540, 1080, 540, 540, 540, 540, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 540, 540, 540, 540]
Prompts retrieved: 880740 . Total input tokens: 196131426 . Total output tokens: 172959159
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 7.718978513032198,
    "estimated_duration": 3600.017216605335,
    "input_throughput": 4435.827952805778,
    "output_throughput": 3894.0819325356183,
    "total_throughput": 8329.909885341396,
    "itl": 124.10260207570103,
    "ttft": 2008492.5084125595,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2283,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.647586319693636,
    "arrivals": 293562,
    "finished_requests": 64936,
    "scheduler_time": 131.75431787173125
}
#Debug simulation 
Total elapsed time: 7.719069284852594. Arrivals time: 0.24553625844419003 Scheduler time: 7.320994585752487 Scheduler overhead time: 0.04522546147927642 Adapter cache time: 0.04267653822898865 Engine time: 0.04429912148043513 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_8-16-32/adapters_256_slots_96_rate_0.8-0.1-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_8-16-32/adapters_256_slots_96_rate_0.8-0.1-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 540, 8640, 8640, 540, 8640, 1080, 8640, 540, 1080, 540, 8640, 1080, 1080, 1080, 1080, 8640, 540, 540, 540, 1080, 8640, 540, 8640, 8640, 1080, 1080, 1080, 540, 8640, 540, 1080, 1080, 540, 1080, 540, 540, 1080, 1080, 8640, 1080, 540, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 540, 8640, 8640, 1080, 540, 540, 8640, 1080, 540, 1080, 1080, 8640, 1080, 540, 540, 8640, 8640, 8640, 8640, 8640, 8640, 540, 1080, 540, 1080, 540, 540, 540, 1080, 1080, 1080, 540, 540, 8640, 8640, 540, 8640, 540, 1080, 8640, 8640, 8640, 1080, 540, 8640, 1080, 540, 540, 540, 540, 540, 8640, 1080, 540, 8640, 540, 8640, 540, 540, 1080, 1080, 8640, 1080, 8640, 540, 1080, 540, 8640, 8640, 540, 8640, 1080, 540, 8640, 540, 540, 8640, 8640, 1080, 8640, 8640, 540, 8640, 1080, 1080, 540, 1080, 8640, 8640, 540, 8640, 1080, 540, 1080, 8640, 540, 540, 540, 540, 540, 540, 8640, 540, 540, 540, 8640, 540, 1080, 8640, 8640, 1080, 540, 8640, 540, 1080, 1080, 540, 1080, 540, 8640, 540, 540, 8640, 540, 8640, 8640, 1080, 8640, 1080, 540, 1080, 8640, 1080, 8640, 540, 8640, 540, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 540, 8640, 540, 8640, 1080, 1080, 540, 1080, 8640, 1080, 1080, 8640, 540, 8640, 8640, 1080, 540, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 540, 8640, 1080, 8640, 8640, 540, 8640, 1080, 1080, 8640, 540, 1080, 540, 540, 540, 540, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 540, 540, 540, 540]
Prompts retrieved: 880740 . Total input tokens: 196131426 . Total output tokens: 172959159
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 5.717474116943777,
    "estimated_duration": 3600.090738989553,
    "input_throughput": 3912.5316613417936,
    "output_throughput": 3441.532144125202,
    "total_throughput": 7354.063805466996,
    "itl": 99.94667221211432,
    "ttft": 2099115.0013025017,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3418,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 25.433484143438548,
    "arrivals": 293562,
    "finished_requests": 57307,
    "scheduler_time": 143.4288848313771
}
#Debug simulation 
Total elapsed time: 5.71759371785447. Arrivals time: 0.21921425452455878 Scheduler time: 5.308606563135982 Scheduler overhead time: 0.05269887577742338 Adapter cache time: 0.06119950581341982 Engine time: 0.051753956358879805 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_16-16-16/adapters_256_slots_96_rate_0.8-0.1-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_16-16-16/adapters_256_slots_96_rate_0.8-0.1-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 540, 8640, 8640, 540, 8640, 1080, 8640, 540, 1080, 540, 8640, 1080, 1080, 1080, 1080, 8640, 540, 540, 540, 1080, 8640, 540, 8640, 8640, 1080, 1080, 1080, 540, 8640, 540, 1080, 1080, 540, 1080, 540, 540, 1080, 1080, 8640, 1080, 540, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 540, 8640, 8640, 1080, 540, 540, 8640, 1080, 540, 1080, 1080, 8640, 1080, 540, 540, 8640, 8640, 8640, 8640, 8640, 8640, 540, 1080, 540, 1080, 540, 540, 540, 1080, 1080, 1080, 540, 540, 8640, 8640, 540, 8640, 540, 1080, 8640, 8640, 8640, 1080, 540, 8640, 1080, 540, 540, 540, 540, 540, 8640, 1080, 540, 8640, 540, 8640, 540, 540, 1080, 1080, 8640, 1080, 8640, 540, 1080, 540, 8640, 8640, 540, 8640, 1080, 540, 8640, 540, 540, 8640, 8640, 1080, 8640, 8640, 540, 8640, 1080, 1080, 540, 1080, 8640, 8640, 540, 8640, 1080, 540, 1080, 8640, 540, 540, 540, 540, 540, 540, 8640, 540, 540, 540, 8640, 540, 1080, 8640, 8640, 1080, 540, 8640, 540, 1080, 1080, 540, 1080, 540, 8640, 540, 540, 8640, 540, 8640, 8640, 1080, 8640, 1080, 540, 1080, 8640, 1080, 8640, 540, 8640, 540, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 540, 8640, 540, 8640, 1080, 1080, 540, 1080, 8640, 1080, 1080, 8640, 540, 8640, 8640, 1080, 540, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 540, 8640, 1080, 8640, 8640, 540, 8640, 1080, 1080, 8640, 540, 1080, 540, 540, 540, 540, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 540, 540, 540, 540]
Prompts retrieved: 880740 . Total input tokens: 196131426 . Total output tokens: 172959159
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 7.95421185484156,
    "estimated_duration": 3600.042066410049,
    "input_throughput": 4437.563424343715,
    "output_throughput": 3895.9353088854923,
    "total_throughput": 8333.498733229208,
    "itl": 123.85586492153367,
    "ttft": 2008648.1030997885,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1973,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.595476015746234,
    "arrivals": 293562,
    "finished_requests": 64955,
    "scheduler_time": 131.93345844615385
}
#Debug simulation 
Total elapsed time: 7.9543019430711865. Arrivals time: 0.24396852822974324 Scheduler time: 7.561722608748823 Scheduler overhead time: 0.04521617339923978 Adapter cache time: 0.03848059382289648 Engine time: 0.04448925331234932 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_16-16-32/adapters_256_slots_96_rate_0.8-0.1-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_16-16-32/adapters_256_slots_96_rate_0.8-0.1-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 540, 8640, 8640, 540, 8640, 1080, 8640, 540, 1080, 540, 8640, 1080, 1080, 1080, 1080, 8640, 540, 540, 540, 1080, 8640, 540, 8640, 8640, 1080, 1080, 1080, 540, 8640, 540, 1080, 1080, 540, 1080, 540, 540, 1080, 1080, 8640, 1080, 540, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 540, 8640, 8640, 1080, 540, 540, 8640, 1080, 540, 1080, 1080, 8640, 1080, 540, 540, 8640, 8640, 8640, 8640, 8640, 8640, 540, 1080, 540, 1080, 540, 540, 540, 1080, 1080, 1080, 540, 540, 8640, 8640, 540, 8640, 540, 1080, 8640, 8640, 8640, 1080, 540, 8640, 1080, 540, 540, 540, 540, 540, 8640, 1080, 540, 8640, 540, 8640, 540, 540, 1080, 1080, 8640, 1080, 8640, 540, 1080, 540, 8640, 8640, 540, 8640, 1080, 540, 8640, 540, 540, 8640, 8640, 1080, 8640, 8640, 540, 8640, 1080, 1080, 540, 1080, 8640, 8640, 540, 8640, 1080, 540, 1080, 8640, 540, 540, 540, 540, 540, 540, 8640, 540, 540, 540, 8640, 540, 1080, 8640, 8640, 1080, 540, 8640, 540, 1080, 1080, 540, 1080, 540, 8640, 540, 540, 8640, 540, 8640, 8640, 1080, 8640, 1080, 540, 1080, 8640, 1080, 8640, 540, 8640, 540, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 540, 8640, 540, 8640, 1080, 1080, 540, 1080, 8640, 1080, 1080, 8640, 540, 8640, 8640, 1080, 540, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 540, 8640, 1080, 8640, 8640, 540, 8640, 1080, 1080, 8640, 540, 1080, 540, 540, 540, 540, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 540, 540, 540, 540]
Prompts retrieved: 880740 . Total input tokens: 196131426 . Total output tokens: 172959159
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.744193512015045,
    "estimated_duration": 3600.0562390933987,
    "input_throughput": 3920.9465248672714,
    "output_throughput": 3449.6777759026013,
    "total_throughput": 7370.624300769873,
    "itl": 100.22819061725636,
    "ttft": 2097687.9129128065,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3344,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.654422937073466,
    "arrivals": 293562,
    "finished_requests": 57457,
    "scheduler_time": 143.27136079336518
}
#Debug simulation 
Total elapsed time: 5.744306767825037. Arrivals time: 0.2165253865532577 Scheduler time: 5.340030167251825 Scheduler overhead time: 0.05234434176236391 Adapter cache time: 0.05969622544944286 Engine time: 0.05171817960217595 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_8-8-8/adapters_256_slots_96_rate_0.8-0.1-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_8-8-8/adapters_256_slots_96_rate_0.8-0.1-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 270, 8640, 8640, 270, 8640, 1080, 8640, 270, 1080, 270, 8640, 1080, 1080, 1080, 1080, 8640, 270, 270, 270, 1080, 8640, 270, 8640, 8640, 1080, 1080, 1080, 270, 8640, 270, 1080, 1080, 270, 1080, 270, 270, 1080, 1080, 8640, 1080, 270, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 270, 8640, 8640, 1080, 270, 270, 8640, 1080, 270, 1080, 1080, 8640, 1080, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 270, 1080, 270, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 270, 8640, 8640, 270, 8640, 270, 1080, 8640, 8640, 8640, 1080, 270, 8640, 1080, 270, 270, 270, 270, 270, 8640, 1080, 270, 8640, 270, 8640, 270, 270, 1080, 1080, 8640, 1080, 8640, 270, 1080, 270, 8640, 8640, 270, 8640, 1080, 270, 8640, 270, 270, 8640, 8640, 1080, 8640, 8640, 270, 8640, 1080, 1080, 270, 1080, 8640, 8640, 270, 8640, 1080, 270, 1080, 8640, 270, 270, 270, 270, 270, 270, 8640, 270, 270, 270, 8640, 270, 1080, 8640, 8640, 1080, 270, 8640, 270, 1080, 1080, 270, 1080, 270, 8640, 270, 270, 8640, 270, 8640, 8640, 1080, 8640, 1080, 270, 1080, 8640, 1080, 8640, 270, 8640, 270, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 270, 8640, 270, 8640, 1080, 1080, 270, 1080, 8640, 1080, 1080, 8640, 270, 8640, 8640, 1080, 270, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 270, 8640, 1080, 8640, 8640, 270, 8640, 1080, 1080, 8640, 270, 1080, 270, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 270, 270, 270, 270]
Prompts retrieved: 857790 . Total input tokens: 191014731 . Total output tokens: 168440396
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 8.485548603348434,
    "estimated_duration": 3600.066869899262,
    "input_throughput": 4673.280971714499,
    "output_throughput": 4050.766423793696,
    "total_throughput": 8724.047395508196,
    "itl": 135.06198601361206,
    "ttft": 1969529.0984588885,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1755,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.604777851072447,
    "arrivals": 285871,
    "finished_requests": 67834,
    "scheduler_time": 127.51125393680269
}
#Debug simulation 
Total elapsed time: 8.48564178403467. Arrivals time: 0.2791494312696159 Scheduler time: 8.067805957514793 Scheduler overhead time: 0.042780105490237474 Adapter cache time: 0.033740182872861624 Engine time: 0.04309664014726877 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_8-8-16/adapters_256_slots_96_rate_0.8-0.1-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_8-8-16/adapters_256_slots_96_rate_0.8-0.1-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 270, 8640, 8640, 270, 8640, 1080, 8640, 270, 1080, 270, 8640, 1080, 1080, 1080, 1080, 8640, 270, 270, 270, 1080, 8640, 270, 8640, 8640, 1080, 1080, 1080, 270, 8640, 270, 1080, 1080, 270, 1080, 270, 270, 1080, 1080, 8640, 1080, 270, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 270, 8640, 8640, 1080, 270, 270, 8640, 1080, 270, 1080, 1080, 8640, 1080, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 270, 1080, 270, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 270, 8640, 8640, 270, 8640, 270, 1080, 8640, 8640, 8640, 1080, 270, 8640, 1080, 270, 270, 270, 270, 270, 8640, 1080, 270, 8640, 270, 8640, 270, 270, 1080, 1080, 8640, 1080, 8640, 270, 1080, 270, 8640, 8640, 270, 8640, 1080, 270, 8640, 270, 270, 8640, 8640, 1080, 8640, 8640, 270, 8640, 1080, 1080, 270, 1080, 8640, 8640, 270, 8640, 1080, 270, 1080, 8640, 270, 270, 270, 270, 270, 270, 8640, 270, 270, 270, 8640, 270, 1080, 8640, 8640, 1080, 270, 8640, 270, 1080, 1080, 270, 1080, 270, 8640, 270, 270, 8640, 270, 8640, 8640, 1080, 8640, 1080, 270, 1080, 8640, 1080, 8640, 270, 8640, 270, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 270, 8640, 270, 8640, 1080, 1080, 270, 1080, 8640, 1080, 1080, 8640, 270, 8640, 8640, 1080, 270, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 270, 8640, 1080, 8640, 8640, 270, 8640, 1080, 1080, 8640, 270, 1080, 270, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 270, 270, 270, 270]
Prompts retrieved: 857790 . Total input tokens: 191014731 . Total output tokens: 168440396
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 7.625097604934126,
    "estimated_duration": 3600.0527399830053,
    "input_throughput": 4481.078518887519,
    "output_throughput": 3889.3169104145118,
    "total_throughput": 8370.39542930203,
    "itl": 123.3494057812606,
    "ttft": 2000184.8842060398,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1722,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.585401316052142,
    "arrivals": 285871,
    "finished_requests": 65063,
    "scheduler_time": 131.7574309768782
}
#Debug simulation 
Total elapsed time: 7.625191690865904. Arrivals time: 0.2660556607879698 Scheduler time: 7.214934787712991 Scheduler overhead time: 0.04501026123762131 Adapter cache time: 0.03449449175968766 Engine time: 0.04431857541203499 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_8-8-32/adapters_256_slots_96_rate_0.8-0.1-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_8-8-32/adapters_256_slots_96_rate_0.8-0.1-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 270, 8640, 8640, 270, 8640, 1080, 8640, 270, 1080, 270, 8640, 1080, 1080, 1080, 1080, 8640, 270, 270, 270, 1080, 8640, 270, 8640, 8640, 1080, 1080, 1080, 270, 8640, 270, 1080, 1080, 270, 1080, 270, 270, 1080, 1080, 8640, 1080, 270, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 270, 8640, 8640, 1080, 270, 270, 8640, 1080, 270, 1080, 1080, 8640, 1080, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 270, 1080, 270, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 270, 8640, 8640, 270, 8640, 270, 1080, 8640, 8640, 8640, 1080, 270, 8640, 1080, 270, 270, 270, 270, 270, 8640, 1080, 270, 8640, 270, 8640, 270, 270, 1080, 1080, 8640, 1080, 8640, 270, 1080, 270, 8640, 8640, 270, 8640, 1080, 270, 8640, 270, 270, 8640, 8640, 1080, 8640, 8640, 270, 8640, 1080, 1080, 270, 1080, 8640, 8640, 270, 8640, 1080, 270, 1080, 8640, 270, 270, 270, 270, 270, 270, 8640, 270, 270, 270, 8640, 270, 1080, 8640, 8640, 1080, 270, 8640, 270, 1080, 1080, 270, 1080, 270, 8640, 270, 270, 8640, 270, 8640, 8640, 1080, 8640, 1080, 270, 1080, 8640, 1080, 8640, 270, 8640, 270, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 270, 8640, 270, 8640, 1080, 1080, 270, 1080, 8640, 1080, 1080, 8640, 270, 8640, 8640, 1080, 270, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 270, 8640, 1080, 8640, 8640, 270, 8640, 1080, 1080, 8640, 270, 1080, 270, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 270, 270, 270, 270]
Prompts retrieved: 857790 . Total input tokens: 191014731 . Total output tokens: 168440396
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.455010420177132,
    "estimated_duration": 3600.083463867787,
    "input_throughput": 3945.809074309197,
    "output_throughput": 3442.854623899128,
    "total_throughput": 7388.663698208325,
    "itl": 99.74722377120389,
    "ttft": 2090460.0840870652,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3058,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 22.97073791813151,
    "arrivals": 285871,
    "finished_requests": 57406,
    "scheduler_time": 143.206501364552
}
#Debug simulation 
Total elapsed time: 5.4551090891472995. Arrivals time: 0.23879040498286486 Scheduler time: 5.031947924289852 Scheduler overhead time: 0.05283240182325244 Adapter cache time: 0.05527139874175191 Engine time: 0.05194526258856058 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_8-16-16/adapters_256_slots_96_rate_0.8-0.1-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_8-16-16/adapters_256_slots_96_rate_0.8-0.1-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 270, 8640, 8640, 270, 8640, 1080, 8640, 270, 1080, 270, 8640, 1080, 1080, 1080, 1080, 8640, 270, 270, 270, 1080, 8640, 270, 8640, 8640, 1080, 1080, 1080, 270, 8640, 270, 1080, 1080, 270, 1080, 270, 270, 1080, 1080, 8640, 1080, 270, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 270, 8640, 8640, 1080, 270, 270, 8640, 1080, 270, 1080, 1080, 8640, 1080, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 270, 1080, 270, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 270, 8640, 8640, 270, 8640, 270, 1080, 8640, 8640, 8640, 1080, 270, 8640, 1080, 270, 270, 270, 270, 270, 8640, 1080, 270, 8640, 270, 8640, 270, 270, 1080, 1080, 8640, 1080, 8640, 270, 1080, 270, 8640, 8640, 270, 8640, 1080, 270, 8640, 270, 270, 8640, 8640, 1080, 8640, 8640, 270, 8640, 1080, 1080, 270, 1080, 8640, 8640, 270, 8640, 1080, 270, 1080, 8640, 270, 270, 270, 270, 270, 270, 8640, 270, 270, 270, 8640, 270, 1080, 8640, 8640, 1080, 270, 8640, 270, 1080, 1080, 270, 1080, 270, 8640, 270, 270, 8640, 270, 8640, 8640, 1080, 8640, 1080, 270, 1080, 8640, 1080, 8640, 270, 8640, 270, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 270, 8640, 270, 8640, 1080, 1080, 270, 1080, 8640, 1080, 1080, 8640, 270, 8640, 8640, 1080, 270, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 270, 8640, 1080, 8640, 8640, 270, 8640, 1080, 1080, 8640, 270, 1080, 270, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 270, 270, 270, 270]
Prompts retrieved: 857790 . Total input tokens: 191014731 . Total output tokens: 168440396
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 7.686667084693909,
    "estimated_duration": 3600.1024859597687,
    "input_throughput": 4484.0573464108875,
    "output_throughput": 3891.5694913237985,
    "total_throughput": 8375.626837734686,
    "itl": 123.45776529698082,
    "ttft": 1999977.4623841126,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1787,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.277093050093553,
    "arrivals": 285871,
    "finished_requests": 65126,
    "scheduler_time": 131.7135348734424
}
#Debug simulation 
Total elapsed time: 7.686789099127054. Arrivals time: 0.2455116081982851 Scheduler time: 7.295570569578558 Scheduler overhead time: 0.04525222955271602 Adapter cache time: 0.03557004779577255 Engine time: 0.04450847953557968 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_8-16-32/adapters_256_slots_96_rate_0.8-0.1-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_8-16-32/adapters_256_slots_96_rate_0.8-0.1-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 270, 8640, 8640, 270, 8640, 1080, 8640, 270, 1080, 270, 8640, 1080, 1080, 1080, 1080, 8640, 270, 270, 270, 1080, 8640, 270, 8640, 8640, 1080, 1080, 1080, 270, 8640, 270, 1080, 1080, 270, 1080, 270, 270, 1080, 1080, 8640, 1080, 270, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 270, 8640, 8640, 1080, 270, 270, 8640, 1080, 270, 1080, 1080, 8640, 1080, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 270, 1080, 270, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 270, 8640, 8640, 270, 8640, 270, 1080, 8640, 8640, 8640, 1080, 270, 8640, 1080, 270, 270, 270, 270, 270, 8640, 1080, 270, 8640, 270, 8640, 270, 270, 1080, 1080, 8640, 1080, 8640, 270, 1080, 270, 8640, 8640, 270, 8640, 1080, 270, 8640, 270, 270, 8640, 8640, 1080, 8640, 8640, 270, 8640, 1080, 1080, 270, 1080, 8640, 8640, 270, 8640, 1080, 270, 1080, 8640, 270, 270, 270, 270, 270, 270, 8640, 270, 270, 270, 8640, 270, 1080, 8640, 8640, 1080, 270, 8640, 270, 1080, 1080, 270, 1080, 270, 8640, 270, 270, 8640, 270, 8640, 8640, 1080, 8640, 1080, 270, 1080, 8640, 1080, 8640, 270, 8640, 270, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 270, 8640, 270, 8640, 1080, 1080, 270, 1080, 8640, 1080, 1080, 8640, 270, 8640, 8640, 1080, 270, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 270, 8640, 1080, 8640, 8640, 270, 8640, 1080, 1080, 8640, 270, 1080, 270, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 270, 270, 270, 270]
Prompts retrieved: 857790 . Total input tokens: 191014731 . Total output tokens: 168440396
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 5.70222724089399,
    "estimated_duration": 3600.012600766015,
    "input_throughput": 3943.3259197424345,
    "output_throughput": 3441.34934343393,
    "total_throughput": 7384.675263176364,
    "itl": 99.60445511148335,
    "ttft": 2090953.9473024497,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2999,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 22.32037597494238,
    "arrivals": 285871,
    "finished_requests": 57363,
    "scheduler_time": 143.3247472323837
}
#Debug simulation 
Total elapsed time: 5.702339806128293. Arrivals time: 0.2150527946650982 Scheduler time: 5.303479956462979 Scheduler overhead time: 0.052660844288766384 Adapter cache time: 0.05502000404521823 Engine time: 0.05212222784757614 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_16-16-16/adapters_256_slots_96_rate_0.8-0.1-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_16-16-16/adapters_256_slots_96_rate_0.8-0.1-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 270, 8640, 8640, 270, 8640, 1080, 8640, 270, 1080, 270, 8640, 1080, 1080, 1080, 1080, 8640, 270, 270, 270, 1080, 8640, 270, 8640, 8640, 1080, 1080, 1080, 270, 8640, 270, 1080, 1080, 270, 1080, 270, 270, 1080, 1080, 8640, 1080, 270, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 270, 8640, 8640, 1080, 270, 270, 8640, 1080, 270, 1080, 1080, 8640, 1080, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 270, 1080, 270, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 270, 8640, 8640, 270, 8640, 270, 1080, 8640, 8640, 8640, 1080, 270, 8640, 1080, 270, 270, 270, 270, 270, 8640, 1080, 270, 8640, 270, 8640, 270, 270, 1080, 1080, 8640, 1080, 8640, 270, 1080, 270, 8640, 8640, 270, 8640, 1080, 270, 8640, 270, 270, 8640, 8640, 1080, 8640, 8640, 270, 8640, 1080, 1080, 270, 1080, 8640, 8640, 270, 8640, 1080, 270, 1080, 8640, 270, 270, 270, 270, 270, 270, 8640, 270, 270, 270, 8640, 270, 1080, 8640, 8640, 1080, 270, 8640, 270, 1080, 1080, 270, 1080, 270, 8640, 270, 270, 8640, 270, 8640, 8640, 1080, 8640, 1080, 270, 1080, 8640, 1080, 8640, 270, 8640, 270, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 270, 8640, 270, 8640, 1080, 1080, 270, 1080, 8640, 1080, 1080, 8640, 270, 8640, 8640, 1080, 270, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 270, 8640, 1080, 8640, 8640, 270, 8640, 1080, 1080, 8640, 270, 1080, 270, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 270, 270, 270, 270]
Prompts retrieved: 857790 . Total input tokens: 191014731 . Total output tokens: 168440396
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 7.780983577016741,
    "estimated_duration": 3600.0936572386504,
    "input_throughput": 4488.462117508969,
    "output_throughput": 3894.3495183271593,
    "total_throughput": 8382.811635836128,
    "itl": 123.39352738247311,
    "ttft": 1999854.4082864046,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1667,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.64199620793139,
    "arrivals": 285871,
    "finished_requests": 65155,
    "scheduler_time": 131.7864253936298
}
#Debug simulation 
Total elapsed time: 7.781107295304537. Arrivals time: 0.3060455685481429 Scheduler time: 7.331887734122574 Scheduler overhead time: 0.04506770055741072 Adapter cache time: 0.03345752786844969 Engine time: 0.044148676097393036 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_16-16-32/adapters_256_slots_96_rate_0.8-0.1-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_16-16-32/adapters_256_slots_96_rate_0.8-0.1-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 270, 8640, 8640, 270, 8640, 1080, 8640, 270, 1080, 270, 8640, 1080, 1080, 1080, 1080, 8640, 270, 270, 270, 1080, 8640, 270, 8640, 8640, 1080, 1080, 1080, 270, 8640, 270, 1080, 1080, 270, 1080, 270, 270, 1080, 1080, 8640, 1080, 270, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 270, 8640, 8640, 1080, 270, 270, 8640, 1080, 270, 1080, 1080, 8640, 1080, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 270, 1080, 270, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 270, 8640, 8640, 270, 8640, 270, 1080, 8640, 8640, 8640, 1080, 270, 8640, 1080, 270, 270, 270, 270, 270, 8640, 1080, 270, 8640, 270, 8640, 270, 270, 1080, 1080, 8640, 1080, 8640, 270, 1080, 270, 8640, 8640, 270, 8640, 1080, 270, 8640, 270, 270, 8640, 8640, 1080, 8640, 8640, 270, 8640, 1080, 1080, 270, 1080, 8640, 8640, 270, 8640, 1080, 270, 1080, 8640, 270, 270, 270, 270, 270, 270, 8640, 270, 270, 270, 8640, 270, 1080, 8640, 8640, 1080, 270, 8640, 270, 1080, 1080, 270, 1080, 270, 8640, 270, 270, 8640, 270, 8640, 8640, 1080, 8640, 1080, 270, 1080, 8640, 1080, 8640, 270, 8640, 270, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 270, 8640, 270, 8640, 1080, 1080, 270, 1080, 8640, 1080, 1080, 8640, 270, 8640, 8640, 1080, 270, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 270, 8640, 1080, 8640, 8640, 270, 8640, 1080, 1080, 8640, 270, 1080, 270, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 270, 270, 270, 270]
Prompts retrieved: 857790 . Total input tokens: 191014731 . Total output tokens: 168440396
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.469012578949332,
    "estimated_duration": 3600.040044668436,
    "input_throughput": 3945.322225244338,
    "output_throughput": 3442.4430968076604,
    "total_throughput": 7387.765322051999,
    "itl": 99.63811653250822,
    "ttft": 2090948.8872575362,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2995,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 22.06283121375403,
    "arrivals": 285871,
    "finished_requests": 57391,
    "scheduler_time": 143.29485199037592
}
#Debug simulation 
Total elapsed time: 5.469101986847818. Arrivals time: 0.23964125523343682 Scheduler time: 5.04542622808367 Scheduler overhead time: 0.0522529655136168 Adapter cache time: 0.05625413125380874 Engine time: 0.05160877201706171 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-8/adapters_256_slots_96_rate_0.8-0.1-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-8/adapters_256_slots_96_rate_0.8-0.1-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 135, 8640, 8640, 135, 8640, 1080, 8640, 135, 1080, 135, 8640, 1080, 1080, 1080, 1080, 8640, 135, 135, 135, 1080, 8640, 135, 8640, 8640, 1080, 1080, 1080, 135, 8640, 135, 1080, 1080, 135, 1080, 135, 135, 1080, 1080, 8640, 1080, 135, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 135, 8640, 8640, 1080, 135, 135, 8640, 1080, 135, 1080, 1080, 8640, 1080, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 135, 1080, 135, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 135, 8640, 8640, 135, 8640, 135, 1080, 8640, 8640, 8640, 1080, 135, 8640, 1080, 135, 135, 135, 135, 135, 8640, 1080, 135, 8640, 135, 8640, 135, 135, 1080, 1080, 8640, 1080, 8640, 135, 1080, 135, 8640, 8640, 135, 8640, 1080, 135, 8640, 135, 135, 8640, 8640, 1080, 8640, 8640, 135, 8640, 1080, 1080, 135, 1080, 8640, 8640, 135, 8640, 1080, 135, 1080, 8640, 135, 135, 135, 135, 135, 135, 8640, 135, 135, 135, 8640, 135, 1080, 8640, 8640, 1080, 135, 8640, 135, 1080, 1080, 135, 1080, 135, 8640, 135, 135, 8640, 135, 8640, 8640, 1080, 8640, 1080, 135, 1080, 8640, 1080, 8640, 135, 8640, 135, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 135, 8640, 135, 8640, 1080, 1080, 135, 1080, 8640, 1080, 1080, 8640, 135, 8640, 8640, 1080, 135, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 135, 8640, 1080, 8640, 8640, 135, 8640, 1080, 1080, 8640, 135, 1080, 135, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 135, 135, 135, 135]
Prompts retrieved: 846315 . Total input tokens: 188481277 . Total output tokens: 166186996
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 8.256098790094256,
    "estimated_duration": 3600.099209662025,
    "input_throughput": 4649.383815611953,
    "output_throughput": 4057.5123487697824,
    "total_throughput": 8706.896164381735,
    "itl": 135.40246482321626,
    "ttft": 1965948.3507598378,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1273,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.417596697672474,
    "arrivals": 281942,
    "finished_requests": 67872,
    "scheduler_time": 127.55613577453308
}
#Debug simulation 
Total elapsed time: 8.256215789820999. Arrivals time: 0.249317635782063 Scheduler time: 7.877617768011987 Scheduler overhead time: 0.04225621139630675 Adapter cache time: 0.02663181582465768 Engine time: 0.041387638077139854 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-16/adapters_256_slots_96_rate_0.8-0.1-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-16/adapters_256_slots_96_rate_0.8-0.1-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 135, 8640, 8640, 135, 8640, 1080, 8640, 135, 1080, 135, 8640, 1080, 1080, 1080, 1080, 8640, 135, 135, 135, 1080, 8640, 135, 8640, 8640, 1080, 1080, 1080, 135, 8640, 135, 1080, 1080, 135, 1080, 135, 135, 1080, 1080, 8640, 1080, 135, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 135, 8640, 8640, 1080, 135, 135, 8640, 1080, 135, 1080, 1080, 8640, 1080, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 135, 1080, 135, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 135, 8640, 8640, 135, 8640, 135, 1080, 8640, 8640, 8640, 1080, 135, 8640, 1080, 135, 135, 135, 135, 135, 8640, 1080, 135, 8640, 135, 8640, 135, 135, 1080, 1080, 8640, 1080, 8640, 135, 1080, 135, 8640, 8640, 135, 8640, 1080, 135, 8640, 135, 135, 8640, 8640, 1080, 8640, 8640, 135, 8640, 1080, 1080, 135, 1080, 8640, 8640, 135, 8640, 1080, 135, 1080, 8640, 135, 135, 135, 135, 135, 135, 8640, 135, 135, 135, 8640, 135, 1080, 8640, 8640, 1080, 135, 8640, 135, 1080, 1080, 135, 1080, 135, 8640, 135, 135, 8640, 135, 8640, 8640, 1080, 8640, 1080, 135, 1080, 8640, 1080, 8640, 135, 8640, 135, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 135, 8640, 135, 8640, 1080, 1080, 135, 1080, 8640, 1080, 1080, 8640, 135, 8640, 8640, 1080, 135, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 135, 8640, 1080, 8640, 8640, 135, 8640, 1080, 1080, 8640, 135, 1080, 135, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 135, 135, 135, 135]
Prompts retrieved: 846315 . Total input tokens: 188481277 . Total output tokens: 166186996
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 7.137301630806178,
    "estimated_duration": 3600.030352304896,
    "input_throughput": 4455.852987386543,
    "output_throughput": 3894.8871614437057,
    "total_throughput": 8350.74014883025,
    "itl": 123.67966407424412,
    "ttft": 1997589.4678124518,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1595,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.653868131921504,
    "arrivals": 281942,
    "finished_requests": 65067,
    "scheduler_time": 131.74984835879417
}
#Debug simulation 
Total elapsed time: 7.13741814577952. Arrivals time: 0.23791546234861016 Scheduler time: 6.758369831368327 Scheduler overhead time: 0.04477324616163969 Adapter cache time: 0.0322695248760283 Engine time: 0.043803205247968435 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-32/adapters_256_slots_96_rate_0.8-0.1-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-32/adapters_256_slots_96_rate_0.8-0.1-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 135, 8640, 8640, 135, 8640, 1080, 8640, 135, 1080, 135, 8640, 1080, 1080, 1080, 1080, 8640, 135, 135, 135, 1080, 8640, 135, 8640, 8640, 1080, 1080, 1080, 135, 8640, 135, 1080, 1080, 135, 1080, 135, 135, 1080, 1080, 8640, 1080, 135, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 135, 8640, 8640, 1080, 135, 135, 8640, 1080, 135, 1080, 1080, 8640, 1080, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 135, 1080, 135, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 135, 8640, 8640, 135, 8640, 135, 1080, 8640, 8640, 8640, 1080, 135, 8640, 1080, 135, 135, 135, 135, 135, 8640, 1080, 135, 8640, 135, 8640, 135, 135, 1080, 1080, 8640, 1080, 8640, 135, 1080, 135, 8640, 8640, 135, 8640, 1080, 135, 8640, 135, 135, 8640, 8640, 1080, 8640, 8640, 135, 8640, 1080, 1080, 135, 1080, 8640, 8640, 135, 8640, 1080, 135, 1080, 8640, 135, 135, 135, 135, 135, 135, 8640, 135, 135, 135, 8640, 135, 1080, 8640, 8640, 1080, 135, 8640, 135, 1080, 1080, 135, 1080, 135, 8640, 135, 135, 8640, 135, 8640, 8640, 1080, 8640, 1080, 135, 1080, 8640, 1080, 8640, 135, 8640, 135, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 135, 8640, 135, 8640, 1080, 1080, 135, 1080, 8640, 1080, 1080, 8640, 135, 8640, 8640, 1080, 135, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 135, 8640, 1080, 8640, 8640, 135, 8640, 1080, 1080, 8640, 135, 1080, 135, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 135, 135, 135, 135]
Prompts retrieved: 846315 . Total input tokens: 188481277 . Total output tokens: 166186996
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.224773944355547,
    "estimated_duration": 3600.1100253436243,
    "input_throughput": 3951.756724057921,
    "output_throughput": 3452.2411572167784,
    "total_throughput": 7403.9978812746995,
    "itl": 100.09048664101213,
    "ttft": 2089248.8658973647,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2832,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 21.239529687385335,
    "arrivals": 281942,
    "finished_requests": 57710,
    "scheduler_time": 143.07069975376646
}
#Debug simulation 
Total elapsed time: 5.224887304008007. Arrivals time: 0.2113708476535976 Scheduler time: 4.833004264626652 Scheduler overhead time: 0.05211538542062044 Adapter cache time: 0.05266840569674969 Engine time: 0.051927225198596716 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_8-16-16/adapters_256_slots_96_rate_0.8-0.1-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_8-16-16/adapters_256_slots_96_rate_0.8-0.1-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 135, 8640, 8640, 135, 8640, 1080, 8640, 135, 1080, 135, 8640, 1080, 1080, 1080, 1080, 8640, 135, 135, 135, 1080, 8640, 135, 8640, 8640, 1080, 1080, 1080, 135, 8640, 135, 1080, 1080, 135, 1080, 135, 135, 1080, 1080, 8640, 1080, 135, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 135, 8640, 8640, 1080, 135, 135, 8640, 1080, 135, 1080, 1080, 8640, 1080, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 135, 1080, 135, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 135, 8640, 8640, 135, 8640, 135, 1080, 8640, 8640, 8640, 1080, 135, 8640, 1080, 135, 135, 135, 135, 135, 8640, 1080, 135, 8640, 135, 8640, 135, 135, 1080, 1080, 8640, 1080, 8640, 135, 1080, 135, 8640, 8640, 135, 8640, 1080, 135, 8640, 135, 135, 8640, 8640, 1080, 8640, 8640, 135, 8640, 1080, 1080, 135, 1080, 8640, 8640, 135, 8640, 1080, 135, 1080, 8640, 135, 135, 135, 135, 135, 135, 8640, 135, 135, 135, 8640, 135, 1080, 8640, 8640, 1080, 135, 8640, 135, 1080, 1080, 135, 1080, 135, 8640, 135, 135, 8640, 135, 8640, 8640, 1080, 8640, 1080, 135, 1080, 8640, 1080, 8640, 135, 8640, 135, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 135, 8640, 135, 8640, 1080, 1080, 135, 1080, 8640, 1080, 1080, 8640, 135, 8640, 8640, 1080, 135, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 135, 8640, 1080, 8640, 8640, 135, 8640, 1080, 1080, 8640, 135, 1080, 135, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 135, 135, 135, 135]
Prompts retrieved: 846315 . Total input tokens: 188481277 . Total output tokens: 166186996
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 6.923878433182836,
    "estimated_duration": 3600.053279018046,
    "input_throughput": 4462.005074653085,
    "output_throughput": 3899.4961774091094,
    "total_throughput": 8361.501252062195,
    "itl": 123.99433835132669,
    "ttft": 1996900.7240264216,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1774,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.174666984239751,
    "arrivals": 281942,
    "finished_requests": 65152,
    "scheduler_time": 131.59946663803638
}
#Debug simulation 
Total elapsed time: 6.923995485994965. Arrivals time: 0.2375817783176899 Scheduler time: 6.542543620802462 Scheduler overhead time: 0.044667075388133526 Adapter cache time: 0.03461230592802167 Engine time: 0.04432691773399711 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_8-16-32/adapters_256_slots_96_rate_0.8-0.1-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_8-16-32/adapters_256_slots_96_rate_0.8-0.1-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 135, 8640, 8640, 135, 8640, 1080, 8640, 135, 1080, 135, 8640, 1080, 1080, 1080, 1080, 8640, 135, 135, 135, 1080, 8640, 135, 8640, 8640, 1080, 1080, 1080, 135, 8640, 135, 1080, 1080, 135, 1080, 135, 135, 1080, 1080, 8640, 1080, 135, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 135, 8640, 8640, 1080, 135, 135, 8640, 1080, 135, 1080, 1080, 8640, 1080, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 135, 1080, 135, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 135, 8640, 8640, 135, 8640, 135, 1080, 8640, 8640, 8640, 1080, 135, 8640, 1080, 135, 135, 135, 135, 135, 8640, 1080, 135, 8640, 135, 8640, 135, 135, 1080, 1080, 8640, 1080, 8640, 135, 1080, 135, 8640, 8640, 135, 8640, 1080, 135, 8640, 135, 135, 8640, 8640, 1080, 8640, 8640, 135, 8640, 1080, 1080, 135, 1080, 8640, 8640, 135, 8640, 1080, 135, 1080, 8640, 135, 135, 135, 135, 135, 135, 8640, 135, 135, 135, 8640, 135, 1080, 8640, 8640, 1080, 135, 8640, 135, 1080, 1080, 135, 1080, 135, 8640, 135, 135, 8640, 135, 8640, 8640, 1080, 8640, 1080, 135, 1080, 8640, 1080, 8640, 135, 8640, 135, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 135, 8640, 135, 8640, 1080, 1080, 135, 1080, 8640, 1080, 1080, 8640, 135, 8640, 8640, 1080, 135, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 135, 8640, 1080, 8640, 8640, 135, 8640, 1080, 1080, 8640, 135, 1080, 135, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 135, 135, 135, 135]
Prompts retrieved: 846315 . Total input tokens: 188481277 . Total output tokens: 166186996
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 5.244350716937333,
    "estimated_duration": 3600.0618290103653,
    "input_throughput": 3951.880738645791,
    "output_throughput": 3452.3407069974005,
    "total_throughput": 7404.221445643192,
    "itl": 100.12664160981046,
    "ttft": 2089270.8717725596,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2854,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 21.249646581975078,
    "arrivals": 281942,
    "finished_requests": 57705,
    "scheduler_time": 143.06013825574303
}
#Debug simulation 
Total elapsed time: 5.244442930910736. Arrivals time: 0.21122712036594748 Scheduler time: 4.852022603154182 Scheduler overhead time: 0.05230032233521342 Adapter cache time: 0.053261284716427326 Engine time: 0.051727287005633116 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_16-16-16/adapters_256_slots_96_rate_0.8-0.1-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_16-16-16/adapters_256_slots_96_rate_0.8-0.1-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 135, 8640, 8640, 135, 8640, 1080, 8640, 135, 1080, 135, 8640, 1080, 1080, 1080, 1080, 8640, 135, 135, 135, 1080, 8640, 135, 8640, 8640, 1080, 1080, 1080, 135, 8640, 135, 1080, 1080, 135, 1080, 135, 135, 1080, 1080, 8640, 1080, 135, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 135, 8640, 8640, 1080, 135, 135, 8640, 1080, 135, 1080, 1080, 8640, 1080, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 135, 1080, 135, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 135, 8640, 8640, 135, 8640, 135, 1080, 8640, 8640, 8640, 1080, 135, 8640, 1080, 135, 135, 135, 135, 135, 8640, 1080, 135, 8640, 135, 8640, 135, 135, 1080, 1080, 8640, 1080, 8640, 135, 1080, 135, 8640, 8640, 135, 8640, 1080, 135, 8640, 135, 135, 8640, 8640, 1080, 8640, 8640, 135, 8640, 1080, 1080, 135, 1080, 8640, 8640, 135, 8640, 1080, 135, 1080, 8640, 135, 135, 135, 135, 135, 135, 8640, 135, 135, 135, 8640, 135, 1080, 8640, 8640, 1080, 135, 8640, 135, 1080, 1080, 135, 1080, 135, 8640, 135, 135, 8640, 135, 8640, 8640, 1080, 8640, 1080, 135, 1080, 8640, 1080, 8640, 135, 8640, 135, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 135, 8640, 135, 8640, 1080, 1080, 135, 1080, 8640, 1080, 1080, 8640, 135, 8640, 8640, 1080, 135, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 135, 8640, 1080, 8640, 8640, 135, 8640, 1080, 1080, 8640, 135, 1080, 135, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 135, 135, 135, 135]
Prompts retrieved: 846315 . Total input tokens: 188481277 . Total output tokens: 166186996
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 7.195086078718305,
    "estimated_duration": 3600.0027196563574,
    "input_throughput": 4465.047460168136,
    "output_throughput": 3900.720664272291,
    "total_throughput": 8365.768124440427,
    "itl": 123.81525830120798,
    "ttft": 1996292.9637851513,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1442,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.205613996302828,
    "arrivals": 281942,
    "finished_requests": 65187,
    "scheduler_time": 131.73858056646512
}
#Debug simulation 
Total elapsed time: 7.195216648746282. Arrivals time: 0.23878828482702374 Scheduler time: 6.817395717371255 Scheduler overhead time: 0.0448546907864511 Adapter cache time: 0.02976524457335472 Engine time: 0.04404157446697354 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_16-16-32/adapters_256_slots_96_rate_0.8-0.1-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_16-16-32/adapters_256_slots_96_rate_0.8-0.1-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 135, 8640, 8640, 135, 8640, 1080, 8640, 135, 1080, 135, 8640, 1080, 1080, 1080, 1080, 8640, 135, 135, 135, 1080, 8640, 135, 8640, 8640, 1080, 1080, 1080, 135, 8640, 135, 1080, 1080, 135, 1080, 135, 135, 1080, 1080, 8640, 1080, 135, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 135, 8640, 8640, 1080, 135, 135, 8640, 1080, 135, 1080, 1080, 8640, 1080, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 135, 1080, 135, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 135, 8640, 8640, 135, 8640, 135, 1080, 8640, 8640, 8640, 1080, 135, 8640, 1080, 135, 135, 135, 135, 135, 8640, 1080, 135, 8640, 135, 8640, 135, 135, 1080, 1080, 8640, 1080, 8640, 135, 1080, 135, 8640, 8640, 135, 8640, 1080, 135, 8640, 135, 135, 8640, 8640, 1080, 8640, 8640, 135, 8640, 1080, 1080, 135, 1080, 8640, 8640, 135, 8640, 1080, 135, 1080, 8640, 135, 135, 135, 135, 135, 135, 8640, 135, 135, 135, 8640, 135, 1080, 8640, 8640, 1080, 135, 8640, 135, 1080, 1080, 135, 1080, 135, 8640, 135, 135, 8640, 135, 8640, 8640, 1080, 8640, 1080, 135, 1080, 8640, 1080, 8640, 135, 8640, 135, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 135, 8640, 135, 8640, 1080, 1080, 135, 1080, 8640, 1080, 1080, 8640, 135, 8640, 8640, 1080, 135, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 135, 8640, 1080, 8640, 8640, 135, 8640, 1080, 1080, 8640, 135, 1080, 135, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 135, 135, 135, 135]
Prompts retrieved: 846315 . Total input tokens: 188481277 . Total output tokens: 166186996
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.271879954729229,
    "estimated_duration": 3600.015971275358,
    "input_throughput": 3953.5341269493947,
    "output_throughput": 3452.9213479006567,
    "total_throughput": 7406.455474850051,
    "itl": 100.08530852742321,
    "ttft": 2089198.0152562181,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2832,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.86128257140539,
    "arrivals": 281942,
    "finished_requests": 57711,
    "scheduler_time": 143.08555942219516
}
#Debug simulation 
Total elapsed time: 5.2719996008090675. Arrivals time: 0.21187855070456862 Scheduler time: 4.879277526400983 Scheduler overhead time: 0.05229790974408388 Adapter cache time: 0.052633619867265224 Engine time: 0.05185778625309467 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-8/adapters_256_slots_96_rate_0.8-0.1-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-8/adapters_256_slots_96_rate_0.8-0.1-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 66, 8640, 8640, 66, 8640, 1080, 8640, 66, 1080, 66, 8640, 1080, 1080, 1080, 1080, 8640, 66, 66, 66, 1080, 8640, 66, 8640, 8640, 1080, 1080, 1080, 66, 8640, 66, 1080, 1080, 66, 1080, 66, 66, 1080, 1080, 8640, 1080, 66, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 66, 8640, 8640, 1080, 66, 66, 8640, 1080, 66, 1080, 1080, 8640, 1080, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 66, 1080, 66, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 66, 8640, 8640, 66, 8640, 66, 1080, 8640, 8640, 8640, 1080, 66, 8640, 1080, 66, 66, 66, 66, 66, 8640, 1080, 66, 8640, 66, 8640, 66, 66, 1080, 1080, 8640, 1080, 8640, 66, 1080, 66, 8640, 8640, 66, 8640, 1080, 66, 8640, 66, 66, 8640, 8640, 1080, 8640, 8640, 66, 8640, 1080, 1080, 66, 1080, 8640, 8640, 66, 8640, 1080, 66, 1080, 8640, 66, 66, 66, 66, 66, 66, 8640, 66, 66, 66, 8640, 66, 1080, 8640, 8640, 1080, 66, 8640, 66, 1080, 1080, 66, 1080, 66, 8640, 66, 66, 8640, 66, 8640, 8640, 1080, 8640, 1080, 66, 1080, 8640, 1080, 8640, 66, 8640, 66, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 66, 8640, 66, 8640, 1080, 1080, 66, 1080, 8640, 1080, 1080, 8640, 66, 8640, 8640, 1080, 66, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 66, 8640, 1080, 8640, 8640, 66, 8640, 1080, 1080, 8640, 66, 1080, 66, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 66, 66, 66, 66]
Prompts retrieved: 840450 . Total input tokens: 187162021 . Total output tokens: 165050758
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 8.06680294405669,
    "estimated_duration": 3600.084219486318,
    "input_throughput": 4681.264929520088,
    "output_throughput": 4055.469569565576,
    "total_throughput": 8736.734499085664,
    "itl": 135.07983622744717,
    "ttft": 1960213.1420147147,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 990,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.5462849416305815,
    "arrivals": 279961,
    "finished_requests": 67907,
    "scheduler_time": 127.65266573049622
}
#Debug simulation 
Total elapsed time: 8.066928386222571. Arrivals time: 0.24734340468421578 Scheduler time: 7.694740436971188 Scheduler overhead time: 0.04203583160415292 Adapter cache time: 0.02262665517628193 Engine time: 0.04130258271470666 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-16/adapters_256_slots_96_rate_0.8-0.1-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-16/adapters_256_slots_96_rate_0.8-0.1-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 66, 8640, 8640, 66, 8640, 1080, 8640, 66, 1080, 66, 8640, 1080, 1080, 1080, 1080, 8640, 66, 66, 66, 1080, 8640, 66, 8640, 8640, 1080, 1080, 1080, 66, 8640, 66, 1080, 1080, 66, 1080, 66, 66, 1080, 1080, 8640, 1080, 66, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 66, 8640, 8640, 1080, 66, 66, 8640, 1080, 66, 1080, 1080, 8640, 1080, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 66, 1080, 66, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 66, 8640, 8640, 66, 8640, 66, 1080, 8640, 8640, 8640, 1080, 66, 8640, 1080, 66, 66, 66, 66, 66, 8640, 1080, 66, 8640, 66, 8640, 66, 66, 1080, 1080, 8640, 1080, 8640, 66, 1080, 66, 8640, 8640, 66, 8640, 1080, 66, 8640, 66, 66, 8640, 8640, 1080, 8640, 8640, 66, 8640, 1080, 1080, 66, 1080, 8640, 8640, 66, 8640, 1080, 66, 1080, 8640, 66, 66, 66, 66, 66, 66, 8640, 66, 66, 66, 8640, 66, 1080, 8640, 8640, 1080, 66, 8640, 66, 1080, 1080, 66, 1080, 66, 8640, 66, 66, 8640, 66, 8640, 8640, 1080, 8640, 1080, 66, 1080, 8640, 1080, 8640, 66, 8640, 66, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 66, 8640, 66, 8640, 1080, 1080, 66, 1080, 8640, 1080, 1080, 8640, 66, 8640, 8640, 1080, 66, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 66, 8640, 1080, 8640, 8640, 66, 8640, 1080, 1080, 8640, 66, 1080, 66, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 66, 66, 66, 66]
Prompts retrieved: 840450 . Total input tokens: 187162021 . Total output tokens: 165050758
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 6.957550805062056,
    "estimated_duration": 3600.1334098603716,
    "input_throughput": 4497.833873503045,
    "output_throughput": 3897.267240589334,
    "total_throughput": 8395.101114092378,
    "itl": 123.66971234894534,
    "ttft": 1991568.7337834632,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1446,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.552736046658744,
    "arrivals": 279961,
    "finished_requests": 65218,
    "scheduler_time": 131.7241893961319
}
#Debug simulation 
Total elapsed time: 6.957640554290265. Arrivals time: 0.2398545085452497 Scheduler time: 6.5775943589396775 Scheduler overhead time: 0.045371368527412415 Adapter cache time: 0.030035671312361956 Engine time: 0.04440924245864153 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-32/adapters_256_slots_96_rate_0.8-0.1-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-32/adapters_256_slots_96_rate_0.8-0.1-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 66, 8640, 8640, 66, 8640, 1080, 8640, 66, 1080, 66, 8640, 1080, 1080, 1080, 1080, 8640, 66, 66, 66, 1080, 8640, 66, 8640, 8640, 1080, 1080, 1080, 66, 8640, 66, 1080, 1080, 66, 1080, 66, 66, 1080, 1080, 8640, 1080, 66, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 66, 8640, 8640, 1080, 66, 66, 8640, 1080, 66, 1080, 1080, 8640, 1080, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 66, 1080, 66, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 66, 8640, 8640, 66, 8640, 66, 1080, 8640, 8640, 8640, 1080, 66, 8640, 1080, 66, 66, 66, 66, 66, 8640, 1080, 66, 8640, 66, 8640, 66, 66, 1080, 1080, 8640, 1080, 8640, 66, 1080, 66, 8640, 8640, 66, 8640, 1080, 66, 8640, 66, 66, 8640, 8640, 1080, 8640, 8640, 66, 8640, 1080, 1080, 66, 1080, 8640, 8640, 66, 8640, 1080, 66, 1080, 8640, 66, 66, 66, 66, 66, 66, 8640, 66, 66, 66, 8640, 66, 1080, 8640, 8640, 1080, 66, 8640, 66, 1080, 1080, 66, 1080, 66, 8640, 66, 66, 8640, 66, 8640, 8640, 1080, 8640, 1080, 66, 1080, 8640, 1080, 8640, 66, 8640, 66, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 66, 8640, 66, 8640, 1080, 1080, 66, 1080, 8640, 1080, 1080, 8640, 66, 8640, 8640, 1080, 66, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 66, 8640, 1080, 8640, 8640, 66, 8640, 1080, 1080, 8640, 66, 1080, 66, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 66, 66, 66, 66]
Prompts retrieved: 840450 . Total input tokens: 187162021 . Total output tokens: 165050758
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.124403716996312,
    "estimated_duration": 3600.103679588225,
    "input_throughput": 3986.5990752915154,
    "output_throughput": 3448.478461992516,
    "total_throughput": 7435.077537284032,
    "itl": 99.82070543705848,
    "ttft": 2083584.0867600709,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2674,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.074582509994634,
    "arrivals": 279961,
    "finished_requests": 57759,
    "scheduler_time": 143.22452799802812
}
#Debug simulation 
Total elapsed time: 5.124523749109358. Arrivals time: 0.2136355834081769 Scheduler time: 4.732499458361417 Scheduler overhead time: 0.05205636890605092 Adapter cache time: 0.050676376558840275 Engine time: 0.05168734723702073 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_8-16-16/adapters_256_slots_96_rate_0.8-0.1-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_8-16-16/adapters_256_slots_96_rate_0.8-0.1-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 66, 8640, 8640, 66, 8640, 1080, 8640, 66, 1080, 66, 8640, 1080, 1080, 1080, 1080, 8640, 66, 66, 66, 1080, 8640, 66, 8640, 8640, 1080, 1080, 1080, 66, 8640, 66, 1080, 1080, 66, 1080, 66, 66, 1080, 1080, 8640, 1080, 66, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 66, 8640, 8640, 1080, 66, 66, 8640, 1080, 66, 1080, 1080, 8640, 1080, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 66, 1080, 66, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 66, 8640, 8640, 66, 8640, 66, 1080, 8640, 8640, 8640, 1080, 66, 8640, 1080, 66, 66, 66, 66, 66, 8640, 1080, 66, 8640, 66, 8640, 66, 66, 1080, 1080, 8640, 1080, 8640, 66, 1080, 66, 8640, 8640, 66, 8640, 1080, 66, 8640, 66, 66, 8640, 8640, 1080, 8640, 8640, 66, 8640, 1080, 1080, 66, 1080, 8640, 8640, 66, 8640, 1080, 66, 1080, 8640, 66, 66, 66, 66, 66, 66, 8640, 66, 66, 66, 8640, 66, 1080, 8640, 8640, 1080, 66, 8640, 66, 1080, 1080, 66, 1080, 66, 8640, 66, 66, 8640, 66, 8640, 8640, 1080, 8640, 1080, 66, 1080, 8640, 1080, 8640, 66, 8640, 66, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 66, 8640, 66, 8640, 1080, 1080, 66, 1080, 8640, 1080, 1080, 8640, 66, 8640, 8640, 1080, 66, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 66, 8640, 1080, 8640, 8640, 66, 8640, 1080, 1080, 8640, 66, 1080, 66, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 66, 66, 66, 66]
Prompts retrieved: 840450 . Total input tokens: 187162021 . Total output tokens: 165050758
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 6.839444817043841,
    "estimated_duration": 3600.0994662212693,
    "input_throughput": 4491.910057411196,
    "output_throughput": 3889.593365790453,
    "total_throughput": 8381.50342320165,
    "itl": 123.14415371788103,
    "ttft": 1991757.9388369033,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1486,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.215322528677127,
    "arrivals": 279961,
    "finished_requests": 65134,
    "scheduler_time": 131.94408117513152
}
#Debug simulation 
Total elapsed time: 6.839569224044681. Arrivals time: 0.23803775710985065 Scheduler time: 6.461094383616 Scheduler overhead time: 0.04502485506236553 Adapter cache time: 0.03092324361205101 Engine time: 0.04398789629340172 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_8-16-32/adapters_256_slots_96_rate_0.8-0.1-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_8-16-32/adapters_256_slots_96_rate_0.8-0.1-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 66, 8640, 8640, 66, 8640, 1080, 8640, 66, 1080, 66, 8640, 1080, 1080, 1080, 1080, 8640, 66, 66, 66, 1080, 8640, 66, 8640, 8640, 1080, 1080, 1080, 66, 8640, 66, 1080, 1080, 66, 1080, 66, 66, 1080, 1080, 8640, 1080, 66, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 66, 8640, 8640, 1080, 66, 66, 8640, 1080, 66, 1080, 1080, 8640, 1080, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 66, 1080, 66, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 66, 8640, 8640, 66, 8640, 66, 1080, 8640, 8640, 8640, 1080, 66, 8640, 1080, 66, 66, 66, 66, 66, 8640, 1080, 66, 8640, 66, 8640, 66, 66, 1080, 1080, 8640, 1080, 8640, 66, 1080, 66, 8640, 8640, 66, 8640, 1080, 66, 8640, 66, 66, 8640, 8640, 1080, 8640, 8640, 66, 8640, 1080, 1080, 66, 1080, 8640, 8640, 66, 8640, 1080, 66, 1080, 8640, 66, 66, 66, 66, 66, 66, 8640, 66, 66, 66, 8640, 66, 1080, 8640, 8640, 1080, 66, 8640, 66, 1080, 1080, 66, 1080, 66, 8640, 66, 66, 8640, 66, 8640, 8640, 1080, 8640, 1080, 66, 1080, 8640, 1080, 8640, 66, 8640, 66, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 66, 8640, 66, 8640, 1080, 1080, 66, 1080, 8640, 1080, 1080, 8640, 66, 8640, 8640, 1080, 66, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 66, 8640, 1080, 8640, 8640, 66, 8640, 1080, 1080, 8640, 66, 1080, 66, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 66, 66, 66, 66]
Prompts retrieved: 840450 . Total input tokens: 187162021 . Total output tokens: 165050758
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 5.0949987871572375,
    "estimated_duration": 3600.0346889531506,
    "input_throughput": 3984.6099383479236,
    "output_throughput": 3448.773434905525,
    "total_throughput": 7433.383373253449,
    "itl": 99.82786824618827,
    "ttft": 2083163.2783317163,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2711,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.18326293918784,
    "arrivals": 279961,
    "finished_requests": 57743,
    "scheduler_time": 143.22840105968714
}
#Debug simulation 
Total elapsed time: 5.095090928021818. Arrivals time: 0.21314334450289607 Scheduler time: 4.704803948290646 Scheduler overhead time: 0.05219173105433583 Adapter cache time: 0.049700778909027576 Engine time: 0.051425376906991005 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_16-16-16/adapters_256_slots_96_rate_0.8-0.1-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_16-16-16/adapters_256_slots_96_rate_0.8-0.1-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 66, 8640, 8640, 66, 8640, 1080, 8640, 66, 1080, 66, 8640, 1080, 1080, 1080, 1080, 8640, 66, 66, 66, 1080, 8640, 66, 8640, 8640, 1080, 1080, 1080, 66, 8640, 66, 1080, 1080, 66, 1080, 66, 66, 1080, 1080, 8640, 1080, 66, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 66, 8640, 8640, 1080, 66, 66, 8640, 1080, 66, 1080, 1080, 8640, 1080, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 66, 1080, 66, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 66, 8640, 8640, 66, 8640, 66, 1080, 8640, 8640, 8640, 1080, 66, 8640, 1080, 66, 66, 66, 66, 66, 8640, 1080, 66, 8640, 66, 8640, 66, 66, 1080, 1080, 8640, 1080, 8640, 66, 1080, 66, 8640, 8640, 66, 8640, 1080, 66, 8640, 66, 66, 8640, 8640, 1080, 8640, 8640, 66, 8640, 1080, 1080, 66, 1080, 8640, 8640, 66, 8640, 1080, 66, 1080, 8640, 66, 66, 66, 66, 66, 66, 8640, 66, 66, 66, 8640, 66, 1080, 8640, 8640, 1080, 66, 8640, 66, 1080, 1080, 66, 1080, 66, 8640, 66, 66, 8640, 66, 8640, 8640, 1080, 8640, 1080, 66, 1080, 8640, 1080, 8640, 66, 8640, 66, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 66, 8640, 66, 8640, 1080, 1080, 66, 1080, 8640, 1080, 1080, 8640, 66, 8640, 8640, 1080, 66, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 66, 8640, 1080, 8640, 8640, 66, 8640, 1080, 1080, 8640, 66, 1080, 66, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 66, 66, 66, 66]
Prompts retrieved: 840450 . Total input tokens: 187162021 . Total output tokens: 165050758
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 6.834451070055366,
    "estimated_duration": 3600.004793556931,
    "input_throughput": 4498.5067878198915,
    "output_throughput": 3899.2648079589317,
    "total_throughput": 8397.771595778822,
    "itl": 123.62303860035657,
    "ttft": 1990959.189717485,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1402,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.950257158679973,
    "arrivals": 279961,
    "finished_requests": 65274,
    "scheduler_time": 131.76376862245098
}
#Debug simulation 
Total elapsed time: 6.834569194354117. Arrivals time: 0.23576164292171597 Scheduler time: 6.460042840335518 Scheduler overhead time: 0.04483477910980582 Adapter cache time: 0.029383869841694832 Engine time: 0.04425304802134633 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_16-16-32/adapters_256_slots_96_rate_0.8-0.1-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_16-16-32/adapters_256_slots_96_rate_0.8-0.1-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 66, 8640, 8640, 66, 8640, 1080, 8640, 66, 1080, 66, 8640, 1080, 1080, 1080, 1080, 8640, 66, 66, 66, 1080, 8640, 66, 8640, 8640, 1080, 1080, 1080, 66, 8640, 66, 1080, 1080, 66, 1080, 66, 66, 1080, 1080, 8640, 1080, 66, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 66, 8640, 8640, 1080, 66, 66, 8640, 1080, 66, 1080, 1080, 8640, 1080, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 66, 1080, 66, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 66, 8640, 8640, 66, 8640, 66, 1080, 8640, 8640, 8640, 1080, 66, 8640, 1080, 66, 66, 66, 66, 66, 8640, 1080, 66, 8640, 66, 8640, 66, 66, 1080, 1080, 8640, 1080, 8640, 66, 1080, 66, 8640, 8640, 66, 8640, 1080, 66, 8640, 66, 66, 8640, 8640, 1080, 8640, 8640, 66, 8640, 1080, 1080, 66, 1080, 8640, 8640, 66, 8640, 1080, 66, 1080, 8640, 66, 66, 66, 66, 66, 66, 8640, 66, 66, 66, 8640, 66, 1080, 8640, 8640, 1080, 66, 8640, 66, 1080, 1080, 66, 1080, 66, 8640, 66, 66, 8640, 66, 8640, 8640, 1080, 8640, 1080, 66, 1080, 8640, 1080, 8640, 66, 8640, 66, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 66, 8640, 66, 8640, 1080, 1080, 66, 1080, 8640, 1080, 1080, 8640, 66, 8640, 8640, 1080, 66, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 66, 8640, 1080, 8640, 8640, 66, 8640, 1080, 1080, 8640, 66, 1080, 66, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 66, 66, 66, 66]
Prompts retrieved: 840450 . Total input tokens: 187162021 . Total output tokens: 165050758
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.101422606036067,
    "estimated_duration": 3600.03256905246,
    "input_throughput": 3980.1281586103346,
    "output_throughput": 3446.4782642968353,
    "total_throughput": 7426.60642290717,
    "itl": 99.72783393761084,
    "ttft": 2082749.143662507,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2630,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.390386867821267,
    "arrivals": 279961,
    "finished_requests": 57680,
    "scheduler_time": 143.3234637854227
}
#Debug simulation 
Total elapsed time: 5.101512947119772. Arrivals time: 0.21232327912002802 Scheduler time: 4.712963443715125 Scheduler overhead time: 0.05199799034744501 Adapter cache time: 0.048991532530635595 Engine time: 0.05142601393163204 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-8/adapters_256_slots_96_rate_0.8-0.1-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-8/adapters_256_slots_96_rate_0.8-0.1-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 33, 8640, 8640, 33, 8640, 1080, 8640, 33, 1080, 33, 8640, 1080, 1080, 1080, 1080, 8640, 33, 33, 33, 1080, 8640, 33, 8640, 8640, 1080, 1080, 1080, 33, 8640, 33, 1080, 1080, 33, 1080, 33, 33, 1080, 1080, 8640, 1080, 33, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 33, 8640, 8640, 1080, 33, 33, 8640, 1080, 33, 1080, 1080, 8640, 1080, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 1080, 33, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 33, 8640, 8640, 33, 8640, 33, 1080, 8640, 8640, 8640, 1080, 33, 8640, 1080, 33, 33, 33, 33, 33, 8640, 1080, 33, 8640, 33, 8640, 33, 33, 1080, 1080, 8640, 1080, 8640, 33, 1080, 33, 8640, 8640, 33, 8640, 1080, 33, 8640, 33, 33, 8640, 8640, 1080, 8640, 8640, 33, 8640, 1080, 1080, 33, 1080, 8640, 8640, 33, 8640, 1080, 33, 1080, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 1080, 8640, 8640, 1080, 33, 8640, 33, 1080, 1080, 33, 1080, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 1080, 8640, 1080, 33, 1080, 8640, 1080, 8640, 33, 8640, 33, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 33, 8640, 33, 8640, 1080, 1080, 33, 1080, 8640, 1080, 1080, 8640, 33, 8640, 8640, 1080, 33, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 33, 8640, 1080, 8640, 8640, 33, 8640, 1080, 1080, 8640, 33, 1080, 33, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 33, 33, 33, 33]
Prompts retrieved: 837645 . Total input tokens: 186540932 . Total output tokens: 164512523
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 7.68915438791737,
    "estimated_duration": 3600.052605304369,
    "input_throughput": 4642.071611780544,
    "output_throughput": 4054.85241479293,
    "total_throughput": 8696.924026573473,
    "itl": 134.9493051947844,
    "ttft": 1965156.5972164113,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 960,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.347912670672077,
    "arrivals": 278999,
    "finished_requests": 67607,
    "scheduler_time": 127.6291468644637
}
#Debug simulation 
Total elapsed time: 7.6892569260671735. Arrivals time: 0.249527495354414 Scheduler time: 7.3156729796901345 Scheduler overhead time: 0.04221361456438899 Adapter cache time: 0.021623916923999786 Engine time: 0.04121559578925371 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-16/adapters_256_slots_96_rate_0.8-0.1-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-16/adapters_256_slots_96_rate_0.8-0.1-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 33, 8640, 8640, 33, 8640, 1080, 8640, 33, 1080, 33, 8640, 1080, 1080, 1080, 1080, 8640, 33, 33, 33, 1080, 8640, 33, 8640, 8640, 1080, 1080, 1080, 33, 8640, 33, 1080, 1080, 33, 1080, 33, 33, 1080, 1080, 8640, 1080, 33, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 33, 8640, 8640, 1080, 33, 33, 8640, 1080, 33, 1080, 1080, 8640, 1080, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 1080, 33, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 33, 8640, 8640, 33, 8640, 33, 1080, 8640, 8640, 8640, 1080, 33, 8640, 1080, 33, 33, 33, 33, 33, 8640, 1080, 33, 8640, 33, 8640, 33, 33, 1080, 1080, 8640, 1080, 8640, 33, 1080, 33, 8640, 8640, 33, 8640, 1080, 33, 8640, 33, 33, 8640, 8640, 1080, 8640, 8640, 33, 8640, 1080, 1080, 33, 1080, 8640, 8640, 33, 8640, 1080, 33, 1080, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 1080, 8640, 8640, 1080, 33, 8640, 33, 1080, 1080, 33, 1080, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 1080, 8640, 1080, 33, 1080, 8640, 1080, 8640, 33, 8640, 33, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 33, 8640, 33, 8640, 1080, 1080, 33, 1080, 8640, 1080, 1080, 8640, 33, 8640, 8640, 1080, 33, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 33, 8640, 1080, 8640, 8640, 33, 8640, 1080, 1080, 8640, 33, 1080, 33, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 33, 33, 33, 33]
Prompts retrieved: 837645 . Total input tokens: 186540932 . Total output tokens: 164512523
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 6.740049147978425,
    "estimated_duration": 3600.0740317600453,
    "input_throughput": 4455.251713853939,
    "output_throughput": 3896.3387631065652,
    "total_throughput": 8351.590476960504,
    "itl": 123.4602876908422,
    "ttft": 1996653.4402180035,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1354,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.901557155353892,
    "arrivals": 278999,
    "finished_requests": 64900,
    "scheduler_time": 131.72131558915606
}
#Debug simulation 
Total elapsed time: 6.740151935257018. Arrivals time: 0.23950725235044956 Scheduler time: 6.362501363269985 Scheduler overhead time: 0.044933180790394545 Adapter cache time: 0.02844316652044654 Engine time: 0.04433920048177242 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-32/adapters_256_slots_96_rate_0.8-0.1-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-32/adapters_256_slots_96_rate_0.8-0.1-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 33, 8640, 8640, 33, 8640, 1080, 8640, 33, 1080, 33, 8640, 1080, 1080, 1080, 1080, 8640, 33, 33, 33, 1080, 8640, 33, 8640, 8640, 1080, 1080, 1080, 33, 8640, 33, 1080, 1080, 33, 1080, 33, 33, 1080, 1080, 8640, 1080, 33, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 33, 8640, 8640, 1080, 33, 33, 8640, 1080, 33, 1080, 1080, 8640, 1080, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 1080, 33, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 33, 8640, 8640, 33, 8640, 33, 1080, 8640, 8640, 8640, 1080, 33, 8640, 1080, 33, 33, 33, 33, 33, 8640, 1080, 33, 8640, 33, 8640, 33, 33, 1080, 1080, 8640, 1080, 8640, 33, 1080, 33, 8640, 8640, 33, 8640, 1080, 33, 8640, 33, 33, 8640, 8640, 1080, 8640, 8640, 33, 8640, 1080, 1080, 33, 1080, 8640, 8640, 33, 8640, 1080, 33, 1080, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 1080, 8640, 8640, 1080, 33, 8640, 33, 1080, 1080, 33, 1080, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 1080, 8640, 1080, 33, 1080, 8640, 1080, 8640, 33, 8640, 33, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 33, 8640, 33, 8640, 1080, 1080, 33, 1080, 8640, 1080, 1080, 8640, 33, 8640, 8640, 1080, 33, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 33, 8640, 1080, 8640, 8640, 33, 8640, 1080, 1080, 8640, 33, 1080, 33, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 33, 33, 33, 33]
Prompts retrieved: 837645 . Total input tokens: 186540932 . Total output tokens: 164512523
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.023578136228025,
    "estimated_duration": 3600.0113524061107,
    "input_throughput": 3927.3953929479285,
    "output_throughput": 3446.138299455142,
    "total_throughput": 7373.53369240307,
    "itl": 99.73382482340587,
    "ttft": 2089451.640056525,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2621,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.690979587449775,
    "arrivals": 278999,
    "finished_requests": 57302,
    "scheduler_time": 143.22600754047173
}
#Debug simulation 
Total elapsed time: 5.023664629086852. Arrivals time: 0.20940864318981767 Scheduler time: 4.636724389623851 Scheduler overhead time: 0.05239202221855521 Adapter cache time: 0.04917687550187111 Engine time: 0.05172066483646631 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_8-16-16/adapters_256_slots_96_rate_0.8-0.1-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_8-16-16/adapters_256_slots_96_rate_0.8-0.1-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 33, 8640, 8640, 33, 8640, 1080, 8640, 33, 1080, 33, 8640, 1080, 1080, 1080, 1080, 8640, 33, 33, 33, 1080, 8640, 33, 8640, 8640, 1080, 1080, 1080, 33, 8640, 33, 1080, 1080, 33, 1080, 33, 33, 1080, 1080, 8640, 1080, 33, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 33, 8640, 8640, 1080, 33, 33, 8640, 1080, 33, 1080, 1080, 8640, 1080, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 1080, 33, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 33, 8640, 8640, 33, 8640, 33, 1080, 8640, 8640, 8640, 1080, 33, 8640, 1080, 33, 33, 33, 33, 33, 8640, 1080, 33, 8640, 33, 8640, 33, 33, 1080, 1080, 8640, 1080, 8640, 33, 1080, 33, 8640, 8640, 33, 8640, 1080, 33, 8640, 33, 33, 8640, 8640, 1080, 8640, 8640, 33, 8640, 1080, 1080, 33, 1080, 8640, 8640, 33, 8640, 1080, 33, 1080, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 1080, 8640, 8640, 1080, 33, 8640, 33, 1080, 1080, 33, 1080, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 1080, 8640, 1080, 33, 1080, 8640, 1080, 8640, 33, 8640, 33, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 33, 8640, 33, 8640, 1080, 1080, 33, 1080, 8640, 1080, 1080, 8640, 33, 8640, 8640, 1080, 33, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 33, 8640, 1080, 8640, 8640, 33, 8640, 1080, 1080, 8640, 33, 1080, 33, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 33, 33, 33, 33]
Prompts retrieved: 837645 . Total input tokens: 186540932 . Total output tokens: 164512523
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 7.190083825029433,
    "estimated_duration": 3600.095980155901,
    "input_throughput": 4147.678029226702,
    "output_throughput": 3636.056391872401,
    "total_throughput": 7783.734421099103,
    "itl": 107.78065200193777,
    "ttft": 2049999.4820122384,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 855,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.865001149368465,
    "arrivals": 278999,
    "finished_requests": 60475,
    "scheduler_time": 138.99889032522285
}
#Debug simulation 
Total elapsed time: 7.190174585208297. Arrivals time: 0.2292462713085115 Scheduler time: 6.818373765796423 Scheduler overhead time: 0.04979925416409969 Adapter cache time: 0.02136765280738473 Engine time: 0.048792092595249414 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_8-16-32/adapters_256_slots_96_rate_0.8-0.1-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_8-16-32/adapters_256_slots_96_rate_0.8-0.1-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 33, 8640, 8640, 33, 8640, 1080, 8640, 33, 1080, 33, 8640, 1080, 1080, 1080, 1080, 8640, 33, 33, 33, 1080, 8640, 33, 8640, 8640, 1080, 1080, 1080, 33, 8640, 33, 1080, 1080, 33, 1080, 33, 33, 1080, 1080, 8640, 1080, 33, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 33, 8640, 8640, 1080, 33, 33, 8640, 1080, 33, 1080, 1080, 8640, 1080, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 1080, 33, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 33, 8640, 8640, 33, 8640, 33, 1080, 8640, 8640, 8640, 1080, 33, 8640, 1080, 33, 33, 33, 33, 33, 8640, 1080, 33, 8640, 33, 8640, 33, 33, 1080, 1080, 8640, 1080, 8640, 33, 1080, 33, 8640, 8640, 33, 8640, 1080, 33, 8640, 33, 33, 8640, 8640, 1080, 8640, 8640, 33, 8640, 1080, 1080, 33, 1080, 8640, 8640, 33, 8640, 1080, 33, 1080, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 1080, 8640, 8640, 1080, 33, 8640, 33, 1080, 1080, 33, 1080, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 1080, 8640, 1080, 33, 1080, 8640, 1080, 8640, 33, 8640, 33, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 33, 8640, 33, 8640, 1080, 1080, 33, 1080, 8640, 1080, 1080, 8640, 33, 8640, 8640, 1080, 33, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 33, 8640, 1080, 8640, 8640, 33, 8640, 1080, 1080, 8640, 33, 1080, 33, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 33, 33, 33, 33]
Prompts retrieved: 837645 . Total input tokens: 186540932 . Total output tokens: 164512523
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 5.07359512662515,
    "estimated_duration": 3600.0634674167336,
    "input_throughput": 3928.310466745152,
    "output_throughput": 3447.515887520131,
    "total_throughput": 7375.826354265283,
    "itl": 99.74545214756489,
    "ttft": 2088968.1123514925,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2564,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.10083459814546,
    "arrivals": 278999,
    "finished_requests": 57318,
    "scheduler_time": 143.22522824528406
}
#Debug simulation 
Total elapsed time: 5.073681629728526. Arrivals time: 0.22358229663223028 Scheduler time: 4.674136247951537 Scheduler overhead time: 0.05207235552370548 Adapter cache time: 0.048189674969762564 Engine time: 0.0517094056122005 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_16-16-16/adapters_256_slots_96_rate_0.8-0.1-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_16-16-16/adapters_256_slots_96_rate_0.8-0.1-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 33, 8640, 8640, 33, 8640, 1080, 8640, 33, 1080, 33, 8640, 1080, 1080, 1080, 1080, 8640, 33, 33, 33, 1080, 8640, 33, 8640, 8640, 1080, 1080, 1080, 33, 8640, 33, 1080, 1080, 33, 1080, 33, 33, 1080, 1080, 8640, 1080, 33, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 33, 8640, 8640, 1080, 33, 33, 8640, 1080, 33, 1080, 1080, 8640, 1080, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 1080, 33, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 33, 8640, 8640, 33, 8640, 33, 1080, 8640, 8640, 8640, 1080, 33, 8640, 1080, 33, 33, 33, 33, 33, 8640, 1080, 33, 8640, 33, 8640, 33, 33, 1080, 1080, 8640, 1080, 8640, 33, 1080, 33, 8640, 8640, 33, 8640, 1080, 33, 8640, 33, 33, 8640, 8640, 1080, 8640, 8640, 33, 8640, 1080, 1080, 33, 1080, 8640, 8640, 33, 8640, 1080, 33, 1080, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 1080, 8640, 8640, 1080, 33, 8640, 33, 1080, 1080, 33, 1080, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 1080, 8640, 1080, 33, 1080, 8640, 1080, 8640, 33, 8640, 33, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 33, 8640, 33, 8640, 1080, 1080, 33, 1080, 8640, 1080, 1080, 8640, 33, 8640, 8640, 1080, 33, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 33, 8640, 1080, 8640, 8640, 33, 8640, 1080, 1080, 8640, 33, 1080, 33, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 33, 33, 33, 33]
Prompts retrieved: 837645 . Total input tokens: 186540932 . Total output tokens: 164512523
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 6.717795319855213,
    "estimated_duration": 3600.000633187224,
    "input_throughput": 4458.682549116437,
    "output_throughput": 3901.26931382392,
    "total_throughput": 8359.951862940357,
    "itl": 123.56586634714962,
    "ttft": 1995807.3007044839,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1270,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.10757959452455,
    "arrivals": 278999,
    "finished_requests": 64955,
    "scheduler_time": 131.72345412787087
}
#Debug simulation 
Total elapsed time: 6.717883960809559. Arrivals time: 0.23697823518887162 Scheduler time: 6.34446004871279 Scheduler overhead time: 0.04482138529419899 Adapter cache time: 0.02729884861037135 Engine time: 0.04399709077551961 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_16-16-32/adapters_256_slots_96_rate_0.8-0.1-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_16-16-32/adapters_256_slots_96_rate_0.8-0.1-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 33, 8640, 8640, 33, 8640, 1080, 8640, 33, 1080, 33, 8640, 1080, 1080, 1080, 1080, 8640, 33, 33, 33, 1080, 8640, 33, 8640, 8640, 1080, 1080, 1080, 33, 8640, 33, 1080, 1080, 33, 1080, 33, 33, 1080, 1080, 8640, 1080, 33, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 33, 8640, 8640, 1080, 33, 33, 8640, 1080, 33, 1080, 1080, 8640, 1080, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 1080, 33, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 33, 8640, 8640, 33, 8640, 33, 1080, 8640, 8640, 8640, 1080, 33, 8640, 1080, 33, 33, 33, 33, 33, 8640, 1080, 33, 8640, 33, 8640, 33, 33, 1080, 1080, 8640, 1080, 8640, 33, 1080, 33, 8640, 8640, 33, 8640, 1080, 33, 8640, 33, 33, 8640, 8640, 1080, 8640, 8640, 33, 8640, 1080, 1080, 33, 1080, 8640, 8640, 33, 8640, 1080, 33, 1080, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 1080, 8640, 8640, 1080, 33, 8640, 33, 1080, 1080, 33, 1080, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 1080, 8640, 1080, 33, 1080, 8640, 1080, 8640, 33, 8640, 33, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 33, 8640, 33, 8640, 1080, 1080, 33, 1080, 8640, 1080, 1080, 8640, 33, 8640, 8640, 1080, 33, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 33, 8640, 1080, 8640, 8640, 33, 8640, 1080, 1080, 8640, 33, 1080, 33, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 33, 33, 33, 33]
Prompts retrieved: 837645 . Total input tokens: 186540932 . Total output tokens: 164512523
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.003700855653733,
    "estimated_duration": 3600.06640568327,
    "input_throughput": 3928.2997607139723,
    "output_throughput": 3447.416408877181,
    "total_throughput": 7375.716169591153,
    "itl": 99.7598258113605,
    "ttft": 2088940.7680295727,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2596,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.145367695391204,
    "arrivals": 278999,
    "finished_requests": 57311,
    "scheduler_time": 143.22657480949007
}
#Debug simulation 
Total elapsed time: 5.003787521738559. Arrivals time: 0.20557058649137616 Scheduler time: 4.6215783203952014 Scheduler overhead time: 0.05217750230804086 Adapter cache time: 0.04879303928464651 Engine time: 0.05175501899793744 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.025_size_8-8-8/adapters_256_slots_96_rate_0.8-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.025_size_8-8-8/adapters_256_slots_96_rate_0.8-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 8640, 270, 8640, 8640, 270, 8640, 540, 8640, 270, 540, 270, 8640, 540, 540, 540, 540, 8640, 270, 270, 270, 540, 8640, 270, 8640, 8640, 540, 540, 540, 270, 8640, 270, 540, 540, 270, 540, 270, 270, 540, 540, 8640, 540, 270, 540, 8640, 540, 540, 8640, 540, 8640, 270, 8640, 8640, 540, 270, 270, 8640, 540, 270, 540, 540, 8640, 540, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 8640, 8640, 270, 8640, 270, 540, 8640, 8640, 8640, 540, 270, 8640, 540, 270, 270, 270, 270, 270, 8640, 540, 270, 8640, 270, 8640, 270, 270, 540, 540, 8640, 540, 8640, 270, 540, 270, 8640, 8640, 270, 8640, 540, 270, 8640, 270, 270, 8640, 8640, 540, 8640, 8640, 270, 8640, 540, 540, 270, 540, 8640, 8640, 270, 8640, 540, 270, 540, 8640, 270, 270, 270, 270, 270, 270, 8640, 270, 270, 270, 8640, 270, 540, 8640, 8640, 540, 270, 8640, 270, 540, 540, 270, 540, 270, 8640, 270, 270, 8640, 270, 8640, 8640, 540, 8640, 540, 270, 540, 8640, 540, 8640, 270, 8640, 270, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 540, 270, 8640, 270, 8640, 540, 540, 270, 540, 8640, 540, 540, 8640, 270, 8640, 8640, 540, 270, 8640, 8640, 540, 540, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 8640, 270, 8640, 540, 8640, 8640, 270, 8640, 540, 540, 8640, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 8640, 540, 270, 270, 270, 270]
Prompts retrieved: 811890 . Total input tokens: 180825203 . Total output tokens: 159433071
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 7.992097747977823,
    "estimated_duration": 3600.031078796951,
    "input_throughput": 4634.133049088868,
    "output_throughput": 4051.8058540968264,
    "total_throughput": 8685.938903185694,
    "itl": 135.03179940836503,
    "ttft": 1958030.6380385563,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1290,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.530007651215627,
    "arrivals": 270522,
    "finished_requests": 67634,
    "scheduler_time": 127.43900828699724
}
#Debug simulation 
Total elapsed time: 7.99218818731606. Arrivals time: 0.25358721148222685 Scheduler time: 7.608814939856529 Scheduler overhead time: 0.04233730770647526 Adapter cache time: 0.027054678183048964 Engine time: 0.0411944966763258 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.025_size_8-8-16/adapters_256_slots_96_rate_0.8-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.025_size_8-8-16/adapters_256_slots_96_rate_0.8-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 8640, 270, 8640, 8640, 270, 8640, 540, 8640, 270, 540, 270, 8640, 540, 540, 540, 540, 8640, 270, 270, 270, 540, 8640, 270, 8640, 8640, 540, 540, 540, 270, 8640, 270, 540, 540, 270, 540, 270, 270, 540, 540, 8640, 540, 270, 540, 8640, 540, 540, 8640, 540, 8640, 270, 8640, 8640, 540, 270, 270, 8640, 540, 270, 540, 540, 8640, 540, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 8640, 8640, 270, 8640, 270, 540, 8640, 8640, 8640, 540, 270, 8640, 540, 270, 270, 270, 270, 270, 8640, 540, 270, 8640, 270, 8640, 270, 270, 540, 540, 8640, 540, 8640, 270, 540, 270, 8640, 8640, 270, 8640, 540, 270, 8640, 270, 270, 8640, 8640, 540, 8640, 8640, 270, 8640, 540, 540, 270, 540, 8640, 8640, 270, 8640, 540, 270, 540, 8640, 270, 270, 270, 270, 270, 270, 8640, 270, 270, 270, 8640, 270, 540, 8640, 8640, 540, 270, 8640, 270, 540, 540, 270, 540, 270, 8640, 270, 270, 8640, 270, 8640, 8640, 540, 8640, 540, 270, 540, 8640, 540, 8640, 270, 8640, 270, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 540, 270, 8640, 270, 8640, 540, 540, 270, 540, 8640, 540, 540, 8640, 270, 8640, 8640, 540, 270, 8640, 8640, 540, 540, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 8640, 270, 8640, 540, 8640, 8640, 270, 8640, 540, 540, 8640, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 8640, 540, 270, 270, 270, 270]
Prompts retrieved: 811890 . Total input tokens: 180825203 . Total output tokens: 159433071
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 6.898627758026123,
    "estimated_duration": 3600.0561227799194,
    "input_throughput": 4448.909531897072,
    "output_throughput": 3893.5579118628357,
    "total_throughput": 8342.467443759908,
    "itl": 123.43587839140788,
    "ttft": 1990524.8499835422,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1641,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.994728008280367,
    "arrivals": 270522,
    "finished_requests": 64958,
    "scheduler_time": 131.55795160901212
}
#Debug simulation 
Total elapsed time: 6.898716212715954. Arrivals time: 0.24761755345389247 Scheduler time: 6.509448661468923 Scheduler overhead time: 0.045157224871218204 Adapter cache time: 0.03257080912590027 Engine time: 0.04364429647102952 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.025_size_8-8-32/adapters_256_slots_96_rate_0.8-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.025_size_8-8-32/adapters_256_slots_96_rate_0.8-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 8640, 270, 8640, 8640, 270, 8640, 540, 8640, 270, 540, 270, 8640, 540, 540, 540, 540, 8640, 270, 270, 270, 540, 8640, 270, 8640, 8640, 540, 540, 540, 270, 8640, 270, 540, 540, 270, 540, 270, 270, 540, 540, 8640, 540, 270, 540, 8640, 540, 540, 8640, 540, 8640, 270, 8640, 8640, 540, 270, 270, 8640, 540, 270, 540, 540, 8640, 540, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 8640, 8640, 270, 8640, 270, 540, 8640, 8640, 8640, 540, 270, 8640, 540, 270, 270, 270, 270, 270, 8640, 540, 270, 8640, 270, 8640, 270, 270, 540, 540, 8640, 540, 8640, 270, 540, 270, 8640, 8640, 270, 8640, 540, 270, 8640, 270, 270, 8640, 8640, 540, 8640, 8640, 270, 8640, 540, 540, 270, 540, 8640, 8640, 270, 8640, 540, 270, 540, 8640, 270, 270, 270, 270, 270, 270, 8640, 270, 270, 270, 8640, 270, 540, 8640, 8640, 540, 270, 8640, 270, 540, 540, 270, 540, 270, 8640, 270, 270, 8640, 270, 8640, 8640, 540, 8640, 540, 270, 540, 8640, 540, 8640, 270, 8640, 270, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 540, 270, 8640, 270, 8640, 540, 540, 270, 540, 8640, 540, 540, 8640, 270, 8640, 8640, 540, 270, 8640, 8640, 540, 540, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 8640, 270, 8640, 540, 8640, 8640, 270, 8640, 540, 540, 8640, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 8640, 540, 270, 270, 270, 270]
Prompts retrieved: 811890 . Total input tokens: 180825203 . Total output tokens: 159433071
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.012017361354083,
    "estimated_duration": 3600.052292780797,
    "input_throughput": 3921.4730375750123,
    "output_throughput": 3445.128567957494,
    "total_throughput": 7366.601605532506,
    "itl": 99.85451462691448,
    "ttft": 2083801.7044604872,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3073,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 23.069664535606734,
    "arrivals": 270522,
    "finished_requests": 57346,
    "scheduler_time": 142.90988173545222
}
#Debug simulation 
Total elapsed time: 5.012104811146855. Arrivals time: 0.2097652181982994 Scheduler time: 4.619322654325515 Scheduler overhead time: 0.052142536733299494 Adapter cache time: 0.05516434833407402 Engine time: 0.05179009446874261 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.025_size_8-16-16/adapters_256_slots_96_rate_0.8-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.025_size_8-16-16/adapters_256_slots_96_rate_0.8-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 8640, 270, 8640, 8640, 270, 8640, 540, 8640, 270, 540, 270, 8640, 540, 540, 540, 540, 8640, 270, 270, 270, 540, 8640, 270, 8640, 8640, 540, 540, 540, 270, 8640, 270, 540, 540, 270, 540, 270, 270, 540, 540, 8640, 540, 270, 540, 8640, 540, 540, 8640, 540, 8640, 270, 8640, 8640, 540, 270, 270, 8640, 540, 270, 540, 540, 8640, 540, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 8640, 8640, 270, 8640, 270, 540, 8640, 8640, 8640, 540, 270, 8640, 540, 270, 270, 270, 270, 270, 8640, 540, 270, 8640, 270, 8640, 270, 270, 540, 540, 8640, 540, 8640, 270, 540, 270, 8640, 8640, 270, 8640, 540, 270, 8640, 270, 270, 8640, 8640, 540, 8640, 8640, 270, 8640, 540, 540, 270, 540, 8640, 8640, 270, 8640, 540, 270, 540, 8640, 270, 270, 270, 270, 270, 270, 8640, 270, 270, 270, 8640, 270, 540, 8640, 8640, 540, 270, 8640, 270, 540, 540, 270, 540, 270, 8640, 270, 270, 8640, 270, 8640, 8640, 540, 8640, 540, 270, 540, 8640, 540, 8640, 270, 8640, 270, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 540, 270, 8640, 270, 8640, 540, 540, 270, 540, 8640, 540, 540, 8640, 270, 8640, 8640, 540, 270, 8640, 8640, 540, 540, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 8640, 270, 8640, 540, 8640, 8640, 270, 8640, 540, 540, 8640, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 8640, 540, 270, 270, 270, 270]
Prompts retrieved: 811890 . Total input tokens: 180825203 . Total output tokens: 159433071
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 6.928976136725396,
    "estimated_duration": 3600.0585240874475,
    "input_throughput": 4451.094028828838,
    "output_throughput": 3895.347785645987,
    "total_throughput": 8346.441814474827,
    "itl": 123.58270664527294,
    "ttft": 1990168.3503901474,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1666,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.442168672485392,
    "arrivals": 270522,
    "finished_requests": 64996,
    "scheduler_time": 131.51370235965246
}
#Debug simulation 
Total elapsed time: 6.929067961871624. Arrivals time: 0.23828327096998692 Scheduler time: 6.548337911721319 Scheduler overhead time: 0.04500839626416564 Adapter cache time: 0.032835857942700386 Engine time: 0.04418478813022375 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.025_size_8-16-32/adapters_256_slots_96_rate_0.8-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.025_size_8-16-32/adapters_256_slots_96_rate_0.8-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 8640, 270, 8640, 8640, 270, 8640, 540, 8640, 270, 540, 270, 8640, 540, 540, 540, 540, 8640, 270, 270, 270, 540, 8640, 270, 8640, 8640, 540, 540, 540, 270, 8640, 270, 540, 540, 270, 540, 270, 270, 540, 540, 8640, 540, 270, 540, 8640, 540, 540, 8640, 540, 8640, 270, 8640, 8640, 540, 270, 270, 8640, 540, 270, 540, 540, 8640, 540, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 8640, 8640, 270, 8640, 270, 540, 8640, 8640, 8640, 540, 270, 8640, 540, 270, 270, 270, 270, 270, 8640, 540, 270, 8640, 270, 8640, 270, 270, 540, 540, 8640, 540, 8640, 270, 540, 270, 8640, 8640, 270, 8640, 540, 270, 8640, 270, 270, 8640, 8640, 540, 8640, 8640, 270, 8640, 540, 540, 270, 540, 8640, 8640, 270, 8640, 540, 270, 540, 8640, 270, 270, 270, 270, 270, 270, 8640, 270, 270, 270, 8640, 270, 540, 8640, 8640, 540, 270, 8640, 270, 540, 540, 270, 540, 270, 8640, 270, 270, 8640, 270, 8640, 8640, 540, 8640, 540, 270, 540, 8640, 540, 8640, 270, 8640, 270, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 540, 270, 8640, 270, 8640, 540, 540, 270, 540, 8640, 540, 540, 8640, 270, 8640, 8640, 540, 270, 8640, 8640, 540, 540, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 8640, 270, 8640, 540, 8640, 8640, 270, 8640, 540, 540, 8640, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 8640, 540, 270, 270, 270, 270]
Prompts retrieved: 811890 . Total input tokens: 180825203 . Total output tokens: 159433071
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 5.004048120230436,
    "estimated_duration": 3600.035794766666,
    "input_throughput": 3920.2799095820474,
    "output_throughput": 3443.732425667045,
    "total_throughput": 7364.012335249093,
    "itl": 99.78595251854814,
    "ttft": 2083965.069884587,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3040,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 22.602768425275965,
    "arrivals": 270522,
    "finished_requests": 57320,
    "scheduler_time": 142.97103291025832
}
#Debug simulation 
Total elapsed time: 5.004138972144574. Arrivals time: 0.20869011199101806 Scheduler time: 4.611779328901321 Scheduler overhead time: 0.05384725285694003 Adapter cache time: 0.054641048423945904 Engine time: 0.0513670458458364 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.025_size_16-16-16/adapters_256_slots_96_rate_0.8-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.025_size_16-16-16/adapters_256_slots_96_rate_0.8-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 8640, 270, 8640, 8640, 270, 8640, 540, 8640, 270, 540, 270, 8640, 540, 540, 540, 540, 8640, 270, 270, 270, 540, 8640, 270, 8640, 8640, 540, 540, 540, 270, 8640, 270, 540, 540, 270, 540, 270, 270, 540, 540, 8640, 540, 270, 540, 8640, 540, 540, 8640, 540, 8640, 270, 8640, 8640, 540, 270, 270, 8640, 540, 270, 540, 540, 8640, 540, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 8640, 8640, 270, 8640, 270, 540, 8640, 8640, 8640, 540, 270, 8640, 540, 270, 270, 270, 270, 270, 8640, 540, 270, 8640, 270, 8640, 270, 270, 540, 540, 8640, 540, 8640, 270, 540, 270, 8640, 8640, 270, 8640, 540, 270, 8640, 270, 270, 8640, 8640, 540, 8640, 8640, 270, 8640, 540, 540, 270, 540, 8640, 8640, 270, 8640, 540, 270, 540, 8640, 270, 270, 270, 270, 270, 270, 8640, 270, 270, 270, 8640, 270, 540, 8640, 8640, 540, 270, 8640, 270, 540, 540, 270, 540, 270, 8640, 270, 270, 8640, 270, 8640, 8640, 540, 8640, 540, 270, 540, 8640, 540, 8640, 270, 8640, 270, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 540, 270, 8640, 270, 8640, 540, 540, 270, 540, 8640, 540, 540, 8640, 270, 8640, 8640, 540, 270, 8640, 8640, 540, 540, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 8640, 270, 8640, 540, 8640, 8640, 270, 8640, 540, 540, 8640, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 8640, 540, 270, 270, 270, 270]
Prompts retrieved: 811890 . Total input tokens: 180825203 . Total output tokens: 159433071
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 6.891748548019677,
    "estimated_duration": 3600.017341257213,
    "input_throughput": 4444.164147946226,
    "output_throughput": 3890.125150094217,
    "total_throughput": 8334.289298040443,
    "itl": 123.08138858109137,
    "ttft": 1991103.3961902803,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1657,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.578156998525676,
    "arrivals": 270522,
    "finished_requests": 64883,
    "scheduler_time": 131.73218076941234
}
#Debug simulation 
Total elapsed time: 6.891836617607623. Arrivals time: 0.23659006459638476 Scheduler time: 6.512440428137779 Scheduler overhead time: 0.04533462133258581 Adapter cache time: 0.03275087522342801 Engine time: 0.044242169708013535 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.025_size_16-16-32/adapters_256_slots_96_rate_0.8-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.025_size_16-16-32/adapters_256_slots_96_rate_0.8-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 8640, 270, 8640, 8640, 270, 8640, 540, 8640, 270, 540, 270, 8640, 540, 540, 540, 540, 8640, 270, 270, 270, 540, 8640, 270, 8640, 8640, 540, 540, 540, 270, 8640, 270, 540, 540, 270, 540, 270, 270, 540, 540, 8640, 540, 270, 540, 8640, 540, 540, 8640, 540, 8640, 270, 8640, 8640, 540, 270, 270, 8640, 540, 270, 540, 540, 8640, 540, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 8640, 8640, 270, 8640, 270, 540, 8640, 8640, 8640, 540, 270, 8640, 540, 270, 270, 270, 270, 270, 8640, 540, 270, 8640, 270, 8640, 270, 270, 540, 540, 8640, 540, 8640, 270, 540, 270, 8640, 8640, 270, 8640, 540, 270, 8640, 270, 270, 8640, 8640, 540, 8640, 8640, 270, 8640, 540, 540, 270, 540, 8640, 8640, 270, 8640, 540, 270, 540, 8640, 270, 270, 270, 270, 270, 270, 8640, 270, 270, 270, 8640, 270, 540, 8640, 8640, 540, 270, 8640, 270, 540, 540, 270, 540, 270, 8640, 270, 270, 8640, 270, 8640, 8640, 540, 8640, 540, 270, 540, 8640, 540, 8640, 270, 8640, 270, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 540, 270, 8640, 270, 8640, 540, 540, 270, 540, 8640, 540, 540, 8640, 270, 8640, 8640, 540, 270, 8640, 8640, 540, 540, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 8640, 270, 8640, 540, 8640, 8640, 270, 8640, 540, 540, 8640, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 8640, 540, 270, 270, 270, 270]
Prompts retrieved: 811890 . Total input tokens: 180825203 . Total output tokens: 159433071
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.049824351910502,
    "estimated_duration": 3600.004650768481,
    "input_throughput": 3923.702986601617,
    "output_throughput": 3447.5986016714132,
    "total_throughput": 7371.301588273031,
    "itl": 99.91359037609769,
    "ttft": 2083541.612510378,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3069,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 22.60158498501446,
    "arrivals": 270522,
    "finished_requests": 57386,
    "scheduler_time": 142.87634952275513
}
#Debug simulation 
Total elapsed time: 5.049939956981689. Arrivals time: 0.20310648158192635 Scheduler time: 4.6625707619823515 Scheduler overhead time: 0.052255617920309305 Adapter cache time: 0.05614858027547598 Engine time: 0.051813461817801 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-8/adapters_256_slots_96_rate_0.8-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-8/adapters_256_slots_96_rate_0.8-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 8640, 135, 8640, 8640, 135, 8640, 540, 8640, 135, 540, 135, 8640, 540, 540, 540, 540, 8640, 135, 135, 135, 540, 8640, 135, 8640, 8640, 540, 540, 540, 135, 8640, 135, 540, 540, 135, 540, 135, 135, 540, 540, 8640, 540, 135, 540, 8640, 540, 540, 8640, 540, 8640, 135, 8640, 8640, 540, 135, 135, 8640, 540, 135, 540, 540, 8640, 540, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 8640, 8640, 135, 8640, 135, 540, 8640, 8640, 8640, 540, 135, 8640, 540, 135, 135, 135, 135, 135, 8640, 540, 135, 8640, 135, 8640, 135, 135, 540, 540, 8640, 540, 8640, 135, 540, 135, 8640, 8640, 135, 8640, 540, 135, 8640, 135, 135, 8640, 8640, 540, 8640, 8640, 135, 8640, 540, 540, 135, 540, 8640, 8640, 135, 8640, 540, 135, 540, 8640, 135, 135, 135, 135, 135, 135, 8640, 135, 135, 135, 8640, 135, 540, 8640, 8640, 540, 135, 8640, 135, 540, 540, 135, 540, 135, 8640, 135, 135, 8640, 135, 8640, 8640, 540, 8640, 540, 135, 540, 8640, 540, 8640, 135, 8640, 135, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 540, 135, 8640, 135, 8640, 540, 540, 135, 540, 8640, 540, 540, 8640, 135, 8640, 8640, 540, 135, 8640, 8640, 540, 540, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 8640, 135, 8640, 540, 8640, 8640, 135, 8640, 540, 540, 8640, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 8640, 540, 135, 135, 135, 135]
Prompts retrieved: 800415 . Total input tokens: 178214941 . Total output tokens: 157218537
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 7.184728391002864,
    "estimated_duration": 3600.0996675224737,
    "input_throughput": 4651.973430370439,
    "output_throughput": 4055.5838305576176,
    "total_throughput": 8707.557260928057,
    "itl": 135.4024429017472,
    "ttft": 1950505.945014352,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1210,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.001014928659615,
    "arrivals": 266663,
    "finished_requests": 67577,
    "scheduler_time": 127.2896844996257
}
#Debug simulation 
Total elapsed time: 7.1848165933042765. Arrivals time: 0.23193723428994417 Scheduler time: 6.825840745586902 Scheduler overhead time: 0.041664086282253265 Adapter cache time: 0.02577596064656973 Engine time: 0.04076030058786273 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-16/adapters_256_slots_96_rate_0.8-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-16/adapters_256_slots_96_rate_0.8-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 8640, 135, 8640, 8640, 135, 8640, 540, 8640, 135, 540, 135, 8640, 540, 540, 540, 540, 8640, 135, 135, 135, 540, 8640, 135, 8640, 8640, 540, 540, 540, 135, 8640, 135, 540, 540, 135, 540, 135, 135, 540, 540, 8640, 540, 135, 540, 8640, 540, 540, 8640, 540, 8640, 135, 8640, 8640, 540, 135, 135, 8640, 540, 135, 540, 540, 8640, 540, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 8640, 8640, 135, 8640, 135, 540, 8640, 8640, 8640, 540, 135, 8640, 540, 135, 135, 135, 135, 135, 8640, 540, 135, 8640, 135, 8640, 135, 135, 540, 540, 8640, 540, 8640, 135, 540, 135, 8640, 8640, 135, 8640, 540, 135, 8640, 135, 135, 8640, 8640, 540, 8640, 8640, 135, 8640, 540, 540, 135, 540, 8640, 8640, 135, 8640, 540, 135, 540, 8640, 135, 135, 135, 135, 135, 135, 8640, 135, 135, 135, 8640, 135, 540, 8640, 8640, 540, 135, 8640, 135, 540, 540, 135, 540, 135, 8640, 135, 135, 8640, 135, 8640, 8640, 540, 8640, 540, 135, 540, 8640, 540, 8640, 135, 8640, 135, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 540, 135, 8640, 135, 8640, 540, 540, 135, 540, 8640, 540, 540, 8640, 135, 8640, 8640, 540, 135, 8640, 8640, 540, 540, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 8640, 135, 8640, 540, 8640, 8640, 135, 8640, 540, 540, 8640, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 8640, 540, 135, 135, 135, 135]
Prompts retrieved: 800415 . Total input tokens: 178214941 . Total output tokens: 157218537
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 6.422111880965531,
    "estimated_duration": 3600.005195024369,
    "input_throughput": 4464.207724536689,
    "output_throughput": 3895.3185454792306,
    "total_throughput": 8359.52627001592,
    "itl": 123.76670383573781,
    "ttft": 1983316.3805337937,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1486,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.859457060294135,
    "arrivals": 266663,
    "finished_requests": 64863,
    "scheduler_time": 131.43131254616716
}
#Debug simulation 
Total elapsed time: 6.422197035048157. Arrivals time: 0.22492631152272224 Scheduler time: 6.057752871885896 Scheduler overhead time: 0.044923484325408936 Adapter cache time: 0.030158914159983397 Engine time: 0.04410069342702627 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-32/adapters_256_slots_96_rate_0.8-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-32/adapters_256_slots_96_rate_0.8-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 8640, 135, 8640, 8640, 135, 8640, 540, 8640, 135, 540, 135, 8640, 540, 540, 540, 540, 8640, 135, 135, 135, 540, 8640, 135, 8640, 8640, 540, 540, 540, 135, 8640, 135, 540, 540, 135, 540, 135, 135, 540, 540, 8640, 540, 135, 540, 8640, 540, 540, 8640, 540, 8640, 135, 8640, 8640, 540, 135, 135, 8640, 540, 135, 540, 540, 8640, 540, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 8640, 8640, 135, 8640, 135, 540, 8640, 8640, 8640, 540, 135, 8640, 540, 135, 135, 135, 135, 135, 8640, 540, 135, 8640, 135, 8640, 135, 135, 540, 540, 8640, 540, 8640, 135, 540, 135, 8640, 8640, 135, 8640, 540, 135, 8640, 135, 135, 8640, 8640, 540, 8640, 8640, 135, 8640, 540, 540, 135, 540, 8640, 8640, 135, 8640, 540, 135, 540, 8640, 135, 135, 135, 135, 135, 135, 8640, 135, 135, 135, 8640, 135, 540, 8640, 8640, 540, 135, 8640, 135, 540, 540, 135, 540, 135, 8640, 135, 135, 8640, 135, 8640, 8640, 540, 8640, 540, 135, 540, 8640, 540, 8640, 135, 8640, 135, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 540, 135, 8640, 135, 8640, 540, 540, 135, 540, 8640, 540, 540, 8640, 135, 8640, 8640, 540, 135, 8640, 8640, 540, 540, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 8640, 135, 8640, 540, 8640, 8640, 135, 8640, 540, 540, 8640, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 8640, 540, 135, 135, 135, 135]
Prompts retrieved: 800415 . Total input tokens: 178214941 . Total output tokens: 157218537
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.768578853923827,
    "estimated_duration": 3600.036938970959,
    "input_throughput": 3940.970395724723,
    "output_throughput": 3441.7563514061353,
    "total_throughput": 7382.726747130858,
    "itl": 99.84331634040097,
    "ttft": 2077766.2541020187,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2863,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 21.50184960673126,
    "arrivals": 266663,
    "finished_requests": 57199,
    "scheduler_time": 142.9534442092969
}
#Debug simulation 
Total elapsed time: 4.768664676696062. Arrivals time: 0.19746959349140525 Scheduler time: 4.391083613969386 Scheduler overhead time: 0.05218616221100092 Adapter cache time: 0.0521552967838943 Engine time: 0.05178267089650035 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.0125_size_8-16-16/adapters_256_slots_96_rate_0.8-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.0125_size_8-16-16/adapters_256_slots_96_rate_0.8-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 8640, 135, 8640, 8640, 135, 8640, 540, 8640, 135, 540, 135, 8640, 540, 540, 540, 540, 8640, 135, 135, 135, 540, 8640, 135, 8640, 8640, 540, 540, 540, 135, 8640, 135, 540, 540, 135, 540, 135, 135, 540, 540, 8640, 540, 135, 540, 8640, 540, 540, 8640, 540, 8640, 135, 8640, 8640, 540, 135, 135, 8640, 540, 135, 540, 540, 8640, 540, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 8640, 8640, 135, 8640, 135, 540, 8640, 8640, 8640, 540, 135, 8640, 540, 135, 135, 135, 135, 135, 8640, 540, 135, 8640, 135, 8640, 135, 135, 540, 540, 8640, 540, 8640, 135, 540, 135, 8640, 8640, 135, 8640, 540, 135, 8640, 135, 135, 8640, 8640, 540, 8640, 8640, 135, 8640, 540, 540, 135, 540, 8640, 8640, 135, 8640, 540, 135, 540, 8640, 135, 135, 135, 135, 135, 135, 8640, 135, 135, 135, 8640, 135, 540, 8640, 8640, 540, 135, 8640, 135, 540, 540, 135, 540, 135, 8640, 135, 135, 8640, 135, 8640, 8640, 540, 8640, 540, 135, 540, 8640, 540, 8640, 135, 8640, 135, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 540, 135, 8640, 135, 8640, 540, 540, 135, 540, 8640, 540, 540, 8640, 135, 8640, 8640, 540, 135, 8640, 8640, 540, 540, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 8640, 135, 8640, 540, 8640, 8640, 135, 8640, 540, 540, 8640, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 8640, 540, 135, 135, 135, 135]
Prompts retrieved: 800415 . Total input tokens: 178214941 . Total output tokens: 157218537
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 6.386681248899549,
    "estimated_duration": 3600.00147969054,
    "input_throughput": 4467.266497174452,
    "output_throughput": 3897.9478422898483,
    "total_throughput": 8365.214339464299,
    "itl": 123.89787305534293,
    "ttft": 1982104.206175824,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1484,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.19144891900949,
    "arrivals": 266663,
    "finished_requests": 64906,
    "scheduler_time": 131.3844412394445
}
#Debug simulation 
Total elapsed time: 6.386775174178183. Arrivals time: 0.22647041594609618 Scheduler time: 6.0215213149785995 Scheduler overhead time: 0.044675901997834444 Adapter cache time: 0.030139042530208826 Engine time: 0.043730749282985926 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.0125_size_8-16-32/adapters_256_slots_96_rate_0.8-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.0125_size_8-16-32/adapters_256_slots_96_rate_0.8-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 8640, 135, 8640, 8640, 135, 8640, 540, 8640, 135, 540, 135, 8640, 540, 540, 540, 540, 8640, 135, 135, 135, 540, 8640, 135, 8640, 8640, 540, 540, 540, 135, 8640, 135, 540, 540, 135, 540, 135, 135, 540, 540, 8640, 540, 135, 540, 8640, 540, 540, 8640, 540, 8640, 135, 8640, 8640, 540, 135, 135, 8640, 540, 135, 540, 540, 8640, 540, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 8640, 8640, 135, 8640, 135, 540, 8640, 8640, 8640, 540, 135, 8640, 540, 135, 135, 135, 135, 135, 8640, 540, 135, 8640, 135, 8640, 135, 135, 540, 540, 8640, 540, 8640, 135, 540, 135, 8640, 8640, 135, 8640, 540, 135, 8640, 135, 135, 8640, 8640, 540, 8640, 8640, 135, 8640, 540, 540, 135, 540, 8640, 8640, 135, 8640, 540, 135, 540, 8640, 135, 135, 135, 135, 135, 135, 8640, 135, 135, 135, 8640, 135, 540, 8640, 8640, 540, 135, 8640, 135, 540, 540, 135, 540, 135, 8640, 135, 135, 8640, 135, 8640, 8640, 540, 8640, 540, 135, 540, 8640, 540, 8640, 135, 8640, 135, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 540, 135, 8640, 135, 8640, 540, 540, 135, 540, 8640, 540, 540, 8640, 135, 8640, 8640, 540, 135, 8640, 8640, 540, 540, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 8640, 135, 8640, 540, 8640, 8640, 135, 8640, 540, 540, 8640, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 8640, 540, 135, 135, 135, 135]
Prompts retrieved: 800415 . Total input tokens: 178214941 . Total output tokens: 157218537
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 4.800303542986512,
    "estimated_duration": 3600.020285330853,
    "input_throughput": 3939.5461347231244,
    "output_throughput": 3440.377836332592,
    "total_throughput": 7379.923971055716,
    "itl": 99.7604437674518,
    "ttft": 2077853.4256455882,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2814,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.941723918421427,
    "arrivals": 266663,
    "finished_requests": 57173,
    "scheduler_time": 143.02545064635837
}
#Debug simulation 
Total elapsed time: 4.800394233781844. Arrivals time: 0.20007530180737376 Scheduler time: 4.420700263231993 Scheduler overhead time: 0.05211524246260524 Adapter cache time: 0.05155764892697334 Engine time: 0.05199360707774758 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.0125_size_16-16-16/adapters_256_slots_96_rate_0.8-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.0125_size_16-16-16/adapters_256_slots_96_rate_0.8-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 8640, 135, 8640, 8640, 135, 8640, 540, 8640, 135, 540, 135, 8640, 540, 540, 540, 540, 8640, 135, 135, 135, 540, 8640, 135, 8640, 8640, 540, 540, 540, 135, 8640, 135, 540, 540, 135, 540, 135, 135, 540, 540, 8640, 540, 135, 540, 8640, 540, 540, 8640, 540, 8640, 135, 8640, 8640, 540, 135, 135, 8640, 540, 135, 540, 540, 8640, 540, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 8640, 8640, 135, 8640, 135, 540, 8640, 8640, 8640, 540, 135, 8640, 540, 135, 135, 135, 135, 135, 8640, 540, 135, 8640, 135, 8640, 135, 135, 540, 540, 8640, 540, 8640, 135, 540, 135, 8640, 8640, 135, 8640, 540, 135, 8640, 135, 135, 8640, 8640, 540, 8640, 8640, 135, 8640, 540, 540, 135, 540, 8640, 8640, 135, 8640, 540, 135, 540, 8640, 135, 135, 135, 135, 135, 135, 8640, 135, 135, 135, 8640, 135, 540, 8640, 8640, 540, 135, 8640, 135, 540, 540, 135, 540, 135, 8640, 135, 135, 8640, 135, 8640, 8640, 540, 8640, 540, 135, 540, 8640, 540, 8640, 135, 8640, 135, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 540, 135, 8640, 135, 8640, 540, 540, 135, 540, 8640, 540, 540, 8640, 135, 8640, 8640, 540, 135, 8640, 8640, 540, 540, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 8640, 135, 8640, 540, 8640, 8640, 135, 8640, 540, 540, 8640, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 8640, 540, 135, 135, 135, 135]
Prompts retrieved: 800415 . Total input tokens: 178214941 . Total output tokens: 157218537
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 6.3125287112779915,
    "estimated_duration": 3600.0986069041373,
    "input_throughput": 4469.574796962906,
    "output_throughput": 3899.1157000755397,
    "total_throughput": 8368.690497038446,
    "itl": 123.90442090787644,
    "ttft": 1982702.8866798203,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1515,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.67164022496454,
    "arrivals": 266663,
    "finished_requests": 64936,
    "scheduler_time": 131.39336062051888
}
#Debug simulation 
Total elapsed time: 6.3126439321786165. Arrivals time: 0.21992083452641964 Scheduler time: 5.954187962692231 Scheduler overhead time: 0.04434504546225071 Adapter cache time: 0.030355591792613268 Engine time: 0.043597448617219925 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.0125_size_16-16-32/adapters_256_slots_96_rate_0.8-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.0125_size_16-16-32/adapters_256_slots_96_rate_0.8-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 8640, 135, 8640, 8640, 135, 8640, 540, 8640, 135, 540, 135, 8640, 540, 540, 540, 540, 8640, 135, 135, 135, 540, 8640, 135, 8640, 8640, 540, 540, 540, 135, 8640, 135, 540, 540, 135, 540, 135, 135, 540, 540, 8640, 540, 135, 540, 8640, 540, 540, 8640, 540, 8640, 135, 8640, 8640, 540, 135, 135, 8640, 540, 135, 540, 540, 8640, 540, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 8640, 8640, 135, 8640, 135, 540, 8640, 8640, 8640, 540, 135, 8640, 540, 135, 135, 135, 135, 135, 8640, 540, 135, 8640, 135, 8640, 135, 135, 540, 540, 8640, 540, 8640, 135, 540, 135, 8640, 8640, 135, 8640, 540, 135, 8640, 135, 135, 8640, 8640, 540, 8640, 8640, 135, 8640, 540, 540, 135, 540, 8640, 8640, 135, 8640, 540, 135, 540, 8640, 135, 135, 135, 135, 135, 135, 8640, 135, 135, 135, 8640, 135, 540, 8640, 8640, 540, 135, 8640, 135, 540, 540, 135, 540, 135, 8640, 135, 135, 8640, 135, 8640, 8640, 540, 8640, 540, 135, 540, 8640, 540, 8640, 135, 8640, 135, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 540, 135, 8640, 135, 8640, 540, 540, 135, 540, 8640, 540, 540, 8640, 135, 8640, 8640, 540, 135, 8640, 8640, 540, 540, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 8640, 135, 8640, 540, 8640, 8640, 135, 8640, 540, 540, 8640, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 8640, 540, 135, 135, 135, 135]
Prompts retrieved: 800415 . Total input tokens: 178214941 . Total output tokens: 157218537
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.787214580923319,
    "estimated_duration": 3600.0615328418226,
    "input_throughput": 3940.2890396716075,
    "output_throughput": 3441.2425696014698,
    "total_throughput": 7381.531609273077,
    "itl": 99.77370384454292,
    "ttft": 2077854.1820434774,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2839,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.91486357556679,
    "arrivals": 266663,
    "finished_requests": 57193,
    "scheduler_time": 143.0153513226796
}
#Debug simulation 
Total elapsed time: 4.787331475876272. Arrivals time: 0.20228214235976338 Scheduler time: 4.405027877073735 Scheduler overhead time: 0.05235263518989086 Adapter cache time: 0.0517419409006834 Engine time: 0.051879686303436756 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-8/adapters_256_slots_96_rate_0.8-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-8/adapters_256_slots_96_rate_0.8-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 8640, 66, 8640, 8640, 66, 8640, 540, 8640, 66, 540, 66, 8640, 540, 540, 540, 540, 8640, 66, 66, 66, 540, 8640, 66, 8640, 8640, 540, 540, 540, 66, 8640, 66, 540, 540, 66, 540, 66, 66, 540, 540, 8640, 540, 66, 540, 8640, 540, 540, 8640, 540, 8640, 66, 8640, 8640, 540, 66, 66, 8640, 540, 66, 540, 540, 8640, 540, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 8640, 8640, 66, 8640, 66, 540, 8640, 8640, 8640, 540, 66, 8640, 540, 66, 66, 66, 66, 66, 8640, 540, 66, 8640, 66, 8640, 66, 66, 540, 540, 8640, 540, 8640, 66, 540, 66, 8640, 8640, 66, 8640, 540, 66, 8640, 66, 66, 8640, 8640, 540, 8640, 8640, 66, 8640, 540, 540, 66, 540, 8640, 8640, 66, 8640, 540, 66, 540, 8640, 66, 66, 66, 66, 66, 66, 8640, 66, 66, 66, 8640, 66, 540, 8640, 8640, 540, 66, 8640, 66, 540, 540, 66, 540, 66, 8640, 66, 66, 8640, 66, 8640, 8640, 540, 8640, 540, 66, 540, 8640, 540, 8640, 66, 8640, 66, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 540, 66, 8640, 66, 8640, 540, 540, 66, 540, 8640, 540, 540, 8640, 66, 8640, 8640, 540, 66, 8640, 8640, 540, 540, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 8640, 66, 8640, 540, 8640, 8640, 66, 8640, 540, 540, 8640, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 8640, 540, 66, 66, 66, 66]
Prompts retrieved: 794550 . Total input tokens: 176917091 . Total output tokens: 156115593
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 6.824168601073325,
    "estimated_duration": 3600.135443862621,
    "input_throughput": 4646.561847698734,
    "output_throughput": 4056.6034883206726,
    "total_throughput": 8703.165336019407,
    "itl": 135.17379643714713,
    "ttft": 1948842.4367552078,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1090,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.2075258448255966,
    "arrivals": 264754,
    "finished_requests": 67815,
    "scheduler_time": 127.30072595739006
}
#Debug simulation 
Total elapsed time: 6.824284127913415. Arrivals time: 0.22926460532471538 Scheduler time: 6.470381041057408 Scheduler overhead time: 0.04174320911988616 Adapter cache time: 0.0230720192193985 Engine time: 0.04089127853512764 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-16/adapters_256_slots_96_rate_0.8-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-16/adapters_256_slots_96_rate_0.8-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 8640, 66, 8640, 8640, 66, 8640, 540, 8640, 66, 540, 66, 8640, 540, 540, 540, 540, 8640, 66, 66, 66, 540, 8640, 66, 8640, 8640, 540, 540, 540, 66, 8640, 66, 540, 540, 66, 540, 66, 66, 540, 540, 8640, 540, 66, 540, 8640, 540, 540, 8640, 540, 8640, 66, 8640, 8640, 540, 66, 66, 8640, 540, 66, 540, 540, 8640, 540, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 8640, 8640, 66, 8640, 66, 540, 8640, 8640, 8640, 540, 66, 8640, 540, 66, 66, 66, 66, 66, 8640, 540, 66, 8640, 66, 8640, 66, 66, 540, 540, 8640, 540, 8640, 66, 540, 66, 8640, 8640, 66, 8640, 540, 66, 8640, 66, 66, 8640, 8640, 540, 8640, 8640, 66, 8640, 540, 540, 66, 540, 8640, 8640, 66, 8640, 540, 66, 540, 8640, 66, 66, 66, 66, 66, 66, 8640, 66, 66, 66, 8640, 66, 540, 8640, 8640, 540, 66, 8640, 66, 540, 540, 66, 540, 66, 8640, 66, 66, 8640, 66, 8640, 8640, 540, 8640, 540, 66, 540, 8640, 540, 8640, 66, 8640, 66, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 540, 66, 8640, 66, 8640, 540, 540, 66, 540, 8640, 540, 540, 8640, 66, 8640, 8640, 540, 66, 8640, 8640, 540, 540, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 8640, 66, 8640, 540, 8640, 8640, 66, 8640, 540, 540, 8640, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 8640, 540, 66, 66, 66, 66]
Prompts retrieved: 794550 . Total input tokens: 176917091 . Total output tokens: 156115593
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.989495492074639,
    "estimated_duration": 3600.017085895219,
    "input_throughput": 4457.514122050215,
    "output_throughput": 3895.235957335161,
    "total_throughput": 8352.750079385376,
    "itl": 123.4915218668662,
    "ttft": 1981844.052204765,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1457,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.656276480364516,
    "arrivals": 264754,
    "finished_requests": 65092,
    "scheduler_time": 131.4456642187044
}
#Debug simulation 
Total elapsed time: 5.989589252043515. Arrivals time: 0.22072523040696979 Scheduler time: 5.630830253008753 Scheduler overhead time: 0.044440535362809896 Adapter cache time: 0.029044620227068663 Engine time: 0.04428755585104227 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-32/adapters_256_slots_96_rate_0.8-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-32/adapters_256_slots_96_rate_0.8-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 8640, 66, 8640, 8640, 66, 8640, 540, 8640, 66, 540, 66, 8640, 540, 540, 540, 540, 8640, 66, 66, 66, 540, 8640, 66, 8640, 8640, 540, 540, 540, 66, 8640, 66, 540, 540, 66, 540, 66, 66, 540, 540, 8640, 540, 66, 540, 8640, 540, 540, 8640, 540, 8640, 66, 8640, 8640, 540, 66, 66, 8640, 540, 66, 540, 540, 8640, 540, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 8640, 8640, 66, 8640, 66, 540, 8640, 8640, 8640, 540, 66, 8640, 540, 66, 66, 66, 66, 66, 8640, 540, 66, 8640, 66, 8640, 66, 66, 540, 540, 8640, 540, 8640, 66, 540, 66, 8640, 8640, 66, 8640, 540, 66, 8640, 66, 66, 8640, 8640, 540, 8640, 8640, 66, 8640, 540, 540, 66, 540, 8640, 8640, 66, 8640, 540, 66, 540, 8640, 66, 66, 66, 66, 66, 66, 8640, 66, 66, 66, 8640, 66, 540, 8640, 8640, 540, 66, 8640, 66, 540, 540, 66, 540, 66, 8640, 66, 66, 8640, 66, 8640, 8640, 540, 8640, 540, 66, 540, 8640, 540, 8640, 66, 8640, 66, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 540, 66, 8640, 66, 8640, 540, 540, 66, 540, 8640, 540, 540, 8640, 66, 8640, 8640, 540, 66, 8640, 8640, 540, 540, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 8640, 66, 8640, 540, 8640, 8640, 66, 8640, 540, 540, 8640, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 8640, 540, 66, 66, 66, 66]
Prompts retrieved: 794550 . Total input tokens: 176917091 . Total output tokens: 156115593
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.7237316789105535,
    "estimated_duration": 3600.031823495844,
    "input_throughput": 3931.0816386777246,
    "output_throughput": 3450.0203356367188,
    "total_throughput": 7381.101974314443,
    "itl": 99.84089038394768,
    "ttft": 2074251.0934889633,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2680,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.136709401393432,
    "arrivals": 264754,
    "finished_requests": 57495,
    "scheduler_time": 142.8326829273461
}
#Debug simulation 
Total elapsed time: 4.723854622337967. Arrivals time: 0.20117116905748844 Scheduler time: 4.345687008462846 Scheduler overhead time: 0.05211552698165178 Adapter cache time: 0.04859940009191632 Engine time: 0.052064447198063135 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.00625_size_8-16-16/adapters_256_slots_96_rate_0.8-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.00625_size_8-16-16/adapters_256_slots_96_rate_0.8-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 8640, 66, 8640, 8640, 66, 8640, 540, 8640, 66, 540, 66, 8640, 540, 540, 540, 540, 8640, 66, 66, 66, 540, 8640, 66, 8640, 8640, 540, 540, 540, 66, 8640, 66, 540, 540, 66, 540, 66, 66, 540, 540, 8640, 540, 66, 540, 8640, 540, 540, 8640, 540, 8640, 66, 8640, 8640, 540, 66, 66, 8640, 540, 66, 540, 540, 8640, 540, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 8640, 8640, 66, 8640, 66, 540, 8640, 8640, 8640, 540, 66, 8640, 540, 66, 66, 66, 66, 66, 8640, 540, 66, 8640, 66, 8640, 66, 66, 540, 540, 8640, 540, 8640, 66, 540, 66, 8640, 8640, 66, 8640, 540, 66, 8640, 66, 66, 8640, 8640, 540, 8640, 8640, 66, 8640, 540, 540, 66, 540, 8640, 8640, 66, 8640, 540, 66, 540, 8640, 66, 66, 66, 66, 66, 66, 8640, 66, 66, 66, 8640, 66, 540, 8640, 8640, 540, 66, 8640, 66, 540, 540, 66, 540, 66, 8640, 66, 66, 8640, 66, 8640, 8640, 540, 8640, 540, 66, 540, 8640, 540, 8640, 66, 8640, 66, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 540, 66, 8640, 66, 8640, 540, 540, 66, 540, 8640, 540, 540, 8640, 66, 8640, 8640, 540, 66, 8640, 8640, 540, 540, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 8640, 66, 8640, 540, 8640, 8640, 66, 8640, 540, 540, 8640, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 8640, 540, 66, 66, 66, 66]
Prompts retrieved: 794550 . Total input tokens: 176917091 . Total output tokens: 156115593
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 6.033991735894233,
    "estimated_duration": 3600.123790132276,
    "input_throughput": 4457.45755853867,
    "output_throughput": 3896.6554534738834,
    "total_throughput": 8354.113012012554,
    "itl": 123.51554697208796,
    "ttft": 1980647.36427426,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1444,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.941644965279885,
    "arrivals": 264754,
    "finished_requests": 65108,
    "scheduler_time": 131.4607339864102
}
#Debug simulation 
Total elapsed time: 6.034111096989363. Arrivals time: 0.2202300215139985 Scheduler time: 5.6756616611965 Scheduler overhead time: 0.04455855209380388 Adapter cache time: 0.02927184710279107 Engine time: 0.04399213474243879 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.00625_size_8-16-32/adapters_256_slots_96_rate_0.8-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.00625_size_8-16-32/adapters_256_slots_96_rate_0.8-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 8640, 66, 8640, 8640, 66, 8640, 540, 8640, 66, 540, 66, 8640, 540, 540, 540, 540, 8640, 66, 66, 66, 540, 8640, 66, 8640, 8640, 540, 540, 540, 66, 8640, 66, 540, 540, 66, 540, 66, 66, 540, 540, 8640, 540, 66, 540, 8640, 540, 540, 8640, 540, 8640, 66, 8640, 8640, 540, 66, 66, 8640, 540, 66, 540, 540, 8640, 540, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 8640, 8640, 66, 8640, 66, 540, 8640, 8640, 8640, 540, 66, 8640, 540, 66, 66, 66, 66, 66, 8640, 540, 66, 8640, 66, 8640, 66, 66, 540, 540, 8640, 540, 8640, 66, 540, 66, 8640, 8640, 66, 8640, 540, 66, 8640, 66, 66, 8640, 8640, 540, 8640, 8640, 66, 8640, 540, 540, 66, 540, 8640, 8640, 66, 8640, 540, 66, 540, 8640, 66, 66, 66, 66, 66, 66, 8640, 66, 66, 66, 8640, 66, 540, 8640, 8640, 540, 66, 8640, 66, 540, 540, 66, 540, 66, 8640, 66, 66, 8640, 66, 8640, 8640, 540, 8640, 540, 66, 540, 8640, 540, 8640, 66, 8640, 66, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 540, 66, 8640, 66, 8640, 540, 540, 66, 540, 8640, 540, 540, 8640, 66, 8640, 8640, 540, 66, 8640, 8640, 540, 540, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 8640, 66, 8640, 540, 8640, 8640, 66, 8640, 540, 540, 8640, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 8640, 540, 66, 66, 66, 66]
Prompts retrieved: 794550 . Total input tokens: 176917091 . Total output tokens: 156115593
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 4.674880272708833,
    "estimated_duration": 3600.0111007640785,
    "input_throughput": 3925.6187285090646,
    "output_throughput": 3444.399101260607,
    "total_throughput": 7370.017829769671,
    "itl": 99.5964998450443,
    "ttft": 2075431.176727901,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2694,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.045606967713795,
    "arrivals": 264754,
    "finished_requests": 57407,
    "scheduler_time": 142.98777245761818
}
#Debug simulation 
Total elapsed time: 4.674965814687312. Arrivals time: 0.19842665176838636 Scheduler time: 4.298774034716189 Scheduler overhead time: 0.052095777820795774 Adapter cache time: 0.04983704350888729 Engine time: 0.05181369325146079 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.00625_size_16-16-16/adapters_256_slots_96_rate_0.8-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.00625_size_16-16-16/adapters_256_slots_96_rate_0.8-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 8640, 66, 8640, 8640, 66, 8640, 540, 8640, 66, 540, 66, 8640, 540, 540, 540, 540, 8640, 66, 66, 66, 540, 8640, 66, 8640, 8640, 540, 540, 540, 66, 8640, 66, 540, 540, 66, 540, 66, 66, 540, 540, 8640, 540, 66, 540, 8640, 540, 540, 8640, 540, 8640, 66, 8640, 8640, 540, 66, 66, 8640, 540, 66, 540, 540, 8640, 540, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 8640, 8640, 66, 8640, 66, 540, 8640, 8640, 8640, 540, 66, 8640, 540, 66, 66, 66, 66, 66, 8640, 540, 66, 8640, 66, 8640, 66, 66, 540, 540, 8640, 540, 8640, 66, 540, 66, 8640, 8640, 66, 8640, 540, 66, 8640, 66, 66, 8640, 8640, 540, 8640, 8640, 66, 8640, 540, 540, 66, 540, 8640, 8640, 66, 8640, 540, 66, 540, 8640, 66, 66, 66, 66, 66, 66, 8640, 66, 66, 66, 8640, 66, 540, 8640, 8640, 540, 66, 8640, 66, 540, 540, 66, 540, 66, 8640, 66, 66, 8640, 66, 8640, 8640, 540, 8640, 540, 66, 540, 8640, 540, 8640, 66, 8640, 66, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 540, 66, 8640, 66, 8640, 540, 540, 66, 540, 8640, 540, 540, 8640, 66, 8640, 8640, 540, 66, 8640, 8640, 540, 540, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 8640, 66, 8640, 540, 8640, 8640, 66, 8640, 540, 540, 8640, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 8640, 540, 66, 66, 66, 66]
Prompts retrieved: 794550 . Total input tokens: 176917091 . Total output tokens: 156115593
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 6.074534613173455,
    "estimated_duration": 3600.074686847041,
    "input_throughput": 4456.646151986259,
    "output_throughput": 3896.7874892302334,
    "total_throughput": 8353.433641216492,
    "itl": 123.38170993391078,
    "ttft": 1980657.8912482539,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1418,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.052399893729115,
    "arrivals": 264754,
    "finished_requests": 65110,
    "scheduler_time": 131.53004028351538
}
#Debug simulation 
Total elapsed time: 6.074636891949922. Arrivals time: 0.23224339028820395 Scheduler time: 5.705478868447244 Scheduler overhead time: 0.04455465963110328 Adapter cache time: 0.028257280588150024 Engine time: 0.04380664695054293 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.00625_size_16-16-32/adapters_256_slots_96_rate_0.8-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.00625_size_16-16-32/adapters_256_slots_96_rate_0.8-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 8640, 66, 8640, 8640, 66, 8640, 540, 8640, 66, 540, 66, 8640, 540, 540, 540, 540, 8640, 66, 66, 66, 540, 8640, 66, 8640, 8640, 540, 540, 540, 66, 8640, 66, 540, 540, 66, 540, 66, 66, 540, 540, 8640, 540, 66, 540, 8640, 540, 540, 8640, 540, 8640, 66, 8640, 8640, 540, 66, 66, 8640, 540, 66, 540, 540, 8640, 540, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 8640, 8640, 66, 8640, 66, 540, 8640, 8640, 8640, 540, 66, 8640, 540, 66, 66, 66, 66, 66, 8640, 540, 66, 8640, 66, 8640, 66, 66, 540, 540, 8640, 540, 8640, 66, 540, 66, 8640, 8640, 66, 8640, 540, 66, 8640, 66, 66, 8640, 8640, 540, 8640, 8640, 66, 8640, 540, 540, 66, 540, 8640, 8640, 66, 8640, 540, 66, 540, 8640, 66, 66, 66, 66, 66, 66, 8640, 66, 66, 66, 8640, 66, 540, 8640, 8640, 540, 66, 8640, 66, 540, 540, 66, 540, 66, 8640, 66, 66, 8640, 66, 8640, 8640, 540, 8640, 540, 66, 540, 8640, 540, 8640, 66, 8640, 66, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 540, 66, 8640, 66, 8640, 540, 540, 66, 540, 8640, 540, 540, 8640, 66, 8640, 8640, 540, 66, 8640, 8640, 540, 540, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 8640, 66, 8640, 540, 8640, 8640, 66, 8640, 540, 540, 8640, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 8640, 540, 66, 66, 66, 66]
Prompts retrieved: 794550 . Total input tokens: 176917091 . Total output tokens: 156115593
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.6514425477944314,
    "estimated_duration": 3600.0441255197325,
    "input_throughput": 3926.2363202171605,
    "output_throughput": 3444.5677796267973,
    "total_throughput": 7370.804099843958,
    "itl": 99.59697921041025,
    "ttft": 2075439.3148070776,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2695,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.861323411744184,
    "arrivals": 264754,
    "finished_requests": 57422,
    "scheduler_time": 142.9843426282167
}
#Debug simulation 
Total elapsed time: 4.651527436915785. Arrivals time: 0.19808436604216695 Scheduler time: 4.275385539978743 Scheduler overhead time: 0.051741689909249544 Adapter cache time: 0.04994898056611419 Engine time: 0.05235633905977011 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-8/adapters_256_slots_96_rate_0.8-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-8/adapters_256_slots_96_rate_0.8-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 8640, 33, 8640, 8640, 33, 8640, 540, 8640, 33, 540, 33, 8640, 540, 540, 540, 540, 8640, 33, 33, 33, 540, 8640, 33, 8640, 8640, 540, 540, 540, 33, 8640, 33, 540, 540, 33, 540, 33, 33, 540, 540, 8640, 540, 33, 540, 8640, 540, 540, 8640, 540, 8640, 33, 8640, 8640, 540, 33, 33, 8640, 540, 33, 540, 540, 8640, 540, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 8640, 8640, 33, 8640, 33, 540, 8640, 8640, 8640, 540, 33, 8640, 540, 33, 33, 33, 33, 33, 8640, 540, 33, 8640, 33, 8640, 33, 33, 540, 540, 8640, 540, 8640, 33, 540, 33, 8640, 8640, 33, 8640, 540, 33, 8640, 33, 33, 8640, 8640, 540, 8640, 8640, 33, 8640, 540, 540, 33, 540, 8640, 8640, 33, 8640, 540, 33, 540, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 540, 8640, 8640, 540, 33, 8640, 33, 540, 540, 33, 540, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 540, 8640, 540, 33, 540, 8640, 540, 8640, 33, 8640, 33, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 540, 33, 8640, 33, 8640, 540, 540, 33, 540, 8640, 540, 540, 8640, 33, 8640, 8640, 540, 33, 8640, 8640, 540, 540, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 8640, 33, 8640, 540, 8640, 8640, 33, 8640, 540, 540, 8640, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 8640, 540, 33, 33, 33, 33]
Prompts retrieved: 791745 . Total input tokens: 176275360 . Total output tokens: 155563613
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 6.556154842954129,
    "estimated_duration": 3600.0054364591333,
    "input_throughput": 4705.48067190184,
    "output_throughput": 4057.938038662691,
    "total_throughput": 8763.41871056453,
    "itl": 135.19120911928857,
    "ttft": 1941643.7164301947,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 986,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.519835305502781,
    "arrivals": 263766,
    "finished_requests": 68297,
    "scheduler_time": 127.29094893135608
}
#Debug simulation 
Total elapsed time: 6.556241994723678. Arrivals time: 0.26749994372949004 Scheduler time: 6.1655065305531025 Scheduler overhead time: 0.04189982125535607 Adapter cache time: 0.021446740720421076 Engine time: 0.04097880143672228 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-16/adapters_256_slots_96_rate_0.8-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-16/adapters_256_slots_96_rate_0.8-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 8640, 33, 8640, 8640, 33, 8640, 540, 8640, 33, 540, 33, 8640, 540, 540, 540, 540, 8640, 33, 33, 33, 540, 8640, 33, 8640, 8640, 540, 540, 540, 33, 8640, 33, 540, 540, 33, 540, 33, 33, 540, 540, 8640, 540, 33, 540, 8640, 540, 540, 8640, 540, 8640, 33, 8640, 8640, 540, 33, 33, 8640, 540, 33, 540, 540, 8640, 540, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 8640, 8640, 33, 8640, 33, 540, 8640, 8640, 8640, 540, 33, 8640, 540, 33, 33, 33, 33, 33, 8640, 540, 33, 8640, 33, 8640, 33, 33, 540, 540, 8640, 540, 8640, 33, 540, 33, 8640, 8640, 33, 8640, 540, 33, 8640, 33, 33, 8640, 8640, 540, 8640, 8640, 33, 8640, 540, 540, 33, 540, 8640, 8640, 33, 8640, 540, 33, 540, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 540, 8640, 8640, 540, 33, 8640, 33, 540, 540, 33, 540, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 540, 8640, 540, 33, 540, 8640, 540, 8640, 33, 8640, 33, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 540, 33, 8640, 33, 8640, 540, 540, 33, 540, 8640, 540, 540, 8640, 33, 8640, 8640, 540, 33, 8640, 8640, 540, 540, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 8640, 33, 8640, 540, 8640, 8640, 33, 8640, 540, 540, 8640, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 8640, 540, 33, 33, 33, 33]
Prompts retrieved: 791745 . Total input tokens: 176275360 . Total output tokens: 155563613
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.856637405231595,
    "estimated_duration": 3600.066182688633,
    "input_throughput": 4518.845814065141,
    "output_throughput": 3895.5353286106356,
    "total_throughput": 8414.381142675777,
    "itl": 123.5388680783382,
    "ttft": 1973635.332390379,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1327,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.718085522171988,
    "arrivals": 263766,
    "finished_requests": 65581,
    "scheduler_time": 131.41064709734027
}
#Debug simulation 
Total elapsed time: 5.8567250282503664. Arrivals time: 0.2489198506809771 Scheduler time: 5.472507822327316 Scheduler overhead time: 0.04463934479281306 Adapter cache time: 0.026976481080055237 Engine time: 0.043423994444310665 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-32/adapters_256_slots_96_rate_0.8-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-32/adapters_256_slots_96_rate_0.8-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 8640, 33, 8640, 8640, 33, 8640, 540, 8640, 33, 540, 33, 8640, 540, 540, 540, 540, 8640, 33, 33, 33, 540, 8640, 33, 8640, 8640, 540, 540, 540, 33, 8640, 33, 540, 540, 33, 540, 33, 33, 540, 540, 8640, 540, 33, 540, 8640, 540, 540, 8640, 540, 8640, 33, 8640, 8640, 540, 33, 33, 8640, 540, 33, 540, 540, 8640, 540, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 8640, 8640, 33, 8640, 33, 540, 8640, 8640, 8640, 540, 33, 8640, 540, 33, 33, 33, 33, 33, 8640, 540, 33, 8640, 33, 8640, 33, 33, 540, 540, 8640, 540, 8640, 33, 540, 33, 8640, 8640, 33, 8640, 540, 33, 8640, 33, 33, 8640, 8640, 540, 8640, 8640, 33, 8640, 540, 540, 33, 540, 8640, 8640, 33, 8640, 540, 33, 540, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 540, 8640, 8640, 540, 33, 8640, 33, 540, 540, 33, 540, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 540, 8640, 540, 33, 540, 8640, 540, 8640, 33, 8640, 33, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 540, 33, 8640, 33, 8640, 540, 540, 33, 540, 8640, 540, 540, 8640, 33, 8640, 8640, 540, 33, 8640, 8640, 540, 540, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 8640, 33, 8640, 540, 8640, 8640, 33, 8640, 540, 540, 8640, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 8640, 540, 33, 33, 33, 33]
Prompts retrieved: 791745 . Total input tokens: 176275360 . Total output tokens: 155563613
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.612505826167762,
    "estimated_duration": 3600.0283401462866,
    "input_throughput": 3985.521958256854,
    "output_throughput": 3441.762072210942,
    "total_throughput": 7427.284030467796,
    "itl": 99.54498108483556,
    "ttft": 2069761.050773389,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2682,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.142608709773167,
    "arrivals": 263766,
    "finished_requests": 57863,
    "scheduler_time": 142.99207943996112
}
#Debug simulation 
Total elapsed time: 4.612592197954655. Arrivals time: 0.22315019369125366 Scheduler time: 4.212135550100356 Scheduler overhead time: 0.05209833476692438 Adapter cache time: 0.04948986787348986 Engine time: 0.051723701879382133 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.003125_size_8-16-16/adapters_256_slots_96_rate_0.8-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.003125_size_8-16-16/adapters_256_slots_96_rate_0.8-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 8640, 33, 8640, 8640, 33, 8640, 540, 8640, 33, 540, 33, 8640, 540, 540, 540, 540, 8640, 33, 33, 33, 540, 8640, 33, 8640, 8640, 540, 540, 540, 33, 8640, 33, 540, 540, 33, 540, 33, 33, 540, 540, 8640, 540, 33, 540, 8640, 540, 540, 8640, 540, 8640, 33, 8640, 8640, 540, 33, 33, 8640, 540, 33, 540, 540, 8640, 540, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 8640, 8640, 33, 8640, 33, 540, 8640, 8640, 8640, 540, 33, 8640, 540, 33, 33, 33, 33, 33, 8640, 540, 33, 8640, 33, 8640, 33, 33, 540, 540, 8640, 540, 8640, 33, 540, 33, 8640, 8640, 33, 8640, 540, 33, 8640, 33, 33, 8640, 8640, 540, 8640, 8640, 33, 8640, 540, 540, 33, 540, 8640, 8640, 33, 8640, 540, 33, 540, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 540, 8640, 8640, 540, 33, 8640, 33, 540, 540, 33, 540, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 540, 8640, 540, 33, 540, 8640, 540, 8640, 33, 8640, 33, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 540, 33, 8640, 33, 8640, 540, 540, 33, 540, 8640, 540, 540, 8640, 33, 8640, 8640, 540, 33, 8640, 8640, 540, 540, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 8640, 33, 8640, 540, 8640, 8640, 33, 8640, 540, 540, 8640, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 8640, 540, 33, 33, 33, 33]
Prompts retrieved: 791745 . Total input tokens: 176275360 . Total output tokens: 155563613
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 5.844137812033296,
    "estimated_duration": 3600.0046281020213,
    "input_throughput": 4520.528355148217,
    "output_throughput": 3897.25860085822,
    "total_throughput": 8417.786956006437,
    "itl": 123.48043026072517,
    "ttft": 1974135.518779304,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1307,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.021236504302378,
    "arrivals": 263766,
    "finished_requests": 65605,
    "scheduler_time": 131.43541595411594
}
#Debug simulation 
Total elapsed time: 5.84422672400251. Arrivals time: 0.24145606346428394 Scheduler time: 5.467691503465176 Scheduler overhead time: 0.044549901969730854 Adapter cache time: 0.02672872133553028 Engine time: 0.043432355392724276 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.003125_size_8-16-32/adapters_256_slots_96_rate_0.8-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.003125_size_8-16-32/adapters_256_slots_96_rate_0.8-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 8640, 33, 8640, 8640, 33, 8640, 540, 8640, 33, 540, 33, 8640, 540, 540, 540, 540, 8640, 33, 33, 33, 540, 8640, 33, 8640, 8640, 540, 540, 540, 33, 8640, 33, 540, 540, 33, 540, 33, 33, 540, 540, 8640, 540, 33, 540, 8640, 540, 540, 8640, 540, 8640, 33, 8640, 8640, 540, 33, 33, 8640, 540, 33, 540, 540, 8640, 540, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 8640, 8640, 33, 8640, 33, 540, 8640, 8640, 8640, 540, 33, 8640, 540, 33, 33, 33, 33, 33, 8640, 540, 33, 8640, 33, 8640, 33, 33, 540, 540, 8640, 540, 8640, 33, 540, 33, 8640, 8640, 33, 8640, 540, 33, 8640, 33, 33, 8640, 8640, 540, 8640, 8640, 33, 8640, 540, 540, 33, 540, 8640, 8640, 33, 8640, 540, 33, 540, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 540, 8640, 8640, 540, 33, 8640, 33, 540, 540, 33, 540, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 540, 8640, 540, 33, 540, 8640, 540, 8640, 33, 8640, 33, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 540, 33, 8640, 33, 8640, 540, 540, 33, 540, 8640, 540, 540, 8640, 33, 8640, 8640, 540, 33, 8640, 8640, 540, 540, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 8640, 33, 8640, 540, 8640, 8640, 33, 8640, 540, 540, 8640, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 8640, 540, 33, 33, 33, 33]
Prompts retrieved: 791745 . Total input tokens: 176275360 . Total output tokens: 155563613
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 4.62574920989573,
    "estimated_duration": 3600.1040800424717,
    "input_throughput": 3992.487628255023,
    "output_throughput": 3446.2770309278476,
    "total_throughput": 7438.764659182871,
    "itl": 99.7862629804239,
    "ttft": 2068630.3343296058,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2648,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.72257552310366,
    "arrivals": 263766,
    "finished_requests": 57950,
    "scheduler_time": 142.85213450142894
}
#Debug simulation 
Total elapsed time: 4.625841591972858. Arrivals time: 0.22837462648749352 Scheduler time: 4.2207823526114225 Scheduler overhead time: 0.05192299047484994 Adapter cache time: 0.0494735911488533 Engine time: 0.05143898446112871 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.003125_size_16-16-16/adapters_256_slots_96_rate_0.8-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.003125_size_16-16-16/adapters_256_slots_96_rate_0.8-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 8640, 33, 8640, 8640, 33, 8640, 540, 8640, 33, 540, 33, 8640, 540, 540, 540, 540, 8640, 33, 33, 33, 540, 8640, 33, 8640, 8640, 540, 540, 540, 33, 8640, 33, 540, 540, 33, 540, 33, 33, 540, 540, 8640, 540, 33, 540, 8640, 540, 540, 8640, 540, 8640, 33, 8640, 8640, 540, 33, 33, 8640, 540, 33, 540, 540, 8640, 540, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 8640, 8640, 33, 8640, 33, 540, 8640, 8640, 8640, 540, 33, 8640, 540, 33, 33, 33, 33, 33, 8640, 540, 33, 8640, 33, 8640, 33, 33, 540, 540, 8640, 540, 8640, 33, 540, 33, 8640, 8640, 33, 8640, 540, 33, 8640, 33, 33, 8640, 8640, 540, 8640, 8640, 33, 8640, 540, 540, 33, 540, 8640, 8640, 33, 8640, 540, 33, 540, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 540, 8640, 8640, 540, 33, 8640, 33, 540, 540, 33, 540, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 540, 8640, 540, 33, 540, 8640, 540, 8640, 33, 8640, 33, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 540, 33, 8640, 33, 8640, 540, 540, 33, 540, 8640, 540, 540, 8640, 33, 8640, 8640, 540, 33, 8640, 8640, 540, 540, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 8640, 33, 8640, 540, 8640, 8640, 33, 8640, 540, 540, 8640, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 8640, 540, 33, 33, 33, 33]
Prompts retrieved: 791745 . Total input tokens: 176275360 . Total output tokens: 155563613
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.827204707078636,
    "estimated_duration": 3600.053956860848,
    "input_throughput": 4518.905326126148,
    "output_throughput": 3896.864371508712,
    "total_throughput": 8415.76969763486,
    "itl": 123.37698647399263,
    "ttft": 1974393.1768851918,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1294,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.260793697098263,
    "arrivals": 263766,
    "finished_requests": 65584,
    "scheduler_time": 131.50718330554412
}
#Debug simulation 
Total elapsed time: 5.827291775960475. Arrivals time: 0.24014971544966102 Scheduler time: 5.452023836784065 Scheduler overhead time: 0.04471430415287614 Adapter cache time: 0.02652152767404914 Engine time: 0.04366493411362171 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.003125_size_16-16-32/adapters_256_slots_96_rate_0.8-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.003125_size_16-16-32/adapters_256_slots_96_rate_0.8-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 8640, 33, 8640, 8640, 33, 8640, 540, 8640, 33, 540, 33, 8640, 540, 540, 540, 540, 8640, 33, 33, 33, 540, 8640, 33, 8640, 8640, 540, 540, 540, 33, 8640, 33, 540, 540, 33, 540, 33, 33, 540, 540, 8640, 540, 33, 540, 8640, 540, 540, 8640, 540, 8640, 33, 8640, 8640, 540, 33, 33, 8640, 540, 33, 540, 540, 8640, 540, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 8640, 8640, 33, 8640, 33, 540, 8640, 8640, 8640, 540, 33, 8640, 540, 33, 33, 33, 33, 33, 8640, 540, 33, 8640, 33, 8640, 33, 33, 540, 540, 8640, 540, 8640, 33, 540, 33, 8640, 8640, 33, 8640, 540, 33, 8640, 33, 33, 8640, 8640, 540, 8640, 8640, 33, 8640, 540, 540, 33, 540, 8640, 8640, 33, 8640, 540, 33, 540, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 540, 8640, 8640, 540, 33, 8640, 33, 540, 540, 33, 540, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 540, 8640, 540, 33, 540, 8640, 540, 8640, 33, 8640, 33, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 540, 33, 8640, 33, 8640, 540, 540, 33, 540, 8640, 540, 540, 8640, 33, 8640, 8640, 540, 33, 8640, 8640, 540, 540, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 8640, 33, 8640, 540, 8640, 8640, 33, 8640, 540, 540, 8640, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 8640, 540, 33, 33, 33, 33]
Prompts retrieved: 791745 . Total input tokens: 176275360 . Total output tokens: 155563613
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.6082464419305325,
    "estimated_duration": 3600.038584471318,
    "input_throughput": 3986.7317150179138,
    "output_throughput": 3442.52643664929,
    "total_throughput": 7429.258151667204,
    "itl": 99.53787528388044,
    "ttft": 2069798.9211748985,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2672,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.698357689827755,
    "arrivals": 263766,
    "finished_requests": 57873,
    "scheduler_time": 143.0105678082562
}
#Debug simulation 
Total elapsed time: 4.608326216228306. Arrivals time: 0.18775434466078877 Scheduler time: 4.243279274087399 Scheduler overhead time: 0.052128391806036234 Adapter cache time: 0.049198991153389215 Engine time: 0.051965259946882725 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-8/adapters_256_slots_96_rate_0.8-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-8/adapters_256_slots_96_rate_0.8-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 8640, 135, 8640, 8640, 135, 8640, 270, 8640, 135, 270, 135, 8640, 270, 270, 270, 270, 8640, 135, 135, 135, 270, 8640, 135, 8640, 8640, 270, 270, 270, 135, 8640, 135, 270, 270, 135, 270, 135, 135, 270, 270, 8640, 270, 135, 270, 8640, 270, 270, 8640, 270, 8640, 135, 8640, 8640, 270, 135, 135, 8640, 270, 135, 270, 270, 8640, 270, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 8640, 8640, 135, 8640, 135, 270, 8640, 8640, 8640, 270, 135, 8640, 270, 135, 135, 135, 135, 135, 8640, 270, 135, 8640, 135, 8640, 135, 135, 270, 270, 8640, 270, 8640, 135, 270, 135, 8640, 8640, 135, 8640, 270, 135, 8640, 135, 135, 8640, 8640, 270, 8640, 8640, 135, 8640, 270, 270, 135, 270, 8640, 8640, 135, 8640, 270, 135, 270, 8640, 135, 135, 135, 135, 135, 135, 8640, 135, 135, 135, 8640, 135, 270, 8640, 8640, 270, 135, 8640, 135, 270, 270, 135, 270, 135, 8640, 135, 135, 8640, 135, 8640, 8640, 270, 8640, 270, 135, 270, 8640, 270, 8640, 135, 8640, 135, 270, 8640, 270, 8640, 270, 8640, 270, 8640, 270, 135, 8640, 135, 8640, 270, 270, 135, 270, 8640, 270, 270, 8640, 135, 8640, 8640, 270, 135, 8640, 8640, 270, 270, 8640, 8640, 270, 270, 270, 270, 8640, 8640, 270, 270, 8640, 135, 8640, 270, 8640, 8640, 135, 8640, 270, 270, 8640, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 8640, 270, 135, 135, 135, 135]
Prompts retrieved: 777465 . Total input tokens: 173094731 . Total output tokens: 152764019
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 6.484251013025641,
    "estimated_duration": 3600.041128628625,
    "input_throughput": 4659.932873153179,
    "output_throughput": 4060.3002792826965,
    "total_throughput": 8720.233152435876,
    "itl": 135.53256681634775,
    "ttft": 1933915.4773944614,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1087,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.187688617729746,
    "arrivals": 258949,
    "finished_requests": 67793,
    "scheduler_time": 127.0509844613108
}
#Debug simulation 
Total elapsed time: 6.484332368709147. Arrivals time: 0.22937597194686532 Scheduler time: 6.130505017004907 Scheduler overhead time: 0.04174530832096934 Adapter cache time: 0.022993599995970726 Engine time: 0.04091227566823363 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-16/adapters_256_slots_96_rate_0.8-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-16/adapters_256_slots_96_rate_0.8-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 8640, 135, 8640, 8640, 135, 8640, 270, 8640, 135, 270, 135, 8640, 270, 270, 270, 270, 8640, 135, 135, 135, 270, 8640, 135, 8640, 8640, 270, 270, 270, 135, 8640, 135, 270, 270, 135, 270, 135, 135, 270, 270, 8640, 270, 135, 270, 8640, 270, 270, 8640, 270, 8640, 135, 8640, 8640, 270, 135, 135, 8640, 270, 135, 270, 270, 8640, 270, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 8640, 8640, 135, 8640, 135, 270, 8640, 8640, 8640, 270, 135, 8640, 270, 135, 135, 135, 135, 135, 8640, 270, 135, 8640, 135, 8640, 135, 135, 270, 270, 8640, 270, 8640, 135, 270, 135, 8640, 8640, 135, 8640, 270, 135, 8640, 135, 135, 8640, 8640, 270, 8640, 8640, 135, 8640, 270, 270, 135, 270, 8640, 8640, 135, 8640, 270, 135, 270, 8640, 135, 135, 135, 135, 135, 135, 8640, 135, 135, 135, 8640, 135, 270, 8640, 8640, 270, 135, 8640, 135, 270, 270, 135, 270, 135, 8640, 135, 135, 8640, 135, 8640, 8640, 270, 8640, 270, 135, 270, 8640, 270, 8640, 135, 8640, 135, 270, 8640, 270, 8640, 270, 8640, 270, 8640, 270, 135, 8640, 135, 8640, 270, 270, 135, 270, 8640, 270, 270, 8640, 135, 8640, 8640, 270, 135, 8640, 8640, 270, 270, 8640, 8640, 270, 270, 270, 270, 8640, 8640, 270, 270, 8640, 135, 8640, 270, 8640, 8640, 135, 8640, 270, 270, 8640, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 8640, 270, 135, 135, 135, 135]
Prompts retrieved: 777465 . Total input tokens: 173094731 . Total output tokens: 152764019
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.699747664388269,
    "estimated_duration": 3600.0789567292295,
    "input_throughput": 4470.956941073168,
    "output_throughput": 3897.378965473422,
    "total_throughput": 8368.33590654659,
    "itl": 123.77592040452258,
    "ttft": 1965806.881665305,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1539,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.238063278370422,
    "arrivals": 258949,
    "finished_requests": 65066,
    "scheduler_time": 131.19070512662412
}
#Debug simulation 
Total elapsed time: 5.699825798161328. Arrivals time: 0.2062973091378808 Scheduler time: 5.354634453076869 Scheduler overhead time: 0.04476433573290706 Adapter cache time: 0.03013307461515069 Engine time: 0.04375443886965513 
