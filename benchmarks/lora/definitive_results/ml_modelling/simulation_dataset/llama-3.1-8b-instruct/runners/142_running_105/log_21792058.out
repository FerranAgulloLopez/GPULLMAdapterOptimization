INFO 05-31 19:30:51 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 05-31 19:30:51 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.05_size_8-16-16/adapters_160_slots_96_rate_3.2-0.1-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.05_size_8-16-16/adapters_160_slots_96_rate_3.2-0.1-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [53 53 54]
Adapter prompts. [540, 34560, 540, 540, 1080, 540, 540, 540, 34560, 540, 1080, 34560, 1080, 540, 1080, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 540, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 540, 1080, 1080, 1080, 34560, 540, 540, 34560, 540, 34560, 540, 540, 1080, 540, 1080, 34560, 540, 540, 1080, 540, 540, 540, 540, 540, 34560, 1080, 1080, 34560, 1080, 540, 34560, 34560, 34560, 1080, 1080, 540, 540, 540, 34560, 540, 1080, 1080, 540, 34560, 34560, 34560, 540, 540, 34560, 1080, 34560, 34560, 540, 34560, 540, 1080, 540, 540, 1080, 1080, 34560, 34560, 34560, 540, 34560, 1080, 1080, 540, 540, 540, 540, 34560, 1080, 34560, 1080, 34560, 34560, 34560, 540, 1080, 1080, 34560, 1080, 34560, 540, 540, 540, 1080, 1080, 1080, 34560, 34560, 1080, 34560, 540, 1080, 1080, 540, 34560, 34560, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 34560, 540, 34560, 540, 34560, 1080, 540, 1080, 540, 540, 1080, 1080, 1080, 34560, 1080, 540, 540]
Prompts retrieved: 1952100 . Total input tokens: 435376779 . Total output tokens: 383506976
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 5.3853312828578055,
    "estimated_duration": 3600.0285416129173,
    "input_throughput": 5005.338094327109,
    "output_throughput": 4404.923687881436,
    "total_throughput": 9410.261782208545,
    "itl": 110.09275382623488,
    "ttft": 2101561.1172996233,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1836,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.560752535741962,
    "arrivals": 650482,
    "finished_requests": 73388,
    "scheduler_time": 107.66899930483812
}
#Debug simulation 
Total elapsed time: 5.385435453150421. Arrivals time: 0.22926508309319615 Scheduler time: 4.995101895183325 Scheduler overhead time: 0.0477009667083621 Adapter cache time: 0.04159250948578119 Engine time: 0.04924426507204771 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.05_size_8-16-32/adapters_160_slots_96_rate_3.2-0.1-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.05_size_8-16-32/adapters_160_slots_96_rate_3.2-0.1-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [53 53 54]
Adapter prompts. [540, 34560, 540, 540, 1080, 540, 540, 540, 34560, 540, 1080, 34560, 1080, 540, 1080, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 540, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 540, 1080, 1080, 1080, 34560, 540, 540, 34560, 540, 34560, 540, 540, 1080, 540, 1080, 34560, 540, 540, 1080, 540, 540, 540, 540, 540, 34560, 1080, 1080, 34560, 1080, 540, 34560, 34560, 34560, 1080, 1080, 540, 540, 540, 34560, 540, 1080, 1080, 540, 34560, 34560, 34560, 540, 540, 34560, 1080, 34560, 34560, 540, 34560, 540, 1080, 540, 540, 1080, 1080, 34560, 34560, 34560, 540, 34560, 1080, 1080, 540, 540, 540, 540, 34560, 1080, 34560, 1080, 34560, 34560, 34560, 540, 1080, 1080, 34560, 1080, 34560, 540, 540, 540, 1080, 1080, 1080, 34560, 34560, 1080, 34560, 540, 1080, 1080, 540, 34560, 34560, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 34560, 540, 34560, 540, 34560, 1080, 540, 1080, 540, 540, 1080, 1080, 1080, 34560, 1080, 540, 540]
Prompts retrieved: 1952100 . Total input tokens: 435376779 . Total output tokens: 383506976
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 5.0131172887049615,
    "estimated_duration": 3600.0516471481556,
    "input_throughput": 4598.4737505402545,
    "output_throughput": 4038.2528988206236,
    "total_throughput": 8636.726649360879,
    "itl": 85.66083901799134,
    "ttft": 2152100.0219690856,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1683,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.466814151531848,
    "arrivals": 650482,
    "finished_requests": 67352,
    "scheduler_time": 114.6300585552206
}
#Debug simulation 
Total elapsed time: 5.013222988694906. Arrivals time: 0.21486574411392212 Scheduler time: 4.606805338989943 Scheduler overhead time: 0.05840133083984256 Adapter cache time: 0.04515882208943367 Engine time: 0.06017681956291199 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.05_size_16-16-16/adapters_160_slots_96_rate_3.2-0.1-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.05_size_16-16-16/adapters_160_slots_96_rate_3.2-0.1-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [53 53 54]
Adapter prompts. [540, 34560, 540, 540, 1080, 540, 540, 540, 34560, 540, 1080, 34560, 1080, 540, 1080, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 540, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 540, 1080, 1080, 1080, 34560, 540, 540, 34560, 540, 34560, 540, 540, 1080, 540, 1080, 34560, 540, 540, 1080, 540, 540, 540, 540, 540, 34560, 1080, 1080, 34560, 1080, 540, 34560, 34560, 34560, 1080, 1080, 540, 540, 540, 34560, 540, 1080, 1080, 540, 34560, 34560, 34560, 540, 540, 34560, 1080, 34560, 34560, 540, 34560, 540, 1080, 540, 540, 1080, 1080, 34560, 34560, 34560, 540, 34560, 1080, 1080, 540, 540, 540, 540, 34560, 1080, 34560, 1080, 34560, 34560, 34560, 540, 1080, 1080, 34560, 1080, 34560, 540, 540, 540, 1080, 1080, 1080, 34560, 34560, 1080, 34560, 540, 1080, 1080, 540, 34560, 34560, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 34560, 540, 34560, 540, 34560, 1080, 540, 1080, 540, 540, 1080, 1080, 1080, 34560, 1080, 540, 540]
Prompts retrieved: 1952100 . Total input tokens: 435376779 . Total output tokens: 383506976
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.399372207932174,
    "estimated_duration": 3600.110143950103,
    "input_throughput": 5006.022393588685,
    "output_throughput": 4405.584930964775,
    "total_throughput": 9411.607324553459,
    "itl": 110.06346371756489,
    "ttft": 2101437.6666345596,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1837,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.727262767828526,
    "arrivals": 650482,
    "finished_requests": 73406,
    "scheduler_time": 107.69667187037668
}
#Debug simulation 
Total elapsed time: 5.3994658761657774. Arrivals time: 0.22988884523510933 Scheduler time: 5.007695491425693 Scheduler overhead time: 0.048243917524814606 Adapter cache time: 0.04174143774434924 Engine time: 0.04929286893457174 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.05_size_16-16-32/adapters_160_slots_96_rate_3.2-0.1-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.05_size_16-16-32/adapters_160_slots_96_rate_3.2-0.1-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [53 53 54]
Adapter prompts. [540, 34560, 540, 540, 1080, 540, 540, 540, 34560, 540, 1080, 34560, 1080, 540, 1080, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 540, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 540, 1080, 1080, 1080, 34560, 540, 540, 34560, 540, 34560, 540, 540, 1080, 540, 1080, 34560, 540, 540, 1080, 540, 540, 540, 540, 540, 34560, 1080, 1080, 34560, 1080, 540, 34560, 34560, 34560, 1080, 1080, 540, 540, 540, 34560, 540, 1080, 1080, 540, 34560, 34560, 34560, 540, 540, 34560, 1080, 34560, 34560, 540, 34560, 540, 1080, 540, 540, 1080, 1080, 34560, 34560, 34560, 540, 34560, 1080, 1080, 540, 540, 540, 540, 34560, 1080, 34560, 1080, 34560, 34560, 34560, 540, 1080, 1080, 34560, 1080, 34560, 540, 540, 540, 1080, 1080, 1080, 34560, 34560, 1080, 34560, 540, 1080, 1080, 540, 34560, 34560, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 34560, 540, 34560, 540, 34560, 1080, 540, 1080, 540, 540, 1080, 1080, 1080, 34560, 1080, 540, 540]
Prompts retrieved: 1952100 . Total input tokens: 435376779 . Total output tokens: 383506976
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.010031452868134,
    "estimated_duration": 3600.0309447815157,
    "input_throughput": 4598.50019456005,
    "output_throughput": 4038.2761212299247,
    "total_throughput": 8636.776315789974,
    "itl": 85.65803356221089,
    "ttft": 2152181.2375703026,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1683,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.351449884157459,
    "arrivals": 650482,
    "finished_requests": 67352,
    "scheduler_time": 114.63297282447036
}
#Debug simulation 
Total elapsed time: 5.010124186985195. Arrivals time: 0.2257580552250147 Scheduler time: 4.592292521614581 Scheduler overhead time: 0.05867527658119798 Adapter cache time: 0.04542817873880267 Engine time: 0.06002110242843628 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.025_size_8-8-8/adapters_160_slots_96_rate_3.2-0.1-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.025_size_8-8-8/adapters_160_slots_96_rate_3.2-0.1-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [53 53 54]
Adapter prompts. [270, 34560, 270, 270, 1080, 270, 270, 270, 34560, 270, 1080, 34560, 1080, 270, 1080, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 270, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 270, 1080, 1080, 1080, 34560, 270, 270, 34560, 270, 34560, 270, 270, 1080, 270, 1080, 34560, 270, 270, 1080, 270, 270, 270, 270, 270, 34560, 1080, 1080, 34560, 1080, 270, 34560, 34560, 34560, 1080, 1080, 270, 270, 270, 34560, 270, 1080, 1080, 270, 34560, 34560, 34560, 270, 270, 34560, 1080, 34560, 34560, 270, 34560, 270, 1080, 270, 270, 1080, 1080, 34560, 34560, 34560, 270, 34560, 1080, 1080, 270, 270, 270, 270, 34560, 1080, 34560, 1080, 34560, 34560, 34560, 270, 1080, 1080, 34560, 1080, 34560, 270, 270, 270, 1080, 1080, 1080, 34560, 34560, 1080, 34560, 270, 1080, 1080, 270, 34560, 34560, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 34560, 270, 34560, 270, 34560, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 34560, 1080, 270, 270]
Prompts retrieved: 1937790 . Total input tokens: 432218215 . Total output tokens: 380691861
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.6166608966887,
    "estimated_duration": 3600.065922922577,
    "input_throughput": 5343.221599782268,
    "output_throughput": 4594.69447341999,
    "total_throughput": 9937.916073202257,
    "itl": 119.48678889793251,
    "ttft": 2069026.8190196657,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1487,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.832652230509806,
    "arrivals": 645743,
    "finished_requests": 77443,
    "scheduler_time": 107.02027912727893
}
#Debug simulation 
Total elapsed time: 5.6167533355765045. Arrivals time: 0.3015741119161248 Scheduler time: 5.165171122178435 Scheduler overhead time: 0.04620306892320514 Adapter cache time: 0.03670037304982543 Engine time: 0.045822037383913994 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.025_size_8-8-16/adapters_160_slots_96_rate_3.2-0.1-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.025_size_8-8-16/adapters_160_slots_96_rate_3.2-0.1-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [53 53 54]
Adapter prompts. [270, 34560, 270, 270, 1080, 270, 270, 270, 34560, 270, 1080, 34560, 1080, 270, 1080, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 270, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 270, 1080, 1080, 1080, 34560, 270, 270, 34560, 270, 34560, 270, 270, 1080, 270, 1080, 34560, 270, 270, 1080, 270, 270, 270, 270, 270, 34560, 1080, 1080, 34560, 1080, 270, 34560, 34560, 34560, 1080, 1080, 270, 270, 270, 34560, 270, 1080, 1080, 270, 34560, 34560, 34560, 270, 270, 34560, 1080, 34560, 34560, 270, 34560, 270, 1080, 270, 270, 1080, 1080, 34560, 34560, 34560, 270, 34560, 1080, 1080, 270, 270, 270, 270, 34560, 1080, 34560, 1080, 34560, 34560, 34560, 270, 1080, 1080, 34560, 1080, 34560, 270, 270, 270, 1080, 1080, 1080, 34560, 34560, 1080, 34560, 270, 1080, 1080, 270, 34560, 34560, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 34560, 270, 34560, 270, 34560, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 34560, 1080, 270, 270]
Prompts retrieved: 1937790 . Total input tokens: 432218215 . Total output tokens: 380691861
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.48613593634218,
    "estimated_duration": 3600.005589751894,
    "input_throughput": 5200.336092058744,
    "output_throughput": 4475.562772976254,
    "total_throughput": 9675.898865034998,
    "itl": 107.90075096634521,
    "ttft": 2084335.8515690484,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1437,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.489727874300371,
    "arrivals": 645743,
    "finished_requests": 75381,
    "scheduler_time": 109.51731053257444
}
#Debug simulation 
Total elapsed time: 5.48622660106048. Arrivals time: 0.23355321306735277 Scheduler time: 5.094144204631448 Scheduler overhead time: 0.04857656778767705 Adapter cache time: 0.0374436997808516 Engine time: 0.04949596198275685 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.025_size_8-8-32/adapters_160_slots_96_rate_3.2-0.1-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.025_size_8-8-32/adapters_160_slots_96_rate_3.2-0.1-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [53 53 54]
Adapter prompts. [270, 34560, 270, 270, 1080, 270, 270, 270, 34560, 270, 1080, 34560, 1080, 270, 1080, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 270, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 270, 1080, 1080, 1080, 34560, 270, 270, 34560, 270, 34560, 270, 270, 1080, 270, 1080, 34560, 270, 270, 1080, 270, 270, 270, 270, 270, 34560, 1080, 1080, 34560, 1080, 270, 34560, 34560, 34560, 1080, 1080, 270, 270, 270, 34560, 270, 1080, 1080, 270, 34560, 34560, 34560, 270, 270, 34560, 1080, 34560, 34560, 270, 34560, 270, 1080, 270, 270, 1080, 1080, 34560, 34560, 34560, 270, 34560, 1080, 1080, 270, 270, 270, 270, 34560, 1080, 34560, 1080, 34560, 34560, 34560, 270, 1080, 1080, 34560, 1080, 34560, 270, 270, 270, 1080, 1080, 1080, 34560, 34560, 1080, 34560, 270, 1080, 1080, 270, 34560, 34560, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 34560, 270, 34560, 270, 34560, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 34560, 1080, 270, 270]
Prompts retrieved: 1937790 . Total input tokens: 432218215 . Total output tokens: 380691861
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.101180837955326,
    "estimated_duration": 3600.027555434099,
    "input_throughput": 4744.200908745696,
    "output_throughput": 4081.0362625761695,
    "total_throughput": 8825.237171321865,
    "itl": 84.374136901808,
    "ttft": 2135572.1765751136,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1308,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.809920352739217,
    "arrivals": 645743,
    "finished_requests": 68701,
    "scheduler_time": 116.06684291764654
}
#Debug simulation 
Total elapsed time: 5.101268851663917. Arrivals time: 0.28164862282574177 Scheduler time: 4.630975249223411 Scheduler overhead time: 0.059204922057688236 Adapter cache time: 0.041094614658504725 Engine time: 0.060485292226076126 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.025_size_8-16-16/adapters_160_slots_96_rate_3.2-0.1-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.025_size_8-16-16/adapters_160_slots_96_rate_3.2-0.1-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [53 53 54]
Adapter prompts. [270, 34560, 270, 270, 1080, 270, 270, 270, 34560, 270, 1080, 34560, 1080, 270, 1080, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 270, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 270, 1080, 1080, 1080, 34560, 270, 270, 34560, 270, 34560, 270, 270, 1080, 270, 1080, 34560, 270, 270, 1080, 270, 270, 270, 270, 270, 34560, 1080, 1080, 34560, 1080, 270, 34560, 34560, 34560, 1080, 1080, 270, 270, 270, 34560, 270, 1080, 1080, 270, 34560, 34560, 34560, 270, 270, 34560, 1080, 34560, 34560, 270, 34560, 270, 1080, 270, 270, 1080, 1080, 34560, 34560, 34560, 270, 34560, 1080, 1080, 270, 270, 270, 270, 34560, 1080, 34560, 1080, 34560, 34560, 34560, 270, 1080, 1080, 34560, 1080, 34560, 270, 270, 270, 1080, 1080, 1080, 34560, 34560, 1080, 34560, 270, 1080, 1080, 270, 34560, 34560, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 34560, 270, 34560, 270, 34560, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 34560, 1080, 270, 270]
Prompts retrieved: 1937790 . Total input tokens: 432218215 . Total output tokens: 380691861
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 5.531964139081538,
    "estimated_duration": 3600.0863989772074,
    "input_throughput": 5201.346835820356,
    "output_throughput": 4476.54978629918,
    "total_throughput": 9677.896622119537,
    "itl": 107.8814948965734,
    "ttft": 2084219.8021359667,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1437,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.849758005603276,
    "arrivals": 645743,
    "finished_requests": 75402,
    "scheduler_time": 109.53830127318284
}
#Debug simulation 
Total elapsed time: 5.53206509212032. Arrivals time: 0.2952543953433633 Scheduler time: 5.076621618587524 Scheduler overhead time: 0.04925148421898484 Adapter cache time: 0.03762023476883769 Engine time: 0.05017084022983909 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.025_size_8-16-32/adapters_160_slots_96_rate_3.2-0.1-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.025_size_8-16-32/adapters_160_slots_96_rate_3.2-0.1-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [53 53 54]
Adapter prompts. [270, 34560, 270, 270, 1080, 270, 270, 270, 34560, 270, 1080, 34560, 1080, 270, 1080, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 270, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 270, 1080, 1080, 1080, 34560, 270, 270, 34560, 270, 34560, 270, 270, 1080, 270, 1080, 34560, 270, 270, 1080, 270, 270, 270, 270, 270, 34560, 1080, 1080, 34560, 1080, 270, 34560, 34560, 34560, 1080, 1080, 270, 270, 270, 34560, 270, 1080, 1080, 270, 34560, 34560, 34560, 270, 270, 34560, 1080, 34560, 34560, 270, 34560, 270, 1080, 270, 270, 1080, 1080, 34560, 34560, 34560, 270, 34560, 1080, 1080, 270, 270, 270, 270, 34560, 1080, 34560, 1080, 34560, 34560, 34560, 270, 1080, 1080, 34560, 1080, 34560, 270, 270, 270, 1080, 1080, 1080, 34560, 34560, 1080, 34560, 270, 1080, 1080, 270, 34560, 34560, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 34560, 270, 34560, 270, 34560, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 34560, 1080, 270, 270]
Prompts retrieved: 1937790 . Total input tokens: 432218215 . Total output tokens: 380691861
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 5.114170155022293,
    "estimated_duration": 3600.030929233433,
    "input_throughput": 4744.457015994844,
    "output_throughput": 4081.0991040925405,
    "total_throughput": 8825.556120087385,
    "itl": 84.37210153268464,
    "ttft": 2135596.6405105167,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1308,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.721481318324743,
    "arrivals": 645743,
    "finished_requests": 68702,
    "scheduler_time": 116.06970201816817
}
#Debug simulation 
Total elapsed time: 5.114256182685494. Arrivals time: 0.2815158786252141 Scheduler time: 4.643372284248471 Scheduler overhead time: 0.059368351474404335 Adapter cache time: 0.04109022533521056 Engine time: 0.06072588777169585 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.025_size_16-16-16/adapters_160_slots_96_rate_3.2-0.1-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.025_size_16-16-16/adapters_160_slots_96_rate_3.2-0.1-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [53 53 54]
Adapter prompts. [270, 34560, 270, 270, 1080, 270, 270, 270, 34560, 270, 1080, 34560, 1080, 270, 1080, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 270, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 270, 1080, 1080, 1080, 34560, 270, 270, 34560, 270, 34560, 270, 270, 1080, 270, 1080, 34560, 270, 270, 1080, 270, 270, 270, 270, 270, 34560, 1080, 1080, 34560, 1080, 270, 34560, 34560, 34560, 1080, 1080, 270, 270, 270, 34560, 270, 1080, 1080, 270, 34560, 34560, 34560, 270, 270, 34560, 1080, 34560, 34560, 270, 34560, 270, 1080, 270, 270, 1080, 1080, 34560, 34560, 34560, 270, 34560, 1080, 1080, 270, 270, 270, 270, 34560, 1080, 34560, 1080, 34560, 34560, 34560, 270, 1080, 1080, 34560, 1080, 34560, 270, 270, 270, 1080, 1080, 1080, 34560, 34560, 1080, 34560, 270, 1080, 1080, 270, 34560, 34560, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 34560, 270, 34560, 270, 34560, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 34560, 1080, 270, 270]
Prompts retrieved: 1937790 . Total input tokens: 432218215 . Total output tokens: 380691861
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.56557341106236,
    "estimated_duration": 3600.022676889053,
    "input_throughput": 5202.713060736985,
    "output_throughput": 4477.656239079513,
    "total_throughput": 9680.369299816499,
    "itl": 107.85899780176884,
    "ttft": 2084258.1454759748,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1438,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.180078312540543,
    "arrivals": 645743,
    "finished_requests": 75421,
    "scheduler_time": 109.55576193639682
}
#Debug simulation 
Total elapsed time: 5.565664998721331. Arrivals time: 0.30318283708766103 Scheduler time: 5.102754888124764 Scheduler overhead time: 0.0490593402646482 Adapter cache time: 0.037607119884341955 Engine time: 0.04998480714857578 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.025_size_16-16-32/adapters_160_slots_96_rate_3.2-0.1-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.025_size_16-16-32/adapters_160_slots_96_rate_3.2-0.1-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [53 53 54]
Adapter prompts. [270, 34560, 270, 270, 1080, 270, 270, 270, 34560, 270, 1080, 34560, 1080, 270, 1080, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 270, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 270, 1080, 1080, 1080, 34560, 270, 270, 34560, 270, 34560, 270, 270, 1080, 270, 1080, 34560, 270, 270, 1080, 270, 270, 270, 270, 270, 34560, 1080, 1080, 34560, 1080, 270, 34560, 34560, 34560, 1080, 1080, 270, 270, 270, 34560, 270, 1080, 1080, 270, 34560, 34560, 34560, 270, 270, 34560, 1080, 34560, 34560, 270, 34560, 270, 1080, 270, 270, 1080, 1080, 34560, 34560, 34560, 270, 34560, 1080, 1080, 270, 270, 270, 270, 34560, 1080, 34560, 1080, 34560, 34560, 34560, 270, 1080, 1080, 34560, 1080, 34560, 270, 270, 270, 1080, 1080, 1080, 34560, 34560, 1080, 34560, 270, 1080, 1080, 270, 34560, 34560, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 34560, 270, 34560, 270, 34560, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 34560, 1080, 270, 270]
Prompts retrieved: 1937790 . Total input tokens: 432218215 . Total output tokens: 380691861
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.145868458785117,
    "estimated_duration": 3600.032069239544,
    "input_throughput": 4744.608012230309,
    "output_throughput": 4081.2125329493474,
    "total_throughput": 8825.820545179657,
    "itl": 84.36901881435182,
    "ttft": 2135651.396102576,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1308,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.630349760614276,
    "arrivals": 645743,
    "finished_requests": 68707,
    "scheduler_time": 116.07258711197005
}
#Debug simulation 
Total elapsed time: 5.145960316993296. Arrivals time: 0.22308155335485935 Scheduler time: 4.732436517719179 Scheduler overhead time: 0.05969390692189336 Adapter cache time: 0.04120052419602871 Engine time: 0.061379287391901016 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-8/adapters_160_slots_96_rate_3.2-0.1-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-8/adapters_160_slots_96_rate_3.2-0.1-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [53 53 54]
Adapter prompts. [135, 34560, 135, 135, 1080, 135, 135, 135, 34560, 135, 1080, 34560, 1080, 135, 1080, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 135, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 135, 1080, 1080, 1080, 34560, 135, 135, 34560, 135, 34560, 135, 135, 1080, 135, 1080, 34560, 135, 135, 1080, 135, 135, 135, 135, 135, 34560, 1080, 1080, 34560, 1080, 135, 34560, 34560, 34560, 1080, 1080, 135, 135, 135, 34560, 135, 1080, 1080, 135, 34560, 34560, 34560, 135, 135, 34560, 1080, 34560, 34560, 135, 34560, 135, 1080, 135, 135, 1080, 1080, 34560, 34560, 34560, 135, 34560, 1080, 1080, 135, 135, 135, 135, 34560, 1080, 34560, 1080, 34560, 34560, 34560, 135, 1080, 1080, 34560, 1080, 34560, 135, 135, 135, 1080, 1080, 1080, 34560, 34560, 1080, 34560, 135, 1080, 1080, 135, 34560, 34560, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 34560, 135, 34560, 135, 34560, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 34560, 1080, 135, 135]
Prompts retrieved: 1930635 . Total input tokens: 430645999 . Total output tokens: 379281691
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.597719295881689,
    "estimated_duration": 3600.0523632048653,
    "input_throughput": 5339.332059850419,
    "output_throughput": 4639.108355949657,
    "total_throughput": 9978.440415800076,
    "itl": 118.52455037606799,
    "ttft": 2071317.1898456311,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1116,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.3794484796563005,
    "arrivals": 643390,
    "finished_requests": 77831,
    "scheduler_time": 107.99377730781211
}
#Debug simulation 
Total elapsed time: 5.597806720994413. Arrivals time: 0.24037170503288507 Scheduler time: 5.211041843984276 Scheduler overhead time: 0.04534190474078059 Adapter cache time: 0.03358565689995885 Engine time: 0.04606082942336798 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-16/adapters_160_slots_96_rate_3.2-0.1-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-16/adapters_160_slots_96_rate_3.2-0.1-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [53 53 54]
Adapter prompts. [135, 34560, 135, 135, 1080, 135, 135, 135, 34560, 135, 1080, 34560, 1080, 135, 1080, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 135, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 135, 1080, 1080, 1080, 34560, 135, 135, 34560, 135, 34560, 135, 135, 1080, 135, 1080, 34560, 135, 135, 1080, 135, 135, 135, 135, 135, 34560, 1080, 1080, 34560, 1080, 135, 34560, 34560, 34560, 1080, 1080, 135, 135, 135, 34560, 135, 1080, 1080, 135, 34560, 34560, 34560, 135, 135, 34560, 1080, 34560, 34560, 135, 34560, 135, 1080, 135, 135, 1080, 1080, 34560, 34560, 34560, 135, 34560, 1080, 1080, 135, 135, 135, 135, 34560, 1080, 34560, 1080, 34560, 34560, 34560, 135, 1080, 1080, 34560, 1080, 34560, 135, 135, 135, 1080, 1080, 1080, 34560, 34560, 1080, 34560, 135, 1080, 1080, 135, 34560, 34560, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 34560, 135, 34560, 135, 34560, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 34560, 1080, 135, 135]
Prompts retrieved: 1930635 . Total input tokens: 430645999 . Total output tokens: 379281691
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.5605481481179595,
    "estimated_duration": 3600.0123513692643,
    "input_throughput": 5200.948544767778,
    "output_throughput": 4513.046182694469,
    "total_throughput": 9713.994727462246,
    "itl": 107.0357741711111,
    "ttft": 2088934.2427643747,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1097,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.019339024270897,
    "arrivals": 643390,
    "finished_requests": 75746,
    "scheduler_time": 110.42971497693271
}
#Debug simulation 
Total elapsed time: 5.560639223083854. Arrivals time: 0.2703510639257729 Scheduler time: 5.133043386507779 Scheduler overhead time: 0.04909445159137249 Adapter cache time: 0.03462842106819153 Engine time: 0.050208928529173136 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-32/adapters_160_slots_96_rate_3.2-0.1-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-32/adapters_160_slots_96_rate_3.2-0.1-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [53 53 54]
Adapter prompts. [135, 34560, 135, 135, 1080, 135, 135, 135, 34560, 135, 1080, 34560, 1080, 135, 1080, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 135, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 135, 1080, 1080, 1080, 34560, 135, 135, 34560, 135, 34560, 135, 135, 1080, 135, 1080, 34560, 135, 135, 1080, 135, 135, 135, 135, 135, 34560, 1080, 1080, 34560, 1080, 135, 34560, 34560, 34560, 1080, 1080, 135, 135, 135, 34560, 135, 1080, 1080, 135, 34560, 34560, 34560, 135, 135, 34560, 1080, 34560, 34560, 135, 34560, 135, 1080, 135, 135, 1080, 1080, 34560, 34560, 34560, 135, 34560, 1080, 1080, 135, 135, 135, 135, 34560, 1080, 34560, 1080, 34560, 34560, 34560, 135, 1080, 1080, 34560, 1080, 34560, 135, 135, 135, 1080, 1080, 1080, 34560, 34560, 1080, 34560, 135, 1080, 1080, 135, 34560, 34560, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 34560, 135, 34560, 135, 34560, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 34560, 1080, 135, 135]
Prompts retrieved: 1930635 . Total input tokens: 430645999 . Total output tokens: 379281691
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.054045580327511,
    "estimated_duration": 3600.0624193422377,
    "input_throughput": 4726.601657953747,
    "output_throughput": 4108.439598306291,
    "total_throughput": 8835.04125626004,
    "itl": 84.0125953303467,
    "ttft": 2140773.0492758756,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1000,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.513876069844717,
    "arrivals": 643390,
    "finished_requests": 68810,
    "scheduler_time": 116.68003113897548
}
#Debug simulation 
Total elapsed time: 5.054132380988449. Arrivals time: 0.2198113314807415 Scheduler time: 4.648066298570484 Scheduler overhead time: 0.059227332938462496 Adapter cache time: 0.0379870580509305 Engine time: 0.060925908386707306 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.0125_size_8-16-16/adapters_160_slots_96_rate_3.2-0.1-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.0125_size_8-16-16/adapters_160_slots_96_rate_3.2-0.1-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [53 53 54]
Adapter prompts. [135, 34560, 135, 135, 1080, 135, 135, 135, 34560, 135, 1080, 34560, 1080, 135, 1080, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 135, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 135, 1080, 1080, 1080, 34560, 135, 135, 34560, 135, 34560, 135, 135, 1080, 135, 1080, 34560, 135, 135, 1080, 135, 135, 135, 135, 135, 34560, 1080, 1080, 34560, 1080, 135, 34560, 34560, 34560, 1080, 1080, 135, 135, 135, 34560, 135, 1080, 1080, 135, 34560, 34560, 34560, 135, 135, 34560, 1080, 34560, 34560, 135, 34560, 135, 1080, 135, 135, 1080, 1080, 34560, 34560, 34560, 135, 34560, 1080, 1080, 135, 135, 135, 135, 34560, 1080, 34560, 1080, 34560, 34560, 34560, 135, 1080, 1080, 34560, 1080, 34560, 135, 135, 135, 1080, 1080, 1080, 34560, 34560, 1080, 34560, 135, 1080, 1080, 135, 34560, 34560, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 34560, 135, 34560, 135, 34560, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 34560, 1080, 135, 135]
Prompts retrieved: 1930635 . Total input tokens: 430645999 . Total output tokens: 379281691
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 5.488734446000308,
    "estimated_duration": 3600.0880557023816,
    "input_throughput": 5202.076924295164,
    "output_throughput": 4513.828758788393,
    "total_throughput": 9715.905683083556,
    "itl": 107.0205294850579,
    "ttft": 2088988.7864369466,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1095,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.510976294917043,
    "arrivals": 643390,
    "finished_requests": 75761,
    "scheduler_time": 110.44698354134286
}
#Debug simulation 
Total elapsed time: 5.488829032052308. Arrivals time: 0.24492817046120763 Scheduler time: 5.087165844161063 Scheduler overhead time: 0.04897973220795393 Adapter cache time: 0.03451706236228347 Engine time: 0.050158733036369085 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.0125_size_8-16-32/adapters_160_slots_96_rate_3.2-0.1-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.0125_size_8-16-32/adapters_160_slots_96_rate_3.2-0.1-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [53 53 54]
Adapter prompts. [135, 34560, 135, 135, 1080, 135, 135, 135, 34560, 135, 1080, 34560, 1080, 135, 1080, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 135, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 135, 1080, 1080, 1080, 34560, 135, 135, 34560, 135, 34560, 135, 135, 1080, 135, 1080, 34560, 135, 135, 1080, 135, 135, 135, 135, 135, 34560, 1080, 1080, 34560, 1080, 135, 34560, 34560, 34560, 1080, 1080, 135, 135, 135, 34560, 135, 1080, 1080, 135, 34560, 34560, 34560, 135, 135, 34560, 1080, 34560, 34560, 135, 34560, 135, 1080, 135, 135, 1080, 1080, 34560, 34560, 34560, 135, 34560, 1080, 1080, 135, 135, 135, 135, 34560, 1080, 34560, 1080, 34560, 34560, 34560, 135, 1080, 1080, 34560, 1080, 34560, 135, 135, 135, 1080, 1080, 1080, 34560, 34560, 1080, 34560, 135, 1080, 1080, 135, 34560, 34560, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 34560, 135, 34560, 135, 34560, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 34560, 1080, 135, 135]
Prompts retrieved: 1930635 . Total input tokens: 430645999 . Total output tokens: 379281691
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 5.073780389036983,
    "estimated_duration": 3600.088615613229,
    "input_throughput": 4726.811425196372,
    "output_throughput": 4108.431646891722,
    "total_throughput": 8835.243072088093,
    "itl": 84.01054388310664,
    "ttft": 2140801.173637182,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1000,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.446770104621555,
    "arrivals": 643390,
    "finished_requests": 68812,
    "scheduler_time": 116.68293718598852
}
#Debug simulation 
Total elapsed time: 5.073925659060478. Arrivals time: 0.21870464365929365 Scheduler time: 4.66851328779012 Scheduler overhead time: 0.05944370897486806 Adapter cache time: 0.03792159678414464 Engine time: 0.061048796866089106 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.0125_size_16-16-16/adapters_160_slots_96_rate_3.2-0.1-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.0125_size_16-16-16/adapters_160_slots_96_rate_3.2-0.1-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [53 53 54]
Adapter prompts. [135, 34560, 135, 135, 1080, 135, 135, 135, 34560, 135, 1080, 34560, 1080, 135, 1080, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 135, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 135, 1080, 1080, 1080, 34560, 135, 135, 34560, 135, 34560, 135, 135, 1080, 135, 1080, 34560, 135, 135, 1080, 135, 135, 135, 135, 135, 34560, 1080, 1080, 34560, 1080, 135, 34560, 34560, 34560, 1080, 1080, 135, 135, 135, 34560, 135, 1080, 1080, 135, 34560, 34560, 34560, 135, 135, 34560, 1080, 34560, 34560, 135, 34560, 135, 1080, 135, 135, 1080, 1080, 34560, 34560, 34560, 135, 34560, 1080, 1080, 135, 135, 135, 135, 34560, 1080, 34560, 1080, 34560, 34560, 34560, 135, 1080, 1080, 34560, 1080, 34560, 135, 135, 135, 1080, 1080, 1080, 34560, 34560, 1080, 34560, 135, 1080, 1080, 135, 34560, 34560, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 34560, 135, 34560, 135, 34560, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 34560, 1080, 135, 135]
Prompts retrieved: 1930635 . Total input tokens: 430645999 . Total output tokens: 379281691
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.557529747951776,
    "estimated_duration": 3600.0332003912754,
    "input_throughput": 5203.538955686293,
    "output_throughput": 4514.456977294988,
    "total_throughput": 9717.995932981281,
    "itl": 107.00276353857375,
    "ttft": 2089046.8797298896,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1096,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.996777350865269,
    "arrivals": 643390,
    "finished_requests": 75776,
    "scheduler_time": 110.46140573523648
}
#Debug simulation 
Total elapsed time: 5.557622223161161. Arrivals time: 0.2706335731782019 Scheduler time: 5.127061349339783 Scheduler overhead time: 0.04932035878300667 Adapter cache time: 0.03458437090739608 Engine time: 0.052680689841508865 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.0125_size_16-16-32/adapters_160_slots_96_rate_3.2-0.1-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.0125_size_16-16-32/adapters_160_slots_96_rate_3.2-0.1-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [53 53 54]
Adapter prompts. [135, 34560, 135, 135, 1080, 135, 135, 135, 34560, 135, 1080, 34560, 1080, 135, 1080, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 135, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 135, 1080, 1080, 1080, 34560, 135, 135, 34560, 135, 34560, 135, 135, 1080, 135, 1080, 34560, 135, 135, 1080, 135, 135, 135, 135, 135, 34560, 1080, 1080, 34560, 1080, 135, 34560, 34560, 34560, 1080, 1080, 135, 135, 135, 34560, 135, 1080, 1080, 135, 34560, 34560, 34560, 135, 135, 34560, 1080, 34560, 34560, 135, 34560, 135, 1080, 135, 135, 1080, 1080, 34560, 34560, 34560, 135, 34560, 1080, 1080, 135, 135, 135, 135, 34560, 1080, 34560, 1080, 34560, 34560, 34560, 135, 1080, 1080, 34560, 1080, 34560, 135, 135, 135, 1080, 1080, 1080, 34560, 34560, 1080, 34560, 135, 1080, 1080, 135, 34560, 34560, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 34560, 135, 34560, 135, 34560, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 34560, 1080, 135, 135]
Prompts retrieved: 1930635 . Total input tokens: 430645999 . Total output tokens: 379281691
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.0484662633389235,
    "estimated_duration": 3600.0893303905145,
    "input_throughput": 4726.699656131631,
    "output_throughput": 4108.670547459861,
    "total_throughput": 8835.370203591492,
    "itl": 84.00628555959933,
    "ttft": 2140796.9882724592,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 997,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.354296954181064,
    "arrivals": 643390,
    "finished_requests": 68814,
    "scheduler_time": 116.68868211518182
}
#Debug simulation 
Total elapsed time: 5.048557531088591. Arrivals time: 0.21756787737831473 Scheduler time: 4.6431770459748805 Scheduler overhead time: 0.05912554217502475 Adapter cache time: 0.03962515899911523 Engine time: 0.06089886091649532 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-8/adapters_160_slots_96_rate_3.2-0.1-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-8/adapters_160_slots_96_rate_3.2-0.1-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [53 53 54]
Adapter prompts. [66, 34560, 66, 66, 1080, 66, 66, 66, 34560, 66, 1080, 34560, 1080, 66, 1080, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 66, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 66, 1080, 1080, 1080, 34560, 66, 66, 34560, 66, 34560, 66, 66, 1080, 66, 1080, 34560, 66, 66, 1080, 66, 66, 66, 66, 66, 34560, 1080, 1080, 34560, 1080, 66, 34560, 34560, 34560, 1080, 1080, 66, 66, 66, 34560, 66, 1080, 1080, 66, 34560, 34560, 34560, 66, 66, 34560, 1080, 34560, 34560, 66, 34560, 66, 1080, 66, 66, 1080, 1080, 34560, 34560, 34560, 66, 34560, 1080, 1080, 66, 66, 66, 66, 34560, 1080, 34560, 1080, 34560, 34560, 34560, 66, 1080, 1080, 34560, 1080, 34560, 66, 66, 66, 1080, 1080, 1080, 34560, 34560, 1080, 34560, 66, 1080, 1080, 66, 34560, 34560, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 34560, 66, 34560, 66, 34560, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 34560, 1080, 66, 66]
Prompts retrieved: 1926978 . Total input tokens: 429837677 . Total output tokens: 378550917
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.723040891811252,
    "estimated_duration": 3600.0231087464804,
    "input_throughput": 5364.337788021673,
    "output_throughput": 4671.65473442086,
    "total_throughput": 10035.992522442533,
    "itl": 117.53812633041002,
    "ttft": 2068416.3391726778,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 866,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.726346221668763,
    "arrivals": 642182,
    "finished_requests": 77982,
    "scheduler_time": 108.84404171290248
}
#Debug simulation 
Total elapsed time: 5.7231289790943265. Arrivals time: 0.29912144457921386 Scheduler time: 5.280201968736947 Scheduler overhead time: 0.045437340158969164 Adapter cache time: 0.030176949221640825 Engine time: 0.04681332828477025 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-16/adapters_160_slots_96_rate_3.2-0.1-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-16/adapters_160_slots_96_rate_3.2-0.1-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [53 53 54]
Adapter prompts. [66, 34560, 66, 66, 1080, 66, 66, 66, 34560, 66, 1080, 34560, 1080, 66, 1080, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 66, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 66, 1080, 1080, 1080, 34560, 66, 66, 34560, 66, 34560, 66, 66, 1080, 66, 1080, 34560, 66, 66, 1080, 66, 66, 66, 66, 66, 34560, 1080, 1080, 34560, 1080, 66, 34560, 34560, 34560, 1080, 1080, 66, 66, 66, 34560, 66, 1080, 1080, 66, 34560, 34560, 34560, 66, 66, 34560, 1080, 34560, 34560, 66, 34560, 66, 1080, 66, 66, 1080, 1080, 34560, 34560, 34560, 66, 34560, 1080, 1080, 66, 66, 66, 66, 34560, 1080, 34560, 1080, 34560, 34560, 34560, 66, 1080, 1080, 34560, 1080, 34560, 66, 66, 66, 1080, 1080, 1080, 34560, 34560, 1080, 34560, 66, 1080, 1080, 66, 34560, 34560, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 34560, 66, 34560, 66, 34560, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 34560, 1080, 66, 66]
Prompts retrieved: 1926978 . Total input tokens: 429837677 . Total output tokens: 378550917
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.581651953049004,
    "estimated_duration": 3600.01920014189,
    "input_throughput": 5208.098889933982,
    "output_throughput": 4539.906898095386,
    "total_throughput": 9748.005788029368,
    "itl": 106.32069647802753,
    "ttft": 2084296.5384177142,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 843,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.160437318929479,
    "arrivals": 642182,
    "finished_requests": 75699,
    "scheduler_time": 111.17585011233125
}
#Debug simulation 
Total elapsed time: 5.581745814997703. Arrivals time: 0.2975416802801192 Scheduler time: 5.1280978112481534 Scheduler overhead time: 0.049802436493337154 Adapter cache time: 0.032164032105356455 Engine time: 0.05075374897569418 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-32/adapters_160_slots_96_rate_3.2-0.1-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-32/adapters_160_slots_96_rate_3.2-0.1-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [53 53 54]
Adapter prompts. [66, 34560, 66, 66, 1080, 66, 66, 66, 34560, 66, 1080, 34560, 1080, 66, 1080, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 66, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 66, 1080, 1080, 1080, 34560, 66, 66, 34560, 66, 34560, 66, 66, 1080, 66, 1080, 34560, 66, 66, 1080, 66, 66, 66, 66, 66, 34560, 1080, 1080, 34560, 1080, 66, 34560, 34560, 34560, 1080, 1080, 66, 66, 66, 34560, 66, 1080, 1080, 66, 34560, 34560, 34560, 66, 66, 34560, 1080, 34560, 34560, 66, 34560, 66, 1080, 66, 66, 1080, 1080, 34560, 34560, 34560, 66, 34560, 1080, 1080, 66, 66, 66, 66, 34560, 1080, 34560, 1080, 34560, 34560, 34560, 66, 1080, 1080, 34560, 1080, 34560, 66, 66, 66, 1080, 1080, 1080, 34560, 34560, 1080, 34560, 66, 1080, 1080, 66, 34560, 34560, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 34560, 66, 34560, 66, 34560, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 34560, 1080, 66, 66]
Prompts retrieved: 1926978 . Total input tokens: 429837677 . Total output tokens: 378550917
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.44340989086777,
    "estimated_duration": 3600.026746578942,
    "input_throughput": 4699.1984201440255,
    "output_throughput": 4102.133133881195,
    "total_throughput": 8801.33155402522,
    "itl": 83.71620856828055,
    "ttft": 2138290.092706236,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 780,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.851629956075947,
    "arrivals": 642182,
    "finished_requests": 68273,
    "scheduler_time": 116.8760551559932
}
#Debug simulation 
Total elapsed time: 5.4434679937548935. Arrivals time: 0.6023545465432107 Scheduler time: 4.656632459256798 Scheduler overhead time: 0.059353782795369625 Adapter cache time: 0.0354751730337739 Engine time: 0.061575404834002256 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.00625_size_8-16-16/adapters_160_slots_96_rate_3.2-0.1-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.00625_size_8-16-16/adapters_160_slots_96_rate_3.2-0.1-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [53 53 54]
Adapter prompts. [66, 34560, 66, 66, 1080, 66, 66, 66, 34560, 66, 1080, 34560, 1080, 66, 1080, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 66, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 66, 1080, 1080, 1080, 34560, 66, 66, 34560, 66, 34560, 66, 66, 1080, 66, 1080, 34560, 66, 66, 1080, 66, 66, 66, 66, 66, 34560, 1080, 1080, 34560, 1080, 66, 34560, 34560, 34560, 1080, 1080, 66, 66, 66, 34560, 66, 1080, 1080, 66, 34560, 34560, 34560, 66, 66, 34560, 1080, 34560, 34560, 66, 34560, 66, 1080, 66, 66, 1080, 1080, 34560, 34560, 34560, 66, 34560, 1080, 1080, 66, 66, 66, 66, 34560, 1080, 34560, 1080, 34560, 34560, 34560, 66, 1080, 1080, 34560, 1080, 34560, 66, 66, 66, 1080, 1080, 1080, 34560, 34560, 1080, 34560, 66, 1080, 1080, 66, 34560, 34560, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 34560, 66, 34560, 66, 34560, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 34560, 1080, 66, 66]
Prompts retrieved: 1926978 . Total input tokens: 429837677 . Total output tokens: 378550917
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 5.599507508333772,
    "estimated_duration": 3600.0358797642166,
    "input_throughput": 5208.596143555131,
    "output_throughput": 4540.07058426053,
    "total_throughput": 9748.666727815662,
    "itl": 106.31069211297306,
    "ttft": 2084377.2138419081,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 845,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.798385498016133,
    "arrivals": 642182,
    "finished_requests": 75705,
    "scheduler_time": 111.18577929539454
}
#Debug simulation 
Total elapsed time: 5.599627283401787. Arrivals time: 0.3152480451390147 Scheduler time: 5.128456262405962 Scheduler overhead time: 0.04951707134023309 Adapter cache time: 0.03228542348369956 Engine time: 0.05079216556623578 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.00625_size_8-16-32/adapters_160_slots_96_rate_3.2-0.1-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.00625_size_8-16-32/adapters_160_slots_96_rate_3.2-0.1-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [53 53 54]
Adapter prompts. [66, 34560, 66, 66, 1080, 66, 66, 66, 34560, 66, 1080, 34560, 1080, 66, 1080, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 66, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 66, 1080, 1080, 1080, 34560, 66, 66, 34560, 66, 34560, 66, 66, 1080, 66, 1080, 34560, 66, 66, 1080, 66, 66, 66, 66, 66, 34560, 1080, 1080, 34560, 1080, 66, 34560, 34560, 34560, 1080, 1080, 66, 66, 66, 34560, 66, 1080, 1080, 66, 34560, 34560, 34560, 66, 66, 34560, 1080, 34560, 34560, 66, 34560, 66, 1080, 66, 66, 1080, 1080, 34560, 34560, 34560, 66, 34560, 1080, 1080, 66, 66, 66, 66, 34560, 1080, 34560, 1080, 34560, 34560, 34560, 66, 1080, 1080, 34560, 1080, 34560, 66, 66, 66, 1080, 1080, 1080, 34560, 34560, 1080, 34560, 66, 1080, 1080, 66, 34560, 34560, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 34560, 66, 34560, 66, 34560, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 34560, 1080, 66, 66]
Prompts retrieved: 1926978 . Total input tokens: 429837677 . Total output tokens: 378550917
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 5.178298129234463,
    "estimated_duration": 3600.068521632741,
    "input_throughput": 4699.287499207732,
    "output_throughput": 4102.105532508676,
    "total_throughput": 8801.393031716409,
    "itl": 83.71509398444199,
    "ttft": 2138280.931394408,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 780,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.799643544745657,
    "arrivals": 642182,
    "finished_requests": 68274,
    "scheduler_time": 116.87902585386712
}
#Debug simulation 
Total elapsed time: 5.17838896298781. Arrivals time: 0.312678228598088 Scheduler time: 4.6798494956456125 Scheduler overhead time: 0.06001994898542762 Adapter cache time: 0.035793352872133255 Engine time: 0.061565603129565716 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.00625_size_16-16-16/adapters_160_slots_96_rate_3.2-0.1-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.00625_size_16-16-16/adapters_160_slots_96_rate_3.2-0.1-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [53 53 54]
Adapter prompts. [66, 34560, 66, 66, 1080, 66, 66, 66, 34560, 66, 1080, 34560, 1080, 66, 1080, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 66, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 66, 1080, 1080, 1080, 34560, 66, 66, 34560, 66, 34560, 66, 66, 1080, 66, 1080, 34560, 66, 66, 1080, 66, 66, 66, 66, 66, 34560, 1080, 1080, 34560, 1080, 66, 34560, 34560, 34560, 1080, 1080, 66, 66, 66, 34560, 66, 1080, 1080, 66, 34560, 34560, 34560, 66, 66, 34560, 1080, 34560, 34560, 66, 34560, 66, 1080, 66, 66, 1080, 1080, 34560, 34560, 34560, 66, 34560, 1080, 1080, 66, 66, 66, 66, 34560, 1080, 34560, 1080, 34560, 34560, 34560, 66, 1080, 1080, 34560, 1080, 34560, 66, 66, 66, 1080, 1080, 1080, 34560, 34560, 1080, 34560, 66, 1080, 1080, 66, 34560, 34560, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 34560, 66, 34560, 66, 34560, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 34560, 1080, 66, 66]
Prompts retrieved: 1926978 . Total input tokens: 429837677 . Total output tokens: 378550917
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.589079337194562,
    "estimated_duration": 3600.0847809559405,
    "input_throughput": 5209.433427570584,
    "output_throughput": 4540.396961334797,
    "total_throughput": 9749.83038890538,
    "itl": 106.29563120995901,
    "ttft": 2084411.3104575085,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 845,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.394413194782074,
    "arrivals": 642182,
    "finished_requests": 75718,
    "scheduler_time": 111.1997152523497
}
#Debug simulation 
Total elapsed time: 5.589197721797973. Arrivals time: 0.29803109215572476 Scheduler time: 5.135186562780291 Scheduler overhead time: 0.04953288799151778 Adapter cache time: 0.03225439274683595 Engine time: 0.050822563003748655 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.00625_size_16-16-32/adapters_160_slots_96_rate_3.2-0.1-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.00625_size_16-16-32/adapters_160_slots_96_rate_3.2-0.1-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [53 53 54]
Adapter prompts. [66, 34560, 66, 66, 1080, 66, 66, 66, 34560, 66, 1080, 34560, 1080, 66, 1080, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 66, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 66, 1080, 1080, 1080, 34560, 66, 66, 34560, 66, 34560, 66, 66, 1080, 66, 1080, 34560, 66, 66, 1080, 66, 66, 66, 66, 66, 34560, 1080, 1080, 34560, 1080, 66, 34560, 34560, 34560, 1080, 1080, 66, 66, 66, 34560, 66, 1080, 1080, 66, 34560, 34560, 34560, 66, 66, 34560, 1080, 34560, 34560, 66, 34560, 66, 1080, 66, 66, 1080, 1080, 34560, 34560, 34560, 66, 34560, 1080, 1080, 66, 66, 66, 66, 34560, 1080, 34560, 1080, 34560, 34560, 34560, 66, 1080, 1080, 34560, 1080, 34560, 66, 66, 66, 1080, 1080, 1080, 34560, 34560, 1080, 34560, 66, 1080, 1080, 66, 34560, 34560, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 34560, 66, 34560, 66, 34560, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 34560, 1080, 66, 66]
Prompts retrieved: 1926978 . Total input tokens: 429837677 . Total output tokens: 378550917
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.156383339315653,
    "estimated_duration": 3600.013083288506,
    "input_throughput": 4699.359865810856,
    "output_throughput": 4102.1687028176,
    "total_throughput": 8801.528568628457,
    "itl": 83.71375358176614,
    "ttft": 2138259.168775458,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 780,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.744343258589533,
    "arrivals": 642182,
    "finished_requests": 68274,
    "scheduler_time": 116.87888779578847
}
#Debug simulation 
Total elapsed time: 5.156499416101724. Arrivals time: 0.27919828658923507 Scheduler time: 4.69315439928323 Scheduler overhead time: 0.0594619270414114 Adapter cache time: 0.03540245397016406 Engine time: 0.06134389992803335 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-8/adapters_160_slots_96_rate_3.2-0.1-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-8/adapters_160_slots_96_rate_3.2-0.1-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [53 53 54]
Adapter prompts. [33, 34560, 33, 33, 1080, 33, 33, 33, 34560, 33, 1080, 34560, 1080, 33, 1080, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 33, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 33, 1080, 1080, 1080, 34560, 33, 33, 34560, 33, 34560, 33, 33, 1080, 33, 1080, 34560, 33, 33, 1080, 33, 33, 33, 33, 33, 34560, 1080, 1080, 34560, 1080, 33, 34560, 34560, 34560, 1080, 1080, 33, 33, 33, 34560, 33, 1080, 1080, 33, 34560, 34560, 34560, 33, 33, 34560, 1080, 34560, 34560, 33, 34560, 33, 1080, 33, 33, 1080, 1080, 34560, 34560, 34560, 33, 34560, 1080, 1080, 33, 33, 33, 33, 34560, 1080, 34560, 1080, 34560, 34560, 34560, 33, 1080, 1080, 34560, 1080, 34560, 33, 33, 33, 1080, 1080, 1080, 34560, 34560, 1080, 34560, 33, 1080, 1080, 33, 34560, 34560, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 34560, 33, 34560, 33, 34560, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 34560, 1080, 33, 33]
Prompts retrieved: 1925229 . Total input tokens: 429435227 . Total output tokens: 378209537
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.683040569070727,
    "estimated_duration": 3600.088650685206,
    "input_throughput": 5403.020005159545,
    "output_throughput": 4694.513007834763,
    "total_throughput": 10097.533012994307,
    "itl": 117.07640213718308,
    "ttft": 2061156.5503343286,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 735,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.860120638483293,
    "arrivals": 641592,
    "finished_requests": 78789,
    "scheduler_time": 109.34473249348962
}
#Debug simulation 
Total elapsed time: 5.683140865992755. Arrivals time: 0.2361909686587751 Scheduler time: 5.301992895547301 Scheduler overhead time: 0.04575129225850105 Adapter cache time: 0.03072684397920966 Engine time: 0.046753444243222475 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-16/adapters_160_slots_96_rate_3.2-0.1-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-16/adapters_160_slots_96_rate_3.2-0.1-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [53 53 54]
Adapter prompts. [33, 34560, 33, 33, 1080, 33, 33, 33, 34560, 33, 1080, 34560, 1080, 33, 1080, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 33, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 33, 1080, 1080, 1080, 34560, 33, 33, 34560, 33, 34560, 33, 33, 1080, 33, 1080, 34560, 33, 33, 1080, 33, 33, 33, 33, 33, 34560, 1080, 1080, 34560, 1080, 33, 34560, 34560, 34560, 1080, 1080, 33, 33, 33, 34560, 33, 1080, 1080, 33, 34560, 34560, 34560, 33, 33, 34560, 1080, 34560, 34560, 33, 34560, 33, 1080, 33, 33, 1080, 1080, 34560, 34560, 34560, 33, 34560, 1080, 1080, 33, 33, 33, 33, 34560, 1080, 34560, 1080, 34560, 34560, 34560, 33, 1080, 1080, 34560, 1080, 34560, 33, 33, 33, 1080, 1080, 1080, 34560, 34560, 1080, 34560, 33, 1080, 1080, 33, 34560, 34560, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 34560, 33, 34560, 33, 34560, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 34560, 1080, 33, 33]
Prompts retrieved: 1925229 . Total input tokens: 429435227 . Total output tokens: 378209537
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.528264891821891,
    "estimated_duration": 3600.0127584943025,
    "input_throughput": 5243.509472420631,
    "output_throughput": 4560.934391484598,
    "total_throughput": 9804.44386390523,
    "itl": 105.99092437768402,
    "ttft": 2077623.0989143124,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 718,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.245836639599882,
    "arrivals": 641592,
    "finished_requests": 76527,
    "scheduler_time": 111.65487015355653
}
#Debug simulation 
Total elapsed time: 5.528377505019307. Arrivals time: 0.23434559302404523 Scheduler time: 5.138930183835328 Scheduler overhead time: 0.04970589280128479 Adapter cache time: 0.03155112965032458 Engine time: 0.05046517727896571 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-32/adapters_160_slots_96_rate_3.2-0.1-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-32/adapters_160_slots_96_rate_3.2-0.1-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [53 53 54]
Adapter prompts. [33, 34560, 33, 33, 1080, 33, 33, 33, 34560, 33, 1080, 34560, 1080, 33, 1080, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 33, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 33, 1080, 1080, 1080, 34560, 33, 33, 34560, 33, 34560, 33, 33, 1080, 33, 1080, 34560, 33, 33, 1080, 33, 33, 33, 33, 33, 34560, 1080, 1080, 34560, 1080, 33, 34560, 34560, 34560, 1080, 1080, 33, 33, 33, 34560, 33, 1080, 1080, 33, 34560, 34560, 34560, 33, 33, 34560, 1080, 34560, 34560, 33, 34560, 33, 1080, 33, 33, 1080, 1080, 34560, 34560, 34560, 33, 34560, 1080, 1080, 33, 33, 33, 33, 34560, 1080, 34560, 1080, 34560, 34560, 34560, 33, 1080, 1080, 34560, 1080, 34560, 33, 33, 33, 1080, 1080, 1080, 34560, 34560, 1080, 34560, 33, 1080, 1080, 33, 34560, 34560, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 34560, 33, 34560, 33, 34560, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 34560, 1080, 33, 33]
Prompts retrieved: 1925229 . Total input tokens: 429435227 . Total output tokens: 378209537
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.18181435065344,
    "estimated_duration": 3600.062353022379,
    "input_throughput": 4769.527668204047,
    "output_throughput": 4146.429293778181,
    "total_throughput": 8915.956961982229,
    "itl": 83.38720417365552,
    "ttft": 2132486.495769787,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 669,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.0218292609881905,
    "arrivals": 641592,
    "finished_requests": 69563,
    "scheduler_time": 117.71775629051123
}
#Debug simulation 
Total elapsed time: 5.181904785800725. Arrivals time: 0.23029901878908277 Scheduler time: 4.7664446090348065 Scheduler overhead time: 0.059922317042946815 Adapter cache time: 0.03488434664905071 Engine time: 0.061855592764914036 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.003125_size_8-16-16/adapters_160_slots_96_rate_3.2-0.1-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.003125_size_8-16-16/adapters_160_slots_96_rate_3.2-0.1-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [53 53 54]
Adapter prompts. [33, 34560, 33, 33, 1080, 33, 33, 33, 34560, 33, 1080, 34560, 1080, 33, 1080, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 33, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 33, 1080, 1080, 1080, 34560, 33, 33, 34560, 33, 34560, 33, 33, 1080, 33, 1080, 34560, 33, 33, 1080, 33, 33, 33, 33, 33, 34560, 1080, 1080, 34560, 1080, 33, 34560, 34560, 34560, 1080, 1080, 33, 33, 33, 34560, 33, 1080, 1080, 33, 34560, 34560, 34560, 33, 33, 34560, 1080, 34560, 34560, 33, 34560, 33, 1080, 33, 33, 1080, 1080, 34560, 34560, 34560, 33, 34560, 1080, 1080, 33, 33, 33, 33, 34560, 1080, 34560, 1080, 34560, 34560, 34560, 33, 1080, 1080, 34560, 1080, 34560, 33, 33, 33, 1080, 1080, 1080, 34560, 34560, 1080, 34560, 33, 1080, 1080, 33, 34560, 34560, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 34560, 33, 34560, 33, 34560, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 34560, 1080, 33, 33]
Prompts retrieved: 1925229 . Total input tokens: 429435227 . Total output tokens: 378209537
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 5.562707343138754,
    "estimated_duration": 3600.0075414287858,
    "input_throughput": 5244.169847629598,
    "output_throughput": 4561.534610975438,
    "total_throughput": 9805.704458605036,
    "itl": 105.98102622232251,
    "ttft": 2077517.7084480084,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 717,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.911832568957464,
    "arrivals": 641592,
    "finished_requests": 76536,
    "scheduler_time": 111.66375464401932
}
#Debug simulation 
Total elapsed time: 5.562820217106491. Arrivals time: 0.23835323844105005 Scheduler time: 5.167929215822369 Scheduler overhead time: 0.049744957592338324 Adapter cache time: 0.031974113546311855 Engine time: 0.05123130464926362 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.003125_size_8-16-32/adapters_160_slots_96_rate_3.2-0.1-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.003125_size_8-16-32/adapters_160_slots_96_rate_3.2-0.1-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [53 53 54]
Adapter prompts. [33, 34560, 33, 33, 1080, 33, 33, 33, 34560, 33, 1080, 34560, 1080, 33, 1080, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 33, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 33, 1080, 1080, 1080, 34560, 33, 33, 34560, 33, 34560, 33, 33, 1080, 33, 1080, 34560, 33, 33, 1080, 33, 33, 33, 33, 33, 34560, 1080, 1080, 34560, 1080, 33, 34560, 34560, 34560, 1080, 1080, 33, 33, 33, 34560, 33, 1080, 1080, 33, 34560, 34560, 34560, 33, 33, 34560, 1080, 34560, 34560, 33, 34560, 33, 1080, 33, 33, 1080, 1080, 34560, 34560, 34560, 33, 34560, 1080, 1080, 33, 33, 33, 33, 34560, 1080, 34560, 1080, 34560, 34560, 34560, 33, 1080, 1080, 34560, 1080, 34560, 33, 33, 33, 1080, 1080, 1080, 34560, 34560, 1080, 34560, 33, 1080, 1080, 33, 34560, 34560, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 34560, 33, 34560, 33, 34560, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 34560, 1080, 33, 33]
Prompts retrieved: 1925229 . Total input tokens: 429435227 . Total output tokens: 378209537
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 5.08873929688707,
    "estimated_duration": 3600.0164503570572,
    "input_throughput": 4769.588482935123,
    "output_throughput": 4146.482163579966,
    "total_throughput": 8916.070646515089,
    "itl": 83.38611993767248,
    "ttft": 2132468.1564506334,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 669,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.976056364956341,
    "arrivals": 641592,
    "finished_requests": 69563,
    "scheduler_time": 117.71762652122213
}
#Debug simulation 
Total elapsed time: 5.088852799963206. Arrivals time: 0.22201234987005591 Scheduler time: 4.6826736382208765 Scheduler overhead time: 0.05963955353945494 Adapter cache time: 0.03469489747658372 Engine time: 0.06149760354310274 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.003125_size_16-16-16/adapters_160_slots_96_rate_3.2-0.1-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.003125_size_16-16-16/adapters_160_slots_96_rate_3.2-0.1-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [53 53 54]
Adapter prompts. [33, 34560, 33, 33, 1080, 33, 33, 33, 34560, 33, 1080, 34560, 1080, 33, 1080, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 33, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 33, 1080, 1080, 1080, 34560, 33, 33, 34560, 33, 34560, 33, 33, 1080, 33, 1080, 34560, 33, 33, 1080, 33, 33, 33, 33, 33, 34560, 1080, 1080, 34560, 1080, 33, 34560, 34560, 34560, 1080, 1080, 33, 33, 33, 34560, 33, 1080, 1080, 33, 34560, 34560, 34560, 33, 33, 34560, 1080, 34560, 34560, 33, 34560, 33, 1080, 33, 33, 1080, 1080, 34560, 34560, 34560, 33, 34560, 1080, 1080, 33, 33, 33, 33, 34560, 1080, 34560, 1080, 34560, 34560, 34560, 33, 1080, 1080, 34560, 1080, 34560, 33, 33, 33, 1080, 1080, 1080, 34560, 34560, 1080, 34560, 33, 1080, 1080, 33, 34560, 34560, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 34560, 33, 34560, 33, 34560, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 34560, 1080, 33, 33]
Prompts retrieved: 1925229 . Total input tokens: 429435227 . Total output tokens: 378209537
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.583612759131938,
    "estimated_duration": 3600.0155425734233,
    "input_throughput": 5244.5912459876345,
    "output_throughput": 4561.949748766966,
    "total_throughput": 9806.5409947546,
    "itl": 105.97039511785474,
    "ttft": 2077521.2083871202,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 717,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.57727131438905,
    "arrivals": 641592,
    "finished_requests": 76543,
    "scheduler_time": 111.67370266200126
}
#Debug simulation 
Total elapsed time: 5.583728838246316. Arrivals time: 0.27274502953514457 Scheduler time: 5.155120663810521 Scheduler overhead time: 0.04975213250145316 Adapter cache time: 0.031867851968854666 Engine time: 0.05068998318165541 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.003125_size_16-16-32/adapters_160_slots_96_rate_3.2-0.1-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.1-0.003125_size_16-16-32/adapters_160_slots_96_rate_3.2-0.1-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [53 53 54]
Adapter prompts. [33, 34560, 33, 33, 1080, 33, 33, 33, 34560, 33, 1080, 34560, 1080, 33, 1080, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 33, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 33, 1080, 1080, 1080, 34560, 33, 33, 34560, 33, 34560, 33, 33, 1080, 33, 1080, 34560, 33, 33, 1080, 33, 33, 33, 33, 33, 34560, 1080, 1080, 34560, 1080, 33, 34560, 34560, 34560, 1080, 1080, 33, 33, 33, 34560, 33, 1080, 1080, 33, 34560, 34560, 34560, 33, 33, 34560, 1080, 34560, 34560, 33, 34560, 33, 1080, 33, 33, 1080, 1080, 34560, 34560, 34560, 33, 34560, 1080, 1080, 33, 33, 33, 33, 34560, 1080, 34560, 1080, 34560, 34560, 34560, 33, 1080, 1080, 34560, 1080, 34560, 33, 33, 33, 1080, 1080, 1080, 34560, 34560, 1080, 34560, 33, 1080, 1080, 33, 34560, 34560, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 1080, 34560, 33, 34560, 33, 34560, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 34560, 1080, 33, 33]
Prompts retrieved: 1925229 . Total input tokens: 429435227 . Total output tokens: 378209537
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.120056891813874,
    "estimated_duration": 3600.0616126532836,
    "input_throughput": 4769.628369594715,
    "output_throughput": 4146.437368608901,
    "total_throughput": 8916.065738203615,
    "itl": 83.38504435073287,
    "ttft": 2132475.38014163,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 669,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.929455000218034,
    "arrivals": 641592,
    "finished_requests": 69564,
    "scheduler_time": 117.72054967581178
}
#Debug simulation 
Total elapsed time: 5.120171864051372. Arrivals time: 0.22218923131003976 Scheduler time: 4.712778989691287 Scheduler overhead time: 0.05985354911535978 Adapter cache time: 0.035093532875180244 Engine time: 0.06174379074946046 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.025_size_8-8-8/adapters_160_slots_96_rate_3.2-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.025_size_8-8-8/adapters_160_slots_96_rate_3.2-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [53 53 54]
Adapter prompts. [270, 34560, 270, 270, 540, 270, 270, 270, 34560, 270, 540, 34560, 540, 270, 540, 540, 540, 540, 34560, 34560, 34560, 540, 540, 540, 34560, 34560, 270, 34560, 540, 34560, 34560, 34560, 540, 34560, 270, 540, 540, 540, 34560, 270, 270, 34560, 270, 34560, 270, 270, 540, 270, 540, 34560, 270, 270, 540, 270, 270, 270, 270, 270, 34560, 540, 540, 34560, 540, 270, 34560, 34560, 34560, 540, 540, 270, 270, 270, 34560, 270, 540, 540, 270, 34560, 34560, 34560, 270, 270, 34560, 540, 34560, 34560, 270, 34560, 270, 540, 270, 270, 540, 540, 34560, 34560, 34560, 270, 34560, 540, 540, 270, 270, 270, 270, 34560, 540, 34560, 540, 34560, 34560, 34560, 270, 540, 540, 34560, 540, 34560, 270, 270, 270, 540, 540, 540, 34560, 34560, 540, 34560, 270, 540, 540, 270, 34560, 34560, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 540, 34560, 270, 34560, 270, 34560, 540, 270, 540, 270, 270, 540, 540, 540, 34560, 540, 270, 270]
Prompts retrieved: 1909170 . Total input tokens: 425809991 . Total output tokens: 375033853
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.8350430079735816,
    "estimated_duration": 3600.071198946481,
    "input_throughput": 5469.125723336201,
    "output_throughput": 4779.582138551977,
    "total_throughput": 10248.707861888177,
    "itl": 115.2809573825436,
    "ttft": 2054243.0186524633,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1113,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.35961125256045,
    "arrivals": 636231,
    "finished_requests": 79727,
    "scheduler_time": 111.22309110829069
}
#Debug simulation 
Total elapsed time: 5.835159591399133. Arrivals time: 0.29946514358744025 Scheduler time: 5.3910513813607395 Scheduler overhead time: 0.04649370815604925 Adapter cache time: 0.028962515760213137 Engine time: 0.047335170209407806 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.025_size_8-8-16/adapters_160_slots_96_rate_3.2-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.025_size_8-8-16/adapters_160_slots_96_rate_3.2-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [53 53 54]
Adapter prompts. [270, 34560, 270, 270, 540, 270, 270, 270, 34560, 270, 540, 34560, 540, 270, 540, 540, 540, 540, 34560, 34560, 34560, 540, 540, 540, 34560, 34560, 270, 34560, 540, 34560, 34560, 34560, 540, 34560, 270, 540, 540, 540, 34560, 270, 270, 34560, 270, 34560, 270, 270, 540, 270, 540, 34560, 270, 270, 540, 270, 270, 270, 270, 270, 34560, 540, 540, 34560, 540, 270, 34560, 34560, 34560, 540, 540, 270, 270, 270, 34560, 270, 540, 540, 270, 34560, 34560, 34560, 270, 270, 34560, 540, 34560, 34560, 270, 34560, 270, 540, 270, 270, 540, 540, 34560, 34560, 34560, 270, 34560, 540, 540, 270, 270, 270, 270, 34560, 540, 34560, 540, 34560, 34560, 34560, 270, 540, 540, 34560, 540, 34560, 270, 270, 270, 540, 540, 540, 34560, 34560, 540, 34560, 270, 540, 540, 270, 34560, 34560, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 540, 34560, 270, 34560, 270, 34560, 540, 270, 540, 270, 270, 540, 540, 540, 34560, 540, 270, 270]
Prompts retrieved: 1909170 . Total input tokens: 425809991 . Total output tokens: 375033853
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.669945874251425,
    "estimated_duration": 3600.0070011554917,
    "input_throughput": 5298.758861823693,
    "output_throughput": 4636.082650573469,
    "total_throughput": 9934.841512397163,
    "itl": 104.50650305118147,
    "ttft": 2071162.945250359,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1091,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.976870835707534,
    "arrivals": 636231,
    "finished_requests": 77314,
    "scheduler_time": 113.35711213956144
}
#Debug simulation 
Total elapsed time: 5.67006455687806. Arrivals time: 0.29957557609304786 Scheduler time: 5.215693075675517 Scheduler overhead time: 0.050131113268435 Adapter cache time: 0.02949935896322131 Engine time: 0.0513223959133029 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.025_size_8-8-32/adapters_160_slots_96_rate_3.2-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.025_size_8-8-32/adapters_160_slots_96_rate_3.2-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [53 53 54]
Adapter prompts. [270, 34560, 270, 270, 540, 270, 270, 270, 34560, 270, 540, 34560, 540, 270, 540, 540, 540, 540, 34560, 34560, 34560, 540, 540, 540, 34560, 34560, 270, 34560, 540, 34560, 34560, 34560, 540, 34560, 270, 540, 540, 540, 34560, 270, 270, 34560, 270, 34560, 270, 270, 540, 270, 540, 34560, 270, 270, 540, 270, 270, 270, 270, 270, 34560, 540, 540, 34560, 540, 270, 34560, 34560, 34560, 540, 540, 270, 270, 270, 34560, 270, 540, 540, 270, 34560, 34560, 34560, 270, 270, 34560, 540, 34560, 34560, 270, 34560, 270, 540, 270, 270, 540, 540, 34560, 34560, 34560, 270, 34560, 540, 540, 270, 270, 270, 270, 34560, 540, 34560, 540, 34560, 34560, 34560, 270, 540, 540, 34560, 540, 34560, 270, 270, 270, 540, 540, 540, 34560, 34560, 540, 34560, 270, 540, 540, 270, 34560, 34560, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 540, 34560, 270, 34560, 270, 34560, 540, 270, 540, 270, 270, 540, 540, 540, 34560, 540, 270, 270]
Prompts retrieved: 1909170 . Total input tokens: 425809991 . Total output tokens: 375033853
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.254252261016518,
    "estimated_duration": 3600.0230876720675,
    "input_throughput": 4795.742299298465,
    "output_throughput": 4199.4983453775985,
    "total_throughput": 8995.240644676063,
    "itl": 82.45053312618033,
    "ttft": 2125752.1766026136,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 990,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.43311533610804,
    "arrivals": 636231,
    "finished_requests": 69957,
    "scheduler_time": 119.14802967156261
}
#Debug simulation 
Total elapsed time: 5.254372661933303. Arrivals time: 0.2896002745255828 Scheduler time: 4.78123354492709 Scheduler overhead time: 0.060764459893107414 Adapter cache time: 0.031234823167324066 Engine time: 0.06252114102244377 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.025_size_8-16-16/adapters_160_slots_96_rate_3.2-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.025_size_8-16-16/adapters_160_slots_96_rate_3.2-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [53 53 54]
Adapter prompts. [270, 34560, 270, 270, 540, 270, 270, 270, 34560, 270, 540, 34560, 540, 270, 540, 540, 540, 540, 34560, 34560, 34560, 540, 540, 540, 34560, 34560, 270, 34560, 540, 34560, 34560, 34560, 540, 34560, 270, 540, 540, 540, 34560, 270, 270, 34560, 270, 34560, 270, 270, 540, 270, 540, 34560, 270, 270, 540, 270, 270, 270, 270, 270, 34560, 540, 540, 34560, 540, 270, 34560, 34560, 34560, 540, 540, 270, 270, 270, 34560, 270, 540, 540, 270, 34560, 34560, 34560, 270, 270, 34560, 540, 34560, 34560, 270, 34560, 270, 540, 270, 270, 540, 540, 34560, 34560, 34560, 270, 34560, 540, 540, 270, 270, 270, 270, 34560, 540, 34560, 540, 34560, 34560, 34560, 270, 540, 540, 34560, 540, 34560, 270, 270, 270, 540, 540, 540, 34560, 34560, 540, 34560, 270, 540, 540, 270, 34560, 34560, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 540, 34560, 270, 34560, 270, 34560, 540, 270, 540, 270, 270, 540, 540, 540, 34560, 540, 270, 270]
Prompts retrieved: 1909170 . Total input tokens: 425809991 . Total output tokens: 375033853
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 5.679462892003357,
    "estimated_duration": 3600.096118171046,
    "input_throughput": 5299.758499140577,
    "output_throughput": 4636.645370590886,
    "total_throughput": 9936.403869731463,
    "itl": 104.4920582786824,
    "ttft": 2071227.6221843222,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1092,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.483495206255454,
    "arrivals": 636231,
    "finished_requests": 77332,
    "scheduler_time": 113.37510433026546
}
#Debug simulation 
Total elapsed time: 5.679582064040005. Arrivals time: 0.3026440474204719 Scheduler time: 5.220614903140813 Scheduler overhead time: 0.05106709385290742 Adapter cache time: 0.02983628259971738 Engine time: 0.05144450766965747 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.025_size_8-16-32/adapters_160_slots_96_rate_3.2-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.025_size_8-16-32/adapters_160_slots_96_rate_3.2-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [53 53 54]
Adapter prompts. [270, 34560, 270, 270, 540, 270, 270, 270, 34560, 270, 540, 34560, 540, 270, 540, 540, 540, 540, 34560, 34560, 34560, 540, 540, 540, 34560, 34560, 270, 34560, 540, 34560, 34560, 34560, 540, 34560, 270, 540, 540, 540, 34560, 270, 270, 34560, 270, 34560, 270, 270, 540, 270, 540, 34560, 270, 270, 540, 270, 270, 270, 270, 270, 34560, 540, 540, 34560, 540, 270, 34560, 34560, 34560, 540, 540, 270, 270, 270, 34560, 270, 540, 540, 270, 34560, 34560, 34560, 270, 270, 34560, 540, 34560, 34560, 270, 34560, 270, 540, 270, 270, 540, 540, 34560, 34560, 34560, 270, 34560, 540, 540, 270, 270, 270, 270, 34560, 540, 34560, 540, 34560, 34560, 34560, 270, 540, 540, 34560, 540, 34560, 270, 270, 270, 540, 540, 540, 34560, 34560, 540, 34560, 270, 540, 540, 270, 34560, 34560, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 540, 34560, 270, 34560, 270, 34560, 540, 270, 540, 270, 270, 540, 540, 540, 34560, 540, 270, 270]
Prompts retrieved: 1909170 . Total input tokens: 425809991 . Total output tokens: 375033853
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 5.190867853816599,
    "estimated_duration": 3600.0506985081656,
    "input_throughput": 4795.8032944243105,
    "output_throughput": 4199.660856516603,
    "total_throughput": 8995.464150940914,
    "itl": 82.44925309630277,
    "ttft": 2125824.653682512,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 990,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.365802253708263,
    "arrivals": 636231,
    "finished_requests": 69959,
    "scheduler_time": 119.15102914714376
}
#Debug simulation 
Total elapsed time: 5.190981407184154. Arrivals time: 0.28226721938699484 Scheduler time: 4.7268634010106325 Scheduler overhead time: 0.06034374330192804 Adapter cache time: 0.031055953819304705 Engine time: 0.061798966489732265 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.025_size_16-16-16/adapters_160_slots_96_rate_3.2-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.025_size_16-16-16/adapters_160_slots_96_rate_3.2-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [53 53 54]
Adapter prompts. [270, 34560, 270, 270, 540, 270, 270, 270, 34560, 270, 540, 34560, 540, 270, 540, 540, 540, 540, 34560, 34560, 34560, 540, 540, 540, 34560, 34560, 270, 34560, 540, 34560, 34560, 34560, 540, 34560, 270, 540, 540, 540, 34560, 270, 270, 34560, 270, 34560, 270, 270, 540, 270, 540, 34560, 270, 270, 540, 270, 270, 270, 270, 270, 34560, 540, 540, 34560, 540, 270, 34560, 34560, 34560, 540, 540, 270, 270, 270, 34560, 270, 540, 540, 270, 34560, 34560, 34560, 270, 270, 34560, 540, 34560, 34560, 270, 34560, 270, 540, 270, 270, 540, 540, 34560, 34560, 34560, 270, 34560, 540, 540, 270, 270, 270, 270, 34560, 540, 34560, 540, 34560, 34560, 34560, 270, 540, 540, 34560, 540, 34560, 270, 270, 270, 540, 540, 540, 34560, 34560, 540, 34560, 270, 540, 540, 270, 34560, 34560, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 540, 34560, 270, 34560, 270, 34560, 540, 270, 540, 270, 270, 540, 540, 540, 34560, 540, 270, 270]
Prompts retrieved: 1909170 . Total input tokens: 425809991 . Total output tokens: 375033853
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.6375725152902305,
    "estimated_duration": 3600.049974555654,
    "input_throughput": 5300.305033225315,
    "output_throughput": 4637.467845723625,
    "total_throughput": 9937.77287894894,
    "itl": 104.47817180404061,
    "ttft": 2071156.0772336724,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1092,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.971241667102987,
    "arrivals": 636231,
    "finished_requests": 77343,
    "scheduler_time": 113.38950119931654
}
#Debug simulation 
Total elapsed time: 5.637661822140217. Arrivals time: 0.2961270068772137 Scheduler time: 5.18676347238943 Scheduler overhead time: 0.05000572558492422 Adapter cache time: 0.029610045719891787 Engine time: 0.05137884011492133 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.025_size_16-16-32/adapters_160_slots_96_rate_3.2-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.025_size_16-16-32/adapters_160_slots_96_rate_3.2-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [53 53 54]
Adapter prompts. [270, 34560, 270, 270, 540, 270, 270, 270, 34560, 270, 540, 34560, 540, 270, 540, 540, 540, 540, 34560, 34560, 34560, 540, 540, 540, 34560, 34560, 270, 34560, 540, 34560, 34560, 34560, 540, 34560, 270, 540, 540, 540, 34560, 270, 270, 34560, 270, 34560, 270, 270, 540, 270, 540, 34560, 270, 270, 540, 270, 270, 270, 270, 270, 34560, 540, 540, 34560, 540, 270, 34560, 34560, 34560, 540, 540, 270, 270, 270, 34560, 270, 540, 540, 270, 34560, 34560, 34560, 270, 270, 34560, 540, 34560, 34560, 270, 34560, 270, 540, 270, 270, 540, 540, 34560, 34560, 34560, 270, 34560, 540, 540, 270, 270, 270, 270, 34560, 540, 34560, 540, 34560, 34560, 34560, 270, 540, 540, 34560, 540, 34560, 270, 270, 270, 540, 540, 540, 34560, 34560, 540, 34560, 270, 540, 540, 270, 34560, 34560, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 540, 34560, 270, 34560, 270, 34560, 540, 270, 540, 270, 270, 540, 540, 540, 34560, 540, 270, 270]
Prompts retrieved: 1909170 . Total input tokens: 425809991 . Total output tokens: 375033853
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.206139158923179,
    "estimated_duration": 3600.0769349563857,
    "input_throughput": 4795.969172866905,
    "output_throughput": 4199.849967979413,
    "total_throughput": 8995.819140846319,
    "itl": 82.44814937685422,
    "ttft": 2125780.754498223,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 990,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.296210882365724,
    "arrivals": 636231,
    "finished_requests": 69963,
    "scheduler_time": 119.15408226704331
}
#Debug simulation 
Total elapsed time: 5.206227007322013. Arrivals time: 0.2803788594901562 Scheduler time: 4.743909764103591 Scheduler overhead time: 0.06034618243575096 Adapter cache time: 0.030941345263272524 Engine time: 0.061969212256371975 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-8/adapters_160_slots_96_rate_3.2-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-8/adapters_160_slots_96_rate_3.2-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [53 53 54]
Adapter prompts. [135, 34560, 135, 135, 540, 135, 135, 135, 34560, 135, 540, 34560, 540, 135, 540, 540, 540, 540, 34560, 34560, 34560, 540, 540, 540, 34560, 34560, 135, 34560, 540, 34560, 34560, 34560, 540, 34560, 135, 540, 540, 540, 34560, 135, 135, 34560, 135, 34560, 135, 135, 540, 135, 540, 34560, 135, 135, 540, 135, 135, 135, 135, 135, 34560, 540, 540, 34560, 540, 135, 34560, 34560, 34560, 540, 540, 135, 135, 135, 34560, 135, 540, 540, 135, 34560, 34560, 34560, 135, 135, 34560, 540, 34560, 34560, 135, 34560, 135, 540, 135, 135, 540, 540, 34560, 34560, 34560, 135, 34560, 540, 540, 135, 135, 135, 135, 34560, 540, 34560, 540, 34560, 34560, 34560, 135, 540, 540, 34560, 540, 34560, 135, 135, 135, 540, 540, 540, 34560, 34560, 540, 34560, 135, 540, 540, 135, 34560, 34560, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 540, 34560, 135, 34560, 135, 34560, 540, 135, 540, 135, 135, 540, 540, 540, 34560, 540, 135, 135]
Prompts retrieved: 1902015 . Total input tokens: 424192335 . Total output tokens: 373625052
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.871409866027534,
    "estimated_duration": 3600.023415667079,
    "input_throughput": 5563.43242458848,
    "output_throughput": 4831.769405804497,
    "total_throughput": 10395.201830392978,
    "itl": 113.7512109786343,
    "ttft": 2042668.4158146938,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 855,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.653609722317311,
    "arrivals": 633808,
    "finished_requests": 80840,
    "scheduler_time": 112.42821798339573
}
#Debug simulation 
Total elapsed time: 5.871508768294007. Arrivals time: 0.2473869281820953 Scheduler time: 5.481552875600755 Scheduler overhead time: 0.04682424012571573 Adapter cache time: 0.025832671206444502 Engine time: 0.04785953788086772 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-16/adapters_160_slots_96_rate_3.2-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-16/adapters_160_slots_96_rate_3.2-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [53 53 54]
Adapter prompts. [135, 34560, 135, 135, 540, 135, 135, 135, 34560, 135, 540, 34560, 540, 135, 540, 540, 540, 540, 34560, 34560, 34560, 540, 540, 540, 34560, 34560, 135, 34560, 540, 34560, 34560, 34560, 540, 34560, 135, 540, 540, 540, 34560, 135, 135, 34560, 135, 34560, 135, 135, 540, 135, 540, 34560, 135, 135, 540, 135, 135, 135, 135, 135, 34560, 540, 540, 34560, 540, 135, 34560, 34560, 34560, 540, 540, 135, 135, 135, 34560, 135, 540, 540, 135, 34560, 34560, 34560, 135, 135, 34560, 540, 34560, 34560, 135, 34560, 135, 540, 135, 135, 540, 540, 34560, 34560, 34560, 135, 34560, 540, 540, 135, 135, 135, 135, 34560, 540, 34560, 540, 34560, 34560, 34560, 135, 540, 540, 34560, 540, 34560, 135, 135, 135, 540, 540, 540, 34560, 34560, 540, 34560, 135, 540, 540, 135, 34560, 34560, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 540, 34560, 135, 34560, 135, 34560, 540, 135, 540, 135, 135, 540, 540, 540, 34560, 540, 135, 135]
Prompts retrieved: 1902015 . Total input tokens: 424192335 . Total output tokens: 373625052
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.7262026984244585,
    "estimated_duration": 3600.082741203923,
    "input_throughput": 5378.354719015396,
    "output_throughput": 4680.166599272505,
    "total_throughput": 10058.5213182879,
    "itl": 103.23975631155531,
    "ttft": 2059127.6694980424,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 828,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.028584759514786,
    "arrivals": 633808,
    "finished_requests": 78214,
    "scheduler_time": 114.48483238260587
}
#Debug simulation 
Total elapsed time: 5.726317771244794. Arrivals time: 0.29737973818555474 Scheduler time: 5.275360443629324 Scheduler overhead time: 0.05063725681975484 Adapter cache time: 0.02703390410169959 Engine time: 0.0519818845205009 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-32/adapters_160_slots_96_rate_3.2-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-32/adapters_160_slots_96_rate_3.2-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [53 53 54]
Adapter prompts. [135, 34560, 135, 135, 540, 135, 135, 135, 34560, 135, 540, 34560, 540, 135, 540, 540, 540, 540, 34560, 34560, 34560, 540, 540, 540, 34560, 34560, 135, 34560, 540, 34560, 34560, 34560, 540, 34560, 135, 540, 540, 540, 34560, 135, 135, 34560, 135, 34560, 135, 135, 540, 135, 540, 34560, 135, 135, 540, 135, 135, 135, 135, 135, 34560, 540, 540, 34560, 540, 135, 34560, 34560, 34560, 540, 540, 135, 135, 135, 34560, 135, 540, 540, 135, 34560, 34560, 34560, 135, 135, 34560, 540, 34560, 34560, 135, 34560, 135, 540, 135, 135, 540, 540, 34560, 34560, 34560, 135, 34560, 540, 540, 135, 135, 135, 135, 34560, 540, 34560, 540, 34560, 34560, 34560, 135, 540, 540, 34560, 540, 34560, 135, 135, 135, 540, 540, 540, 34560, 34560, 540, 34560, 135, 540, 540, 135, 34560, 34560, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 540, 34560, 135, 34560, 135, 34560, 540, 135, 540, 135, 135, 540, 540, 540, 34560, 540, 135, 135]
Prompts retrieved: 1902015 . Total input tokens: 424192335 . Total output tokens: 373625052
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.250663102604449,
    "estimated_duration": 3600.0450090036734,
    "input_throughput": 4862.551705942335,
    "output_throughput": 4223.755525825562,
    "total_throughput": 9086.307231767896,
    "itl": 81.40405031101211,
    "ttft": 2117130.734951545,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 765,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.7151095979195325,
    "arrivals": 633808,
    "finished_requests": 70562,
    "scheduler_time": 120.10910576947623
}
#Debug simulation 
Total elapsed time: 5.250782676972449. Arrivals time: 0.28786632465198636 Scheduler time: 4.780654715374112 Scheduler overhead time: 0.061094334814697504 Adapter cache time: 0.029405622743070126 Engine time: 0.06264270003885031 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.0125_size_8-16-16/adapters_160_slots_96_rate_3.2-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.0125_size_8-16-16/adapters_160_slots_96_rate_3.2-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [53 53 54]
Adapter prompts. [135, 34560, 135, 135, 540, 135, 135, 135, 34560, 135, 540, 34560, 540, 135, 540, 540, 540, 540, 34560, 34560, 34560, 540, 540, 540, 34560, 34560, 135, 34560, 540, 34560, 34560, 34560, 540, 34560, 135, 540, 540, 540, 34560, 135, 135, 34560, 135, 34560, 135, 135, 540, 135, 540, 34560, 135, 135, 540, 135, 135, 135, 135, 135, 34560, 540, 540, 34560, 540, 135, 34560, 34560, 34560, 540, 540, 135, 135, 135, 34560, 135, 540, 540, 135, 34560, 34560, 34560, 135, 135, 34560, 540, 34560, 34560, 135, 34560, 135, 540, 135, 135, 540, 540, 34560, 34560, 34560, 135, 34560, 540, 540, 135, 135, 135, 135, 34560, 540, 34560, 540, 34560, 34560, 34560, 135, 540, 540, 34560, 540, 34560, 135, 135, 135, 540, 540, 540, 34560, 34560, 540, 34560, 135, 540, 540, 135, 34560, 34560, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 540, 34560, 135, 34560, 135, 34560, 540, 135, 540, 135, 135, 540, 540, 540, 34560, 540, 135, 135]
Prompts retrieved: 1902015 . Total input tokens: 424192335 . Total output tokens: 373625052
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 5.732172596268356,
    "estimated_duration": 3600.0426358224013,
    "input_throughput": 5378.842685727369,
    "output_throughput": 4680.710953899738,
    "total_throughput": 10059.553639627107,
    "itl": 103.22974270458731,
    "ttft": 2058962.9990409026,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 828,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.660706201586864,
    "arrivals": 633808,
    "finished_requests": 78218,
    "scheduler_time": 114.49486627038613
}
#Debug simulation 
Total elapsed time: 5.732263305224478. Arrivals time: 0.30096681229770184 Scheduler time: 5.276688242331147 Scheduler overhead time: 0.051037102937698364 Adapter cache time: 0.02716558240354061 Engine time: 0.05241642287001014 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.0125_size_8-16-32/adapters_160_slots_96_rate_3.2-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.0125_size_8-16-32/adapters_160_slots_96_rate_3.2-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [53 53 54]
Adapter prompts. [135, 34560, 135, 135, 540, 135, 135, 135, 34560, 135, 540, 34560, 540, 135, 540, 540, 540, 540, 34560, 34560, 34560, 540, 540, 540, 34560, 34560, 135, 34560, 540, 34560, 34560, 34560, 540, 34560, 135, 540, 540, 540, 34560, 135, 135, 34560, 135, 34560, 135, 135, 540, 135, 540, 34560, 135, 135, 540, 135, 135, 135, 135, 135, 34560, 540, 540, 34560, 540, 135, 34560, 34560, 34560, 540, 540, 135, 135, 135, 34560, 135, 540, 540, 135, 34560, 34560, 34560, 135, 135, 34560, 540, 34560, 34560, 135, 34560, 135, 540, 135, 135, 540, 540, 34560, 34560, 34560, 135, 34560, 540, 540, 135, 135, 135, 135, 34560, 540, 34560, 540, 34560, 34560, 34560, 135, 540, 540, 34560, 540, 34560, 135, 135, 135, 540, 540, 540, 34560, 34560, 540, 34560, 135, 540, 540, 135, 34560, 34560, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 540, 34560, 135, 34560, 135, 34560, 540, 135, 540, 135, 135, 540, 540, 540, 34560, 540, 135, 135]
Prompts retrieved: 1902015 . Total input tokens: 424192335 . Total output tokens: 373625052
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 5.271664972882718,
    "estimated_duration": 3600.0808310098387,
    "input_throughput": 4862.79498204749,
    "output_throughput": 4223.881272058706,
    "total_throughput": 9086.676254106196,
    "itl": 81.40315868626314,
    "ttft": 2117129.2156221354,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 765,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.663744538119087,
    "arrivals": 633808,
    "finished_requests": 70565,
    "scheduler_time": 120.11195671467775
}
#Debug simulation 
Total elapsed time: 5.27178332908079. Arrivals time: 0.22584493644535542 Scheduler time: 4.8628986878320575 Scheduler overhead time: 0.061168336775153875 Adapter cache time: 0.0294282054528594 Engine time: 0.06319644534960389 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.0125_size_16-16-16/adapters_160_slots_96_rate_3.2-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.0125_size_16-16-16/adapters_160_slots_96_rate_3.2-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [53 53 54]
Adapter prompts. [135, 34560, 135, 135, 540, 135, 135, 135, 34560, 135, 540, 34560, 540, 135, 540, 540, 540, 540, 34560, 34560, 34560, 540, 540, 540, 34560, 34560, 135, 34560, 540, 34560, 34560, 34560, 540, 34560, 135, 540, 540, 540, 34560, 135, 135, 34560, 135, 34560, 135, 135, 540, 135, 540, 34560, 135, 135, 540, 135, 135, 135, 135, 135, 34560, 540, 540, 34560, 540, 135, 34560, 34560, 34560, 540, 540, 135, 135, 135, 34560, 135, 540, 540, 135, 34560, 34560, 34560, 135, 135, 34560, 540, 34560, 34560, 135, 34560, 135, 540, 135, 135, 540, 540, 34560, 34560, 34560, 135, 34560, 540, 540, 135, 135, 135, 135, 34560, 540, 34560, 540, 34560, 34560, 34560, 135, 540, 540, 34560, 540, 34560, 135, 135, 135, 540, 540, 540, 34560, 34560, 540, 34560, 135, 540, 540, 135, 34560, 34560, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 540, 34560, 135, 34560, 135, 34560, 540, 135, 540, 135, 135, 540, 540, 540, 34560, 540, 135, 135]
Prompts retrieved: 1902015 . Total input tokens: 424192335 . Total output tokens: 373625052
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.777804714627564,
    "estimated_duration": 3600.108311711028,
    "input_throughput": 5379.49342718401,
    "output_throughput": 4681.288044911678,
    "total_throughput": 10060.781472095689,
    "itl": 103.21819359095981,
    "ttft": 2058990.9724157234,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 828,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.285886538792376,
    "arrivals": 633808,
    "finished_requests": 78229,
    "scheduler_time": 114.50869401508909
}
#Debug simulation 
Total elapsed time: 5.7778953136876225. Arrivals time: 0.24193133600056171 Scheduler time: 5.381829371675849 Scheduler overhead time: 0.05088335322216153 Adapter cache time: 0.027125058695673943 Engine time: 0.0520816626958549 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.0125_size_16-16-32/adapters_160_slots_96_rate_3.2-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.0125_size_16-16-32/adapters_160_slots_96_rate_3.2-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [53 53 54]
Adapter prompts. [135, 34560, 135, 135, 540, 135, 135, 135, 34560, 135, 540, 34560, 540, 135, 540, 540, 540, 540, 34560, 34560, 34560, 540, 540, 540, 34560, 34560, 135, 34560, 540, 34560, 34560, 34560, 540, 34560, 135, 540, 540, 540, 34560, 135, 135, 34560, 135, 34560, 135, 135, 540, 135, 540, 34560, 135, 135, 540, 135, 135, 135, 135, 135, 34560, 540, 540, 34560, 540, 135, 34560, 34560, 34560, 540, 540, 135, 135, 135, 34560, 135, 540, 540, 135, 34560, 34560, 34560, 135, 135, 34560, 540, 34560, 34560, 135, 34560, 135, 540, 135, 135, 540, 540, 34560, 34560, 34560, 135, 34560, 540, 540, 135, 135, 135, 135, 34560, 540, 34560, 540, 34560, 34560, 34560, 135, 540, 540, 34560, 540, 34560, 135, 135, 135, 540, 540, 540, 34560, 34560, 540, 34560, 135, 540, 540, 135, 34560, 34560, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 540, 34560, 135, 34560, 135, 34560, 540, 135, 540, 135, 135, 540, 540, 540, 34560, 540, 135, 135]
Prompts retrieved: 1902015 . Total input tokens: 424192335 . Total output tokens: 373625052
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.248960885684937,
    "estimated_duration": 3600.029763279303,
    "input_throughput": 4862.863962561575,
    "output_throughput": 4223.941189349617,
    "total_throughput": 9086.805151911192,
    "itl": 81.40196797547198,
    "ttft": 2117110.137206785,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 765,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.612793712671871,
    "arrivals": 633808,
    "finished_requests": 70565,
    "scheduler_time": 120.11183980959001
}
#Debug simulation 
Total elapsed time: 5.24907161295414. Arrivals time: 0.2853225222788751 Scheduler time: 4.779551141895354 Scheduler overhead time: 0.06267431890591979 Adapter cache time: 0.029495694674551487 Engine time: 0.06279670493677258 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-8/adapters_160_slots_96_rate_3.2-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-8/adapters_160_slots_96_rate_3.2-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [53 53 54]
Adapter prompts. [66, 34560, 66, 66, 540, 66, 66, 66, 34560, 66, 540, 34560, 540, 66, 540, 540, 540, 540, 34560, 34560, 34560, 540, 540, 540, 34560, 34560, 66, 34560, 540, 34560, 34560, 34560, 540, 34560, 66, 540, 540, 540, 34560, 66, 66, 34560, 66, 34560, 66, 66, 540, 66, 540, 34560, 66, 66, 540, 66, 66, 66, 66, 66, 34560, 540, 540, 34560, 540, 66, 34560, 34560, 34560, 540, 540, 66, 66, 66, 34560, 66, 540, 540, 66, 34560, 34560, 34560, 66, 66, 34560, 540, 34560, 34560, 66, 34560, 66, 540, 66, 66, 540, 540, 34560, 34560, 34560, 66, 34560, 540, 540, 66, 66, 66, 66, 34560, 540, 34560, 540, 34560, 34560, 34560, 66, 540, 540, 34560, 540, 34560, 66, 66, 66, 540, 540, 540, 34560, 34560, 540, 34560, 66, 540, 540, 66, 34560, 34560, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 540, 34560, 66, 34560, 66, 34560, 540, 66, 540, 66, 66, 540, 540, 540, 34560, 540, 66, 66]
Prompts retrieved: 1898358 . Total input tokens: 423390014 . Total output tokens: 372904001
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.8587785442359746,
    "estimated_duration": 3600.0262751560695,
    "input_throughput": 5586.9170008010715,
    "output_throughput": 4861.037298746199,
    "total_throughput": 10447.95429954727,
    "itl": 112.89170559659975,
    "ttft": 2046911.5433216363,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 629,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.159205281096577,
    "arrivals": 632594,
    "finished_requests": 81392,
    "scheduler_time": 113.21460800848018
}
#Debug simulation 
Total elapsed time: 5.858876537065953. Arrivals time: 0.25304481061175466 Scheduler time: 5.464437823742628 Scheduler overhead time: 0.04705254966393113 Adapter cache time: 0.0238658357411623 Engine time: 0.04819578165188432 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-16/adapters_160_slots_96_rate_3.2-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-16/adapters_160_slots_96_rate_3.2-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [53 53 54]
Adapter prompts. [66, 34560, 66, 66, 540, 66, 66, 66, 34560, 66, 540, 34560, 540, 66, 540, 540, 540, 540, 34560, 34560, 34560, 540, 540, 540, 34560, 34560, 66, 34560, 540, 34560, 34560, 34560, 540, 34560, 66, 540, 540, 540, 34560, 66, 66, 34560, 66, 34560, 66, 66, 540, 66, 540, 34560, 66, 66, 540, 66, 66, 66, 66, 66, 34560, 540, 540, 34560, 540, 66, 34560, 34560, 34560, 540, 540, 66, 66, 66, 34560, 66, 540, 540, 66, 34560, 34560, 34560, 66, 66, 34560, 540, 34560, 34560, 66, 34560, 66, 540, 66, 66, 540, 540, 34560, 34560, 34560, 66, 34560, 540, 540, 66, 66, 66, 66, 34560, 540, 34560, 540, 34560, 34560, 34560, 66, 540, 540, 34560, 540, 34560, 66, 66, 66, 540, 540, 540, 34560, 34560, 540, 34560, 66, 540, 540, 66, 34560, 34560, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 540, 34560, 66, 34560, 66, 34560, 540, 66, 540, 66, 66, 540, 540, 540, 34560, 540, 66, 66]
Prompts retrieved: 1898358 . Total input tokens: 423390014 . Total output tokens: 372904001
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.6818319680169225,
    "estimated_duration": 3600.112860600639,
    "input_throughput": 5403.073390525514,
    "output_throughput": 4709.143478677362,
    "total_throughput": 10112.216869202875,
    "itl": 102.46583181020615,
    "ttft": 2065359.4707330726,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 612,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.478906656634069,
    "arrivals": 632594,
    "finished_requests": 78782,
    "scheduler_time": 115.24580463453984
}
#Debug simulation 
Total elapsed time: 5.681922503747046. Arrivals time: 0.24004088761284947 Scheduler time: 5.289397940505296 Scheduler overhead time: 0.05108326068148017 Adapter cache time: 0.02494677994400263 Engine time: 0.052270989399403334 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-32/adapters_160_slots_96_rate_3.2-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-32/adapters_160_slots_96_rate_3.2-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [53 53 54]
Adapter prompts. [66, 34560, 66, 66, 540, 66, 66, 66, 34560, 66, 540, 34560, 540, 66, 540, 540, 540, 540, 34560, 34560, 34560, 540, 540, 540, 34560, 34560, 66, 34560, 540, 34560, 34560, 34560, 540, 34560, 66, 540, 540, 540, 34560, 66, 66, 34560, 66, 34560, 66, 66, 540, 66, 540, 34560, 66, 66, 540, 66, 66, 66, 66, 66, 34560, 540, 540, 34560, 540, 66, 34560, 34560, 34560, 540, 540, 66, 66, 66, 34560, 66, 540, 540, 66, 34560, 34560, 34560, 66, 66, 34560, 540, 34560, 34560, 66, 34560, 66, 540, 66, 66, 540, 540, 34560, 34560, 34560, 66, 34560, 540, 540, 66, 66, 66, 66, 34560, 540, 34560, 540, 34560, 34560, 34560, 66, 540, 540, 34560, 540, 34560, 66, 66, 66, 540, 540, 540, 34560, 34560, 540, 34560, 66, 540, 540, 66, 34560, 34560, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 540, 34560, 66, 34560, 66, 34560, 540, 66, 540, 66, 66, 540, 540, 540, 34560, 540, 66, 66]
Prompts retrieved: 1898358 . Total input tokens: 423390014 . Total output tokens: 372904001
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.229532930068672,
    "estimated_duration": 3600.0364265095614,
    "input_throughput": 4862.537187428514,
    "output_throughput": 4245.452598050096,
    "total_throughput": 9107.98978547861,
    "itl": 81.31096300487478,
    "ttft": 2122401.716082618,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 555,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.166091539384832,
    "arrivals": 632594,
    "finished_requests": 70945,
    "scheduler_time": 120.53063405439228
}
#Debug simulation 
Total elapsed time: 5.229621961247176. Arrivals time: 0.22982946457341313 Scheduler time: 4.819876252207905 Scheduler overhead time: 0.0609230836853385 Adapter cache time: 0.027101455256342888 Engine time: 0.06268484983593225 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.00625_size_8-16-16/adapters_160_slots_96_rate_3.2-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.00625_size_8-16-16/adapters_160_slots_96_rate_3.2-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [53 53 54]
Adapter prompts. [66, 34560, 66, 66, 540, 66, 66, 66, 34560, 66, 540, 34560, 540, 66, 540, 540, 540, 540, 34560, 34560, 34560, 540, 540, 540, 34560, 34560, 66, 34560, 540, 34560, 34560, 34560, 540, 34560, 66, 540, 540, 540, 34560, 66, 66, 34560, 66, 34560, 66, 66, 540, 66, 540, 34560, 66, 66, 540, 66, 66, 66, 66, 66, 34560, 540, 540, 34560, 540, 66, 34560, 34560, 34560, 540, 540, 66, 66, 66, 34560, 66, 540, 540, 66, 34560, 34560, 34560, 66, 66, 34560, 540, 34560, 34560, 66, 34560, 66, 540, 66, 66, 540, 540, 34560, 34560, 34560, 66, 34560, 540, 540, 66, 66, 66, 66, 34560, 540, 34560, 540, 34560, 34560, 34560, 66, 540, 540, 34560, 540, 34560, 66, 66, 66, 540, 540, 540, 34560, 34560, 540, 34560, 66, 540, 540, 66, 34560, 34560, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 540, 34560, 66, 34560, 66, 34560, 540, 66, 540, 66, 66, 540, 540, 540, 34560, 540, 66, 66]
Prompts retrieved: 1898358 . Total input tokens: 423390014 . Total output tokens: 372904001
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 5.736624335870147,
    "estimated_duration": 3600.053283001551,
    "input_throughput": 5403.47113523309,
    "output_throughput": 4709.281687593482,
    "total_throughput": 10112.752822826571,
    "itl": 102.45794591735032,
    "ttft": 2065214.558138151,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 612,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.190156694184983,
    "arrivals": 632594,
    "finished_requests": 78784,
    "scheduler_time": 115.25236752402236
}
#Debug simulation 
Total elapsed time: 5.73671721899882. Arrivals time: 0.24047760060057044 Scheduler time: 5.343799290712923 Scheduler overhead time: 0.05098181962966919 Adapter cache time: 0.025193353183567524 Engine time: 0.052102981600910425 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.00625_size_8-16-32/adapters_160_slots_96_rate_3.2-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.00625_size_8-16-32/adapters_160_slots_96_rate_3.2-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [53 53 54]
Adapter prompts. [66, 34560, 66, 66, 540, 66, 66, 66, 34560, 66, 540, 34560, 540, 66, 540, 540, 540, 540, 34560, 34560, 34560, 540, 540, 540, 34560, 34560, 66, 34560, 540, 34560, 34560, 34560, 540, 34560, 66, 540, 540, 540, 34560, 66, 66, 34560, 66, 34560, 66, 66, 540, 66, 540, 34560, 66, 66, 540, 66, 66, 66, 66, 66, 34560, 540, 540, 34560, 540, 66, 34560, 34560, 34560, 540, 540, 66, 66, 66, 34560, 66, 540, 540, 66, 34560, 34560, 34560, 66, 66, 34560, 540, 34560, 34560, 66, 34560, 66, 540, 66, 66, 540, 540, 34560, 34560, 34560, 66, 34560, 540, 540, 66, 66, 66, 66, 34560, 540, 34560, 540, 34560, 34560, 34560, 66, 540, 540, 34560, 540, 34560, 66, 66, 66, 540, 540, 540, 34560, 34560, 540, 34560, 66, 540, 540, 66, 34560, 34560, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 540, 34560, 66, 34560, 66, 34560, 540, 66, 540, 66, 66, 540, 540, 540, 34560, 540, 66, 66]
Prompts retrieved: 1898358 . Total input tokens: 423390014 . Total output tokens: 372904001
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 5.241172799374908,
    "estimated_duration": 3600.086414554662,
    "input_throughput": 4862.54300153111,
    "output_throughput": 4245.463369492664,
    "total_throughput": 9108.006371023776,
    "itl": 81.31018270825916,
    "ttft": 2122365.812837402,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 555,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.127567744534496,
    "arrivals": 632594,
    "finished_requests": 70946,
    "scheduler_time": 120.53353791364991
}
#Debug simulation 
Total elapsed time: 5.2412594254128635. Arrivals time: 0.22570003988221288 Scheduler time: 4.835277698002756 Scheduler overhead time: 0.061301165260374546 Adapter cache time: 0.0270972503349185 Engine time: 0.0627311086282134 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.00625_size_16-16-16/adapters_160_slots_96_rate_3.2-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.00625_size_16-16-16/adapters_160_slots_96_rate_3.2-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [53 53 54]
Adapter prompts. [66, 34560, 66, 66, 540, 66, 66, 66, 34560, 66, 540, 34560, 540, 66, 540, 540, 540, 540, 34560, 34560, 34560, 540, 540, 540, 34560, 34560, 66, 34560, 540, 34560, 34560, 34560, 540, 34560, 66, 540, 540, 540, 34560, 66, 66, 34560, 66, 34560, 66, 66, 540, 66, 540, 34560, 66, 66, 540, 66, 66, 66, 66, 66, 34560, 540, 540, 34560, 540, 66, 34560, 34560, 34560, 540, 540, 66, 66, 66, 34560, 66, 540, 540, 66, 34560, 34560, 34560, 66, 66, 34560, 540, 34560, 34560, 66, 34560, 66, 540, 66, 66, 540, 540, 34560, 34560, 34560, 66, 34560, 540, 540, 66, 66, 66, 66, 34560, 540, 34560, 540, 34560, 34560, 34560, 66, 540, 540, 34560, 540, 34560, 66, 66, 66, 540, 540, 540, 34560, 34560, 540, 34560, 66, 540, 540, 66, 34560, 34560, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 540, 34560, 66, 34560, 66, 34560, 540, 66, 540, 66, 66, 540, 540, 540, 34560, 540, 66, 66]
Prompts retrieved: 1898358 . Total input tokens: 423390014 . Total output tokens: 372904001
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.739694011863321,
    "estimated_duration": 3600.000008736354,
    "input_throughput": 5403.942209108124,
    "output_throughput": 4709.735821903911,
    "total_throughput": 10113.678031012036,
    "itl": 102.45020112822674,
    "ttft": 2065123.10869959,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 612,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.906959615629148,
    "arrivals": 632594,
    "finished_requests": 78791,
    "scheduler_time": 115.25910726263358
}
#Debug simulation 
Total elapsed time: 5.739800601731986. Arrivals time: 0.2564234514720738 Scheduler time: 5.331248399801552 Scheduler overhead time: 0.050931320525705814 Adapter cache time: 0.024796557147055864 Engine time: 0.05218766164034605 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.00625_size_16-16-32/adapters_160_slots_96_rate_3.2-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.00625_size_16-16-32/adapters_160_slots_96_rate_3.2-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [53 53 54]
Adapter prompts. [66, 34560, 66, 66, 540, 66, 66, 66, 34560, 66, 540, 34560, 540, 66, 540, 540, 540, 540, 34560, 34560, 34560, 540, 540, 540, 34560, 34560, 66, 34560, 540, 34560, 34560, 34560, 540, 34560, 66, 540, 540, 540, 34560, 66, 66, 34560, 66, 34560, 66, 66, 540, 66, 540, 34560, 66, 66, 540, 66, 66, 66, 66, 66, 34560, 540, 540, 34560, 540, 66, 34560, 34560, 34560, 540, 540, 66, 66, 66, 34560, 66, 540, 540, 66, 34560, 34560, 34560, 66, 66, 34560, 540, 34560, 34560, 66, 34560, 66, 540, 66, 66, 540, 540, 34560, 34560, 34560, 66, 34560, 540, 540, 66, 66, 66, 66, 34560, 540, 34560, 540, 34560, 34560, 34560, 66, 540, 540, 34560, 540, 34560, 66, 66, 66, 540, 540, 540, 34560, 34560, 540, 34560, 66, 540, 540, 66, 34560, 34560, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 540, 34560, 66, 34560, 66, 34560, 540, 66, 540, 66, 66, 540, 540, 540, 34560, 540, 66, 66]
Prompts retrieved: 1898358 . Total input tokens: 423390014 . Total output tokens: 372904001
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.216309902258217,
    "estimated_duration": 3600.048200754348,
    "input_throughput": 4862.594616464277,
    "output_throughput": 4245.5084342474665,
    "total_throughput": 9108.103050711745,
    "itl": 81.30932984411966,
    "ttft": 2122349.740495632,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 555,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.089458184037391,
    "arrivals": 632594,
    "finished_requests": 70946,
    "scheduler_time": 120.5334336738326
}
#Debug simulation 
Total elapsed time: 5.216436113230884. Arrivals time: 0.22547563165426254 Scheduler time: 4.810591048561037 Scheduler overhead time: 0.061302886344492435 Adapter cache time: 0.02702061226591468 Engine time: 0.06264836201444268 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-8/adapters_160_slots_96_rate_3.2-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-8/adapters_160_slots_96_rate_3.2-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [53 53 54]
Adapter prompts. [33, 34560, 33, 33, 540, 33, 33, 33, 34560, 33, 540, 34560, 540, 33, 540, 540, 540, 540, 34560, 34560, 34560, 540, 540, 540, 34560, 34560, 33, 34560, 540, 34560, 34560, 34560, 540, 34560, 33, 540, 540, 540, 34560, 33, 33, 34560, 33, 34560, 33, 33, 540, 33, 540, 34560, 33, 33, 540, 33, 33, 33, 33, 33, 34560, 540, 540, 34560, 540, 33, 34560, 34560, 34560, 540, 540, 33, 33, 33, 34560, 33, 540, 540, 33, 34560, 34560, 34560, 33, 33, 34560, 540, 34560, 34560, 33, 34560, 33, 540, 33, 33, 540, 540, 34560, 34560, 34560, 33, 34560, 540, 540, 33, 33, 33, 33, 34560, 540, 34560, 540, 34560, 34560, 34560, 33, 540, 540, 34560, 540, 34560, 33, 33, 33, 540, 540, 540, 34560, 34560, 540, 34560, 33, 540, 540, 33, 34560, 34560, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 540, 34560, 33, 34560, 33, 34560, 540, 33, 540, 33, 33, 540, 540, 540, 34560, 540, 33, 33]
Prompts retrieved: 1896609 . Total input tokens: 422992933 . Total output tokens: 372560486
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.957440332043916,
    "estimated_duration": 3600.095094660282,
    "input_throughput": 5620.9093004276665,
    "output_throughput": 4876.856176949614,
    "total_throughput": 10497.76547737728,
    "itl": 113.02451457558054,
    "ttft": 2037963.7313812538,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 452,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.988808882441401,
    "arrivals": 632045,
    "finished_requests": 81821,
    "scheduler_time": 113.47347962536934
}
#Debug simulation 
Total elapsed time: 5.9575316132977605. Arrivals time: 0.3277155105024576 Scheduler time: 5.488517396617681 Scheduler overhead time: 0.04739313060417771 Adapter cache time: 0.022983725648373365 Engine time: 0.0486132986843586 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-16/adapters_160_slots_96_rate_3.2-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-16/adapters_160_slots_96_rate_3.2-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [53 53 54]
Adapter prompts. [33, 34560, 33, 33, 540, 33, 33, 33, 34560, 33, 540, 34560, 540, 33, 540, 540, 540, 540, 34560, 34560, 34560, 540, 540, 540, 34560, 34560, 33, 34560, 540, 34560, 34560, 34560, 540, 34560, 33, 540, 540, 540, 34560, 33, 33, 34560, 33, 34560, 33, 33, 540, 33, 540, 34560, 33, 33, 540, 33, 33, 33, 33, 33, 34560, 540, 540, 34560, 540, 33, 34560, 34560, 34560, 540, 540, 33, 33, 33, 34560, 33, 540, 540, 33, 34560, 34560, 34560, 33, 33, 34560, 540, 34560, 34560, 33, 34560, 33, 540, 33, 33, 540, 540, 34560, 34560, 34560, 33, 34560, 540, 540, 33, 33, 33, 33, 34560, 540, 34560, 540, 34560, 34560, 34560, 33, 540, 540, 34560, 540, 34560, 33, 33, 33, 540, 540, 540, 34560, 34560, 540, 34560, 33, 540, 540, 33, 34560, 34560, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 540, 34560, 33, 34560, 33, 34560, 540, 33, 540, 33, 33, 540, 540, 540, 34560, 540, 33, 33]
Prompts retrieved: 1896609 . Total input tokens: 422992933 . Total output tokens: 372560486
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.812241235282272,
    "estimated_duration": 3600.077473021573,
    "input_throughput": 5441.583451135527,
    "output_throughput": 4725.802466056555,
    "total_throughput": 10167.385917192083,
    "itl": 102.5022443042482,
    "ttft": 2056033.8881232673,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 442,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.2353829057794106,
    "arrivals": 632045,
    "finished_requests": 79182,
    "scheduler_time": 115.54360351293577
}
#Debug simulation 
Total elapsed time: 5.812358288094401. Arrivals time: 0.30026353942230344 Scheduler time: 5.3602662165649235 Scheduler overhead time: 0.05148925352841616 Adapter cache time: 0.023088242392987013 Engine time: 0.05299790995195508 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-32/adapters_160_slots_96_rate_3.2-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-32/adapters_160_slots_96_rate_3.2-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [53 53 54]
Adapter prompts. [33, 34560, 33, 33, 540, 33, 33, 33, 34560, 33, 540, 34560, 540, 33, 540, 540, 540, 540, 34560, 34560, 34560, 540, 540, 540, 34560, 34560, 33, 34560, 540, 34560, 34560, 34560, 540, 34560, 33, 540, 540, 540, 34560, 33, 33, 34560, 33, 34560, 33, 33, 540, 33, 540, 34560, 33, 33, 540, 33, 33, 33, 33, 33, 34560, 540, 540, 34560, 540, 33, 34560, 34560, 34560, 540, 540, 33, 33, 33, 34560, 33, 540, 540, 33, 34560, 34560, 34560, 33, 33, 34560, 540, 34560, 34560, 33, 34560, 33, 540, 33, 33, 540, 540, 34560, 34560, 34560, 33, 34560, 540, 540, 33, 33, 33, 33, 34560, 540, 34560, 540, 34560, 34560, 34560, 33, 540, 540, 34560, 540, 34560, 33, 33, 33, 540, 540, 540, 34560, 34560, 540, 34560, 33, 540, 540, 33, 34560, 34560, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 540, 34560, 33, 34560, 33, 34560, 540, 33, 540, 33, 33, 540, 540, 540, 34560, 540, 33, 33]
Prompts retrieved: 1896609 . Total input tokens: 422992933 . Total output tokens: 372560486
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.3203383521176875,
    "estimated_duration": 3600.0761799249576,
    "input_throughput": 4928.179881007358,
    "output_throughput": 4263.435336615554,
    "total_throughput": 9191.615217622912,
    "itl": 81.21718408888277,
    "ttft": 2117339.488898085,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 400,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.004866905380062,
    "arrivals": 632045,
    "finished_requests": 71636,
    "scheduler_time": 120.92059618994872
}
#Debug simulation 
Total elapsed time: 5.320428914856166. Arrivals time: 0.28708597319200635 Scheduler time: 4.854650001972914 Scheduler overhead time: 0.06155114620923996 Adapter cache time: 0.02491322299465537 Engine time: 0.06300775613635778 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.003125_size_8-16-16/adapters_160_slots_96_rate_3.2-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.003125_size_8-16-16/adapters_160_slots_96_rate_3.2-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [53 53 54]
Adapter prompts. [33, 34560, 33, 33, 540, 33, 33, 33, 34560, 33, 540, 34560, 540, 33, 540, 540, 540, 540, 34560, 34560, 34560, 540, 540, 540, 34560, 34560, 33, 34560, 540, 34560, 34560, 34560, 540, 34560, 33, 540, 540, 540, 34560, 33, 33, 34560, 33, 34560, 33, 33, 540, 33, 540, 34560, 33, 33, 540, 33, 33, 33, 33, 33, 34560, 540, 540, 34560, 540, 33, 34560, 34560, 34560, 540, 540, 33, 33, 33, 34560, 33, 540, 540, 33, 34560, 34560, 34560, 33, 33, 34560, 540, 34560, 34560, 33, 34560, 33, 540, 33, 33, 540, 540, 34560, 34560, 34560, 33, 34560, 540, 540, 33, 33, 33, 33, 34560, 540, 34560, 540, 34560, 34560, 34560, 33, 540, 540, 34560, 540, 34560, 33, 33, 33, 540, 540, 540, 34560, 34560, 540, 34560, 33, 540, 540, 33, 34560, 34560, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 540, 34560, 33, 34560, 33, 34560, 540, 33, 540, 33, 33, 540, 540, 540, 34560, 540, 33, 33]
Prompts retrieved: 1896609 . Total input tokens: 422992933 . Total output tokens: 372560486
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 5.792471252847463,
    "estimated_duration": 3600.0972142284168,
    "input_throughput": 5442.028321504362,
    "output_throughput": 4725.937658782488,
    "total_throughput": 10167.96598028685,
    "itl": 102.49720039677206,
    "ttft": 2055934.4183683302,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 442,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.022985096862535,
    "arrivals": 632045,
    "finished_requests": 79187,
    "scheduler_time": 115.55021759483131
}
#Debug simulation 
Total elapsed time: 5.792562999762595. Arrivals time: 0.2440581563860178 Scheduler time: 5.397032083012164 Scheduler overhead time: 0.05131393251940608 Adapter cache time: 0.02315458608791232 Engine time: 0.052677493542432785 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.003125_size_8-16-32/adapters_160_slots_96_rate_3.2-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.003125_size_8-16-32/adapters_160_slots_96_rate_3.2-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [53 53 54]
Adapter prompts. [33, 34560, 33, 33, 540, 33, 33, 33, 34560, 33, 540, 34560, 540, 33, 540, 540, 540, 540, 34560, 34560, 34560, 540, 540, 540, 34560, 34560, 33, 34560, 540, 34560, 34560, 34560, 540, 34560, 33, 540, 540, 540, 34560, 33, 33, 34560, 33, 34560, 33, 33, 540, 33, 540, 34560, 33, 33, 540, 33, 33, 33, 33, 33, 34560, 540, 540, 34560, 540, 33, 34560, 34560, 34560, 540, 540, 33, 33, 33, 34560, 33, 540, 540, 33, 34560, 34560, 34560, 33, 33, 34560, 540, 34560, 34560, 33, 34560, 33, 540, 33, 33, 540, 540, 34560, 34560, 34560, 33, 34560, 540, 540, 33, 33, 33, 33, 34560, 540, 34560, 540, 34560, 34560, 34560, 33, 540, 540, 34560, 540, 34560, 33, 33, 33, 540, 540, 540, 34560, 34560, 540, 34560, 33, 540, 540, 33, 34560, 34560, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 540, 34560, 33, 34560, 33, 34560, 540, 33, 540, 33, 33, 540, 540, 540, 34560, 540, 33, 33]
Prompts retrieved: 1896609 . Total input tokens: 422992933 . Total output tokens: 372560486
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 5.334992189891636,
    "estimated_duration": 3600.0466478053786,
    "input_throughput": 4928.220308149501,
    "output_throughput": 4263.470310685198,
    "total_throughput": 9191.690618834698,
    "itl": 81.21652712721037,
    "ttft": 2117326.88358798,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 400,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.9754562663007738,
    "arrivals": 632045,
    "finished_requests": 71636,
    "scheduler_time": 120.92047470944915
}
#Debug simulation 
Total elapsed time: 5.335092585068196. Arrivals time: 0.3201512275263667 Scheduler time: 4.836485106963664 Scheduler overhead time: 0.0615381826646626 Adapter cache time: 0.024867813102900982 Engine time: 0.06302590714767575 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.003125_size_16-16-16/adapters_160_slots_96_rate_3.2-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.003125_size_16-16-16/adapters_160_slots_96_rate_3.2-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [53 53 54]
Adapter prompts. [33, 34560, 33, 33, 540, 33, 33, 33, 34560, 33, 540, 34560, 540, 33, 540, 540, 540, 540, 34560, 34560, 34560, 540, 540, 540, 34560, 34560, 33, 34560, 540, 34560, 34560, 34560, 540, 34560, 33, 540, 540, 540, 34560, 33, 33, 34560, 33, 34560, 33, 33, 540, 33, 540, 34560, 33, 33, 540, 33, 33, 33, 33, 33, 34560, 540, 540, 34560, 540, 33, 34560, 34560, 34560, 540, 540, 33, 33, 33, 34560, 33, 540, 540, 33, 34560, 34560, 34560, 33, 33, 34560, 540, 34560, 34560, 33, 34560, 33, 540, 33, 33, 540, 540, 34560, 34560, 34560, 33, 34560, 540, 540, 33, 33, 33, 33, 34560, 540, 34560, 540, 34560, 34560, 34560, 33, 540, 540, 34560, 540, 34560, 33, 33, 33, 540, 540, 540, 34560, 34560, 540, 34560, 33, 540, 540, 33, 34560, 34560, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 540, 34560, 33, 34560, 33, 34560, 540, 33, 540, 33, 33, 540, 540, 540, 34560, 540, 33, 33]
Prompts retrieved: 1896609 . Total input tokens: 422992933 . Total output tokens: 372560486
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.814503773115575,
    "estimated_duration": 3600.0115189485405,
    "input_throughput": 5442.222864254133,
    "output_throughput": 4726.209321955008,
    "total_throughput": 10168.432186209142,
    "itl": 102.4920065597649,
    "ttft": 2055838.6544969298,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 442,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.8216930557321636,
    "arrivals": 632045,
    "finished_requests": 79189,
    "scheduler_time": 115.55319782550617
}
#Debug simulation 
Total elapsed time: 5.814589635003358. Arrivals time: 0.24298212258145213 Scheduler time: 5.420852334238589 Scheduler overhead time: 0.05118904169648886 Adapter cache time: 0.023104536347091198 Engine time: 0.052331788931041956 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.003125_size_16-16-32/adapters_160_slots_96_rate_3.2-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.05-0.003125_size_16-16-32/adapters_160_slots_96_rate_3.2-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [53 53 54]
Adapter prompts. [33, 34560, 33, 33, 540, 33, 33, 33, 34560, 33, 540, 34560, 540, 33, 540, 540, 540, 540, 34560, 34560, 34560, 540, 540, 540, 34560, 34560, 33, 34560, 540, 34560, 34560, 34560, 540, 34560, 33, 540, 540, 540, 34560, 33, 33, 34560, 33, 34560, 33, 33, 540, 33, 540, 34560, 33, 33, 540, 33, 33, 33, 33, 33, 34560, 540, 540, 34560, 540, 33, 34560, 34560, 34560, 540, 540, 33, 33, 33, 34560, 33, 540, 540, 33, 34560, 34560, 34560, 33, 33, 34560, 540, 34560, 34560, 33, 34560, 33, 540, 33, 33, 540, 540, 34560, 34560, 34560, 33, 34560, 540, 540, 33, 33, 33, 33, 34560, 540, 34560, 540, 34560, 34560, 34560, 33, 540, 540, 34560, 540, 34560, 33, 33, 33, 540, 540, 540, 34560, 34560, 540, 34560, 33, 540, 540, 33, 34560, 34560, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 540, 34560, 33, 34560, 33, 34560, 540, 33, 540, 33, 33, 540, 540, 540, 34560, 540, 33, 33]
Prompts retrieved: 1896609 . Total input tokens: 422992933 . Total output tokens: 372560486
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.6047718189656734,
    "estimated_duration": 3600.0204357937955,
    "input_throughput": 4928.256190881309,
    "output_throughput": 4263.501353323749,
    "total_throughput": 9191.757544205058,
    "itl": 81.21596988894497,
    "ttft": 2117315.1108911177,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 400,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.949359502047321,
    "arrivals": 632045,
    "finished_requests": 71636,
    "scheduler_time": 120.92035946211934
}
#Debug simulation 
Total elapsed time: 5.604833491612226. Arrivals time: 0.6119446218945086 Scheduler time: 4.813098753802478 Scheduler overhead time: 0.06277511455118656 Adapter cache time: 0.024882077239453793 Engine time: 0.06313589680939913 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-8/adapters_160_slots_96_rate_3.2-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-8/adapters_160_slots_96_rate_3.2-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [53 53 54]
Adapter prompts. [135, 34560, 135, 135, 270, 135, 135, 135, 34560, 135, 270, 34560, 270, 135, 270, 270, 270, 270, 34560, 34560, 34560, 270, 270, 270, 34560, 34560, 135, 34560, 270, 34560, 34560, 34560, 270, 34560, 135, 270, 270, 270, 34560, 135, 135, 34560, 135, 34560, 135, 135, 270, 135, 270, 34560, 135, 135, 270, 135, 135, 135, 135, 135, 34560, 270, 270, 34560, 270, 135, 34560, 34560, 34560, 270, 270, 135, 135, 135, 34560, 135, 270, 270, 135, 34560, 34560, 34560, 135, 135, 34560, 270, 34560, 34560, 135, 34560, 135, 270, 135, 135, 270, 270, 34560, 34560, 34560, 135, 34560, 270, 270, 135, 135, 135, 135, 34560, 270, 34560, 270, 34560, 34560, 34560, 135, 270, 270, 34560, 270, 34560, 135, 135, 135, 270, 270, 270, 34560, 34560, 270, 34560, 135, 270, 270, 135, 34560, 34560, 34560, 34560, 34560, 34560, 270, 270, 270, 270, 270, 34560, 135, 34560, 135, 34560, 270, 135, 270, 135, 135, 270, 270, 270, 34560, 270, 135, 135]
Prompts retrieved: 1887705 . Total input tokens: 421040890 . Total output tokens: 370772489
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.999599989037961,
    "estimated_duration": 3600.116327271508,
    "input_throughput": 5677.023502040478,
    "output_throughput": 4957.711745255487,
    "total_throughput": 10634.735247295965,
    "itl": 110.99999136095147,
    "ttft": 2028273.1750472782,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 597,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.947608192074173,
    "arrivals": 629108,
    "finished_requests": 82935,
    "scheduler_time": 115.35234480818146
}
#Debug simulation 
Total elapsed time: 5.999691158067435. Arrivals time: 0.30537156062200665 Scheduler time: 5.554886119905859 Scheduler overhead time: 0.04790289141237736 Adapter cache time: 0.02009321330115199 Engine time: 0.04891632730141282 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-16/adapters_160_slots_96_rate_3.2-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-16/adapters_160_slots_96_rate_3.2-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [53 53 54]
Adapter prompts. [135, 34560, 135, 135, 270, 135, 135, 135, 34560, 135, 270, 34560, 270, 135, 270, 270, 270, 270, 34560, 34560, 34560, 270, 270, 270, 34560, 34560, 135, 34560, 270, 34560, 34560, 34560, 270, 34560, 135, 270, 270, 270, 34560, 135, 135, 34560, 135, 34560, 135, 135, 270, 135, 270, 34560, 135, 135, 270, 135, 135, 135, 135, 135, 34560, 270, 270, 34560, 270, 135, 34560, 34560, 34560, 270, 270, 135, 135, 135, 34560, 135, 270, 270, 135, 34560, 34560, 34560, 135, 135, 34560, 270, 34560, 34560, 135, 34560, 135, 270, 135, 135, 270, 270, 34560, 34560, 34560, 135, 34560, 270, 270, 135, 135, 135, 135, 34560, 270, 34560, 270, 34560, 34560, 34560, 135, 270, 270, 34560, 270, 34560, 135, 135, 135, 270, 270, 270, 34560, 34560, 270, 34560, 135, 270, 270, 135, 34560, 34560, 34560, 34560, 34560, 34560, 270, 270, 270, 270, 270, 34560, 135, 34560, 135, 34560, 270, 135, 270, 135, 135, 270, 270, 270, 34560, 270, 135, 135]
Prompts retrieved: 1887705 . Total input tokens: 421040890 . Total output tokens: 370772489
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.827312648296356,
    "estimated_duration": 3600.017399706904,
    "input_throughput": 5484.370714876946,
    "output_throughput": 4795.035713273332,
    "total_throughput": 10279.406428150278,
    "itl": 100.89488863323564,
    "ttft": 2047008.8751698483,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 582,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.251295283110818,
    "arrivals": 629108,
    "finished_requests": 80116,
    "scheduler_time": 117.24010742133434
}
#Debug simulation 
Total elapsed time: 5.827403545379639. Arrivals time: 0.3046203413978219 Scheduler time: 5.371617717202753 Scheduler overhead time: 0.051927302964031696 Adapter cache time: 0.021054773591458797 Engine time: 0.05361730931326747 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-32/adapters_160_slots_96_rate_3.2-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-32/adapters_160_slots_96_rate_3.2-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [53 53 54]
Adapter prompts. [135, 34560, 135, 135, 270, 135, 135, 135, 34560, 135, 270, 34560, 270, 135, 270, 270, 270, 270, 34560, 34560, 34560, 270, 270, 270, 34560, 34560, 135, 34560, 270, 34560, 34560, 34560, 270, 34560, 135, 270, 270, 270, 34560, 135, 135, 34560, 135, 34560, 135, 135, 270, 135, 270, 34560, 135, 135, 270, 135, 135, 135, 135, 135, 34560, 270, 270, 34560, 270, 135, 34560, 34560, 34560, 270, 270, 135, 135, 135, 34560, 135, 270, 270, 135, 34560, 34560, 34560, 135, 135, 34560, 270, 34560, 34560, 135, 34560, 135, 270, 135, 135, 270, 270, 34560, 34560, 34560, 135, 34560, 270, 270, 135, 135, 135, 135, 34560, 270, 34560, 270, 34560, 34560, 34560, 135, 270, 270, 34560, 270, 34560, 135, 135, 135, 270, 270, 270, 34560, 34560, 270, 34560, 135, 270, 270, 135, 34560, 34560, 34560, 34560, 34560, 34560, 270, 270, 270, 270, 270, 34560, 135, 34560, 135, 34560, 270, 135, 270, 135, 135, 270, 270, 270, 34560, 270, 135, 135]
Prompts retrieved: 1887705 . Total input tokens: 421040890 . Total output tokens: 370772489
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.33812058204785,
    "estimated_duration": 3600.051858549195,
    "input_throughput": 4922.710198719718,
    "output_throughput": 4311.3106726898295,
    "total_throughput": 9234.020871409548,
    "itl": 80.29373160344262,
    "ttft": 2107262.3853524644,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 516,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.8682127417577763,
    "arrivals": 629108,
    "finished_requests": 72021,
    "scheduler_time": 122.23121175501512
}
#Debug simulation 
Total elapsed time: 5.338212813716382. Arrivals time: 0.2869710084050894 Scheduler time: 4.87446798896417 Scheduler overhead time: 0.061999133322387934 Adapter cache time: 0.022152357269078493 Engine time: 0.0634120455943048 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.0125_size_8-16-16/adapters_160_slots_96_rate_3.2-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.0125_size_8-16-16/adapters_160_slots_96_rate_3.2-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [53 53 54]
Adapter prompts. [135, 34560, 135, 135, 270, 135, 135, 135, 34560, 135, 270, 34560, 270, 135, 270, 270, 270, 270, 34560, 34560, 34560, 270, 270, 270, 34560, 34560, 135, 34560, 270, 34560, 34560, 34560, 270, 34560, 135, 270, 270, 270, 34560, 135, 135, 34560, 135, 34560, 135, 135, 270, 135, 270, 34560, 135, 135, 270, 135, 135, 135, 135, 135, 34560, 270, 270, 34560, 270, 135, 34560, 34560, 34560, 270, 270, 135, 135, 135, 34560, 135, 270, 270, 135, 34560, 34560, 34560, 135, 135, 34560, 270, 34560, 34560, 135, 34560, 135, 270, 135, 135, 270, 270, 34560, 34560, 34560, 135, 34560, 270, 270, 135, 135, 135, 135, 34560, 270, 34560, 270, 34560, 34560, 34560, 135, 270, 270, 34560, 270, 34560, 135, 135, 135, 270, 270, 270, 34560, 34560, 270, 34560, 135, 270, 270, 135, 34560, 34560, 34560, 34560, 34560, 34560, 270, 270, 270, 270, 270, 34560, 135, 34560, 135, 34560, 270, 135, 270, 135, 135, 270, 270, 270, 34560, 270, 135, 135]
Prompts retrieved: 1887705 . Total input tokens: 421040890 . Total output tokens: 370772489
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 5.815902351867408,
    "estimated_duration": 3600.097261129376,
    "input_throughput": 5484.751818567716,
    "output_throughput": 4794.980176336865,
    "total_throughput": 10279.731994904581,
    "itl": 100.88634714149424,
    "ttft": 2046921.0521838989,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 582,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.997250844994555,
    "arrivals": 629108,
    "finished_requests": 80121,
    "scheduler_time": 117.2502834086061
}
#Debug simulation 
Total elapsed time: 5.815995579119772. Arrivals time: 0.30203167675063014 Scheduler time: 5.3639542907476425 Scheduler overhead time: 0.05196702852845192 Adapter cache time: 0.02075812639668584 Engine time: 0.05283076921477914 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.0125_size_8-16-32/adapters_160_slots_96_rate_3.2-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.0125_size_8-16-32/adapters_160_slots_96_rate_3.2-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [53 53 54]
Adapter prompts. [135, 34560, 135, 135, 270, 135, 135, 135, 34560, 135, 270, 34560, 270, 135, 270, 270, 270, 270, 34560, 34560, 34560, 270, 270, 270, 34560, 34560, 135, 34560, 270, 34560, 34560, 34560, 270, 34560, 135, 270, 270, 270, 34560, 135, 135, 34560, 135, 34560, 135, 135, 270, 135, 270, 34560, 135, 135, 270, 135, 135, 135, 135, 135, 34560, 270, 270, 34560, 270, 135, 34560, 34560, 34560, 270, 270, 135, 135, 135, 34560, 135, 270, 270, 135, 34560, 34560, 34560, 135, 135, 34560, 270, 34560, 34560, 135, 34560, 135, 270, 135, 135, 270, 270, 34560, 34560, 34560, 135, 34560, 270, 270, 135, 135, 135, 135, 34560, 270, 34560, 270, 34560, 34560, 34560, 135, 270, 270, 34560, 270, 34560, 135, 135, 135, 270, 270, 270, 34560, 34560, 270, 34560, 135, 270, 270, 135, 34560, 34560, 34560, 34560, 34560, 34560, 270, 270, 270, 270, 270, 34560, 135, 34560, 135, 34560, 270, 135, 270, 135, 135, 270, 270, 270, 34560, 270, 135, 135]
Prompts retrieved: 1887705 . Total input tokens: 421040890 . Total output tokens: 370772489
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 5.35469426587224,
    "estimated_duration": 3600.0173472622773,
    "input_throughput": 4922.757389899009,
    "output_throughput": 4311.3520027350105,
    "total_throughput": 9234.109392634018,
    "itl": 80.29294554575269,
    "ttft": 2107247.739722709,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 516,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.833831290439736,
    "arrivals": 629108,
    "finished_requests": 72021,
    "scheduler_time": 122.23108191941571
}
#Debug simulation 
Total elapsed time: 5.35478907590732. Arrivals time: 0.2985279392451048 Scheduler time: 4.8791041183285415 Scheduler overhead time: 0.061906058341264725 Adapter cache time: 0.02212259778752923 Engine time: 0.06375826522707939 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.0125_size_16-16-16/adapters_160_slots_96_rate_3.2-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.0125_size_16-16-16/adapters_160_slots_96_rate_3.2-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [53 53 54]
Adapter prompts. [135, 34560, 135, 135, 270, 135, 135, 135, 34560, 135, 270, 34560, 270, 135, 270, 270, 270, 270, 34560, 34560, 34560, 270, 270, 270, 34560, 34560, 135, 34560, 270, 34560, 34560, 34560, 270, 34560, 135, 270, 270, 270, 34560, 135, 135, 34560, 135, 34560, 135, 135, 270, 135, 270, 34560, 135, 135, 270, 135, 135, 135, 135, 135, 34560, 270, 270, 34560, 270, 135, 34560, 34560, 34560, 270, 270, 135, 135, 135, 34560, 135, 270, 270, 135, 34560, 34560, 34560, 135, 135, 34560, 270, 34560, 34560, 135, 34560, 135, 270, 135, 135, 270, 270, 34560, 34560, 34560, 135, 34560, 270, 270, 135, 135, 135, 135, 34560, 270, 34560, 270, 34560, 34560, 34560, 135, 270, 270, 34560, 270, 34560, 135, 135, 135, 270, 270, 270, 34560, 34560, 270, 34560, 135, 270, 270, 135, 34560, 34560, 34560, 34560, 34560, 34560, 270, 270, 270, 270, 270, 34560, 135, 34560, 135, 34560, 270, 135, 270, 135, 135, 270, 270, 270, 34560, 270, 135, 135]
Prompts retrieved: 1887705 . Total input tokens: 421040890 . Total output tokens: 370772489
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.859633414074779,
    "estimated_duration": 3600.03709350383,
    "input_throughput": 5485.305702997749,
    "output_throughput": 4795.473366413977,
    "total_throughput": 10280.779069411727,
    "itl": 100.87922224728736,
    "ttft": 2046797.3201895047,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 582,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.7154419874120332,
    "arrivals": 629108,
    "finished_requests": 80129,
    "scheduler_time": 117.25694483728007
}
#Debug simulation 
Total elapsed time: 5.859728496987373. Arrivals time: 0.3029371602460742 Scheduler time: 5.406199520919472 Scheduler overhead time: 0.05174957076087594 Adapter cache time: 0.02104609366506338 Engine time: 0.05304968636482954 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.0125_size_16-16-32/adapters_160_slots_96_rate_3.2-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.0125_size_16-16-32/adapters_160_slots_96_rate_3.2-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [53 53 54]
Adapter prompts. [135, 34560, 135, 135, 270, 135, 135, 135, 34560, 135, 270, 34560, 270, 135, 270, 270, 270, 270, 34560, 34560, 34560, 270, 270, 270, 34560, 34560, 135, 34560, 270, 34560, 34560, 34560, 270, 34560, 135, 270, 270, 270, 34560, 135, 135, 34560, 135, 34560, 135, 135, 270, 135, 270, 34560, 135, 135, 270, 135, 135, 135, 135, 135, 34560, 270, 270, 34560, 270, 135, 34560, 34560, 34560, 270, 270, 135, 135, 135, 34560, 135, 270, 270, 135, 34560, 34560, 34560, 135, 135, 34560, 270, 34560, 34560, 135, 34560, 135, 270, 135, 135, 270, 270, 34560, 34560, 34560, 135, 34560, 270, 270, 135, 135, 135, 135, 34560, 270, 34560, 270, 34560, 34560, 34560, 135, 270, 270, 34560, 270, 34560, 135, 135, 135, 270, 270, 270, 34560, 34560, 270, 34560, 135, 270, 270, 135, 34560, 34560, 34560, 34560, 34560, 34560, 270, 270, 270, 270, 270, 34560, 135, 34560, 135, 34560, 270, 135, 270, 135, 135, 270, 270, 270, 34560, 270, 135, 135]
Prompts retrieved: 1887705 . Total input tokens: 421040890 . Total output tokens: 370772489
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.329583875834942,
    "estimated_duration": 3600.0688997649745,
    "input_throughput": 4922.896614883401,
    "output_throughput": 4311.3547079649725,
    "total_throughput": 9234.251322848373,
    "itl": 80.29218356086368,
    "ttft": 2107227.784334641,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 516,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.7975857845321626,
    "arrivals": 629108,
    "finished_requests": 72022,
    "scheduler_time": 122.23404147861153
}
#Debug simulation 
Total elapsed time: 5.329673400148749. Arrivals time: 0.2845488674938679 Scheduler time: 4.86614656355232 Scheduler overhead time: 0.06436820421367884 Adapter cache time: 0.021952274721115828 Engine time: 0.0634456230327487 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-8/adapters_160_slots_96_rate_3.2-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-8/adapters_160_slots_96_rate_3.2-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [53 53 54]
Adapter prompts. [66, 34560, 66, 66, 270, 66, 66, 66, 34560, 66, 270, 34560, 270, 66, 270, 270, 270, 270, 34560, 34560, 34560, 270, 270, 270, 34560, 34560, 66, 34560, 270, 34560, 34560, 34560, 270, 34560, 66, 270, 270, 270, 34560, 66, 66, 34560, 66, 34560, 66, 66, 270, 66, 270, 34560, 66, 66, 270, 66, 66, 66, 66, 66, 34560, 270, 270, 34560, 270, 66, 34560, 34560, 34560, 270, 270, 66, 66, 66, 34560, 66, 270, 270, 66, 34560, 34560, 34560, 66, 66, 34560, 270, 34560, 34560, 66, 34560, 66, 270, 66, 66, 270, 270, 34560, 34560, 34560, 66, 34560, 270, 270, 66, 66, 66, 66, 34560, 270, 34560, 270, 34560, 34560, 34560, 66, 270, 270, 34560, 270, 34560, 66, 66, 66, 270, 270, 270, 34560, 34560, 270, 34560, 66, 270, 270, 66, 34560, 34560, 34560, 34560, 34560, 34560, 270, 270, 270, 270, 270, 34560, 66, 34560, 66, 34560, 270, 66, 270, 66, 66, 270, 270, 270, 34560, 270, 66, 66]
Prompts retrieved: 1884048 . Total input tokens: 420228146 . Total output tokens: 370028549
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.99239419028163,
    "estimated_duration": 3600.040248136738,
    "input_throughput": 5718.738286510966,
    "output_throughput": 4987.503961738491,
    "total_throughput": 10706.242248249457,
    "itl": 110.90603878154032,
    "ttft": 2027861.683386144,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 455,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.0086461095372514,
    "arrivals": 627971,
    "finished_requests": 83647,
    "scheduler_time": 115.81353103766897
}
#Debug simulation 
Total elapsed time: 5.9924901612102985. Arrivals time: 0.24967995192855597 Scheduler time: 5.604187992401421 Scheduler overhead time: 0.048097018618136644 Adapter cache time: 0.018612789921462536 Engine time: 0.049275978934019804 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-16/adapters_160_slots_96_rate_3.2-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-16/adapters_160_slots_96_rate_3.2-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [53 53 54]
Adapter prompts. [66, 34560, 66, 66, 270, 66, 66, 66, 34560, 66, 270, 34560, 270, 66, 270, 270, 270, 270, 34560, 34560, 34560, 270, 270, 270, 34560, 34560, 66, 34560, 270, 34560, 34560, 34560, 270, 34560, 66, 270, 270, 270, 34560, 66, 66, 34560, 66, 34560, 66, 66, 270, 66, 270, 34560, 66, 66, 270, 66, 66, 66, 66, 66, 34560, 270, 270, 34560, 270, 66, 34560, 34560, 34560, 270, 270, 66, 66, 66, 34560, 66, 270, 270, 66, 34560, 34560, 34560, 66, 66, 34560, 270, 34560, 34560, 66, 34560, 66, 270, 66, 66, 270, 270, 34560, 34560, 34560, 66, 34560, 270, 270, 66, 66, 66, 66, 34560, 270, 34560, 270, 34560, 34560, 34560, 66, 270, 270, 34560, 270, 34560, 66, 66, 66, 270, 270, 270, 34560, 34560, 270, 34560, 66, 270, 270, 66, 34560, 34560, 34560, 34560, 34560, 34560, 270, 270, 270, 270, 270, 34560, 66, 34560, 66, 34560, 270, 66, 270, 66, 66, 270, 270, 270, 34560, 270, 66, 66]
Prompts retrieved: 1884048 . Total input tokens: 420228146 . Total output tokens: 370028549
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.794178689364344,
    "estimated_duration": 3600.024527687311,
    "input_throughput": 5519.369617396631,
    "output_throughput": 4817.759119864102,
    "total_throughput": 10337.128737260733,
    "itl": 100.90445758280985,
    "ttft": 2045820.1596691585,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 445,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.2517582266544958,
    "arrivals": 627971,
    "finished_requests": 80712,
    "scheduler_time": 117.59785832584475
}
#Debug simulation 
Total elapsed time: 5.794266816228628. Arrivals time: 0.24126957822591066 Scheduler time: 5.405345775652677 Scheduler overhead time: 0.051773933693766594 Adapter cache time: 0.018659119959920645 Engine time: 0.05288595054298639 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-32/adapters_160_slots_96_rate_3.2-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-32/adapters_160_slots_96_rate_3.2-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [53 53 54]
Adapter prompts. [66, 34560, 66, 66, 270, 66, 66, 66, 34560, 66, 270, 34560, 270, 66, 270, 270, 270, 270, 34560, 34560, 34560, 270, 270, 270, 34560, 34560, 66, 34560, 270, 34560, 34560, 34560, 270, 34560, 66, 270, 270, 270, 34560, 66, 66, 34560, 66, 34560, 66, 66, 270, 66, 270, 34560, 66, 66, 270, 66, 66, 66, 66, 66, 34560, 270, 270, 34560, 270, 66, 34560, 34560, 34560, 270, 270, 66, 66, 66, 34560, 66, 270, 270, 66, 34560, 34560, 34560, 66, 66, 34560, 270, 34560, 34560, 66, 34560, 66, 270, 66, 66, 270, 270, 34560, 34560, 34560, 66, 34560, 270, 270, 66, 66, 66, 66, 34560, 270, 34560, 270, 34560, 34560, 34560, 66, 270, 270, 34560, 270, 34560, 66, 66, 66, 270, 270, 270, 34560, 34560, 270, 34560, 66, 270, 270, 66, 34560, 34560, 34560, 34560, 34560, 34560, 270, 270, 270, 270, 270, 34560, 66, 34560, 66, 34560, 270, 66, 270, 66, 66, 270, 270, 270, 34560, 270, 66, 66]
Prompts retrieved: 1884048 . Total input tokens: 420228146 . Total output tokens: 370028549
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.292025434784591,
    "estimated_duration": 3600.0242064565737,
    "input_throughput": 4962.914962615133,
    "output_throughput": 4326.195632814802,
    "total_throughput": 9289.110595429935,
    "itl": 80.30454513190136,
    "ttft": 2108589.021952347,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 416,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.1187048218073543,
    "arrivals": 627971,
    "finished_requests": 72543,
    "scheduler_time": 122.46351670702411
}
#Debug simulation 
Total elapsed time: 5.292113807052374. Arrivals time: 0.22651656018570065 Scheduler time: 4.8898527645505965 Scheduler overhead time: 0.06181697128340602 Adapter cache time: 0.021165229845792055 Engine time: 0.06360642099753022 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.00625_size_8-16-16/adapters_160_slots_96_rate_3.2-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.00625_size_8-16-16/adapters_160_slots_96_rate_3.2-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [53 53 54]
Adapter prompts. [66, 34560, 66, 66, 270, 66, 66, 66, 34560, 66, 270, 34560, 270, 66, 270, 270, 270, 270, 34560, 34560, 34560, 270, 270, 270, 34560, 34560, 66, 34560, 270, 34560, 34560, 34560, 270, 34560, 66, 270, 270, 270, 34560, 66, 66, 34560, 66, 34560, 66, 66, 270, 66, 270, 34560, 66, 66, 270, 66, 66, 66, 66, 66, 34560, 270, 270, 34560, 270, 66, 34560, 34560, 34560, 270, 270, 66, 66, 66, 34560, 66, 270, 270, 66, 34560, 34560, 34560, 66, 66, 34560, 270, 34560, 34560, 66, 34560, 66, 270, 66, 66, 270, 270, 34560, 34560, 34560, 66, 34560, 270, 270, 66, 66, 66, 66, 34560, 270, 34560, 270, 34560, 34560, 34560, 66, 270, 270, 34560, 270, 34560, 66, 66, 66, 270, 270, 270, 34560, 34560, 270, 34560, 66, 270, 270, 66, 34560, 34560, 34560, 34560, 34560, 34560, 270, 270, 270, 270, 270, 34560, 66, 34560, 66, 34560, 270, 66, 270, 66, 66, 270, 270, 270, 34560, 270, 66, 66]
Prompts retrieved: 1884048 . Total input tokens: 420228146 . Total output tokens: 370028549
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 5.822374012786895,
    "estimated_duration": 3600.043179220689,
    "input_throughput": 5519.603796613764,
    "output_throughput": 4817.879157703499,
    "total_throughput": 10337.482954317262,
    "itl": 100.89838815029107,
    "ttft": 2045855.540275341,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 445,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.051854406497437,
    "arrivals": 627971,
    "finished_requests": 80717,
    "scheduler_time": 117.60440192254167
}
#Debug simulation 
Total elapsed time: 5.8224836378358305. Arrivals time: 0.2525957594625652 Scheduler time: 5.42197787668556 Scheduler overhead time: 0.05179531034082174 Adapter cache time: 0.01878195209428668 Engine time: 0.05287688272073865 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.00625_size_8-16-32/adapters_160_slots_96_rate_3.2-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.00625_size_8-16-32/adapters_160_slots_96_rate_3.2-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [53 53 54]
Adapter prompts. [66, 34560, 66, 66, 270, 66, 66, 66, 34560, 66, 270, 34560, 270, 66, 270, 270, 270, 270, 34560, 34560, 34560, 270, 270, 270, 34560, 34560, 66, 34560, 270, 34560, 34560, 34560, 270, 34560, 66, 270, 270, 270, 34560, 66, 66, 34560, 66, 34560, 66, 66, 270, 66, 270, 34560, 66, 66, 270, 66, 66, 66, 66, 66, 34560, 270, 270, 34560, 270, 66, 34560, 34560, 34560, 270, 270, 66, 66, 66, 34560, 66, 270, 270, 66, 34560, 34560, 34560, 66, 66, 34560, 270, 34560, 34560, 66, 34560, 66, 270, 66, 66, 270, 270, 34560, 34560, 34560, 66, 34560, 270, 270, 66, 66, 66, 66, 34560, 270, 34560, 270, 34560, 34560, 34560, 66, 270, 270, 34560, 270, 34560, 66, 66, 66, 270, 270, 270, 34560, 34560, 270, 34560, 66, 270, 270, 66, 34560, 34560, 34560, 34560, 34560, 34560, 270, 270, 270, 270, 270, 34560, 66, 34560, 66, 34560, 270, 66, 270, 66, 66, 270, 270, 270, 34560, 270, 66, 66]
Prompts retrieved: 1884048 . Total input tokens: 420228146 . Total output tokens: 370028549
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 5.301529219374061,
    "estimated_duration": 3600.0885286581665,
    "input_throughput": 4962.826291013262,
    "output_throughput": 4326.11833737459,
    "total_throughput": 9288.944628387851,
    "itl": 80.30394441165718,
    "ttft": 2108561.9225179786,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 416,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.0913653544942137,
    "arrivals": 627971,
    "finished_requests": 72543,
    "scheduler_time": 122.46654423186908
}
#Debug simulation 
Total elapsed time: 5.3016418712213635. Arrivals time: 0.22880232334136963 Scheduler time: 4.8948623007163405 Scheduler overhead time: 0.06309259310364723 Adapter cache time: 0.021171733271330595 Engine time: 0.06410907814279199 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.00625_size_16-16-16/adapters_160_slots_96_rate_3.2-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.00625_size_16-16-16/adapters_160_slots_96_rate_3.2-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [53 53 54]
Adapter prompts. [66, 34560, 66, 66, 270, 66, 66, 66, 34560, 66, 270, 34560, 270, 66, 270, 270, 270, 270, 34560, 34560, 34560, 270, 270, 270, 34560, 34560, 66, 34560, 270, 34560, 34560, 34560, 270, 34560, 66, 270, 270, 270, 34560, 66, 66, 34560, 66, 34560, 66, 66, 270, 66, 270, 34560, 66, 66, 270, 66, 66, 66, 66, 66, 34560, 270, 270, 34560, 270, 66, 34560, 34560, 34560, 270, 270, 66, 66, 66, 34560, 66, 270, 270, 66, 34560, 34560, 34560, 66, 66, 34560, 270, 34560, 34560, 66, 34560, 66, 270, 66, 66, 270, 270, 34560, 34560, 34560, 66, 34560, 270, 270, 66, 66, 66, 66, 34560, 270, 34560, 270, 34560, 34560, 34560, 66, 270, 270, 34560, 270, 34560, 66, 66, 66, 270, 270, 270, 34560, 34560, 270, 34560, 66, 270, 270, 66, 34560, 34560, 34560, 34560, 34560, 34560, 270, 270, 270, 270, 270, 34560, 66, 34560, 66, 34560, 270, 66, 270, 66, 66, 270, 270, 270, 34560, 270, 66, 66]
Prompts retrieved: 1884048 . Total input tokens: 420228146 . Total output tokens: 370028549
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.838053924031556,
    "estimated_duration": 3600.0499746795276,
    "input_throughput": 5519.828930088381,
    "output_throughput": 4818.198947792134,
    "total_throughput": 10338.027877880515,
    "itl": 100.8929526109055,
    "ttft": 2045761.6115816394,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 445,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.840844818553875,
    "arrivals": 627971,
    "finished_requests": 80723,
    "scheduler_time": 117.61089107907509
}
#Debug simulation 
Total elapsed time: 5.838146474678069. Arrivals time: 0.27726991521194577 Scheduler time: 5.413053340278566 Scheduler overhead time: 0.051681830547749996 Adapter cache time: 0.018823142163455486 Engine time: 0.05296506732702255 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.00625_size_16-16-32/adapters_160_slots_96_rate_3.2-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.00625_size_16-16-32/adapters_160_slots_96_rate_3.2-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [53 53 54]
Adapter prompts. [66, 34560, 66, 66, 270, 66, 66, 66, 34560, 66, 270, 34560, 270, 66, 270, 270, 270, 270, 34560, 34560, 34560, 270, 270, 270, 34560, 34560, 66, 34560, 270, 34560, 34560, 34560, 270, 34560, 66, 270, 270, 270, 34560, 66, 66, 34560, 66, 34560, 66, 66, 270, 66, 270, 34560, 66, 66, 270, 66, 66, 66, 66, 66, 34560, 270, 270, 34560, 270, 66, 34560, 34560, 34560, 270, 270, 66, 66, 66, 34560, 66, 270, 270, 66, 34560, 34560, 34560, 66, 66, 34560, 270, 34560, 34560, 66, 34560, 66, 270, 66, 66, 270, 270, 34560, 34560, 34560, 66, 34560, 270, 270, 66, 66, 66, 66, 34560, 270, 34560, 270, 34560, 34560, 34560, 66, 270, 270, 34560, 270, 34560, 66, 66, 66, 270, 270, 270, 34560, 34560, 270, 34560, 66, 270, 270, 66, 34560, 34560, 34560, 34560, 34560, 34560, 270, 270, 270, 270, 270, 34560, 66, 34560, 66, 34560, 270, 66, 270, 66, 66, 270, 270, 270, 34560, 270, 66, 66]
Prompts retrieved: 1884048 . Total input tokens: 420228146 . Total output tokens: 370028549
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.347529728896916,
    "estimated_duration": 3600.058794262064,
    "input_throughput": 4962.867281077913,
    "output_throughput": 4326.1540686011,
    "total_throughput": 9289.021349679013,
    "itl": 80.3032804207787,
    "ttft": 2108548.9854340004,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 416,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.0617475982383113,
    "arrivals": 627971,
    "finished_requests": 72543,
    "scheduler_time": 122.46642759202261
}
#Debug simulation 
Total elapsed time: 5.3476214818656445. Arrivals time: 0.2650043941102922 Scheduler time: 4.906303576659411 Scheduler overhead time: 0.06195968296378851 Adapter cache time: 0.02129940874874592 Engine time: 0.06377668958157301 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-8/adapters_160_slots_96_rate_3.2-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-8/adapters_160_slots_96_rate_3.2-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [53 53 54]
Adapter prompts. [33, 34560, 33, 33, 270, 33, 33, 33, 34560, 33, 270, 34560, 270, 33, 270, 270, 270, 270, 34560, 34560, 34560, 270, 270, 270, 34560, 34560, 33, 34560, 270, 34560, 34560, 34560, 270, 34560, 33, 270, 270, 270, 34560, 33, 33, 34560, 33, 34560, 33, 33, 270, 33, 270, 34560, 33, 33, 270, 33, 33, 33, 33, 33, 34560, 270, 270, 34560, 270, 33, 34560, 34560, 34560, 270, 270, 33, 33, 33, 34560, 33, 270, 270, 33, 34560, 34560, 34560, 33, 33, 34560, 270, 34560, 34560, 33, 34560, 33, 270, 33, 33, 270, 270, 34560, 34560, 34560, 33, 34560, 270, 270, 33, 33, 33, 33, 34560, 270, 34560, 270, 34560, 34560, 34560, 33, 270, 270, 34560, 270, 34560, 33, 33, 33, 270, 270, 270, 34560, 34560, 270, 34560, 33, 270, 270, 33, 34560, 34560, 34560, 34560, 34560, 34560, 270, 270, 270, 270, 270, 34560, 33, 34560, 33, 34560, 270, 33, 270, 33, 33, 270, 270, 270, 34560, 270, 33, 33]
Prompts retrieved: 1882299 . Total input tokens: 419846205 . Total output tokens: 369675113
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 6.135320330969989,
    "estimated_duration": 3600.087444818607,
    "input_throughput": 5747.86343864562,
    "output_throughput": 5008.200849662543,
    "total_throughput": 10756.064288308162,
    "itl": 109.7840317401455,
    "ttft": 2024132.2787353406,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 355,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3474052063422364,
    "arrivals": 627360,
    "finished_requests": 83927,
    "scheduler_time": 116.5064487859942
}
#Debug simulation 
Total elapsed time: 6.135417389217764. Arrivals time: 0.30251468485221267 Scheduler time: 5.694037276785821 Scheduler overhead time: 0.04860407719388604 Adapter cache time: 0.01765721244737506 Engine time: 0.04971591755747795 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-16/adapters_160_slots_96_rate_3.2-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-16/adapters_160_slots_96_rate_3.2-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [53 53 54]
Adapter prompts. [33, 34560, 33, 33, 270, 33, 33, 33, 34560, 33, 270, 34560, 270, 33, 270, 270, 270, 270, 34560, 34560, 34560, 270, 270, 270, 34560, 34560, 33, 34560, 270, 34560, 34560, 34560, 270, 34560, 33, 270, 270, 270, 34560, 33, 33, 34560, 33, 34560, 33, 33, 270, 33, 270, 34560, 33, 33, 270, 33, 33, 33, 33, 33, 34560, 270, 270, 34560, 270, 33, 34560, 34560, 34560, 270, 270, 33, 33, 33, 34560, 33, 270, 270, 33, 34560, 34560, 34560, 33, 33, 34560, 270, 34560, 34560, 33, 34560, 33, 270, 33, 33, 270, 270, 34560, 34560, 34560, 33, 34560, 270, 270, 33, 33, 33, 33, 34560, 270, 34560, 270, 34560, 34560, 34560, 33, 270, 270, 34560, 270, 34560, 33, 33, 33, 270, 270, 270, 34560, 34560, 270, 34560, 33, 270, 270, 33, 34560, 34560, 34560, 34560, 34560, 34560, 270, 270, 270, 270, 270, 34560, 33, 34560, 33, 34560, 270, 33, 270, 33, 33, 270, 270, 270, 34560, 270, 33, 33]
Prompts retrieved: 1882299 . Total input tokens: 419846205 . Total output tokens: 369675113
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.927213289309293,
    "estimated_duration": 3600.049924958678,
    "input_throughput": 5557.3548748020885,
    "output_throughput": 4833.862408227505,
    "total_throughput": 10391.217283029593,
    "itl": 99.78081827668915,
    "ttft": 2044775.697107651,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 339,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.479275359795431,
    "arrivals": 627360,
    "finished_requests": 81066,
    "scheduler_time": 118.29871797891376
}
#Debug simulation 
Total elapsed time: 5.927308123093098. Arrivals time: 0.3141712984070182 Scheduler time: 5.4642965155653656 Scheduler overhead time: 0.052513104397803545 Adapter cache time: 0.017861215863376856 Engine time: 0.05369663145393133 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-32/adapters_160_slots_96_rate_3.2-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-32/adapters_160_slots_96_rate_3.2-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [53 53 54]
Adapter prompts. [33, 34560, 33, 33, 270, 33, 33, 33, 34560, 33, 270, 34560, 270, 33, 270, 270, 270, 270, 34560, 34560, 34560, 270, 270, 270, 34560, 34560, 33, 34560, 270, 34560, 34560, 34560, 270, 34560, 33, 270, 270, 270, 34560, 33, 33, 34560, 33, 34560, 33, 33, 270, 33, 270, 34560, 33, 33, 270, 33, 33, 33, 33, 33, 34560, 270, 270, 34560, 270, 33, 34560, 34560, 34560, 270, 270, 33, 33, 33, 34560, 33, 270, 270, 33, 34560, 34560, 34560, 33, 33, 34560, 270, 34560, 34560, 33, 34560, 33, 270, 33, 33, 270, 270, 34560, 34560, 34560, 33, 34560, 270, 270, 33, 33, 33, 33, 34560, 270, 34560, 270, 34560, 34560, 34560, 33, 270, 270, 34560, 270, 34560, 33, 33, 33, 270, 270, 270, 34560, 34560, 270, 34560, 33, 270, 270, 33, 34560, 34560, 34560, 34560, 34560, 34560, 270, 270, 270, 270, 270, 34560, 33, 34560, 33, 34560, 270, 33, 270, 33, 33, 270, 270, 270, 34560, 270, 33, 33]
Prompts retrieved: 1882299 . Total input tokens: 419846205 . Total output tokens: 369675113
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.360032189171761,
    "estimated_duration": 3600.082507328942,
    "input_throughput": 4978.980610446938,
    "output_throughput": 4333.175411464156,
    "total_throughput": 9312.156021911094,
    "itl": 79.56529243729652,
    "ttft": 2108917.258495179,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 305,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.288904126719581,
    "arrivals": 627360,
    "finished_requests": 72687,
    "scheduler_time": 123.01399679817392
}
#Debug simulation 
Total elapsed time: 5.36012187320739. Arrivals time: 0.28738950099796057 Scheduler time: 4.896530812140554 Scheduler overhead time: 0.062115125358104706 Adapter cache time: 0.02016319753602147 Engine time: 0.06446047406643629 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.003125_size_8-16-16/adapters_160_slots_96_rate_3.2-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.003125_size_8-16-16/adapters_160_slots_96_rate_3.2-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [53 53 54]
Adapter prompts. [33, 34560, 33, 33, 270, 33, 33, 33, 34560, 33, 270, 34560, 270, 33, 270, 270, 270, 270, 34560, 34560, 34560, 270, 270, 270, 34560, 34560, 33, 34560, 270, 34560, 34560, 34560, 270, 34560, 33, 270, 270, 270, 34560, 33, 33, 34560, 33, 34560, 33, 33, 270, 33, 270, 34560, 33, 33, 270, 33, 33, 33, 33, 33, 34560, 270, 270, 34560, 270, 33, 34560, 34560, 34560, 270, 270, 33, 33, 33, 34560, 33, 270, 270, 33, 34560, 34560, 34560, 33, 33, 34560, 270, 34560, 34560, 33, 34560, 33, 270, 33, 33, 270, 270, 34560, 34560, 34560, 33, 34560, 270, 270, 33, 33, 33, 33, 34560, 270, 34560, 270, 34560, 34560, 34560, 33, 270, 270, 34560, 270, 34560, 33, 33, 33, 270, 270, 270, 34560, 34560, 270, 34560, 33, 270, 270, 33, 34560, 34560, 34560, 34560, 34560, 34560, 270, 270, 270, 270, 270, 34560, 33, 34560, 33, 34560, 270, 33, 270, 33, 33, 270, 270, 270, 34560, 270, 33, 33]
Prompts retrieved: 1882299 . Total input tokens: 419846205 . Total output tokens: 369675113
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 5.920557343866676,
    "estimated_duration": 3600.1071988261383,
    "input_throughput": 5557.561732196144,
    "output_throughput": 4834.151051300535,
    "total_throughput": 10391.712783496678,
    "itl": 99.77718423905213,
    "ttft": 2044724.1280772616,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 339,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3224063898110736,
    "arrivals": 627360,
    "finished_requests": 81068,
    "scheduler_time": 118.30521197707034
}
#Debug simulation 
Total elapsed time: 5.920658366754651. Arrivals time: 0.31602935772389174 Scheduler time: 5.455678123049438 Scheduler overhead time: 0.052480035461485386 Adapter cache time: 0.01779933925718069 Engine time: 0.053655237425118685 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.003125_size_8-16-32/adapters_160_slots_96_rate_3.2-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.003125_size_8-16-32/adapters_160_slots_96_rate_3.2-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [53 53 54]
Adapter prompts. [33, 34560, 33, 33, 270, 33, 33, 33, 34560, 33, 270, 34560, 270, 33, 270, 270, 270, 270, 34560, 34560, 34560, 270, 270, 270, 34560, 34560, 33, 34560, 270, 34560, 34560, 34560, 270, 34560, 33, 270, 270, 270, 34560, 33, 33, 34560, 33, 34560, 33, 33, 270, 33, 270, 34560, 33, 33, 270, 33, 33, 33, 33, 33, 34560, 270, 270, 34560, 270, 33, 34560, 34560, 34560, 270, 270, 33, 33, 33, 34560, 33, 270, 270, 33, 34560, 34560, 34560, 33, 33, 34560, 270, 34560, 34560, 33, 34560, 33, 270, 33, 33, 270, 270, 34560, 34560, 34560, 33, 34560, 270, 270, 33, 33, 33, 33, 34560, 270, 34560, 270, 34560, 34560, 34560, 33, 270, 270, 34560, 270, 34560, 33, 33, 33, 270, 270, 270, 34560, 34560, 270, 34560, 33, 270, 270, 33, 34560, 34560, 34560, 34560, 34560, 34560, 270, 270, 270, 270, 270, 34560, 33, 34560, 33, 34560, 270, 33, 270, 33, 33, 270, 270, 270, 34560, 270, 33, 33]
Prompts retrieved: 1882299 . Total input tokens: 419846205 . Total output tokens: 369675113
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 5.390650419984013,
    "estimated_duration": 3600.0610590124206,
    "input_throughput": 4979.0102740416205,
    "output_throughput": 4333.201227503452,
    "total_throughput": 9312.211501545073,
    "itl": 79.56486062167144,
    "ttft": 2108907.609515566,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 305,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.267571057528267,
    "arrivals": 627360,
    "finished_requests": 72687,
    "scheduler_time": 123.01388155084409
}
#Debug simulation 
Total elapsed time: 5.390738382004201. Arrivals time: 0.2859304170124233 Scheduler time: 4.928585224319249 Scheduler overhead time: 0.062400924041867256 Adapter cache time: 0.02020483138039708 Engine time: 0.06394875794649124 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.003125_size_16-16-16/adapters_160_slots_96_rate_3.2-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.003125_size_16-16-16/adapters_160_slots_96_rate_3.2-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [53 53 54]
Adapter prompts. [33, 34560, 33, 33, 270, 33, 33, 33, 34560, 33, 270, 34560, 270, 33, 270, 270, 270, 270, 34560, 34560, 34560, 270, 270, 270, 34560, 34560, 33, 34560, 270, 34560, 34560, 34560, 270, 34560, 33, 270, 270, 270, 34560, 33, 33, 34560, 33, 34560, 33, 33, 270, 33, 270, 34560, 33, 33, 270, 33, 33, 33, 33, 33, 34560, 270, 270, 34560, 270, 33, 34560, 34560, 34560, 270, 270, 33, 33, 33, 34560, 33, 270, 270, 33, 34560, 34560, 34560, 33, 33, 34560, 270, 34560, 34560, 33, 34560, 33, 270, 33, 33, 270, 270, 34560, 34560, 34560, 33, 34560, 270, 270, 33, 33, 33, 33, 34560, 270, 34560, 270, 34560, 34560, 34560, 33, 270, 270, 34560, 270, 34560, 33, 33, 33, 270, 270, 270, 34560, 34560, 270, 34560, 33, 270, 270, 33, 34560, 34560, 34560, 34560, 34560, 34560, 270, 270, 270, 270, 270, 34560, 33, 34560, 33, 34560, 270, 33, 270, 33, 33, 270, 270, 270, 34560, 270, 33, 33]
Prompts retrieved: 1882299 . Total input tokens: 419846205 . Total output tokens: 369675113
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.871152255218476,
    "estimated_duration": 3600.0567295748915,
    "input_throughput": 5558.115191802214,
    "output_throughput": 4834.472984000776,
    "total_throughput": 10392.58817580299,
    "itl": 99.77359485606988,
    "ttft": 2044638.544999095,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 339,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1641491988534023,
    "arrivals": 627360,
    "finished_requests": 81072,
    "scheduler_time": 118.30828186050549
}
#Debug simulation 
Total elapsed time: 5.871244561858475. Arrivals time: 0.30414575058966875 Scheduler time: 5.418643809389323 Scheduler overhead time: 0.052415368147194386 Adapter cache time: 0.017764995340257883 Engine time: 0.05357118649408221 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.003125_size_16-16-32/adapters_160_slots_96_rate_3.2-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.025-0.003125_size_16-16-32/adapters_160_slots_96_rate_3.2-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [53 53 54]
Adapter prompts. [33, 34560, 33, 33, 270, 33, 33, 33, 34560, 33, 270, 34560, 270, 33, 270, 270, 270, 270, 34560, 34560, 34560, 270, 270, 270, 34560, 34560, 33, 34560, 270, 34560, 34560, 34560, 270, 34560, 33, 270, 270, 270, 34560, 33, 33, 34560, 33, 34560, 33, 33, 270, 33, 270, 34560, 33, 33, 270, 33, 33, 33, 33, 33, 34560, 270, 270, 34560, 270, 33, 34560, 34560, 34560, 270, 270, 33, 33, 33, 34560, 33, 270, 270, 33, 34560, 34560, 34560, 33, 33, 34560, 270, 34560, 34560, 33, 34560, 33, 270, 33, 33, 270, 270, 34560, 34560, 34560, 33, 34560, 270, 270, 33, 33, 33, 33, 34560, 270, 34560, 270, 34560, 34560, 34560, 33, 270, 270, 34560, 270, 34560, 33, 33, 33, 270, 270, 270, 34560, 34560, 270, 34560, 33, 270, 270, 33, 34560, 34560, 34560, 34560, 34560, 34560, 270, 270, 270, 270, 270, 34560, 33, 34560, 33, 34560, 270, 33, 270, 33, 33, 270, 270, 270, 34560, 270, 33, 33]
Prompts retrieved: 1882299 . Total input tokens: 419846205 . Total output tokens: 369675113
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.375477688852698,
    "estimated_duration": 3600.040250614318,
    "input_throughput": 4979.0390529498345,
    "output_throughput": 4333.226273605696,
    "total_throughput": 9312.265326555531,
    "itl": 79.56442864933096,
    "ttft": 2108898.6153787887,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 305,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2468593398667966,
    "arrivals": 627360,
    "finished_requests": 72687,
    "scheduler_time": 123.01378487040286
}
#Debug simulation 
Total elapsed time: 5.375570395961404. Arrivals time: 0.2879351512528956 Scheduler time: 4.91094175260514 Scheduler overhead time: 0.06235760822892189 Adapter cache time: 0.02012522565200925 Engine time: 0.06434055790305138 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-8/adapters_160_slots_96_rate_3.2-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-8/adapters_160_slots_96_rate_3.2-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [53 53 54]
Adapter prompts. [66, 34560, 66, 66, 135, 66, 66, 66, 34560, 66, 135, 34560, 135, 66, 135, 135, 135, 135, 34560, 34560, 34560, 135, 135, 135, 34560, 34560, 66, 34560, 135, 34560, 34560, 34560, 135, 34560, 66, 135, 135, 135, 34560, 66, 66, 34560, 66, 34560, 66, 66, 135, 66, 135, 34560, 66, 66, 135, 66, 66, 66, 66, 66, 34560, 135, 135, 34560, 135, 66, 34560, 34560, 34560, 135, 135, 66, 66, 66, 34560, 66, 135, 135, 66, 34560, 34560, 34560, 66, 66, 34560, 135, 34560, 34560, 66, 34560, 66, 135, 66, 66, 135, 135, 34560, 34560, 34560, 66, 34560, 135, 135, 66, 66, 66, 66, 34560, 135, 34560, 135, 34560, 34560, 34560, 66, 135, 135, 34560, 135, 34560, 66, 66, 66, 135, 135, 135, 34560, 34560, 135, 34560, 66, 135, 135, 66, 34560, 34560, 34560, 34560, 34560, 34560, 135, 135, 135, 135, 135, 34560, 66, 34560, 66, 34560, 135, 66, 135, 66, 66, 135, 135, 135, 34560, 135, 66, 66]
Prompts retrieved: 1876893 . Total input tokens: 418631234 . Total output tokens: 368602470
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 6.188277559820563,
    "estimated_duration": 3600.079114725921,
    "input_throughput": 5817.708259334881,
    "output_throughput": 5057.716072271987,
    "total_throughput": 10875.42433160687,
    "itl": 108.68378124427613,
    "ttft": 2023445.6322338101,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 325,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.149032935383732,
    "arrivals": 625657,
    "finished_requests": 84597,
    "scheduler_time": 117.72114358535971
}
#Debug simulation 
Total elapsed time: 6.188378069084138. Arrivals time: 0.31395403016358614 Scheduler time: 5.735917951911688 Scheduler overhead time: 0.049667070619761944 Adapter cache time: 0.015018556267023087 Engine time: 0.050480315927416086 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-16/adapters_160_slots_96_rate_3.2-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-16/adapters_160_slots_96_rate_3.2-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [53 53 54]
Adapter prompts. [66, 34560, 66, 66, 135, 66, 66, 66, 34560, 66, 135, 34560, 135, 66, 135, 135, 135, 135, 34560, 34560, 34560, 135, 135, 135, 34560, 34560, 66, 34560, 135, 34560, 34560, 34560, 135, 34560, 66, 135, 135, 135, 34560, 66, 66, 34560, 66, 34560, 66, 66, 135, 66, 135, 34560, 66, 66, 135, 66, 66, 66, 66, 66, 34560, 135, 135, 34560, 135, 66, 34560, 34560, 34560, 135, 135, 66, 66, 66, 34560, 66, 135, 135, 66, 34560, 34560, 34560, 66, 66, 34560, 135, 34560, 34560, 66, 34560, 66, 135, 66, 66, 135, 135, 34560, 34560, 34560, 66, 34560, 135, 135, 66, 66, 66, 66, 34560, 135, 34560, 135, 34560, 34560, 34560, 66, 135, 135, 34560, 135, 34560, 66, 66, 66, 135, 135, 135, 34560, 34560, 135, 34560, 66, 135, 135, 66, 34560, 34560, 34560, 34560, 34560, 34560, 135, 135, 135, 135, 135, 34560, 66, 34560, 66, 34560, 135, 66, 135, 66, 66, 135, 135, 135, 34560, 135, 66, 66]
Prompts retrieved: 1876893 . Total input tokens: 418631234 . Total output tokens: 368602470
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.961407947354019,
    "estimated_duration": 3600.0130050663765,
    "input_throughput": 5605.7300269746975,
    "output_throughput": 4877.993767046465,
    "total_throughput": 10483.723794021163,
    "itl": 99.03483128411563,
    "ttft": 2044180.216664407,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 311,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.275537595939825,
    "arrivals": 625657,
    "finished_requests": 81528,
    "scheduler_time": 119.3392634731406
}
#Debug simulation 
Total elapsed time: 5.961499805096537. Arrivals time: 0.3036194406449795 Scheduler time: 5.510070398449898 Scheduler overhead time: 0.05278913304209709 Adapter cache time: 0.015641558915376663 Engine time: 0.05414047185331583 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-32/adapters_160_slots_96_rate_3.2-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-32/adapters_160_slots_96_rate_3.2-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [53 53 54]
Adapter prompts. [66, 34560, 66, 66, 135, 66, 66, 66, 34560, 66, 135, 34560, 135, 66, 135, 135, 135, 135, 34560, 34560, 34560, 135, 135, 135, 34560, 34560, 66, 34560, 135, 34560, 34560, 34560, 135, 34560, 66, 135, 135, 135, 34560, 66, 66, 34560, 66, 34560, 66, 66, 135, 66, 135, 34560, 66, 66, 135, 66, 66, 66, 66, 66, 34560, 135, 135, 34560, 135, 66, 34560, 34560, 34560, 135, 135, 66, 66, 66, 34560, 66, 135, 135, 66, 34560, 34560, 34560, 66, 66, 34560, 135, 34560, 34560, 66, 34560, 66, 135, 66, 66, 135, 135, 34560, 34560, 34560, 66, 34560, 135, 135, 66, 66, 66, 66, 34560, 135, 34560, 135, 34560, 34560, 34560, 66, 135, 135, 34560, 135, 34560, 66, 66, 66, 135, 135, 135, 34560, 34560, 135, 34560, 66, 135, 135, 66, 34560, 34560, 34560, 34560, 34560, 34560, 135, 135, 135, 135, 135, 34560, 66, 34560, 66, 34560, 135, 66, 135, 66, 66, 135, 135, 135, 34560, 135, 66, 66]
Prompts retrieved: 1876893 . Total input tokens: 418631234 . Total output tokens: 368602470
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.411543401423842,
    "estimated_duration": 3600.0177602912077,
    "input_throughput": 4993.320643658688,
    "output_throughput": 4351.346033007586,
    "total_throughput": 9344.666676666273,
    "itl": 78.93734923442248,
    "ttft": 2108219.0419850573,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 289,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1682309847138903,
    "arrivals": 625657,
    "finished_requests": 72590,
    "scheduler_time": 123.88053404611205
}
#Debug simulation 
Total elapsed time: 5.4116373104043305. Arrivals time: 0.2612380622886121 Scheduler time: 4.975204735528678 Scheduler overhead time: 0.06282017333433032 Adapter cache time: 0.017865721136331558 Engine time: 0.06460709311068058 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.00625_size_8-16-16/adapters_160_slots_96_rate_3.2-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.00625_size_8-16-16/adapters_160_slots_96_rate_3.2-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [53 53 54]
Adapter prompts. [66, 34560, 66, 66, 135, 66, 66, 66, 34560, 66, 135, 34560, 135, 66, 135, 135, 135, 135, 34560, 34560, 34560, 135, 135, 135, 34560, 34560, 66, 34560, 135, 34560, 34560, 34560, 135, 34560, 66, 135, 135, 135, 34560, 66, 66, 34560, 66, 34560, 66, 66, 135, 66, 135, 34560, 66, 66, 135, 66, 66, 66, 66, 66, 34560, 135, 135, 34560, 135, 66, 34560, 34560, 34560, 135, 135, 66, 66, 66, 34560, 66, 135, 135, 66, 34560, 34560, 34560, 66, 66, 34560, 135, 34560, 34560, 66, 34560, 66, 135, 66, 66, 135, 135, 34560, 34560, 34560, 66, 34560, 135, 135, 66, 66, 66, 66, 34560, 135, 34560, 135, 34560, 34560, 34560, 66, 135, 135, 34560, 135, 34560, 66, 66, 66, 135, 135, 135, 34560, 34560, 135, 34560, 66, 135, 135, 66, 34560, 34560, 34560, 34560, 34560, 34560, 135, 135, 135, 135, 135, 34560, 66, 34560, 66, 34560, 135, 66, 135, 66, 66, 135, 135, 135, 34560, 135, 66, 66]
Prompts retrieved: 1876893 . Total input tokens: 418631234 . Total output tokens: 368602470
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 5.944281373172998,
    "estimated_duration": 3600.043608697958,
    "input_throughput": 5605.707928437808,
    "output_throughput": 4878.1872968343305,
    "total_throughput": 10483.895225272137,
    "itl": 99.02944475721617,
    "ttft": 2044113.6765176305,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 311,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.129774393741971,
    "arrivals": 625657,
    "finished_requests": 81529,
    "scheduler_time": 119.34444110496658
}
#Debug simulation 
Total elapsed time: 5.944376724306494. Arrivals time: 0.2508133826777339 Scheduler time: 5.5463140248321 Scheduler overhead time: 0.05272936215624213 Adapter cache time: 0.015690498054027557 Engine time: 0.05383270652964711 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.00625_size_8-16-32/adapters_160_slots_96_rate_3.2-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.00625_size_8-16-32/adapters_160_slots_96_rate_3.2-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [53 53 54]
Adapter prompts. [66, 34560, 66, 66, 135, 66, 66, 66, 34560, 66, 135, 34560, 135, 66, 135, 135, 135, 135, 34560, 34560, 34560, 135, 135, 135, 34560, 34560, 66, 34560, 135, 34560, 34560, 34560, 135, 34560, 66, 135, 135, 135, 34560, 66, 66, 34560, 66, 34560, 66, 66, 135, 66, 135, 34560, 66, 66, 135, 66, 66, 66, 66, 66, 34560, 135, 135, 34560, 135, 66, 34560, 34560, 34560, 135, 135, 66, 66, 66, 34560, 66, 135, 135, 66, 34560, 34560, 34560, 66, 66, 34560, 135, 34560, 34560, 66, 34560, 66, 135, 66, 66, 135, 135, 34560, 34560, 34560, 66, 34560, 135, 135, 66, 66, 66, 66, 34560, 135, 34560, 135, 34560, 34560, 34560, 66, 135, 135, 34560, 135, 34560, 66, 66, 66, 135, 135, 135, 34560, 34560, 135, 34560, 66, 135, 135, 66, 34560, 34560, 34560, 34560, 34560, 34560, 135, 135, 135, 135, 135, 34560, 66, 34560, 66, 34560, 135, 66, 135, 66, 66, 135, 135, 135, 34560, 135, 66, 66]
Prompts retrieved: 1876893 . Total input tokens: 418631234 . Total output tokens: 368602470
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 5.391452254727483,
    "estimated_duration": 3600.089381015134,
    "input_throughput": 5000.560012463846,
    "output_throughput": 4356.425171748831,
    "total_throughput": 9356.985184212677,
    "itl": 79.07806720622305,
    "ttft": 2108169.9630125444,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 291,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.162376841758386,
    "arrivals": 625657,
    "finished_requests": 72688,
    "scheduler_time": 123.83622222001954
}
#Debug simulation 
Total elapsed time: 5.3915419317781925. Arrivals time: 0.26682980405166745 Scheduler time: 4.950032449327409 Scheduler overhead time: 0.06262670876458287 Adapter cache time: 0.018086503725498915 Engine time: 0.06418098462745547 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.00625_size_16-16-16/adapters_160_slots_96_rate_3.2-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.00625_size_16-16-16/adapters_160_slots_96_rate_3.2-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [53 53 54]
Adapter prompts. [66, 34560, 66, 66, 135, 66, 66, 66, 34560, 66, 135, 34560, 135, 66, 135, 135, 135, 135, 34560, 34560, 34560, 135, 135, 135, 34560, 34560, 66, 34560, 135, 34560, 34560, 34560, 135, 34560, 66, 135, 135, 135, 34560, 66, 66, 34560, 66, 34560, 66, 66, 135, 66, 135, 34560, 66, 66, 135, 66, 66, 66, 66, 66, 34560, 135, 135, 34560, 135, 66, 34560, 34560, 34560, 135, 135, 66, 66, 66, 34560, 66, 135, 135, 66, 34560, 34560, 34560, 66, 66, 34560, 135, 34560, 34560, 66, 34560, 66, 135, 66, 66, 135, 135, 34560, 34560, 34560, 66, 34560, 135, 135, 66, 66, 66, 66, 34560, 135, 34560, 135, 34560, 34560, 34560, 66, 135, 135, 34560, 135, 34560, 66, 66, 66, 135, 135, 135, 34560, 34560, 135, 34560, 66, 135, 135, 66, 34560, 34560, 34560, 34560, 34560, 34560, 135, 135, 135, 135, 135, 34560, 66, 34560, 66, 34560, 135, 66, 135, 66, 66, 135, 135, 135, 34560, 135, 66, 66]
Prompts retrieved: 1876893 . Total input tokens: 418631234 . Total output tokens: 368602470
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.951486655976623,
    "estimated_duration": 3600.0668681477596,
    "input_throughput": 5605.855596338796,
    "output_throughput": 4878.306610186882,
    "total_throughput": 10484.162206525678,
    "itl": 99.026403618046,
    "ttft": 2044026.6859521372,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 311,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9853994125174284,
    "arrivals": 625657,
    "finished_requests": 81532,
    "scheduler_time": 119.34944404443331
}
#Debug simulation 
Total elapsed time: 5.9515878558158875. Arrivals time: 0.31367989676073194 Scheduler time: 5.490032895933837 Scheduler overhead time: 0.05278839776292443 Adapter cache time: 0.015698738861829042 Engine time: 0.054224660620093346 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.00625_size_16-16-32/adapters_160_slots_96_rate_3.2-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.00625_size_16-16-32/adapters_160_slots_96_rate_3.2-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [53 53 54]
Adapter prompts. [66, 34560, 66, 66, 135, 66, 66, 66, 34560, 66, 135, 34560, 135, 66, 135, 135, 135, 135, 34560, 34560, 34560, 135, 135, 135, 34560, 34560, 66, 34560, 135, 34560, 34560, 34560, 135, 34560, 66, 135, 135, 135, 34560, 66, 66, 34560, 66, 34560, 66, 66, 135, 66, 135, 34560, 66, 66, 135, 66, 66, 66, 66, 66, 34560, 135, 135, 34560, 135, 66, 34560, 34560, 34560, 135, 135, 66, 66, 66, 34560, 66, 135, 135, 66, 34560, 34560, 34560, 66, 66, 34560, 135, 34560, 34560, 66, 34560, 66, 135, 66, 66, 135, 135, 34560, 34560, 34560, 66, 34560, 135, 135, 66, 66, 66, 66, 34560, 135, 34560, 135, 34560, 34560, 34560, 66, 135, 135, 34560, 135, 34560, 66, 66, 66, 135, 135, 135, 34560, 34560, 135, 34560, 66, 135, 135, 66, 34560, 34560, 34560, 34560, 34560, 34560, 135, 135, 135, 135, 135, 34560, 66, 34560, 66, 34560, 135, 66, 135, 66, 66, 135, 135, 135, 34560, 135, 66, 66]
Prompts retrieved: 1876893 . Total input tokens: 418631234 . Total output tokens: 368602470
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.440585601143539,
    "estimated_duration": 3600.0695990520912,
    "input_throughput": 5000.587489958555,
    "output_throughput": 4356.4491097976315,
    "total_throughput": 9357.036599756188,
    "itl": 79.07765334492137,
    "ttft": 2108161.3787587117,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 291,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1427007099799895,
    "arrivals": 625657,
    "finished_requests": 72688,
    "scheduler_time": 123.83611638875463
}
#Debug simulation 
Total elapsed time: 5.440676188096404. Arrivals time: 0.2865771106444299 Scheduler time: 4.97850702283904 Scheduler overhead time: 0.06299155671149492 Adapter cache time: 0.018248078413307667 Engine time: 0.06452221656218171 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-8/adapters_160_slots_96_rate_3.2-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-8/adapters_160_slots_96_rate_3.2-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [53 53 54]
Adapter prompts. [33, 34560, 33, 33, 135, 33, 33, 33, 34560, 33, 135, 34560, 135, 33, 135, 135, 135, 135, 34560, 34560, 34560, 135, 135, 135, 34560, 34560, 33, 34560, 135, 34560, 34560, 34560, 135, 34560, 33, 135, 135, 135, 34560, 33, 33, 34560, 33, 34560, 33, 33, 135, 33, 135, 34560, 33, 33, 135, 33, 33, 33, 33, 33, 34560, 135, 135, 34560, 135, 33, 34560, 34560, 34560, 135, 135, 33, 33, 33, 34560, 33, 135, 135, 33, 34560, 34560, 34560, 33, 33, 34560, 135, 34560, 34560, 33, 34560, 33, 135, 33, 33, 135, 135, 34560, 34560, 34560, 33, 34560, 135, 135, 33, 33, 33, 33, 34560, 135, 34560, 135, 34560, 34560, 34560, 33, 135, 135, 34560, 135, 34560, 33, 33, 33, 135, 135, 135, 34560, 34560, 135, 34560, 33, 135, 135, 33, 34560, 34560, 34560, 34560, 34560, 34560, 135, 135, 135, 135, 135, 34560, 33, 34560, 33, 34560, 135, 33, 135, 33, 33, 135, 135, 135, 34560, 135, 33, 33]
Prompts retrieved: 1875144 . Total input tokens: 418237307 . Total output tokens: 368265940
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 6.128273454029113,
    "estimated_duration": 3600.0073282024377,
    "input_throughput": 5791.720432527835,
    "output_throughput": 5076.156055805783,
    "total_throughput": 10867.876488333619,
    "itl": 108.55188653749612,
    "ttft": 2019785.1362293533,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 253,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6729394850833321,
    "arrivals": 625114,
    "finished_requests": 84404,
    "scheduler_time": 118.10077731025056
}
#Debug simulation 
Total elapsed time: 6.1283771796152. Arrivals time: 0.2700712117366493 Scheduler time: 5.721609770786017 Scheduler overhead time: 0.04927917290478945 Adapter cache time: 0.014041352551430464 Engine time: 0.05012133251875639 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-16/adapters_160_slots_96_rate_3.2-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-16/adapters_160_slots_96_rate_3.2-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [53 53 54]
Adapter prompts. [33, 34560, 33, 33, 135, 33, 33, 33, 34560, 33, 135, 34560, 135, 33, 135, 135, 135, 135, 34560, 34560, 34560, 135, 135, 135, 34560, 34560, 33, 34560, 135, 34560, 34560, 34560, 135, 34560, 33, 135, 135, 135, 34560, 33, 33, 34560, 33, 34560, 33, 33, 135, 33, 135, 34560, 33, 33, 135, 33, 33, 33, 33, 33, 34560, 135, 135, 34560, 135, 33, 34560, 34560, 34560, 135, 135, 33, 33, 33, 34560, 33, 135, 135, 33, 34560, 34560, 34560, 33, 33, 34560, 135, 34560, 34560, 33, 34560, 33, 135, 33, 33, 135, 135, 34560, 34560, 34560, 33, 34560, 135, 135, 33, 33, 33, 33, 34560, 135, 34560, 135, 34560, 34560, 34560, 33, 135, 135, 34560, 135, 34560, 33, 33, 33, 135, 135, 135, 34560, 34560, 135, 34560, 33, 135, 135, 33, 34560, 34560, 34560, 34560, 34560, 34560, 135, 135, 135, 135, 135, 34560, 33, 34560, 33, 34560, 135, 33, 135, 33, 33, 135, 135, 135, 34560, 135, 33, 33]
Prompts retrieved: 1875144 . Total input tokens: 418237307 . Total output tokens: 368265940
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.945610237773508,
    "estimated_duration": 3600.0561121918163,
    "input_throughput": 5588.900109601391,
    "output_throughput": 4897.534219061243,
    "total_throughput": 10486.434328662634,
    "itl": 98.97143950370379,
    "ttft": 2042132.6694942724,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 248,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.813657074831428,
    "arrivals": 625114,
    "finished_requests": 81479,
    "scheduler_time": 119.66193531685393
}
#Debug simulation 
Total elapsed time: 5.945725181140006. Arrivals time: 0.24697505868971348 Scheduler time: 5.551098361611366 Scheduler overhead time: 0.05317316809669137 Adapter cache time: 0.014795252587646246 Engine time: 0.05439698230475187 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-32/adapters_160_slots_96_rate_3.2-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-32/adapters_160_slots_96_rate_3.2-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [53 53 54]
Adapter prompts. [33, 34560, 33, 33, 135, 33, 33, 33, 34560, 33, 135, 34560, 135, 33, 135, 135, 135, 135, 34560, 34560, 34560, 135, 135, 135, 34560, 34560, 33, 34560, 135, 34560, 34560, 34560, 135, 34560, 33, 135, 135, 135, 34560, 33, 33, 34560, 33, 34560, 33, 33, 135, 33, 135, 34560, 33, 33, 135, 33, 33, 33, 33, 33, 34560, 135, 135, 34560, 135, 33, 34560, 34560, 34560, 135, 135, 33, 33, 33, 34560, 33, 135, 135, 33, 34560, 34560, 34560, 33, 33, 34560, 135, 34560, 34560, 33, 34560, 33, 135, 33, 33, 135, 135, 34560, 34560, 34560, 33, 34560, 135, 135, 33, 33, 33, 33, 34560, 135, 34560, 135, 34560, 34560, 34560, 33, 135, 135, 34560, 135, 34560, 33, 33, 33, 135, 135, 135, 34560, 34560, 135, 34560, 33, 135, 135, 33, 34560, 34560, 34560, 34560, 34560, 34560, 135, 135, 135, 135, 135, 34560, 33, 34560, 33, 34560, 135, 33, 135, 33, 33, 135, 135, 135, 34560, 135, 33, 33]
Prompts retrieved: 1875144 . Total input tokens: 418237307 . Total output tokens: 368265940
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.365671048872173,
    "estimated_duration": 3600.032658481037,
    "input_throughput": 4980.926202921127,
    "output_throughput": 4371.686174269438,
    "total_throughput": 9352.612377190566,
    "itl": 79.13750052915026,
    "ttft": 2104640.446855932,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 234,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7530966578703409,
    "arrivals": 625114,
    "finished_requests": 72656,
    "scheduler_time": 124.04345509486625
}
#Debug simulation 
Total elapsed time: 5.365755047183484. Arrivals time: 0.22896801540628076 Scheduler time: 4.962871940340847 Scheduler overhead time: 0.0628637932240963 Adapter cache time: 0.016788354609161615 Engine time: 0.06445663422346115 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_8-16-16/adapters_160_slots_96_rate_3.2-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_8-16-16/adapters_160_slots_96_rate_3.2-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [53 53 54]
Adapter prompts. [33, 34560, 33, 33, 135, 33, 33, 33, 34560, 33, 135, 34560, 135, 33, 135, 135, 135, 135, 34560, 34560, 34560, 135, 135, 135, 34560, 34560, 33, 34560, 135, 34560, 34560, 34560, 135, 34560, 33, 135, 135, 135, 34560, 33, 33, 34560, 33, 34560, 33, 33, 135, 33, 135, 34560, 33, 33, 135, 33, 33, 33, 33, 33, 34560, 135, 135, 34560, 135, 33, 34560, 34560, 34560, 135, 135, 33, 33, 33, 34560, 33, 135, 135, 33, 34560, 34560, 34560, 33, 33, 34560, 135, 34560, 34560, 33, 34560, 33, 135, 33, 33, 135, 135, 34560, 34560, 34560, 33, 34560, 135, 135, 33, 33, 33, 33, 34560, 135, 34560, 135, 34560, 34560, 34560, 33, 135, 135, 34560, 135, 34560, 33, 33, 33, 135, 135, 135, 34560, 34560, 135, 34560, 33, 135, 135, 33, 34560, 34560, 34560, 34560, 34560, 34560, 135, 135, 135, 135, 135, 34560, 33, 34560, 33, 34560, 135, 33, 135, 33, 33, 135, 135, 135, 34560, 135, 33, 33]
Prompts retrieved: 1875144 . Total input tokens: 418237307 . Total output tokens: 368265940
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 5.937021126970649,
    "estimated_duration": 3600.05910838828,
    "input_throughput": 5589.2212861494545,
    "output_throughput": 4897.733195245723,
    "total_throughput": 10486.954481395178,
    "itl": 98.96874639146691,
    "ttft": 2042073.8385958374,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 248,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7067640598863352,
    "arrivals": 625114,
    "finished_requests": 81483,
    "scheduler_time": 119.66498981265799
}
#Debug simulation 
Total elapsed time: 5.937116634100676. Arrivals time: 0.24806452868506312 Scheduler time: 5.541760859079659 Scheduler overhead time: 0.05293607525527477 Adapter cache time: 0.014732453506439924 Engine time: 0.05450681783258915 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_8-16-32/adapters_160_slots_96_rate_3.2-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_8-16-32/adapters_160_slots_96_rate_3.2-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [53 53 54]
Adapter prompts. [33, 34560, 33, 33, 135, 33, 33, 33, 34560, 33, 135, 34560, 135, 33, 135, 135, 135, 135, 34560, 34560, 34560, 135, 135, 135, 34560, 34560, 33, 34560, 135, 34560, 34560, 34560, 135, 34560, 33, 135, 135, 135, 34560, 33, 33, 34560, 33, 34560, 33, 33, 135, 33, 135, 34560, 33, 33, 135, 33, 33, 33, 33, 33, 34560, 135, 135, 34560, 135, 33, 34560, 34560, 34560, 135, 135, 33, 33, 33, 34560, 33, 135, 135, 33, 34560, 34560, 34560, 33, 33, 34560, 135, 34560, 34560, 33, 34560, 33, 135, 33, 33, 135, 135, 34560, 34560, 34560, 33, 34560, 135, 135, 33, 33, 33, 33, 34560, 135, 34560, 135, 34560, 34560, 34560, 33, 135, 135, 34560, 135, 34560, 33, 33, 33, 135, 135, 135, 34560, 34560, 135, 34560, 33, 135, 135, 33, 34560, 34560, 34560, 34560, 34560, 34560, 135, 135, 135, 135, 135, 34560, 33, 34560, 33, 34560, 135, 33, 135, 33, 33, 135, 135, 135, 34560, 135, 33, 33]
Prompts retrieved: 1875144 . Total input tokens: 418237307 . Total output tokens: 368265940
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 5.391025090124458,
    "estimated_duration": 3600.0178302221702,
    "input_throughput": 4980.946719059272,
    "output_throughput": 4371.704180984219,
    "total_throughput": 9352.650900043493,
    "itl": 79.13722859135082,
    "ttft": 2104632.7483704756,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 234,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.738391338330697,
    "arrivals": 625114,
    "finished_requests": 72656,
    "scheduler_time": 124.04333215553973
}
#Debug simulation 
Total elapsed time: 5.391119979321957. Arrivals time: 0.2662130417302251 Scheduler time: 4.950808362103999 Scheduler overhead time: 0.06282026087865233 Adapter cache time: 0.016749896574765444 Engine time: 0.06463374709710479 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_16-16-16/adapters_160_slots_96_rate_3.2-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_16-16-16/adapters_160_slots_96_rate_3.2-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [53 53 54]
Adapter prompts. [33, 34560, 33, 33, 135, 33, 33, 33, 34560, 33, 135, 34560, 135, 33, 135, 135, 135, 135, 34560, 34560, 34560, 135, 135, 135, 34560, 34560, 33, 34560, 135, 34560, 34560, 34560, 135, 34560, 33, 135, 135, 135, 34560, 33, 33, 34560, 33, 34560, 33, 33, 135, 33, 135, 34560, 33, 33, 135, 33, 33, 33, 33, 33, 34560, 135, 135, 34560, 135, 33, 34560, 34560, 34560, 135, 135, 33, 33, 33, 34560, 33, 135, 135, 33, 34560, 34560, 34560, 33, 33, 34560, 135, 34560, 34560, 33, 34560, 33, 135, 33, 33, 135, 135, 34560, 34560, 34560, 33, 34560, 135, 135, 33, 33, 33, 33, 34560, 135, 34560, 135, 34560, 34560, 34560, 33, 135, 135, 34560, 135, 34560, 33, 33, 33, 135, 135, 135, 34560, 34560, 135, 34560, 33, 135, 135, 33, 34560, 34560, 34560, 34560, 34560, 34560, 135, 135, 135, 135, 135, 34560, 33, 34560, 33, 34560, 135, 33, 135, 33, 33, 135, 135, 135, 34560, 135, 33, 33]
Prompts retrieved: 1875144 . Total input tokens: 418237307 . Total output tokens: 368265940
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.90048478031531,
    "estimated_duration": 3600.045561246705,
    "input_throughput": 5589.412872050334,
    "output_throughput": 4897.881068453419,
    "total_throughput": 10487.293940503752,
    "itl": 98.9658876740168,
    "ttft": 2042028.2307015578,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 248,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.583212393261487,
    "arrivals": 625114,
    "finished_requests": 81486,
    "scheduler_time": 119.6681596221022
}
#Debug simulation 
Total elapsed time: 5.900579916313291. Arrivals time: 0.259465120267123 Scheduler time: 5.494269639719278 Scheduler overhead time: 0.053038717713207006 Adapter cache time: 0.014545940328389406 Engine time: 0.05424979468807578 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_16-16-32/adapters_160_slots_96_rate_3.2-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_16-16-32/adapters_160_slots_96_rate_3.2-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [53 53 54]
Adapter prompts. [33, 34560, 33, 33, 135, 33, 33, 33, 34560, 33, 135, 34560, 135, 33, 135, 135, 135, 135, 34560, 34560, 34560, 135, 135, 135, 34560, 34560, 33, 34560, 135, 34560, 34560, 34560, 135, 34560, 33, 135, 135, 135, 34560, 33, 33, 34560, 33, 34560, 33, 33, 135, 33, 135, 34560, 33, 33, 135, 33, 33, 33, 33, 33, 34560, 135, 135, 34560, 135, 33, 34560, 34560, 34560, 135, 135, 33, 33, 33, 34560, 33, 135, 135, 33, 34560, 34560, 34560, 33, 33, 34560, 135, 34560, 34560, 33, 34560, 33, 135, 33, 33, 135, 135, 34560, 34560, 34560, 33, 34560, 135, 135, 33, 33, 33, 33, 34560, 135, 34560, 135, 34560, 34560, 34560, 33, 135, 135, 34560, 135, 34560, 33, 33, 33, 135, 135, 135, 34560, 34560, 135, 34560, 33, 135, 135, 33, 34560, 34560, 34560, 34560, 34560, 34560, 135, 135, 135, 135, 135, 34560, 33, 34560, 33, 34560, 135, 33, 135, 33, 33, 135, 135, 135, 34560, 135, 33, 33]
Prompts retrieved: 1875144 . Total input tokens: 418237307 . Total output tokens: 368265940
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.334735642652959,
    "estimated_duration": 3600.0005415561745,
    "input_throughput": 4980.970639590165,
    "output_throughput": 4371.725175684788,
    "total_throughput": 9352.695815274954,
    "itl": 79.1368512380429,
    "ttft": 2104624.5262340945,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 234,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7212006126716768,
    "arrivals": 625114,
    "finished_requests": 72656,
    "scheduler_time": 124.04323421520247
}
#Debug simulation 
Total elapsed time: 5.334821305703372. Arrivals time: 0.22976858401671052 Scheduler time: 4.931122542358935 Scheduler overhead time: 0.06274963589385152 Adapter cache time: 0.016740165650844574 Engine time: 0.06462025083601475 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-8/adapters_160_slots_96_rate_3.2-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-8/adapters_160_slots_96_rate_3.2-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [53 53 54]
Adapter prompts. [33, 34560, 33, 33, 66, 33, 33, 33, 34560, 33, 66, 34560, 66, 33, 66, 66, 66, 66, 34560, 34560, 34560, 66, 66, 66, 34560, 34560, 33, 34560, 66, 34560, 34560, 34560, 66, 34560, 33, 66, 66, 66, 34560, 33, 33, 34560, 33, 34560, 33, 33, 66, 33, 66, 34560, 33, 33, 66, 33, 33, 33, 33, 33, 34560, 66, 66, 34560, 66, 33, 34560, 34560, 34560, 66, 66, 33, 33, 33, 34560, 33, 66, 66, 33, 34560, 34560, 34560, 33, 33, 34560, 66, 34560, 34560, 33, 34560, 33, 66, 33, 33, 66, 66, 34560, 34560, 34560, 33, 34560, 66, 66, 33, 33, 33, 33, 34560, 66, 34560, 66, 34560, 34560, 34560, 33, 66, 66, 34560, 66, 34560, 33, 33, 33, 66, 66, 66, 34560, 34560, 66, 34560, 33, 66, 66, 33, 34560, 34560, 34560, 34560, 34560, 34560, 66, 66, 66, 66, 66, 34560, 33, 34560, 33, 34560, 66, 33, 66, 33, 33, 66, 66, 66, 34560, 66, 33, 33]
Prompts retrieved: 1871487 . Total input tokens: 417378462 . Total output tokens: 367552348
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 6.289792691823095,
    "estimated_duration": 3600.03406582252,
    "input_throughput": 5854.2129365058645,
    "output_throughput": 5119.373778978175,
    "total_throughput": 10973.58671548404,
    "itl": 107.73302321332358,
    "ttft": 2012693.2521485207,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 202,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3357066244538858,
    "arrivals": 623927,
    "finished_requests": 85338,
    "scheduler_time": 118.9988637351323
}
#Debug simulation 
Total elapsed time: 6.289898242801428. Arrivals time: 0.3234438872896135 Scheduler time: 5.830182792618871 Scheduler overhead time: 0.04963998822495341 Adapter cache time: 0.012248216196894646 Engine time: 0.050951541401445866 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-16/adapters_160_slots_96_rate_3.2-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-16/adapters_160_slots_96_rate_3.2-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [53 53 54]
Adapter prompts. [33, 34560, 33, 33, 66, 33, 33, 33, 34560, 33, 66, 34560, 66, 33, 66, 66, 66, 66, 34560, 34560, 34560, 66, 66, 66, 34560, 34560, 33, 34560, 66, 34560, 34560, 34560, 66, 34560, 33, 66, 66, 66, 34560, 33, 33, 34560, 33, 34560, 33, 33, 66, 33, 66, 34560, 33, 33, 66, 33, 33, 33, 33, 33, 34560, 66, 66, 34560, 66, 33, 34560, 34560, 34560, 66, 66, 33, 33, 33, 34560, 33, 66, 66, 33, 34560, 34560, 34560, 33, 33, 34560, 66, 34560, 34560, 33, 34560, 33, 66, 33, 33, 66, 66, 34560, 34560, 34560, 33, 34560, 66, 66, 33, 33, 33, 33, 34560, 66, 34560, 66, 34560, 34560, 34560, 33, 66, 66, 34560, 66, 34560, 33, 33, 33, 66, 66, 66, 34560, 34560, 66, 34560, 33, 66, 66, 33, 34560, 34560, 34560, 34560, 34560, 34560, 66, 66, 66, 66, 66, 34560, 33, 34560, 33, 34560, 66, 33, 66, 33, 33, 66, 66, 66, 34560, 66, 33, 33]
Prompts retrieved: 1871487 . Total input tokens: 417378462 . Total output tokens: 367552348
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 6.318642189260572,
    "estimated_duration": 3600.027480818521,
    "input_throughput": 5633.741716712858,
    "output_throughput": 4931.774019670328,
    "total_throughput": 10565.515736383186,
    "itl": 98.2604595054363,
    "ttft": 2032827.2553500896,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 192,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3992404422536502,
    "arrivals": 623927,
    "finished_requests": 82114,
    "scheduler_time": 120.5085079891475
}
#Debug simulation 
Total elapsed time: 6.318731336388737. Arrivals time: 0.31904958141967654 Scheduler time: 5.854052182752639 Scheduler overhead time: 0.05325130699202418 Adapter cache time: 0.01269024284556508 Engine time: 0.054398301523178816 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-32/adapters_160_slots_96_rate_3.2-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-32/adapters_160_slots_96_rate_3.2-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [53 53 54]
Adapter prompts. [33, 34560, 33, 33, 66, 33, 33, 33, 34560, 33, 66, 34560, 66, 33, 66, 66, 66, 66, 34560, 34560, 34560, 66, 66, 66, 34560, 34560, 33, 34560, 66, 34560, 34560, 34560, 66, 34560, 33, 66, 66, 66, 34560, 33, 33, 34560, 33, 34560, 33, 33, 66, 33, 66, 34560, 33, 33, 66, 33, 33, 33, 33, 33, 34560, 66, 66, 34560, 66, 33, 34560, 34560, 34560, 66, 66, 33, 33, 33, 34560, 33, 66, 66, 33, 34560, 34560, 34560, 33, 33, 34560, 66, 34560, 34560, 33, 34560, 33, 66, 33, 33, 66, 66, 34560, 34560, 34560, 33, 34560, 66, 66, 33, 33, 33, 33, 34560, 66, 34560, 66, 34560, 34560, 34560, 33, 66, 66, 34560, 66, 34560, 33, 33, 33, 66, 66, 66, 34560, 34560, 66, 34560, 33, 66, 66, 33, 34560, 34560, 34560, 34560, 34560, 34560, 66, 66, 66, 66, 66, 34560, 33, 34560, 33, 34560, 66, 33, 66, 33, 33, 66, 66, 66, 34560, 66, 33, 33]
Prompts retrieved: 1871487 . Total input tokens: 417378462 . Total output tokens: 367552348
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.461709348950535,
    "estimated_duration": 3600.022205559144,
    "input_throughput": 5030.475915408205,
    "output_throughput": 4397.76259589516,
    "total_throughput": 9428.238511303365,
    "itl": 78.7247686489628,
    "ttft": 2099565.0778200994,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 172,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2882650429895164,
    "arrivals": 623927,
    "finished_requests": 73272,
    "scheduler_time": 124.70861330931776
}
#Debug simulation 
Total elapsed time: 5.461804661899805. Arrivals time: 0.2346639703027904 Scheduler time: 5.053412753157318 Scheduler overhead time: 0.06328122690320015 Adapter cache time: 0.015204898547381163 Engine time: 0.06527067115530372 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_8-16-16/adapters_160_slots_96_rate_3.2-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_8-16-16/adapters_160_slots_96_rate_3.2-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [53 53 54]
Adapter prompts. [33, 34560, 33, 33, 66, 33, 33, 33, 34560, 33, 66, 34560, 66, 33, 66, 66, 66, 66, 34560, 34560, 34560, 66, 66, 66, 34560, 34560, 33, 34560, 66, 34560, 34560, 34560, 66, 34560, 33, 66, 66, 66, 34560, 33, 33, 34560, 33, 34560, 33, 33, 66, 33, 66, 34560, 33, 33, 66, 33, 33, 33, 33, 33, 34560, 66, 66, 34560, 66, 33, 34560, 34560, 34560, 66, 66, 33, 33, 33, 34560, 33, 66, 66, 33, 34560, 34560, 34560, 33, 33, 34560, 66, 34560, 34560, 33, 34560, 33, 66, 33, 33, 66, 66, 34560, 34560, 34560, 33, 34560, 66, 66, 33, 33, 33, 33, 34560, 66, 34560, 66, 34560, 34560, 34560, 33, 66, 66, 34560, 66, 34560, 33, 33, 33, 66, 66, 66, 34560, 34560, 66, 34560, 33, 66, 66, 33, 34560, 34560, 34560, 34560, 34560, 34560, 66, 66, 66, 66, 66, 34560, 33, 34560, 33, 34560, 66, 33, 66, 33, 33, 66, 66, 66, 34560, 66, 33, 33]
Prompts retrieved: 1871487 . Total input tokens: 417378462 . Total output tokens: 367552348
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 6.025794701185077,
    "estimated_duration": 3600.054212241995,
    "input_throughput": 5633.98043591367,
    "output_throughput": 4931.989896047288,
    "total_throughput": 10565.970331960958,
    "itl": 98.25862426912526,
    "ttft": 2032799.1415212315,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 192,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3215000677481283,
    "arrivals": 623927,
    "finished_requests": 82118,
    "scheduler_time": 120.51154292825849
}
#Debug simulation 
Total elapsed time: 6.025880753993988. Arrivals time: 0.2498852564021945 Scheduler time: 5.6298541482537985 Scheduler overhead time: 0.05337804742157459 Adapter cache time: 0.012846451718360186 Engine time: 0.05464143771678209 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_8-16-32/adapters_160_slots_96_rate_3.2-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_8-16-32/adapters_160_slots_96_rate_3.2-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [53 53 54]
Adapter prompts. [33, 34560, 33, 33, 66, 33, 33, 33, 34560, 33, 66, 34560, 66, 33, 66, 66, 66, 66, 34560, 34560, 34560, 66, 66, 66, 34560, 34560, 33, 34560, 66, 34560, 34560, 34560, 66, 34560, 33, 66, 66, 66, 34560, 33, 33, 34560, 33, 34560, 33, 33, 66, 33, 66, 34560, 33, 33, 66, 33, 33, 33, 33, 33, 34560, 66, 66, 34560, 66, 33, 34560, 34560, 34560, 66, 66, 33, 33, 33, 34560, 33, 66, 66, 33, 34560, 34560, 34560, 33, 33, 34560, 66, 34560, 34560, 33, 34560, 33, 66, 33, 33, 66, 66, 34560, 34560, 34560, 33, 34560, 66, 66, 33, 33, 33, 33, 34560, 66, 34560, 66, 34560, 34560, 34560, 33, 66, 66, 34560, 66, 34560, 33, 33, 33, 66, 66, 66, 34560, 34560, 66, 34560, 33, 66, 66, 33, 34560, 34560, 34560, 34560, 34560, 34560, 66, 66, 66, 66, 66, 34560, 33, 34560, 33, 34560, 66, 33, 66, 33, 33, 66, 66, 66, 34560, 66, 33, 33]
Prompts retrieved: 1871487 . Total input tokens: 417378462 . Total output tokens: 367552348
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 5.426183471921831,
    "estimated_duration": 3600.0119662375982,
    "input_throughput": 5030.490223321875,
    "output_throughput": 4397.775104216166,
    "total_throughput": 9428.265327538042,
    "itl": 78.72457667668937,
    "ttft": 2099559.7589802523,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 172,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.278116301335396,
    "arrivals": 623927,
    "finished_requests": 73272,
    "scheduler_time": 124.70852272942561
}
#Debug simulation 
Total elapsed time: 5.426285580266267. Arrivals time: 0.23686112416908145 Scheduler time: 5.016651700716466 Scheduler overhead time: 0.06290792999789119 Adapter cache time: 0.015103207435458899 Engine time: 0.06504965992644429 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_16-16-16/adapters_160_slots_96_rate_3.2-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_16-16-16/adapters_160_slots_96_rate_3.2-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [53 53 54]
Adapter prompts. [33, 34560, 33, 33, 66, 33, 33, 33, 34560, 33, 66, 34560, 66, 33, 66, 66, 66, 66, 34560, 34560, 34560, 66, 66, 66, 34560, 34560, 33, 34560, 66, 34560, 34560, 34560, 66, 34560, 33, 66, 66, 66, 34560, 33, 33, 34560, 33, 34560, 33, 33, 66, 33, 66, 34560, 33, 33, 66, 33, 33, 33, 33, 33, 34560, 66, 66, 34560, 66, 33, 34560, 34560, 34560, 66, 66, 33, 33, 33, 34560, 33, 66, 66, 33, 34560, 34560, 34560, 33, 33, 34560, 66, 34560, 34560, 33, 34560, 33, 66, 33, 33, 66, 66, 34560, 34560, 34560, 33, 34560, 66, 66, 33, 33, 33, 33, 34560, 66, 34560, 66, 34560, 34560, 34560, 33, 66, 66, 34560, 66, 34560, 33, 33, 33, 66, 66, 66, 34560, 34560, 66, 34560, 33, 66, 66, 33, 34560, 34560, 34560, 34560, 34560, 34560, 66, 66, 66, 66, 66, 34560, 33, 34560, 33, 34560, 66, 33, 66, 33, 33, 66, 66, 66, 34560, 66, 33, 33]
Prompts retrieved: 1871487 . Total input tokens: 417378462 . Total output tokens: 367552348
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 6.012834689114243,
    "estimated_duration": 3600.0630312749417,
    "input_throughput": 5634.055799522184,
    "output_throughput": 4931.978369754269,
    "total_throughput": 10566.034169276454,
    "itl": 98.25565940377105,
    "ttft": 2032746.9497467785,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 192,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2257128205895391,
    "arrivals": 623927,
    "finished_requests": 82119,
    "scheduler_time": 120.51457740307602
}
#Debug simulation 
Total elapsed time: 6.012928017880768. Arrivals time: 0.3059882870875299 Scheduler time: 5.560790432617068 Scheduler overhead time: 0.053461925592273474 Adapter cache time: 0.01280138036236167 Engine time: 0.054631996899843216 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_16-16-32/adapters_160_slots_96_rate_3.2-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_16-16-32/adapters_160_slots_96_rate_3.2-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [53 53 54]
Adapter prompts. [33, 34560, 33, 33, 66, 33, 33, 33, 34560, 33, 66, 34560, 66, 33, 66, 66, 66, 66, 34560, 34560, 34560, 66, 66, 66, 34560, 34560, 33, 34560, 66, 34560, 34560, 34560, 66, 34560, 33, 66, 66, 66, 34560, 33, 33, 34560, 33, 34560, 33, 33, 66, 33, 66, 34560, 33, 33, 66, 33, 33, 33, 33, 33, 34560, 66, 66, 34560, 66, 33, 34560, 34560, 34560, 66, 66, 33, 33, 33, 34560, 33, 66, 66, 33, 34560, 34560, 34560, 33, 33, 34560, 66, 34560, 34560, 33, 34560, 33, 66, 33, 33, 66, 66, 34560, 34560, 34560, 33, 34560, 66, 66, 33, 33, 33, 33, 34560, 66, 34560, 66, 34560, 34560, 34560, 33, 66, 66, 34560, 66, 34560, 33, 33, 33, 66, 66, 66, 34560, 34560, 66, 34560, 33, 66, 66, 33, 34560, 34560, 34560, 34560, 34560, 34560, 66, 66, 66, 66, 66, 34560, 33, 34560, 33, 34560, 66, 33, 66, 33, 33, 66, 66, 66, 34560, 66, 33, 33]
Prompts retrieved: 1871487 . Total input tokens: 417378462 . Total output tokens: 367552348
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.449410276953131,
    "estimated_duration": 3600.0880637881196,
    "input_throughput": 5030.421389454613,
    "output_throughput": 4397.732144180069,
    "total_throughput": 9428.153533634682,
    "itl": 78.72440999359813,
    "ttft": 2099563.8844805113,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 172,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.264860802032055,
    "arrivals": 623927,
    "finished_requests": 73273,
    "scheduler_time": 124.71156842341851
}
#Debug simulation 
Total elapsed time: 5.449502367991954. Arrivals time: 0.2841900340281427 Scheduler time: 4.99163742410019 Scheduler overhead time: 0.0633839638903737 Adapter cache time: 0.01521217729896307 Engine time: 0.06512216059491038 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_8-8-8/adapters_160_slots_96_rate_1.6-0.8-0.4_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_8-8-8/adapters_160_slots_96_rate_1.6-0.8-0.4_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [53 53 54]
Adapter prompts. [4320, 17280, 4320, 4320, 8640, 4320, 4320, 4320, 17280, 4320, 8640, 17280, 8640, 4320, 8640, 8640, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 8640, 17280, 17280, 4320, 17280, 8640, 17280, 17280, 17280, 8640, 17280, 4320, 8640, 8640, 8640, 17280, 4320, 4320, 17280, 4320, 17280, 4320, 4320, 8640, 4320, 8640, 17280, 4320, 4320, 8640, 4320, 4320, 4320, 4320, 4320, 17280, 8640, 8640, 17280, 8640, 4320, 17280, 17280, 17280, 8640, 8640, 4320, 4320, 4320, 17280, 4320, 8640, 8640, 4320, 17280, 17280, 17280, 4320, 4320, 17280, 8640, 17280, 17280, 4320, 17280, 4320, 8640, 4320, 4320, 8640, 8640, 17280, 17280, 17280, 4320, 17280, 8640, 8640, 4320, 4320, 4320, 4320, 17280, 8640, 17280, 8640, 17280, 17280, 17280, 4320, 8640, 8640, 17280, 8640, 17280, 4320, 4320, 4320, 8640, 8640, 8640, 17280, 17280, 8640, 17280, 4320, 8640, 8640, 4320, 17280, 17280, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 17280, 4320, 17280, 4320, 17280, 8640, 4320, 8640, 4320, 4320, 8640, 8640, 8640, 17280, 8640, 4320, 4320]
Prompts retrieved: 1620000 . Total input tokens: 361237859 . Total output tokens: 318173948
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 8.35141514101997,
    "estimated_duration": 3600.05971213862,
    "input_throughput": 4747.8101383619105,
    "output_throughput": 4102.902779694577,
    "total_throughput": 8850.712918056486,
    "itl": 133.69144430345673,
    "ttft": 2108449.1536813704,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1016,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.718207576461285,
    "arrivals": 540089,
    "finished_requests": 69056,
    "scheduler_time": 95.4181338402775
}
#Debug simulation 
Total elapsed time: 8.351506057195365. Arrivals time: 0.24885357404127717 Scheduler time: 7.975204381626099 Scheduler overhead time: 0.042355556041002274 Adapter cache time: 0.023045338224619627 Engine time: 0.04266614746302366 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_8-8-16/adapters_160_slots_96_rate_1.6-0.8-0.4_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_8-8-16/adapters_160_slots_96_rate_1.6-0.8-0.4_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [53 53 54]
Adapter prompts. [4320, 17280, 4320, 4320, 8640, 4320, 4320, 4320, 17280, 4320, 8640, 17280, 8640, 4320, 8640, 8640, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 8640, 17280, 17280, 4320, 17280, 8640, 17280, 17280, 17280, 8640, 17280, 4320, 8640, 8640, 8640, 17280, 4320, 4320, 17280, 4320, 17280, 4320, 4320, 8640, 4320, 8640, 17280, 4320, 4320, 8640, 4320, 4320, 4320, 4320, 4320, 17280, 8640, 8640, 17280, 8640, 4320, 17280, 17280, 17280, 8640, 8640, 4320, 4320, 4320, 17280, 4320, 8640, 8640, 4320, 17280, 17280, 17280, 4320, 4320, 17280, 8640, 17280, 17280, 4320, 17280, 4320, 8640, 4320, 4320, 8640, 8640, 17280, 17280, 17280, 4320, 17280, 8640, 8640, 4320, 4320, 4320, 4320, 17280, 8640, 17280, 8640, 17280, 17280, 17280, 4320, 8640, 8640, 17280, 8640, 17280, 4320, 4320, 4320, 8640, 8640, 8640, 17280, 17280, 8640, 17280, 4320, 8640, 8640, 4320, 17280, 17280, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 17280, 4320, 17280, 4320, 17280, 8640, 4320, 8640, 4320, 4320, 8640, 8640, 8640, 17280, 8640, 4320, 4320]
Prompts retrieved: 1620000 . Total input tokens: 361237859 . Total output tokens: 318173948
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 7.2761291190981865,
    "estimated_duration": 3600.009555213668,
    "input_throughput": 4550.519866336215,
    "output_throughput": 3941.5325938371907,
    "total_throughput": 8492.052460173407,
    "itl": 122.3165381206699,
    "ttft": 2133000.2776042465,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1287,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.405811624643357,
    "arrivals": 540089,
    "finished_requests": 66232,
    "scheduler_time": 96.32237569100576
}
#Debug simulation 
Total elapsed time: 7.2762456107884645. Arrivals time: 0.26273902179673314 Scheduler time: 6.873642219696194 Scheduler overhead time: 0.044920386746525764 Adapter cache time: 0.028947212267667055 Engine time: 0.04502389580011368 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_8-8-32/adapters_160_slots_96_rate_1.6-0.8-0.4_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_8-8-32/adapters_160_slots_96_rate_1.6-0.8-0.4_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [53 53 54]
Adapter prompts. [4320, 17280, 4320, 4320, 8640, 4320, 4320, 4320, 17280, 4320, 8640, 17280, 8640, 4320, 8640, 8640, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 8640, 17280, 17280, 4320, 17280, 8640, 17280, 17280, 17280, 8640, 17280, 4320, 8640, 8640, 8640, 17280, 4320, 4320, 17280, 4320, 17280, 4320, 4320, 8640, 4320, 8640, 17280, 4320, 4320, 8640, 4320, 4320, 4320, 4320, 4320, 17280, 8640, 8640, 17280, 8640, 4320, 17280, 17280, 17280, 8640, 8640, 4320, 4320, 4320, 17280, 4320, 8640, 8640, 4320, 17280, 17280, 17280, 4320, 4320, 17280, 8640, 17280, 17280, 4320, 17280, 4320, 8640, 4320, 4320, 8640, 8640, 17280, 17280, 17280, 4320, 17280, 8640, 8640, 4320, 4320, 4320, 4320, 17280, 8640, 17280, 8640, 17280, 17280, 17280, 4320, 8640, 8640, 17280, 8640, 17280, 4320, 4320, 4320, 8640, 8640, 8640, 17280, 17280, 8640, 17280, 4320, 8640, 8640, 4320, 17280, 17280, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 17280, 4320, 17280, 4320, 17280, 8640, 4320, 8640, 4320, 4320, 8640, 8640, 8640, 17280, 8640, 4320, 4320]
Prompts retrieved: 1620000 . Total input tokens: 361237859 . Total output tokens: 318173948
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.488268243148923,
    "estimated_duration": 3600.015210241785,
    "input_throughput": 4024.4913295871706,
    "output_throughput": 3501.5299280231047,
    "total_throughput": 7526.021257610276,
    "itl": 98.68036658436166,
    "ttft": 2201379.0597935603,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2328,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.46993863250578,
    "arrivals": 540089,
    "finished_requests": 58693,
    "scheduler_time": 99.15562881372762
}
#Debug simulation 
Total elapsed time: 5.48835529293865. Arrivals time: 0.2591476673260331 Scheduler time: 5.052700167521834 Scheduler overhead time: 0.05286544281989336 Adapter cache time: 0.04594268277287483 Engine time: 0.05295355478301644 
