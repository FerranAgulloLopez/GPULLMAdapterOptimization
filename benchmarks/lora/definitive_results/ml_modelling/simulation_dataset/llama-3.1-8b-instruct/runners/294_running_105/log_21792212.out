INFO 05-31 19:31:05 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 05-31 19:31:06 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-16/adapters_384_slots_96_rate_0.1-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-16/adapters_384_slots_96_rate_0.1-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 1080, 135, 66, 1080, 1080, 66, 135, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 1080, 1080, 135, 135, 66, 1080, 66, 1080, 135, 135, 135, 66, 66, 135, 66, 1080, 66, 1080, 135, 1080, 135, 66, 135, 1080, 135, 1080, 66, 1080, 1080, 1080, 1080, 66, 135, 135, 135, 1080, 135, 66, 135, 66, 1080, 135, 1080, 1080, 135, 1080, 1080, 66, 66, 1080, 135, 135, 66, 66, 66, 135, 66, 135, 66, 1080, 66, 135, 1080, 66, 1080, 135, 66, 1080, 1080, 1080, 1080, 135, 66, 135, 1080, 1080, 135, 66, 66, 1080, 135, 135, 66, 66, 1080, 135, 1080, 135, 1080, 1080, 135, 1080, 1080, 66, 135, 135, 135, 135, 66, 66, 1080, 66, 1080, 66, 66, 66, 135, 135, 1080, 66, 66, 1080, 66, 1080, 135, 66, 1080, 135, 135, 66, 1080, 1080, 1080, 66, 135, 1080, 66, 1080, 135, 135, 1080, 1080, 66, 135, 1080, 66, 135, 135, 66, 135, 66, 135, 1080, 1080, 135, 66, 1080, 66, 1080, 135, 135, 135, 135, 135, 66, 66, 1080, 66, 1080, 66, 135, 1080, 135, 1080, 135, 1080, 135, 1080, 66, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 66, 66, 66, 66, 66, 135, 66, 66, 135, 1080, 1080, 66, 66, 1080, 66, 66, 66, 135, 66, 135, 1080, 1080, 135, 135, 66, 1080, 135, 1080, 66, 135, 135, 66, 66, 135, 66, 1080, 1080, 66, 1080, 1080, 66, 135, 1080, 66, 66, 135, 135, 66, 66, 1080, 1080, 1080, 1080, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 1080, 135, 135, 135, 1080, 66, 135, 135, 1080, 1080, 66, 1080, 1080, 66, 1080, 66, 66, 135, 66, 1080, 1080, 1080, 135, 66, 1080, 1080, 135, 135, 1080, 1080, 66, 1080, 1080, 135, 66, 1080, 135, 135, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 66, 1080, 66, 135, 1080, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 1080, 66, 66, 66, 135, 66, 135, 135, 66, 1080, 135, 1080, 66, 1080, 66, 135, 135, 135, 135, 66, 135, 1080, 1080, 66, 1080, 1080, 66, 1080, 135, 1080, 135, 135, 135, 66, 135, 66, 66, 1080, 66, 135, 66, 66, 135, 1080, 135, 1080, 66, 1080, 1080, 135, 1080, 135, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 163968 . Total input tokens: 36469343 . Total output tokens: 32209821
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 8.061770915985107,
    "estimated_duration": 3600.072295921981,
    "input_throughput": 3726.520441046926,
    "output_throughput": 3241.3426844839355,
    "total_throughput": 6967.863125530862,
    "itl": 86.97211092619392,
    "ttft": 95058.97653644634,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5584,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 40.87169005472084,
    "arrivals": 55057,
    "finished_requests": 54152,
    "scheduler_time": 43.30304285136431
}
#Debug simulation 
Total elapsed time: 8.061939336825162. Arrivals time: 0.14229049906134605 Scheduler time: 7.688267091289163 Scheduler overhead time: 0.06175870122388005 Adapter cache time: 0.08224064949899912 Engine time: 0.06018802477046847 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-32/adapters_384_slots_96_rate_0.1-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-32/adapters_384_slots_96_rate_0.1-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 1080, 135, 66, 1080, 1080, 66, 135, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 1080, 1080, 135, 135, 66, 1080, 66, 1080, 135, 135, 135, 66, 66, 135, 66, 1080, 66, 1080, 135, 1080, 135, 66, 135, 1080, 135, 1080, 66, 1080, 1080, 1080, 1080, 66, 135, 135, 135, 1080, 135, 66, 135, 66, 1080, 135, 1080, 1080, 135, 1080, 1080, 66, 66, 1080, 135, 135, 66, 66, 66, 135, 66, 135, 66, 1080, 66, 135, 1080, 66, 1080, 135, 66, 1080, 1080, 1080, 1080, 135, 66, 135, 1080, 1080, 135, 66, 66, 1080, 135, 135, 66, 66, 1080, 135, 1080, 135, 1080, 1080, 135, 1080, 1080, 66, 135, 135, 135, 135, 66, 66, 1080, 66, 1080, 66, 66, 66, 135, 135, 1080, 66, 66, 1080, 66, 1080, 135, 66, 1080, 135, 135, 66, 1080, 1080, 1080, 66, 135, 1080, 66, 1080, 135, 135, 1080, 1080, 66, 135, 1080, 66, 135, 135, 66, 135, 66, 135, 1080, 1080, 135, 66, 1080, 66, 1080, 135, 135, 135, 135, 135, 66, 66, 1080, 66, 1080, 66, 135, 1080, 135, 1080, 135, 1080, 135, 1080, 66, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 66, 66, 66, 66, 66, 135, 66, 66, 135, 1080, 1080, 66, 66, 1080, 66, 66, 66, 135, 66, 135, 1080, 1080, 135, 135, 66, 1080, 135, 1080, 66, 135, 135, 66, 66, 135, 66, 1080, 1080, 66, 1080, 1080, 66, 135, 1080, 66, 66, 135, 135, 66, 66, 1080, 1080, 1080, 1080, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 1080, 135, 135, 135, 1080, 66, 135, 135, 1080, 1080, 66, 1080, 1080, 66, 1080, 66, 66, 135, 66, 1080, 1080, 1080, 135, 66, 1080, 1080, 135, 135, 1080, 1080, 66, 1080, 1080, 135, 66, 1080, 135, 135, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 66, 1080, 66, 135, 1080, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 1080, 66, 66, 66, 135, 66, 135, 135, 66, 1080, 135, 1080, 66, 1080, 66, 135, 135, 135, 135, 66, 135, 1080, 1080, 66, 1080, 1080, 66, 1080, 135, 1080, 135, 135, 135, 66, 135, 66, 66, 1080, 66, 135, 66, 66, 135, 1080, 135, 1080, 66, 1080, 1080, 135, 1080, 135, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 163968 . Total input tokens: 36469343 . Total output tokens: 32209821
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 8.033561759162694,
    "estimated_duration": 3600.0748371894856,
    "input_throughput": 3725.5386642102917,
    "output_throughput": 3241.2637313699897,
    "total_throughput": 6966.802395580282,
    "itl": 86.97548224950748,
    "ttft": 95691.41619807754,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5556,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 41.74525676837606,
    "arrivals": 55057,
    "finished_requests": 54147,
    "scheduler_time": 43.33810411031108
}
#Debug simulation 
Total elapsed time: 8.03366186376661. Arrivals time: 0.14229006599634886 Scheduler time: 7.662820661906153 Scheduler overhead time: 0.06021322403103113 Adapter cache time: 0.08176913065835834 Engine time: 0.05974519532173872 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-16/adapters_384_slots_96_rate_0.1-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-16/adapters_384_slots_96_rate_0.1-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 1080, 135, 66, 1080, 1080, 66, 135, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 1080, 1080, 135, 135, 66, 1080, 66, 1080, 135, 135, 135, 66, 66, 135, 66, 1080, 66, 1080, 135, 1080, 135, 66, 135, 1080, 135, 1080, 66, 1080, 1080, 1080, 1080, 66, 135, 135, 135, 1080, 135, 66, 135, 66, 1080, 135, 1080, 1080, 135, 1080, 1080, 66, 66, 1080, 135, 135, 66, 66, 66, 135, 66, 135, 66, 1080, 66, 135, 1080, 66, 1080, 135, 66, 1080, 1080, 1080, 1080, 135, 66, 135, 1080, 1080, 135, 66, 66, 1080, 135, 135, 66, 66, 1080, 135, 1080, 135, 1080, 1080, 135, 1080, 1080, 66, 135, 135, 135, 135, 66, 66, 1080, 66, 1080, 66, 66, 66, 135, 135, 1080, 66, 66, 1080, 66, 1080, 135, 66, 1080, 135, 135, 66, 1080, 1080, 1080, 66, 135, 1080, 66, 1080, 135, 135, 1080, 1080, 66, 135, 1080, 66, 135, 135, 66, 135, 66, 135, 1080, 1080, 135, 66, 1080, 66, 1080, 135, 135, 135, 135, 135, 66, 66, 1080, 66, 1080, 66, 135, 1080, 135, 1080, 135, 1080, 135, 1080, 66, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 66, 66, 66, 66, 66, 135, 66, 66, 135, 1080, 1080, 66, 66, 1080, 66, 66, 66, 135, 66, 135, 1080, 1080, 135, 135, 66, 1080, 135, 1080, 66, 135, 135, 66, 66, 135, 66, 1080, 1080, 66, 1080, 1080, 66, 135, 1080, 66, 66, 135, 135, 66, 66, 1080, 1080, 1080, 1080, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 1080, 135, 135, 135, 1080, 66, 135, 135, 1080, 1080, 66, 1080, 1080, 66, 1080, 66, 66, 135, 66, 1080, 1080, 1080, 135, 66, 1080, 1080, 135, 135, 1080, 1080, 66, 1080, 1080, 135, 66, 1080, 135, 135, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 66, 1080, 66, 135, 1080, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 1080, 66, 66, 66, 135, 66, 135, 135, 66, 1080, 135, 1080, 66, 1080, 66, 135, 135, 135, 135, 66, 135, 1080, 1080, 66, 1080, 1080, 66, 1080, 135, 1080, 135, 135, 135, 66, 135, 66, 66, 1080, 66, 135, 66, 66, 135, 1080, 135, 1080, 66, 1080, 1080, 135, 1080, 135, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 163968 . Total input tokens: 36469343 . Total output tokens: 32209821
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 7.975438680965453,
    "estimated_duration": 3600.0384550934377,
    "input_throughput": 3726.8826895494285,
    "output_throughput": 3242.020646609197,
    "total_throughput": 6968.903336158625,
    "itl": 86.82875914741855,
    "ttft": 94358.88679020935,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5626,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 38.53551218829242,
    "arrivals": 55057,
    "finished_requests": 54158,
    "scheduler_time": 43.27802144200523
}
#Debug simulation 
Total elapsed time: 7.975562532898039. Arrivals time: 0.14259514352306724 Scheduler time: 7.6048876056447625 Scheduler overhead time: 0.05980685958638787 Adapter cache time: 0.0820919401012361 Engine time: 0.05947967851534486 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-32/adapters_384_slots_96_rate_0.1-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-32/adapters_384_slots_96_rate_0.1-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 1080, 135, 66, 1080, 1080, 66, 135, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 1080, 1080, 135, 135, 66, 1080, 66, 1080, 135, 135, 135, 66, 66, 135, 66, 1080, 66, 1080, 135, 1080, 135, 66, 135, 1080, 135, 1080, 66, 1080, 1080, 1080, 1080, 66, 135, 135, 135, 1080, 135, 66, 135, 66, 1080, 135, 1080, 1080, 135, 1080, 1080, 66, 66, 1080, 135, 135, 66, 66, 66, 135, 66, 135, 66, 1080, 66, 135, 1080, 66, 1080, 135, 66, 1080, 1080, 1080, 1080, 135, 66, 135, 1080, 1080, 135, 66, 66, 1080, 135, 135, 66, 66, 1080, 135, 1080, 135, 1080, 1080, 135, 1080, 1080, 66, 135, 135, 135, 135, 66, 66, 1080, 66, 1080, 66, 66, 66, 135, 135, 1080, 66, 66, 1080, 66, 1080, 135, 66, 1080, 135, 135, 66, 1080, 1080, 1080, 66, 135, 1080, 66, 1080, 135, 135, 1080, 1080, 66, 135, 1080, 66, 135, 135, 66, 135, 66, 135, 1080, 1080, 135, 66, 1080, 66, 1080, 135, 135, 135, 135, 135, 66, 66, 1080, 66, 1080, 66, 135, 1080, 135, 1080, 135, 1080, 135, 1080, 66, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 66, 66, 66, 66, 66, 135, 66, 66, 135, 1080, 1080, 66, 66, 1080, 66, 66, 66, 135, 66, 135, 1080, 1080, 135, 135, 66, 1080, 135, 1080, 66, 135, 135, 66, 66, 135, 66, 1080, 1080, 66, 1080, 1080, 66, 135, 1080, 66, 66, 135, 135, 66, 66, 1080, 1080, 1080, 1080, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 1080, 135, 135, 135, 1080, 66, 135, 135, 1080, 1080, 66, 1080, 1080, 66, 1080, 66, 66, 135, 66, 1080, 1080, 1080, 135, 66, 1080, 1080, 135, 135, 1080, 1080, 66, 1080, 1080, 135, 66, 1080, 135, 135, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 66, 1080, 66, 135, 1080, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 1080, 66, 66, 66, 135, 66, 135, 135, 66, 1080, 135, 1080, 66, 1080, 66, 135, 135, 135, 135, 66, 135, 1080, 1080, 66, 1080, 1080, 66, 1080, 135, 1080, 135, 135, 135, 66, 135, 66, 66, 1080, 66, 135, 66, 66, 135, 1080, 135, 1080, 66, 1080, 1080, 135, 1080, 135, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 163968 . Total input tokens: 36469343 . Total output tokens: 32209821
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 7.907249480951577,
    "estimated_duration": 3600.008371331739,
    "input_throughput": 3725.918835860387,
    "output_throughput": 3240.9599635691643,
    "total_throughput": 6966.878799429552,
    "itl": 87.0266384937132,
    "ttft": 95143.02905388239,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5629,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 41.906645257858955,
    "arrivals": 55057,
    "finished_requests": 54149,
    "scheduler_time": 43.30258779980791
}
#Debug simulation 
Total elapsed time: 7.907368002925068. Arrivals time: 0.14210218284279108 Scheduler time: 7.536063015460968 Scheduler overhead time: 0.06093966634944081 Adapter cache time: 0.08199298987165093 Engine time: 0.05949297035112977 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-16/adapters_384_slots_96_rate_0.1-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-16/adapters_384_slots_96_rate_0.1-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 1080, 135, 66, 1080, 1080, 66, 135, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 1080, 1080, 135, 135, 66, 1080, 66, 1080, 135, 135, 135, 66, 66, 135, 66, 1080, 66, 1080, 135, 1080, 135, 66, 135, 1080, 135, 1080, 66, 1080, 1080, 1080, 1080, 66, 135, 135, 135, 1080, 135, 66, 135, 66, 1080, 135, 1080, 1080, 135, 1080, 1080, 66, 66, 1080, 135, 135, 66, 66, 66, 135, 66, 135, 66, 1080, 66, 135, 1080, 66, 1080, 135, 66, 1080, 1080, 1080, 1080, 135, 66, 135, 1080, 1080, 135, 66, 66, 1080, 135, 135, 66, 66, 1080, 135, 1080, 135, 1080, 1080, 135, 1080, 1080, 66, 135, 135, 135, 135, 66, 66, 1080, 66, 1080, 66, 66, 66, 135, 135, 1080, 66, 66, 1080, 66, 1080, 135, 66, 1080, 135, 135, 66, 1080, 1080, 1080, 66, 135, 1080, 66, 1080, 135, 135, 1080, 1080, 66, 135, 1080, 66, 135, 135, 66, 135, 66, 135, 1080, 1080, 135, 66, 1080, 66, 1080, 135, 135, 135, 135, 135, 66, 66, 1080, 66, 1080, 66, 135, 1080, 135, 1080, 135, 1080, 135, 1080, 66, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 66, 66, 66, 66, 66, 135, 66, 66, 135, 1080, 1080, 66, 66, 1080, 66, 66, 66, 135, 66, 135, 1080, 1080, 135, 135, 66, 1080, 135, 1080, 66, 135, 135, 66, 66, 135, 66, 1080, 1080, 66, 1080, 1080, 66, 135, 1080, 66, 66, 135, 135, 66, 66, 1080, 1080, 1080, 1080, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 1080, 135, 135, 135, 1080, 66, 135, 135, 1080, 1080, 66, 1080, 1080, 66, 1080, 66, 66, 135, 66, 1080, 1080, 1080, 135, 66, 1080, 1080, 135, 135, 1080, 1080, 66, 1080, 1080, 135, 66, 1080, 135, 135, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 66, 1080, 66, 135, 1080, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 1080, 66, 66, 66, 135, 66, 135, 135, 66, 1080, 135, 1080, 66, 1080, 66, 135, 135, 135, 135, 66, 135, 1080, 1080, 66, 1080, 1080, 66, 1080, 135, 1080, 135, 135, 135, 66, 135, 66, 66, 1080, 66, 135, 66, 66, 135, 1080, 135, 1080, 66, 1080, 1080, 135, 1080, 135, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 163968 . Total input tokens: 36469343 . Total output tokens: 32209821
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 8.02240808494389,
    "estimated_duration": 3600.065289942423,
    "input_throughput": 3726.36852933702,
    "output_throughput": 3240.844001522705,
    "total_throughput": 6967.212530859725,
    "itl": 86.6796774545043,
    "ttft": 94409.76707973095,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5636,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 35.979778421059216,
    "arrivals": 55057,
    "finished_requests": 54154,
    "scheduler_time": 43.25074394284512
}
#Debug simulation 
Total elapsed time: 8.02251152601093. Arrivals time: 0.1451796512119472 Scheduler time: 7.646208186633885 Scheduler overhead time: 0.06118074618279934 Adapter cache time: 0.08264967193827033 Engine time: 0.06033779913559556 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-32/adapters_384_slots_96_rate_0.1-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-32/adapters_384_slots_96_rate_0.1-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 1080, 135, 66, 1080, 1080, 66, 135, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 1080, 1080, 135, 135, 66, 1080, 66, 1080, 135, 135, 135, 66, 66, 135, 66, 1080, 66, 1080, 135, 1080, 135, 66, 135, 1080, 135, 1080, 66, 1080, 1080, 1080, 1080, 66, 135, 135, 135, 1080, 135, 66, 135, 66, 1080, 135, 1080, 1080, 135, 1080, 1080, 66, 66, 1080, 135, 135, 66, 66, 66, 135, 66, 135, 66, 1080, 66, 135, 1080, 66, 1080, 135, 66, 1080, 1080, 1080, 1080, 135, 66, 135, 1080, 1080, 135, 66, 66, 1080, 135, 135, 66, 66, 1080, 135, 1080, 135, 1080, 1080, 135, 1080, 1080, 66, 135, 135, 135, 135, 66, 66, 1080, 66, 1080, 66, 66, 66, 135, 135, 1080, 66, 66, 1080, 66, 1080, 135, 66, 1080, 135, 135, 66, 1080, 1080, 1080, 66, 135, 1080, 66, 1080, 135, 135, 1080, 1080, 66, 135, 1080, 66, 135, 135, 66, 135, 66, 135, 1080, 1080, 135, 66, 1080, 66, 1080, 135, 135, 135, 135, 135, 66, 66, 1080, 66, 1080, 66, 135, 1080, 135, 1080, 135, 1080, 135, 1080, 66, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 66, 66, 66, 66, 66, 135, 66, 66, 135, 1080, 1080, 66, 66, 1080, 66, 66, 66, 135, 66, 135, 1080, 1080, 135, 135, 66, 1080, 135, 1080, 66, 135, 135, 66, 66, 135, 66, 1080, 1080, 66, 1080, 1080, 66, 135, 1080, 66, 66, 135, 135, 66, 66, 1080, 1080, 1080, 1080, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 1080, 135, 135, 135, 1080, 66, 135, 135, 1080, 1080, 66, 1080, 1080, 66, 1080, 66, 66, 135, 66, 1080, 1080, 1080, 135, 66, 1080, 1080, 135, 135, 1080, 1080, 66, 1080, 1080, 135, 66, 1080, 135, 135, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 66, 1080, 66, 135, 1080, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 1080, 66, 66, 66, 135, 66, 135, 135, 66, 1080, 135, 1080, 66, 1080, 66, 135, 135, 135, 135, 66, 135, 1080, 1080, 66, 1080, 1080, 66, 1080, 135, 1080, 135, 135, 135, 66, 135, 66, 66, 1080, 66, 135, 66, 66, 135, 1080, 135, 1080, 66, 1080, 1080, 135, 1080, 135, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 163968 . Total input tokens: 36469343 . Total output tokens: 32209821
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 7.92768137389794,
    "estimated_duration": 3600.0270330599797,
    "input_throughput": 3725.2075822888864,
    "output_throughput": 3240.1626134693684,
    "total_throughput": 6965.370195758255,
    "itl": 87.00926813077061,
    "ttft": 96031.20896336959,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5585,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 41.209039226937634,
    "arrivals": 55057,
    "finished_requests": 54142,
    "scheduler_time": 43.33797939546752
}
#Debug simulation 
Total elapsed time: 7.927780579775572. Arrivals time: 0.14459082623943686 Scheduler time: 7.554697137791663 Scheduler overhead time: 0.06006329087540507 Adapter cache time: 0.08224763069301844 Engine time: 0.0595488091930747 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-8/adapters_384_slots_96_rate_0.1-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-8/adapters_384_slots_96_rate_0.1-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 1080, 135, 33, 1080, 1080, 33, 135, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 1080, 1080, 135, 135, 33, 1080, 33, 1080, 135, 135, 135, 33, 33, 135, 33, 1080, 33, 1080, 135, 1080, 135, 33, 135, 1080, 135, 1080, 33, 1080, 1080, 1080, 1080, 33, 135, 135, 135, 1080, 135, 33, 135, 33, 1080, 135, 1080, 1080, 135, 1080, 1080, 33, 33, 1080, 135, 135, 33, 33, 33, 135, 33, 135, 33, 1080, 33, 135, 1080, 33, 1080, 135, 33, 1080, 1080, 1080, 1080, 135, 33, 135, 1080, 1080, 135, 33, 33, 1080, 135, 135, 33, 33, 1080, 135, 1080, 135, 1080, 1080, 135, 1080, 1080, 33, 135, 135, 135, 135, 33, 33, 1080, 33, 1080, 33, 33, 33, 135, 135, 1080, 33, 33, 1080, 33, 1080, 135, 33, 1080, 135, 135, 33, 1080, 1080, 1080, 33, 135, 1080, 33, 1080, 135, 135, 1080, 1080, 33, 135, 1080, 33, 135, 135, 33, 135, 33, 135, 1080, 1080, 135, 33, 1080, 33, 1080, 135, 135, 135, 135, 135, 33, 33, 1080, 33, 1080, 33, 135, 1080, 135, 1080, 135, 1080, 135, 1080, 33, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 33, 33, 33, 33, 33, 135, 33, 33, 135, 1080, 1080, 33, 33, 1080, 33, 33, 33, 135, 33, 135, 1080, 1080, 135, 135, 33, 1080, 135, 1080, 33, 135, 135, 33, 33, 135, 33, 1080, 1080, 33, 1080, 1080, 33, 135, 1080, 33, 33, 135, 135, 33, 33, 1080, 1080, 1080, 1080, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 1080, 135, 135, 135, 1080, 33, 135, 135, 1080, 1080, 33, 1080, 1080, 33, 1080, 33, 33, 135, 33, 1080, 1080, 1080, 135, 33, 1080, 1080, 135, 135, 1080, 1080, 33, 1080, 1080, 135, 33, 1080, 135, 135, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 33, 1080, 33, 135, 1080, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 1080, 33, 33, 33, 135, 33, 135, 135, 33, 1080, 135, 1080, 33, 1080, 33, 135, 135, 135, 135, 33, 135, 1080, 1080, 33, 1080, 1080, 33, 1080, 135, 1080, 135, 135, 135, 33, 135, 33, 33, 1080, 33, 135, 33, 33, 135, 1080, 135, 1080, 33, 1080, 1080, 135, 1080, 135, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 159744 . Total input tokens: 35546497 . Total output tokens: 31385770
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 6.907344822771847,
    "estimated_duration": 3600.0607932699654,
    "input_throughput": 3655.023277550877,
    "output_throughput": 3153.915906427459,
    "total_throughput": 6808.939183978337,
    "itl": 83.5413160917356,
    "ttft": 75475.7815269245,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5733,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 37.908940980167436,
    "arrivals": 53529,
    "finished_requests": 52789,
    "scheduler_time": 40.78195992009537
}
#Debug simulation 
Total elapsed time: 6.907437060028315. Arrivals time: 0.14051657682284713 Scheduler time: 6.532218983396888 Scheduler overhead time: 0.06161993136629462 Adapter cache time: 0.08469226164743304 Engine time: 0.0610182024538517 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-16/adapters_384_slots_96_rate_0.1-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-16/adapters_384_slots_96_rate_0.1-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 1080, 135, 33, 1080, 1080, 33, 135, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 1080, 1080, 135, 135, 33, 1080, 33, 1080, 135, 135, 135, 33, 33, 135, 33, 1080, 33, 1080, 135, 1080, 135, 33, 135, 1080, 135, 1080, 33, 1080, 1080, 1080, 1080, 33, 135, 135, 135, 1080, 135, 33, 135, 33, 1080, 135, 1080, 1080, 135, 1080, 1080, 33, 33, 1080, 135, 135, 33, 33, 33, 135, 33, 135, 33, 1080, 33, 135, 1080, 33, 1080, 135, 33, 1080, 1080, 1080, 1080, 135, 33, 135, 1080, 1080, 135, 33, 33, 1080, 135, 135, 33, 33, 1080, 135, 1080, 135, 1080, 1080, 135, 1080, 1080, 33, 135, 135, 135, 135, 33, 33, 1080, 33, 1080, 33, 33, 33, 135, 135, 1080, 33, 33, 1080, 33, 1080, 135, 33, 1080, 135, 135, 33, 1080, 1080, 1080, 33, 135, 1080, 33, 1080, 135, 135, 1080, 1080, 33, 135, 1080, 33, 135, 135, 33, 135, 33, 135, 1080, 1080, 135, 33, 1080, 33, 1080, 135, 135, 135, 135, 135, 33, 33, 1080, 33, 1080, 33, 135, 1080, 135, 1080, 135, 1080, 135, 1080, 33, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 33, 33, 33, 33, 33, 135, 33, 33, 135, 1080, 1080, 33, 33, 1080, 33, 33, 33, 135, 33, 135, 1080, 1080, 135, 135, 33, 1080, 135, 1080, 33, 135, 135, 33, 33, 135, 33, 1080, 1080, 33, 1080, 1080, 33, 135, 1080, 33, 33, 135, 135, 33, 33, 1080, 1080, 1080, 1080, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 1080, 135, 135, 135, 1080, 33, 135, 135, 1080, 1080, 33, 1080, 1080, 33, 1080, 33, 33, 135, 33, 1080, 1080, 1080, 135, 33, 1080, 1080, 135, 135, 1080, 1080, 33, 1080, 1080, 135, 33, 1080, 135, 135, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 33, 1080, 33, 135, 1080, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 1080, 33, 33, 33, 135, 33, 135, 135, 33, 1080, 135, 1080, 33, 1080, 33, 135, 135, 135, 135, 33, 135, 1080, 1080, 33, 1080, 1080, 33, 1080, 135, 1080, 135, 135, 135, 33, 135, 33, 33, 1080, 33, 135, 33, 33, 135, 1080, 135, 1080, 33, 1080, 1080, 135, 1080, 135, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 159744 . Total input tokens: 35546497 . Total output tokens: 31385770
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 6.905321278143674,
    "estimated_duration": 3600.068093165934,
    "input_throughput": 3654.0747729111536,
    "output_throughput": 3152.7925878808774,
    "total_throughput": 6806.867360792031,
    "itl": 83.73518956134458,
    "ttft": 76247.36256652839,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5707,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 41.75269957756956,
    "arrivals": 53529,
    "finished_requests": 52781,
    "scheduler_time": 40.81877960248947
}
#Debug simulation 
Total elapsed time: 6.905416585039347. Arrivals time: 0.13965345732867718 Scheduler time: 6.532644770108163 Scheduler overhead time: 0.06156537029892206 Adapter cache time: 0.0843070768751204 Engine time: 0.059966846369206905 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-32/adapters_384_slots_96_rate_0.1-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-32/adapters_384_slots_96_rate_0.1-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 1080, 135, 33, 1080, 1080, 33, 135, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 1080, 1080, 135, 135, 33, 1080, 33, 1080, 135, 135, 135, 33, 33, 135, 33, 1080, 33, 1080, 135, 1080, 135, 33, 135, 1080, 135, 1080, 33, 1080, 1080, 1080, 1080, 33, 135, 135, 135, 1080, 135, 33, 135, 33, 1080, 135, 1080, 1080, 135, 1080, 1080, 33, 33, 1080, 135, 135, 33, 33, 33, 135, 33, 135, 33, 1080, 33, 135, 1080, 33, 1080, 135, 33, 1080, 1080, 1080, 1080, 135, 33, 135, 1080, 1080, 135, 33, 33, 1080, 135, 135, 33, 33, 1080, 135, 1080, 135, 1080, 1080, 135, 1080, 1080, 33, 135, 135, 135, 135, 33, 33, 1080, 33, 1080, 33, 33, 33, 135, 135, 1080, 33, 33, 1080, 33, 1080, 135, 33, 1080, 135, 135, 33, 1080, 1080, 1080, 33, 135, 1080, 33, 1080, 135, 135, 1080, 1080, 33, 135, 1080, 33, 135, 135, 33, 135, 33, 135, 1080, 1080, 135, 33, 1080, 33, 1080, 135, 135, 135, 135, 135, 33, 33, 1080, 33, 1080, 33, 135, 1080, 135, 1080, 135, 1080, 135, 1080, 33, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 33, 33, 33, 33, 33, 135, 33, 33, 135, 1080, 1080, 33, 33, 1080, 33, 33, 33, 135, 33, 135, 1080, 1080, 135, 135, 33, 1080, 135, 1080, 33, 135, 135, 33, 33, 135, 33, 1080, 1080, 33, 1080, 1080, 33, 135, 1080, 33, 33, 135, 135, 33, 33, 1080, 1080, 1080, 1080, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 1080, 135, 135, 135, 1080, 33, 135, 135, 1080, 1080, 33, 1080, 1080, 33, 1080, 33, 33, 135, 33, 1080, 1080, 1080, 135, 33, 1080, 1080, 135, 135, 1080, 1080, 33, 1080, 1080, 135, 33, 1080, 135, 135, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 33, 1080, 33, 135, 1080, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 1080, 33, 33, 33, 135, 33, 135, 135, 33, 1080, 135, 1080, 33, 1080, 33, 135, 135, 135, 135, 33, 135, 1080, 1080, 33, 1080, 1080, 33, 1080, 135, 1080, 135, 135, 135, 33, 135, 33, 33, 1080, 33, 135, 33, 33, 135, 1080, 135, 1080, 33, 1080, 1080, 135, 1080, 135, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 159744 . Total input tokens: 35546497 . Total output tokens: 31385770
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 6.9594818712212145,
    "estimated_duration": 3600.0198302800613,
    "input_throughput": 3654.7959789922693,
    "output_throughput": 3153.5745732591718,
    "total_throughput": 6808.370552251441,
    "itl": 83.80618337849089,
    "ttft": 75686.35062710177,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5720,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 42.975748449954395,
    "arrivals": 53529,
    "finished_requests": 52789,
    "scheduler_time": 40.82122764352778
}
#Debug simulation 
Total elapsed time: 6.959570045117289. Arrivals time: 0.14028292568400502 Scheduler time: 6.584387176670134 Scheduler overhead time: 0.061712917406111956 Adapter cache time: 0.08456708677113056 Engine time: 0.061110072769224644 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-16/adapters_384_slots_96_rate_0.1-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-16/adapters_384_slots_96_rate_0.1-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 1080, 135, 33, 1080, 1080, 33, 135, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 1080, 1080, 135, 135, 33, 1080, 33, 1080, 135, 135, 135, 33, 33, 135, 33, 1080, 33, 1080, 135, 1080, 135, 33, 135, 1080, 135, 1080, 33, 1080, 1080, 1080, 1080, 33, 135, 135, 135, 1080, 135, 33, 135, 33, 1080, 135, 1080, 1080, 135, 1080, 1080, 33, 33, 1080, 135, 135, 33, 33, 33, 135, 33, 135, 33, 1080, 33, 135, 1080, 33, 1080, 135, 33, 1080, 1080, 1080, 1080, 135, 33, 135, 1080, 1080, 135, 33, 33, 1080, 135, 135, 33, 33, 1080, 135, 1080, 135, 1080, 1080, 135, 1080, 1080, 33, 135, 135, 135, 135, 33, 33, 1080, 33, 1080, 33, 33, 33, 135, 135, 1080, 33, 33, 1080, 33, 1080, 135, 33, 1080, 135, 135, 33, 1080, 1080, 1080, 33, 135, 1080, 33, 1080, 135, 135, 1080, 1080, 33, 135, 1080, 33, 135, 135, 33, 135, 33, 135, 1080, 1080, 135, 33, 1080, 33, 1080, 135, 135, 135, 135, 135, 33, 33, 1080, 33, 1080, 33, 135, 1080, 135, 1080, 135, 1080, 135, 1080, 33, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 33, 33, 33, 33, 33, 135, 33, 33, 135, 1080, 1080, 33, 33, 1080, 33, 33, 33, 135, 33, 135, 1080, 1080, 135, 135, 33, 1080, 135, 1080, 33, 135, 135, 33, 33, 135, 33, 1080, 1080, 33, 1080, 1080, 33, 135, 1080, 33, 33, 135, 135, 33, 33, 1080, 1080, 1080, 1080, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 1080, 135, 135, 135, 1080, 33, 135, 135, 1080, 1080, 33, 1080, 1080, 33, 1080, 33, 33, 135, 33, 1080, 1080, 1080, 135, 33, 1080, 1080, 135, 135, 1080, 1080, 33, 1080, 1080, 135, 33, 1080, 135, 135, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 33, 1080, 33, 135, 1080, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 1080, 33, 33, 33, 135, 33, 135, 135, 33, 1080, 135, 1080, 33, 1080, 33, 135, 135, 135, 135, 33, 135, 1080, 1080, 33, 1080, 1080, 33, 1080, 135, 1080, 135, 135, 135, 33, 135, 33, 33, 1080, 33, 135, 33, 33, 135, 1080, 135, 1080, 33, 1080, 1080, 135, 1080, 135, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 159744 . Total input tokens: 35546497 . Total output tokens: 31385770
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 6.910701986402273,
    "estimated_duration": 3600.0616174677048,
    "input_throughput": 3655.089106295843,
    "output_throughput": 3154.284344718405,
    "total_throughput": 6809.373451014248,
    "itl": 83.60892610189211,
    "ttft": 75425.44648060032,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5729,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 39.32493703763586,
    "arrivals": 53529,
    "finished_requests": 52791,
    "scheduler_time": 40.79383689141239
}
#Debug simulation 
Total elapsed time: 6.910814534407109. Arrivals time: 0.13971728831529617 Scheduler time: 6.537771806586534 Scheduler overhead time: 0.06133989151567221 Adapter cache time: 0.08450361946597695 Engine time: 0.06026390101760626 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-32/adapters_384_slots_96_rate_0.1-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-32/adapters_384_slots_96_rate_0.1-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 1080, 135, 33, 1080, 1080, 33, 135, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 1080, 1080, 135, 135, 33, 1080, 33, 1080, 135, 135, 135, 33, 33, 135, 33, 1080, 33, 1080, 135, 1080, 135, 33, 135, 1080, 135, 1080, 33, 1080, 1080, 1080, 1080, 33, 135, 135, 135, 1080, 135, 33, 135, 33, 1080, 135, 1080, 1080, 135, 1080, 1080, 33, 33, 1080, 135, 135, 33, 33, 33, 135, 33, 135, 33, 1080, 33, 135, 1080, 33, 1080, 135, 33, 1080, 1080, 1080, 1080, 135, 33, 135, 1080, 1080, 135, 33, 33, 1080, 135, 135, 33, 33, 1080, 135, 1080, 135, 1080, 1080, 135, 1080, 1080, 33, 135, 135, 135, 135, 33, 33, 1080, 33, 1080, 33, 33, 33, 135, 135, 1080, 33, 33, 1080, 33, 1080, 135, 33, 1080, 135, 135, 33, 1080, 1080, 1080, 33, 135, 1080, 33, 1080, 135, 135, 1080, 1080, 33, 135, 1080, 33, 135, 135, 33, 135, 33, 135, 1080, 1080, 135, 33, 1080, 33, 1080, 135, 135, 135, 135, 135, 33, 33, 1080, 33, 1080, 33, 135, 1080, 135, 1080, 135, 1080, 135, 1080, 33, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 33, 33, 33, 33, 33, 135, 33, 33, 135, 1080, 1080, 33, 33, 1080, 33, 33, 33, 135, 33, 135, 1080, 1080, 135, 135, 33, 1080, 135, 1080, 33, 135, 135, 33, 33, 135, 33, 1080, 1080, 33, 1080, 1080, 33, 135, 1080, 33, 33, 135, 135, 33, 33, 1080, 1080, 1080, 1080, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 1080, 135, 135, 135, 1080, 33, 135, 135, 1080, 1080, 33, 1080, 1080, 33, 1080, 33, 33, 135, 33, 1080, 1080, 1080, 135, 33, 1080, 1080, 135, 135, 1080, 1080, 33, 1080, 1080, 135, 33, 1080, 135, 135, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 33, 1080, 33, 135, 1080, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 1080, 33, 33, 33, 135, 33, 135, 135, 33, 1080, 135, 1080, 33, 1080, 33, 135, 135, 135, 135, 33, 135, 1080, 1080, 33, 1080, 1080, 33, 1080, 135, 1080, 135, 135, 135, 33, 135, 33, 33, 1080, 33, 135, 33, 33, 135, 1080, 135, 1080, 33, 1080, 1080, 135, 1080, 135, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 159744 . Total input tokens: 35546497 . Total output tokens: 31385770
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 6.92655097739771,
    "estimated_duration": 3600.0373431329986,
    "input_throughput": 3653.8229318900835,
    "output_throughput": 3153.419233735043,
    "total_throughput": 6807.242165625126,
    "itl": 83.79362562216727,
    "ttft": 76105.72130266856,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5716,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 42.56649125377116,
    "arrivals": 53529,
    "finished_requests": 52782,
    "scheduler_time": 40.81287944082268
}
#Debug simulation 
Total elapsed time: 6.92667003814131. Arrivals time: 0.14009699318557978 Scheduler time: 6.552565421443433 Scheduler overhead time: 0.0615158760920167 Adapter cache time: 0.08444390818476677 Engine time: 0.06068692822009325 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-16/adapters_384_slots_96_rate_0.1-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-16/adapters_384_slots_96_rate_0.1-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 1080, 135, 33, 1080, 1080, 33, 135, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 1080, 1080, 135, 135, 33, 1080, 33, 1080, 135, 135, 135, 33, 33, 135, 33, 1080, 33, 1080, 135, 1080, 135, 33, 135, 1080, 135, 1080, 33, 1080, 1080, 1080, 1080, 33, 135, 135, 135, 1080, 135, 33, 135, 33, 1080, 135, 1080, 1080, 135, 1080, 1080, 33, 33, 1080, 135, 135, 33, 33, 33, 135, 33, 135, 33, 1080, 33, 135, 1080, 33, 1080, 135, 33, 1080, 1080, 1080, 1080, 135, 33, 135, 1080, 1080, 135, 33, 33, 1080, 135, 135, 33, 33, 1080, 135, 1080, 135, 1080, 1080, 135, 1080, 1080, 33, 135, 135, 135, 135, 33, 33, 1080, 33, 1080, 33, 33, 33, 135, 135, 1080, 33, 33, 1080, 33, 1080, 135, 33, 1080, 135, 135, 33, 1080, 1080, 1080, 33, 135, 1080, 33, 1080, 135, 135, 1080, 1080, 33, 135, 1080, 33, 135, 135, 33, 135, 33, 135, 1080, 1080, 135, 33, 1080, 33, 1080, 135, 135, 135, 135, 135, 33, 33, 1080, 33, 1080, 33, 135, 1080, 135, 1080, 135, 1080, 135, 1080, 33, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 33, 33, 33, 33, 33, 135, 33, 33, 135, 1080, 1080, 33, 33, 1080, 33, 33, 33, 135, 33, 135, 1080, 1080, 135, 135, 33, 1080, 135, 1080, 33, 135, 135, 33, 33, 135, 33, 1080, 1080, 33, 1080, 1080, 33, 135, 1080, 33, 33, 135, 135, 33, 33, 1080, 1080, 1080, 1080, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 1080, 135, 135, 135, 1080, 33, 135, 135, 1080, 1080, 33, 1080, 1080, 33, 1080, 33, 33, 135, 33, 1080, 1080, 1080, 135, 33, 1080, 1080, 135, 135, 1080, 1080, 33, 1080, 1080, 135, 33, 1080, 135, 135, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 33, 1080, 33, 135, 1080, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 1080, 33, 33, 33, 135, 33, 135, 135, 33, 1080, 135, 1080, 33, 1080, 33, 135, 135, 135, 135, 33, 135, 1080, 1080, 33, 1080, 1080, 33, 1080, 135, 1080, 135, 135, 135, 33, 135, 33, 33, 1080, 33, 135, 33, 33, 135, 1080, 135, 1080, 33, 1080, 1080, 135, 1080, 135, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 159744 . Total input tokens: 35546497 . Total output tokens: 31385770
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 6.878551970236003,
    "estimated_duration": 3600.0571782595525,
    "input_throughput": 3655.128335034267,
    "output_throughput": 3153.732687514954,
    "total_throughput": 6808.861022549221,
    "itl": 83.51067509063232,
    "ttft": 75333.00530126067,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5777,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 36.87991127367978,
    "arrivals": 53529,
    "finished_requests": 52788,
    "scheduler_time": 40.7604034176871
}
#Debug simulation 
Total elapsed time: 6.878645566292107. Arrivals time: 0.14076482504606247 Scheduler time: 6.502287902403623 Scheduler overhead time: 0.06162381079047918 Adapter cache time: 0.08580635162070394 Engine time: 0.06089018424972892 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-32/adapters_384_slots_96_rate_0.1-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-32/adapters_384_slots_96_rate_0.1-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 1080, 135, 33, 1080, 1080, 33, 135, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 1080, 1080, 135, 135, 33, 1080, 33, 1080, 135, 135, 135, 33, 33, 135, 33, 1080, 33, 1080, 135, 1080, 135, 33, 135, 1080, 135, 1080, 33, 1080, 1080, 1080, 1080, 33, 135, 135, 135, 1080, 135, 33, 135, 33, 1080, 135, 1080, 1080, 135, 1080, 1080, 33, 33, 1080, 135, 135, 33, 33, 33, 135, 33, 135, 33, 1080, 33, 135, 1080, 33, 1080, 135, 33, 1080, 1080, 1080, 1080, 135, 33, 135, 1080, 1080, 135, 33, 33, 1080, 135, 135, 33, 33, 1080, 135, 1080, 135, 1080, 1080, 135, 1080, 1080, 33, 135, 135, 135, 135, 33, 33, 1080, 33, 1080, 33, 33, 33, 135, 135, 1080, 33, 33, 1080, 33, 1080, 135, 33, 1080, 135, 135, 33, 1080, 1080, 1080, 33, 135, 1080, 33, 1080, 135, 135, 1080, 1080, 33, 135, 1080, 33, 135, 135, 33, 135, 33, 135, 1080, 1080, 135, 33, 1080, 33, 1080, 135, 135, 135, 135, 135, 33, 33, 1080, 33, 1080, 33, 135, 1080, 135, 1080, 135, 1080, 135, 1080, 33, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 33, 33, 33, 33, 33, 135, 33, 33, 135, 1080, 1080, 33, 33, 1080, 33, 33, 33, 135, 33, 135, 1080, 1080, 135, 135, 33, 1080, 135, 1080, 33, 135, 135, 33, 33, 135, 33, 1080, 1080, 33, 1080, 1080, 33, 135, 1080, 33, 33, 135, 135, 33, 33, 1080, 1080, 1080, 1080, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 1080, 135, 135, 135, 1080, 33, 135, 135, 1080, 1080, 33, 1080, 1080, 33, 1080, 33, 33, 135, 33, 1080, 1080, 1080, 135, 33, 1080, 1080, 135, 135, 1080, 1080, 33, 1080, 1080, 135, 33, 1080, 135, 135, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 33, 1080, 33, 135, 1080, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 1080, 33, 33, 33, 135, 33, 135, 135, 33, 1080, 135, 1080, 33, 1080, 33, 135, 135, 135, 135, 33, 135, 1080, 1080, 33, 1080, 1080, 33, 1080, 135, 1080, 135, 135, 135, 33, 135, 33, 33, 1080, 33, 135, 33, 33, 135, 1080, 135, 1080, 33, 1080, 1080, 135, 1080, 135, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 159744 . Total input tokens: 35546497 . Total output tokens: 31385770
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 6.968210415914655,
    "estimated_duration": 3600.076948882738,
    "input_throughput": 3654.1213387348876,
    "output_throughput": 3153.864809340726,
    "total_throughput": 6807.9861480756135,
    "itl": 83.77016451740478,
    "ttft": 75786.64748219782,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5712,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 42.12280037853808,
    "arrivals": 53529,
    "finished_requests": 52786,
    "scheduler_time": 40.807893210755935
}
#Debug simulation 
Total elapsed time: 6.968299644999206. Arrivals time: 0.14493546076118946 Scheduler time: 6.588552082423121 Scheduler overhead time: 0.06146636884659529 Adapter cache time: 0.08498131623491645 Engine time: 0.06102270586416125 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-8/adapters_384_slots_96_rate_0.1-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-8/adapters_384_slots_96_rate_0.1-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 1080, 66, 33, 1080, 1080, 33, 66, 1080, 1080, 1080, 1080, 66, 66, 66, 66, 1080, 1080, 66, 66, 33, 1080, 33, 1080, 66, 66, 66, 33, 33, 66, 33, 1080, 33, 1080, 66, 1080, 66, 33, 66, 1080, 66, 1080, 33, 1080, 1080, 1080, 1080, 33, 66, 66, 66, 1080, 66, 33, 66, 33, 1080, 66, 1080, 1080, 66, 1080, 1080, 33, 33, 1080, 66, 66, 33, 33, 33, 66, 33, 66, 33, 1080, 33, 66, 1080, 33, 1080, 66, 33, 1080, 1080, 1080, 1080, 66, 33, 66, 1080, 1080, 66, 33, 33, 1080, 66, 66, 33, 33, 1080, 66, 1080, 66, 1080, 1080, 66, 1080, 1080, 33, 66, 66, 66, 66, 33, 33, 1080, 33, 1080, 33, 33, 33, 66, 66, 1080, 33, 33, 1080, 33, 1080, 66, 33, 1080, 66, 66, 33, 1080, 1080, 1080, 33, 66, 1080, 33, 1080, 66, 66, 1080, 1080, 33, 66, 1080, 33, 66, 66, 33, 66, 33, 66, 1080, 1080, 66, 33, 1080, 33, 1080, 66, 66, 66, 66, 66, 33, 33, 1080, 33, 1080, 33, 66, 1080, 66, 1080, 66, 1080, 66, 1080, 33, 66, 66, 66, 66, 66, 66, 66, 66, 1080, 33, 33, 33, 33, 33, 66, 33, 33, 66, 1080, 1080, 33, 33, 1080, 33, 33, 33, 66, 33, 66, 1080, 1080, 66, 66, 33, 1080, 66, 1080, 33, 66, 66, 33, 33, 66, 33, 1080, 1080, 33, 1080, 1080, 33, 66, 1080, 33, 33, 66, 66, 33, 33, 1080, 1080, 1080, 1080, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 1080, 66, 66, 66, 1080, 33, 66, 66, 1080, 1080, 33, 1080, 1080, 33, 1080, 33, 33, 66, 33, 1080, 1080, 1080, 66, 33, 1080, 1080, 66, 66, 1080, 1080, 33, 1080, 1080, 66, 33, 1080, 66, 66, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 33, 1080, 33, 66, 1080, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 1080, 33, 33, 33, 66, 33, 66, 66, 33, 1080, 66, 1080, 33, 1080, 33, 66, 66, 66, 66, 33, 66, 1080, 1080, 33, 1080, 1080, 33, 1080, 66, 1080, 66, 66, 66, 33, 66, 33, 33, 1080, 33, 66, 33, 33, 66, 1080, 66, 1080, 33, 1080, 1080, 66, 1080, 66, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 150912 . Total input tokens: 33584756 . Total output tokens: 29637005
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 5.711527653038502,
    "estimated_duration": 3600.064662434817,
    "input_throughput": 3443.36509545249,
    "output_throughput": 3025.270660731416,
    "total_throughput": 6468.635756183906,
    "itl": 79.4584548307339,
    "ttft": 55455.20613515803,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5929,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 39.204973150430014,
    "arrivals": 50610,
    "finished_requests": 50057,
    "scheduler_time": 37.636614269584015
}
#Debug simulation 
Total elapsed time: 5.711616429965943. Arrivals time: 0.1339130592532456 Scheduler time: 5.340440288651735 Scheduler overhead time: 0.06136824283748865 Adapter cache time: 0.08697352791205049 Engine time: 0.0613770573399961 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-16/adapters_384_slots_96_rate_0.1-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-16/adapters_384_slots_96_rate_0.1-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 1080, 66, 33, 1080, 1080, 33, 66, 1080, 1080, 1080, 1080, 66, 66, 66, 66, 1080, 1080, 66, 66, 33, 1080, 33, 1080, 66, 66, 66, 33, 33, 66, 33, 1080, 33, 1080, 66, 1080, 66, 33, 66, 1080, 66, 1080, 33, 1080, 1080, 1080, 1080, 33, 66, 66, 66, 1080, 66, 33, 66, 33, 1080, 66, 1080, 1080, 66, 1080, 1080, 33, 33, 1080, 66, 66, 33, 33, 33, 66, 33, 66, 33, 1080, 33, 66, 1080, 33, 1080, 66, 33, 1080, 1080, 1080, 1080, 66, 33, 66, 1080, 1080, 66, 33, 33, 1080, 66, 66, 33, 33, 1080, 66, 1080, 66, 1080, 1080, 66, 1080, 1080, 33, 66, 66, 66, 66, 33, 33, 1080, 33, 1080, 33, 33, 33, 66, 66, 1080, 33, 33, 1080, 33, 1080, 66, 33, 1080, 66, 66, 33, 1080, 1080, 1080, 33, 66, 1080, 33, 1080, 66, 66, 1080, 1080, 33, 66, 1080, 33, 66, 66, 33, 66, 33, 66, 1080, 1080, 66, 33, 1080, 33, 1080, 66, 66, 66, 66, 66, 33, 33, 1080, 33, 1080, 33, 66, 1080, 66, 1080, 66, 1080, 66, 1080, 33, 66, 66, 66, 66, 66, 66, 66, 66, 1080, 33, 33, 33, 33, 33, 66, 33, 33, 66, 1080, 1080, 33, 33, 1080, 33, 33, 33, 66, 33, 66, 1080, 1080, 66, 66, 33, 1080, 66, 1080, 33, 66, 66, 33, 33, 66, 33, 1080, 1080, 33, 1080, 1080, 33, 66, 1080, 33, 33, 66, 66, 33, 33, 1080, 1080, 1080, 1080, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 1080, 66, 66, 66, 1080, 33, 66, 66, 1080, 1080, 33, 1080, 1080, 33, 1080, 33, 33, 66, 33, 1080, 1080, 1080, 66, 33, 1080, 1080, 66, 66, 1080, 1080, 33, 1080, 1080, 66, 33, 1080, 66, 66, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 33, 1080, 33, 66, 1080, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 1080, 33, 33, 33, 66, 33, 66, 66, 33, 1080, 66, 1080, 33, 1080, 33, 66, 66, 66, 66, 33, 66, 1080, 1080, 33, 1080, 1080, 33, 1080, 66, 1080, 66, 66, 66, 33, 66, 33, 33, 1080, 33, 66, 33, 33, 66, 1080, 66, 1080, 33, 1080, 1080, 66, 1080, 66, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 150912 . Total input tokens: 33584756 . Total output tokens: 29637005
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 5.6564201740548015,
    "estimated_duration": 3600.0558317458813,
    "input_throughput": 3443.8152016068893,
    "output_throughput": 3025.3219697201603,
    "total_throughput": 6469.13717132705,
    "itl": 79.67230814476959,
    "ttft": 54867.8671556274,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6008,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 43.97272728994347,
    "arrivals": 50610,
    "finished_requests": 50060,
    "scheduler_time": 37.62552734639546
}
#Debug simulation 
Total elapsed time: 5.656509011052549. Arrivals time: 0.13105302909389138 Scheduler time: 5.287049781996757 Scheduler overhead time: 0.06184524763375521 Adapter cache time: 0.08738465933129191 Engine time: 0.06141863204538822 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-32/adapters_384_slots_96_rate_0.1-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-32/adapters_384_slots_96_rate_0.1-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 1080, 66, 33, 1080, 1080, 33, 66, 1080, 1080, 1080, 1080, 66, 66, 66, 66, 1080, 1080, 66, 66, 33, 1080, 33, 1080, 66, 66, 66, 33, 33, 66, 33, 1080, 33, 1080, 66, 1080, 66, 33, 66, 1080, 66, 1080, 33, 1080, 1080, 1080, 1080, 33, 66, 66, 66, 1080, 66, 33, 66, 33, 1080, 66, 1080, 1080, 66, 1080, 1080, 33, 33, 1080, 66, 66, 33, 33, 33, 66, 33, 66, 33, 1080, 33, 66, 1080, 33, 1080, 66, 33, 1080, 1080, 1080, 1080, 66, 33, 66, 1080, 1080, 66, 33, 33, 1080, 66, 66, 33, 33, 1080, 66, 1080, 66, 1080, 1080, 66, 1080, 1080, 33, 66, 66, 66, 66, 33, 33, 1080, 33, 1080, 33, 33, 33, 66, 66, 1080, 33, 33, 1080, 33, 1080, 66, 33, 1080, 66, 66, 33, 1080, 1080, 1080, 33, 66, 1080, 33, 1080, 66, 66, 1080, 1080, 33, 66, 1080, 33, 66, 66, 33, 66, 33, 66, 1080, 1080, 66, 33, 1080, 33, 1080, 66, 66, 66, 66, 66, 33, 33, 1080, 33, 1080, 33, 66, 1080, 66, 1080, 66, 1080, 66, 1080, 33, 66, 66, 66, 66, 66, 66, 66, 66, 1080, 33, 33, 33, 33, 33, 66, 33, 33, 66, 1080, 1080, 33, 33, 1080, 33, 33, 33, 66, 33, 66, 1080, 1080, 66, 66, 33, 1080, 66, 1080, 33, 66, 66, 33, 33, 66, 33, 1080, 1080, 33, 1080, 1080, 33, 66, 1080, 33, 33, 66, 66, 33, 33, 1080, 1080, 1080, 1080, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 1080, 66, 66, 66, 1080, 33, 66, 66, 1080, 1080, 33, 1080, 1080, 33, 1080, 33, 33, 66, 33, 1080, 1080, 1080, 66, 33, 1080, 1080, 66, 66, 1080, 1080, 33, 1080, 1080, 66, 33, 1080, 66, 66, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 33, 1080, 33, 66, 1080, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 1080, 33, 33, 33, 66, 33, 66, 66, 33, 1080, 66, 1080, 33, 1080, 33, 66, 66, 66, 66, 33, 66, 1080, 1080, 33, 1080, 1080, 33, 1080, 66, 1080, 66, 66, 66, 33, 66, 33, 33, 1080, 33, 66, 33, 33, 66, 1080, 66, 1080, 33, 1080, 1080, 66, 1080, 66, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 150912 . Total input tokens: 33584756 . Total output tokens: 29637005
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 5.67676991596818,
    "estimated_duration": 3600.0358380103107,
    "input_throughput": 3443.668218273024,
    "output_throughput": 3025.4779369140283,
    "total_throughput": 6469.1461551870525,
    "itl": 79.72524925406216,
    "ttft": 54826.00835288827,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6000,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 45.108888514986006,
    "arrivals": 50610,
    "finished_requests": 50061,
    "scheduler_time": 37.631793287351734
}
#Debug simulation 
Total elapsed time: 5.676859233062714. Arrivals time: 0.13314153999090195 Scheduler time: 5.305504702031612 Scheduler overhead time: 0.061560044065117836 Adapter cache time: 0.08784420788288116 Engine time: 0.06113029411062598 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-16/adapters_384_slots_96_rate_0.1-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-16/adapters_384_slots_96_rate_0.1-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 1080, 66, 33, 1080, 1080, 33, 66, 1080, 1080, 1080, 1080, 66, 66, 66, 66, 1080, 1080, 66, 66, 33, 1080, 33, 1080, 66, 66, 66, 33, 33, 66, 33, 1080, 33, 1080, 66, 1080, 66, 33, 66, 1080, 66, 1080, 33, 1080, 1080, 1080, 1080, 33, 66, 66, 66, 1080, 66, 33, 66, 33, 1080, 66, 1080, 1080, 66, 1080, 1080, 33, 33, 1080, 66, 66, 33, 33, 33, 66, 33, 66, 33, 1080, 33, 66, 1080, 33, 1080, 66, 33, 1080, 1080, 1080, 1080, 66, 33, 66, 1080, 1080, 66, 33, 33, 1080, 66, 66, 33, 33, 1080, 66, 1080, 66, 1080, 1080, 66, 1080, 1080, 33, 66, 66, 66, 66, 33, 33, 1080, 33, 1080, 33, 33, 33, 66, 66, 1080, 33, 33, 1080, 33, 1080, 66, 33, 1080, 66, 66, 33, 1080, 1080, 1080, 33, 66, 1080, 33, 1080, 66, 66, 1080, 1080, 33, 66, 1080, 33, 66, 66, 33, 66, 33, 66, 1080, 1080, 66, 33, 1080, 33, 1080, 66, 66, 66, 66, 66, 33, 33, 1080, 33, 1080, 33, 66, 1080, 66, 1080, 66, 1080, 66, 1080, 33, 66, 66, 66, 66, 66, 66, 66, 66, 1080, 33, 33, 33, 33, 33, 66, 33, 33, 66, 1080, 1080, 33, 33, 1080, 33, 33, 33, 66, 33, 66, 1080, 1080, 66, 66, 33, 1080, 66, 1080, 33, 66, 66, 33, 33, 66, 33, 1080, 1080, 33, 1080, 1080, 33, 66, 1080, 33, 33, 66, 66, 33, 33, 1080, 1080, 1080, 1080, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 1080, 66, 66, 66, 1080, 33, 66, 66, 1080, 1080, 33, 1080, 1080, 33, 1080, 33, 33, 66, 33, 1080, 1080, 1080, 66, 33, 1080, 1080, 66, 66, 1080, 1080, 33, 1080, 1080, 66, 33, 1080, 66, 66, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 33, 1080, 33, 66, 1080, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 1080, 33, 33, 33, 66, 33, 66, 66, 33, 1080, 66, 1080, 33, 1080, 33, 66, 66, 66, 66, 33, 66, 1080, 1080, 33, 1080, 1080, 33, 1080, 66, 1080, 66, 66, 66, 33, 66, 33, 33, 1080, 33, 66, 33, 33, 66, 1080, 66, 1080, 33, 1080, 1080, 66, 1080, 66, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 150912 . Total input tokens: 33584756 . Total output tokens: 29637005
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 5.668015368748456,
    "estimated_duration": 3600.024978771608,
    "input_throughput": 3443.389441211553,
    "output_throughput": 3025.256786889351,
    "total_throughput": 6468.646228100904,
    "itl": 79.53450320156401,
    "ttft": 55578.53376249525,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5914,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 40.64756095091932,
    "arrivals": 50610,
    "finished_requests": 50056,
    "scheduler_time": 37.64525301495382
}
#Debug simulation 
Total elapsed time: 5.668111437931657. Arrivals time: 0.13203784357756376 Scheduler time: 5.2987226862460375 Scheduler overhead time: 0.061720109079033136 Adapter cache time: 0.0864672171883285 Engine time: 0.06134950602427125 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-32/adapters_384_slots_96_rate_0.1-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-32/adapters_384_slots_96_rate_0.1-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 1080, 66, 33, 1080, 1080, 33, 66, 1080, 1080, 1080, 1080, 66, 66, 66, 66, 1080, 1080, 66, 66, 33, 1080, 33, 1080, 66, 66, 66, 33, 33, 66, 33, 1080, 33, 1080, 66, 1080, 66, 33, 66, 1080, 66, 1080, 33, 1080, 1080, 1080, 1080, 33, 66, 66, 66, 1080, 66, 33, 66, 33, 1080, 66, 1080, 1080, 66, 1080, 1080, 33, 33, 1080, 66, 66, 33, 33, 33, 66, 33, 66, 33, 1080, 33, 66, 1080, 33, 1080, 66, 33, 1080, 1080, 1080, 1080, 66, 33, 66, 1080, 1080, 66, 33, 33, 1080, 66, 66, 33, 33, 1080, 66, 1080, 66, 1080, 1080, 66, 1080, 1080, 33, 66, 66, 66, 66, 33, 33, 1080, 33, 1080, 33, 33, 33, 66, 66, 1080, 33, 33, 1080, 33, 1080, 66, 33, 1080, 66, 66, 33, 1080, 1080, 1080, 33, 66, 1080, 33, 1080, 66, 66, 1080, 1080, 33, 66, 1080, 33, 66, 66, 33, 66, 33, 66, 1080, 1080, 66, 33, 1080, 33, 1080, 66, 66, 66, 66, 66, 33, 33, 1080, 33, 1080, 33, 66, 1080, 66, 1080, 66, 1080, 66, 1080, 33, 66, 66, 66, 66, 66, 66, 66, 66, 1080, 33, 33, 33, 33, 33, 66, 33, 33, 66, 1080, 1080, 33, 33, 1080, 33, 33, 33, 66, 33, 66, 1080, 1080, 66, 66, 33, 1080, 66, 1080, 33, 66, 66, 33, 33, 66, 33, 1080, 1080, 33, 1080, 1080, 33, 66, 1080, 33, 33, 66, 66, 33, 33, 1080, 1080, 1080, 1080, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 1080, 66, 66, 66, 1080, 33, 66, 66, 1080, 1080, 33, 1080, 1080, 33, 1080, 33, 33, 66, 33, 1080, 1080, 1080, 66, 33, 1080, 1080, 66, 66, 1080, 1080, 33, 1080, 1080, 66, 33, 1080, 66, 66, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 33, 1080, 33, 66, 1080, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 1080, 33, 33, 33, 66, 33, 66, 66, 33, 1080, 66, 1080, 33, 1080, 33, 66, 66, 66, 66, 33, 66, 1080, 1080, 33, 1080, 1080, 33, 1080, 66, 1080, 66, 66, 66, 33, 66, 33, 33, 1080, 33, 66, 33, 33, 66, 1080, 66, 1080, 33, 1080, 1080, 66, 1080, 66, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 150912 . Total input tokens: 33584756 . Total output tokens: 29637005
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 5.658812164794654,
    "estimated_duration": 3600.0071637171077,
    "input_throughput": 3443.602036391439,
    "output_throughput": 3025.1487024140242,
    "total_throughput": 6468.750738805463,
    "itl": 79.70376178878102,
    "ttft": 54937.06345141542,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6008,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 44.769825724753346,
    "arrivals": 50610,
    "finished_requests": 50058,
    "scheduler_time": 37.62550289935218
}
#Debug simulation 
Total elapsed time: 5.658930137753487. Arrivals time: 0.13248212169855833 Scheduler time: 5.2896472392603755 Scheduler overhead time: 0.06114374240860343 Adapter cache time: 0.08747138688340783 Engine time: 0.060641161166131496 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-16/adapters_384_slots_96_rate_0.1-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-16/adapters_384_slots_96_rate_0.1-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 1080, 66, 33, 1080, 1080, 33, 66, 1080, 1080, 1080, 1080, 66, 66, 66, 66, 1080, 1080, 66, 66, 33, 1080, 33, 1080, 66, 66, 66, 33, 33, 66, 33, 1080, 33, 1080, 66, 1080, 66, 33, 66, 1080, 66, 1080, 33, 1080, 1080, 1080, 1080, 33, 66, 66, 66, 1080, 66, 33, 66, 33, 1080, 66, 1080, 1080, 66, 1080, 1080, 33, 33, 1080, 66, 66, 33, 33, 33, 66, 33, 66, 33, 1080, 33, 66, 1080, 33, 1080, 66, 33, 1080, 1080, 1080, 1080, 66, 33, 66, 1080, 1080, 66, 33, 33, 1080, 66, 66, 33, 33, 1080, 66, 1080, 66, 1080, 1080, 66, 1080, 1080, 33, 66, 66, 66, 66, 33, 33, 1080, 33, 1080, 33, 33, 33, 66, 66, 1080, 33, 33, 1080, 33, 1080, 66, 33, 1080, 66, 66, 33, 1080, 1080, 1080, 33, 66, 1080, 33, 1080, 66, 66, 1080, 1080, 33, 66, 1080, 33, 66, 66, 33, 66, 33, 66, 1080, 1080, 66, 33, 1080, 33, 1080, 66, 66, 66, 66, 66, 33, 33, 1080, 33, 1080, 33, 66, 1080, 66, 1080, 66, 1080, 66, 1080, 33, 66, 66, 66, 66, 66, 66, 66, 66, 1080, 33, 33, 33, 33, 33, 66, 33, 33, 66, 1080, 1080, 33, 33, 1080, 33, 33, 33, 66, 33, 66, 1080, 1080, 66, 66, 33, 1080, 66, 1080, 33, 66, 66, 33, 33, 66, 33, 1080, 1080, 33, 1080, 1080, 33, 66, 1080, 33, 33, 66, 66, 33, 33, 1080, 1080, 1080, 1080, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 1080, 66, 66, 66, 1080, 33, 66, 66, 1080, 1080, 33, 1080, 1080, 33, 1080, 33, 33, 66, 33, 1080, 1080, 1080, 66, 33, 1080, 1080, 66, 66, 1080, 1080, 33, 1080, 1080, 66, 33, 1080, 66, 66, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 33, 1080, 33, 66, 1080, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 1080, 33, 33, 33, 66, 33, 66, 66, 33, 1080, 66, 1080, 33, 1080, 33, 66, 66, 66, 66, 33, 66, 1080, 1080, 33, 1080, 1080, 33, 1080, 66, 1080, 66, 66, 66, 33, 66, 33, 33, 1080, 33, 66, 33, 33, 66, 1080, 66, 1080, 33, 1080, 1080, 66, 1080, 66, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 150912 . Total input tokens: 33584756 . Total output tokens: 29637005
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 5.6693333042785525,
    "estimated_duration": 3600.0293614252014,
    "input_throughput": 3444.304408420484,
    "output_throughput": 3025.718100167867,
    "total_throughput": 6470.022508588351,
    "itl": 79.42210926946632,
    "ttft": 54107.979366178864,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6039,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 38.552498560109484,
    "arrivals": 50610,
    "finished_requests": 50068,
    "scheduler_time": 37.58625167866925
}
#Debug simulation 
Total elapsed time: 5.669434482231736. Arrivals time: 0.13446553563699126 Scheduler time: 5.296045355964452 Scheduler overhead time: 0.06157970055937767 Adapter cache time: 0.08802830334752798 Engine time: 0.06138884928077459 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-32/adapters_384_slots_96_rate_0.1-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-32/adapters_384_slots_96_rate_0.1-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 1080, 66, 33, 1080, 1080, 33, 66, 1080, 1080, 1080, 1080, 66, 66, 66, 66, 1080, 1080, 66, 66, 33, 1080, 33, 1080, 66, 66, 66, 33, 33, 66, 33, 1080, 33, 1080, 66, 1080, 66, 33, 66, 1080, 66, 1080, 33, 1080, 1080, 1080, 1080, 33, 66, 66, 66, 1080, 66, 33, 66, 33, 1080, 66, 1080, 1080, 66, 1080, 1080, 33, 33, 1080, 66, 66, 33, 33, 33, 66, 33, 66, 33, 1080, 33, 66, 1080, 33, 1080, 66, 33, 1080, 1080, 1080, 1080, 66, 33, 66, 1080, 1080, 66, 33, 33, 1080, 66, 66, 33, 33, 1080, 66, 1080, 66, 1080, 1080, 66, 1080, 1080, 33, 66, 66, 66, 66, 33, 33, 1080, 33, 1080, 33, 33, 33, 66, 66, 1080, 33, 33, 1080, 33, 1080, 66, 33, 1080, 66, 66, 33, 1080, 1080, 1080, 33, 66, 1080, 33, 1080, 66, 66, 1080, 1080, 33, 66, 1080, 33, 66, 66, 33, 66, 33, 66, 1080, 1080, 66, 33, 1080, 33, 1080, 66, 66, 66, 66, 66, 33, 33, 1080, 33, 1080, 33, 66, 1080, 66, 1080, 66, 1080, 66, 1080, 33, 66, 66, 66, 66, 66, 66, 66, 66, 1080, 33, 33, 33, 33, 33, 66, 33, 33, 66, 1080, 1080, 33, 33, 1080, 33, 33, 33, 66, 33, 66, 1080, 1080, 66, 66, 33, 1080, 66, 1080, 33, 66, 66, 33, 33, 66, 33, 1080, 1080, 33, 1080, 1080, 33, 66, 1080, 33, 33, 66, 66, 33, 33, 1080, 1080, 1080, 1080, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 1080, 66, 66, 66, 1080, 33, 66, 66, 1080, 1080, 33, 1080, 1080, 33, 1080, 33, 33, 66, 33, 1080, 1080, 1080, 66, 33, 1080, 1080, 66, 66, 1080, 1080, 33, 1080, 1080, 66, 33, 1080, 66, 66, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 33, 1080, 33, 66, 1080, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 1080, 33, 33, 33, 66, 33, 66, 66, 33, 1080, 66, 1080, 33, 1080, 33, 66, 66, 66, 66, 33, 66, 1080, 1080, 33, 1080, 1080, 33, 1080, 66, 1080, 66, 66, 66, 33, 66, 33, 33, 1080, 33, 66, 33, 33, 66, 1080, 66, 1080, 33, 1080, 1080, 66, 1080, 66, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 150912 . Total input tokens: 33584756 . Total output tokens: 29637005
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 5.696375356987119,
    "estimated_duration": 3600.0147531492703,
    "input_throughput": 3443.3439443979996,
    "output_throughput": 3025.2939909406014,
    "total_throughput": 6468.637935338601,
    "itl": 79.66474699959565,
    "ttft": 55515.01699288851,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5904,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 43.5465419937289,
    "arrivals": 50610,
    "finished_requests": 50058,
    "scheduler_time": 37.66074739264817
}
#Debug simulation 
Total elapsed time: 5.696470335125923. Arrivals time: 0.13245100108906627 Scheduler time: 5.327824198640883 Scheduler overhead time: 0.061161893885582685 Adapter cache time: 0.08614364312961698 Engine time: 0.06141128996387124 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-8/adapters_384_slots_96_rate_0.05-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-8/adapters_384_slots_96_rate_0.05-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 540, 270, 135, 540, 540, 135, 270, 540, 540, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 135, 540, 135, 540, 270, 270, 270, 135, 135, 270, 135, 540, 135, 540, 270, 540, 270, 135, 270, 540, 270, 540, 135, 540, 540, 540, 540, 135, 270, 270, 270, 540, 270, 135, 270, 135, 540, 270, 540, 540, 270, 540, 540, 135, 135, 540, 270, 270, 135, 135, 135, 270, 135, 270, 135, 540, 135, 270, 540, 135, 540, 270, 135, 540, 540, 540, 540, 270, 135, 270, 540, 540, 270, 135, 135, 540, 270, 270, 135, 135, 540, 270, 540, 270, 540, 540, 270, 540, 540, 135, 270, 270, 270, 270, 135, 135, 540, 135, 540, 135, 135, 135, 270, 270, 540, 135, 135, 540, 135, 540, 270, 135, 540, 270, 270, 135, 540, 540, 540, 135, 270, 540, 135, 540, 270, 270, 540, 540, 135, 270, 540, 135, 270, 270, 135, 270, 135, 270, 540, 540, 270, 135, 540, 135, 540, 270, 270, 270, 270, 270, 135, 135, 540, 135, 540, 135, 270, 540, 270, 540, 270, 540, 270, 540, 135, 270, 270, 270, 270, 270, 270, 270, 270, 540, 135, 135, 135, 135, 135, 270, 135, 135, 270, 540, 540, 135, 135, 540, 135, 135, 135, 270, 135, 270, 540, 540, 270, 270, 135, 540, 270, 540, 135, 270, 270, 135, 135, 270, 135, 540, 540, 135, 540, 540, 135, 270, 540, 135, 135, 270, 270, 135, 135, 540, 540, 540, 540, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 540, 270, 270, 270, 540, 135, 270, 270, 540, 540, 135, 540, 540, 135, 540, 135, 135, 270, 135, 540, 540, 540, 270, 135, 540, 540, 270, 270, 540, 540, 135, 540, 540, 270, 135, 540, 270, 270, 540, 540, 540, 135, 540, 135, 540, 540, 135, 135, 540, 135, 270, 540, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 540, 135, 135, 135, 270, 135, 270, 270, 135, 540, 270, 540, 135, 540, 135, 270, 270, 270, 270, 135, 270, 540, 540, 135, 540, 540, 135, 540, 270, 540, 270, 270, 270, 135, 270, 135, 135, 540, 135, 270, 135, 135, 270, 540, 270, 540, 135, 540, 540, 270, 540, 270, 135, 540, 135, 540, 540, 135, 135, 135]
Prompts retrieved: 120960 . Total input tokens: 26885424 . Total output tokens: 23776768
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.829426255077124,
    "estimated_duration": 3599.995271013484,
    "input_throughput": 2740.1180438836896,
    "output_throughput": 2394.0406448294243,
    "total_throughput": 5134.158688713114,
    "itl": 65.20773716989434,
    "ttft": 63005.88120392977,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 12164,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 80.43334346463261,
    "arrivals": 40507,
    "finished_requests": 40040,
    "scheduler_time": 27.06884532535211
}
#Debug simulation 
Total elapsed time: 4.829518490936607. Arrivals time: 0.1104439846239984 Scheduler time: 4.401152269449085 Scheduler overhead time: 0.06753938039764762 Adapter cache time: 0.15493109449744225 Engine time: 0.06544658401980996 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-16/adapters_384_slots_96_rate_0.05-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-16/adapters_384_slots_96_rate_0.05-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 540, 270, 135, 540, 540, 135, 270, 540, 540, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 135, 540, 135, 540, 270, 270, 270, 135, 135, 270, 135, 540, 135, 540, 270, 540, 270, 135, 270, 540, 270, 540, 135, 540, 540, 540, 540, 135, 270, 270, 270, 540, 270, 135, 270, 135, 540, 270, 540, 540, 270, 540, 540, 135, 135, 540, 270, 270, 135, 135, 135, 270, 135, 270, 135, 540, 135, 270, 540, 135, 540, 270, 135, 540, 540, 540, 540, 270, 135, 270, 540, 540, 270, 135, 135, 540, 270, 270, 135, 135, 540, 270, 540, 270, 540, 540, 270, 540, 540, 135, 270, 270, 270, 270, 135, 135, 540, 135, 540, 135, 135, 135, 270, 270, 540, 135, 135, 540, 135, 540, 270, 135, 540, 270, 270, 135, 540, 540, 540, 135, 270, 540, 135, 540, 270, 270, 540, 540, 135, 270, 540, 135, 270, 270, 135, 270, 135, 270, 540, 540, 270, 135, 540, 135, 540, 270, 270, 270, 270, 270, 135, 135, 540, 135, 540, 135, 270, 540, 270, 540, 270, 540, 270, 540, 135, 270, 270, 270, 270, 270, 270, 270, 270, 540, 135, 135, 135, 135, 135, 270, 135, 135, 270, 540, 540, 135, 135, 540, 135, 135, 135, 270, 135, 270, 540, 540, 270, 270, 135, 540, 270, 540, 135, 270, 270, 135, 135, 270, 135, 540, 540, 135, 540, 540, 135, 270, 540, 135, 135, 270, 270, 135, 135, 540, 540, 540, 540, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 540, 270, 270, 270, 540, 135, 270, 270, 540, 540, 135, 540, 540, 135, 540, 135, 135, 270, 135, 540, 540, 540, 270, 135, 540, 540, 270, 270, 540, 540, 135, 540, 540, 270, 135, 540, 270, 270, 540, 540, 540, 135, 540, 135, 540, 540, 135, 135, 540, 135, 270, 540, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 540, 135, 135, 135, 270, 135, 270, 270, 135, 540, 270, 540, 135, 540, 135, 270, 270, 270, 270, 135, 270, 540, 540, 135, 540, 540, 135, 540, 270, 540, 270, 270, 270, 135, 270, 135, 135, 540, 135, 270, 135, 135, 270, 540, 270, 540, 135, 540, 540, 270, 540, 270, 135, 540, 135, 540, 540, 135, 135, 135]
Prompts retrieved: 120960 . Total input tokens: 26885424 . Total output tokens: 23776768
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.782504153903574,
    "estimated_duration": 3599.9538391590418,
    "input_throughput": 2739.713463188179,
    "output_throughput": 2393.94569626293,
    "total_throughput": 5133.659159451109,
    "itl": 65.45141564912349,
    "ttft": 63501.595201393975,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 12055,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 88.1347339947244,
    "arrivals": 40507,
    "finished_requests": 40037,
    "scheduler_time": 27.116237374741388
}
#Debug simulation 
Total elapsed time: 4.7825916721485555. Arrivals time: 0.10755016980692744 Scheduler time: 4.359344142023474 Scheduler overhead time: 0.0672283130697906 Adapter cache time: 0.15384717797860503 Engine time: 0.0649300329387188 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-32/adapters_384_slots_96_rate_0.05-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-32/adapters_384_slots_96_rate_0.05-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 540, 270, 135, 540, 540, 135, 270, 540, 540, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 135, 540, 135, 540, 270, 270, 270, 135, 135, 270, 135, 540, 135, 540, 270, 540, 270, 135, 270, 540, 270, 540, 135, 540, 540, 540, 540, 135, 270, 270, 270, 540, 270, 135, 270, 135, 540, 270, 540, 540, 270, 540, 540, 135, 135, 540, 270, 270, 135, 135, 135, 270, 135, 270, 135, 540, 135, 270, 540, 135, 540, 270, 135, 540, 540, 540, 540, 270, 135, 270, 540, 540, 270, 135, 135, 540, 270, 270, 135, 135, 540, 270, 540, 270, 540, 540, 270, 540, 540, 135, 270, 270, 270, 270, 135, 135, 540, 135, 540, 135, 135, 135, 270, 270, 540, 135, 135, 540, 135, 540, 270, 135, 540, 270, 270, 135, 540, 540, 540, 135, 270, 540, 135, 540, 270, 270, 540, 540, 135, 270, 540, 135, 270, 270, 135, 270, 135, 270, 540, 540, 270, 135, 540, 135, 540, 270, 270, 270, 270, 270, 135, 135, 540, 135, 540, 135, 270, 540, 270, 540, 270, 540, 270, 540, 135, 270, 270, 270, 270, 270, 270, 270, 270, 540, 135, 135, 135, 135, 135, 270, 135, 135, 270, 540, 540, 135, 135, 540, 135, 135, 135, 270, 135, 270, 540, 540, 270, 270, 135, 540, 270, 540, 135, 270, 270, 135, 135, 270, 135, 540, 540, 135, 540, 540, 135, 270, 540, 135, 135, 270, 270, 135, 135, 540, 540, 540, 540, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 540, 270, 270, 270, 540, 135, 270, 270, 540, 540, 135, 540, 540, 135, 540, 135, 135, 270, 135, 540, 540, 540, 270, 135, 540, 540, 270, 270, 540, 540, 135, 540, 540, 270, 135, 540, 270, 270, 540, 540, 540, 135, 540, 135, 540, 540, 135, 135, 540, 135, 270, 540, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 540, 135, 135, 135, 270, 135, 270, 270, 135, 540, 270, 540, 135, 540, 135, 270, 270, 270, 270, 135, 270, 540, 540, 135, 540, 540, 135, 540, 270, 540, 270, 270, 270, 135, 270, 135, 135, 540, 135, 270, 135, 135, 270, 540, 270, 540, 135, 540, 540, 270, 540, 270, 135, 540, 135, 540, 540, 135, 135, 135]
Prompts retrieved: 120960 . Total input tokens: 26885424 . Total output tokens: 23776768
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.837989239953458,
    "estimated_duration": 3599.9501469504376,
    "input_throughput": 2739.6212717986236,
    "output_throughput": 2393.859539221737,
    "total_throughput": 5133.480811020361,
    "itl": 65.52456201477057,
    "ttft": 63894.68018158499,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 12051,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 90.48782584128608,
    "arrivals": 40507,
    "finished_requests": 40033,
    "scheduler_time": 27.127345603592406
}
#Debug simulation 
Total elapsed time: 4.838086913805455. Arrivals time: 0.10997678153216839 Scheduler time: 4.4099068799987435 Scheduler overhead time: 0.06811795849353075 Adapter cache time: 0.15349702071398497 Engine time: 0.0666391565464437 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-16/adapters_384_slots_96_rate_0.05-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-16/adapters_384_slots_96_rate_0.05-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 540, 270, 135, 540, 540, 135, 270, 540, 540, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 135, 540, 135, 540, 270, 270, 270, 135, 135, 270, 135, 540, 135, 540, 270, 540, 270, 135, 270, 540, 270, 540, 135, 540, 540, 540, 540, 135, 270, 270, 270, 540, 270, 135, 270, 135, 540, 270, 540, 540, 270, 540, 540, 135, 135, 540, 270, 270, 135, 135, 135, 270, 135, 270, 135, 540, 135, 270, 540, 135, 540, 270, 135, 540, 540, 540, 540, 270, 135, 270, 540, 540, 270, 135, 135, 540, 270, 270, 135, 135, 540, 270, 540, 270, 540, 540, 270, 540, 540, 135, 270, 270, 270, 270, 135, 135, 540, 135, 540, 135, 135, 135, 270, 270, 540, 135, 135, 540, 135, 540, 270, 135, 540, 270, 270, 135, 540, 540, 540, 135, 270, 540, 135, 540, 270, 270, 540, 540, 135, 270, 540, 135, 270, 270, 135, 270, 135, 270, 540, 540, 270, 135, 540, 135, 540, 270, 270, 270, 270, 270, 135, 135, 540, 135, 540, 135, 270, 540, 270, 540, 270, 540, 270, 540, 135, 270, 270, 270, 270, 270, 270, 270, 270, 540, 135, 135, 135, 135, 135, 270, 135, 135, 270, 540, 540, 135, 135, 540, 135, 135, 135, 270, 135, 270, 540, 540, 270, 270, 135, 540, 270, 540, 135, 270, 270, 135, 135, 270, 135, 540, 540, 135, 540, 540, 135, 270, 540, 135, 135, 270, 270, 135, 135, 540, 540, 540, 540, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 540, 270, 270, 270, 540, 135, 270, 270, 540, 540, 135, 540, 540, 135, 540, 135, 135, 270, 135, 540, 540, 540, 270, 135, 540, 540, 270, 270, 540, 540, 135, 540, 540, 270, 135, 540, 270, 270, 540, 540, 540, 135, 540, 135, 540, 540, 135, 135, 540, 135, 270, 540, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 540, 135, 135, 135, 270, 135, 270, 270, 135, 540, 270, 540, 135, 540, 135, 270, 270, 270, 270, 135, 270, 540, 540, 135, 540, 540, 135, 540, 270, 540, 270, 270, 270, 135, 270, 135, 135, 540, 135, 270, 135, 135, 270, 540, 270, 540, 135, 540, 540, 270, 540, 270, 135, 540, 135, 540, 540, 135, 135, 135]
Prompts retrieved: 120960 . Total input tokens: 26885424 . Total output tokens: 23776768
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 4.823704385198653,
    "estimated_duration": 3599.971515484516,
    "input_throughput": 2739.7063997803793,
    "output_throughput": 2393.973386436665,
    "total_throughput": 5133.679786217044,
    "itl": 65.29603023805554,
    "ttft": 63442.21416243297,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 12139,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 83.19445161400482,
    "arrivals": 40507,
    "finished_requests": 40036,
    "scheduler_time": 27.086047271775573
}
#Debug simulation 
Total elapsed time: 4.823820089455694. Arrivals time: 0.10799741977825761 Scheduler time: 4.397826861590147 Scheduler overhead time: 0.06719464715570211 Adapter cache time: 0.15563480835407972 Engine time: 0.06530948588624597 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-32/adapters_384_slots_96_rate_0.05-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-32/adapters_384_slots_96_rate_0.05-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 540, 270, 135, 540, 540, 135, 270, 540, 540, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 135, 540, 135, 540, 270, 270, 270, 135, 135, 270, 135, 540, 135, 540, 270, 540, 270, 135, 270, 540, 270, 540, 135, 540, 540, 540, 540, 135, 270, 270, 270, 540, 270, 135, 270, 135, 540, 270, 540, 540, 270, 540, 540, 135, 135, 540, 270, 270, 135, 135, 135, 270, 135, 270, 135, 540, 135, 270, 540, 135, 540, 270, 135, 540, 540, 540, 540, 270, 135, 270, 540, 540, 270, 135, 135, 540, 270, 270, 135, 135, 540, 270, 540, 270, 540, 540, 270, 540, 540, 135, 270, 270, 270, 270, 135, 135, 540, 135, 540, 135, 135, 135, 270, 270, 540, 135, 135, 540, 135, 540, 270, 135, 540, 270, 270, 135, 540, 540, 540, 135, 270, 540, 135, 540, 270, 270, 540, 540, 135, 270, 540, 135, 270, 270, 135, 270, 135, 270, 540, 540, 270, 135, 540, 135, 540, 270, 270, 270, 270, 270, 135, 135, 540, 135, 540, 135, 270, 540, 270, 540, 270, 540, 270, 540, 135, 270, 270, 270, 270, 270, 270, 270, 270, 540, 135, 135, 135, 135, 135, 270, 135, 135, 270, 540, 540, 135, 135, 540, 135, 135, 135, 270, 135, 270, 540, 540, 270, 270, 135, 540, 270, 540, 135, 270, 270, 135, 135, 270, 135, 540, 540, 135, 540, 540, 135, 270, 540, 135, 135, 270, 270, 135, 135, 540, 540, 540, 540, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 540, 270, 270, 270, 540, 135, 270, 270, 540, 540, 135, 540, 540, 135, 540, 135, 135, 270, 135, 540, 540, 540, 270, 135, 540, 540, 270, 270, 540, 540, 135, 540, 540, 270, 135, 540, 270, 270, 540, 540, 540, 135, 540, 135, 540, 540, 135, 135, 540, 135, 270, 540, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 540, 135, 135, 135, 270, 135, 270, 270, 135, 540, 270, 540, 135, 540, 135, 270, 270, 270, 270, 135, 270, 540, 540, 135, 540, 540, 135, 540, 270, 540, 270, 270, 270, 135, 270, 135, 135, 540, 135, 270, 135, 135, 270, 540, 270, 540, 135, 540, 540, 270, 540, 270, 135, 540, 135, 540, 540, 135, 135, 135]
Prompts retrieved: 120960 . Total input tokens: 26885424 . Total output tokens: 23776768
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 4.830108941998333,
    "estimated_duration": 3599.9445772624445,
    "input_throughput": 2739.3810622215765,
    "output_throughput": 2393.75185230019,
    "total_throughput": 5133.132914521767,
    "itl": 65.4964119069832,
    "ttft": 63986.486097563386,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 12055,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 89.69300751059463,
    "arrivals": 40507,
    "finished_requests": 40032,
    "scheduler_time": 27.12519019283027
}
#Debug simulation 
Total elapsed time: 4.830199607647955. Arrivals time: 0.11154916184023023 Scheduler time: 4.403122264426202 Scheduler overhead time: 0.06724961288273335 Adapter cache time: 0.15317970886826515 Engine time: 0.06525519723072648 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-16/adapters_384_slots_96_rate_0.05-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-16/adapters_384_slots_96_rate_0.05-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 540, 270, 135, 540, 540, 135, 270, 540, 540, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 135, 540, 135, 540, 270, 270, 270, 135, 135, 270, 135, 540, 135, 540, 270, 540, 270, 135, 270, 540, 270, 540, 135, 540, 540, 540, 540, 135, 270, 270, 270, 540, 270, 135, 270, 135, 540, 270, 540, 540, 270, 540, 540, 135, 135, 540, 270, 270, 135, 135, 135, 270, 135, 270, 135, 540, 135, 270, 540, 135, 540, 270, 135, 540, 540, 540, 540, 270, 135, 270, 540, 540, 270, 135, 135, 540, 270, 270, 135, 135, 540, 270, 540, 270, 540, 540, 270, 540, 540, 135, 270, 270, 270, 270, 135, 135, 540, 135, 540, 135, 135, 135, 270, 270, 540, 135, 135, 540, 135, 540, 270, 135, 540, 270, 270, 135, 540, 540, 540, 135, 270, 540, 135, 540, 270, 270, 540, 540, 135, 270, 540, 135, 270, 270, 135, 270, 135, 270, 540, 540, 270, 135, 540, 135, 540, 270, 270, 270, 270, 270, 135, 135, 540, 135, 540, 135, 270, 540, 270, 540, 270, 540, 270, 540, 135, 270, 270, 270, 270, 270, 270, 270, 270, 540, 135, 135, 135, 135, 135, 270, 135, 135, 270, 540, 540, 135, 135, 540, 135, 135, 135, 270, 135, 270, 540, 540, 270, 270, 135, 540, 270, 540, 135, 270, 270, 135, 135, 270, 135, 540, 540, 135, 540, 540, 135, 270, 540, 135, 135, 270, 270, 135, 135, 540, 540, 540, 540, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 540, 270, 270, 270, 540, 135, 270, 270, 540, 540, 135, 540, 540, 135, 540, 135, 135, 270, 135, 540, 540, 540, 270, 135, 540, 540, 270, 270, 540, 540, 135, 540, 540, 270, 135, 540, 270, 270, 540, 540, 540, 135, 540, 135, 540, 540, 135, 135, 540, 135, 270, 540, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 540, 135, 135, 135, 270, 135, 270, 270, 135, 540, 270, 540, 135, 540, 135, 270, 270, 270, 270, 135, 270, 540, 540, 135, 540, 540, 135, 540, 270, 540, 270, 270, 270, 135, 270, 135, 135, 540, 135, 270, 135, 135, 270, 540, 270, 540, 135, 540, 540, 270, 540, 270, 135, 540, 135, 540, 540, 135, 135, 135]
Prompts retrieved: 120960 . Total input tokens: 26885424 . Total output tokens: 23776768
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.782429957296699,
    "estimated_duration": 3599.94311322301,
    "input_throughput": 2739.8369056919564,
    "output_throughput": 2393.7992154228127,
    "total_throughput": 5133.636121114769,
    "itl": 65.08054687822916,
    "ttft": 63655.036303935034,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 12017,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 76.71557794283108,
    "arrivals": 40507,
    "finished_requests": 40037,
    "scheduler_time": 27.083661923409288
}
#Debug simulation 
Total elapsed time: 4.782521087210625. Arrivals time: 0.10999740054830909 Scheduler time: 4.35912813199684 Scheduler overhead time: 0.06750280130654573 Adapter cache time: 0.15145088965073228 Engine time: 0.0645432067103684 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-32/adapters_384_slots_96_rate_0.05-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-32/adapters_384_slots_96_rate_0.05-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 540, 270, 135, 540, 540, 135, 270, 540, 540, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 135, 540, 135, 540, 270, 270, 270, 135, 135, 270, 135, 540, 135, 540, 270, 540, 270, 135, 270, 540, 270, 540, 135, 540, 540, 540, 540, 135, 270, 270, 270, 540, 270, 135, 270, 135, 540, 270, 540, 540, 270, 540, 540, 135, 135, 540, 270, 270, 135, 135, 135, 270, 135, 270, 135, 540, 135, 270, 540, 135, 540, 270, 135, 540, 540, 540, 540, 270, 135, 270, 540, 540, 270, 135, 135, 540, 270, 270, 135, 135, 540, 270, 540, 270, 540, 540, 270, 540, 540, 135, 270, 270, 270, 270, 135, 135, 540, 135, 540, 135, 135, 135, 270, 270, 540, 135, 135, 540, 135, 540, 270, 135, 540, 270, 270, 135, 540, 540, 540, 135, 270, 540, 135, 540, 270, 270, 540, 540, 135, 270, 540, 135, 270, 270, 135, 270, 135, 270, 540, 540, 270, 135, 540, 135, 540, 270, 270, 270, 270, 270, 135, 135, 540, 135, 540, 135, 270, 540, 270, 540, 270, 540, 270, 540, 135, 270, 270, 270, 270, 270, 270, 270, 270, 540, 135, 135, 135, 135, 135, 270, 135, 135, 270, 540, 540, 135, 135, 540, 135, 135, 135, 270, 135, 270, 540, 540, 270, 270, 135, 540, 270, 540, 135, 270, 270, 135, 135, 270, 135, 540, 540, 135, 540, 540, 135, 270, 540, 135, 135, 270, 270, 135, 135, 540, 540, 540, 540, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 540, 270, 270, 270, 540, 135, 270, 270, 540, 540, 135, 540, 540, 135, 540, 135, 135, 270, 135, 540, 540, 540, 270, 135, 540, 540, 270, 270, 540, 540, 135, 540, 540, 270, 135, 540, 270, 270, 540, 540, 540, 135, 540, 135, 540, 540, 135, 135, 540, 135, 270, 540, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 540, 135, 135, 135, 270, 135, 270, 270, 135, 540, 270, 540, 135, 540, 135, 270, 270, 270, 270, 135, 270, 540, 540, 135, 540, 540, 135, 540, 270, 540, 270, 270, 270, 135, 270, 135, 135, 540, 135, 270, 135, 135, 270, 540, 270, 540, 135, 540, 540, 270, 540, 270, 135, 540, 135, 540, 540, 135, 135, 135]
Prompts retrieved: 120960 . Total input tokens: 26885424 . Total output tokens: 23776768
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.831636489368975,
    "estimated_duration": 3599.9595198116253,
    "input_throughput": 2739.4696928470034,
    "output_throughput": 2393.841361985909,
    "total_throughput": 5133.311054832912,
    "itl": 65.47438937922384,
    "ttft": 63852.03501028098,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 12067,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 88.94493417947201,
    "arrivals": 40507,
    "finished_requests": 40033,
    "scheduler_time": 27.116927796572188
}
#Debug simulation 
Total elapsed time: 4.831727331038564. Arrivals time: 0.10967201553285122 Scheduler time: 4.405966983176768 Scheduler overhead time: 0.0670911562629044 Adapter cache time: 0.1539698112756014 Engine time: 0.06513137649744749 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-8/adapters_384_slots_96_rate_0.05-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-8/adapters_384_slots_96_rate_0.05-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 540, 270, 66, 540, 540, 66, 270, 540, 540, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 66, 540, 66, 540, 270, 270, 270, 66, 66, 270, 66, 540, 66, 540, 270, 540, 270, 66, 270, 540, 270, 540, 66, 540, 540, 540, 540, 66, 270, 270, 270, 540, 270, 66, 270, 66, 540, 270, 540, 540, 270, 540, 540, 66, 66, 540, 270, 270, 66, 66, 66, 270, 66, 270, 66, 540, 66, 270, 540, 66, 540, 270, 66, 540, 540, 540, 540, 270, 66, 270, 540, 540, 270, 66, 66, 540, 270, 270, 66, 66, 540, 270, 540, 270, 540, 540, 270, 540, 540, 66, 270, 270, 270, 270, 66, 66, 540, 66, 540, 66, 66, 66, 270, 270, 540, 66, 66, 540, 66, 540, 270, 66, 540, 270, 270, 66, 540, 540, 540, 66, 270, 540, 66, 540, 270, 270, 540, 540, 66, 270, 540, 66, 270, 270, 66, 270, 66, 270, 540, 540, 270, 66, 540, 66, 540, 270, 270, 270, 270, 270, 66, 66, 540, 66, 540, 66, 270, 540, 270, 540, 270, 540, 270, 540, 66, 270, 270, 270, 270, 270, 270, 270, 270, 540, 66, 66, 66, 66, 66, 270, 66, 66, 270, 540, 540, 66, 66, 540, 66, 66, 66, 270, 66, 270, 540, 540, 270, 270, 66, 540, 270, 540, 66, 270, 270, 66, 66, 270, 66, 540, 540, 66, 540, 540, 66, 270, 540, 66, 66, 270, 270, 66, 66, 540, 540, 540, 540, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 540, 270, 270, 270, 540, 66, 270, 270, 540, 540, 66, 540, 540, 66, 540, 66, 66, 270, 66, 540, 540, 540, 270, 66, 540, 540, 270, 270, 540, 540, 66, 540, 540, 270, 66, 540, 270, 270, 540, 540, 540, 66, 540, 66, 540, 540, 66, 66, 540, 66, 270, 540, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 540, 66, 66, 66, 270, 66, 270, 270, 66, 540, 270, 540, 66, 540, 66, 270, 270, 270, 270, 66, 270, 540, 540, 66, 540, 540, 66, 540, 270, 540, 270, 270, 270, 66, 270, 66, 66, 540, 66, 270, 66, 66, 270, 540, 270, 540, 66, 540, 540, 270, 540, 270, 66, 540, 66, 540, 540, 66, 66, 66]
Prompts retrieved: 112128 . Total input tokens: 24949201 . Total output tokens: 22033828
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.049029651097953,
    "estimated_duration": 3600.005866698273,
    "input_throughput": 2555.537779841922,
    "output_throughput": 2252.943550738878,
    "total_throughput": 4808.4813305808,
    "itl": 62.754382211386,
    "ttft": 47159.57170286676,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 13536,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 89.50556865646091,
    "arrivals": 37708,
    "finished_requests": 37346,
    "scheduler_time": 23.782284424463775
}
#Debug simulation 
Total elapsed time: 4.049118205904961. Arrivals time: 0.10156856430694461 Scheduler time: 3.615504170767963 Scheduler overhead time: 0.06634187512099743 Adapter cache time: 0.1686442089267075 Engine time: 0.06631527841091156 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-16/adapters_384_slots_96_rate_0.05-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-16/adapters_384_slots_96_rate_0.05-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 540, 270, 66, 540, 540, 66, 270, 540, 540, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 66, 540, 66, 540, 270, 270, 270, 66, 66, 270, 66, 540, 66, 540, 270, 540, 270, 66, 270, 540, 270, 540, 66, 540, 540, 540, 540, 66, 270, 270, 270, 540, 270, 66, 270, 66, 540, 270, 540, 540, 270, 540, 540, 66, 66, 540, 270, 270, 66, 66, 66, 270, 66, 270, 66, 540, 66, 270, 540, 66, 540, 270, 66, 540, 540, 540, 540, 270, 66, 270, 540, 540, 270, 66, 66, 540, 270, 270, 66, 66, 540, 270, 540, 270, 540, 540, 270, 540, 540, 66, 270, 270, 270, 270, 66, 66, 540, 66, 540, 66, 66, 66, 270, 270, 540, 66, 66, 540, 66, 540, 270, 66, 540, 270, 270, 66, 540, 540, 540, 66, 270, 540, 66, 540, 270, 270, 540, 540, 66, 270, 540, 66, 270, 270, 66, 270, 66, 270, 540, 540, 270, 66, 540, 66, 540, 270, 270, 270, 270, 270, 66, 66, 540, 66, 540, 66, 270, 540, 270, 540, 270, 540, 270, 540, 66, 270, 270, 270, 270, 270, 270, 270, 270, 540, 66, 66, 66, 66, 66, 270, 66, 66, 270, 540, 540, 66, 66, 540, 66, 66, 66, 270, 66, 270, 540, 540, 270, 270, 66, 540, 270, 540, 66, 270, 270, 66, 66, 270, 66, 540, 540, 66, 540, 540, 66, 270, 540, 66, 66, 270, 270, 66, 66, 540, 540, 540, 540, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 540, 270, 270, 270, 540, 66, 270, 270, 540, 540, 66, 540, 540, 66, 540, 66, 66, 270, 66, 540, 540, 540, 270, 66, 540, 540, 270, 270, 540, 540, 66, 540, 540, 270, 66, 540, 270, 270, 540, 540, 540, 66, 540, 66, 540, 540, 66, 66, 540, 66, 270, 540, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 540, 66, 66, 66, 270, 66, 270, 270, 66, 540, 270, 540, 66, 540, 66, 270, 270, 270, 270, 66, 270, 540, 540, 66, 540, 540, 66, 540, 270, 540, 270, 270, 270, 66, 270, 66, 66, 540, 66, 270, 66, 66, 270, 540, 270, 540, 66, 540, 540, 270, 540, 270, 66, 540, 66, 540, 540, 66, 66, 66]
Prompts retrieved: 112128 . Total input tokens: 24949201 . Total output tokens: 22033828
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 3.9998181858099997,
    "estimated_duration": 3600.0158075544164,
    "input_throughput": 2555.2757242610946,
    "output_throughput": 2252.532053604719,
    "total_throughput": 4807.8077778658135,
    "itl": 63.014336268375466,
    "ttft": 48058.28077666269,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 13440,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 98.3952263321435,
    "arrivals": 37708,
    "finished_requests": 37339,
    "scheduler_time": 23.836892480726934
}
#Debug simulation 
Total elapsed time: 3.9999078740365803. Arrivals time: 0.09978252463042736 Scheduler time: 3.5734571940265596 Scheduler overhead time: 0.06647784588858485 Adapter cache time: 0.16513391630724072 Engine time: 0.06459091184660792 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-32/adapters_384_slots_96_rate_0.05-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-32/adapters_384_slots_96_rate_0.05-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 540, 270, 66, 540, 540, 66, 270, 540, 540, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 66, 540, 66, 540, 270, 270, 270, 66, 66, 270, 66, 540, 66, 540, 270, 540, 270, 66, 270, 540, 270, 540, 66, 540, 540, 540, 540, 66, 270, 270, 270, 540, 270, 66, 270, 66, 540, 270, 540, 540, 270, 540, 540, 66, 66, 540, 270, 270, 66, 66, 66, 270, 66, 270, 66, 540, 66, 270, 540, 66, 540, 270, 66, 540, 540, 540, 540, 270, 66, 270, 540, 540, 270, 66, 66, 540, 270, 270, 66, 66, 540, 270, 540, 270, 540, 540, 270, 540, 540, 66, 270, 270, 270, 270, 66, 66, 540, 66, 540, 66, 66, 66, 270, 270, 540, 66, 66, 540, 66, 540, 270, 66, 540, 270, 270, 66, 540, 540, 540, 66, 270, 540, 66, 540, 270, 270, 540, 540, 66, 270, 540, 66, 270, 270, 66, 270, 66, 270, 540, 540, 270, 66, 540, 66, 540, 270, 270, 270, 270, 270, 66, 66, 540, 66, 540, 66, 270, 540, 270, 540, 270, 540, 270, 540, 66, 270, 270, 270, 270, 270, 270, 270, 270, 540, 66, 66, 66, 66, 66, 270, 66, 66, 270, 540, 540, 66, 66, 540, 66, 66, 66, 270, 66, 270, 540, 540, 270, 270, 66, 540, 270, 540, 66, 270, 270, 66, 66, 270, 66, 540, 540, 66, 540, 540, 66, 270, 540, 66, 66, 270, 270, 66, 66, 540, 540, 540, 540, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 540, 270, 270, 270, 540, 66, 270, 270, 540, 540, 66, 540, 540, 66, 540, 66, 66, 270, 66, 540, 540, 540, 270, 66, 540, 540, 270, 270, 540, 540, 66, 540, 540, 270, 66, 540, 270, 270, 540, 540, 540, 66, 540, 66, 540, 540, 66, 66, 540, 66, 270, 540, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 540, 66, 66, 66, 270, 66, 270, 270, 66, 540, 270, 540, 66, 540, 66, 270, 270, 270, 270, 66, 270, 540, 540, 66, 540, 540, 66, 540, 270, 540, 270, 270, 270, 66, 270, 66, 66, 540, 66, 270, 66, 66, 270, 540, 270, 540, 66, 540, 540, 270, 540, 270, 66, 540, 66, 540, 540, 66, 66, 66]
Prompts retrieved: 112128 . Total input tokens: 24949201 . Total output tokens: 22033828
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.0712843127548695,
    "estimated_duration": 3600.0241628214076,
    "input_throughput": 2555.270071518226,
    "output_throughput": 2252.527381273103,
    "total_throughput": 4807.797452791329,
    "itl": 63.088109815969005,
    "ttft": 48140.41317803568,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 13390,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 100.712149882495,
    "arrivals": 37708,
    "finished_requests": 37340,
    "scheduler_time": 23.854374575810784
}
#Debug simulation 
Total elapsed time: 4.071375655941665. Arrivals time: 0.10140947578474879 Scheduler time: 3.640554321464151 Scheduler overhead time: 0.06627171067520976 Adapter cache time: 0.16689923591911793 Engine time: 0.06567837297916412 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-16/adapters_384_slots_96_rate_0.05-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-16/adapters_384_slots_96_rate_0.05-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 540, 270, 66, 540, 540, 66, 270, 540, 540, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 66, 540, 66, 540, 270, 270, 270, 66, 66, 270, 66, 540, 66, 540, 270, 540, 270, 66, 270, 540, 270, 540, 66, 540, 540, 540, 540, 66, 270, 270, 270, 540, 270, 66, 270, 66, 540, 270, 540, 540, 270, 540, 540, 66, 66, 540, 270, 270, 66, 66, 66, 270, 66, 270, 66, 540, 66, 270, 540, 66, 540, 270, 66, 540, 540, 540, 540, 270, 66, 270, 540, 540, 270, 66, 66, 540, 270, 270, 66, 66, 540, 270, 540, 270, 540, 540, 270, 540, 540, 66, 270, 270, 270, 270, 66, 66, 540, 66, 540, 66, 66, 66, 270, 270, 540, 66, 66, 540, 66, 540, 270, 66, 540, 270, 270, 66, 540, 540, 540, 66, 270, 540, 66, 540, 270, 270, 540, 540, 66, 270, 540, 66, 270, 270, 66, 270, 66, 270, 540, 540, 270, 66, 540, 66, 540, 270, 270, 270, 270, 270, 66, 66, 540, 66, 540, 66, 270, 540, 270, 540, 270, 540, 270, 540, 66, 270, 270, 270, 270, 270, 270, 270, 270, 540, 66, 66, 66, 66, 66, 270, 66, 66, 270, 540, 540, 66, 66, 540, 66, 66, 66, 270, 66, 270, 540, 540, 270, 270, 66, 540, 270, 540, 66, 270, 270, 66, 66, 270, 66, 540, 540, 66, 540, 540, 66, 270, 540, 66, 66, 270, 270, 66, 66, 540, 540, 540, 540, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 540, 270, 270, 270, 540, 66, 270, 270, 540, 540, 66, 540, 540, 66, 540, 66, 66, 270, 66, 540, 540, 540, 270, 66, 540, 540, 270, 270, 540, 540, 66, 540, 540, 270, 66, 540, 270, 270, 540, 540, 540, 66, 540, 66, 540, 540, 66, 66, 540, 66, 270, 540, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 540, 66, 66, 66, 270, 66, 270, 270, 66, 540, 270, 540, 66, 540, 66, 270, 270, 270, 270, 66, 270, 540, 540, 66, 540, 540, 66, 540, 270, 540, 270, 270, 270, 66, 270, 66, 66, 540, 66, 270, 66, 66, 270, 540, 270, 540, 66, 540, 540, 270, 540, 270, 66, 540, 66, 540, 540, 66, 66, 66]
Prompts retrieved: 112128 . Total input tokens: 24949201 . Total output tokens: 22033828
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 3.9955083108507097,
    "estimated_duration": 3600.0628470777156,
    "input_throughput": 2555.557052974246,
    "output_throughput": 2253.0362231270524,
    "total_throughput": 4808.593276101298,
    "itl": 62.86217118070017,
    "ttft": 47606.41648662826,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 13503,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 92.72255837216855,
    "arrivals": 37708,
    "finished_requests": 37344,
    "scheduler_time": 23.8021312019573
}
#Debug simulation 
Total elapsed time: 3.9956187210045755. Arrivals time: 0.10199195239692926 Scheduler time: 3.5647251131013036 Scheduler overhead time: 0.06610584212467074 Adapter cache time: 0.1675475686788559 Engine time: 0.06487100943922997 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-32/adapters_384_slots_96_rate_0.05-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-32/adapters_384_slots_96_rate_0.05-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 540, 270, 66, 540, 540, 66, 270, 540, 540, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 66, 540, 66, 540, 270, 270, 270, 66, 66, 270, 66, 540, 66, 540, 270, 540, 270, 66, 270, 540, 270, 540, 66, 540, 540, 540, 540, 66, 270, 270, 270, 540, 270, 66, 270, 66, 540, 270, 540, 540, 270, 540, 540, 66, 66, 540, 270, 270, 66, 66, 66, 270, 66, 270, 66, 540, 66, 270, 540, 66, 540, 270, 66, 540, 540, 540, 540, 270, 66, 270, 540, 540, 270, 66, 66, 540, 270, 270, 66, 66, 540, 270, 540, 270, 540, 540, 270, 540, 540, 66, 270, 270, 270, 270, 66, 66, 540, 66, 540, 66, 66, 66, 270, 270, 540, 66, 66, 540, 66, 540, 270, 66, 540, 270, 270, 66, 540, 540, 540, 66, 270, 540, 66, 540, 270, 270, 540, 540, 66, 270, 540, 66, 270, 270, 66, 270, 66, 270, 540, 540, 270, 66, 540, 66, 540, 270, 270, 270, 270, 270, 66, 66, 540, 66, 540, 66, 270, 540, 270, 540, 270, 540, 270, 540, 66, 270, 270, 270, 270, 270, 270, 270, 270, 540, 66, 66, 66, 66, 66, 270, 66, 66, 270, 540, 540, 66, 66, 540, 66, 66, 66, 270, 66, 270, 540, 540, 270, 270, 66, 540, 270, 540, 66, 270, 270, 66, 66, 270, 66, 540, 540, 66, 540, 540, 66, 270, 540, 66, 66, 270, 270, 66, 66, 540, 540, 540, 540, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 540, 270, 270, 270, 540, 66, 270, 270, 540, 540, 66, 540, 540, 66, 540, 66, 66, 270, 66, 540, 540, 540, 270, 66, 540, 540, 270, 270, 540, 540, 66, 540, 540, 270, 66, 540, 270, 270, 540, 540, 540, 66, 540, 66, 540, 540, 66, 66, 540, 66, 270, 540, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 540, 66, 66, 66, 270, 66, 270, 270, 66, 540, 270, 540, 66, 540, 66, 270, 270, 270, 270, 66, 270, 540, 540, 66, 540, 540, 66, 540, 270, 540, 270, 270, 270, 66, 270, 66, 66, 540, 66, 270, 66, 66, 270, 540, 270, 540, 66, 540, 540, 270, 540, 270, 66, 540, 66, 540, 540, 66, 66, 66]
Prompts retrieved: 112128 . Total input tokens: 24949201 . Total output tokens: 22033828
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 4.012703948188573,
    "estimated_duration": 3600.0637422401014,
    "input_throughput": 2555.399753637597,
    "output_throughput": 2252.7081687041755,
    "total_throughput": 4808.107922341773,
    "itl": 63.07707336373608,
    "ttft": 47973.096579768084,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 13420,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 100.02701215955555,
    "arrivals": 37708,
    "finished_requests": 37342,
    "scheduler_time": 23.846343160671278
}
#Debug simulation 
Total elapsed time: 4.012828011997044. Arrivals time: 0.09962298488244414 Scheduler time: 3.5839992626570165 Scheduler overhead time: 0.06595834717154503 Adapter cache time: 0.16780880466103554 Engine time: 0.06521117780357599 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-16/adapters_384_slots_96_rate_0.05-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-16/adapters_384_slots_96_rate_0.05-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 540, 270, 66, 540, 540, 66, 270, 540, 540, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 66, 540, 66, 540, 270, 270, 270, 66, 66, 270, 66, 540, 66, 540, 270, 540, 270, 66, 270, 540, 270, 540, 66, 540, 540, 540, 540, 66, 270, 270, 270, 540, 270, 66, 270, 66, 540, 270, 540, 540, 270, 540, 540, 66, 66, 540, 270, 270, 66, 66, 66, 270, 66, 270, 66, 540, 66, 270, 540, 66, 540, 270, 66, 540, 540, 540, 540, 270, 66, 270, 540, 540, 270, 66, 66, 540, 270, 270, 66, 66, 540, 270, 540, 270, 540, 540, 270, 540, 540, 66, 270, 270, 270, 270, 66, 66, 540, 66, 540, 66, 66, 66, 270, 270, 540, 66, 66, 540, 66, 540, 270, 66, 540, 270, 270, 66, 540, 540, 540, 66, 270, 540, 66, 540, 270, 270, 540, 540, 66, 270, 540, 66, 270, 270, 66, 270, 66, 270, 540, 540, 270, 66, 540, 66, 540, 270, 270, 270, 270, 270, 66, 66, 540, 66, 540, 66, 270, 540, 270, 540, 270, 540, 270, 540, 66, 270, 270, 270, 270, 270, 270, 270, 270, 540, 66, 66, 66, 66, 66, 270, 66, 66, 270, 540, 540, 66, 66, 540, 66, 66, 66, 270, 66, 270, 540, 540, 270, 270, 66, 540, 270, 540, 66, 270, 270, 66, 66, 270, 66, 540, 540, 66, 540, 540, 66, 270, 540, 66, 66, 270, 270, 66, 66, 540, 540, 540, 540, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 540, 270, 270, 270, 540, 66, 270, 270, 540, 540, 66, 540, 540, 66, 540, 66, 66, 270, 66, 540, 540, 540, 270, 66, 540, 540, 270, 270, 540, 540, 66, 540, 540, 270, 66, 540, 270, 270, 540, 540, 540, 66, 540, 66, 540, 540, 66, 66, 540, 66, 270, 540, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 540, 66, 66, 66, 270, 66, 270, 270, 66, 540, 270, 540, 66, 540, 66, 270, 270, 270, 270, 66, 270, 540, 540, 66, 540, 540, 66, 540, 270, 540, 270, 270, 270, 66, 270, 66, 66, 540, 66, 270, 66, 66, 270, 540, 270, 540, 66, 540, 540, 270, 540, 270, 66, 540, 66, 540, 540, 66, 66, 66]
Prompts retrieved: 112128 . Total input tokens: 24949201 . Total output tokens: 22033828
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.0218010428361595,
    "estimated_duration": 3600.015490958092,
    "input_throughput": 2555.5403922863557,
    "output_throughput": 2253.026694016084,
    "total_throughput": 4808.56708630244,
    "itl": 62.66706212235797,
    "ttft": 46969.03766616377,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 13572,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 86.64257500540853,
    "arrivals": 37708,
    "finished_requests": 37347,
    "scheduler_time": 23.76246293607925
}
#Debug simulation 
Total elapsed time: 4.021899169776589. Arrivals time: 0.10258098412305117 Scheduler time: 3.588759845122695 Scheduler overhead time: 0.0660032769665122 Adapter cache time: 0.16833841567859054 Engine time: 0.06565495999529958 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-32/adapters_384_slots_96_rate_0.05-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-32/adapters_384_slots_96_rate_0.05-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 540, 270, 66, 540, 540, 66, 270, 540, 540, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 66, 540, 66, 540, 270, 270, 270, 66, 66, 270, 66, 540, 66, 540, 270, 540, 270, 66, 270, 540, 270, 540, 66, 540, 540, 540, 540, 66, 270, 270, 270, 540, 270, 66, 270, 66, 540, 270, 540, 540, 270, 540, 540, 66, 66, 540, 270, 270, 66, 66, 66, 270, 66, 270, 66, 540, 66, 270, 540, 66, 540, 270, 66, 540, 540, 540, 540, 270, 66, 270, 540, 540, 270, 66, 66, 540, 270, 270, 66, 66, 540, 270, 540, 270, 540, 540, 270, 540, 540, 66, 270, 270, 270, 270, 66, 66, 540, 66, 540, 66, 66, 66, 270, 270, 540, 66, 66, 540, 66, 540, 270, 66, 540, 270, 270, 66, 540, 540, 540, 66, 270, 540, 66, 540, 270, 270, 540, 540, 66, 270, 540, 66, 270, 270, 66, 270, 66, 270, 540, 540, 270, 66, 540, 66, 540, 270, 270, 270, 270, 270, 66, 66, 540, 66, 540, 66, 270, 540, 270, 540, 270, 540, 270, 540, 66, 270, 270, 270, 270, 270, 270, 270, 270, 540, 66, 66, 66, 66, 66, 270, 66, 66, 270, 540, 540, 66, 66, 540, 66, 66, 66, 270, 66, 270, 540, 540, 270, 270, 66, 540, 270, 540, 66, 270, 270, 66, 66, 270, 66, 540, 540, 66, 540, 540, 66, 270, 540, 66, 66, 270, 270, 66, 66, 540, 540, 540, 540, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 540, 270, 270, 270, 540, 66, 270, 270, 540, 540, 66, 540, 540, 66, 540, 66, 66, 270, 66, 540, 540, 540, 270, 66, 540, 540, 270, 270, 540, 540, 66, 540, 540, 270, 66, 540, 270, 270, 540, 540, 540, 66, 540, 66, 540, 540, 66, 66, 540, 66, 270, 540, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 540, 66, 66, 66, 270, 66, 270, 270, 66, 540, 270, 540, 66, 540, 66, 270, 270, 270, 270, 66, 270, 540, 540, 66, 540, 540, 66, 540, 270, 540, 270, 270, 270, 66, 270, 66, 66, 540, 66, 270, 66, 66, 270, 540, 270, 540, 66, 540, 540, 270, 540, 270, 66, 540, 66, 540, 540, 66, 66, 66]
Prompts retrieved: 112128 . Total input tokens: 24949201 . Total output tokens: 22033828
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 3.9729315768927336,
    "estimated_duration": 3600.0182900879227,
    "input_throughput": 2555.2897954236037,
    "output_throughput": 2252.613555416671,
    "total_throughput": 4807.9033508402745,
    "itl": 63.04925983391621,
    "ttft": 47863.1392703077,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 13427,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 99.10910986743033,
    "arrivals": 37708,
    "finished_requests": 37341,
    "scheduler_time": 23.840800330948415
}
#Debug simulation 
Total elapsed time: 3.9730270011350513. Arrivals time: 0.10498533770442009 Scheduler time: 3.541749359574169 Scheduler overhead time: 0.0652331281453371 Adapter cache time: 0.1660688165575266 Engine time: 0.06460287654772401 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-8/adapters_384_slots_96_rate_0.05-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-8/adapters_384_slots_96_rate_0.05-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 540, 270, 33, 540, 540, 33, 270, 540, 540, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 33, 540, 33, 540, 270, 270, 270, 33, 33, 270, 33, 540, 33, 540, 270, 540, 270, 33, 270, 540, 270, 540, 33, 540, 540, 540, 540, 33, 270, 270, 270, 540, 270, 33, 270, 33, 540, 270, 540, 540, 270, 540, 540, 33, 33, 540, 270, 270, 33, 33, 33, 270, 33, 270, 33, 540, 33, 270, 540, 33, 540, 270, 33, 540, 540, 540, 540, 270, 33, 270, 540, 540, 270, 33, 33, 540, 270, 270, 33, 33, 540, 270, 540, 270, 540, 540, 270, 540, 540, 33, 270, 270, 270, 270, 33, 33, 540, 33, 540, 33, 33, 33, 270, 270, 540, 33, 33, 540, 33, 540, 270, 33, 540, 270, 270, 33, 540, 540, 540, 33, 270, 540, 33, 540, 270, 270, 540, 540, 33, 270, 540, 33, 270, 270, 33, 270, 33, 270, 540, 540, 270, 33, 540, 33, 540, 270, 270, 270, 270, 270, 33, 33, 540, 33, 540, 33, 270, 540, 270, 540, 270, 540, 270, 540, 33, 270, 270, 270, 270, 270, 270, 270, 270, 540, 33, 33, 33, 33, 33, 270, 33, 33, 270, 540, 540, 33, 33, 540, 33, 33, 33, 270, 33, 270, 540, 540, 270, 270, 33, 540, 270, 540, 33, 270, 270, 33, 33, 270, 33, 540, 540, 33, 540, 540, 33, 270, 540, 33, 33, 270, 270, 33, 33, 540, 540, 540, 540, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 540, 270, 270, 270, 540, 33, 270, 270, 540, 540, 33, 540, 540, 33, 540, 33, 33, 270, 33, 540, 540, 540, 270, 33, 540, 540, 270, 270, 540, 540, 33, 540, 540, 270, 33, 540, 270, 270, 540, 540, 540, 33, 540, 33, 540, 540, 33, 33, 540, 33, 270, 540, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 540, 33, 33, 33, 270, 33, 270, 270, 33, 540, 270, 540, 33, 540, 33, 270, 270, 270, 270, 33, 270, 540, 540, 33, 540, 540, 33, 540, 270, 540, 270, 270, 270, 33, 270, 33, 33, 540, 33, 270, 33, 33, 270, 540, 270, 540, 33, 540, 540, 270, 540, 270, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 107904 . Total input tokens: 24005309 . Total output tokens: 21207746
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.539952740073204,
    "estimated_duration": 3600.023998217544,
    "input_throughput": 2474.1190626534735,
    "output_throughput": 2144.6607033238565,
    "total_throughput": 4618.7797659773305,
    "itl": 60.93486427042686,
    "ttft": 24451.60370721707,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 15176,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 100.34991946885042,
    "arrivals": 36171,
    "finished_requests": 35999,
    "scheduler_time": 21.42042328017823
}
#Debug simulation 
Total elapsed time: 3.5400406317785382. Arrivals time: 0.09712775843217969 Scheduler time: 3.0940357139334083 Scheduler overhead time: 0.06770025985315442 Adapter cache time: 0.18358747428283095 Engine time: 0.06630707625299692 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-16/adapters_384_slots_96_rate_0.05-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-16/adapters_384_slots_96_rate_0.05-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 540, 270, 33, 540, 540, 33, 270, 540, 540, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 33, 540, 33, 540, 270, 270, 270, 33, 33, 270, 33, 540, 33, 540, 270, 540, 270, 33, 270, 540, 270, 540, 33, 540, 540, 540, 540, 33, 270, 270, 270, 540, 270, 33, 270, 33, 540, 270, 540, 540, 270, 540, 540, 33, 33, 540, 270, 270, 33, 33, 33, 270, 33, 270, 33, 540, 33, 270, 540, 33, 540, 270, 33, 540, 540, 540, 540, 270, 33, 270, 540, 540, 270, 33, 33, 540, 270, 270, 33, 33, 540, 270, 540, 270, 540, 540, 270, 540, 540, 33, 270, 270, 270, 270, 33, 33, 540, 33, 540, 33, 33, 33, 270, 270, 540, 33, 33, 540, 33, 540, 270, 33, 540, 270, 270, 33, 540, 540, 540, 33, 270, 540, 33, 540, 270, 270, 540, 540, 33, 270, 540, 33, 270, 270, 33, 270, 33, 270, 540, 540, 270, 33, 540, 33, 540, 270, 270, 270, 270, 270, 33, 33, 540, 33, 540, 33, 270, 540, 270, 540, 270, 540, 270, 540, 33, 270, 270, 270, 270, 270, 270, 270, 270, 540, 33, 33, 33, 33, 33, 270, 33, 33, 270, 540, 540, 33, 33, 540, 33, 33, 33, 270, 33, 270, 540, 540, 270, 270, 33, 540, 270, 540, 33, 270, 270, 33, 33, 270, 33, 540, 540, 33, 540, 540, 33, 270, 540, 33, 33, 270, 270, 33, 33, 540, 540, 540, 540, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 540, 270, 270, 270, 540, 33, 270, 270, 540, 540, 33, 540, 540, 33, 540, 33, 33, 270, 33, 540, 540, 540, 270, 33, 540, 540, 270, 270, 540, 540, 33, 540, 540, 270, 33, 540, 270, 270, 540, 540, 540, 33, 540, 33, 540, 540, 33, 33, 540, 33, 270, 540, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 540, 33, 33, 33, 270, 33, 270, 270, 33, 540, 270, 540, 33, 540, 33, 270, 270, 270, 270, 33, 270, 540, 540, 33, 540, 540, 33, 540, 270, 540, 270, 270, 270, 33, 270, 33, 33, 540, 33, 270, 33, 33, 270, 540, 270, 540, 33, 540, 540, 270, 540, 270, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 107904 . Total input tokens: 24005309 . Total output tokens: 21207746
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 3.5599734890274704,
    "estimated_duration": 3600.04928787578,
    "input_throughput": 2474.101682439891,
    "output_throughput": 2144.6456374922855,
    "total_throughput": 4618.747319932177,
    "itl": 61.224014790273955,
    "ttft": 24747.374790706355,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 15048,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 110.26257820778802,
    "arrivals": 36171,
    "finished_requests": 35999,
    "scheduler_time": 21.480700540000257
}
#Debug simulation 
Total elapsed time: 3.5600618310272694. Arrivals time: 0.0966410362161696 Scheduler time: 3.114603700581938 Scheduler overhead time: 0.06750761903822422 Adapter cache time: 0.18411362590268254 Engine time: 0.06611111434176564 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-32/adapters_384_slots_96_rate_0.05-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-32/adapters_384_slots_96_rate_0.05-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 540, 270, 33, 540, 540, 33, 270, 540, 540, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 33, 540, 33, 540, 270, 270, 270, 33, 33, 270, 33, 540, 33, 540, 270, 540, 270, 33, 270, 540, 270, 540, 33, 540, 540, 540, 540, 33, 270, 270, 270, 540, 270, 33, 270, 33, 540, 270, 540, 540, 270, 540, 540, 33, 33, 540, 270, 270, 33, 33, 33, 270, 33, 270, 33, 540, 33, 270, 540, 33, 540, 270, 33, 540, 540, 540, 540, 270, 33, 270, 540, 540, 270, 33, 33, 540, 270, 270, 33, 33, 540, 270, 540, 270, 540, 540, 270, 540, 540, 33, 270, 270, 270, 270, 33, 33, 540, 33, 540, 33, 33, 33, 270, 270, 540, 33, 33, 540, 33, 540, 270, 33, 540, 270, 270, 33, 540, 540, 540, 33, 270, 540, 33, 540, 270, 270, 540, 540, 33, 270, 540, 33, 270, 270, 33, 270, 33, 270, 540, 540, 270, 33, 540, 33, 540, 270, 270, 270, 270, 270, 33, 33, 540, 33, 540, 33, 270, 540, 270, 540, 270, 540, 270, 540, 33, 270, 270, 270, 270, 270, 270, 270, 270, 540, 33, 33, 33, 33, 33, 270, 33, 33, 270, 540, 540, 33, 33, 540, 33, 33, 33, 270, 33, 270, 540, 540, 270, 270, 33, 540, 270, 540, 33, 270, 270, 33, 33, 270, 33, 540, 540, 33, 540, 540, 33, 270, 540, 33, 33, 270, 270, 33, 33, 540, 540, 540, 540, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 540, 270, 270, 270, 540, 33, 270, 270, 540, 540, 33, 540, 540, 33, 540, 33, 33, 270, 33, 540, 540, 540, 270, 33, 540, 540, 270, 270, 540, 540, 33, 540, 540, 270, 33, 540, 270, 270, 540, 540, 540, 33, 540, 33, 540, 540, 33, 33, 540, 33, 270, 540, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 540, 33, 33, 33, 270, 33, 270, 270, 33, 540, 270, 540, 33, 540, 33, 270, 270, 270, 270, 33, 270, 540, 540, 33, 540, 540, 33, 540, 270, 540, 270, 270, 270, 33, 270, 33, 33, 540, 33, 270, 33, 33, 270, 540, 270, 540, 33, 540, 540, 270, 540, 270, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 107904 . Total input tokens: 24005309 . Total output tokens: 21207746
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 3.531975084915757,
    "estimated_duration": 3600.039214912186,
    "input_throughput": 2473.9561066745905,
    "output_throughput": 2144.4813623199148,
    "total_throughput": 4618.437468994505,
    "itl": 61.295903389569176,
    "ttft": 24899.39837658343,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 14997,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 112.90434885246904,
    "arrivals": 36171,
    "finished_requests": 35997,
    "scheduler_time": 21.49702306403556
}
#Debug simulation 
Total elapsed time: 3.5320635559037328. Arrivals time: 0.0970413638278842 Scheduler time: 3.089332840871066 Scheduler overhead time: 0.06692220782861114 Adapter cache time: 0.18214927148073912 Engine time: 0.0655264388769865 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-16/adapters_384_slots_96_rate_0.05-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-16/adapters_384_slots_96_rate_0.05-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 540, 270, 33, 540, 540, 33, 270, 540, 540, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 33, 540, 33, 540, 270, 270, 270, 33, 33, 270, 33, 540, 33, 540, 270, 540, 270, 33, 270, 540, 270, 540, 33, 540, 540, 540, 540, 33, 270, 270, 270, 540, 270, 33, 270, 33, 540, 270, 540, 540, 270, 540, 540, 33, 33, 540, 270, 270, 33, 33, 33, 270, 33, 270, 33, 540, 33, 270, 540, 33, 540, 270, 33, 540, 540, 540, 540, 270, 33, 270, 540, 540, 270, 33, 33, 540, 270, 270, 33, 33, 540, 270, 540, 270, 540, 540, 270, 540, 540, 33, 270, 270, 270, 270, 33, 33, 540, 33, 540, 33, 33, 33, 270, 270, 540, 33, 33, 540, 33, 540, 270, 33, 540, 270, 270, 33, 540, 540, 540, 33, 270, 540, 33, 540, 270, 270, 540, 540, 33, 270, 540, 33, 270, 270, 33, 270, 33, 270, 540, 540, 270, 33, 540, 33, 540, 270, 270, 270, 270, 270, 33, 33, 540, 33, 540, 33, 270, 540, 270, 540, 270, 540, 270, 540, 33, 270, 270, 270, 270, 270, 270, 270, 270, 540, 33, 33, 33, 33, 33, 270, 33, 33, 270, 540, 540, 33, 33, 540, 33, 33, 33, 270, 33, 270, 540, 540, 270, 270, 33, 540, 270, 540, 33, 270, 270, 33, 33, 270, 33, 540, 540, 33, 540, 540, 33, 270, 540, 33, 33, 270, 270, 33, 33, 540, 540, 540, 540, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 540, 270, 270, 270, 540, 33, 270, 270, 540, 540, 33, 540, 540, 33, 540, 33, 33, 270, 33, 540, 540, 540, 270, 33, 540, 540, 270, 270, 540, 540, 33, 540, 540, 270, 33, 540, 270, 270, 540, 540, 540, 33, 540, 33, 540, 540, 33, 33, 540, 33, 270, 540, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 540, 33, 33, 33, 270, 33, 270, 270, 33, 540, 270, 540, 33, 540, 33, 270, 270, 270, 270, 33, 270, 540, 540, 33, 540, 540, 33, 540, 270, 540, 270, 270, 270, 33, 270, 33, 33, 540, 33, 270, 33, 33, 270, 540, 270, 540, 33, 540, 540, 270, 540, 270, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 107904 . Total input tokens: 24005309 . Total output tokens: 21207746
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 3.5406765290535986,
    "estimated_duration": 3600.014380908548,
    "input_throughput": 2474.1256721736036,
    "output_throughput": 2144.666432707824,
    "total_throughput": 4618.792104881427,
    "itl": 61.038763280778,
    "ttft": 24527.298904779836,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 15127,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 103.9174256797467,
    "arrivals": 36171,
    "finished_requests": 35999,
    "scheduler_time": 21.44190655225201
}
#Debug simulation 
Total elapsed time: 3.540767897851765. Arrivals time: 0.10174673749133945 Scheduler time: 3.090862449258566 Scheduler overhead time: 0.06714439671486616 Adapter cache time: 0.18427964486181736 Engine time: 0.06573158223181963 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-32/adapters_384_slots_96_rate_0.05-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-32/adapters_384_slots_96_rate_0.05-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 540, 270, 33, 540, 540, 33, 270, 540, 540, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 33, 540, 33, 540, 270, 270, 270, 33, 33, 270, 33, 540, 33, 540, 270, 540, 270, 33, 270, 540, 270, 540, 33, 540, 540, 540, 540, 33, 270, 270, 270, 540, 270, 33, 270, 33, 540, 270, 540, 540, 270, 540, 540, 33, 33, 540, 270, 270, 33, 33, 33, 270, 33, 270, 33, 540, 33, 270, 540, 33, 540, 270, 33, 540, 540, 540, 540, 270, 33, 270, 540, 540, 270, 33, 33, 540, 270, 270, 33, 33, 540, 270, 540, 270, 540, 540, 270, 540, 540, 33, 270, 270, 270, 270, 33, 33, 540, 33, 540, 33, 33, 33, 270, 270, 540, 33, 33, 540, 33, 540, 270, 33, 540, 270, 270, 33, 540, 540, 540, 33, 270, 540, 33, 540, 270, 270, 540, 540, 33, 270, 540, 33, 270, 270, 33, 270, 33, 270, 540, 540, 270, 33, 540, 33, 540, 270, 270, 270, 270, 270, 33, 33, 540, 33, 540, 33, 270, 540, 270, 540, 270, 540, 270, 540, 33, 270, 270, 270, 270, 270, 270, 270, 270, 540, 33, 33, 33, 33, 33, 270, 33, 33, 270, 540, 540, 33, 33, 540, 33, 33, 33, 270, 33, 270, 540, 540, 270, 270, 33, 540, 270, 540, 33, 270, 270, 33, 33, 270, 33, 540, 540, 33, 540, 540, 33, 270, 540, 33, 33, 270, 270, 33, 33, 540, 540, 540, 540, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 540, 270, 270, 270, 540, 33, 270, 270, 540, 540, 33, 540, 540, 33, 540, 33, 33, 270, 33, 540, 540, 540, 270, 33, 540, 540, 270, 270, 540, 540, 33, 540, 540, 270, 33, 540, 270, 270, 540, 540, 540, 33, 540, 33, 540, 540, 33, 33, 540, 33, 270, 540, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 540, 33, 33, 33, 270, 33, 270, 270, 33, 540, 270, 540, 33, 540, 33, 270, 270, 270, 270, 33, 270, 540, 540, 33, 540, 540, 33, 540, 270, 540, 270, 270, 270, 33, 270, 33, 33, 540, 33, 270, 33, 33, 270, 540, 270, 540, 33, 540, 540, 270, 540, 270, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 107904 . Total input tokens: 24005309 . Total output tokens: 21207746
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 3.540560402907431,
    "estimated_duration": 3600.0613824797088,
    "input_throughput": 2474.093370559412,
    "output_throughput": 2144.638432437483,
    "total_throughput": 4618.731802996895,
    "itl": 61.26515231853064,
    "ttft": 24976.011139049875,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 15016,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 112.02122392909338,
    "arrivals": 36171,
    "finished_requests": 35999,
    "scheduler_time": 21.491714868059656
}
#Debug simulation 
Total elapsed time: 3.540677823126316. Arrivals time: 0.0951787238009274 Scheduler time: 3.0987513652071357 Scheduler overhead time: 0.06712953699752688 Adapter cache time: 0.18189776921644807 Engine time: 0.06667359871789813 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-16/adapters_384_slots_96_rate_0.05-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-16/adapters_384_slots_96_rate_0.05-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 540, 270, 33, 540, 540, 33, 270, 540, 540, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 33, 540, 33, 540, 270, 270, 270, 33, 33, 270, 33, 540, 33, 540, 270, 540, 270, 33, 270, 540, 270, 540, 33, 540, 540, 540, 540, 33, 270, 270, 270, 540, 270, 33, 270, 33, 540, 270, 540, 540, 270, 540, 540, 33, 33, 540, 270, 270, 33, 33, 33, 270, 33, 270, 33, 540, 33, 270, 540, 33, 540, 270, 33, 540, 540, 540, 540, 270, 33, 270, 540, 540, 270, 33, 33, 540, 270, 270, 33, 33, 540, 270, 540, 270, 540, 540, 270, 540, 540, 33, 270, 270, 270, 270, 33, 33, 540, 33, 540, 33, 33, 33, 270, 270, 540, 33, 33, 540, 33, 540, 270, 33, 540, 270, 270, 33, 540, 540, 540, 33, 270, 540, 33, 540, 270, 270, 540, 540, 33, 270, 540, 33, 270, 270, 33, 270, 33, 270, 540, 540, 270, 33, 540, 33, 540, 270, 270, 270, 270, 270, 33, 33, 540, 33, 540, 33, 270, 540, 270, 540, 270, 540, 270, 540, 33, 270, 270, 270, 270, 270, 270, 270, 270, 540, 33, 33, 33, 33, 33, 270, 33, 33, 270, 540, 540, 33, 33, 540, 33, 33, 33, 270, 33, 270, 540, 540, 270, 270, 33, 540, 270, 540, 33, 270, 270, 33, 33, 270, 33, 540, 540, 33, 540, 540, 33, 270, 540, 33, 33, 270, 270, 33, 33, 540, 540, 540, 540, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 540, 270, 270, 270, 540, 33, 270, 270, 540, 540, 33, 540, 540, 33, 540, 33, 33, 270, 33, 540, 540, 540, 270, 33, 540, 540, 270, 270, 540, 540, 33, 540, 540, 270, 33, 540, 270, 270, 540, 540, 540, 33, 540, 33, 540, 540, 33, 33, 540, 33, 270, 540, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 540, 33, 33, 33, 270, 33, 270, 270, 33, 540, 270, 540, 33, 540, 33, 270, 270, 270, 270, 33, 270, 540, 540, 33, 540, 540, 33, 540, 270, 540, 270, 270, 270, 33, 270, 33, 33, 540, 33, 270, 33, 33, 270, 540, 270, 540, 33, 540, 540, 270, 540, 270, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 107904 . Total input tokens: 24005309 . Total output tokens: 21207746
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.53341553080827,
    "estimated_duration": 3600.057689970853,
    "input_throughput": 2474.041742389998,
    "output_throughput": 2144.557022379968,
    "total_throughput": 4618.598764769966,
    "itl": 60.855153108656005,
    "ttft": 24588.35739143289,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 15226,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 97.20158024110185,
    "arrivals": 36171,
    "finished_requests": 35999,
    "scheduler_time": 21.40209298254217
}
#Debug simulation 
Total elapsed time: 3.533504877705127. Arrivals time: 0.09666375955566764 Scheduler time: 3.0871068914420903 Scheduler overhead time: 0.06750915758311749 Adapter cache time: 0.18410190241411328 Engine time: 0.06687525566667318 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-32/adapters_384_slots_96_rate_0.05-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-32/adapters_384_slots_96_rate_0.05-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 540, 270, 33, 540, 540, 33, 270, 540, 540, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 33, 540, 33, 540, 270, 270, 270, 33, 33, 270, 33, 540, 33, 540, 270, 540, 270, 33, 270, 540, 270, 540, 33, 540, 540, 540, 540, 33, 270, 270, 270, 540, 270, 33, 270, 33, 540, 270, 540, 540, 270, 540, 540, 33, 33, 540, 270, 270, 33, 33, 33, 270, 33, 270, 33, 540, 33, 270, 540, 33, 540, 270, 33, 540, 540, 540, 540, 270, 33, 270, 540, 540, 270, 33, 33, 540, 270, 270, 33, 33, 540, 270, 540, 270, 540, 540, 270, 540, 540, 33, 270, 270, 270, 270, 33, 33, 540, 33, 540, 33, 33, 33, 270, 270, 540, 33, 33, 540, 33, 540, 270, 33, 540, 270, 270, 33, 540, 540, 540, 33, 270, 540, 33, 540, 270, 270, 540, 540, 33, 270, 540, 33, 270, 270, 33, 270, 33, 270, 540, 540, 270, 33, 540, 33, 540, 270, 270, 270, 270, 270, 33, 33, 540, 33, 540, 33, 270, 540, 270, 540, 270, 540, 270, 540, 33, 270, 270, 270, 270, 270, 270, 270, 270, 540, 33, 33, 33, 33, 33, 270, 33, 33, 270, 540, 540, 33, 33, 540, 33, 33, 33, 270, 33, 270, 540, 540, 270, 270, 33, 540, 270, 540, 33, 270, 270, 33, 33, 270, 33, 540, 540, 33, 540, 540, 33, 270, 540, 33, 33, 270, 270, 33, 33, 540, 540, 540, 540, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 540, 270, 270, 270, 540, 33, 270, 270, 540, 540, 33, 540, 540, 33, 540, 33, 33, 270, 33, 540, 540, 540, 270, 33, 540, 540, 270, 270, 540, 540, 33, 540, 540, 270, 33, 540, 270, 270, 540, 540, 540, 33, 540, 33, 540, 540, 33, 33, 540, 33, 270, 540, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 540, 33, 33, 33, 270, 33, 270, 270, 33, 540, 270, 540, 33, 540, 33, 270, 270, 270, 270, 33, 270, 540, 540, 33, 540, 540, 33, 540, 270, 540, 270, 270, 270, 33, 270, 33, 33, 540, 33, 270, 33, 33, 270, 540, 270, 540, 33, 540, 540, 270, 540, 270, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 107904 . Total input tokens: 24005309 . Total output tokens: 21207746
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 3.521013980731368,
    "estimated_duration": 3600.0273650676,
    "input_throughput": 2474.095360059229,
    "output_throughput": 2144.5925869663565,
    "total_throughput": 4618.687947025585,
    "itl": 61.24542749814166,
    "ttft": 24758.568792453683,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 15032,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 111.0555159695231,
    "arrivals": 36171,
    "finished_requests": 35998,
    "scheduler_time": 21.484850509882126
}
#Debug simulation 
Total elapsed time: 3.521104756742716. Arrivals time: 0.09799619112163782 Scheduler time: 3.075551735237241 Scheduler overhead time: 0.0685895667411387 Adapter cache time: 0.18182360706850886 Engine time: 0.06580698862671852 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-8/adapters_384_slots_96_rate_0.05-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-8/adapters_384_slots_96_rate_0.05-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 540, 135, 66, 540, 540, 66, 135, 540, 540, 540, 540, 135, 135, 135, 135, 540, 540, 135, 135, 66, 540, 66, 540, 135, 135, 135, 66, 66, 135, 66, 540, 66, 540, 135, 540, 135, 66, 135, 540, 135, 540, 66, 540, 540, 540, 540, 66, 135, 135, 135, 540, 135, 66, 135, 66, 540, 135, 540, 540, 135, 540, 540, 66, 66, 540, 135, 135, 66, 66, 66, 135, 66, 135, 66, 540, 66, 135, 540, 66, 540, 135, 66, 540, 540, 540, 540, 135, 66, 135, 540, 540, 135, 66, 66, 540, 135, 135, 66, 66, 540, 135, 540, 135, 540, 540, 135, 540, 540, 66, 135, 135, 135, 135, 66, 66, 540, 66, 540, 66, 66, 66, 135, 135, 540, 66, 66, 540, 66, 540, 135, 66, 540, 135, 135, 66, 540, 540, 540, 66, 135, 540, 66, 540, 135, 135, 540, 540, 66, 135, 540, 66, 135, 135, 66, 135, 66, 135, 540, 540, 135, 66, 540, 66, 540, 135, 135, 135, 135, 135, 66, 66, 540, 66, 540, 66, 135, 540, 135, 540, 135, 540, 135, 540, 66, 135, 135, 135, 135, 135, 135, 135, 135, 540, 66, 66, 66, 66, 66, 135, 66, 66, 135, 540, 540, 66, 66, 540, 66, 66, 66, 135, 66, 135, 540, 540, 135, 135, 66, 540, 135, 540, 66, 135, 135, 66, 66, 135, 66, 540, 540, 66, 540, 540, 66, 135, 540, 66, 66, 135, 135, 66, 66, 540, 540, 540, 540, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 540, 135, 135, 135, 540, 66, 135, 135, 540, 540, 66, 540, 540, 66, 540, 66, 66, 135, 66, 540, 540, 540, 135, 66, 540, 540, 135, 135, 540, 540, 66, 540, 540, 135, 66, 540, 135, 135, 540, 540, 540, 66, 540, 66, 540, 540, 66, 66, 540, 66, 135, 540, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 540, 66, 66, 66, 135, 66, 135, 135, 66, 540, 135, 540, 66, 540, 66, 135, 135, 135, 135, 66, 135, 540, 540, 66, 540, 540, 66, 540, 135, 540, 135, 135, 135, 66, 135, 66, 66, 540, 66, 135, 66, 66, 135, 540, 135, 540, 66, 540, 540, 135, 540, 135, 66, 540, 66, 540, 540, 66, 66, 66]
Prompts retrieved: 94848 . Total input tokens: 21123351 . Total output tokens: 18651401
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 2.794952896423638,
    "estimated_duration": 3599.7848251698274,
    "input_throughput": 2179.432766409829,
    "output_throughput": 1907.7523611917586,
    "total_throughput": 4087.1851276015877,
    "itl": 55.637123716220984,
    "ttft": 12179.927462461319,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 18072,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 119.49945602536262,
    "arrivals": 31815,
    "finished_requests": 31716,
    "scheduler_time": 16.28431215316284
}
#Debug simulation 
Total elapsed time: 2.7950405590236187. Arrivals time: 0.08579305652529001 Scheduler time: 2.32370542967692 Scheduler overhead time: 0.07005321839824319 Adapter cache time: 0.21461616130545735 Engine time: 0.06789462873712182 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-16/adapters_384_slots_96_rate_0.05-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-16/adapters_384_slots_96_rate_0.05-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 540, 135, 66, 540, 540, 66, 135, 540, 540, 540, 540, 135, 135, 135, 135, 540, 540, 135, 135, 66, 540, 66, 540, 135, 135, 135, 66, 66, 135, 66, 540, 66, 540, 135, 540, 135, 66, 135, 540, 135, 540, 66, 540, 540, 540, 540, 66, 135, 135, 135, 540, 135, 66, 135, 66, 540, 135, 540, 540, 135, 540, 540, 66, 66, 540, 135, 135, 66, 66, 66, 135, 66, 135, 66, 540, 66, 135, 540, 66, 540, 135, 66, 540, 540, 540, 540, 135, 66, 135, 540, 540, 135, 66, 66, 540, 135, 135, 66, 66, 540, 135, 540, 135, 540, 540, 135, 540, 540, 66, 135, 135, 135, 135, 66, 66, 540, 66, 540, 66, 66, 66, 135, 135, 540, 66, 66, 540, 66, 540, 135, 66, 540, 135, 135, 66, 540, 540, 540, 66, 135, 540, 66, 540, 135, 135, 540, 540, 66, 135, 540, 66, 135, 135, 66, 135, 66, 135, 540, 540, 135, 66, 540, 66, 540, 135, 135, 135, 135, 135, 66, 66, 540, 66, 540, 66, 135, 540, 135, 540, 135, 540, 135, 540, 66, 135, 135, 135, 135, 135, 135, 135, 135, 540, 66, 66, 66, 66, 66, 135, 66, 66, 135, 540, 540, 66, 66, 540, 66, 66, 66, 135, 66, 135, 540, 540, 135, 135, 66, 540, 135, 540, 66, 135, 135, 66, 66, 135, 66, 540, 540, 66, 540, 540, 66, 135, 540, 66, 66, 135, 135, 66, 66, 540, 540, 540, 540, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 540, 135, 135, 135, 540, 66, 135, 135, 540, 540, 66, 540, 540, 66, 540, 66, 66, 135, 66, 540, 540, 540, 135, 66, 540, 540, 135, 135, 540, 540, 66, 540, 540, 135, 66, 540, 135, 135, 540, 540, 540, 66, 540, 66, 540, 540, 66, 66, 540, 66, 135, 540, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 540, 66, 66, 66, 135, 66, 135, 135, 66, 540, 135, 540, 66, 540, 66, 135, 135, 135, 135, 66, 135, 540, 540, 66, 540, 540, 66, 540, 135, 540, 135, 135, 135, 66, 135, 66, 66, 540, 66, 135, 66, 66, 135, 540, 135, 540, 66, 540, 540, 135, 540, 135, 66, 540, 66, 540, 540, 66, 66, 66]
Prompts retrieved: 94848 . Total input tokens: 21123351 . Total output tokens: 18651401
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 2.7852367609739304,
    "estimated_duration": 3599.8142644690747,
    "input_throughput": 2179.296881350917,
    "output_throughput": 1907.6048083310752,
    "total_throughput": 4086.9016896819926,
    "itl": 56.11554487331762,
    "ttft": 12379.539852356877,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 18009,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 132.01955043395282,
    "arrivals": 31815,
    "finished_requests": 31715,
    "scheduler_time": 16.39726627849441
}
#Debug simulation 
Total elapsed time: 2.7853318070992827. Arrivals time: 0.08644259255379438 Scheduler time: 2.315924647729844 Scheduler overhead time: 0.0700607830658555 Adapter cache time: 0.21294069522991776 Engine time: 0.06749998265877366 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-32/adapters_384_slots_96_rate_0.05-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-32/adapters_384_slots_96_rate_0.05-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 540, 135, 66, 540, 540, 66, 135, 540, 540, 540, 540, 135, 135, 135, 135, 540, 540, 135, 135, 66, 540, 66, 540, 135, 135, 135, 66, 66, 135, 66, 540, 66, 540, 135, 540, 135, 66, 135, 540, 135, 540, 66, 540, 540, 540, 540, 66, 135, 135, 135, 540, 135, 66, 135, 66, 540, 135, 540, 540, 135, 540, 540, 66, 66, 540, 135, 135, 66, 66, 66, 135, 66, 135, 66, 540, 66, 135, 540, 66, 540, 135, 66, 540, 540, 540, 540, 135, 66, 135, 540, 540, 135, 66, 66, 540, 135, 135, 66, 66, 540, 135, 540, 135, 540, 540, 135, 540, 540, 66, 135, 135, 135, 135, 66, 66, 540, 66, 540, 66, 66, 66, 135, 135, 540, 66, 66, 540, 66, 540, 135, 66, 540, 135, 135, 66, 540, 540, 540, 66, 135, 540, 66, 540, 135, 135, 540, 540, 66, 135, 540, 66, 135, 135, 66, 135, 66, 135, 540, 540, 135, 66, 540, 66, 540, 135, 135, 135, 135, 135, 66, 66, 540, 66, 540, 66, 135, 540, 135, 540, 135, 540, 135, 540, 66, 135, 135, 135, 135, 135, 135, 135, 135, 540, 66, 66, 66, 66, 66, 135, 66, 66, 135, 540, 540, 66, 66, 540, 66, 66, 66, 135, 66, 135, 540, 540, 135, 135, 66, 540, 135, 540, 66, 135, 135, 66, 66, 135, 66, 540, 540, 66, 540, 540, 66, 135, 540, 66, 66, 135, 135, 66, 66, 540, 540, 540, 540, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 540, 135, 135, 135, 540, 66, 135, 135, 540, 540, 66, 540, 540, 66, 540, 66, 66, 135, 66, 540, 540, 540, 135, 66, 540, 540, 135, 135, 540, 540, 66, 540, 540, 135, 66, 540, 135, 135, 540, 540, 540, 66, 540, 66, 540, 540, 66, 66, 540, 66, 135, 540, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 540, 66, 66, 66, 135, 66, 135, 135, 66, 540, 135, 540, 66, 540, 66, 135, 135, 135, 135, 66, 135, 540, 540, 66, 540, 540, 66, 540, 135, 540, 135, 135, 135, 66, 135, 66, 66, 540, 66, 135, 66, 66, 135, 540, 135, 540, 66, 540, 540, 135, 540, 135, 66, 540, 66, 540, 540, 66, 66, 66]
Prompts retrieved: 94848 . Total input tokens: 21123351 . Total output tokens: 18651401
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 2.775557910092175,
    "estimated_duration": 3599.805867411802,
    "input_throughput": 2179.301964869696,
    "output_throughput": 1907.6092580895954,
    "total_throughput": 4086.9112229592915,
    "itl": 56.252992067478196,
    "ttft": 12402.640690485236,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 17974,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 135.39351427319315,
    "arrivals": 31815,
    "finished_requests": 31715,
    "scheduler_time": 16.427442065680538
}
#Debug simulation 
Total elapsed time: 2.7756432900205255. Arrivals time: 0.0851006549783051 Scheduler time: 2.3053169986233115 Scheduler overhead time: 0.06998649938032031 Adapter cache time: 0.21357859950512648 Engine time: 0.06889924872666597 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-16/adapters_384_slots_96_rate_0.05-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-16/adapters_384_slots_96_rate_0.05-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 540, 135, 66, 540, 540, 66, 135, 540, 540, 540, 540, 135, 135, 135, 135, 540, 540, 135, 135, 66, 540, 66, 540, 135, 135, 135, 66, 66, 135, 66, 540, 66, 540, 135, 540, 135, 66, 135, 540, 135, 540, 66, 540, 540, 540, 540, 66, 135, 135, 135, 540, 135, 66, 135, 66, 540, 135, 540, 540, 135, 540, 540, 66, 66, 540, 135, 135, 66, 66, 66, 135, 66, 135, 66, 540, 66, 135, 540, 66, 540, 135, 66, 540, 540, 540, 540, 135, 66, 135, 540, 540, 135, 66, 66, 540, 135, 135, 66, 66, 540, 135, 540, 135, 540, 540, 135, 540, 540, 66, 135, 135, 135, 135, 66, 66, 540, 66, 540, 66, 66, 66, 135, 135, 540, 66, 66, 540, 66, 540, 135, 66, 540, 135, 135, 66, 540, 540, 540, 66, 135, 540, 66, 540, 135, 135, 540, 540, 66, 135, 540, 66, 135, 135, 66, 135, 66, 135, 540, 540, 135, 66, 540, 66, 540, 135, 135, 135, 135, 135, 66, 66, 540, 66, 540, 66, 135, 540, 135, 540, 135, 540, 135, 540, 66, 135, 135, 135, 135, 135, 135, 135, 135, 540, 66, 66, 66, 66, 66, 135, 66, 66, 135, 540, 540, 66, 66, 540, 66, 66, 66, 135, 66, 135, 540, 540, 135, 135, 66, 540, 135, 540, 66, 135, 135, 66, 66, 135, 66, 540, 540, 66, 540, 540, 66, 135, 540, 66, 66, 135, 135, 66, 66, 540, 540, 540, 540, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 540, 135, 135, 135, 540, 66, 135, 135, 540, 540, 66, 540, 540, 66, 540, 66, 66, 135, 66, 540, 540, 540, 135, 66, 540, 540, 135, 135, 540, 540, 66, 540, 540, 135, 66, 540, 135, 135, 540, 540, 540, 66, 540, 66, 540, 540, 66, 66, 540, 66, 135, 540, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 540, 66, 66, 66, 135, 66, 135, 135, 66, 540, 135, 540, 66, 540, 66, 135, 135, 135, 135, 66, 135, 540, 540, 66, 540, 540, 66, 540, 135, 540, 135, 135, 135, 66, 135, 66, 66, 540, 66, 135, 66, 66, 135, 540, 135, 540, 66, 540, 540, 135, 540, 135, 66, 540, 66, 540, 540, 66, 66, 66]
Prompts retrieved: 94848 . Total input tokens: 21123351 . Total output tokens: 18651401
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 2.808380034286529,
    "estimated_duration": 3599.771641893474,
    "input_throughput": 2179.4407480451414,
    "output_throughput": 1907.7593478645515,
    "total_throughput": 4087.2000959096927,
    "itl": 55.823986561447065,
    "ttft": 12211.531063086106,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 18059,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 124.28151195184387,
    "arrivals": 31815,
    "finished_requests": 31716,
    "scheduler_time": 16.327507963639846
}
#Debug simulation 
Total elapsed time: 2.8084707902744412. Arrivals time: 0.08659692760556936 Scheduler time: 2.333357479888946 Scheduler overhead time: 0.07017272897064686 Adapter cache time: 0.21690717991441488 Engine time: 0.06849566707387567 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-32/adapters_384_slots_96_rate_0.05-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-32/adapters_384_slots_96_rate_0.05-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 540, 135, 66, 540, 540, 66, 135, 540, 540, 540, 540, 135, 135, 135, 135, 540, 540, 135, 135, 66, 540, 66, 540, 135, 135, 135, 66, 66, 135, 66, 540, 66, 540, 135, 540, 135, 66, 135, 540, 135, 540, 66, 540, 540, 540, 540, 66, 135, 135, 135, 540, 135, 66, 135, 66, 540, 135, 540, 540, 135, 540, 540, 66, 66, 540, 135, 135, 66, 66, 66, 135, 66, 135, 66, 540, 66, 135, 540, 66, 540, 135, 66, 540, 540, 540, 540, 135, 66, 135, 540, 540, 135, 66, 66, 540, 135, 135, 66, 66, 540, 135, 540, 135, 540, 540, 135, 540, 540, 66, 135, 135, 135, 135, 66, 66, 540, 66, 540, 66, 66, 66, 135, 135, 540, 66, 66, 540, 66, 540, 135, 66, 540, 135, 135, 66, 540, 540, 540, 66, 135, 540, 66, 540, 135, 135, 540, 540, 66, 135, 540, 66, 135, 135, 66, 135, 66, 135, 540, 540, 135, 66, 540, 66, 540, 135, 135, 135, 135, 135, 66, 66, 540, 66, 540, 66, 135, 540, 135, 540, 135, 540, 135, 540, 66, 135, 135, 135, 135, 135, 135, 135, 135, 540, 66, 66, 66, 66, 66, 135, 66, 66, 135, 540, 540, 66, 66, 540, 66, 66, 66, 135, 66, 135, 540, 540, 135, 135, 66, 540, 135, 540, 66, 135, 135, 66, 66, 135, 66, 540, 540, 66, 540, 540, 66, 135, 540, 66, 66, 135, 135, 66, 66, 540, 540, 540, 540, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 540, 135, 135, 135, 540, 66, 135, 135, 540, 540, 66, 540, 540, 66, 540, 66, 66, 135, 66, 540, 540, 540, 135, 66, 540, 540, 135, 135, 540, 540, 66, 540, 540, 135, 66, 540, 135, 135, 540, 540, 540, 66, 540, 66, 540, 540, 66, 66, 540, 66, 135, 540, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 540, 66, 66, 66, 135, 66, 135, 135, 66, 540, 135, 540, 66, 540, 66, 135, 135, 135, 135, 66, 135, 540, 540, 66, 540, 540, 66, 540, 135, 540, 135, 135, 135, 66, 135, 66, 66, 540, 66, 135, 66, 66, 135, 540, 135, 540, 66, 540, 540, 135, 540, 135, 66, 540, 66, 540, 540, 66, 66, 66]
Prompts retrieved: 94848 . Total input tokens: 21123351 . Total output tokens: 18651401
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 2.774267059750855,
    "estimated_duration": 3599.783139456534,
    "input_throughput": 2179.3157243312116,
    "output_throughput": 1907.6213021645317,
    "total_throughput": 4086.9370264957433,
    "itl": 56.21480300211513,
    "ttft": 12393.948072141084,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 17988,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 134.2954095618136,
    "arrivals": 31815,
    "finished_requests": 31715,
    "scheduler_time": 16.417428775308185
}
#Debug simulation 
Total elapsed time: 2.7743534580804408. Arrivals time: 0.08649392891675234 Scheduler time: 2.3020727443508804 Scheduler overhead time: 0.07061635656282306 Adapter cache time: 0.21375815151259303 Engine time: 0.06852036947384477 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-16/adapters_384_slots_96_rate_0.05-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-16/adapters_384_slots_96_rate_0.05-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 540, 135, 66, 540, 540, 66, 135, 540, 540, 540, 540, 135, 135, 135, 135, 540, 540, 135, 135, 66, 540, 66, 540, 135, 135, 135, 66, 66, 135, 66, 540, 66, 540, 135, 540, 135, 66, 135, 540, 135, 540, 66, 540, 540, 540, 540, 66, 135, 135, 135, 540, 135, 66, 135, 66, 540, 135, 540, 540, 135, 540, 540, 66, 66, 540, 135, 135, 66, 66, 66, 135, 66, 135, 66, 540, 66, 135, 540, 66, 540, 135, 66, 540, 540, 540, 540, 135, 66, 135, 540, 540, 135, 66, 66, 540, 135, 135, 66, 66, 540, 135, 540, 135, 540, 540, 135, 540, 540, 66, 135, 135, 135, 135, 66, 66, 540, 66, 540, 66, 66, 66, 135, 135, 540, 66, 66, 540, 66, 540, 135, 66, 540, 135, 135, 66, 540, 540, 540, 66, 135, 540, 66, 540, 135, 135, 540, 540, 66, 135, 540, 66, 135, 135, 66, 135, 66, 135, 540, 540, 135, 66, 540, 66, 540, 135, 135, 135, 135, 135, 66, 66, 540, 66, 540, 66, 135, 540, 135, 540, 135, 540, 135, 540, 66, 135, 135, 135, 135, 135, 135, 135, 135, 540, 66, 66, 66, 66, 66, 135, 66, 66, 135, 540, 540, 66, 66, 540, 66, 66, 66, 135, 66, 135, 540, 540, 135, 135, 66, 540, 135, 540, 66, 135, 135, 66, 66, 135, 66, 540, 540, 66, 540, 540, 66, 135, 540, 66, 66, 135, 135, 66, 66, 540, 540, 540, 540, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 540, 135, 135, 135, 540, 66, 135, 135, 540, 540, 66, 540, 540, 66, 540, 66, 66, 135, 66, 540, 540, 540, 135, 66, 540, 540, 135, 135, 540, 540, 66, 540, 540, 135, 66, 540, 135, 135, 540, 540, 540, 66, 540, 66, 540, 540, 66, 66, 540, 66, 135, 540, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 540, 66, 66, 66, 135, 66, 135, 135, 66, 540, 135, 540, 66, 540, 66, 135, 135, 135, 135, 66, 135, 540, 540, 66, 540, 540, 66, 540, 135, 540, 135, 135, 135, 66, 135, 66, 66, 540, 66, 135, 66, 66, 135, 540, 135, 540, 66, 540, 540, 135, 540, 135, 66, 540, 66, 540, 540, 66, 66, 66]
Prompts retrieved: 94848 . Total input tokens: 21123351 . Total output tokens: 18651401
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 2.758053250145167,
    "estimated_duration": 3599.781388146046,
    "input_throughput": 2179.4348473034834,
    "output_throughput": 1907.754182688546,
    "total_throughput": 4087.1890299920296,
    "itl": 55.47811193515557,
    "ttft": 12153.71620100453,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 18102,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 115.56173686616472,
    "arrivals": 31815,
    "finished_requests": 31716,
    "scheduler_time": 16.24810332008036
}
#Debug simulation 
Total elapsed time: 2.7581404079683125. Arrivals time: 0.08623316511511803 Scheduler time: 2.2856762148439884 Scheduler overhead time: 0.07103290315717459 Adapter cache time: 0.21422401070594788 Engine time: 0.06818957114592195 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-32/adapters_384_slots_96_rate_0.05-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-32/adapters_384_slots_96_rate_0.05-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 540, 135, 66, 540, 540, 66, 135, 540, 540, 540, 540, 135, 135, 135, 135, 540, 540, 135, 135, 66, 540, 66, 540, 135, 135, 135, 66, 66, 135, 66, 540, 66, 540, 135, 540, 135, 66, 135, 540, 135, 540, 66, 540, 540, 540, 540, 66, 135, 135, 135, 540, 135, 66, 135, 66, 540, 135, 540, 540, 135, 540, 540, 66, 66, 540, 135, 135, 66, 66, 66, 135, 66, 135, 66, 540, 66, 135, 540, 66, 540, 135, 66, 540, 540, 540, 540, 135, 66, 135, 540, 540, 135, 66, 66, 540, 135, 135, 66, 66, 540, 135, 540, 135, 540, 540, 135, 540, 540, 66, 135, 135, 135, 135, 66, 66, 540, 66, 540, 66, 66, 66, 135, 135, 540, 66, 66, 540, 66, 540, 135, 66, 540, 135, 135, 66, 540, 540, 540, 66, 135, 540, 66, 540, 135, 135, 540, 540, 66, 135, 540, 66, 135, 135, 66, 135, 66, 135, 540, 540, 135, 66, 540, 66, 540, 135, 135, 135, 135, 135, 66, 66, 540, 66, 540, 66, 135, 540, 135, 540, 135, 540, 135, 540, 66, 135, 135, 135, 135, 135, 135, 135, 135, 540, 66, 66, 66, 66, 66, 135, 66, 66, 135, 540, 540, 66, 66, 540, 66, 66, 66, 135, 66, 135, 540, 540, 135, 135, 66, 540, 135, 540, 66, 135, 135, 66, 66, 135, 66, 540, 540, 66, 540, 540, 66, 135, 540, 66, 66, 135, 135, 66, 66, 540, 540, 540, 540, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 540, 135, 135, 135, 540, 66, 135, 135, 540, 540, 66, 540, 540, 66, 540, 66, 66, 135, 66, 540, 540, 540, 135, 66, 540, 540, 135, 135, 540, 540, 66, 540, 540, 135, 66, 540, 135, 135, 540, 540, 540, 66, 540, 66, 540, 540, 66, 66, 540, 66, 135, 540, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 540, 66, 66, 66, 135, 66, 135, 135, 66, 540, 135, 540, 66, 540, 66, 135, 135, 135, 135, 66, 135, 540, 540, 66, 540, 540, 66, 540, 135, 540, 135, 135, 135, 66, 135, 66, 66, 540, 66, 135, 66, 66, 135, 540, 135, 540, 66, 540, 540, 135, 540, 135, 66, 540, 66, 540, 540, 66, 66, 66]
Prompts retrieved: 94848 . Total input tokens: 21123351 . Total output tokens: 18651401
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 2.771452184766531,
    "estimated_duration": 3599.76864798761,
    "input_throughput": 2179.3244975300427,
    "output_throughput": 1907.6289816121637,
    "total_throughput": 4086.9534791422066,
    "itl": 56.15865291042444,
    "ttft": 12385.788922944155,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 18000,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 133.04554246323582,
    "arrivals": 31815,
    "finished_requests": 31715,
    "scheduler_time": 16.406162473179926
}
#Debug simulation 
Total elapsed time: 2.7715420578606427. Arrivals time: 0.08665039390325546 Scheduler time: 2.3008496542461216 Scheduler overhead time: 0.06938979215919971 Adapter cache time: 0.21328700985759497 Engine time: 0.06882585724815726 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-8/adapters_384_slots_96_rate_0.05-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-8/adapters_384_slots_96_rate_0.05-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 540, 135, 33, 540, 540, 33, 135, 540, 540, 540, 540, 135, 135, 135, 135, 540, 540, 135, 135, 33, 540, 33, 540, 135, 135, 135, 33, 33, 135, 33, 540, 33, 540, 135, 540, 135, 33, 135, 540, 135, 540, 33, 540, 540, 540, 540, 33, 135, 135, 135, 540, 135, 33, 135, 33, 540, 135, 540, 540, 135, 540, 540, 33, 33, 540, 135, 135, 33, 33, 33, 135, 33, 135, 33, 540, 33, 135, 540, 33, 540, 135, 33, 540, 540, 540, 540, 135, 33, 135, 540, 540, 135, 33, 33, 540, 135, 135, 33, 33, 540, 135, 540, 135, 540, 540, 135, 540, 540, 33, 135, 135, 135, 135, 33, 33, 540, 33, 540, 33, 33, 33, 135, 135, 540, 33, 33, 540, 33, 540, 135, 33, 540, 135, 135, 33, 540, 540, 540, 33, 135, 540, 33, 540, 135, 135, 540, 540, 33, 135, 540, 33, 135, 135, 33, 135, 33, 135, 540, 540, 135, 33, 540, 33, 540, 135, 135, 135, 135, 135, 33, 33, 540, 33, 540, 33, 135, 540, 135, 540, 135, 540, 135, 540, 33, 135, 135, 135, 135, 135, 135, 135, 135, 540, 33, 33, 33, 33, 33, 135, 33, 33, 135, 540, 540, 33, 33, 540, 33, 33, 33, 135, 33, 135, 540, 540, 135, 135, 33, 540, 135, 540, 33, 135, 135, 33, 33, 135, 33, 540, 540, 33, 540, 540, 33, 135, 540, 33, 33, 135, 135, 33, 33, 540, 540, 540, 540, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 540, 135, 135, 135, 540, 33, 135, 135, 540, 540, 33, 540, 540, 33, 540, 33, 33, 135, 33, 540, 540, 540, 135, 33, 540, 540, 135, 135, 540, 540, 33, 540, 540, 135, 33, 540, 135, 135, 540, 540, 540, 33, 540, 33, 540, 540, 33, 33, 540, 33, 135, 540, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 540, 33, 33, 33, 135, 33, 135, 135, 33, 540, 135, 540, 33, 540, 33, 135, 135, 135, 135, 33, 135, 540, 540, 33, 540, 540, 33, 540, 135, 540, 135, 135, 135, 33, 135, 33, 33, 540, 33, 135, 33, 33, 135, 540, 135, 540, 33, 540, 540, 135, 540, 135, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 90624 . Total input tokens: 20211841 . Total output tokens: 17814668
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 2.601237636990845,
    "estimated_duration": 3599.963073015081,
    "input_throughput": 2096.8034523970737,
    "output_throughput": 1820.5250629170953,
    "total_throughput": 3917.3285153141687,
    "itl": 50.54179963684398,
    "ttft": 7277.143506263397,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16854,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 111.44554182445383,
    "arrivals": 30443,
    "finished_requests": 30383,
    "scheduler_time": 13.663769456198265
}
#Debug simulation 
Total elapsed time: 2.60135034378618. Arrivals time: 0.0836993008852005 Scheduler time: 2.1283336747437716 Scheduler overhead time: 0.07433929620310664 Adapter cache time: 0.20767939696088433 Engine time: 0.07258800882846117 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-16/adapters_384_slots_96_rate_0.05-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-16/adapters_384_slots_96_rate_0.05-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 540, 135, 33, 540, 540, 33, 135, 540, 540, 540, 540, 135, 135, 135, 135, 540, 540, 135, 135, 33, 540, 33, 540, 135, 135, 135, 33, 33, 135, 33, 540, 33, 540, 135, 540, 135, 33, 135, 540, 135, 540, 33, 540, 540, 540, 540, 33, 135, 135, 135, 540, 135, 33, 135, 33, 540, 135, 540, 540, 135, 540, 540, 33, 33, 540, 135, 135, 33, 33, 33, 135, 33, 135, 33, 540, 33, 135, 540, 33, 540, 135, 33, 540, 540, 540, 540, 135, 33, 135, 540, 540, 135, 33, 33, 540, 135, 135, 33, 33, 540, 135, 540, 135, 540, 540, 135, 540, 540, 33, 135, 135, 135, 135, 33, 33, 540, 33, 540, 33, 33, 33, 135, 135, 540, 33, 33, 540, 33, 540, 135, 33, 540, 135, 135, 33, 540, 540, 540, 33, 135, 540, 33, 540, 135, 135, 540, 540, 33, 135, 540, 33, 135, 135, 33, 135, 33, 135, 540, 540, 135, 33, 540, 33, 540, 135, 135, 135, 135, 135, 33, 33, 540, 33, 540, 33, 135, 540, 135, 540, 135, 540, 135, 540, 33, 135, 135, 135, 135, 135, 135, 135, 135, 540, 33, 33, 33, 33, 33, 135, 33, 33, 135, 540, 540, 33, 33, 540, 33, 33, 33, 135, 33, 135, 540, 540, 135, 135, 33, 540, 135, 540, 33, 135, 135, 33, 33, 135, 33, 540, 540, 33, 540, 540, 33, 135, 540, 33, 33, 135, 135, 33, 33, 540, 540, 540, 540, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 540, 135, 135, 135, 540, 33, 135, 135, 540, 540, 33, 540, 540, 33, 540, 33, 33, 135, 33, 540, 540, 540, 135, 33, 540, 540, 135, 135, 540, 540, 33, 540, 540, 135, 33, 540, 135, 135, 540, 540, 540, 33, 540, 33, 540, 540, 33, 33, 540, 33, 135, 540, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 540, 33, 33, 33, 135, 33, 135, 135, 33, 540, 135, 540, 33, 540, 33, 135, 135, 135, 135, 33, 135, 540, 540, 33, 540, 540, 33, 540, 135, 540, 135, 135, 135, 33, 135, 33, 33, 540, 33, 135, 33, 33, 135, 540, 135, 540, 33, 540, 540, 135, 540, 135, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 90624 . Total input tokens: 20211841 . Total output tokens: 17814668
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 2.5852452851831913,
    "estimated_duration": 3599.9820447680354,
    "input_throughput": 2096.7924023316573,
    "output_throughput": 1820.5154688270939,
    "total_throughput": 3917.307871158751,
    "itl": 50.66641536323107,
    "ttft": 7276.67471862046,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16886,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 123.88975830416005,
    "arrivals": 30443,
    "finished_requests": 30383,
    "scheduler_time": 13.689610288282239
}
#Debug simulation 
Total elapsed time: 2.585365426260978. Arrivals time: 0.08263599406927824 Scheduler time: 2.113175912760198 Scheduler overhead time: 0.07419063756242394 Adapter cache time: 0.20819246396422386 Engine time: 0.0722413300536573 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-32/adapters_384_slots_96_rate_0.05-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-32/adapters_384_slots_96_rate_0.05-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 540, 135, 33, 540, 540, 33, 135, 540, 540, 540, 540, 135, 135, 135, 135, 540, 540, 135, 135, 33, 540, 33, 540, 135, 135, 135, 33, 33, 135, 33, 540, 33, 540, 135, 540, 135, 33, 135, 540, 135, 540, 33, 540, 540, 540, 540, 33, 135, 135, 135, 540, 135, 33, 135, 33, 540, 135, 540, 540, 135, 540, 540, 33, 33, 540, 135, 135, 33, 33, 33, 135, 33, 135, 33, 540, 33, 135, 540, 33, 540, 135, 33, 540, 540, 540, 540, 135, 33, 135, 540, 540, 135, 33, 33, 540, 135, 135, 33, 33, 540, 135, 540, 135, 540, 540, 135, 540, 540, 33, 135, 135, 135, 135, 33, 33, 540, 33, 540, 33, 33, 33, 135, 135, 540, 33, 33, 540, 33, 540, 135, 33, 540, 135, 135, 33, 540, 540, 540, 33, 135, 540, 33, 540, 135, 135, 540, 540, 33, 135, 540, 33, 135, 135, 33, 135, 33, 135, 540, 540, 135, 33, 540, 33, 540, 135, 135, 135, 135, 135, 33, 33, 540, 33, 540, 33, 135, 540, 135, 540, 135, 540, 135, 540, 33, 135, 135, 135, 135, 135, 135, 135, 135, 540, 33, 33, 33, 33, 33, 135, 33, 33, 135, 540, 540, 33, 33, 540, 33, 33, 33, 135, 33, 135, 540, 540, 135, 135, 33, 540, 135, 540, 33, 135, 135, 33, 33, 135, 33, 540, 540, 33, 540, 540, 33, 135, 540, 33, 33, 135, 135, 33, 33, 540, 540, 540, 540, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 540, 135, 135, 135, 540, 33, 135, 135, 540, 540, 33, 540, 540, 33, 540, 33, 33, 135, 33, 540, 540, 540, 135, 33, 540, 540, 135, 135, 540, 540, 33, 540, 540, 135, 33, 540, 135, 135, 540, 540, 540, 33, 540, 33, 540, 540, 33, 33, 540, 33, 135, 540, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 540, 33, 33, 33, 135, 33, 135, 135, 33, 540, 135, 540, 33, 540, 33, 135, 135, 135, 135, 33, 135, 540, 540, 33, 540, 540, 33, 540, 135, 540, 135, 135, 135, 33, 135, 33, 33, 540, 33, 135, 33, 33, 135, 540, 135, 540, 33, 540, 540, 135, 540, 135, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 90624 . Total input tokens: 20211841 . Total output tokens: 17814668
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 2.549731143284589,
    "estimated_duration": 3599.9604012492605,
    "input_throughput": 2096.8050085719124,
    "output_throughput": 1820.5264140476902,
    "total_throughput": 3917.331422619602,
    "itl": 50.79772969379253,
    "ttft": 7279.763843942913,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16878,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 127.27521579893701,
    "arrivals": 30443,
    "finished_requests": 30383,
    "scheduler_time": 13.723819277258725
}
#Debug simulation 
Total elapsed time: 2.5498319710604846. Arrivals time: 0.08322786260396242 Scheduler time: 2.079434012528509 Scheduler overhead time: 0.0742252441123128 Adapter cache time: 0.20581505075097084 Engine time: 0.07241913909092546 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-16/adapters_384_slots_96_rate_0.05-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-16/adapters_384_slots_96_rate_0.05-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 540, 135, 33, 540, 540, 33, 135, 540, 540, 540, 540, 135, 135, 135, 135, 540, 540, 135, 135, 33, 540, 33, 540, 135, 135, 135, 33, 33, 135, 33, 540, 33, 540, 135, 540, 135, 33, 135, 540, 135, 540, 33, 540, 540, 540, 540, 33, 135, 135, 135, 540, 135, 33, 135, 33, 540, 135, 540, 540, 135, 540, 540, 33, 33, 540, 135, 135, 33, 33, 33, 135, 33, 135, 33, 540, 33, 135, 540, 33, 540, 135, 33, 540, 540, 540, 540, 135, 33, 135, 540, 540, 135, 33, 33, 540, 135, 135, 33, 33, 540, 135, 540, 135, 540, 540, 135, 540, 540, 33, 135, 135, 135, 135, 33, 33, 540, 33, 540, 33, 33, 33, 135, 135, 540, 33, 33, 540, 33, 540, 135, 33, 540, 135, 135, 33, 540, 540, 540, 33, 135, 540, 33, 540, 135, 135, 540, 540, 33, 135, 540, 33, 135, 135, 33, 135, 33, 135, 540, 540, 135, 33, 540, 33, 540, 135, 135, 135, 135, 135, 33, 33, 540, 33, 540, 33, 135, 540, 135, 540, 135, 540, 135, 540, 33, 135, 135, 135, 135, 135, 135, 135, 135, 540, 33, 33, 33, 33, 33, 135, 33, 33, 135, 540, 540, 33, 33, 540, 33, 33, 33, 135, 33, 135, 540, 540, 135, 135, 33, 540, 135, 540, 33, 135, 135, 33, 33, 135, 33, 540, 540, 33, 540, 540, 33, 135, 540, 33, 33, 135, 135, 33, 33, 540, 540, 540, 540, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 540, 135, 135, 135, 540, 33, 135, 135, 540, 540, 33, 540, 540, 33, 540, 33, 33, 135, 33, 540, 540, 540, 135, 33, 540, 540, 135, 135, 540, 540, 33, 540, 540, 135, 33, 540, 135, 135, 540, 540, 540, 33, 540, 33, 540, 540, 33, 33, 540, 33, 135, 540, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 540, 33, 33, 33, 135, 33, 135, 135, 33, 540, 135, 540, 33, 540, 33, 135, 135, 135, 135, 33, 135, 540, 540, 33, 540, 540, 33, 540, 135, 540, 135, 135, 135, 33, 135, 33, 33, 540, 33, 135, 33, 33, 135, 540, 135, 540, 33, 540, 540, 135, 540, 135, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 90624 . Total input tokens: 20211841 . Total output tokens: 17814668
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 2.5616269782185555,
    "estimated_duration": 3599.952404508647,
    "input_throughput": 2096.8096663017614,
    "output_throughput": 1820.530458067132,
    "total_throughput": 3917.3401243688936,
    "itl": 50.372529715101315,
    "ttft": 7269.2805341580615,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16887,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 116.31784393175802,
    "arrivals": 30443,
    "finished_requests": 30383,
    "scheduler_time": 13.613149679315853
}
#Debug simulation 
Total elapsed time: 2.561714488081634. Arrivals time: 0.08406533300876617 Scheduler time: 2.091554631944746 Scheduler overhead time: 0.07354425685480237 Adapter cache time: 0.20624320209026337 Engine time: 0.07142953248694539 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-32/adapters_384_slots_96_rate_0.05-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-32/adapters_384_slots_96_rate_0.05-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 540, 135, 33, 540, 540, 33, 135, 540, 540, 540, 540, 135, 135, 135, 135, 540, 540, 135, 135, 33, 540, 33, 540, 135, 135, 135, 33, 33, 135, 33, 540, 33, 540, 135, 540, 135, 33, 135, 540, 135, 540, 33, 540, 540, 540, 540, 33, 135, 135, 135, 540, 135, 33, 135, 33, 540, 135, 540, 540, 135, 540, 540, 33, 33, 540, 135, 135, 33, 33, 33, 135, 33, 135, 33, 540, 33, 135, 540, 33, 540, 135, 33, 540, 540, 540, 540, 135, 33, 135, 540, 540, 135, 33, 33, 540, 135, 135, 33, 33, 540, 135, 540, 135, 540, 540, 135, 540, 540, 33, 135, 135, 135, 135, 33, 33, 540, 33, 540, 33, 33, 33, 135, 135, 540, 33, 33, 540, 33, 540, 135, 33, 540, 135, 135, 33, 540, 540, 540, 33, 135, 540, 33, 540, 135, 135, 540, 540, 33, 135, 540, 33, 135, 135, 33, 135, 33, 135, 540, 540, 135, 33, 540, 33, 540, 135, 135, 135, 135, 135, 33, 33, 540, 33, 540, 33, 135, 540, 135, 540, 135, 540, 135, 540, 33, 135, 135, 135, 135, 135, 135, 135, 135, 540, 33, 33, 33, 33, 33, 135, 33, 33, 135, 540, 540, 33, 33, 540, 33, 33, 33, 135, 33, 135, 540, 540, 135, 135, 33, 540, 135, 540, 33, 135, 135, 33, 33, 135, 33, 540, 540, 33, 540, 540, 33, 135, 540, 33, 33, 135, 135, 33, 33, 540, 540, 540, 540, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 540, 135, 135, 135, 540, 33, 135, 135, 540, 540, 33, 540, 540, 33, 540, 33, 33, 135, 33, 540, 540, 540, 135, 33, 540, 540, 135, 135, 540, 540, 33, 540, 540, 135, 33, 540, 135, 135, 540, 540, 540, 33, 540, 33, 540, 540, 33, 33, 540, 33, 135, 540, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 540, 33, 33, 33, 135, 33, 135, 135, 33, 540, 135, 540, 33, 540, 33, 135, 135, 135, 135, 33, 135, 540, 540, 33, 540, 540, 33, 540, 135, 540, 135, 135, 135, 33, 135, 33, 33, 540, 33, 135, 33, 33, 135, 540, 135, 540, 33, 540, 540, 135, 540, 135, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 90624 . Total input tokens: 20211841 . Total output tokens: 17814668
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 2.5779978591017425,
    "estimated_duration": 3599.9505595761334,
    "input_throughput": 2096.810740892166,
    "output_throughput": 1820.5313910676769,
    "total_throughput": 3917.342131959843,
    "itl": 50.75344186219752,
    "ttft": 7278.6596335570275,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16882,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 126.17049830304826,
    "arrivals": 30443,
    "finished_requests": 30383,
    "scheduler_time": 13.712490413706236
}
#Debug simulation 
Total elapsed time: 2.5780865140259266. Arrivals time: 0.08736434020102024 Scheduler time: 2.101487847045064 Scheduler overhead time: 0.07469638017937541 Adapter cache time: 0.2067899340763688 Engine time: 0.07290461333468556 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-16/adapters_384_slots_96_rate_0.05-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-16/adapters_384_slots_96_rate_0.05-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 540, 135, 33, 540, 540, 33, 135, 540, 540, 540, 540, 135, 135, 135, 135, 540, 540, 135, 135, 33, 540, 33, 540, 135, 135, 135, 33, 33, 135, 33, 540, 33, 540, 135, 540, 135, 33, 135, 540, 135, 540, 33, 540, 540, 540, 540, 33, 135, 135, 135, 540, 135, 33, 135, 33, 540, 135, 540, 540, 135, 540, 540, 33, 33, 540, 135, 135, 33, 33, 33, 135, 33, 135, 33, 540, 33, 135, 540, 33, 540, 135, 33, 540, 540, 540, 540, 135, 33, 135, 540, 540, 135, 33, 33, 540, 135, 135, 33, 33, 540, 135, 540, 135, 540, 540, 135, 540, 540, 33, 135, 135, 135, 135, 33, 33, 540, 33, 540, 33, 33, 33, 135, 135, 540, 33, 33, 540, 33, 540, 135, 33, 540, 135, 135, 33, 540, 540, 540, 33, 135, 540, 33, 540, 135, 135, 540, 540, 33, 135, 540, 33, 135, 135, 33, 135, 33, 135, 540, 540, 135, 33, 540, 33, 540, 135, 135, 135, 135, 135, 33, 33, 540, 33, 540, 33, 135, 540, 135, 540, 135, 540, 135, 540, 33, 135, 135, 135, 135, 135, 135, 135, 135, 540, 33, 33, 33, 33, 33, 135, 33, 33, 135, 540, 540, 33, 33, 540, 33, 33, 33, 135, 33, 135, 540, 540, 135, 135, 33, 540, 135, 540, 33, 135, 135, 33, 33, 135, 33, 540, 540, 33, 540, 540, 33, 135, 540, 33, 33, 135, 135, 33, 33, 540, 540, 540, 540, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 540, 135, 135, 135, 540, 33, 135, 135, 540, 540, 33, 540, 540, 33, 540, 33, 33, 135, 33, 540, 540, 540, 135, 33, 540, 540, 135, 135, 540, 540, 33, 540, 540, 135, 33, 540, 135, 135, 540, 540, 540, 33, 540, 33, 540, 540, 33, 33, 540, 33, 135, 540, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 540, 33, 33, 33, 135, 33, 135, 135, 33, 540, 135, 540, 33, 540, 33, 135, 135, 135, 135, 33, 135, 540, 540, 33, 540, 540, 33, 540, 135, 540, 135, 135, 135, 33, 135, 33, 33, 540, 33, 135, 33, 33, 135, 540, 135, 540, 33, 540, 540, 135, 540, 135, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 90624 . Total input tokens: 20211841 . Total output tokens: 17814668
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 2.5487063783220947,
    "estimated_duration": 3599.979929814731,
    "input_throughput": 2096.7936341768636,
    "output_throughput": 1820.5165383622807,
    "total_throughput": 3917.3101725391443,
    "itl": 50.38975696303958,
    "ttft": 7273.697712630539,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16859,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 107.62652313704332,
    "arrivals": 30443,
    "finished_requests": 30383,
    "scheduler_time": 13.625405262180033
}
#Debug simulation 
Total elapsed time: 2.5487926830537617. Arrivals time: 0.08228963566944003 Scheduler time: 2.0776906684041023 Scheduler overhead time: 0.07403028942644596 Adapter cache time: 0.20676783891394734 Engine time: 0.07305406639352441 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-32/adapters_384_slots_96_rate_0.05-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-32/adapters_384_slots_96_rate_0.05-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 540, 135, 33, 540, 540, 33, 135, 540, 540, 540, 540, 135, 135, 135, 135, 540, 540, 135, 135, 33, 540, 33, 540, 135, 135, 135, 33, 33, 135, 33, 540, 33, 540, 135, 540, 135, 33, 135, 540, 135, 540, 33, 540, 540, 540, 540, 33, 135, 135, 135, 540, 135, 33, 135, 33, 540, 135, 540, 540, 135, 540, 540, 33, 33, 540, 135, 135, 33, 33, 33, 135, 33, 135, 33, 540, 33, 135, 540, 33, 540, 135, 33, 540, 540, 540, 540, 135, 33, 135, 540, 540, 135, 33, 33, 540, 135, 135, 33, 33, 540, 135, 540, 135, 540, 540, 135, 540, 540, 33, 135, 135, 135, 135, 33, 33, 540, 33, 540, 33, 33, 33, 135, 135, 540, 33, 33, 540, 33, 540, 135, 33, 540, 135, 135, 33, 540, 540, 540, 33, 135, 540, 33, 540, 135, 135, 540, 540, 33, 135, 540, 33, 135, 135, 33, 135, 33, 135, 540, 540, 135, 33, 540, 33, 540, 135, 135, 135, 135, 135, 33, 33, 540, 33, 540, 33, 135, 540, 135, 540, 135, 540, 135, 540, 33, 135, 135, 135, 135, 135, 135, 135, 135, 540, 33, 33, 33, 33, 33, 135, 33, 33, 135, 540, 540, 33, 33, 540, 33, 33, 33, 135, 33, 135, 540, 540, 135, 135, 33, 540, 135, 540, 33, 135, 135, 33, 33, 135, 33, 540, 540, 33, 540, 540, 33, 135, 540, 33, 33, 135, 135, 33, 33, 540, 540, 540, 540, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 540, 135, 135, 135, 540, 33, 135, 135, 540, 540, 33, 540, 540, 33, 540, 33, 33, 135, 33, 540, 540, 540, 135, 33, 540, 540, 135, 135, 540, 540, 33, 540, 540, 135, 33, 540, 135, 135, 540, 540, 540, 33, 540, 33, 540, 540, 33, 33, 540, 33, 135, 540, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 540, 33, 33, 33, 135, 33, 135, 135, 33, 540, 135, 540, 33, 540, 33, 135, 135, 135, 135, 33, 135, 540, 540, 33, 540, 540, 33, 540, 135, 540, 135, 135, 135, 33, 135, 33, 33, 540, 33, 135, 33, 33, 135, 540, 135, 540, 33, 540, 540, 135, 540, 135, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 90624 . Total input tokens: 20211841 . Total output tokens: 17814668
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 2.5681621246039867,
    "estimated_duration": 3599.9482127299375,
    "input_throughput": 2096.8121078263607,
    "output_throughput": 1820.532577892297,
    "total_throughput": 3917.3446857186577,
    "itl": 50.70667994472594,
    "ttft": 7277.565975077708,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16892,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 124.97246536063363,
    "arrivals": 30443,
    "finished_requests": 30383,
    "scheduler_time": 13.70042961945422
}
#Debug simulation 
Total elapsed time: 2.568256797734648. Arrivals time: 0.08307757321745157 Scheduler time: 2.0964542450383306 Scheduler overhead time: 0.07495539356023073 Adapter cache time: 0.20724248606711626 Engine time: 0.07110389042645693 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-8/adapters_384_slots_96_rate_0.05-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-8/adapters_384_slots_96_rate_0.05-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 540, 66, 33, 540, 540, 33, 66, 540, 540, 540, 540, 66, 66, 66, 66, 540, 540, 66, 66, 33, 540, 33, 540, 66, 66, 66, 33, 33, 66, 33, 540, 33, 540, 66, 540, 66, 33, 66, 540, 66, 540, 33, 540, 540, 540, 540, 33, 66, 66, 66, 540, 66, 33, 66, 33, 540, 66, 540, 540, 66, 540, 540, 33, 33, 540, 66, 66, 33, 33, 33, 66, 33, 66, 33, 540, 33, 66, 540, 33, 540, 66, 33, 540, 540, 540, 540, 66, 33, 66, 540, 540, 66, 33, 33, 540, 66, 66, 33, 33, 540, 66, 540, 66, 540, 540, 66, 540, 540, 33, 66, 66, 66, 66, 33, 33, 540, 33, 540, 33, 33, 33, 66, 66, 540, 33, 33, 540, 33, 540, 66, 33, 540, 66, 66, 33, 540, 540, 540, 33, 66, 540, 33, 540, 66, 66, 540, 540, 33, 66, 540, 33, 66, 66, 33, 66, 33, 66, 540, 540, 66, 33, 540, 33, 540, 66, 66, 66, 66, 66, 33, 33, 540, 33, 540, 33, 66, 540, 66, 540, 66, 540, 66, 540, 33, 66, 66, 66, 66, 66, 66, 66, 66, 540, 33, 33, 33, 33, 33, 66, 33, 33, 66, 540, 540, 33, 33, 540, 33, 33, 33, 66, 33, 66, 540, 540, 66, 66, 33, 540, 66, 540, 33, 66, 66, 33, 33, 66, 33, 540, 540, 33, 540, 540, 33, 66, 540, 33, 33, 66, 66, 33, 33, 540, 540, 540, 540, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 540, 66, 66, 66, 540, 33, 66, 66, 540, 540, 33, 540, 540, 33, 540, 33, 33, 66, 33, 540, 540, 540, 66, 33, 540, 540, 66, 66, 540, 540, 33, 540, 540, 66, 33, 540, 66, 66, 540, 540, 540, 33, 540, 33, 540, 540, 33, 33, 540, 33, 66, 540, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 540, 33, 33, 33, 66, 33, 66, 66, 33, 540, 66, 540, 33, 540, 33, 66, 66, 66, 66, 33, 66, 540, 540, 33, 540, 540, 33, 540, 66, 540, 66, 66, 66, 33, 66, 33, 33, 540, 33, 66, 33, 33, 66, 540, 66, 540, 33, 540, 540, 66, 540, 66, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 81792 . Total input tokens: 18238428 . Total output tokens: 16047925
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 2.3806137861683965,
    "estimated_duration": 3600.023343037697,
    "input_throughput": 1876.6331093562735,
    "output_throughput": 1640.2585309397998,
    "total_throughput": 3516.8916402960735,
    "itl": 41.303364767725654,
    "ttft": 6483.193666504234,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 13361,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 88.34839707587057,
    "arrivals": 27512,
    "finished_requests": 27463,
    "scheduler_time": 8.133503227323137
}
#Debug simulation 
Total elapsed time: 2.3807576512917876. Arrivals time: 0.07854354754090309 Scheduler time: 1.903541793115437 Scheduler overhead time: 0.08683570520952344 Adapter cache time: 0.18563807336613536 Engine time: 0.08501222543418407 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-16/adapters_384_slots_96_rate_0.05-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-16/adapters_384_slots_96_rate_0.05-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 540, 66, 33, 540, 540, 33, 66, 540, 540, 540, 540, 66, 66, 66, 66, 540, 540, 66, 66, 33, 540, 33, 540, 66, 66, 66, 33, 33, 66, 33, 540, 33, 540, 66, 540, 66, 33, 66, 540, 66, 540, 33, 540, 540, 540, 540, 33, 66, 66, 66, 540, 66, 33, 66, 33, 540, 66, 540, 540, 66, 540, 540, 33, 33, 540, 66, 66, 33, 33, 33, 66, 33, 66, 33, 540, 33, 66, 540, 33, 540, 66, 33, 540, 540, 540, 540, 66, 33, 66, 540, 540, 66, 33, 33, 540, 66, 66, 33, 33, 540, 66, 540, 66, 540, 540, 66, 540, 540, 33, 66, 66, 66, 66, 33, 33, 540, 33, 540, 33, 33, 33, 66, 66, 540, 33, 33, 540, 33, 540, 66, 33, 540, 66, 66, 33, 540, 540, 540, 33, 66, 540, 33, 540, 66, 66, 540, 540, 33, 66, 540, 33, 66, 66, 33, 66, 33, 66, 540, 540, 66, 33, 540, 33, 540, 66, 66, 66, 66, 66, 33, 33, 540, 33, 540, 33, 66, 540, 66, 540, 66, 540, 66, 540, 33, 66, 66, 66, 66, 66, 66, 66, 66, 540, 33, 33, 33, 33, 33, 66, 33, 33, 66, 540, 540, 33, 33, 540, 33, 33, 33, 66, 33, 66, 540, 540, 66, 66, 33, 540, 66, 540, 33, 66, 66, 33, 33, 66, 33, 540, 540, 33, 540, 540, 33, 66, 540, 33, 33, 66, 66, 33, 33, 540, 540, 540, 540, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 540, 66, 66, 66, 540, 33, 66, 66, 540, 540, 33, 540, 540, 33, 540, 33, 33, 66, 33, 540, 540, 540, 66, 33, 540, 540, 66, 66, 540, 540, 33, 540, 540, 66, 33, 540, 66, 66, 540, 540, 540, 33, 540, 33, 540, 540, 33, 33, 540, 33, 66, 540, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 540, 33, 33, 33, 66, 33, 66, 66, 33, 540, 66, 540, 33, 540, 33, 66, 66, 66, 66, 33, 66, 540, 540, 33, 540, 540, 33, 540, 66, 540, 66, 66, 66, 33, 66, 33, 33, 540, 33, 66, 33, 33, 66, 540, 66, 540, 33, 540, 540, 66, 540, 66, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 81792 . Total input tokens: 18238428 . Total output tokens: 16047925
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 2.3427240229211748,
    "estimated_duration": 3600.034316995835,
    "input_throughput": 1876.502112245786,
    "output_throughput": 1640.0721437919644,
    "total_throughput": 3516.5742560377507,
    "itl": 41.871136821168065,
    "ttft": 6746.162706355398,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 13348,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 98.05084427594156,
    "arrivals": 27512,
    "finished_requests": 27461,
    "scheduler_time": 8.343145956778628
}
#Debug simulation 
Total elapsed time: 2.342810404021293. Arrivals time: 0.0758696785196662 Scheduler time: 1.8737119007855654 Scheduler overhead time: 0.08621213166043162 Adapter cache time: 0.1837788331322372 Engine time: 0.08290829276666045 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-32/adapters_384_slots_96_rate_0.05-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-32/adapters_384_slots_96_rate_0.05-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 540, 66, 33, 540, 540, 33, 66, 540, 540, 540, 540, 66, 66, 66, 66, 540, 540, 66, 66, 33, 540, 33, 540, 66, 66, 66, 33, 33, 66, 33, 540, 33, 540, 66, 540, 66, 33, 66, 540, 66, 540, 33, 540, 540, 540, 540, 33, 66, 66, 66, 540, 66, 33, 66, 33, 540, 66, 540, 540, 66, 540, 540, 33, 33, 540, 66, 66, 33, 33, 33, 66, 33, 66, 33, 540, 33, 66, 540, 33, 540, 66, 33, 540, 540, 540, 540, 66, 33, 66, 540, 540, 66, 33, 33, 540, 66, 66, 33, 33, 540, 66, 540, 66, 540, 540, 66, 540, 540, 33, 66, 66, 66, 66, 33, 33, 540, 33, 540, 33, 33, 33, 66, 66, 540, 33, 33, 540, 33, 540, 66, 33, 540, 66, 66, 33, 540, 540, 540, 33, 66, 540, 33, 540, 66, 66, 540, 540, 33, 66, 540, 33, 66, 66, 33, 66, 33, 66, 540, 540, 66, 33, 540, 33, 540, 66, 66, 66, 66, 66, 33, 33, 540, 33, 540, 33, 66, 540, 66, 540, 66, 540, 66, 540, 33, 66, 66, 66, 66, 66, 66, 66, 66, 540, 33, 33, 33, 33, 33, 66, 33, 33, 66, 540, 540, 33, 33, 540, 33, 33, 33, 66, 33, 66, 540, 540, 66, 66, 33, 540, 66, 540, 33, 66, 66, 33, 33, 66, 33, 540, 540, 33, 540, 540, 33, 66, 540, 33, 33, 66, 66, 33, 33, 540, 540, 540, 540, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 540, 66, 66, 66, 540, 33, 66, 66, 540, 540, 33, 540, 540, 33, 540, 33, 33, 66, 33, 540, 540, 540, 66, 33, 540, 540, 66, 66, 540, 540, 33, 540, 540, 66, 33, 540, 66, 66, 540, 540, 540, 33, 540, 33, 540, 540, 33, 33, 540, 33, 66, 540, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 540, 33, 33, 33, 66, 33, 66, 66, 33, 540, 66, 540, 33, 540, 33, 66, 66, 66, 66, 33, 66, 540, 540, 33, 540, 540, 33, 540, 66, 540, 66, 66, 66, 33, 66, 33, 33, 540, 33, 66, 33, 33, 66, 540, 66, 540, 33, 540, 540, 66, 540, 66, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 81792 . Total input tokens: 18238428 . Total output tokens: 16047925
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 2.329431193880737,
    "estimated_duration": 3600.027708090489,
    "input_throughput": 1876.5055571150613,
    "output_throughput": 1640.0751546247798,
    "total_throughput": 3516.580711739841,
    "itl": 41.92289587621436,
    "ttft": 6746.328386969656,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 13327,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 100.63226766499844,
    "arrivals": 27512,
    "finished_requests": 27461,
    "scheduler_time": 8.363111128788324
}
#Debug simulation 
Total elapsed time: 2.3295196159742773. Arrivals time: 0.07586891250684857 Scheduler time: 1.8617488113231957 Scheduler overhead time: 0.08450659643858671 Adapter cache time: 0.18338645435869694 Engine time: 0.08385046385228634 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-16/adapters_384_slots_96_rate_0.05-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-16/adapters_384_slots_96_rate_0.05-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 540, 66, 33, 540, 540, 33, 66, 540, 540, 540, 540, 66, 66, 66, 66, 540, 540, 66, 66, 33, 540, 33, 540, 66, 66, 66, 33, 33, 66, 33, 540, 33, 540, 66, 540, 66, 33, 66, 540, 66, 540, 33, 540, 540, 540, 540, 33, 66, 66, 66, 540, 66, 33, 66, 33, 540, 66, 540, 540, 66, 540, 540, 33, 33, 540, 66, 66, 33, 33, 33, 66, 33, 66, 33, 540, 33, 66, 540, 33, 540, 66, 33, 540, 540, 540, 540, 66, 33, 66, 540, 540, 66, 33, 33, 540, 66, 66, 33, 33, 540, 66, 540, 66, 540, 540, 66, 540, 540, 33, 66, 66, 66, 66, 33, 33, 540, 33, 540, 33, 33, 33, 66, 66, 540, 33, 33, 540, 33, 540, 66, 33, 540, 66, 66, 33, 540, 540, 540, 33, 66, 540, 33, 540, 66, 66, 540, 540, 33, 66, 540, 33, 66, 66, 33, 66, 33, 66, 540, 540, 66, 33, 540, 33, 540, 66, 66, 66, 66, 66, 33, 33, 540, 33, 540, 33, 66, 540, 66, 540, 66, 540, 66, 540, 33, 66, 66, 66, 66, 66, 66, 66, 66, 540, 33, 33, 33, 33, 33, 66, 33, 33, 66, 540, 540, 33, 33, 540, 33, 33, 33, 66, 33, 66, 540, 540, 66, 66, 33, 540, 66, 540, 33, 66, 66, 33, 33, 66, 33, 540, 540, 33, 540, 540, 33, 66, 540, 33, 33, 66, 66, 33, 33, 540, 540, 540, 540, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 540, 66, 66, 66, 540, 33, 66, 66, 540, 540, 33, 540, 540, 33, 540, 33, 33, 66, 33, 540, 540, 540, 66, 33, 540, 540, 66, 66, 540, 540, 33, 540, 540, 66, 33, 540, 66, 66, 540, 540, 540, 33, 540, 33, 540, 540, 33, 33, 540, 33, 66, 540, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 540, 33, 33, 33, 66, 33, 66, 66, 33, 540, 66, 540, 33, 540, 33, 66, 66, 66, 66, 33, 66, 540, 540, 33, 540, 540, 33, 540, 66, 540, 66, 66, 66, 33, 66, 33, 33, 540, 33, 66, 33, 33, 66, 540, 66, 540, 33, 540, 540, 66, 540, 66, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 81792 . Total input tokens: 18238428 . Total output tokens: 16047925
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 2.3311812160536647,
    "estimated_duration": 3600.0077988120347,
    "input_throughput": 1876.549545873005,
    "output_throughput": 1640.1456135590695,
    "total_throughput": 3516.6951594320744,
    "itl": 41.396498707863564,
    "ttft": 6614.32353643684,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 13354,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 91.9795872980215,
    "arrivals": 27512,
    "finished_requests": 27462,
    "scheduler_time": 8.168437566415268
}
#Debug simulation 
Total elapsed time: 2.3312710179015994. Arrivals time: 0.07611278491094708 Scheduler time: 1.8602516609244049 Scheduler overhead time: 0.08716592565178871 Adapter cache time: 0.1826211200095713 Engine time: 0.08451110357418656 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-32/adapters_384_slots_96_rate_0.05-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-32/adapters_384_slots_96_rate_0.05-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 540, 66, 33, 540, 540, 33, 66, 540, 540, 540, 540, 66, 66, 66, 66, 540, 540, 66, 66, 33, 540, 33, 540, 66, 66, 66, 33, 33, 66, 33, 540, 33, 540, 66, 540, 66, 33, 66, 540, 66, 540, 33, 540, 540, 540, 540, 33, 66, 66, 66, 540, 66, 33, 66, 33, 540, 66, 540, 540, 66, 540, 540, 33, 33, 540, 66, 66, 33, 33, 33, 66, 33, 66, 33, 540, 33, 66, 540, 33, 540, 66, 33, 540, 540, 540, 540, 66, 33, 66, 540, 540, 66, 33, 33, 540, 66, 66, 33, 33, 540, 66, 540, 66, 540, 540, 66, 540, 540, 33, 66, 66, 66, 66, 33, 33, 540, 33, 540, 33, 33, 33, 66, 66, 540, 33, 33, 540, 33, 540, 66, 33, 540, 66, 66, 33, 540, 540, 540, 33, 66, 540, 33, 540, 66, 66, 540, 540, 33, 66, 540, 33, 66, 66, 33, 66, 33, 66, 540, 540, 66, 33, 540, 33, 540, 66, 66, 66, 66, 66, 33, 33, 540, 33, 540, 33, 66, 540, 66, 540, 66, 540, 66, 540, 33, 66, 66, 66, 66, 66, 66, 66, 66, 540, 33, 33, 33, 33, 33, 66, 33, 33, 66, 540, 540, 33, 33, 540, 33, 33, 33, 66, 33, 66, 540, 540, 66, 66, 33, 540, 66, 540, 33, 66, 66, 33, 33, 66, 33, 540, 540, 33, 540, 540, 33, 66, 540, 33, 33, 66, 66, 33, 33, 540, 540, 540, 540, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 540, 66, 66, 66, 540, 33, 66, 66, 540, 540, 33, 540, 540, 33, 540, 33, 33, 66, 33, 540, 540, 540, 66, 33, 540, 540, 66, 66, 540, 540, 33, 540, 540, 66, 33, 540, 66, 66, 540, 540, 540, 33, 540, 33, 540, 540, 33, 33, 540, 33, 66, 540, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 540, 33, 33, 33, 66, 33, 66, 66, 33, 540, 66, 540, 33, 540, 33, 66, 66, 66, 66, 33, 66, 540, 540, 33, 540, 540, 33, 540, 66, 540, 66, 66, 66, 33, 66, 33, 33, 540, 33, 66, 33, 33, 66, 540, 66, 540, 33, 540, 540, 66, 540, 66, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 81792 . Total input tokens: 18238428 . Total output tokens: 16047925
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 2.3513471400365233,
    "estimated_duration": 3600.024745671811,
    "input_throughput": 1876.5071012697558,
    "output_throughput": 1640.0765042236337,
    "total_throughput": 3516.5836054933893,
    "itl": 41.89850269270006,
    "ttft": 6746.160771563475,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 13328,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 99.71116385634643,
    "arrivals": 27512,
    "finished_requests": 27461,
    "scheduler_time": 8.35416905918511
}
#Debug simulation 
Total elapsed time: 2.3514340152032673. Arrivals time: 0.07591763557866216 Scheduler time: 1.8804552215151489 Scheduler overhead time: 0.08592951484024525 Adapter cache time: 0.18545632669702172 Engine time: 0.08341387612745166 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-16/adapters_384_slots_96_rate_0.05-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-16/adapters_384_slots_96_rate_0.05-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 540, 66, 33, 540, 540, 33, 66, 540, 540, 540, 540, 66, 66, 66, 66, 540, 540, 66, 66, 33, 540, 33, 540, 66, 66, 66, 33, 33, 66, 33, 540, 33, 540, 66, 540, 66, 33, 66, 540, 66, 540, 33, 540, 540, 540, 540, 33, 66, 66, 66, 540, 66, 33, 66, 33, 540, 66, 540, 540, 66, 540, 540, 33, 33, 540, 66, 66, 33, 33, 33, 66, 33, 66, 33, 540, 33, 66, 540, 33, 540, 66, 33, 540, 540, 540, 540, 66, 33, 66, 540, 540, 66, 33, 33, 540, 66, 66, 33, 33, 540, 66, 540, 66, 540, 540, 66, 540, 540, 33, 66, 66, 66, 66, 33, 33, 540, 33, 540, 33, 33, 33, 66, 66, 540, 33, 33, 540, 33, 540, 66, 33, 540, 66, 66, 33, 540, 540, 540, 33, 66, 540, 33, 540, 66, 66, 540, 540, 33, 66, 540, 33, 66, 66, 33, 66, 33, 66, 540, 540, 66, 33, 540, 33, 540, 66, 66, 66, 66, 66, 33, 33, 540, 33, 540, 33, 66, 540, 66, 540, 66, 540, 66, 540, 33, 66, 66, 66, 66, 66, 66, 66, 66, 540, 33, 33, 33, 33, 33, 66, 33, 33, 66, 540, 540, 33, 33, 540, 33, 33, 33, 66, 33, 66, 540, 540, 66, 66, 33, 540, 66, 540, 33, 66, 66, 33, 33, 66, 33, 540, 540, 33, 540, 540, 33, 66, 540, 33, 33, 66, 66, 33, 33, 540, 540, 540, 540, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 540, 66, 66, 66, 540, 33, 66, 66, 540, 540, 33, 540, 540, 33, 540, 33, 33, 66, 33, 540, 540, 540, 66, 33, 540, 540, 66, 66, 540, 540, 33, 540, 540, 66, 33, 540, 66, 66, 540, 540, 540, 33, 540, 33, 540, 540, 33, 33, 540, 33, 66, 540, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 540, 33, 33, 33, 66, 33, 66, 66, 33, 540, 66, 540, 33, 540, 33, 66, 66, 66, 66, 33, 66, 540, 540, 33, 540, 540, 33, 540, 66, 540, 66, 66, 66, 33, 66, 33, 33, 540, 33, 66, 33, 33, 66, 540, 66, 540, 33, 540, 540, 66, 540, 66, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 81792 . Total input tokens: 18238428 . Total output tokens: 16047925
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 2.327381792012602,
    "estimated_duration": 3600.0152522559492,
    "input_throughput": 1876.6373269575458,
    "output_throughput": 1640.2622173057882,
    "total_throughput": 3516.899544263334,
    "itl": 41.222816645993774,
    "ttft": 6482.891362746197,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 13356,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 85.26364808224665,
    "arrivals": 27512,
    "finished_requests": 27463,
    "scheduler_time": 8.103998896970289
}
#Debug simulation 
Total elapsed time: 2.3274669270031154. Arrivals time: 0.0749187907204032 Scheduler time: 1.858475307468325 Scheduler overhead time: 0.08749744854867458 Adapter cache time: 0.18330839090049267 Engine time: 0.0824921503663063 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-32/adapters_384_slots_96_rate_0.05-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-32/adapters_384_slots_96_rate_0.05-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 540, 66, 33, 540, 540, 33, 66, 540, 540, 540, 540, 66, 66, 66, 66, 540, 540, 66, 66, 33, 540, 33, 540, 66, 66, 66, 33, 33, 66, 33, 540, 33, 540, 66, 540, 66, 33, 66, 540, 66, 540, 33, 540, 540, 540, 540, 33, 66, 66, 66, 540, 66, 33, 66, 33, 540, 66, 540, 540, 66, 540, 540, 33, 33, 540, 66, 66, 33, 33, 33, 66, 33, 66, 33, 540, 33, 66, 540, 33, 540, 66, 33, 540, 540, 540, 540, 66, 33, 66, 540, 540, 66, 33, 33, 540, 66, 66, 33, 33, 540, 66, 540, 66, 540, 540, 66, 540, 540, 33, 66, 66, 66, 66, 33, 33, 540, 33, 540, 33, 33, 33, 66, 66, 540, 33, 33, 540, 33, 540, 66, 33, 540, 66, 66, 33, 540, 540, 540, 33, 66, 540, 33, 540, 66, 66, 540, 540, 33, 66, 540, 33, 66, 66, 33, 66, 33, 66, 540, 540, 66, 33, 540, 33, 540, 66, 66, 66, 66, 66, 33, 33, 540, 33, 540, 33, 66, 540, 66, 540, 66, 540, 66, 540, 33, 66, 66, 66, 66, 66, 66, 66, 66, 540, 33, 33, 33, 33, 33, 66, 33, 33, 66, 540, 540, 33, 33, 540, 33, 33, 33, 66, 33, 66, 540, 540, 66, 66, 33, 540, 66, 540, 33, 66, 66, 33, 33, 66, 33, 540, 540, 33, 540, 540, 33, 66, 540, 33, 33, 66, 66, 33, 33, 540, 540, 540, 540, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 540, 66, 66, 66, 540, 33, 66, 66, 540, 540, 33, 540, 540, 33, 540, 33, 33, 66, 33, 540, 540, 540, 66, 33, 540, 540, 66, 66, 540, 540, 33, 540, 540, 66, 33, 540, 66, 66, 540, 540, 540, 33, 540, 33, 540, 540, 33, 33, 540, 33, 66, 540, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 540, 33, 33, 33, 66, 33, 66, 66, 33, 540, 66, 540, 33, 540, 33, 66, 66, 66, 66, 33, 66, 540, 540, 33, 540, 540, 33, 540, 66, 540, 66, 66, 66, 33, 66, 33, 33, 540, 33, 66, 33, 33, 66, 540, 66, 540, 33, 540, 540, 66, 540, 66, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 81792 . Total input tokens: 18238428 . Total output tokens: 16047925
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 2.348999763838947,
    "estimated_duration": 3600.0163000840603,
    "input_throughput": 1876.5115035290978,
    "output_throughput": 1640.080351820111,
    "total_throughput": 3516.591855349209,
    "itl": 42.17390362709417,
    "ttft": 6746.777950314261,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 13305,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 98.51550938057791,
    "arrivals": 27512,
    "finished_requests": 27461,
    "scheduler_time": 8.456707901198529
}
#Debug simulation 
Total elapsed time: 2.3490829346701503. Arrivals time: 0.07575084269046783 Scheduler time: 1.880506151355803 Scheduler overhead time: 0.08496988331899047 Adapter cache time: 0.18431953061372042 Engine time: 0.08357668155804276 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-8/adapters_384_slots_96_rate_0.025-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-8/adapters_384_slots_96_rate_0.025-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 270, 135, 66, 270, 270, 66, 135, 270, 270, 270, 270, 135, 135, 135, 135, 270, 270, 135, 135, 66, 270, 66, 270, 135, 135, 135, 66, 66, 135, 66, 270, 66, 270, 135, 270, 135, 66, 135, 270, 135, 270, 66, 270, 270, 270, 270, 66, 135, 135, 135, 270, 135, 66, 135, 66, 270, 135, 270, 270, 135, 270, 270, 66, 66, 270, 135, 135, 66, 66, 66, 135, 66, 135, 66, 270, 66, 135, 270, 66, 270, 135, 66, 270, 270, 270, 270, 135, 66, 135, 270, 270, 135, 66, 66, 270, 135, 135, 66, 66, 270, 135, 270, 135, 270, 270, 135, 270, 270, 66, 135, 135, 135, 135, 66, 66, 270, 66, 270, 66, 66, 66, 135, 135, 270, 66, 66, 270, 66, 270, 135, 66, 270, 135, 135, 66, 270, 270, 270, 66, 135, 270, 66, 270, 135, 135, 270, 270, 66, 135, 270, 66, 135, 135, 66, 135, 66, 135, 270, 270, 135, 66, 270, 66, 270, 135, 135, 135, 135, 135, 66, 66, 270, 66, 270, 66, 135, 270, 135, 270, 135, 270, 135, 270, 66, 135, 135, 135, 135, 135, 135, 135, 135, 270, 66, 66, 66, 66, 66, 135, 66, 66, 135, 270, 270, 66, 66, 270, 66, 66, 66, 135, 66, 135, 270, 270, 135, 135, 66, 270, 135, 270, 66, 135, 135, 66, 66, 135, 66, 270, 270, 66, 270, 270, 66, 135, 270, 66, 66, 135, 135, 66, 66, 270, 270, 270, 270, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 270, 135, 135, 135, 270, 66, 135, 135, 270, 270, 66, 270, 270, 66, 270, 66, 66, 135, 66, 270, 270, 270, 135, 66, 270, 270, 135, 135, 270, 270, 66, 270, 270, 135, 66, 270, 135, 135, 270, 270, 270, 66, 270, 66, 270, 270, 66, 66, 270, 66, 135, 270, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 270, 66, 66, 66, 135, 66, 135, 135, 66, 270, 135, 270, 66, 270, 66, 135, 135, 135, 135, 66, 135, 270, 270, 66, 270, 270, 66, 270, 135, 270, 135, 135, 135, 66, 135, 66, 66, 270, 66, 135, 66, 66, 135, 270, 135, 270, 66, 270, 270, 135, 270, 135, 66, 270, 66, 270, 270, 66, 66, 66]
Prompts retrieved: 60288 . Total input tokens: 13399771 . Total output tokens: 11859158
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 1.8574142307043076,
    "estimated_duration": 3599.970021431452,
    "input_throughput": 1375.4497872265918,
    "output_throughput": 1207.2069973160335,
    "total_throughput": 2582.6567845426252,
    "itl": 32.49765055528796,
    "ttft": 8580.959227054256,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 13839,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 91.50912859314019,
    "arrivals": 20275,
    "finished_requests": 20227,
    "scheduler_time": 0.5405305898233393
}
#Debug simulation 
Total elapsed time: 1.8575023338198662. Arrivals time: 0.05904004629701376 Scheduler time: 1.3810430741868913 Scheduler overhead time: 0.10372616117820144 Adapter cache time: 0.1648221705108881 Engine time: 0.09957028040662408 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-16/adapters_384_slots_96_rate_0.025-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-16/adapters_384_slots_96_rate_0.025-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 270, 135, 66, 270, 270, 66, 135, 270, 270, 270, 270, 135, 135, 135, 135, 270, 270, 135, 135, 66, 270, 66, 270, 135, 135, 135, 66, 66, 135, 66, 270, 66, 270, 135, 270, 135, 66, 135, 270, 135, 270, 66, 270, 270, 270, 270, 66, 135, 135, 135, 270, 135, 66, 135, 66, 270, 135, 270, 270, 135, 270, 270, 66, 66, 270, 135, 135, 66, 66, 66, 135, 66, 135, 66, 270, 66, 135, 270, 66, 270, 135, 66, 270, 270, 270, 270, 135, 66, 135, 270, 270, 135, 66, 66, 270, 135, 135, 66, 66, 270, 135, 270, 135, 270, 270, 135, 270, 270, 66, 135, 135, 135, 135, 66, 66, 270, 66, 270, 66, 66, 66, 135, 135, 270, 66, 66, 270, 66, 270, 135, 66, 270, 135, 135, 66, 270, 270, 270, 66, 135, 270, 66, 270, 135, 135, 270, 270, 66, 135, 270, 66, 135, 135, 66, 135, 66, 135, 270, 270, 135, 66, 270, 66, 270, 135, 135, 135, 135, 135, 66, 66, 270, 66, 270, 66, 135, 270, 135, 270, 135, 270, 135, 270, 66, 135, 135, 135, 135, 135, 135, 135, 135, 270, 66, 66, 66, 66, 66, 135, 66, 66, 135, 270, 270, 66, 66, 270, 66, 66, 66, 135, 66, 135, 270, 270, 135, 135, 66, 270, 135, 270, 66, 135, 135, 66, 66, 135, 66, 270, 270, 66, 270, 270, 66, 135, 270, 66, 66, 135, 135, 66, 66, 270, 270, 270, 270, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 270, 135, 135, 135, 270, 66, 135, 135, 270, 270, 66, 270, 270, 66, 270, 66, 66, 135, 66, 270, 270, 270, 135, 66, 270, 270, 135, 135, 270, 270, 66, 270, 270, 135, 66, 270, 135, 135, 270, 270, 270, 66, 270, 66, 270, 270, 66, 66, 270, 66, 135, 270, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 270, 66, 66, 66, 135, 66, 135, 135, 66, 270, 135, 270, 66, 270, 66, 135, 135, 135, 135, 66, 135, 270, 270, 66, 270, 270, 66, 270, 135, 270, 135, 135, 135, 66, 135, 66, 66, 270, 66, 135, 66, 66, 135, 270, 135, 270, 66, 270, 270, 135, 270, 135, 66, 270, 66, 270, 270, 66, 66, 66]
Prompts retrieved: 60288 . Total input tokens: 13399771 . Total output tokens: 11859158
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 1.8686755960807204,
    "estimated_duration": 3599.9502723632013,
    "input_throughput": 1375.398165361228,
    "output_throughput": 1207.1344522065574,
    "total_throughput": 2582.5326175677856,
    "itl": 32.96539704896648,
    "ttft": 8759.766600193523,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 13812,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 101.0699006522719,
    "arrivals": 20275,
    "finished_requests": 20226,
    "scheduler_time": 0.607501654651432
}
#Debug simulation 
Total elapsed time: 1.8687645178288221. Arrivals time: 0.05978403706103563 Scheduler time: 1.394431356806308 Scheduler overhead time: 0.10124739957973361 Adapter cache time: 0.16514172032475471 Engine time: 0.09952225023880601 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-32/adapters_384_slots_96_rate_0.025-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-32/adapters_384_slots_96_rate_0.025-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 270, 135, 66, 270, 270, 66, 135, 270, 270, 270, 270, 135, 135, 135, 135, 270, 270, 135, 135, 66, 270, 66, 270, 135, 135, 135, 66, 66, 135, 66, 270, 66, 270, 135, 270, 135, 66, 135, 270, 135, 270, 66, 270, 270, 270, 270, 66, 135, 135, 135, 270, 135, 66, 135, 66, 270, 135, 270, 270, 135, 270, 270, 66, 66, 270, 135, 135, 66, 66, 66, 135, 66, 135, 66, 270, 66, 135, 270, 66, 270, 135, 66, 270, 270, 270, 270, 135, 66, 135, 270, 270, 135, 66, 66, 270, 135, 135, 66, 66, 270, 135, 270, 135, 270, 270, 135, 270, 270, 66, 135, 135, 135, 135, 66, 66, 270, 66, 270, 66, 66, 66, 135, 135, 270, 66, 66, 270, 66, 270, 135, 66, 270, 135, 135, 66, 270, 270, 270, 66, 135, 270, 66, 270, 135, 135, 270, 270, 66, 135, 270, 66, 135, 135, 66, 135, 66, 135, 270, 270, 135, 66, 270, 66, 270, 135, 135, 135, 135, 135, 66, 66, 270, 66, 270, 66, 135, 270, 135, 270, 135, 270, 135, 270, 66, 135, 135, 135, 135, 135, 135, 135, 135, 270, 66, 66, 66, 66, 66, 135, 66, 66, 135, 270, 270, 66, 66, 270, 66, 66, 66, 135, 66, 135, 270, 270, 135, 135, 66, 270, 135, 270, 66, 135, 135, 66, 66, 135, 66, 270, 270, 66, 270, 270, 66, 135, 270, 66, 66, 135, 135, 66, 66, 270, 270, 270, 270, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 270, 135, 135, 135, 270, 66, 135, 135, 270, 270, 66, 270, 270, 66, 270, 66, 66, 135, 66, 270, 270, 270, 135, 66, 270, 270, 135, 135, 270, 270, 66, 270, 270, 135, 66, 270, 135, 135, 270, 270, 270, 66, 270, 66, 270, 270, 66, 66, 270, 66, 135, 270, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 270, 66, 66, 66, 135, 66, 135, 135, 66, 270, 135, 270, 66, 270, 66, 135, 135, 135, 135, 66, 135, 270, 270, 66, 270, 270, 66, 270, 135, 270, 135, 135, 135, 66, 135, 66, 66, 270, 66, 135, 66, 66, 135, 270, 135, 270, 66, 270, 270, 135, 270, 135, 66, 270, 66, 270, 270, 66, 66, 66]
Prompts retrieved: 60288 . Total input tokens: 13399771 . Total output tokens: 11859158
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 1.850246551912278,
    "estimated_duration": 3599.9441869677203,
    "input_throughput": 1375.400490353324,
    "output_throughput": 1207.1364927633435,
    "total_throughput": 2582.536983116667,
    "itl": 32.70306258880857,
    "ttft": 8759.562712468314,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 13824,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 103.93521267155931,
    "arrivals": 20275,
    "finished_requests": 20226,
    "scheduler_time": 0.5707207078836868
}
#Debug simulation 
Total elapsed time: 1.8503378629684448. Arrivals time: 0.0595436324365437 Scheduler time: 1.3782980432733893 Scheduler overhead time: 0.10194282978773117 Adapter cache time: 0.16412731911987066 Engine time: 0.09768606256693602 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-16/adapters_384_slots_96_rate_0.025-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-16/adapters_384_slots_96_rate_0.025-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 270, 135, 66, 270, 270, 66, 135, 270, 270, 270, 270, 135, 135, 135, 135, 270, 270, 135, 135, 66, 270, 66, 270, 135, 135, 135, 66, 66, 135, 66, 270, 66, 270, 135, 270, 135, 66, 135, 270, 135, 270, 66, 270, 270, 270, 270, 66, 135, 135, 135, 270, 135, 66, 135, 66, 270, 135, 270, 270, 135, 270, 270, 66, 66, 270, 135, 135, 66, 66, 66, 135, 66, 135, 66, 270, 66, 135, 270, 66, 270, 135, 66, 270, 270, 270, 270, 135, 66, 135, 270, 270, 135, 66, 66, 270, 135, 135, 66, 66, 270, 135, 270, 135, 270, 270, 135, 270, 270, 66, 135, 135, 135, 135, 66, 66, 270, 66, 270, 66, 66, 66, 135, 135, 270, 66, 66, 270, 66, 270, 135, 66, 270, 135, 135, 66, 270, 270, 270, 66, 135, 270, 66, 270, 135, 135, 270, 270, 66, 135, 270, 66, 135, 135, 66, 135, 66, 135, 270, 270, 135, 66, 270, 66, 270, 135, 135, 135, 135, 135, 66, 66, 270, 66, 270, 66, 135, 270, 135, 270, 135, 270, 135, 270, 66, 135, 135, 135, 135, 135, 135, 135, 135, 270, 66, 66, 66, 66, 66, 135, 66, 66, 135, 270, 270, 66, 66, 270, 66, 66, 66, 135, 66, 135, 270, 270, 135, 135, 66, 270, 135, 270, 66, 135, 135, 66, 66, 135, 66, 270, 270, 66, 270, 270, 66, 135, 270, 66, 66, 135, 135, 66, 66, 270, 270, 270, 270, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 270, 135, 135, 135, 270, 66, 135, 135, 270, 270, 66, 270, 270, 66, 270, 66, 66, 135, 66, 270, 270, 270, 135, 66, 270, 270, 135, 135, 270, 270, 66, 270, 270, 135, 66, 270, 135, 135, 270, 270, 270, 66, 270, 66, 270, 270, 66, 66, 270, 66, 135, 270, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 270, 66, 66, 66, 135, 66, 135, 135, 66, 270, 135, 270, 66, 270, 66, 135, 135, 135, 135, 66, 135, 270, 270, 66, 270, 270, 66, 270, 135, 270, 135, 135, 135, 66, 135, 66, 66, 270, 66, 135, 66, 66, 135, 270, 135, 270, 66, 270, 270, 135, 270, 135, 66, 270, 66, 270, 270, 66, 66, 66]
Prompts retrieved: 60288 . Total input tokens: 13399771 . Total output tokens: 11859158
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 1.8767903442494571,
    "estimated_duration": 3599.972740670349,
    "input_throughput": 1375.3895811661087,
    "output_throughput": 1207.1269181862758,
    "total_throughput": 2582.5164993523845,
    "itl": 32.55789307831114,
    "ttft": 8758.712505417445,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 13835,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 94.96973645398192,
    "arrivals": 20275,
    "finished_requests": 20226,
    "scheduler_time": 0.548674165716519
}
#Debug simulation 
Total elapsed time: 1.876879861112684. Arrivals time: 0.059873970691114664 Scheduler time: 1.4001048509962857 Scheduler overhead time: 0.10259665548801422 Adapter cache time: 0.1663780715316534 Engine time: 0.09874360403046012 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-32/adapters_384_slots_96_rate_0.025-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-32/adapters_384_slots_96_rate_0.025-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 270, 135, 66, 270, 270, 66, 135, 270, 270, 270, 270, 135, 135, 135, 135, 270, 270, 135, 135, 66, 270, 66, 270, 135, 135, 135, 66, 66, 135, 66, 270, 66, 270, 135, 270, 135, 66, 135, 270, 135, 270, 66, 270, 270, 270, 270, 66, 135, 135, 135, 270, 135, 66, 135, 66, 270, 135, 270, 270, 135, 270, 270, 66, 66, 270, 135, 135, 66, 66, 66, 135, 66, 135, 66, 270, 66, 135, 270, 66, 270, 135, 66, 270, 270, 270, 270, 135, 66, 135, 270, 270, 135, 66, 66, 270, 135, 135, 66, 66, 270, 135, 270, 135, 270, 270, 135, 270, 270, 66, 135, 135, 135, 135, 66, 66, 270, 66, 270, 66, 66, 66, 135, 135, 270, 66, 66, 270, 66, 270, 135, 66, 270, 135, 135, 66, 270, 270, 270, 66, 135, 270, 66, 270, 135, 135, 270, 270, 66, 135, 270, 66, 135, 135, 66, 135, 66, 135, 270, 270, 135, 66, 270, 66, 270, 135, 135, 135, 135, 135, 66, 66, 270, 66, 270, 66, 135, 270, 135, 270, 135, 270, 135, 270, 66, 135, 135, 135, 135, 135, 135, 135, 135, 270, 66, 66, 66, 66, 66, 135, 66, 66, 135, 270, 270, 66, 66, 270, 66, 66, 66, 135, 66, 135, 270, 270, 135, 135, 66, 270, 135, 270, 66, 135, 135, 66, 66, 135, 66, 270, 270, 66, 270, 270, 66, 135, 270, 66, 66, 135, 135, 66, 66, 270, 270, 270, 270, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 270, 135, 135, 135, 270, 66, 135, 135, 270, 270, 66, 270, 270, 66, 270, 66, 66, 135, 66, 270, 270, 270, 135, 66, 270, 270, 135, 135, 270, 270, 66, 270, 270, 135, 66, 270, 135, 135, 270, 270, 270, 66, 270, 66, 270, 270, 66, 66, 270, 66, 135, 270, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 270, 66, 66, 66, 135, 66, 135, 135, 66, 270, 135, 270, 66, 270, 66, 135, 135, 135, 135, 66, 135, 270, 270, 66, 270, 270, 66, 270, 135, 270, 135, 135, 135, 66, 135, 66, 66, 270, 66, 135, 66, 66, 135, 270, 135, 270, 66, 270, 270, 135, 270, 135, 66, 270, 66, 270, 270, 66, 66, 66]
Prompts retrieved: 60288 . Total input tokens: 13399771 . Total output tokens: 11859158
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 1.8782182759605348,
    "estimated_duration": 3599.966966982252,
    "input_throughput": 1375.3917870392534,
    "output_throughput": 1207.128854196907,
    "total_throughput": 2582.5206412361604,
    "itl": 32.68694474288828,
    "ttft": 8759.491525696827,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 13828,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 103.0294832721657,
    "arrivals": 20275,
    "finished_requests": 20226,
    "scheduler_time": 0.5682959910369206
}
#Debug simulation 
Total elapsed time: 1.8783093560487032. Arrivals time: 0.060165133792907 Scheduler time: 1.4001253177411854 Scheduler overhead time: 0.10303291585296392 Adapter cache time: 0.16659951489418745 Engine time: 0.09951422177255154 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-16/adapters_384_slots_96_rate_0.025-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-16/adapters_384_slots_96_rate_0.025-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 270, 135, 66, 270, 270, 66, 135, 270, 270, 270, 270, 135, 135, 135, 135, 270, 270, 135, 135, 66, 270, 66, 270, 135, 135, 135, 66, 66, 135, 66, 270, 66, 270, 135, 270, 135, 66, 135, 270, 135, 270, 66, 270, 270, 270, 270, 66, 135, 135, 135, 270, 135, 66, 135, 66, 270, 135, 270, 270, 135, 270, 270, 66, 66, 270, 135, 135, 66, 66, 66, 135, 66, 135, 66, 270, 66, 135, 270, 66, 270, 135, 66, 270, 270, 270, 270, 135, 66, 135, 270, 270, 135, 66, 66, 270, 135, 135, 66, 66, 270, 135, 270, 135, 270, 270, 135, 270, 270, 66, 135, 135, 135, 135, 66, 66, 270, 66, 270, 66, 66, 66, 135, 135, 270, 66, 66, 270, 66, 270, 135, 66, 270, 135, 135, 66, 270, 270, 270, 66, 135, 270, 66, 270, 135, 135, 270, 270, 66, 135, 270, 66, 135, 135, 66, 135, 66, 135, 270, 270, 135, 66, 270, 66, 270, 135, 135, 135, 135, 135, 66, 66, 270, 66, 270, 66, 135, 270, 135, 270, 135, 270, 135, 270, 66, 135, 135, 135, 135, 135, 135, 135, 135, 270, 66, 66, 66, 66, 66, 135, 66, 66, 135, 270, 270, 66, 66, 270, 66, 66, 66, 135, 66, 135, 270, 270, 135, 135, 66, 270, 135, 270, 66, 135, 135, 66, 66, 135, 66, 270, 270, 66, 270, 270, 66, 135, 270, 66, 66, 135, 135, 66, 66, 270, 270, 270, 270, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 270, 135, 135, 135, 270, 66, 135, 135, 270, 270, 66, 270, 270, 66, 270, 66, 66, 135, 66, 270, 270, 270, 135, 66, 270, 270, 135, 135, 270, 270, 66, 270, 270, 135, 66, 270, 135, 135, 270, 270, 270, 66, 270, 66, 270, 270, 66, 66, 270, 66, 135, 270, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 270, 66, 66, 66, 135, 66, 135, 135, 66, 270, 135, 270, 66, 270, 66, 135, 135, 135, 135, 66, 135, 270, 270, 66, 270, 270, 66, 270, 135, 270, 135, 135, 135, 66, 135, 66, 66, 270, 66, 135, 66, 66, 135, 270, 135, 270, 66, 270, 270, 135, 270, 135, 66, 270, 66, 270, 270, 66, 66, 66]
Prompts retrieved: 60288 . Total input tokens: 13399771 . Total output tokens: 11859158
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 1.870537699200213,
    "estimated_duration": 3599.9585907651294,
    "input_throughput": 1375.3949872372407,
    "output_throughput": 1207.1316628884856,
    "total_throughput": 2582.526650125726,
    "itl": 32.78706319837953,
    "ttft": 8758.864004121098,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 13842,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 88.36623365936089,
    "arrivals": 20275,
    "finished_requests": 20226,
    "scheduler_time": 0.5772404398863689
}
#Debug simulation 
Total elapsed time: 1.8706550770439208. Arrivals time: 0.06062957551330328 Scheduler time: 1.3939397283829749 Scheduler overhead time: 0.10139991249889135 Adapter cache time: 0.16426002653315663 Engine time: 0.10104663856327534 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-32/adapters_384_slots_96_rate_0.025-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-32/adapters_384_slots_96_rate_0.025-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 270, 135, 66, 270, 270, 66, 135, 270, 270, 270, 270, 135, 135, 135, 135, 270, 270, 135, 135, 66, 270, 66, 270, 135, 135, 135, 66, 66, 135, 66, 270, 66, 270, 135, 270, 135, 66, 135, 270, 135, 270, 66, 270, 270, 270, 270, 66, 135, 135, 135, 270, 135, 66, 135, 66, 270, 135, 270, 270, 135, 270, 270, 66, 66, 270, 135, 135, 66, 66, 66, 135, 66, 135, 66, 270, 66, 135, 270, 66, 270, 135, 66, 270, 270, 270, 270, 135, 66, 135, 270, 270, 135, 66, 66, 270, 135, 135, 66, 66, 270, 135, 270, 135, 270, 270, 135, 270, 270, 66, 135, 135, 135, 135, 66, 66, 270, 66, 270, 66, 66, 66, 135, 135, 270, 66, 66, 270, 66, 270, 135, 66, 270, 135, 135, 66, 270, 270, 270, 66, 135, 270, 66, 270, 135, 135, 270, 270, 66, 135, 270, 66, 135, 135, 66, 135, 66, 135, 270, 270, 135, 66, 270, 66, 270, 135, 135, 135, 135, 135, 66, 66, 270, 66, 270, 66, 135, 270, 135, 270, 135, 270, 135, 270, 66, 135, 135, 135, 135, 135, 135, 135, 135, 270, 66, 66, 66, 66, 66, 135, 66, 66, 135, 270, 270, 66, 66, 270, 66, 66, 66, 135, 66, 135, 270, 270, 135, 135, 66, 270, 135, 270, 66, 135, 135, 66, 66, 135, 66, 270, 270, 66, 270, 270, 66, 135, 270, 66, 66, 135, 135, 66, 66, 270, 270, 270, 270, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 270, 135, 135, 135, 270, 66, 135, 135, 270, 270, 66, 270, 270, 66, 270, 66, 66, 135, 66, 270, 270, 270, 135, 66, 270, 270, 135, 135, 270, 270, 66, 270, 270, 135, 66, 270, 135, 135, 270, 270, 270, 66, 270, 66, 270, 270, 66, 66, 270, 66, 135, 270, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 270, 66, 66, 66, 135, 66, 135, 135, 66, 270, 135, 270, 66, 270, 66, 135, 135, 135, 135, 66, 135, 270, 270, 66, 270, 270, 66, 270, 135, 270, 135, 135, 135, 66, 135, 66, 66, 270, 66, 135, 66, 66, 135, 270, 135, 270, 66, 270, 270, 135, 270, 135, 66, 270, 66, 270, 270, 66, 66, 66]
Prompts retrieved: 60288 . Total input tokens: 13399771 . Total output tokens: 11859158
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 1.8650371432304382,
    "estimated_duration": 3599.9580728656297,
    "input_throughput": 1375.395185105205,
    "output_throughput": 1207.1318365496427,
    "total_throughput": 2582.527021654848,
    "itl": 32.67179269407286,
    "ttft": 8759.283737638905,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 13827,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 102.03143896355513,
    "arrivals": 20275,
    "finished_requests": 20226,
    "scheduler_time": 0.5658156059855879
}
#Debug simulation 
Total elapsed time: 1.8651758949272335. Arrivals time: 0.059764301404356956 Scheduler time: 1.3885961486957967 Scheduler overhead time: 0.10379388323053718 Adapter cache time: 0.1655783518217504 Engine time: 0.0980357606895268 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-8/adapters_384_slots_96_rate_0.025-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-8/adapters_384_slots_96_rate_0.025-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 270, 135, 33, 270, 270, 33, 135, 270, 270, 270, 270, 135, 135, 135, 135, 270, 270, 135, 135, 33, 270, 33, 270, 135, 135, 135, 33, 33, 135, 33, 270, 33, 270, 135, 270, 135, 33, 135, 270, 135, 270, 33, 270, 270, 270, 270, 33, 135, 135, 135, 270, 135, 33, 135, 33, 270, 135, 270, 270, 135, 270, 270, 33, 33, 270, 135, 135, 33, 33, 33, 135, 33, 135, 33, 270, 33, 135, 270, 33, 270, 135, 33, 270, 270, 270, 270, 135, 33, 135, 270, 270, 135, 33, 33, 270, 135, 135, 33, 33, 270, 135, 270, 135, 270, 270, 135, 270, 270, 33, 135, 135, 135, 135, 33, 33, 270, 33, 270, 33, 33, 33, 135, 135, 270, 33, 33, 270, 33, 270, 135, 33, 270, 135, 135, 33, 270, 270, 270, 33, 135, 270, 33, 270, 135, 135, 270, 270, 33, 135, 270, 33, 135, 135, 33, 135, 33, 135, 270, 270, 135, 33, 270, 33, 270, 135, 135, 135, 135, 135, 33, 33, 270, 33, 270, 33, 135, 270, 135, 270, 135, 270, 135, 270, 33, 135, 135, 135, 135, 135, 135, 135, 135, 270, 33, 33, 33, 33, 33, 135, 33, 33, 135, 270, 270, 33, 33, 270, 33, 33, 33, 135, 33, 135, 270, 270, 135, 135, 33, 270, 135, 270, 33, 135, 135, 33, 33, 135, 33, 270, 270, 33, 270, 270, 33, 135, 270, 33, 33, 135, 135, 33, 33, 270, 270, 270, 270, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 270, 135, 135, 135, 270, 33, 135, 135, 270, 270, 33, 270, 270, 33, 270, 33, 33, 135, 33, 270, 270, 270, 135, 33, 270, 270, 135, 135, 270, 270, 33, 270, 270, 135, 33, 270, 135, 135, 270, 270, 270, 33, 270, 33, 270, 270, 33, 33, 270, 33, 135, 270, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 270, 33, 33, 33, 135, 33, 135, 135, 33, 270, 135, 270, 33, 270, 33, 135, 135, 135, 135, 33, 135, 270, 270, 33, 270, 270, 33, 270, 135, 270, 135, 135, 135, 33, 135, 33, 33, 270, 33, 135, 33, 33, 135, 270, 135, 270, 33, 270, 270, 135, 270, 135, 33, 270, 33, 270, 270, 33, 33, 33]
Prompts retrieved: 56064 . Total input tokens: 12455892 . Total output tokens: 11027359
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 1.7951821419410408,
    "estimated_duration": 3598.974783056722,
    "input_throughput": 1279.3279413003972,
    "output_throughput": 1144.8479770954432,
    "total_throughput": 2424.1759183958407,
    "itl": 31.182707744194452,
    "ttft": 11484.214715655115,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 12193,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 80.62510332655901,
    "arrivals": 18900,
    "finished_requests": 18840,
    "scheduler_time": 0.1853947102707607
}
#Debug simulation 
Total elapsed time: 1.795271307695657. Arrivals time: 0.05677772453054786 Scheduler time: 1.3242743578739464 Scheduler overhead time: 0.10645943786948919 Adapter cache time: 0.15302425902336836 Engine time: 0.1036446443758905 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-16/adapters_384_slots_96_rate_0.025-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-16/adapters_384_slots_96_rate_0.025-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 270, 135, 33, 270, 270, 33, 135, 270, 270, 270, 270, 135, 135, 135, 135, 270, 270, 135, 135, 33, 270, 33, 270, 135, 135, 135, 33, 33, 135, 33, 270, 33, 270, 135, 270, 135, 33, 135, 270, 135, 270, 33, 270, 270, 270, 270, 33, 135, 135, 135, 270, 135, 33, 135, 33, 270, 135, 270, 270, 135, 270, 270, 33, 33, 270, 135, 135, 33, 33, 33, 135, 33, 135, 33, 270, 33, 135, 270, 33, 270, 135, 33, 270, 270, 270, 270, 135, 33, 135, 270, 270, 135, 33, 33, 270, 135, 135, 33, 33, 270, 135, 270, 135, 270, 270, 135, 270, 270, 33, 135, 135, 135, 135, 33, 33, 270, 33, 270, 33, 33, 33, 135, 135, 270, 33, 33, 270, 33, 270, 135, 33, 270, 135, 135, 33, 270, 270, 270, 33, 135, 270, 33, 270, 135, 135, 270, 270, 33, 135, 270, 33, 135, 135, 33, 135, 33, 135, 270, 270, 135, 33, 270, 33, 270, 135, 135, 135, 135, 135, 33, 33, 270, 33, 270, 33, 135, 270, 135, 270, 135, 270, 135, 270, 33, 135, 135, 135, 135, 135, 135, 135, 135, 270, 33, 33, 33, 33, 33, 135, 33, 33, 135, 270, 270, 33, 33, 270, 33, 33, 33, 135, 33, 135, 270, 270, 135, 135, 33, 270, 135, 270, 33, 135, 135, 33, 33, 135, 33, 270, 270, 33, 270, 270, 33, 135, 270, 33, 33, 135, 135, 33, 33, 270, 270, 270, 270, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 270, 135, 135, 135, 270, 33, 135, 135, 270, 270, 33, 270, 270, 33, 270, 33, 33, 135, 33, 270, 270, 270, 135, 33, 270, 270, 135, 135, 270, 270, 33, 270, 270, 135, 33, 270, 135, 135, 270, 270, 270, 33, 270, 33, 270, 270, 33, 33, 270, 33, 135, 270, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 270, 33, 33, 33, 135, 33, 135, 135, 33, 270, 135, 270, 33, 270, 33, 135, 135, 135, 135, 33, 135, 270, 270, 33, 270, 270, 33, 270, 135, 270, 135, 135, 135, 33, 135, 33, 33, 270, 33, 135, 33, 33, 135, 270, 135, 270, 33, 270, 270, 135, 270, 135, 33, 270, 33, 270, 270, 33, 33, 33]
Prompts retrieved: 56064 . Total input tokens: 12455892 . Total output tokens: 11027359
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 1.811302192043513,
    "estimated_duration": 3598.9622939955325,
    "input_throughput": 1279.3321029458152,
    "output_throughput": 1144.7644246992254,
    "total_throughput": 2424.0965276450406,
    "itl": 31.306729643243248,
    "ttft": 11675.24867415635,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 12195,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 89.35471485513334,
    "arrivals": 18900,
    "finished_requests": 18839,
    "scheduler_time": 0.1950396616433677
}
#Debug simulation 
Total elapsed time: 1.8113964777439833. Arrivals time: 0.057456305250525475 Scheduler time: 1.3388653248548508 Scheduler overhead time: 0.10652284463867545 Adapter cache time: 0.15284391213208437 Engine time: 0.10479763569310308 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-32/adapters_384_slots_96_rate_0.025-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-32/adapters_384_slots_96_rate_0.025-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 270, 135, 33, 270, 270, 33, 135, 270, 270, 270, 270, 135, 135, 135, 135, 270, 270, 135, 135, 33, 270, 33, 270, 135, 135, 135, 33, 33, 135, 33, 270, 33, 270, 135, 270, 135, 33, 135, 270, 135, 270, 33, 270, 270, 270, 270, 33, 135, 135, 135, 270, 135, 33, 135, 33, 270, 135, 270, 270, 135, 270, 270, 33, 33, 270, 135, 135, 33, 33, 33, 135, 33, 135, 33, 270, 33, 135, 270, 33, 270, 135, 33, 270, 270, 270, 270, 135, 33, 135, 270, 270, 135, 33, 33, 270, 135, 135, 33, 33, 270, 135, 270, 135, 270, 270, 135, 270, 270, 33, 135, 135, 135, 135, 33, 33, 270, 33, 270, 33, 33, 33, 135, 135, 270, 33, 33, 270, 33, 270, 135, 33, 270, 135, 135, 33, 270, 270, 270, 33, 135, 270, 33, 270, 135, 135, 270, 270, 33, 135, 270, 33, 135, 135, 33, 135, 33, 135, 270, 270, 135, 33, 270, 33, 270, 135, 135, 135, 135, 135, 33, 33, 270, 33, 270, 33, 135, 270, 135, 270, 135, 270, 135, 270, 33, 135, 135, 135, 135, 135, 135, 135, 135, 270, 33, 33, 33, 33, 33, 135, 33, 33, 135, 270, 270, 33, 33, 270, 33, 33, 33, 135, 33, 135, 270, 270, 135, 135, 33, 270, 135, 270, 33, 135, 135, 33, 33, 135, 33, 270, 270, 33, 270, 270, 33, 135, 270, 33, 33, 135, 135, 33, 33, 270, 270, 270, 270, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 270, 135, 135, 135, 270, 33, 135, 135, 270, 270, 33, 270, 270, 33, 270, 33, 33, 135, 33, 270, 270, 270, 135, 33, 270, 270, 135, 135, 270, 270, 33, 270, 270, 135, 33, 270, 135, 135, 270, 270, 270, 33, 270, 33, 270, 270, 33, 33, 270, 33, 135, 270, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 270, 33, 33, 33, 135, 33, 135, 135, 33, 270, 135, 270, 33, 270, 33, 135, 135, 135, 135, 33, 135, 270, 270, 33, 270, 270, 33, 270, 135, 270, 135, 135, 135, 33, 135, 33, 33, 270, 33, 135, 33, 33, 135, 270, 135, 270, 33, 270, 270, 135, 270, 135, 33, 270, 33, 270, 270, 33, 33, 33]
Prompts retrieved: 56064 . Total input tokens: 12455892 . Total output tokens: 11027359
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 1.8011593958362937,
    "estimated_duration": 3598.9621937678435,
    "input_throughput": 1279.3321385740028,
    "output_throughput": 1144.7644565798305,
    "total_throughput": 2424.0965951538333,
    "itl": 31.341568362637634,
    "ttft": 11675.4828834986,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 12189,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 91.76295176794515,
    "arrivals": 18900,
    "finished_requests": 18839,
    "scheduler_time": 0.19751537675868855
}
#Debug simulation 
Total elapsed time: 1.8012783247977495. Arrivals time: 0.05714080668985844 Scheduler time: 1.3320249626412988 Scheduler overhead time: 0.10731044877320528 Adapter cache time: 0.1524020596407354 Engine time: 0.10159415891394019 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-16/adapters_384_slots_96_rate_0.025-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-16/adapters_384_slots_96_rate_0.025-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 270, 135, 33, 270, 270, 33, 135, 270, 270, 270, 270, 135, 135, 135, 135, 270, 270, 135, 135, 33, 270, 33, 270, 135, 135, 135, 33, 33, 135, 33, 270, 33, 270, 135, 270, 135, 33, 135, 270, 135, 270, 33, 270, 270, 270, 270, 33, 135, 135, 135, 270, 135, 33, 135, 33, 270, 135, 270, 270, 135, 270, 270, 33, 33, 270, 135, 135, 33, 33, 33, 135, 33, 135, 33, 270, 33, 135, 270, 33, 270, 135, 33, 270, 270, 270, 270, 135, 33, 135, 270, 270, 135, 33, 33, 270, 135, 135, 33, 33, 270, 135, 270, 135, 270, 270, 135, 270, 270, 33, 135, 135, 135, 135, 33, 33, 270, 33, 270, 33, 33, 33, 135, 135, 270, 33, 33, 270, 33, 270, 135, 33, 270, 135, 135, 33, 270, 270, 270, 33, 135, 270, 33, 270, 135, 135, 270, 270, 33, 135, 270, 33, 135, 135, 33, 135, 33, 135, 270, 270, 135, 33, 270, 33, 270, 135, 135, 135, 135, 135, 33, 33, 270, 33, 270, 33, 135, 270, 135, 270, 135, 270, 135, 270, 33, 135, 135, 135, 135, 135, 135, 135, 135, 270, 33, 33, 33, 33, 33, 135, 33, 33, 135, 270, 270, 33, 33, 270, 33, 33, 33, 135, 33, 135, 270, 270, 135, 135, 33, 270, 135, 270, 33, 135, 135, 33, 33, 135, 33, 270, 270, 33, 270, 270, 33, 135, 270, 33, 33, 135, 135, 33, 33, 270, 270, 270, 270, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 270, 135, 135, 135, 270, 33, 135, 135, 270, 270, 33, 270, 270, 33, 270, 33, 33, 135, 33, 270, 270, 270, 135, 33, 270, 270, 135, 135, 270, 270, 33, 270, 270, 135, 33, 270, 135, 135, 270, 270, 270, 33, 270, 33, 270, 270, 33, 33, 270, 33, 135, 270, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 270, 33, 33, 33, 135, 33, 135, 135, 33, 270, 135, 270, 33, 270, 33, 135, 135, 135, 135, 33, 135, 270, 270, 33, 270, 270, 33, 270, 135, 270, 135, 135, 135, 33, 135, 33, 33, 270, 33, 135, 33, 33, 135, 270, 135, 270, 33, 270, 270, 135, 270, 135, 33, 270, 33, 270, 270, 33, 33, 33]
Prompts retrieved: 56064 . Total input tokens: 12455892 . Total output tokens: 11027359
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 1.8007528390735388,
    "estimated_duration": 3598.9854580056813,
    "input_throughput": 1279.324146686433,
    "output_throughput": 1144.8445813624335,
    "total_throughput": 2424.168728048867,
    "itl": 31.223269719869297,
    "ttft": 11484.389299653534,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 12194,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 83.80516458774581,
    "arrivals": 18900,
    "finished_requests": 18840,
    "scheduler_time": 0.1888452659920408
}
#Debug simulation 
Total elapsed time: 1.8008463773876429. Arrivals time: 0.05694537842646241 Scheduler time: 1.3299982682801783 Scheduler overhead time: 0.10581301525235176 Adapter cache time: 0.1531340666115284 Engine time: 0.10427269991487265 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-32/adapters_384_slots_96_rate_0.025-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-32/adapters_384_slots_96_rate_0.025-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 270, 135, 33, 270, 270, 33, 135, 270, 270, 270, 270, 135, 135, 135, 135, 270, 270, 135, 135, 33, 270, 33, 270, 135, 135, 135, 33, 33, 135, 33, 270, 33, 270, 135, 270, 135, 33, 135, 270, 135, 270, 33, 270, 270, 270, 270, 33, 135, 135, 135, 270, 135, 33, 135, 33, 270, 135, 270, 270, 135, 270, 270, 33, 33, 270, 135, 135, 33, 33, 33, 135, 33, 135, 33, 270, 33, 135, 270, 33, 270, 135, 33, 270, 270, 270, 270, 135, 33, 135, 270, 270, 135, 33, 33, 270, 135, 135, 33, 33, 270, 135, 270, 135, 270, 270, 135, 270, 270, 33, 135, 135, 135, 135, 33, 33, 270, 33, 270, 33, 33, 33, 135, 135, 270, 33, 33, 270, 33, 270, 135, 33, 270, 135, 135, 33, 270, 270, 270, 33, 135, 270, 33, 270, 135, 135, 270, 270, 33, 135, 270, 33, 135, 135, 33, 135, 33, 135, 270, 270, 135, 33, 270, 33, 270, 135, 135, 135, 135, 135, 33, 33, 270, 33, 270, 33, 135, 270, 135, 270, 135, 270, 135, 270, 33, 135, 135, 135, 135, 135, 135, 135, 135, 270, 33, 33, 33, 33, 33, 135, 33, 33, 135, 270, 270, 33, 33, 270, 33, 33, 33, 135, 33, 135, 270, 270, 135, 135, 33, 270, 135, 270, 33, 135, 135, 33, 33, 135, 33, 270, 270, 33, 270, 270, 33, 135, 270, 33, 33, 135, 135, 33, 33, 270, 270, 270, 270, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 270, 135, 135, 135, 270, 33, 135, 135, 270, 270, 33, 270, 270, 33, 270, 33, 33, 135, 33, 270, 270, 270, 135, 33, 270, 270, 135, 135, 270, 270, 33, 270, 270, 135, 33, 270, 135, 135, 270, 270, 270, 33, 270, 33, 270, 270, 33, 33, 270, 33, 135, 270, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 270, 33, 33, 33, 135, 33, 135, 135, 33, 270, 135, 270, 33, 270, 33, 135, 135, 135, 135, 33, 135, 270, 270, 33, 270, 270, 33, 270, 135, 270, 135, 135, 135, 33, 135, 33, 33, 270, 33, 135, 33, 33, 135, 270, 135, 270, 33, 270, 270, 135, 270, 135, 33, 270, 33, 270, 270, 33, 33, 33]
Prompts retrieved: 56064 . Total input tokens: 12455892 . Total output tokens: 11027359
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 1.783430378884077,
    "estimated_duration": 3598.952865037246,
    "input_throughput": 1279.3354546899159,
    "output_throughput": 1144.7674238871596,
    "total_throughput": 2424.1028785770754,
    "itl": 31.334105123636796,
    "ttft": 11675.49380176074,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 12191,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 90.95249926282291,
    "arrivals": 18900,
    "finished_requests": 18839,
    "scheduler_time": 0.19667088725004442
}
#Debug simulation 
Total elapsed time: 1.7835186128504574. Arrivals time: 0.056319238152354956 Scheduler time: 1.316902567166835 Scheduler overhead time: 0.10490792896598577 Adapter cache time: 0.15213945973664522 Engine time: 0.10253275092691183 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-16/adapters_384_slots_96_rate_0.025-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-16/adapters_384_slots_96_rate_0.025-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 270, 135, 33, 270, 270, 33, 135, 270, 270, 270, 270, 135, 135, 135, 135, 270, 270, 135, 135, 33, 270, 33, 270, 135, 135, 135, 33, 33, 135, 33, 270, 33, 270, 135, 270, 135, 33, 135, 270, 135, 270, 33, 270, 270, 270, 270, 33, 135, 135, 135, 270, 135, 33, 135, 33, 270, 135, 270, 270, 135, 270, 270, 33, 33, 270, 135, 135, 33, 33, 33, 135, 33, 135, 33, 270, 33, 135, 270, 33, 270, 135, 33, 270, 270, 270, 270, 135, 33, 135, 270, 270, 135, 33, 33, 270, 135, 135, 33, 33, 270, 135, 270, 135, 270, 270, 135, 270, 270, 33, 135, 135, 135, 135, 33, 33, 270, 33, 270, 33, 33, 33, 135, 135, 270, 33, 33, 270, 33, 270, 135, 33, 270, 135, 135, 33, 270, 270, 270, 33, 135, 270, 33, 270, 135, 135, 270, 270, 33, 135, 270, 33, 135, 135, 33, 135, 33, 135, 270, 270, 135, 33, 270, 33, 270, 135, 135, 135, 135, 135, 33, 33, 270, 33, 270, 33, 135, 270, 135, 270, 135, 270, 135, 270, 33, 135, 135, 135, 135, 135, 135, 135, 135, 270, 33, 33, 33, 33, 33, 135, 33, 33, 135, 270, 270, 33, 33, 270, 33, 33, 33, 135, 33, 135, 270, 270, 135, 135, 33, 270, 135, 270, 33, 135, 135, 33, 33, 135, 33, 270, 270, 33, 270, 270, 33, 135, 270, 33, 33, 135, 135, 33, 33, 270, 270, 270, 270, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 270, 135, 135, 135, 270, 33, 135, 135, 270, 270, 33, 270, 270, 33, 270, 33, 33, 135, 33, 270, 270, 270, 135, 33, 270, 270, 135, 135, 270, 270, 33, 270, 270, 135, 33, 270, 135, 135, 270, 270, 270, 33, 270, 33, 270, 270, 33, 33, 270, 33, 135, 270, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 270, 33, 33, 33, 135, 33, 135, 135, 33, 270, 135, 270, 33, 270, 33, 135, 135, 135, 135, 33, 135, 270, 270, 33, 270, 270, 33, 270, 135, 270, 135, 135, 135, 33, 135, 33, 33, 270, 33, 135, 33, 33, 135, 270, 135, 270, 33, 270, 270, 135, 270, 135, 33, 270, 33, 270, 270, 33, 33, 33]
Prompts retrieved: 56064 . Total input tokens: 12455892 . Total output tokens: 11027359
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 1.801214796025306,
    "estimated_duration": 3598.9700076785834,
    "input_throughput": 1279.3296388068143,
    "output_throughput": 1144.8494961639517,
    "total_throughput": 2424.179134970766,
    "itl": 31.137400172746702,
    "ttft": 11484.078022792664,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 12196,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 77.85829979119208,
    "arrivals": 18900,
    "finished_requests": 18840,
    "scheduler_time": 0.1824643086828013
}
#Debug simulation 
Total elapsed time: 1.801309635862708. Arrivals time: 0.0578783736564219 Scheduler time: 1.3288819128647447 Scheduler overhead time: 0.10767568927258253 Adapter cache time: 0.15200363751500845 Engine time: 0.10351993283256888 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-32/adapters_384_slots_96_rate_0.025-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-32/adapters_384_slots_96_rate_0.025-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 270, 135, 33, 270, 270, 33, 135, 270, 270, 270, 270, 135, 135, 135, 135, 270, 270, 135, 135, 33, 270, 33, 270, 135, 135, 135, 33, 33, 135, 33, 270, 33, 270, 135, 270, 135, 33, 135, 270, 135, 270, 33, 270, 270, 270, 270, 33, 135, 135, 135, 270, 135, 33, 135, 33, 270, 135, 270, 270, 135, 270, 270, 33, 33, 270, 135, 135, 33, 33, 33, 135, 33, 135, 33, 270, 33, 135, 270, 33, 270, 135, 33, 270, 270, 270, 270, 135, 33, 135, 270, 270, 135, 33, 33, 270, 135, 135, 33, 33, 270, 135, 270, 135, 270, 270, 135, 270, 270, 33, 135, 135, 135, 135, 33, 33, 270, 33, 270, 33, 33, 33, 135, 135, 270, 33, 33, 270, 33, 270, 135, 33, 270, 135, 135, 33, 270, 270, 270, 33, 135, 270, 33, 270, 135, 135, 270, 270, 33, 135, 270, 33, 135, 135, 33, 135, 33, 135, 270, 270, 135, 33, 270, 33, 270, 135, 135, 135, 135, 135, 33, 33, 270, 33, 270, 33, 135, 270, 135, 270, 135, 270, 135, 270, 33, 135, 135, 135, 135, 135, 135, 135, 135, 270, 33, 33, 33, 33, 33, 135, 33, 33, 135, 270, 270, 33, 33, 270, 33, 33, 33, 135, 33, 135, 270, 270, 135, 135, 33, 270, 135, 270, 33, 135, 135, 33, 33, 135, 33, 270, 270, 33, 270, 270, 33, 135, 270, 33, 33, 135, 135, 33, 33, 270, 270, 270, 270, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 270, 135, 135, 135, 270, 33, 135, 135, 270, 270, 33, 270, 270, 33, 270, 33, 33, 135, 33, 270, 270, 270, 135, 33, 270, 270, 135, 135, 270, 270, 33, 270, 270, 135, 33, 270, 135, 135, 270, 270, 270, 33, 270, 33, 270, 270, 33, 33, 270, 33, 135, 270, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 270, 33, 33, 33, 135, 33, 135, 135, 33, 270, 135, 270, 33, 270, 33, 135, 135, 135, 135, 33, 135, 270, 270, 33, 270, 270, 33, 270, 135, 270, 135, 135, 135, 33, 135, 33, 33, 270, 33, 135, 33, 33, 135, 270, 135, 270, 33, 270, 270, 135, 270, 135, 33, 270, 33, 270, 270, 33, 33, 33]
Prompts retrieved: 56064 . Total input tokens: 12455892 . Total output tokens: 11027359
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 1.7786486470140517,
    "estimated_duration": 3598.974906143477,
    "input_throughput": 1279.32761968984,
    "output_throughput": 1144.7604130184934,
    "total_throughput": 2424.0880327083337,
    "itl": 31.322617124815398,
    "ttft": 11675.472675961766,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 12193,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 90.07758144679183,
    "arrivals": 18900,
    "finished_requests": 18839,
    "scheduler_time": 0.19564296365153339
}
#Debug simulation 
Total elapsed time: 1.778737063985318. Arrivals time: 0.056443731766194105 Scheduler time: 1.3110931990668178 Scheduler overhead time: 0.10724055347964168 Adapter cache time: 0.15194061491638422 Engine time: 0.10148965287953615 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-8/adapters_384_slots_96_rate_0.025-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-8/adapters_384_slots_96_rate_0.025-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 270, 66, 33, 270, 270, 33, 66, 270, 270, 270, 270, 66, 66, 66, 66, 270, 270, 66, 66, 33, 270, 33, 270, 66, 66, 66, 33, 33, 66, 33, 270, 33, 270, 66, 270, 66, 33, 66, 270, 66, 270, 33, 270, 270, 270, 270, 33, 66, 66, 66, 270, 66, 33, 66, 33, 270, 66, 270, 270, 66, 270, 270, 33, 33, 270, 66, 66, 33, 33, 33, 66, 33, 66, 33, 270, 33, 66, 270, 33, 270, 66, 33, 270, 270, 270, 270, 66, 33, 66, 270, 270, 66, 33, 33, 270, 66, 66, 33, 33, 270, 66, 270, 66, 270, 270, 66, 270, 270, 33, 66, 66, 66, 66, 33, 33, 270, 33, 270, 33, 33, 33, 66, 66, 270, 33, 33, 270, 33, 270, 66, 33, 270, 66, 66, 33, 270, 270, 270, 33, 66, 270, 33, 270, 66, 66, 270, 270, 33, 66, 270, 33, 66, 66, 33, 66, 33, 66, 270, 270, 66, 33, 270, 33, 270, 66, 66, 66, 66, 66, 33, 33, 270, 33, 270, 33, 66, 270, 66, 270, 66, 270, 66, 270, 33, 66, 66, 66, 66, 66, 66, 66, 66, 270, 33, 33, 33, 33, 33, 66, 33, 33, 66, 270, 270, 33, 33, 270, 33, 33, 33, 66, 33, 66, 270, 270, 66, 66, 33, 270, 66, 270, 33, 66, 66, 33, 33, 66, 33, 270, 270, 33, 270, 270, 33, 66, 270, 33, 33, 66, 66, 33, 33, 270, 270, 270, 270, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 270, 66, 66, 66, 270, 33, 66, 66, 270, 270, 33, 270, 270, 33, 270, 33, 33, 66, 33, 270, 270, 270, 66, 33, 270, 270, 66, 66, 270, 270, 33, 270, 270, 66, 33, 270, 66, 66, 270, 270, 270, 33, 270, 33, 270, 270, 33, 33, 270, 33, 66, 270, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 270, 33, 33, 33, 66, 33, 66, 66, 33, 270, 66, 270, 33, 270, 33, 66, 66, 66, 66, 33, 66, 270, 270, 33, 270, 270, 33, 270, 66, 270, 66, 66, 66, 33, 66, 33, 33, 270, 33, 66, 33, 33, 66, 270, 66, 270, 33, 270, 270, 66, 270, 66, 33, 270, 33, 270, 270, 33, 33, 33]
Prompts retrieved: 47232 . Total input tokens: 10461289 . Total output tokens: 9308734
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 1.5921709518879652,
    "estimated_duration": 3599.961624473456,
    "input_throughput": 1090.9505182779367,
    "output_throughput": 973.0856507428388,
    "total_throughput": 2064.0361690207756,
    "itl": 28.2296850395676,
    "ttft": 5862.624551246606,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9477,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 62.66580039579545,
    "arrivals": 16104,
    "finished_requests": 16078,
    "scheduler_time": 0.0017767564062769617
}
#Debug simulation 
Total elapsed time: 1.5922616571187973. Arrivals time: 0.05030960449948907 Scheduler time: 1.1300418358296156 Scheduler overhead time: 0.11643836414441466 Adapter cache time: 0.1290257442742586 Engine time: 0.11117598135024309 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-16/adapters_384_slots_96_rate_0.025-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-16/adapters_384_slots_96_rate_0.025-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 270, 66, 33, 270, 270, 33, 66, 270, 270, 270, 270, 66, 66, 66, 66, 270, 270, 66, 66, 33, 270, 33, 270, 66, 66, 66, 33, 33, 66, 33, 270, 33, 270, 66, 270, 66, 33, 66, 270, 66, 270, 33, 270, 270, 270, 270, 33, 66, 66, 66, 270, 66, 33, 66, 33, 270, 66, 270, 270, 66, 270, 270, 33, 33, 270, 66, 66, 33, 33, 33, 66, 33, 66, 33, 270, 33, 66, 270, 33, 270, 66, 33, 270, 270, 270, 270, 66, 33, 66, 270, 270, 66, 33, 33, 270, 66, 66, 33, 33, 270, 66, 270, 66, 270, 270, 66, 270, 270, 33, 66, 66, 66, 66, 33, 33, 270, 33, 270, 33, 33, 33, 66, 66, 270, 33, 33, 270, 33, 270, 66, 33, 270, 66, 66, 33, 270, 270, 270, 33, 66, 270, 33, 270, 66, 66, 270, 270, 33, 66, 270, 33, 66, 66, 33, 66, 33, 66, 270, 270, 66, 33, 270, 33, 270, 66, 66, 66, 66, 66, 33, 33, 270, 33, 270, 33, 66, 270, 66, 270, 66, 270, 66, 270, 33, 66, 66, 66, 66, 66, 66, 66, 66, 270, 33, 33, 33, 33, 33, 66, 33, 33, 66, 270, 270, 33, 33, 270, 33, 33, 33, 66, 33, 66, 270, 270, 66, 66, 33, 270, 66, 270, 33, 66, 66, 33, 33, 66, 33, 270, 270, 33, 270, 270, 33, 66, 270, 33, 33, 66, 66, 33, 33, 270, 270, 270, 270, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 270, 66, 66, 66, 270, 33, 66, 66, 270, 270, 33, 270, 270, 33, 270, 33, 33, 66, 33, 270, 270, 270, 66, 33, 270, 270, 66, 66, 270, 270, 33, 270, 270, 66, 33, 270, 66, 66, 270, 270, 270, 33, 270, 33, 270, 270, 33, 33, 270, 33, 66, 270, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 270, 33, 33, 33, 66, 33, 66, 66, 33, 270, 66, 270, 33, 270, 33, 66, 66, 66, 66, 33, 66, 270, 270, 33, 270, 270, 33, 270, 66, 270, 66, 66, 66, 33, 66, 33, 33, 270, 33, 66, 33, 33, 66, 270, 66, 270, 33, 270, 270, 66, 270, 66, 33, 270, 33, 270, 270, 33, 33, 33]
Prompts retrieved: 47232 . Total input tokens: 10461289 . Total output tokens: 9308734
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 1.605154240038246,
    "estimated_duration": 3599.93951671166,
    "input_throughput": 1090.9572179666613,
    "output_throughput": 973.0916266059537,
    "total_throughput": 2064.048844572615,
    "itl": 28.615643794709097,
    "ttft": 5863.6195502342,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9517,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 69.76810615015619,
    "arrivals": 16104,
    "finished_requests": 16078,
    "scheduler_time": 0.0024681688193734087
}
#Debug simulation 
Total elapsed time: 1.6052710497751832. Arrivals time: 0.05037829652428627 Scheduler time: 1.1463464708067477 Scheduler overhead time: 0.11247319867834449 Adapter cache time: 0.12997195171192288 Engine time: 0.11133484169840813 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-32/adapters_384_slots_96_rate_0.025-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-32/adapters_384_slots_96_rate_0.025-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 270, 66, 33, 270, 270, 33, 66, 270, 270, 270, 270, 66, 66, 66, 66, 270, 270, 66, 66, 33, 270, 33, 270, 66, 66, 66, 33, 33, 66, 33, 270, 33, 270, 66, 270, 66, 33, 66, 270, 66, 270, 33, 270, 270, 270, 270, 33, 66, 66, 66, 270, 66, 33, 66, 33, 270, 66, 270, 270, 66, 270, 270, 33, 33, 270, 66, 66, 33, 33, 33, 66, 33, 66, 33, 270, 33, 66, 270, 33, 270, 66, 33, 270, 270, 270, 270, 66, 33, 66, 270, 270, 66, 33, 33, 270, 66, 66, 33, 33, 270, 66, 270, 66, 270, 270, 66, 270, 270, 33, 66, 66, 66, 66, 33, 33, 270, 33, 270, 33, 33, 33, 66, 66, 270, 33, 33, 270, 33, 270, 66, 33, 270, 66, 66, 33, 270, 270, 270, 33, 66, 270, 33, 270, 66, 66, 270, 270, 33, 66, 270, 33, 66, 66, 33, 66, 33, 66, 270, 270, 66, 33, 270, 33, 270, 66, 66, 66, 66, 66, 33, 33, 270, 33, 270, 33, 66, 270, 66, 270, 66, 270, 66, 270, 33, 66, 66, 66, 66, 66, 66, 66, 66, 270, 33, 33, 33, 33, 33, 66, 33, 33, 66, 270, 270, 33, 33, 270, 33, 33, 33, 66, 33, 66, 270, 270, 66, 66, 33, 270, 66, 270, 33, 66, 66, 33, 33, 66, 33, 270, 270, 33, 270, 270, 33, 66, 270, 33, 33, 66, 66, 33, 33, 270, 270, 270, 270, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 270, 66, 66, 66, 270, 33, 66, 66, 270, 270, 33, 270, 270, 33, 270, 33, 33, 66, 33, 270, 270, 270, 66, 33, 270, 270, 66, 66, 270, 270, 33, 270, 270, 66, 33, 270, 66, 66, 270, 270, 270, 33, 270, 33, 270, 270, 33, 33, 270, 33, 66, 270, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 270, 33, 33, 33, 66, 33, 66, 66, 33, 270, 66, 270, 33, 270, 33, 66, 66, 66, 66, 33, 66, 270, 270, 33, 270, 270, 33, 270, 66, 270, 66, 66, 66, 33, 66, 33, 33, 270, 33, 66, 33, 33, 66, 270, 66, 270, 33, 270, 270, 66, 270, 66, 33, 270, 33, 270, 270, 33, 33, 33]
Prompts retrieved: 47232 . Total input tokens: 10461289 . Total output tokens: 9308734
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 1.596465030219406,
    "estimated_duration": 3599.951347485426,
    "input_throughput": 1090.953632677087,
    "output_throughput": 973.088428666377,
    "total_throughput": 2064.042061343464,
    "itl": 28.637088656151438,
    "ttft": 5863.76978280245,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9516,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 71.68106607376411,
    "arrivals": 16104,
    "finished_requests": 16078,
    "scheduler_time": 0.002512786829831034
}
#Debug simulation 
Total elapsed time: 1.5965568562969565. Arrivals time: 0.05024651810526848 Scheduler time: 1.1405565785244107 Scheduler overhead time: 0.11290750373154879 Adapter cache time: 0.13040699623525143 Engine time: 0.10839558858424425 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-16/adapters_384_slots_96_rate_0.025-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-16/adapters_384_slots_96_rate_0.025-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 270, 66, 33, 270, 270, 33, 66, 270, 270, 270, 270, 66, 66, 66, 66, 270, 270, 66, 66, 33, 270, 33, 270, 66, 66, 66, 33, 33, 66, 33, 270, 33, 270, 66, 270, 66, 33, 66, 270, 66, 270, 33, 270, 270, 270, 270, 33, 66, 66, 66, 270, 66, 33, 66, 33, 270, 66, 270, 270, 66, 270, 270, 33, 33, 270, 66, 66, 33, 33, 33, 66, 33, 66, 33, 270, 33, 66, 270, 33, 270, 66, 33, 270, 270, 270, 270, 66, 33, 66, 270, 270, 66, 33, 33, 270, 66, 66, 33, 33, 270, 66, 270, 66, 270, 270, 66, 270, 270, 33, 66, 66, 66, 66, 33, 33, 270, 33, 270, 33, 33, 33, 66, 66, 270, 33, 33, 270, 33, 270, 66, 33, 270, 66, 66, 33, 270, 270, 270, 33, 66, 270, 33, 270, 66, 66, 270, 270, 33, 66, 270, 33, 66, 66, 33, 66, 33, 66, 270, 270, 66, 33, 270, 33, 270, 66, 66, 66, 66, 66, 33, 33, 270, 33, 270, 33, 66, 270, 66, 270, 66, 270, 66, 270, 33, 66, 66, 66, 66, 66, 66, 66, 66, 270, 33, 33, 33, 33, 33, 66, 33, 33, 66, 270, 270, 33, 33, 270, 33, 33, 33, 66, 33, 66, 270, 270, 66, 66, 33, 270, 66, 270, 33, 66, 66, 33, 33, 66, 33, 270, 270, 33, 270, 270, 33, 66, 270, 33, 33, 66, 66, 33, 33, 270, 270, 270, 270, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 270, 66, 66, 66, 270, 33, 66, 66, 270, 270, 33, 270, 270, 33, 270, 33, 33, 66, 33, 270, 270, 270, 66, 33, 270, 270, 66, 66, 270, 270, 33, 270, 270, 66, 33, 270, 66, 66, 270, 270, 270, 33, 270, 33, 270, 270, 33, 33, 270, 33, 66, 270, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 270, 33, 33, 33, 66, 33, 66, 66, 33, 270, 66, 270, 33, 270, 33, 66, 66, 66, 66, 33, 66, 270, 270, 33, 270, 270, 33, 270, 66, 270, 66, 66, 66, 33, 66, 33, 33, 270, 33, 66, 33, 33, 66, 270, 66, 270, 33, 270, 270, 66, 270, 66, 33, 270, 33, 270, 270, 33, 33, 33]
Prompts retrieved: 47232 . Total input tokens: 10461289 . Total output tokens: 9308734
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 1.6044759363867342,
    "estimated_duration": 3599.9383610171903,
    "input_throughput": 1090.9575681985534,
    "output_throughput": 973.09193899925,
    "total_throughput": 2064.0495071978035,
    "itl": 28.260447472298928,
    "ttft": 5862.935663808618,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9475,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 65.20204933727786,
    "arrivals": 16104,
    "finished_requests": 16078,
    "scheduler_time": 0.001827921182802915
}
#Debug simulation 
Total elapsed time: 1.6046111569739878. Arrivals time: 0.05060583958402276 Scheduler time: 1.1437724716961384 Scheduler overhead time: 0.11277828831225634 Adapter cache time: 0.13034536130726337 Engine time: 0.11209369404241443 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-32/adapters_384_slots_96_rate_0.025-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-32/adapters_384_slots_96_rate_0.025-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 270, 66, 33, 270, 270, 33, 66, 270, 270, 270, 270, 66, 66, 66, 66, 270, 270, 66, 66, 33, 270, 33, 270, 66, 66, 66, 33, 33, 66, 33, 270, 33, 270, 66, 270, 66, 33, 66, 270, 66, 270, 33, 270, 270, 270, 270, 33, 66, 66, 66, 270, 66, 33, 66, 33, 270, 66, 270, 270, 66, 270, 270, 33, 33, 270, 66, 66, 33, 33, 33, 66, 33, 66, 33, 270, 33, 66, 270, 33, 270, 66, 33, 270, 270, 270, 270, 66, 33, 66, 270, 270, 66, 33, 33, 270, 66, 66, 33, 33, 270, 66, 270, 66, 270, 270, 66, 270, 270, 33, 66, 66, 66, 66, 33, 33, 270, 33, 270, 33, 33, 33, 66, 66, 270, 33, 33, 270, 33, 270, 66, 33, 270, 66, 66, 33, 270, 270, 270, 33, 66, 270, 33, 270, 66, 66, 270, 270, 33, 66, 270, 33, 66, 66, 33, 66, 33, 66, 270, 270, 66, 33, 270, 33, 270, 66, 66, 66, 66, 66, 33, 33, 270, 33, 270, 33, 66, 270, 66, 270, 66, 270, 66, 270, 33, 66, 66, 66, 66, 66, 66, 66, 66, 270, 33, 33, 33, 33, 33, 66, 33, 33, 66, 270, 270, 33, 33, 270, 33, 33, 33, 66, 33, 66, 270, 270, 66, 66, 33, 270, 66, 270, 33, 66, 66, 33, 33, 66, 33, 270, 270, 33, 270, 270, 33, 66, 270, 33, 33, 66, 66, 33, 33, 270, 270, 270, 270, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 270, 66, 66, 66, 270, 33, 66, 66, 270, 270, 33, 270, 270, 33, 270, 33, 33, 66, 33, 270, 270, 270, 66, 33, 270, 270, 66, 66, 270, 270, 33, 270, 270, 66, 33, 270, 66, 66, 270, 270, 270, 33, 270, 33, 270, 270, 33, 33, 270, 33, 66, 270, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 270, 33, 33, 33, 66, 33, 66, 66, 33, 270, 66, 270, 33, 270, 33, 66, 66, 66, 66, 33, 66, 270, 270, 33, 270, 270, 33, 270, 66, 270, 66, 66, 66, 33, 66, 33, 33, 270, 33, 66, 33, 33, 66, 270, 66, 270, 33, 270, 270, 66, 270, 66, 33, 270, 33, 270, 270, 33, 33, 33]
Prompts retrieved: 47232 . Total input tokens: 10461289 . Total output tokens: 9308734
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 1.6042764610610902,
    "estimated_duration": 3599.9559409639783,
    "input_throughput": 1090.952240640019,
    "output_throughput": 973.0871870231737,
    "total_throughput": 2064.039427663193,
    "itl": 28.628888622493523,
    "ttft": 5863.709050495811,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9520,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 71.07146236794784,
    "arrivals": 16104,
    "finished_requests": 16078,
    "scheduler_time": 0.002516831637872283
}
#Debug simulation 
Total elapsed time: 1.6043648468330503. Arrivals time: 0.05024586571380496 Scheduler time: 1.1438823230564594 Scheduler overhead time: 0.11270049959421158 Adapter cache time: 0.13125017751008272 Engine time: 0.11154562793672085 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-16/adapters_384_slots_96_rate_0.025-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-16/adapters_384_slots_96_rate_0.025-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 270, 66, 33, 270, 270, 33, 66, 270, 270, 270, 270, 66, 66, 66, 66, 270, 270, 66, 66, 33, 270, 33, 270, 66, 66, 66, 33, 33, 66, 33, 270, 33, 270, 66, 270, 66, 33, 66, 270, 66, 270, 33, 270, 270, 270, 270, 33, 66, 66, 66, 270, 66, 33, 66, 33, 270, 66, 270, 270, 66, 270, 270, 33, 33, 270, 66, 66, 33, 33, 33, 66, 33, 66, 33, 270, 33, 66, 270, 33, 270, 66, 33, 270, 270, 270, 270, 66, 33, 66, 270, 270, 66, 33, 33, 270, 66, 66, 33, 33, 270, 66, 270, 66, 270, 270, 66, 270, 270, 33, 66, 66, 66, 66, 33, 33, 270, 33, 270, 33, 33, 33, 66, 66, 270, 33, 33, 270, 33, 270, 66, 33, 270, 66, 66, 33, 270, 270, 270, 33, 66, 270, 33, 270, 66, 66, 270, 270, 33, 66, 270, 33, 66, 66, 33, 66, 33, 66, 270, 270, 66, 33, 270, 33, 270, 66, 66, 66, 66, 66, 33, 33, 270, 33, 270, 33, 66, 270, 66, 270, 66, 270, 66, 270, 33, 66, 66, 66, 66, 66, 66, 66, 66, 270, 33, 33, 33, 33, 33, 66, 33, 33, 66, 270, 270, 33, 33, 270, 33, 33, 33, 66, 33, 66, 270, 270, 66, 66, 33, 270, 66, 270, 33, 66, 66, 33, 33, 66, 33, 270, 270, 33, 270, 270, 33, 66, 270, 33, 33, 66, 66, 33, 33, 270, 270, 270, 270, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 270, 66, 66, 66, 270, 33, 66, 66, 270, 270, 33, 270, 270, 33, 270, 33, 33, 66, 33, 270, 270, 270, 66, 33, 270, 270, 66, 66, 270, 270, 33, 270, 270, 66, 33, 270, 66, 66, 270, 270, 270, 33, 270, 33, 270, 270, 33, 33, 270, 33, 66, 270, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 270, 33, 33, 33, 66, 33, 66, 66, 33, 270, 66, 270, 33, 270, 33, 66, 66, 66, 66, 33, 66, 270, 270, 33, 270, 270, 33, 270, 66, 270, 66, 66, 66, 33, 66, 33, 33, 270, 33, 66, 33, 33, 66, 270, 66, 270, 33, 270, 270, 66, 270, 66, 33, 270, 33, 270, 270, 33, 33, 33]
Prompts retrieved: 47232 . Total input tokens: 10461289 . Total output tokens: 9308734
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 1.6047501480206847,
    "estimated_duration": 3599.950602940798,
    "input_throughput": 1090.9538583089793,
    "output_throughput": 973.0886299212947,
    "total_throughput": 2064.042488230274,
    "itl": 28.206422995349932,
    "ttft": 5862.364494294281,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9480,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 60.51957051661562,
    "arrivals": 16104,
    "finished_requests": 16078,
    "scheduler_time": 0.0017499856000023864
}
#Debug simulation 
Total elapsed time: 1.6048647752031684. Arrivals time: 0.05033181328326464 Scheduler time: 1.1462946878746152 Scheduler overhead time: 0.11385952914133668 Adapter cache time: 0.12997103203088045 Engine time: 0.10977070685476065 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-32/adapters_384_slots_96_rate_0.025-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-32/adapters_384_slots_96_rate_0.025-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 270, 66, 33, 270, 270, 33, 66, 270, 270, 270, 270, 66, 66, 66, 66, 270, 270, 66, 66, 33, 270, 33, 270, 66, 66, 66, 33, 33, 66, 33, 270, 33, 270, 66, 270, 66, 33, 66, 270, 66, 270, 33, 270, 270, 270, 270, 33, 66, 66, 66, 270, 66, 33, 66, 33, 270, 66, 270, 270, 66, 270, 270, 33, 33, 270, 66, 66, 33, 33, 33, 66, 33, 66, 33, 270, 33, 66, 270, 33, 270, 66, 33, 270, 270, 270, 270, 66, 33, 66, 270, 270, 66, 33, 33, 270, 66, 66, 33, 33, 270, 66, 270, 66, 270, 270, 66, 270, 270, 33, 66, 66, 66, 66, 33, 33, 270, 33, 270, 33, 33, 33, 66, 66, 270, 33, 33, 270, 33, 270, 66, 33, 270, 66, 66, 33, 270, 270, 270, 33, 66, 270, 33, 270, 66, 66, 270, 270, 33, 66, 270, 33, 66, 66, 33, 66, 33, 66, 270, 270, 66, 33, 270, 33, 270, 66, 66, 66, 66, 66, 33, 33, 270, 33, 270, 33, 66, 270, 66, 270, 66, 270, 66, 270, 33, 66, 66, 66, 66, 66, 66, 66, 66, 270, 33, 33, 33, 33, 33, 66, 33, 33, 66, 270, 270, 33, 33, 270, 33, 33, 33, 66, 33, 66, 270, 270, 66, 66, 33, 270, 66, 270, 33, 66, 66, 33, 33, 66, 33, 270, 270, 33, 270, 270, 33, 66, 270, 33, 33, 66, 66, 33, 33, 270, 270, 270, 270, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 270, 66, 66, 66, 270, 33, 66, 66, 270, 270, 33, 270, 270, 33, 270, 33, 33, 66, 33, 270, 270, 270, 66, 33, 270, 270, 66, 66, 270, 270, 33, 270, 270, 66, 33, 270, 66, 66, 270, 270, 270, 33, 270, 33, 270, 270, 33, 33, 270, 33, 66, 270, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 270, 33, 33, 33, 66, 33, 66, 66, 33, 270, 66, 270, 33, 270, 33, 66, 66, 66, 66, 33, 66, 270, 270, 33, 270, 270, 33, 270, 66, 270, 66, 66, 66, 33, 66, 33, 33, 270, 33, 66, 33, 33, 66, 270, 66, 270, 33, 270, 270, 66, 270, 66, 33, 270, 33, 270, 270, 33, 33, 33]
Prompts retrieved: 47232 . Total input tokens: 10461289 . Total output tokens: 9308734
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 1.5985639379359782,
    "estimated_duration": 3599.9495806260516,
    "input_throughput": 1090.9541681183787,
    "output_throughput": 973.0889062592915,
    "total_throughput": 2064.04307437767,
    "itl": 28.618681763500113,
    "ttft": 5863.672847802313,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9519,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 70.36048246612522,
    "arrivals": 16104,
    "finished_requests": 16078,
    "scheduler_time": 0.0024925627896247877
}
#Debug simulation 
Total elapsed time: 1.5986545821651816. Arrivals time: 0.050221520476043224 Scheduler time: 1.1412285123951733 Scheduler overhead time: 0.11383370356634259 Adapter cache time: 0.13061614241451025 Engine time: 0.10852441284805536 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-8/adapters_384_slots_96_rate_0.0125-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-8/adapters_384_slots_96_rate_0.0125-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 135, 66, 33, 135, 135, 33, 66, 135, 135, 135, 135, 66, 66, 66, 66, 135, 135, 66, 66, 33, 135, 33, 135, 66, 66, 66, 33, 33, 66, 33, 135, 33, 135, 66, 135, 66, 33, 66, 135, 66, 135, 33, 135, 135, 135, 135, 33, 66, 66, 66, 135, 66, 33, 66, 33, 135, 66, 135, 135, 66, 135, 135, 33, 33, 135, 66, 66, 33, 33, 33, 66, 33, 66, 33, 135, 33, 66, 135, 33, 135, 66, 33, 135, 135, 135, 135, 66, 33, 66, 135, 135, 66, 33, 33, 135, 66, 66, 33, 33, 135, 66, 135, 66, 135, 135, 66, 135, 135, 33, 66, 66, 66, 66, 33, 33, 135, 33, 135, 33, 33, 33, 66, 66, 135, 33, 33, 135, 33, 135, 66, 33, 135, 66, 66, 33, 135, 135, 135, 33, 66, 135, 33, 135, 66, 66, 135, 135, 33, 66, 135, 33, 66, 66, 33, 66, 33, 66, 135, 135, 66, 33, 135, 33, 135, 66, 66, 66, 66, 66, 33, 33, 135, 33, 135, 33, 66, 135, 66, 135, 66, 135, 66, 135, 33, 66, 66, 66, 66, 66, 66, 66, 66, 135, 33, 33, 33, 33, 33, 66, 33, 33, 66, 135, 135, 33, 33, 135, 33, 33, 33, 66, 33, 66, 135, 135, 66, 66, 33, 135, 66, 135, 33, 66, 66, 33, 33, 66, 33, 135, 135, 33, 135, 135, 33, 66, 135, 33, 33, 66, 66, 33, 33, 135, 135, 135, 135, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 135, 66, 66, 66, 135, 33, 66, 66, 135, 135, 33, 135, 135, 33, 135, 33, 33, 66, 33, 135, 135, 135, 66, 33, 135, 135, 66, 66, 135, 135, 33, 135, 135, 66, 33, 135, 66, 66, 135, 135, 135, 33, 135, 33, 135, 135, 33, 33, 135, 33, 66, 135, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 135, 33, 33, 33, 66, 33, 66, 66, 33, 135, 66, 135, 33, 135, 33, 66, 66, 66, 66, 33, 66, 135, 135, 33, 135, 135, 33, 135, 66, 135, 66, 66, 66, 33, 66, 33, 33, 135, 33, 66, 33, 33, 66, 135, 66, 135, 33, 135, 135, 66, 135, 66, 33, 135, 33, 135, 135, 33, 33, 33]
Prompts retrieved: 29952 . Total input tokens: 6601882 . Total output tokens: 5905358
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 1.1986605608835816,
    "estimated_duration": 3599.92487253439,
    "input_throughput": 683.7564913589695,
    "output_throughput": 604.5303935656535,
    "total_throughput": 1288.286884924623,
    "itl": 23.976454880737474,
    "ttft": 5702.8453496177235,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6996,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 46.26041358752272,
    "arrivals": 10179,
    "finished_requests": 10163,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1987299220636487. Arrivals time: 0.03681526519358158 Scheduler time: 0.7569349170662463 Scheduler overhead time: 0.12691170582547784 Adapter cache time: 0.09219962172210217 Engine time: 0.12401696434244514 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-16/adapters_384_slots_96_rate_0.0125-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-16/adapters_384_slots_96_rate_0.0125-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 135, 66, 33, 135, 135, 33, 66, 135, 135, 135, 135, 66, 66, 66, 66, 135, 135, 66, 66, 33, 135, 33, 135, 66, 66, 66, 33, 33, 66, 33, 135, 33, 135, 66, 135, 66, 33, 66, 135, 66, 135, 33, 135, 135, 135, 135, 33, 66, 66, 66, 135, 66, 33, 66, 33, 135, 66, 135, 135, 66, 135, 135, 33, 33, 135, 66, 66, 33, 33, 33, 66, 33, 66, 33, 135, 33, 66, 135, 33, 135, 66, 33, 135, 135, 135, 135, 66, 33, 66, 135, 135, 66, 33, 33, 135, 66, 66, 33, 33, 135, 66, 135, 66, 135, 135, 66, 135, 135, 33, 66, 66, 66, 66, 33, 33, 135, 33, 135, 33, 33, 33, 66, 66, 135, 33, 33, 135, 33, 135, 66, 33, 135, 66, 66, 33, 135, 135, 135, 33, 66, 135, 33, 135, 66, 66, 135, 135, 33, 66, 135, 33, 66, 66, 33, 66, 33, 66, 135, 135, 66, 33, 135, 33, 135, 66, 66, 66, 66, 66, 33, 33, 135, 33, 135, 33, 66, 135, 66, 135, 66, 135, 66, 135, 33, 66, 66, 66, 66, 66, 66, 66, 66, 135, 33, 33, 33, 33, 33, 66, 33, 33, 66, 135, 135, 33, 33, 135, 33, 33, 33, 66, 33, 66, 135, 135, 66, 66, 33, 135, 66, 135, 33, 66, 66, 33, 33, 66, 33, 135, 135, 33, 135, 135, 33, 66, 135, 33, 33, 66, 66, 33, 33, 135, 135, 135, 135, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 135, 66, 66, 66, 135, 33, 66, 66, 135, 135, 33, 135, 135, 33, 135, 33, 33, 66, 33, 135, 135, 135, 66, 33, 135, 135, 66, 66, 135, 135, 33, 135, 135, 66, 33, 135, 66, 66, 135, 135, 135, 33, 135, 33, 135, 135, 33, 33, 135, 33, 66, 135, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 135, 33, 33, 33, 66, 33, 66, 66, 33, 135, 66, 135, 33, 135, 33, 66, 66, 66, 66, 33, 66, 135, 135, 33, 135, 135, 33, 135, 66, 135, 66, 66, 66, 33, 66, 33, 33, 135, 33, 66, 33, 33, 66, 135, 66, 135, 33, 135, 135, 66, 135, 66, 33, 135, 33, 135, 135, 33, 33, 33]
Prompts retrieved: 29952 . Total input tokens: 6601882 . Total output tokens: 5905358
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 1.2014482947997749,
    "estimated_duration": 3599.9013176041803,
    "input_throughput": 683.7609653250629,
    "output_throughput": 604.5343491383134,
    "total_throughput": 1288.2953144633761,
    "itl": 24.013043773201495,
    "ttft": 5703.534295769339,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6993,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 51.16462127003183,
    "arrivals": 10179,
    "finished_requests": 10163,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2015292500145733. Arrivals time: 0.03710404457524419 Scheduler time: 0.760713036172092 Scheduler overhead time: 0.1268088067881763 Adapter cache time: 0.09260380640625954 Engine time: 0.12313562445342541 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-32/adapters_384_slots_96_rate_0.0125-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-32/adapters_384_slots_96_rate_0.0125-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 135, 66, 33, 135, 135, 33, 66, 135, 135, 135, 135, 66, 66, 66, 66, 135, 135, 66, 66, 33, 135, 33, 135, 66, 66, 66, 33, 33, 66, 33, 135, 33, 135, 66, 135, 66, 33, 66, 135, 66, 135, 33, 135, 135, 135, 135, 33, 66, 66, 66, 135, 66, 33, 66, 33, 135, 66, 135, 135, 66, 135, 135, 33, 33, 135, 66, 66, 33, 33, 33, 66, 33, 66, 33, 135, 33, 66, 135, 33, 135, 66, 33, 135, 135, 135, 135, 66, 33, 66, 135, 135, 66, 33, 33, 135, 66, 66, 33, 33, 135, 66, 135, 66, 135, 135, 66, 135, 135, 33, 66, 66, 66, 66, 33, 33, 135, 33, 135, 33, 33, 33, 66, 66, 135, 33, 33, 135, 33, 135, 66, 33, 135, 66, 66, 33, 135, 135, 135, 33, 66, 135, 33, 135, 66, 66, 135, 135, 33, 66, 135, 33, 66, 66, 33, 66, 33, 66, 135, 135, 66, 33, 135, 33, 135, 66, 66, 66, 66, 66, 33, 33, 135, 33, 135, 33, 66, 135, 66, 135, 66, 135, 66, 135, 33, 66, 66, 66, 66, 66, 66, 66, 66, 135, 33, 33, 33, 33, 33, 66, 33, 33, 66, 135, 135, 33, 33, 135, 33, 33, 33, 66, 33, 66, 135, 135, 66, 66, 33, 135, 66, 135, 33, 66, 66, 33, 33, 66, 33, 135, 135, 33, 135, 135, 33, 66, 135, 33, 33, 66, 66, 33, 33, 135, 135, 135, 135, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 135, 66, 66, 66, 135, 33, 66, 66, 135, 135, 33, 135, 135, 33, 135, 33, 33, 66, 33, 135, 135, 135, 66, 33, 135, 135, 66, 66, 135, 135, 33, 135, 135, 66, 33, 135, 66, 66, 135, 135, 135, 33, 135, 33, 135, 135, 33, 33, 135, 33, 66, 135, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 135, 33, 33, 33, 66, 33, 66, 66, 33, 135, 66, 135, 33, 135, 33, 66, 66, 66, 66, 33, 66, 135, 135, 33, 135, 135, 33, 135, 66, 135, 66, 66, 66, 33, 66, 33, 33, 135, 33, 66, 33, 33, 66, 135, 66, 135, 33, 135, 135, 66, 135, 66, 33, 135, 33, 135, 135, 33, 33, 33]
Prompts retrieved: 29952 . Total input tokens: 6601882 . Total output tokens: 5905358
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 1.1970573239959776,
    "estimated_duration": 3599.9090279545517,
    "input_throughput": 683.7595008334405,
    "output_throughput": 604.5330543356928,
    "total_throughput": 1288.2925551691333,
    "itl": 24.02920076287103,
    "ttft": 5703.594912883672,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6993,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 52.55427042645127,
    "arrivals": 10179,
    "finished_requests": 10163,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1971475849859416. Arrivals time: 0.0363834947347641 Scheduler time: 0.7520715072751045 Scheduler overhead time: 0.12893895572051406 Adapter cache time: 0.09197312593460083 Engine time: 0.1251438343897462 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-16/adapters_384_slots_96_rate_0.0125-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-16/adapters_384_slots_96_rate_0.0125-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 135, 66, 33, 135, 135, 33, 66, 135, 135, 135, 135, 66, 66, 66, 66, 135, 135, 66, 66, 33, 135, 33, 135, 66, 66, 66, 33, 33, 66, 33, 135, 33, 135, 66, 135, 66, 33, 66, 135, 66, 135, 33, 135, 135, 135, 135, 33, 66, 66, 66, 135, 66, 33, 66, 33, 135, 66, 135, 135, 66, 135, 135, 33, 33, 135, 66, 66, 33, 33, 33, 66, 33, 66, 33, 135, 33, 66, 135, 33, 135, 66, 33, 135, 135, 135, 135, 66, 33, 66, 135, 135, 66, 33, 33, 135, 66, 66, 33, 33, 135, 66, 135, 66, 135, 135, 66, 135, 135, 33, 66, 66, 66, 66, 33, 33, 135, 33, 135, 33, 33, 33, 66, 66, 135, 33, 33, 135, 33, 135, 66, 33, 135, 66, 66, 33, 135, 135, 135, 33, 66, 135, 33, 135, 66, 66, 135, 135, 33, 66, 135, 33, 66, 66, 33, 66, 33, 66, 135, 135, 66, 33, 135, 33, 135, 66, 66, 66, 66, 66, 33, 33, 135, 33, 135, 33, 66, 135, 66, 135, 66, 135, 66, 135, 33, 66, 66, 66, 66, 66, 66, 66, 66, 135, 33, 33, 33, 33, 33, 66, 33, 33, 66, 135, 135, 33, 33, 135, 33, 33, 33, 66, 33, 66, 135, 135, 66, 66, 33, 135, 66, 135, 33, 66, 66, 33, 33, 66, 33, 135, 135, 33, 135, 135, 33, 66, 135, 33, 33, 66, 66, 33, 33, 135, 135, 135, 135, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 135, 66, 66, 66, 135, 33, 66, 66, 135, 135, 33, 135, 135, 33, 135, 33, 33, 66, 33, 135, 135, 135, 66, 33, 135, 135, 66, 66, 135, 135, 33, 135, 135, 66, 33, 135, 66, 66, 135, 135, 135, 33, 135, 33, 135, 135, 33, 33, 135, 33, 66, 135, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 135, 33, 33, 33, 66, 33, 66, 66, 33, 135, 66, 135, 33, 135, 33, 66, 66, 66, 66, 33, 66, 135, 135, 33, 135, 135, 33, 135, 66, 135, 66, 66, 66, 33, 66, 33, 33, 135, 33, 66, 33, 33, 66, 135, 66, 135, 33, 135, 135, 66, 135, 66, 33, 135, 33, 135, 135, 33, 33, 33]
Prompts retrieved: 29952 . Total input tokens: 6601882 . Total output tokens: 5905358
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 1.1969845942221582,
    "estimated_duration": 3599.9018206071833,
    "input_throughput": 683.7608697852854,
    "output_throughput": 604.5342646686228,
    "total_throughput": 1288.295134453908,
    "itl": 23.98849454899572,
    "ttft": 5703.213965208342,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6992,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 47.97921132020807,
    "arrivals": 10179,
    "finished_requests": 10163,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1970562692731619. Arrivals time: 0.03703941823914647 Scheduler time: 0.7523736609145999 Scheduler overhead time: 0.12764869537204504 Adapter cache time: 0.09237713320180774 Engine time: 0.12602569814771414 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-32/adapters_384_slots_96_rate_0.0125-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-32/adapters_384_slots_96_rate_0.0125-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 135, 66, 33, 135, 135, 33, 66, 135, 135, 135, 135, 66, 66, 66, 66, 135, 135, 66, 66, 33, 135, 33, 135, 66, 66, 66, 33, 33, 66, 33, 135, 33, 135, 66, 135, 66, 33, 66, 135, 66, 135, 33, 135, 135, 135, 135, 33, 66, 66, 66, 135, 66, 33, 66, 33, 135, 66, 135, 135, 66, 135, 135, 33, 33, 135, 66, 66, 33, 33, 33, 66, 33, 66, 33, 135, 33, 66, 135, 33, 135, 66, 33, 135, 135, 135, 135, 66, 33, 66, 135, 135, 66, 33, 33, 135, 66, 66, 33, 33, 135, 66, 135, 66, 135, 135, 66, 135, 135, 33, 66, 66, 66, 66, 33, 33, 135, 33, 135, 33, 33, 33, 66, 66, 135, 33, 33, 135, 33, 135, 66, 33, 135, 66, 66, 33, 135, 135, 135, 33, 66, 135, 33, 135, 66, 66, 135, 135, 33, 66, 135, 33, 66, 66, 33, 66, 33, 66, 135, 135, 66, 33, 135, 33, 135, 66, 66, 66, 66, 66, 33, 33, 135, 33, 135, 33, 66, 135, 66, 135, 66, 135, 66, 135, 33, 66, 66, 66, 66, 66, 66, 66, 66, 135, 33, 33, 33, 33, 33, 66, 33, 33, 66, 135, 135, 33, 33, 135, 33, 33, 33, 66, 33, 66, 135, 135, 66, 66, 33, 135, 66, 135, 33, 66, 66, 33, 33, 66, 33, 135, 135, 33, 135, 135, 33, 66, 135, 33, 33, 66, 66, 33, 33, 135, 135, 135, 135, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 135, 66, 66, 66, 135, 33, 66, 66, 135, 135, 33, 135, 135, 33, 135, 33, 33, 66, 33, 135, 135, 135, 66, 33, 135, 135, 66, 66, 135, 135, 33, 135, 135, 66, 33, 135, 66, 66, 135, 135, 135, 33, 135, 33, 135, 135, 33, 33, 135, 33, 66, 135, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 135, 33, 33, 33, 66, 33, 66, 66, 33, 135, 66, 135, 33, 135, 33, 66, 66, 66, 66, 33, 66, 135, 135, 33, 135, 135, 33, 135, 66, 135, 66, 66, 66, 33, 66, 33, 33, 135, 33, 66, 33, 33, 66, 135, 66, 135, 33, 135, 135, 66, 135, 66, 33, 135, 33, 135, 135, 33, 33, 33]
Prompts retrieved: 29952 . Total input tokens: 6601882 . Total output tokens: 5905358
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 1.1919206390157342,
    "estimated_duration": 3599.9246483322204,
    "input_throughput": 683.7565339431077,
    "output_throughput": 604.5304312156154,
    "total_throughput": 1288.2869651587232,
    "itl": 24.027501742976746,
    "ttft": 5703.446907997618,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6994,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 52.086546476159356,
    "arrivals": 10179,
    "finished_requests": 10163,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1919921338558197. Arrivals time: 0.037069131154567 Scheduler time: 0.7513739350251853 Scheduler overhead time: 0.12719758693128824 Adapter cache time: 0.09197226818650961 Engine time: 0.12273564003407955 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-16/adapters_384_slots_96_rate_0.0125-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-16/adapters_384_slots_96_rate_0.0125-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 135, 66, 33, 135, 135, 33, 66, 135, 135, 135, 135, 66, 66, 66, 66, 135, 135, 66, 66, 33, 135, 33, 135, 66, 66, 66, 33, 33, 66, 33, 135, 33, 135, 66, 135, 66, 33, 66, 135, 66, 135, 33, 135, 135, 135, 135, 33, 66, 66, 66, 135, 66, 33, 66, 33, 135, 66, 135, 135, 66, 135, 135, 33, 33, 135, 66, 66, 33, 33, 33, 66, 33, 66, 33, 135, 33, 66, 135, 33, 135, 66, 33, 135, 135, 135, 135, 66, 33, 66, 135, 135, 66, 33, 33, 135, 66, 66, 33, 33, 135, 66, 135, 66, 135, 135, 66, 135, 135, 33, 66, 66, 66, 66, 33, 33, 135, 33, 135, 33, 33, 33, 66, 66, 135, 33, 33, 135, 33, 135, 66, 33, 135, 66, 66, 33, 135, 135, 135, 33, 66, 135, 33, 135, 66, 66, 135, 135, 33, 66, 135, 33, 66, 66, 33, 66, 33, 66, 135, 135, 66, 33, 135, 33, 135, 66, 66, 66, 66, 66, 33, 33, 135, 33, 135, 33, 66, 135, 66, 135, 66, 135, 66, 135, 33, 66, 66, 66, 66, 66, 66, 66, 66, 135, 33, 33, 33, 33, 33, 66, 33, 33, 66, 135, 135, 33, 33, 135, 33, 33, 33, 66, 33, 66, 135, 135, 66, 66, 33, 135, 66, 135, 33, 66, 66, 33, 33, 66, 33, 135, 135, 33, 135, 135, 33, 66, 135, 33, 33, 66, 66, 33, 33, 135, 135, 135, 135, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 135, 66, 66, 66, 135, 33, 66, 66, 135, 135, 33, 135, 135, 33, 135, 33, 33, 66, 33, 135, 135, 135, 66, 33, 135, 135, 66, 66, 135, 135, 33, 135, 135, 66, 33, 135, 66, 66, 135, 135, 135, 33, 135, 33, 135, 135, 33, 33, 135, 33, 66, 135, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 135, 33, 33, 33, 66, 33, 66, 66, 33, 135, 66, 135, 33, 135, 33, 66, 66, 66, 66, 33, 66, 135, 135, 33, 135, 135, 33, 135, 66, 135, 66, 66, 66, 33, 66, 33, 33, 135, 33, 66, 33, 33, 66, 135, 66, 135, 33, 135, 135, 66, 135, 66, 33, 135, 33, 135, 135, 33, 33, 33]
Prompts retrieved: 29952 . Total input tokens: 6601882 . Total output tokens: 5905358
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 1.2023612586781383,
    "estimated_duration": 3599.9039202933895,
    "input_throughput": 683.7604709737342,
    "output_throughput": 604.5339120669188,
    "total_throughput": 1288.294383040653,
    "itl": 23.958758872804573,
    "ttft": 5702.7608402538735,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6994,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 44.64914305835516,
    "arrivals": 10179,
    "finished_requests": 10163,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2024914077483118. Arrivals time: 0.03719004988670349 Scheduler time: 0.7601506258361042 Scheduler overhead time: 0.12743326369673014 Adapter cache time: 0.0921760369092226 Engine time: 0.12328990502282977 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-32/adapters_384_slots_96_rate_0.0125-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-32/adapters_384_slots_96_rate_0.0125-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 135, 66, 33, 135, 135, 33, 66, 135, 135, 135, 135, 66, 66, 66, 66, 135, 135, 66, 66, 33, 135, 33, 135, 66, 66, 66, 33, 33, 66, 33, 135, 33, 135, 66, 135, 66, 33, 66, 135, 66, 135, 33, 135, 135, 135, 135, 33, 66, 66, 66, 135, 66, 33, 66, 33, 135, 66, 135, 135, 66, 135, 135, 33, 33, 135, 66, 66, 33, 33, 33, 66, 33, 66, 33, 135, 33, 66, 135, 33, 135, 66, 33, 135, 135, 135, 135, 66, 33, 66, 135, 135, 66, 33, 33, 135, 66, 66, 33, 33, 135, 66, 135, 66, 135, 135, 66, 135, 135, 33, 66, 66, 66, 66, 33, 33, 135, 33, 135, 33, 33, 33, 66, 66, 135, 33, 33, 135, 33, 135, 66, 33, 135, 66, 66, 33, 135, 135, 135, 33, 66, 135, 33, 135, 66, 66, 135, 135, 33, 66, 135, 33, 66, 66, 33, 66, 33, 66, 135, 135, 66, 33, 135, 33, 135, 66, 66, 66, 66, 66, 33, 33, 135, 33, 135, 33, 66, 135, 66, 135, 66, 135, 66, 135, 33, 66, 66, 66, 66, 66, 66, 66, 66, 135, 33, 33, 33, 33, 33, 66, 33, 33, 66, 135, 135, 33, 33, 135, 33, 33, 33, 66, 33, 66, 135, 135, 66, 66, 33, 135, 66, 135, 33, 66, 66, 33, 33, 66, 33, 135, 135, 33, 135, 135, 33, 66, 135, 33, 33, 66, 66, 33, 33, 135, 135, 135, 135, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 135, 66, 66, 66, 135, 33, 66, 66, 135, 135, 33, 135, 135, 33, 135, 33, 33, 66, 33, 135, 135, 135, 66, 33, 135, 135, 66, 66, 135, 135, 33, 135, 135, 66, 33, 135, 66, 66, 135, 135, 135, 33, 135, 33, 135, 135, 33, 33, 135, 33, 66, 135, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 135, 33, 33, 33, 66, 33, 66, 66, 33, 135, 66, 135, 33, 135, 33, 66, 66, 66, 66, 33, 66, 135, 135, 33, 135, 135, 33, 135, 66, 135, 66, 66, 66, 33, 66, 33, 33, 135, 33, 66, 33, 33, 66, 135, 66, 135, 33, 135, 135, 66, 135, 66, 33, 135, 33, 135, 135, 33, 33, 33]
Prompts retrieved: 29952 . Total input tokens: 6601882 . Total output tokens: 5905358
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 1.1964364750310779,
    "estimated_duration": 3599.923933525506,
    "input_throughput": 683.7566697109102,
    "output_throughput": 604.5305512521549,
    "total_throughput": 1288.287220963065,
    "itl": 24.02243157285652,
    "ttft": 5703.59219282453,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6993,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 51.581233930715534,
    "arrivals": 10179,
    "finished_requests": 10163,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1965161971747875. Arrivals time: 0.03774570394307375 Scheduler time: 0.7542210691608489 Scheduler overhead time: 0.1272381949238479 Adapter cache time: 0.09187196847051382 Engine time: 0.1238583717495203 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.8_size_8-8-8/adapters_384_slots_128_rate_3.2-1.6-0.8_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.8_size_8-8-8/adapters_384_slots_128_rate_3.2-1.6-0.8_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [128 128 128]
Adapter prompts. [8640, 8640, 34560, 17280, 8640, 34560, 34560, 8640, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 8640, 34560, 8640, 34560, 17280, 17280, 17280, 8640, 8640, 17280, 8640, 34560, 8640, 34560, 17280, 34560, 17280, 8640, 17280, 34560, 17280, 34560, 8640, 34560, 34560, 34560, 34560, 8640, 17280, 17280, 17280, 34560, 17280, 8640, 17280, 8640, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 8640, 8640, 34560, 17280, 17280, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 34560, 8640, 17280, 34560, 8640, 34560, 17280, 8640, 34560, 34560, 34560, 34560, 17280, 8640, 17280, 34560, 34560, 17280, 8640, 8640, 34560, 17280, 17280, 8640, 8640, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 34560, 8640, 34560, 8640, 8640, 8640, 17280, 17280, 34560, 8640, 8640, 34560, 8640, 34560, 17280, 8640, 34560, 17280, 17280, 8640, 34560, 34560, 34560, 8640, 17280, 34560, 8640, 34560, 17280, 17280, 34560, 34560, 8640, 17280, 34560, 8640, 17280, 17280, 8640, 17280, 8640, 17280, 34560, 34560, 17280, 8640, 34560, 8640, 34560, 17280, 17280, 17280, 17280, 17280, 8640, 8640, 34560, 8640, 34560, 8640, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 8640, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 8640, 17280, 34560, 34560, 8640, 8640, 34560, 8640, 8640, 8640, 17280, 8640, 17280, 34560, 34560, 17280, 17280, 8640, 34560, 17280, 34560, 8640, 17280, 17280, 8640, 8640, 17280, 8640, 34560, 34560, 8640, 34560, 34560, 8640, 17280, 34560, 8640, 8640, 17280, 17280, 8640, 8640, 34560, 34560, 34560, 34560, 17280, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 34560, 17280, 17280, 17280, 34560, 8640, 17280, 17280, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 8640, 8640, 17280, 8640, 34560, 34560, 34560, 17280, 8640, 34560, 34560, 17280, 17280, 34560, 34560, 8640, 34560, 34560, 17280, 8640, 34560, 17280, 17280, 34560, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 34560, 8640, 17280, 34560, 8640, 17280, 17280, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 34560, 8640, 8640, 8640, 17280, 8640, 17280, 17280, 8640, 34560, 17280, 34560, 8640, 34560, 8640, 17280, 17280, 17280, 17280, 8640, 17280, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 17280, 34560, 17280, 17280, 17280, 8640, 17280, 8640, 8640, 34560, 8640, 17280, 8640, 8640, 17280, 34560, 17280, 34560, 8640, 34560, 34560, 17280, 34560, 17280, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 8640]
Prompts retrieved: 7741440 . Total input tokens: 1726659822 . Total output tokens: 1520242460
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 9.07321535795927,
    "estimated_duration": 3600.069813779513,
    "input_throughput": 3913.8046562512977,
    "output_throughput": 3426.4638293360304,
    "total_throughput": 7340.2684855873285,
    "itl": 150.3489590600768,
    "ttft": 2309811.559907983,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2728,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 18.038651839159396,
    "arrivals": 2579962,
    "finished_requests": 57307,
    "scheduler_time": 121.75168833082752
}
#Debug simulation 
Total elapsed time: 9.073323538061231. Arrivals time: 0.2623540423810482 Scheduler time: 8.65762421535328 Scheduler overhead time: 0.03876781556755304 Adapter cache time: 0.059316374361515045 Engine time: 0.038222184870392084 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.8_size_8-8-16/adapters_384_slots_128_rate_3.2-1.6-0.8_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.8_size_8-8-16/adapters_384_slots_128_rate_3.2-1.6-0.8_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [128 128 128]
Adapter prompts. [8640, 8640, 34560, 17280, 8640, 34560, 34560, 8640, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 8640, 34560, 8640, 34560, 17280, 17280, 17280, 8640, 8640, 17280, 8640, 34560, 8640, 34560, 17280, 34560, 17280, 8640, 17280, 34560, 17280, 34560, 8640, 34560, 34560, 34560, 34560, 8640, 17280, 17280, 17280, 34560, 17280, 8640, 17280, 8640, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 8640, 8640, 34560, 17280, 17280, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 34560, 8640, 17280, 34560, 8640, 34560, 17280, 8640, 34560, 34560, 34560, 34560, 17280, 8640, 17280, 34560, 34560, 17280, 8640, 8640, 34560, 17280, 17280, 8640, 8640, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 34560, 8640, 34560, 8640, 8640, 8640, 17280, 17280, 34560, 8640, 8640, 34560, 8640, 34560, 17280, 8640, 34560, 17280, 17280, 8640, 34560, 34560, 34560, 8640, 17280, 34560, 8640, 34560, 17280, 17280, 34560, 34560, 8640, 17280, 34560, 8640, 17280, 17280, 8640, 17280, 8640, 17280, 34560, 34560, 17280, 8640, 34560, 8640, 34560, 17280, 17280, 17280, 17280, 17280, 8640, 8640, 34560, 8640, 34560, 8640, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 8640, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 8640, 17280, 34560, 34560, 8640, 8640, 34560, 8640, 8640, 8640, 17280, 8640, 17280, 34560, 34560, 17280, 17280, 8640, 34560, 17280, 34560, 8640, 17280, 17280, 8640, 8640, 17280, 8640, 34560, 34560, 8640, 34560, 34560, 8640, 17280, 34560, 8640, 8640, 17280, 17280, 8640, 8640, 34560, 34560, 34560, 34560, 17280, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 34560, 17280, 17280, 17280, 34560, 8640, 17280, 17280, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 8640, 8640, 17280, 8640, 34560, 34560, 34560, 17280, 8640, 34560, 34560, 17280, 17280, 34560, 34560, 8640, 34560, 34560, 17280, 8640, 34560, 17280, 17280, 34560, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 34560, 8640, 17280, 34560, 8640, 17280, 17280, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 34560, 8640, 8640, 8640, 17280, 8640, 17280, 17280, 8640, 34560, 17280, 34560, 8640, 34560, 8640, 17280, 17280, 17280, 17280, 8640, 17280, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 17280, 34560, 17280, 17280, 17280, 8640, 17280, 8640, 8640, 34560, 8640, 17280, 8640, 8640, 17280, 34560, 17280, 34560, 8640, 34560, 34560, 17280, 34560, 17280, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 8640]
Prompts retrieved: 7741440 . Total input tokens: 1726659822 . Total output tokens: 1520242460
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 7.514184334781021,
    "estimated_duration": 3600.021361937169,
    "input_throughput": 3684.782579418349,
    "output_throughput": 3230.715829347623,
    "total_throughput": 6915.498408765972,
    "itl": 133.92454686330214,
    "ttft": 2335278.3743272377,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3928,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 28.682639543227072,
    "arrivals": 2579962,
    "finished_requests": 53968,
    "scheduler_time": 127.65629053068373
}
#Debug simulation 
Total elapsed time: 7.514250314794481. Arrivals time: 0.7490907744504511 Scheduler time: 6.583941914141178 Scheduler overhead time: 0.041739937383681536 Adapter cache time: 0.07950149569660425 Engine time: 0.041373752523213625 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.8_size_8-16-16/adapters_384_slots_128_rate_3.2-1.6-0.8_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.8_size_8-16-16/adapters_384_slots_128_rate_3.2-1.6-0.8_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [128 128 128]
Adapter prompts. [8640, 8640, 34560, 17280, 8640, 34560, 34560, 8640, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 8640, 34560, 8640, 34560, 17280, 17280, 17280, 8640, 8640, 17280, 8640, 34560, 8640, 34560, 17280, 34560, 17280, 8640, 17280, 34560, 17280, 34560, 8640, 34560, 34560, 34560, 34560, 8640, 17280, 17280, 17280, 34560, 17280, 8640, 17280, 8640, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 8640, 8640, 34560, 17280, 17280, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 34560, 8640, 17280, 34560, 8640, 34560, 17280, 8640, 34560, 34560, 34560, 34560, 17280, 8640, 17280, 34560, 34560, 17280, 8640, 8640, 34560, 17280, 17280, 8640, 8640, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 34560, 8640, 34560, 8640, 8640, 8640, 17280, 17280, 34560, 8640, 8640, 34560, 8640, 34560, 17280, 8640, 34560, 17280, 17280, 8640, 34560, 34560, 34560, 8640, 17280, 34560, 8640, 34560, 17280, 17280, 34560, 34560, 8640, 17280, 34560, 8640, 17280, 17280, 8640, 17280, 8640, 17280, 34560, 34560, 17280, 8640, 34560, 8640, 34560, 17280, 17280, 17280, 17280, 17280, 8640, 8640, 34560, 8640, 34560, 8640, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 8640, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 8640, 17280, 34560, 34560, 8640, 8640, 34560, 8640, 8640, 8640, 17280, 8640, 17280, 34560, 34560, 17280, 17280, 8640, 34560, 17280, 34560, 8640, 17280, 17280, 8640, 8640, 17280, 8640, 34560, 34560, 8640, 34560, 34560, 8640, 17280, 34560, 8640, 8640, 17280, 17280, 8640, 8640, 34560, 34560, 34560, 34560, 17280, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 34560, 17280, 17280, 17280, 34560, 8640, 17280, 17280, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 8640, 8640, 17280, 8640, 34560, 34560, 34560, 17280, 8640, 34560, 34560, 17280, 17280, 34560, 34560, 8640, 34560, 34560, 17280, 8640, 34560, 17280, 17280, 34560, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 34560, 8640, 17280, 34560, 8640, 17280, 17280, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 34560, 8640, 8640, 8640, 17280, 8640, 17280, 17280, 8640, 34560, 17280, 34560, 8640, 34560, 8640, 17280, 17280, 17280, 17280, 8640, 17280, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 17280, 34560, 17280, 17280, 17280, 8640, 17280, 8640, 8640, 34560, 8640, 17280, 8640, 8640, 17280, 34560, 17280, 34560, 8640, 34560, 34560, 17280, 34560, 17280, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 8640]
Prompts retrieved: 7741440 . Total input tokens: 1726659822 . Total output tokens: 1520242460
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 6.979069644585252,
    "estimated_duration": 3600.0702317232485,
    "input_throughput": 3687.071402950453,
    "output_throughput": 3232.829709110711,
    "total_throughput": 6919.901112061164,
    "itl": 133.8585096177055,
    "ttft": 2335177.660553134,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3932,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 26.902099740710895,
    "arrivals": 2579962,
    "finished_requests": 53998,
    "scheduler_time": 127.71922691444713
}
#Debug simulation 
Total elapsed time: 6.979141281917691. Arrivals time: 0.2545426348224282 Scheduler time: 6.544156500138342 Scheduler overhead time: 0.04147497704252601 Adapter cache time: 0.07906948961317539 Engine time: 0.041241013910621405 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.8_size_16-16-16/adapters_384_slots_128_rate_3.2-1.6-0.8_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.8_size_16-16-16/adapters_384_slots_128_rate_3.2-1.6-0.8_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [128 128 128]
Adapter prompts. [8640, 8640, 34560, 17280, 8640, 34560, 34560, 8640, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 8640, 34560, 8640, 34560, 17280, 17280, 17280, 8640, 8640, 17280, 8640, 34560, 8640, 34560, 17280, 34560, 17280, 8640, 17280, 34560, 17280, 34560, 8640, 34560, 34560, 34560, 34560, 8640, 17280, 17280, 17280, 34560, 17280, 8640, 17280, 8640, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 8640, 8640, 34560, 17280, 17280, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 34560, 8640, 17280, 34560, 8640, 34560, 17280, 8640, 34560, 34560, 34560, 34560, 17280, 8640, 17280, 34560, 34560, 17280, 8640, 8640, 34560, 17280, 17280, 8640, 8640, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 34560, 8640, 34560, 8640, 8640, 8640, 17280, 17280, 34560, 8640, 8640, 34560, 8640, 34560, 17280, 8640, 34560, 17280, 17280, 8640, 34560, 34560, 34560, 8640, 17280, 34560, 8640, 34560, 17280, 17280, 34560, 34560, 8640, 17280, 34560, 8640, 17280, 17280, 8640, 17280, 8640, 17280, 34560, 34560, 17280, 8640, 34560, 8640, 34560, 17280, 17280, 17280, 17280, 17280, 8640, 8640, 34560, 8640, 34560, 8640, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 8640, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 8640, 17280, 34560, 34560, 8640, 8640, 34560, 8640, 8640, 8640, 17280, 8640, 17280, 34560, 34560, 17280, 17280, 8640, 34560, 17280, 34560, 8640, 17280, 17280, 8640, 8640, 17280, 8640, 34560, 34560, 8640, 34560, 34560, 8640, 17280, 34560, 8640, 8640, 17280, 17280, 8640, 8640, 34560, 34560, 34560, 34560, 17280, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 34560, 17280, 17280, 17280, 34560, 8640, 17280, 17280, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 8640, 8640, 17280, 8640, 34560, 34560, 34560, 17280, 8640, 34560, 34560, 17280, 17280, 34560, 34560, 8640, 34560, 34560, 17280, 8640, 34560, 17280, 17280, 34560, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 34560, 8640, 17280, 34560, 8640, 17280, 17280, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 34560, 8640, 8640, 8640, 17280, 8640, 17280, 17280, 8640, 34560, 17280, 34560, 8640, 34560, 8640, 17280, 17280, 17280, 17280, 8640, 17280, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 17280, 34560, 17280, 17280, 17280, 8640, 17280, 8640, 8640, 34560, 8640, 17280, 8640, 8640, 17280, 34560, 17280, 34560, 8640, 34560, 34560, 17280, 34560, 17280, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 8640]
Prompts retrieved: 7741440 . Total input tokens: 1726659822 . Total output tokens: 1520242460
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 7.026025464292616,
    "estimated_duration": 3600.0000704967397,
    "input_throughput": 3678.8688168477065,
    "output_throughput": 3227.0907701390615,
    "total_throughput": 6905.959586986768,
    "itl": 133.10419423741692,
    "ttft": 2335909.9062487343,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3961,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 25.286710845602148,
    "arrivals": 2579962,
    "finished_requests": 53911,
    "scheduler_time": 128.06872109288398
}
#Debug simulation 
Total elapsed time: 7.0261477320455015. Arrivals time: 0.24813490873202682 Scheduler time: 6.596204163040966 Scheduler overhead time: 0.041862701531499624 Adapter cache time: 0.07931579044088721 Engine time: 0.04179526725783944 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.4_size_8-8-8/adapters_384_slots_128_rate_3.2-1.6-0.4_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.4_size_8-8-8/adapters_384_slots_128_rate_3.2-1.6-0.4_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [128 128 128]
Adapter prompts. [4320, 4320, 34560, 17280, 4320, 34560, 34560, 4320, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 4320, 34560, 4320, 34560, 17280, 17280, 17280, 4320, 4320, 17280, 4320, 34560, 4320, 34560, 17280, 34560, 17280, 4320, 17280, 34560, 17280, 34560, 4320, 34560, 34560, 34560, 34560, 4320, 17280, 17280, 17280, 34560, 17280, 4320, 17280, 4320, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 4320, 4320, 34560, 17280, 17280, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 34560, 4320, 17280, 34560, 4320, 34560, 17280, 4320, 34560, 34560, 34560, 34560, 17280, 4320, 17280, 34560, 34560, 17280, 4320, 4320, 34560, 17280, 17280, 4320, 4320, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 34560, 4320, 34560, 4320, 4320, 4320, 17280, 17280, 34560, 4320, 4320, 34560, 4320, 34560, 17280, 4320, 34560, 17280, 17280, 4320, 34560, 34560, 34560, 4320, 17280, 34560, 4320, 34560, 17280, 17280, 34560, 34560, 4320, 17280, 34560, 4320, 17280, 17280, 4320, 17280, 4320, 17280, 34560, 34560, 17280, 4320, 34560, 4320, 34560, 17280, 17280, 17280, 17280, 17280, 4320, 4320, 34560, 4320, 34560, 4320, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 4320, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 4320, 17280, 34560, 34560, 4320, 4320, 34560, 4320, 4320, 4320, 17280, 4320, 17280, 34560, 34560, 17280, 17280, 4320, 34560, 17280, 34560, 4320, 17280, 17280, 4320, 4320, 17280, 4320, 34560, 34560, 4320, 34560, 34560, 4320, 17280, 34560, 4320, 4320, 17280, 17280, 4320, 4320, 34560, 34560, 34560, 34560, 17280, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 34560, 17280, 17280, 17280, 34560, 4320, 17280, 17280, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 4320, 4320, 17280, 4320, 34560, 34560, 34560, 17280, 4320, 34560, 34560, 17280, 17280, 34560, 34560, 4320, 34560, 34560, 17280, 4320, 34560, 17280, 17280, 34560, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 34560, 4320, 17280, 34560, 4320, 17280, 17280, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 34560, 4320, 4320, 4320, 17280, 4320, 17280, 17280, 4320, 34560, 17280, 34560, 4320, 34560, 4320, 17280, 17280, 17280, 17280, 4320, 17280, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 17280, 34560, 17280, 17280, 17280, 4320, 17280, 4320, 4320, 34560, 4320, 17280, 4320, 4320, 17280, 34560, 17280, 34560, 4320, 34560, 34560, 17280, 34560, 17280, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 4320]
Prompts retrieved: 7188480 . Total input tokens: 1603616705 . Total output tokens: 1411485711
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 9.126950920093805,
    "estimated_duration": 3600.113232732361,
    "input_throughput": 3940.682996026942,
    "output_throughput": 3434.700299861168,
    "total_throughput": 7375.383295888109,
    "itl": 151.08981978942936,
    "ttft": 2305660.857707028,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2690,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.787380295945358,
    "arrivals": 2395765,
    "finished_requests": 57636,
    "scheduler_time": 121.50971767940983
}
#Debug simulation 
Total elapsed time: 9.127019330859184. Arrivals time: 0.7674261112697423 Scheduler time: 8.208186118863523 Scheduler overhead time: 0.038689976558089256 Adapter cache time: 0.05757088819518685 Engine time: 0.03821426909416914 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.4_size_8-8-16/adapters_384_slots_128_rate_3.2-1.6-0.4_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.4_size_8-8-16/adapters_384_slots_128_rate_3.2-1.6-0.4_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [128 128 128]
Adapter prompts. [4320, 4320, 34560, 17280, 4320, 34560, 34560, 4320, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 4320, 34560, 4320, 34560, 17280, 17280, 17280, 4320, 4320, 17280, 4320, 34560, 4320, 34560, 17280, 34560, 17280, 4320, 17280, 34560, 17280, 34560, 4320, 34560, 34560, 34560, 34560, 4320, 17280, 17280, 17280, 34560, 17280, 4320, 17280, 4320, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 4320, 4320, 34560, 17280, 17280, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 34560, 4320, 17280, 34560, 4320, 34560, 17280, 4320, 34560, 34560, 34560, 34560, 17280, 4320, 17280, 34560, 34560, 17280, 4320, 4320, 34560, 17280, 17280, 4320, 4320, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 34560, 4320, 34560, 4320, 4320, 4320, 17280, 17280, 34560, 4320, 4320, 34560, 4320, 34560, 17280, 4320, 34560, 17280, 17280, 4320, 34560, 34560, 34560, 4320, 17280, 34560, 4320, 34560, 17280, 17280, 34560, 34560, 4320, 17280, 34560, 4320, 17280, 17280, 4320, 17280, 4320, 17280, 34560, 34560, 17280, 4320, 34560, 4320, 34560, 17280, 17280, 17280, 17280, 17280, 4320, 4320, 34560, 4320, 34560, 4320, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 4320, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 4320, 17280, 34560, 34560, 4320, 4320, 34560, 4320, 4320, 4320, 17280, 4320, 17280, 34560, 34560, 17280, 17280, 4320, 34560, 17280, 34560, 4320, 17280, 17280, 4320, 4320, 17280, 4320, 34560, 34560, 4320, 34560, 34560, 4320, 17280, 34560, 4320, 4320, 17280, 17280, 4320, 4320, 34560, 34560, 34560, 34560, 17280, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 34560, 17280, 17280, 17280, 34560, 4320, 17280, 17280, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 4320, 4320, 17280, 4320, 34560, 34560, 34560, 17280, 4320, 34560, 34560, 17280, 17280, 34560, 34560, 4320, 34560, 34560, 17280, 4320, 34560, 17280, 17280, 34560, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 34560, 4320, 17280, 34560, 4320, 17280, 17280, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 34560, 4320, 4320, 4320, 17280, 4320, 17280, 17280, 4320, 34560, 17280, 34560, 4320, 34560, 4320, 17280, 17280, 17280, 17280, 4320, 17280, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 17280, 34560, 17280, 17280, 17280, 4320, 17280, 4320, 4320, 34560, 4320, 17280, 4320, 4320, 17280, 34560, 17280, 34560, 4320, 34560, 34560, 17280, 34560, 17280, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 4320]
Prompts retrieved: 7188480 . Total input tokens: 1603616705 . Total output tokens: 1411485711
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 6.901628821156919,
    "estimated_duration": 3600.016420759859,
    "input_throughput": 3712.464177365905,
    "output_throughput": 3239.821055465684,
    "total_throughput": 6952.2852328315885,
    "itl": 134.7507805786458,
    "ttft": 2332854.9851790643,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4011,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 29.3207862172128,
    "arrivals": 2395765,
    "finished_requests": 54345,
    "scheduler_time": 127.26309169503178
}
#Debug simulation 
Total elapsed time: 6.901693784166127. Arrivals time: 0.41039491910487413 Scheduler time: 6.309401727281511 Scheduler overhead time: 0.04159604059532285 Adapter cache time: 0.08066047681495547 Engine time: 0.04111916199326515 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.4_size_8-16-16/adapters_384_slots_128_rate_3.2-1.6-0.4_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.4_size_8-16-16/adapters_384_slots_128_rate_3.2-1.6-0.4_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [128 128 128]
Adapter prompts. [4320, 4320, 34560, 17280, 4320, 34560, 34560, 4320, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 4320, 34560, 4320, 34560, 17280, 17280, 17280, 4320, 4320, 17280, 4320, 34560, 4320, 34560, 17280, 34560, 17280, 4320, 17280, 34560, 17280, 34560, 4320, 34560, 34560, 34560, 34560, 4320, 17280, 17280, 17280, 34560, 17280, 4320, 17280, 4320, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 4320, 4320, 34560, 17280, 17280, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 34560, 4320, 17280, 34560, 4320, 34560, 17280, 4320, 34560, 34560, 34560, 34560, 17280, 4320, 17280, 34560, 34560, 17280, 4320, 4320, 34560, 17280, 17280, 4320, 4320, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 34560, 4320, 34560, 4320, 4320, 4320, 17280, 17280, 34560, 4320, 4320, 34560, 4320, 34560, 17280, 4320, 34560, 17280, 17280, 4320, 34560, 34560, 34560, 4320, 17280, 34560, 4320, 34560, 17280, 17280, 34560, 34560, 4320, 17280, 34560, 4320, 17280, 17280, 4320, 17280, 4320, 17280, 34560, 34560, 17280, 4320, 34560, 4320, 34560, 17280, 17280, 17280, 17280, 17280, 4320, 4320, 34560, 4320, 34560, 4320, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 4320, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 4320, 17280, 34560, 34560, 4320, 4320, 34560, 4320, 4320, 4320, 17280, 4320, 17280, 34560, 34560, 17280, 17280, 4320, 34560, 17280, 34560, 4320, 17280, 17280, 4320, 4320, 17280, 4320, 34560, 34560, 4320, 34560, 34560, 4320, 17280, 34560, 4320, 4320, 17280, 17280, 4320, 4320, 34560, 34560, 34560, 34560, 17280, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 34560, 17280, 17280, 17280, 34560, 4320, 17280, 17280, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 4320, 4320, 17280, 4320, 34560, 34560, 34560, 17280, 4320, 34560, 34560, 17280, 17280, 34560, 34560, 4320, 34560, 34560, 17280, 4320, 34560, 17280, 17280, 34560, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 34560, 4320, 17280, 34560, 4320, 17280, 17280, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 34560, 4320, 4320, 4320, 17280, 4320, 17280, 17280, 4320, 34560, 17280, 34560, 4320, 34560, 4320, 17280, 17280, 17280, 17280, 4320, 17280, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 17280, 34560, 17280, 17280, 17280, 4320, 17280, 4320, 4320, 34560, 4320, 17280, 4320, 4320, 17280, 34560, 17280, 34560, 4320, 34560, 34560, 17280, 34560, 17280, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 4320]
Prompts retrieved: 7188480 . Total input tokens: 1603616705 . Total output tokens: 1411485711
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 6.730141940061003,
    "estimated_duration": 3600.125001667221,
    "input_throughput": 3714.314917900744,
    "output_throughput": 3241.3499516255556,
    "total_throughput": 6955.664869526299,
    "itl": 134.6793502126868,
    "ttft": 2332714.0105293947,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4016,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 27.53552456785071,
    "arrivals": 2395765,
    "finished_requests": 54373,
    "scheduler_time": 127.32969631239554
}
#Debug simulation 
Total elapsed time: 6.730265873949975. Arrivals time: 0.25099419616162777 Scheduler time: 6.29817096889019 Scheduler overhead time: 0.04120816756039858 Adapter cache time: 0.08011153573170304 Engine time: 0.041152595076709986 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.4_size_16-16-16/adapters_384_slots_128_rate_3.2-1.6-0.4_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.4_size_16-16-16/adapters_384_slots_128_rate_3.2-1.6-0.4_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [128 128 128]
Adapter prompts. [4320, 4320, 34560, 17280, 4320, 34560, 34560, 4320, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 4320, 34560, 4320, 34560, 17280, 17280, 17280, 4320, 4320, 17280, 4320, 34560, 4320, 34560, 17280, 34560, 17280, 4320, 17280, 34560, 17280, 34560, 4320, 34560, 34560, 34560, 34560, 4320, 17280, 17280, 17280, 34560, 17280, 4320, 17280, 4320, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 4320, 4320, 34560, 17280, 17280, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 34560, 4320, 17280, 34560, 4320, 34560, 17280, 4320, 34560, 34560, 34560, 34560, 17280, 4320, 17280, 34560, 34560, 17280, 4320, 4320, 34560, 17280, 17280, 4320, 4320, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 34560, 4320, 34560, 4320, 4320, 4320, 17280, 17280, 34560, 4320, 4320, 34560, 4320, 34560, 17280, 4320, 34560, 17280, 17280, 4320, 34560, 34560, 34560, 4320, 17280, 34560, 4320, 34560, 17280, 17280, 34560, 34560, 4320, 17280, 34560, 4320, 17280, 17280, 4320, 17280, 4320, 17280, 34560, 34560, 17280, 4320, 34560, 4320, 34560, 17280, 17280, 17280, 17280, 17280, 4320, 4320, 34560, 4320, 34560, 4320, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 4320, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 4320, 17280, 34560, 34560, 4320, 4320, 34560, 4320, 4320, 4320, 17280, 4320, 17280, 34560, 34560, 17280, 17280, 4320, 34560, 17280, 34560, 4320, 17280, 17280, 4320, 4320, 17280, 4320, 34560, 34560, 4320, 34560, 34560, 4320, 17280, 34560, 4320, 4320, 17280, 17280, 4320, 4320, 34560, 34560, 34560, 34560, 17280, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 34560, 17280, 17280, 17280, 34560, 4320, 17280, 17280, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 4320, 4320, 17280, 4320, 34560, 34560, 34560, 17280, 4320, 34560, 34560, 17280, 17280, 34560, 34560, 4320, 34560, 34560, 17280, 4320, 34560, 17280, 17280, 34560, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 34560, 4320, 17280, 34560, 4320, 17280, 17280, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 34560, 4320, 4320, 4320, 17280, 4320, 17280, 17280, 4320, 34560, 17280, 34560, 4320, 34560, 4320, 17280, 17280, 17280, 17280, 4320, 17280, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 17280, 34560, 17280, 17280, 17280, 4320, 17280, 4320, 4320, 34560, 4320, 17280, 4320, 4320, 17280, 34560, 17280, 34560, 4320, 34560, 34560, 17280, 34560, 17280, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 4320]
Prompts retrieved: 7188480 . Total input tokens: 1603616705 . Total output tokens: 1411485711
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 6.799412908963859,
    "estimated_duration": 3600.091538328776,
    "input_throughput": 3717.0807623997457,
    "output_throughput": 3243.560302752945,
    "total_throughput": 6960.64106515269,
    "itl": 134.5514070786762,
    "ttft": 2332258.501507194,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3937,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 25.133496743028434,
    "arrivals": 2395765,
    "finished_requests": 54390,
    "scheduler_time": 127.43350117334296
}
#Debug simulation 
Total elapsed time: 6.799481322988868. Arrivals time: 0.24502213299274445 Scheduler time: 6.374309042934328 Scheduler overhead time: 0.041382066905498505 Adapter cache time: 0.07936276961117983 Engine time: 0.04087781114503741 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.1_size_8-8-8/adapters_384_slots_128_rate_3.2-1.6-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.1_size_8-8-8/adapters_384_slots_128_rate_3.2-1.6-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [128 128 128]
Adapter prompts. [1080, 1080, 34560, 17280, 1080, 34560, 34560, 1080, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 1080, 34560, 1080, 34560, 17280, 17280, 17280, 1080, 1080, 17280, 1080, 34560, 1080, 34560, 17280, 34560, 17280, 1080, 17280, 34560, 17280, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 17280, 17280, 17280, 34560, 17280, 1080, 17280, 1080, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 1080, 1080, 34560, 17280, 17280, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 34560, 1080, 17280, 34560, 1080, 34560, 17280, 1080, 34560, 34560, 34560, 34560, 17280, 1080, 17280, 34560, 34560, 17280, 1080, 1080, 34560, 17280, 17280, 1080, 1080, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 17280, 17280, 34560, 1080, 1080, 34560, 1080, 34560, 17280, 1080, 34560, 17280, 17280, 1080, 34560, 34560, 34560, 1080, 17280, 34560, 1080, 34560, 17280, 17280, 34560, 34560, 1080, 17280, 34560, 1080, 17280, 17280, 1080, 17280, 1080, 17280, 34560, 34560, 17280, 1080, 34560, 1080, 34560, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 34560, 1080, 34560, 1080, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 1080, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 1080, 17280, 34560, 34560, 1080, 1080, 34560, 1080, 1080, 1080, 17280, 1080, 17280, 34560, 34560, 17280, 17280, 1080, 34560, 17280, 34560, 1080, 17280, 17280, 1080, 1080, 17280, 1080, 34560, 34560, 1080, 34560, 34560, 1080, 17280, 34560, 1080, 1080, 17280, 17280, 1080, 1080, 34560, 34560, 34560, 34560, 17280, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 34560, 17280, 17280, 17280, 34560, 1080, 17280, 17280, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 1080, 1080, 17280, 1080, 34560, 34560, 34560, 17280, 1080, 34560, 34560, 17280, 17280, 34560, 34560, 1080, 34560, 34560, 17280, 1080, 34560, 17280, 17280, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 34560, 1080, 17280, 34560, 1080, 17280, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 34560, 1080, 1080, 1080, 17280, 1080, 17280, 17280, 1080, 34560, 17280, 34560, 1080, 34560, 1080, 17280, 17280, 17280, 17280, 1080, 17280, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 17280, 34560, 17280, 17280, 17280, 1080, 17280, 1080, 1080, 34560, 1080, 17280, 1080, 1080, 17280, 34560, 17280, 34560, 1080, 34560, 34560, 17280, 34560, 17280, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 6773760 . Total input tokens: 1510742719 . Total output tokens: 1330273881
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 7.279890350997448,
    "estimated_duration": 3600.114294070722,
    "input_throughput": 3921.875764681664,
    "output_throughput": 3429.5586171624627,
    "total_throughput": 7351.434381844127,
    "itl": 150.91354956047212,
    "ttft": 2312284.0854902794,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3046,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.14139791131898,
    "arrivals": 2257312,
    "finished_requests": 57130,
    "scheduler_time": 121.5435247962315
}
#Debug simulation 
Total elapsed time: 7.279956001788378. Arrivals time: 0.2581355581060052 Scheduler time: 6.8661937466822565 Scheduler overhead time: 0.03799362573772669 Adapter cache time: 0.06286403676494956 Engine time: 0.03772518876940012 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.1_size_8-8-16/adapters_384_slots_128_rate_3.2-1.6-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.1_size_8-8-16/adapters_384_slots_128_rate_3.2-1.6-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [128 128 128]
Adapter prompts. [1080, 1080, 34560, 17280, 1080, 34560, 34560, 1080, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 1080, 34560, 1080, 34560, 17280, 17280, 17280, 1080, 1080, 17280, 1080, 34560, 1080, 34560, 17280, 34560, 17280, 1080, 17280, 34560, 17280, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 17280, 17280, 17280, 34560, 17280, 1080, 17280, 1080, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 1080, 1080, 34560, 17280, 17280, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 34560, 1080, 17280, 34560, 1080, 34560, 17280, 1080, 34560, 34560, 34560, 34560, 17280, 1080, 17280, 34560, 34560, 17280, 1080, 1080, 34560, 17280, 17280, 1080, 1080, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 17280, 17280, 34560, 1080, 1080, 34560, 1080, 34560, 17280, 1080, 34560, 17280, 17280, 1080, 34560, 34560, 34560, 1080, 17280, 34560, 1080, 34560, 17280, 17280, 34560, 34560, 1080, 17280, 34560, 1080, 17280, 17280, 1080, 17280, 1080, 17280, 34560, 34560, 17280, 1080, 34560, 1080, 34560, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 34560, 1080, 34560, 1080, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 1080, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 1080, 17280, 34560, 34560, 1080, 1080, 34560, 1080, 1080, 1080, 17280, 1080, 17280, 34560, 34560, 17280, 17280, 1080, 34560, 17280, 34560, 1080, 17280, 17280, 1080, 1080, 17280, 1080, 34560, 34560, 1080, 34560, 34560, 1080, 17280, 34560, 1080, 1080, 17280, 17280, 1080, 1080, 34560, 34560, 34560, 34560, 17280, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 34560, 17280, 17280, 17280, 34560, 1080, 17280, 17280, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 1080, 1080, 17280, 1080, 34560, 34560, 34560, 17280, 1080, 34560, 34560, 17280, 17280, 34560, 34560, 1080, 34560, 34560, 17280, 1080, 34560, 17280, 17280, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 34560, 1080, 17280, 34560, 1080, 17280, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 34560, 1080, 1080, 1080, 17280, 1080, 17280, 17280, 1080, 34560, 17280, 34560, 1080, 34560, 1080, 17280, 17280, 17280, 17280, 1080, 17280, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 17280, 34560, 17280, 17280, 17280, 1080, 17280, 1080, 1080, 34560, 1080, 17280, 1080, 1080, 17280, 34560, 17280, 34560, 1080, 34560, 34560, 17280, 34560, 17280, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 6773760 . Total input tokens: 1510742719 . Total output tokens: 1330273881
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 6.199650635942817,
    "estimated_duration": 3600.1377195395953,
    "input_throughput": 3697.912701434804,
    "output_throughput": 3231.140835769925,
    "total_throughput": 6929.053537204729,
    "itl": 134.00664584028652,
    "ttft": 2339355.9428552124,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3745,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 27.360289483064978,
    "arrivals": 2257312,
    "finished_requests": 53803,
    "scheduler_time": 127.64656053677668
}
#Debug simulation 
Total elapsed time: 6.199717136099935. Arrivals time: 0.2545523904263973 Scheduler time: 5.768419456668198 Scheduler overhead time: 0.04107441334053874 Adapter cache time: 0.07581992773339152 Engine time: 0.0412333058193326 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.1_size_8-16-16/adapters_384_slots_128_rate_3.2-1.6-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.1_size_8-16-16/adapters_384_slots_128_rate_3.2-1.6-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [128 128 128]
Adapter prompts. [1080, 1080, 34560, 17280, 1080, 34560, 34560, 1080, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 1080, 34560, 1080, 34560, 17280, 17280, 17280, 1080, 1080, 17280, 1080, 34560, 1080, 34560, 17280, 34560, 17280, 1080, 17280, 34560, 17280, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 17280, 17280, 17280, 34560, 17280, 1080, 17280, 1080, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 1080, 1080, 34560, 17280, 17280, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 34560, 1080, 17280, 34560, 1080, 34560, 17280, 1080, 34560, 34560, 34560, 34560, 17280, 1080, 17280, 34560, 34560, 17280, 1080, 1080, 34560, 17280, 17280, 1080, 1080, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 17280, 17280, 34560, 1080, 1080, 34560, 1080, 34560, 17280, 1080, 34560, 17280, 17280, 1080, 34560, 34560, 34560, 1080, 17280, 34560, 1080, 34560, 17280, 17280, 34560, 34560, 1080, 17280, 34560, 1080, 17280, 17280, 1080, 17280, 1080, 17280, 34560, 34560, 17280, 1080, 34560, 1080, 34560, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 34560, 1080, 34560, 1080, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 1080, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 1080, 17280, 34560, 34560, 1080, 1080, 34560, 1080, 1080, 1080, 17280, 1080, 17280, 34560, 34560, 17280, 17280, 1080, 34560, 17280, 34560, 1080, 17280, 17280, 1080, 1080, 17280, 1080, 34560, 34560, 1080, 34560, 34560, 1080, 17280, 34560, 1080, 1080, 17280, 17280, 1080, 1080, 34560, 34560, 34560, 34560, 17280, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 34560, 17280, 17280, 17280, 34560, 1080, 17280, 17280, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 1080, 1080, 17280, 1080, 34560, 34560, 34560, 17280, 1080, 34560, 34560, 17280, 17280, 34560, 34560, 1080, 34560, 34560, 17280, 1080, 34560, 17280, 17280, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 34560, 1080, 17280, 34560, 1080, 17280, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 34560, 1080, 1080, 1080, 17280, 1080, 17280, 17280, 1080, 34560, 17280, 34560, 1080, 34560, 1080, 17280, 17280, 17280, 17280, 1080, 17280, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 17280, 34560, 17280, 17280, 17280, 1080, 17280, 1080, 1080, 34560, 1080, 17280, 1080, 1080, 17280, 34560, 17280, 34560, 1080, 34560, 34560, 17280, 34560, 17280, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 6773760 . Total input tokens: 1510742719 . Total output tokens: 1330273881
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 6.1939017050899565,
    "estimated_duration": 3600.069881736389,
    "input_throughput": 3692.711374143664,
    "output_throughput": 3227.5942916962604,
    "total_throughput": 6920.305665839925,
    "itl": 133.4943373768519,
    "ttft": 2340066.1556835677,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3695,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 25.330805196916426,
    "arrivals": 2257312,
    "finished_requests": 53753,
    "scheduler_time": 127.91093868368644
}
#Debug simulation 
Total elapsed time: 6.1940042222850025. Arrivals time: 0.23964269226416945 Scheduler time: 5.778441661503166 Scheduler overhead time: 0.04130769893527031 Adapter cache time: 0.07477947371080518 Engine time: 0.04111859016120434 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.1_size_16-16-16/adapters_384_slots_128_rate_3.2-1.6-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.1_size_16-16-16/adapters_384_slots_128_rate_3.2-1.6-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [128 128 128]
Adapter prompts. [1080, 1080, 34560, 17280, 1080, 34560, 34560, 1080, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 1080, 34560, 1080, 34560, 17280, 17280, 17280, 1080, 1080, 17280, 1080, 34560, 1080, 34560, 17280, 34560, 17280, 1080, 17280, 34560, 17280, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 17280, 17280, 17280, 34560, 17280, 1080, 17280, 1080, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 1080, 1080, 34560, 17280, 17280, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 34560, 1080, 17280, 34560, 1080, 34560, 17280, 1080, 34560, 34560, 34560, 34560, 17280, 1080, 17280, 34560, 34560, 17280, 1080, 1080, 34560, 17280, 17280, 1080, 1080, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 17280, 17280, 34560, 1080, 1080, 34560, 1080, 34560, 17280, 1080, 34560, 17280, 17280, 1080, 34560, 34560, 34560, 1080, 17280, 34560, 1080, 34560, 17280, 17280, 34560, 34560, 1080, 17280, 34560, 1080, 17280, 17280, 1080, 17280, 1080, 17280, 34560, 34560, 17280, 1080, 34560, 1080, 34560, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 34560, 1080, 34560, 1080, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 1080, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 1080, 17280, 34560, 34560, 1080, 1080, 34560, 1080, 1080, 1080, 17280, 1080, 17280, 34560, 34560, 17280, 17280, 1080, 34560, 17280, 34560, 1080, 17280, 17280, 1080, 1080, 17280, 1080, 34560, 34560, 1080, 34560, 34560, 1080, 17280, 34560, 1080, 1080, 17280, 17280, 1080, 1080, 34560, 34560, 34560, 34560, 17280, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 34560, 17280, 17280, 17280, 34560, 1080, 17280, 17280, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 1080, 1080, 17280, 1080, 34560, 34560, 34560, 17280, 1080, 34560, 34560, 17280, 17280, 34560, 34560, 1080, 34560, 34560, 17280, 1080, 34560, 17280, 17280, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 34560, 1080, 17280, 34560, 1080, 17280, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 34560, 1080, 1080, 1080, 17280, 1080, 17280, 17280, 1080, 34560, 17280, 34560, 1080, 34560, 1080, 17280, 17280, 17280, 17280, 1080, 17280, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 17280, 34560, 17280, 17280, 17280, 1080, 17280, 1080, 1080, 34560, 1080, 17280, 1080, 1080, 17280, 34560, 17280, 34560, 1080, 34560, 34560, 17280, 34560, 17280, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 6773760 . Total input tokens: 1510742719 . Total output tokens: 1330273881
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 6.186357531230897,
    "estimated_duration": 3600.0514132293465,
    "input_throughput": 3700.586594692414,
    "output_throughput": 3234.8801901007996,
    "total_throughput": 6935.466784793213,
    "itl": 133.8665106096164,
    "ttft": 2338346.8033153093,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3695,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 23.58858787541016,
    "arrivals": 2257312,
    "finished_requests": 53852,
    "scheduler_time": 127.79087628636651
}
#Debug simulation 
Total elapsed time: 6.1864272858947515. Arrivals time: 0.2376186097972095 Scheduler time: 5.773085183463991 Scheduler overhead time: 0.04111397033557296 Adapter cache time: 0.07484486838802695 Engine time: 0.041076540015637875 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.05_size_8-8-8/adapters_384_slots_128_rate_3.2-1.6-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 253568,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.05_size_8-8-8/adapters_384_slots_128_rate_3.2-1.6-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 34560, 17280, 540, 34560, 34560, 540, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 540, 34560, 540, 34560, 17280, 17280, 17280, 540, 540, 17280, 540, 34560, 540, 34560, 17280, 34560, 17280, 540, 17280, 34560, 17280, 34560, 540, 34560, 34560, 34560, 34560, 540, 17280, 17280, 17280, 34560, 17280, 540, 17280, 540, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 540, 540, 34560, 17280, 17280, 540, 540, 540, 17280, 540, 17280, 540, 34560, 540, 17280, 34560, 540, 34560, 17280, 540, 34560, 34560, 34560, 34560, 17280, 540, 17280, 34560, 34560, 17280, 540, 540, 34560, 17280, 17280, 540, 540, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 540, 17280, 17280, 17280, 17280, 540, 540, 34560, 540, 34560, 540, 540, 540, 17280, 17280, 34560, 540, 540, 34560, 540, 34560, 17280, 540, 34560, 17280, 17280, 540, 34560, 34560, 34560, 540, 17280, 34560, 540, 34560, 17280, 17280, 34560, 34560, 540, 17280, 34560, 540, 17280, 17280, 540, 17280, 540, 17280, 34560, 34560, 17280, 540, 34560, 540, 34560, 17280, 17280, 17280, 17280, 17280, 540, 540, 34560, 540, 34560, 540, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 540, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 540, 540, 540, 540, 540, 17280, 540, 540, 17280, 34560, 34560, 540, 540, 34560, 540, 540, 540, 17280, 540, 17280, 34560, 34560, 17280, 17280, 540, 34560, 17280, 34560, 540, 17280, 17280, 540, 540, 17280, 540, 34560, 34560, 540, 34560, 34560, 540, 17280, 34560, 540, 540, 17280, 17280, 540, 540, 34560, 34560, 34560, 34560, 17280, 540, 17280, 17280, 540, 540, 540, 540, 540, 540, 540, 540, 17280, 34560, 17280, 17280, 17280, 34560, 540, 17280, 17280, 34560, 34560, 540, 34560, 34560, 540, 34560, 540, 540, 17280, 540, 34560, 34560, 34560, 17280, 540, 34560, 34560, 17280, 17280, 34560, 34560, 540, 34560, 34560, 17280, 540, 34560, 17280, 17280, 34560, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 34560, 540, 17280, 34560, 540, 17280, 17280, 17280, 17280, 540, 17280, 540, 17280, 17280, 540, 34560, 540, 540, 540, 17280, 540, 17280, 17280, 540, 34560, 17280, 34560, 540, 34560, 540, 17280, 17280, 17280, 17280, 540, 17280, 34560, 34560, 540, 34560, 34560, 540, 34560, 17280, 34560, 17280, 17280, 17280, 540, 17280, 540, 540, 34560, 540, 17280, 540, 540, 17280, 34560, 17280, 34560, 540, 34560, 34560, 17280, 34560, 17280, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 6704640 . Total input tokens: 1495324409 . Total output tokens: 1316648793
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 7.242576974909753,
    "estimated_duration": 3600.1173227571317,
    "input_throughput": 3916.1918171051557,
    "output_throughput": 3435.460261758354,
    "total_throughput": 7351.65207886351,
    "itl": 151.70143749362984,
    "ttft": 2310475.8156712847,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3048,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.154622729382876,
    "arrivals": 2233996,
    "finished_requests": 57345,
    "scheduler_time": 121.27003146651332
}
#Debug simulation 
Total elapsed time: 7.242644311860204. Arrivals time: 0.4103652583435178 Scheduler time: 6.67776076355949 Scheduler overhead time: 0.037543090526014566 Adapter cache time: 0.06243707099929452 Engine time: 0.03770417207852006 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.05_size_8-8-16/adapters_384_slots_128_rate_3.2-1.6-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.05_size_8-8-16/adapters_384_slots_128_rate_3.2-1.6-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 34560, 17280, 540, 34560, 34560, 540, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 540, 34560, 540, 34560, 17280, 17280, 17280, 540, 540, 17280, 540, 34560, 540, 34560, 17280, 34560, 17280, 540, 17280, 34560, 17280, 34560, 540, 34560, 34560, 34560, 34560, 540, 17280, 17280, 17280, 34560, 17280, 540, 17280, 540, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 540, 540, 34560, 17280, 17280, 540, 540, 540, 17280, 540, 17280, 540, 34560, 540, 17280, 34560, 540, 34560, 17280, 540, 34560, 34560, 34560, 34560, 17280, 540, 17280, 34560, 34560, 17280, 540, 540, 34560, 17280, 17280, 540, 540, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 540, 17280, 17280, 17280, 17280, 540, 540, 34560, 540, 34560, 540, 540, 540, 17280, 17280, 34560, 540, 540, 34560, 540, 34560, 17280, 540, 34560, 17280, 17280, 540, 34560, 34560, 34560, 540, 17280, 34560, 540, 34560, 17280, 17280, 34560, 34560, 540, 17280, 34560, 540, 17280, 17280, 540, 17280, 540, 17280, 34560, 34560, 17280, 540, 34560, 540, 34560, 17280, 17280, 17280, 17280, 17280, 540, 540, 34560, 540, 34560, 540, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 540, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 540, 540, 540, 540, 540, 17280, 540, 540, 17280, 34560, 34560, 540, 540, 34560, 540, 540, 540, 17280, 540, 17280, 34560, 34560, 17280, 17280, 540, 34560, 17280, 34560, 540, 17280, 17280, 540, 540, 17280, 540, 34560, 34560, 540, 34560, 34560, 540, 17280, 34560, 540, 540, 17280, 17280, 540, 540, 34560, 34560, 34560, 34560, 17280, 540, 17280, 17280, 540, 540, 540, 540, 540, 540, 540, 540, 17280, 34560, 17280, 17280, 17280, 34560, 540, 17280, 17280, 34560, 34560, 540, 34560, 34560, 540, 34560, 540, 540, 17280, 540, 34560, 34560, 34560, 17280, 540, 34560, 34560, 17280, 17280, 34560, 34560, 540, 34560, 34560, 17280, 540, 34560, 17280, 17280, 34560, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 34560, 540, 17280, 34560, 540, 17280, 17280, 17280, 17280, 540, 17280, 540, 17280, 17280, 540, 34560, 540, 540, 540, 17280, 540, 17280, 17280, 540, 34560, 17280, 34560, 540, 34560, 540, 17280, 17280, 17280, 17280, 540, 17280, 34560, 34560, 540, 34560, 34560, 540, 34560, 17280, 34560, 17280, 17280, 17280, 540, 17280, 540, 540, 34560, 540, 17280, 540, 540, 17280, 34560, 17280, 34560, 540, 34560, 34560, 17280, 34560, 17280, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 6704640 . Total input tokens: 1495324409 . Total output tokens: 1316648793
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 6.01250791316852,
    "estimated_duration": 3600.1126850610312,
    "input_throughput": 3692.458587521864,
    "output_throughput": 3242.1987923975566,
    "total_throughput": 6934.65737991942,
    "itl": 134.49751075263333,
    "ttft": 2338401.9511859906,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3459,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 25.312372738331817,
    "arrivals": 2233996,
    "finished_requests": 54049,
    "scheduler_time": 127.4856657857223
}
#Debug simulation 
Total elapsed time: 6.012572183273733. Arrivals time: 0.23920236015692353 Scheduler time: 5.6007254384458065 Scheduler overhead time: 0.0410286458209157 Adapter cache time: 0.07193510141223669 Engine time: 0.04112869733944535 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.05_size_8-16-16/adapters_384_slots_128_rate_3.2-1.6-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 212032,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.05_size_8-16-16/adapters_384_slots_128_rate_3.2-1.6-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 34560, 17280, 540, 34560, 34560, 540, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 540, 34560, 540, 34560, 17280, 17280, 17280, 540, 540, 17280, 540, 34560, 540, 34560, 17280, 34560, 17280, 540, 17280, 34560, 17280, 34560, 540, 34560, 34560, 34560, 34560, 540, 17280, 17280, 17280, 34560, 17280, 540, 17280, 540, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 540, 540, 34560, 17280, 17280, 540, 540, 540, 17280, 540, 17280, 540, 34560, 540, 17280, 34560, 540, 34560, 17280, 540, 34560, 34560, 34560, 34560, 17280, 540, 17280, 34560, 34560, 17280, 540, 540, 34560, 17280, 17280, 540, 540, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 540, 17280, 17280, 17280, 17280, 540, 540, 34560, 540, 34560, 540, 540, 540, 17280, 17280, 34560, 540, 540, 34560, 540, 34560, 17280, 540, 34560, 17280, 17280, 540, 34560, 34560, 34560, 540, 17280, 34560, 540, 34560, 17280, 17280, 34560, 34560, 540, 17280, 34560, 540, 17280, 17280, 540, 17280, 540, 17280, 34560, 34560, 17280, 540, 34560, 540, 34560, 17280, 17280, 17280, 17280, 17280, 540, 540, 34560, 540, 34560, 540, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 540, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 540, 540, 540, 540, 540, 17280, 540, 540, 17280, 34560, 34560, 540, 540, 34560, 540, 540, 540, 17280, 540, 17280, 34560, 34560, 17280, 17280, 540, 34560, 17280, 34560, 540, 17280, 17280, 540, 540, 17280, 540, 34560, 34560, 540, 34560, 34560, 540, 17280, 34560, 540, 540, 17280, 17280, 540, 540, 34560, 34560, 34560, 34560, 17280, 540, 17280, 17280, 540, 540, 540, 540, 540, 540, 540, 540, 17280, 34560, 17280, 17280, 17280, 34560, 540, 17280, 17280, 34560, 34560, 540, 34560, 34560, 540, 34560, 540, 540, 17280, 540, 34560, 34560, 34560, 17280, 540, 34560, 34560, 17280, 17280, 34560, 34560, 540, 34560, 34560, 17280, 540, 34560, 17280, 17280, 34560, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 34560, 540, 17280, 34560, 540, 17280, 17280, 17280, 17280, 540, 17280, 540, 17280, 17280, 540, 34560, 540, 540, 540, 17280, 540, 17280, 17280, 540, 34560, 17280, 34560, 540, 34560, 540, 17280, 17280, 17280, 17280, 540, 17280, 34560, 34560, 540, 34560, 34560, 540, 34560, 17280, 34560, 17280, 17280, 17280, 540, 17280, 540, 540, 34560, 540, 17280, 540, 540, 17280, 34560, 17280, 34560, 540, 34560, 34560, 17280, 34560, 17280, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 6704640 . Total input tokens: 1495324409 . Total output tokens: 1316648793
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 6.023071598261595,
    "estimated_duration": 3600.0940690226043,
    "input_throughput": 3694.355132117658,
    "output_throughput": 3243.574688916464,
    "total_throughput": 6937.929821034121,
    "itl": 134.44003281771526,
    "ttft": 2338162.12236096,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3461,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 23.782827078863626,
    "arrivals": 2233996,
    "finished_requests": 54074,
    "scheduler_time": 127.53762128984623
}
#Debug simulation 
Total elapsed time: 6.023174166213721. Arrivals time: 0.23675877507776022 Scheduler time: 5.614406210370362 Scheduler overhead time: 0.040873049292713404 Adapter cache time: 0.0716547966003418 Engine time: 0.04089880548417568 
