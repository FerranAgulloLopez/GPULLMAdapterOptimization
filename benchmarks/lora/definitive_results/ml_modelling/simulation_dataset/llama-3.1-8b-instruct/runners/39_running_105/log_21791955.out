INFO 05-31 19:30:52 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 05-31 19:30:52 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-8/adapters_64_slots_32_rate_0.1-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-8/adapters_64_slots_32_rate_0.1-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [21 21 22]
Adapter prompts. [66, 270, 1080, 1080, 66, 1080, 66, 270, 66, 1080, 270, 1080, 66, 270, 1080, 1080, 1080, 66, 1080, 270, 270, 66, 66, 66, 1080, 66, 66, 66, 1080, 270, 66, 1080, 1080, 1080, 1080, 270, 270, 270, 1080, 66, 270, 270, 1080, 1080, 270, 1080, 66, 1080, 270, 270, 270, 1080, 270, 66, 66, 270, 270, 66, 270, 66, 66, 66, 1080, 270]
Prompts retrieved: 30816 . Total input tokens: 6814873 . Total output tokens: 6059781
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 1.1598574742674828,
    "estimated_duration": 3599.8692678192488,
    "input_throughput": 704.0600120279867,
    "output_throughput": 615.6718022548155,
    "total_throughput": 1319.7318142828021,
    "itl": 23.064764238571623,
    "ttft": 6624.589701104988,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2187,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.461338552874912,
    "arrivals": 10387,
    "finished_requests": 10368,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1599788991734385. Arrivals time: 0.036602630745619535 Scheduler time: 0.7483388376422226 Scheduler overhead time: 0.12776901805773377 Adapter cache time: 0.04766242718324065 Engine time: 0.13611662248149514 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-16/adapters_64_slots_32_rate_0.1-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-16/adapters_64_slots_32_rate_0.1-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [21 21 22]
Adapter prompts. [66, 270, 1080, 1080, 66, 1080, 66, 270, 66, 1080, 270, 1080, 66, 270, 1080, 1080, 1080, 66, 1080, 270, 270, 66, 66, 66, 1080, 66, 66, 66, 1080, 270, 66, 1080, 1080, 1080, 1080, 270, 270, 270, 1080, 66, 270, 270, 1080, 1080, 270, 1080, 66, 1080, 270, 270, 270, 1080, 270, 66, 66, 270, 270, 66, 270, 66, 66, 66, 1080, 270]
Prompts retrieved: 30816 . Total input tokens: 6814873 . Total output tokens: 6059781
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.1653703460469842,
    "estimated_duration": 3599.8700276106265,
    "input_throughput": 704.059863428531,
    "output_throughput": 615.6716723106443,
    "total_throughput": 1319.7315357391753,
    "itl": 23.07491395688204,
    "ttft": 6624.738086450733,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2186,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.970948029337155,
    "arrivals": 10387,
    "finished_requests": 10368,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1654805070720613. Arrivals time: 0.03714220505207777 Scheduler time: 0.7582744616083801 Scheduler overhead time: 0.12718037236481905 Adapter cache time: 0.04733853181824088 Engine time: 0.132082711905241 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-32/adapters_64_slots_32_rate_0.1-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-32/adapters_64_slots_32_rate_0.1-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [21 21 22]
Adapter prompts. [66, 270, 1080, 1080, 66, 1080, 66, 270, 66, 1080, 270, 1080, 66, 270, 1080, 1080, 1080, 66, 1080, 270, 270, 66, 66, 66, 1080, 66, 66, 66, 1080, 270, 66, 1080, 1080, 1080, 1080, 270, 270, 270, 1080, 66, 270, 270, 1080, 1080, 270, 1080, 66, 1080, 270, 270, 270, 1080, 270, 66, 66, 270, 270, 66, 270, 66, 66, 66, 1080, 270]
Prompts retrieved: 30816 . Total input tokens: 6814873 . Total output tokens: 6059781
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.1440893369726837,
    "estimated_duration": 3599.880583723968,
    "input_throughput": 704.0577988779037,
    "output_throughput": 615.6698669452155,
    "total_throughput": 1319.7276658231192,
    "itl": 23.078722631955337,
    "ttft": 6624.848069365629,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2187,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.409817380970054,
    "arrivals": 10387,
    "finished_requests": 10368,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1441604741849005. Arrivals time: 0.03574534459039569 Scheduler time: 0.7393427407369018 Scheduler overhead time: 0.12900702096521854 Adapter cache time: 0.046490464359521866 Engine time: 0.13030454330146313 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-16/adapters_64_slots_32_rate_0.1-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-16/adapters_64_slots_32_rate_0.1-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [21 21 22]
Adapter prompts. [66, 270, 1080, 1080, 66, 1080, 66, 270, 66, 1080, 270, 1080, 66, 270, 1080, 1080, 1080, 66, 1080, 270, 270, 66, 66, 66, 1080, 66, 66, 66, 1080, 270, 66, 1080, 1080, 1080, 1080, 270, 270, 270, 1080, 66, 270, 270, 1080, 1080, 270, 1080, 66, 1080, 270, 270, 270, 1080, 270, 66, 66, 270, 270, 66, 270, 66, 66, 66, 1080, 270]
Prompts retrieved: 30816 . Total input tokens: 6814873 . Total output tokens: 6059781
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 1.1714927819557488,
    "estimated_duration": 3599.8851422012326,
    "input_throughput": 704.0569073407178,
    "output_throughput": 615.6690873322611,
    "total_throughput": 1319.725994672979,
    "itl": 23.06625819827681,
    "ttft": 6624.734821865968,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2188,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.867586208675382,
    "arrivals": 10387,
    "finished_requests": 10368,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1715542050078511. Arrivals time: 0.03688268968835473 Scheduler time: 0.7582720285281539 Scheduler overhead time: 0.13069111574441195 Adapter cache time: 0.047243676614016294 Engine time: 0.13503419933840632 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-32/adapters_64_slots_32_rate_0.1-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-32/adapters_64_slots_32_rate_0.1-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [21 21 22]
Adapter prompts. [66, 270, 1080, 1080, 66, 1080, 66, 270, 66, 1080, 270, 1080, 66, 270, 1080, 1080, 1080, 66, 1080, 270, 270, 66, 66, 66, 1080, 66, 66, 66, 1080, 270, 66, 1080, 1080, 1080, 1080, 270, 270, 270, 1080, 66, 270, 270, 1080, 1080, 270, 1080, 66, 1080, 270, 270, 270, 1080, 270, 66, 66, 270, 270, 66, 270, 66, 66, 66, 1080, 270]
Prompts retrieved: 30816 . Total input tokens: 6814873 . Total output tokens: 6059781
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 1.145699294283986,
    "estimated_duration": 3599.876975945633,
    "input_throughput": 704.0585044810368,
    "output_throughput": 615.6704839664143,
    "total_throughput": 1319.7289884474512,
    "itl": 23.07617418108546,
    "ttft": 6624.918849461317,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2189,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.258825966189306,
    "arrivals": 10387,
    "finished_requests": 10368,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1457673669792712. Arrivals time: 0.03626123024150729 Scheduler time: 0.7422572150826454 Scheduler overhead time: 0.12760457023978233 Adapter cache time: 0.04673194233328104 Engine time: 0.13007611641660333 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-16/adapters_64_slots_32_rate_0.1-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-16/adapters_64_slots_32_rate_0.1-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [21 21 22]
Adapter prompts. [66, 270, 1080, 1080, 66, 1080, 66, 270, 66, 1080, 270, 1080, 66, 270, 1080, 1080, 1080, 66, 1080, 270, 270, 66, 66, 66, 1080, 66, 66, 66, 1080, 270, 66, 1080, 1080, 1080, 1080, 270, 270, 270, 1080, 66, 270, 270, 1080, 1080, 270, 1080, 66, 1080, 270, 270, 270, 1080, 270, 66, 66, 270, 270, 66, 270, 66, 66, 66, 1080, 270]
Prompts retrieved: 30816 . Total input tokens: 6814873 . Total output tokens: 6059781
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 1.1510315467603505,
    "estimated_duration": 3599.8847443530826,
    "input_throughput": 704.056985150914,
    "output_throughput": 615.6691553741083,
    "total_throughput": 1319.7261405250222,
    "itl": 23.061495845940637,
    "ttft": 6624.807372860933,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2183,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.936099413266225,
    "arrivals": 10387,
    "finished_requests": 10368,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1511139618232846. Arrivals time: 0.0362652032636106 Scheduler time: 0.7472000638954341 Scheduler overhead time: 0.1276176287792623 Adapter cache time: 0.047276065684854984 Engine time: 0.12972296169027686 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-32/adapters_64_slots_32_rate_0.1-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-32/adapters_64_slots_32_rate_0.1-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [21 21 22]
Adapter prompts. [66, 270, 1080, 1080, 66, 1080, 66, 270, 66, 1080, 270, 1080, 66, 270, 1080, 1080, 1080, 66, 1080, 270, 270, 66, 66, 66, 1080, 66, 66, 66, 1080, 270, 66, 1080, 1080, 1080, 1080, 270, 270, 270, 1080, 66, 270, 270, 1080, 1080, 270, 1080, 66, 1080, 270, 270, 270, 1080, 270, 66, 66, 270, 270, 66, 270, 66, 66, 66, 1080, 270]
Prompts retrieved: 30816 . Total input tokens: 6814873 . Total output tokens: 6059781
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.187910480890423,
    "estimated_duration": 3599.8793766704334,
    "input_throughput": 704.0580349512178,
    "output_throughput": 615.6700733817128,
    "total_throughput": 1319.7281083329306,
    "itl": 23.076687202858146,
    "ttft": 6624.822670915497,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2187,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.107167316954254,
    "arrivals": 10387,
    "finished_requests": 10368,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1879698908887804. Arrivals time: 0.03734436444938183 Scheduler time: 0.7773635797202587 Scheduler overhead time: 0.12725586025044322 Adapter cache time: 0.04778073774650693 Engine time: 0.1348992669954896 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-8/adapters_64_slots_32_rate_0.1-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-8/adapters_64_slots_32_rate_0.1-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 270, 1080, 1080, 33, 1080, 33, 270, 33, 1080, 270, 1080, 33, 270, 1080, 1080, 1080, 33, 1080, 270, 270, 33, 33, 33, 1080, 33, 33, 33, 1080, 270, 33, 1080, 1080, 1080, 1080, 270, 270, 270, 1080, 33, 270, 270, 1080, 1080, 270, 1080, 33, 1080, 270, 270, 270, 1080, 270, 33, 33, 270, 270, 33, 270, 33, 33, 33, 1080, 270]
Prompts retrieved: 30123 . Total input tokens: 6670775 . Total output tokens: 5919683
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 1.1815224629826844,
    "estimated_duration": 3599.765712213216,
    "input_throughput": 679.3192100539566,
    "output_throughput": 609.2504833187038,
    "total_throughput": 1288.5696933726604,
    "itl": 23.178345946208776,
    "ttft": 6433.634143827425,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1890,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.497453070385717,
    "arrivals": 10134,
    "finished_requests": 10116,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1815746938809752. Arrivals time: 0.037057116627693176 Scheduler time: 0.7678760387934744 Scheduler overhead time: 0.13015363551676273 Adapter cache time: 0.04673829535022378 Engine time: 0.13569379458203912 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-16/adapters_64_slots_32_rate_0.1-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-16/adapters_64_slots_32_rate_0.1-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 270, 1080, 1080, 33, 1080, 33, 270, 33, 1080, 270, 1080, 33, 270, 1080, 1080, 1080, 33, 1080, 270, 270, 33, 33, 33, 1080, 33, 33, 33, 1080, 270, 33, 1080, 1080, 1080, 1080, 270, 270, 270, 1080, 33, 270, 270, 1080, 1080, 270, 1080, 33, 1080, 270, 270, 270, 1080, 270, 33, 33, 270, 270, 33, 270, 33, 33, 33, 1080, 270]
Prompts retrieved: 30123 . Total input tokens: 6670775 . Total output tokens: 5919683
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.1797835705801845,
    "estimated_duration": 3599.7695100751907,
    "input_throughput": 679.3184933523485,
    "output_throughput": 609.2498405416491,
    "total_throughput": 1288.5683338939975,
    "itl": 23.187653427775984,
    "ttft": 6433.7418410265545,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1892,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.808101752307065,
    "arrivals": 10134,
    "finished_requests": 10116,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1798591879196465. Arrivals time: 0.036689240485429764 Scheduler time: 0.7729630614630878 Scheduler overhead time: 0.1273322869092226 Adapter cache time: 0.04666952043771744 Engine time: 0.1326918457634747 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-32/adapters_64_slots_32_rate_0.1-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-32/adapters_64_slots_32_rate_0.1-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 270, 1080, 1080, 33, 1080, 33, 270, 33, 1080, 270, 1080, 33, 270, 1080, 1080, 1080, 33, 1080, 270, 270, 33, 33, 33, 1080, 33, 33, 33, 1080, 270, 33, 1080, 1080, 1080, 1080, 270, 270, 270, 1080, 33, 270, 270, 1080, 1080, 270, 1080, 33, 1080, 270, 270, 270, 1080, 270, 33, 33, 270, 270, 33, 270, 33, 33, 33, 1080, 270]
Prompts retrieved: 30123 . Total input tokens: 6670775 . Total output tokens: 5919683
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.1881434340029955,
    "estimated_duration": 3599.7830265457847,
    "input_throughput": 679.3159426462721,
    "output_throughput": 609.2475529294531,
    "total_throughput": 1288.5634955757253,
    "itl": 23.190415933465495,
    "ttft": 6433.6373153724835,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1891,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.16796581869455,
    "arrivals": 10134,
    "finished_requests": 10116,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1882589301094413. Arrivals time: 0.036504294257611036 Scheduler time: 0.7753983619622886 Scheduler overhead time: 0.12887491006404161 Adapter cache time: 0.047245138324797153 Engine time: 0.13653238816186786 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-16/adapters_64_slots_32_rate_0.1-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-16/adapters_64_slots_32_rate_0.1-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 270, 1080, 1080, 33, 1080, 33, 270, 33, 1080, 270, 1080, 33, 270, 1080, 1080, 1080, 33, 1080, 270, 270, 33, 33, 33, 1080, 33, 33, 33, 1080, 270, 33, 1080, 1080, 1080, 1080, 270, 270, 270, 1080, 33, 270, 270, 1080, 1080, 270, 1080, 33, 1080, 270, 270, 270, 1080, 270, 33, 33, 270, 270, 33, 270, 33, 33, 33, 1080, 270]
Prompts retrieved: 30123 . Total input tokens: 6670775 . Total output tokens: 5919683
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 1.180538082960993,
    "estimated_duration": 3599.766582210846,
    "input_throughput": 679.3190458749496,
    "output_throughput": 609.2503360740244,
    "total_throughput": 1288.5693819489738,
    "itl": 23.180258052632258,
    "ttft": 6433.664597091467,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1892,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.800253325682387,
    "arrivals": 10134,
    "finished_requests": 10116,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1805895096622407. Arrivals time: 0.03665054775774479 Scheduler time: 0.7703722799196839 Scheduler overhead time: 0.12821712717413902 Adapter cache time: 0.04671395756304264 Engine time: 0.13471319479867816 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-32/adapters_64_slots_32_rate_0.1-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-32/adapters_64_slots_32_rate_0.1-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 270, 1080, 1080, 33, 1080, 33, 270, 33, 1080, 270, 1080, 33, 270, 1080, 1080, 1080, 33, 1080, 270, 270, 33, 33, 33, 1080, 33, 33, 33, 1080, 270, 33, 1080, 1080, 1080, 1080, 270, 270, 270, 1080, 33, 270, 270, 1080, 1080, 270, 1080, 33, 1080, 270, 270, 270, 1080, 270, 33, 33, 270, 270, 33, 270, 33, 33, 33, 1080, 270]
Prompts retrieved: 30123 . Total input tokens: 6670775 . Total output tokens: 5919683
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 1.1729497937485576,
    "estimated_duration": 3599.7657632358237,
    "input_throughput": 679.3192004253751,
    "output_throughput": 609.2504746832674,
    "total_throughput": 1288.5696751086425,
    "itl": 23.19052236605357,
    "ttft": 6433.771553090028,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1891,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.019514672043496,
    "arrivals": 10134,
    "finished_requests": 10116,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1730171306990087. Arrivals time: 0.03629749407991767 Scheduler time: 0.7609932832419872 Scheduler overhead time: 0.12883566971868277 Adapter cache time: 0.04680991964414716 Engine time: 0.13612872641533613 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-16/adapters_64_slots_32_rate_0.1-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-16/adapters_64_slots_32_rate_0.1-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 270, 1080, 1080, 33, 1080, 33, 270, 33, 1080, 270, 1080, 33, 270, 1080, 1080, 1080, 33, 1080, 270, 270, 33, 33, 33, 1080, 33, 33, 33, 1080, 270, 33, 1080, 1080, 1080, 1080, 270, 270, 270, 1080, 33, 270, 270, 1080, 1080, 270, 1080, 33, 1080, 270, 270, 270, 1080, 270, 33, 33, 270, 270, 33, 270, 33, 33, 33, 1080, 270]
Prompts retrieved: 30123 . Total input tokens: 6670775 . Total output tokens: 5919683
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 1.1752286227419972,
    "estimated_duration": 3599.782659545172,
    "input_throughput": 679.3160119030553,
    "output_throughput": 609.2476150427101,
    "total_throughput": 1288.5636269457652,
    "itl": 23.17665972015845,
    "ttft": 6433.418258060133,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1890,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.06561057767881,
    "arrivals": 10134,
    "finished_requests": 10116,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1752989538945258. Arrivals time: 0.036544757429510355 Scheduler time: 0.7672528019174933 Scheduler overhead time: 0.12802464794367552 Adapter cache time: 0.04665315989404917 Engine time: 0.13329694187268615 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-32/adapters_64_slots_32_rate_0.1-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-32/adapters_64_slots_32_rate_0.1-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 270, 1080, 1080, 33, 1080, 33, 270, 33, 1080, 270, 1080, 33, 270, 1080, 1080, 1080, 33, 1080, 270, 270, 33, 33, 33, 1080, 33, 33, 33, 1080, 270, 33, 1080, 1080, 1080, 1080, 270, 270, 270, 1080, 33, 270, 270, 1080, 1080, 270, 1080, 33, 1080, 270, 270, 270, 1080, 270, 33, 33, 270, 270, 33, 270, 33, 33, 33, 1080, 270]
Prompts retrieved: 30123 . Total input tokens: 6670775 . Total output tokens: 5919683
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.1823981530033052,
    "estimated_duration": 3599.7709342898006,
    "input_throughput": 679.3182245865462,
    "output_throughput": 609.2495994978327,
    "total_throughput": 1288.5678240843788,
    "itl": 23.189125233634773,
    "ttft": 6433.8666895983515,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1890,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.903737666830182,
    "arrivals": 10134,
    "finished_requests": 10116,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1824495820328593. Arrivals time: 0.03761606244370341 Scheduler time: 0.7664943980053067 Scheduler overhead time: 0.13099143700674176 Adapter cache time: 0.04669823870062828 Engine time: 0.13709046877920628 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-8/adapters_64_slots_32_rate_0.1-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-8/adapters_64_slots_32_rate_0.1-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 1080, 1080, 66, 1080, 66, 135, 66, 1080, 135, 1080, 66, 135, 1080, 1080, 1080, 66, 1080, 135, 135, 66, 66, 66, 1080, 66, 66, 66, 1080, 135, 66, 1080, 1080, 1080, 1080, 135, 135, 135, 1080, 66, 135, 135, 1080, 1080, 135, 1080, 66, 1080, 135, 135, 135, 1080, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 1080, 135]
Prompts retrieved: 27981 . Total input tokens: 6186519 . Total output tokens: 5499728
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 1.0950083611533046,
    "estimated_duration": 3600.00099883044,
    "input_throughput": 641.1975998756442,
    "output_throughput": 557.3417898083486,
    "total_throughput": 1198.5393896839928,
    "itl": 22.58707834964786,
    "ttft": 5363.886518372172,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1359,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.986263874420187,
    "arrivals": 9465,
    "finished_requests": 9450,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.095092176925391. Arrivals time: 0.03434312902390957 Scheduler time: 0.689843162894249 Scheduler overhead time: 0.13028213009238243 Adapter cache time: 0.043411285150796175 Engine time: 0.13267188984900713 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-16/adapters_64_slots_32_rate_0.1-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-16/adapters_64_slots_32_rate_0.1-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 1080, 1080, 66, 1080, 66, 135, 66, 1080, 135, 1080, 66, 135, 1080, 1080, 1080, 66, 1080, 135, 135, 66, 66, 66, 1080, 66, 66, 66, 1080, 135, 66, 1080, 1080, 1080, 1080, 135, 135, 135, 1080, 66, 135, 135, 1080, 1080, 135, 1080, 66, 1080, 135, 135, 135, 1080, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 1080, 135]
Prompts retrieved: 27981 . Total input tokens: 6186519 . Total output tokens: 5499728
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.092504056636244,
    "estimated_duration": 3600.006700171425,
    "input_throughput": 641.1965844091576,
    "output_throughput": 557.34090714455,
    "total_throughput": 1198.5374915537075,
    "itl": 22.59299303609184,
    "ttft": 5363.8032685266235,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1359,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.936253202003375,
    "arrivals": 9465,
    "finished_requests": 9450,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0925741358660161. Arrivals time: 0.0343778096139431 Scheduler time: 0.6870231991633773 Scheduler overhead time: 0.1302237673662603 Adapter cache time: 0.043596682138741016 Engine time: 0.13322351081296802 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-32/adapters_64_slots_32_rate_0.1-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-32/adapters_64_slots_32_rate_0.1-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 1080, 1080, 66, 1080, 66, 135, 66, 1080, 135, 1080, 66, 135, 1080, 1080, 1080, 66, 1080, 135, 135, 66, 66, 66, 1080, 66, 66, 66, 1080, 135, 66, 1080, 1080, 1080, 1080, 135, 135, 135, 1080, 66, 135, 135, 1080, 1080, 135, 1080, 66, 1080, 135, 135, 135, 1080, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 1080, 135]
Prompts retrieved: 27981 . Total input tokens: 6186519 . Total output tokens: 5499728
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.1388429920189083,
    "estimated_duration": 3600.0092665811817,
    "input_throughput": 641.1961273066759,
    "output_throughput": 557.3405098219222,
    "total_throughput": 1198.536637128598,
    "itl": 22.595442576538527,
    "ttft": 5363.882515903716,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1358,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.196635957476607,
    "arrivals": 9465,
    "finished_requests": 9450,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1389081301167607. Arrivals time: 0.035189156886190176 Scheduler time: 0.7266355832107365 Scheduler overhead time: 0.13157054968178272 Adapter cache time: 0.04380139661952853 Engine time: 0.13678110158070922 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-16/adapters_64_slots_32_rate_0.1-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-16/adapters_64_slots_32_rate_0.1-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 1080, 1080, 66, 1080, 66, 135, 66, 1080, 135, 1080, 66, 135, 1080, 1080, 1080, 66, 1080, 135, 135, 66, 66, 66, 1080, 66, 66, 66, 1080, 135, 66, 1080, 1080, 1080, 1080, 135, 135, 135, 1080, 66, 135, 135, 1080, 1080, 135, 1080, 66, 1080, 135, 135, 135, 1080, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 1080, 135]
Prompts retrieved: 27981 . Total input tokens: 6186519 . Total output tokens: 5499728
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 1.1168196815997362,
    "estimated_duration": 3600.0089978317574,
    "input_throughput": 641.1961751735256,
    "output_throughput": 557.3405514287463,
    "total_throughput": 1198.536726602272,
    "itl": 22.586815179387642,
    "ttft": 5363.833638170506,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1358,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.251029225112925,
    "arrivals": 9465,
    "finished_requests": 9450,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1169060617685318. Arrivals time: 0.034481641836464405 Scheduler time: 0.7090606773272157 Scheduler overhead time: 0.12940337834879756 Adapter cache time: 0.043468618765473366 Engine time: 0.13612703839316964 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-32/adapters_64_slots_32_rate_0.1-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-32/adapters_64_slots_32_rate_0.1-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 1080, 1080, 66, 1080, 66, 135, 66, 1080, 135, 1080, 66, 135, 1080, 1080, 1080, 66, 1080, 135, 135, 66, 66, 66, 1080, 66, 66, 66, 1080, 135, 66, 1080, 1080, 1080, 1080, 135, 135, 135, 1080, 66, 135, 135, 1080, 1080, 135, 1080, 66, 1080, 135, 135, 135, 1080, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 1080, 135]
Prompts retrieved: 27981 . Total input tokens: 6186519 . Total output tokens: 5499728
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 1.1037866892293096,
    "estimated_duration": 3600.0225770069483,
    "input_throughput": 641.1937566011394,
    "output_throughput": 557.3384491572114,
    "total_throughput": 1198.5322057583508,
    "itl": 22.59602496642147,
    "ttft": 5364.025521216658,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1358,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.09556277528864,
    "arrivals": 9465,
    "finished_requests": 9450,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1038584592752159. Arrivals time: 0.03434111410751939 Scheduler time: 0.6981922243721783 Scheduler overhead time: 0.12977819330990314 Adapter cache time: 0.043453479651361704 Engine time: 0.1339356661774218 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-16/adapters_64_slots_32_rate_0.1-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-16/adapters_64_slots_32_rate_0.1-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 1080, 1080, 66, 1080, 66, 135, 66, 1080, 135, 1080, 66, 135, 1080, 1080, 1080, 66, 1080, 135, 135, 66, 66, 66, 1080, 66, 66, 66, 1080, 135, 66, 1080, 1080, 1080, 1080, 135, 135, 135, 1080, 66, 135, 135, 1080, 1080, 135, 1080, 66, 1080, 135, 135, 135, 1080, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 1080, 135]
Prompts retrieved: 27981 . Total input tokens: 6186519 . Total output tokens: 5499728
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 1.109835036098957,
    "estimated_duration": 3600.0181285804074,
    "input_throughput": 641.1945489036287,
    "output_throughput": 557.339137842396,
    "total_throughput": 1198.5336867460246,
    "itl": 22.582146688639074,
    "ttft": 5363.947949921875,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1359,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.675748558235403,
    "arrivals": 9465,
    "finished_requests": 9450,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1098983283154666. Arrivals time: 0.03464800305664539 Scheduler time: 0.698453881777823 Scheduler overhead time: 0.1310274046845734 Adapter cache time: 0.04682236211374402 Engine time: 0.134163121227175 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-32/adapters_64_slots_32_rate_0.1-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-32/adapters_64_slots_32_rate_0.1-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 1080, 1080, 66, 1080, 66, 135, 66, 1080, 135, 1080, 66, 135, 1080, 1080, 1080, 66, 1080, 135, 135, 66, 66, 66, 1080, 66, 66, 66, 1080, 135, 66, 1080, 1080, 1080, 1080, 135, 135, 135, 1080, 66, 135, 135, 1080, 1080, 135, 1080, 66, 1080, 135, 135, 135, 1080, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 1080, 135]
Prompts retrieved: 27981 . Total input tokens: 6186519 . Total output tokens: 5499728
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.1086798328906298,
    "estimated_duration": 3600.0137795802943,
    "input_throughput": 641.1953234993209,
    "output_throughput": 557.3398111364781,
    "total_throughput": 1198.535134635799,
    "itl": 22.59321067937579,
    "ttft": 5363.91380342767,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1358,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.008780678287085,
    "arrivals": 9465,
    "finished_requests": 9450,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.108752773143351. Arrivals time: 0.03489387081936002 Scheduler time: 0.70036256685853 Scheduler overhead time: 0.1295855618081987 Adapter cache time: 0.04356849519535899 Engine time: 0.13591452641412616 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-8/adapters_64_slots_32_rate_0.1-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-8/adapters_64_slots_32_rate_0.1-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 1080, 1080, 33, 1080, 33, 135, 33, 1080, 135, 1080, 33, 135, 1080, 1080, 1080, 33, 1080, 135, 135, 33, 33, 33, 1080, 33, 33, 33, 1080, 135, 33, 1080, 1080, 1080, 1080, 135, 135, 135, 1080, 33, 135, 135, 1080, 1080, 135, 1080, 33, 1080, 135, 135, 135, 1080, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 1080, 135]
Prompts retrieved: 27288 . Total input tokens: 6030177 . Total output tokens: 5357998
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 1.0812437050044537,
    "estimated_duration": 3599.0174831629947,
    "input_throughput": 628.6518502854223,
    "output_throughput": 546.6578056939373,
    "total_throughput": 1175.3096559793596,
    "itl": 22.486521083550585,
    "ttft": 7863.2694973317075,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1053,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.962866710643441,
    "arrivals": 9201,
    "finished_requests": 9181,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0812911689281464. Arrivals time: 0.03360565332695842 Scheduler time: 0.6782689937390387 Scheduler overhead time: 0.13011015811935067 Adapter cache time: 0.04216528730466962 Engine time: 0.1329269609414041 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-16/adapters_64_slots_32_rate_0.1-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-16/adapters_64_slots_32_rate_0.1-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 1080, 1080, 33, 1080, 33, 135, 33, 1080, 135, 1080, 33, 135, 1080, 1080, 1080, 33, 1080, 135, 135, 33, 33, 33, 1080, 33, 33, 33, 1080, 135, 33, 1080, 1080, 1080, 1080, 135, 135, 135, 1080, 33, 135, 135, 1080, 1080, 135, 1080, 33, 1080, 135, 135, 135, 1080, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 1080, 135]
Prompts retrieved: 27288 . Total input tokens: 6030177 . Total output tokens: 5357998
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.087458253838122,
    "estimated_duration": 3598.998125953401,
    "input_throughput": 628.6552314890798,
    "output_throughput": 546.6607458926678,
    "total_throughput": 1175.3159773817476,
    "itl": 22.493431596750032,
    "ttft": 7863.199496416312,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1054,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.699019131707038,
    "arrivals": 9201,
    "finished_requests": 9181,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0875781429931521. Arrivals time: 0.034156741574406624 Scheduler time: 0.6822708719410002 Scheduler overhead time: 0.12993206642568111 Adapter cache time: 0.04249593894928694 Engine time: 0.13429569825530052 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-32/adapters_64_slots_32_rate_0.1-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-32/adapters_64_slots_32_rate_0.1-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 1080, 1080, 33, 1080, 33, 135, 33, 1080, 135, 1080, 33, 135, 1080, 1080, 1080, 33, 1080, 135, 135, 33, 33, 33, 1080, 33, 33, 33, 1080, 135, 33, 1080, 1080, 1080, 1080, 135, 135, 135, 1080, 33, 135, 135, 1080, 1080, 135, 1080, 33, 1080, 135, 135, 135, 1080, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 1080, 135]
Prompts retrieved: 27288 . Total input tokens: 6030177 . Total output tokens: 5357998
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.090729997958988,
    "estimated_duration": 3599.0085312773704,
    "input_throughput": 628.6534139436943,
    "output_throughput": 546.6591654067888,
    "total_throughput": 1175.312579350483,
    "itl": 22.494806866238633,
    "ttft": 7863.42195321503,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1054,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.905555065763196,
    "arrivals": 9201,
    "finished_requests": 9181,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0908286040648818. Arrivals time: 0.03648562077432871 Scheduler time: 0.6812111316248775 Scheduler overhead time: 0.13105970807373524 Adapter cache time: 0.042354960925877094 Engine time: 0.13507095258682966 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-16/adapters_64_slots_32_rate_0.1-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-16/adapters_64_slots_32_rate_0.1-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 1080, 1080, 33, 1080, 33, 135, 33, 1080, 135, 1080, 33, 135, 1080, 1080, 1080, 33, 1080, 135, 135, 33, 33, 33, 1080, 33, 33, 33, 1080, 135, 33, 1080, 1080, 1080, 1080, 135, 135, 135, 1080, 33, 135, 135, 1080, 1080, 135, 1080, 33, 1080, 135, 135, 135, 1080, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 1080, 135]
Prompts retrieved: 27288 . Total input tokens: 6030177 . Total output tokens: 5357998
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 1.097970164846629,
    "estimated_duration": 3599.0105167936144,
    "input_throughput": 628.6530671257121,
    "output_throughput": 546.6588638237154,
    "total_throughput": 1175.3119309494275,
    "itl": 22.49026294745036,
    "ttft": 7863.170055336228,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1054,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.129848532648741,
    "arrivals": 9201,
    "finished_requests": 9181,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0980217889882624. Arrivals time: 0.03406208474189043 Scheduler time: 0.6899678274057806 Scheduler overhead time: 0.13048836262896657 Adapter cache time: 0.04246921185404062 Engine time: 0.13631465518847108 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-32/adapters_64_slots_32_rate_0.1-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-32/adapters_64_slots_32_rate_0.1-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 1080, 1080, 33, 1080, 33, 135, 33, 1080, 135, 1080, 33, 135, 1080, 1080, 1080, 33, 1080, 135, 135, 33, 33, 33, 1080, 33, 33, 33, 1080, 135, 33, 1080, 1080, 1080, 1080, 135, 135, 135, 1080, 33, 135, 135, 1080, 1080, 135, 1080, 33, 1080, 135, 135, 135, 1080, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 1080, 135]
Prompts retrieved: 27288 . Total input tokens: 6030177 . Total output tokens: 5357998
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 1.091744708828628,
    "estimated_duration": 3599.009508364221,
    "input_throughput": 628.6532432720185,
    "output_throughput": 546.6590169955437,
    "total_throughput": 1175.3122602675621,
    "itl": 22.493934029677856,
    "ttft": 7863.303604421395,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1054,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.820844140527783,
    "arrivals": 9201,
    "finished_requests": 9181,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0918160588480532. Arrivals time: 0.03352050809189677 Scheduler time: 0.6860634670592844 Scheduler overhead time: 0.13046256871894002 Adapter cache time: 0.042323590256273746 Engine time: 0.134862438775599 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-16/adapters_64_slots_32_rate_0.1-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-16/adapters_64_slots_32_rate_0.1-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 1080, 1080, 33, 1080, 33, 135, 33, 1080, 135, 1080, 33, 135, 1080, 1080, 1080, 33, 1080, 135, 135, 33, 33, 33, 1080, 33, 33, 33, 1080, 135, 33, 1080, 1080, 1080, 1080, 135, 135, 135, 1080, 33, 135, 135, 1080, 1080, 135, 1080, 33, 1080, 135, 135, 135, 1080, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 1080, 135]
Prompts retrieved: 27288 . Total input tokens: 6030177 . Total output tokens: 5357998
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 1.0866972976364195,
    "estimated_duration": 3599.0111380498356,
    "input_throughput": 628.6529586085073,
    "output_throughput": 546.6587694602341,
    "total_throughput": 1175.3117280687413,
    "itl": 22.48672782123192,
    "ttft": 7863.071938725581,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1053,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.722268750420738,
    "arrivals": 9201,
    "finished_requests": 9181,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0867485366761684. Arrivals time: 0.034419752191752195 Scheduler time: 0.6810893625952303 Scheduler overhead time: 0.1292180847376585 Adapter cache time: 0.04225549753755331 Engine time: 0.13554944982752204 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-32/adapters_64_slots_32_rate_0.1-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-32/adapters_64_slots_32_rate_0.1-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 1080, 1080, 33, 1080, 33, 135, 33, 1080, 135, 1080, 33, 135, 1080, 1080, 1080, 33, 1080, 135, 135, 33, 33, 33, 1080, 33, 33, 33, 1080, 135, 33, 1080, 1080, 1080, 1080, 135, 135, 135, 1080, 33, 135, 135, 1080, 1080, 135, 1080, 33, 1080, 135, 135, 135, 1080, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 1080, 135]
Prompts retrieved: 27288 . Total input tokens: 6030177 . Total output tokens: 5357998
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.0902265910990536,
    "estimated_duration": 3599.005651439017,
    "input_throughput": 628.6539169771396,
    "output_throughput": 546.659602830395,
    "total_throughput": 1175.3135198075345,
    "itl": 22.49385998548445,
    "ttft": 7863.343060836415,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1054,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.760780159309522,
    "arrivals": 9201,
    "finished_requests": 9181,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0903000109829009. Arrivals time: 0.03352964064106345 Scheduler time: 0.6809926680289209 Scheduler overhead time: 0.1332862195558846 Adapter cache time: 0.04255653638392687 Engine time: 0.13532613217830658 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-8/adapters_64_slots_32_rate_0.1-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-8/adapters_64_slots_32_rate_0.1-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 1080, 1080, 33, 1080, 33, 66, 33, 1080, 66, 1080, 33, 66, 1080, 1080, 1080, 33, 1080, 66, 66, 33, 33, 33, 1080, 33, 33, 33, 1080, 66, 33, 1080, 1080, 1080, 1080, 66, 66, 66, 1080, 33, 66, 66, 1080, 1080, 66, 1080, 33, 1080, 66, 66, 66, 1080, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 1080, 66]
Prompts retrieved: 25839 . Total input tokens: 5702576 . Total output tokens: 5075324
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 1.0432612509466708,
    "estimated_duration": 3599.817889505215,
    "input_throughput": 589.9748446141286,
    "output_throughput": 517.9892586889425,
    "total_throughput": 1107.9641033030712,
    "itl": 22.233372980071458,
    "ttft": 6206.606365670728,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 631,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.1724300991604775,
    "arrivals": 8753,
    "finished_requests": 8738,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0433199009858072. Arrivals time: 0.032416506204754114 Scheduler time: 0.6422854727134109 Scheduler overhead time: 0.1308064511977136 Adapter cache time: 0.039579189382493496 Engine time: 0.13357610860839486 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-16/adapters_64_slots_32_rate_0.1-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-16/adapters_64_slots_32_rate_0.1-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 1080, 1080, 33, 1080, 33, 66, 33, 1080, 66, 1080, 33, 66, 1080, 1080, 1080, 33, 1080, 66, 66, 33, 33, 33, 1080, 33, 33, 33, 1080, 66, 33, 1080, 1080, 1080, 1080, 66, 66, 66, 1080, 33, 66, 66, 1080, 1080, 66, 1080, 33, 1080, 66, 66, 66, 1080, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 1080, 66]
Prompts retrieved: 25839 . Total input tokens: 5702576 . Total output tokens: 5075324
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.0602616230025887,
    "estimated_duration": 3599.806361324868,
    "input_throughput": 589.9767339758683,
    "output_throughput": 517.9909175208331,
    "total_throughput": 1107.9676514967014,
    "itl": 22.237156263358916,
    "ttft": 6206.499184059875,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 631,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.615471585211351,
    "arrivals": 8753,
    "finished_requests": 8738,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0603275918401778. Arrivals time: 0.03246619738638401 Scheduler time: 0.655843242071569 Scheduler overhead time: 0.1301410924643278 Adapter cache time: 0.039889146108180285 Engine time: 0.13679132843390107 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-32/adapters_64_slots_32_rate_0.1-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-32/adapters_64_slots_32_rate_0.1-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 1080, 1080, 33, 1080, 33, 66, 33, 1080, 66, 1080, 33, 66, 1080, 1080, 1080, 33, 1080, 66, 66, 33, 33, 33, 1080, 33, 33, 33, 1080, 66, 33, 1080, 1080, 1080, 1080, 66, 66, 66, 1080, 33, 66, 66, 1080, 1080, 66, 1080, 33, 1080, 66, 66, 66, 1080, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 1080, 66]
Prompts retrieved: 25839 . Total input tokens: 5702576 . Total output tokens: 5075324
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.0437694205902517,
    "estimated_duration": 3599.8219410310817,
    "input_throughput": 589.9741806095244,
    "output_throughput": 517.9886757026409,
    "total_throughput": 1107.9628563121653,
    "itl": 22.237588426393852,
    "ttft": 6206.74473571897,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 631,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.740570568707803,
    "arrivals": 8753,
    "finished_requests": 8738,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.043862717691809. Arrivals time: 0.032526894472539425 Scheduler time: 0.6412264904938638 Scheduler overhead time: 0.13139660004526377 Adapter cache time: 0.039804094936698675 Engine time: 0.13394899666309357 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-16/adapters_64_slots_32_rate_0.1-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-16/adapters_64_slots_32_rate_0.1-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 1080, 1080, 33, 1080, 33, 66, 33, 1080, 66, 1080, 33, 66, 1080, 1080, 1080, 33, 1080, 66, 66, 33, 33, 33, 1080, 33, 33, 33, 1080, 66, 33, 1080, 1080, 1080, 1080, 66, 66, 66, 1080, 33, 66, 66, 1080, 1080, 66, 1080, 33, 1080, 66, 66, 66, 1080, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 1080, 66]
Prompts retrieved: 25839 . Total input tokens: 5702576 . Total output tokens: 5075324
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 1.0589339113794267,
    "estimated_duration": 3599.8128129637976,
    "input_throughput": 589.975676610649,
    "output_throughput": 517.989989169682,
    "total_throughput": 1107.965665780331,
    "itl": 22.236144278726073,
    "ttft": 6206.563557258634,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 631,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.2781338886963125,
    "arrivals": 8753,
    "finished_requests": 8738,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0589824821799994. Arrivals time: 0.03271743981167674 Scheduler time: 0.6545348428189754 Scheduler overhead time: 0.13124810298904777 Adapter cache time: 0.03966902941465378 Engine time: 0.13583545433357358 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-32/adapters_64_slots_32_rate_0.1-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-32/adapters_64_slots_32_rate_0.1-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 1080, 1080, 33, 1080, 33, 66, 33, 1080, 66, 1080, 33, 66, 1080, 1080, 1080, 33, 1080, 66, 66, 33, 33, 33, 1080, 33, 33, 33, 1080, 66, 33, 1080, 1080, 1080, 1080, 66, 66, 66, 1080, 33, 66, 66, 1080, 1080, 66, 1080, 33, 1080, 66, 66, 66, 1080, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 1080, 66]
Prompts retrieved: 25839 . Total input tokens: 5702576 . Total output tokens: 5075324
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 1.0559042692184448,
    "estimated_duration": 3599.82148750076,
    "input_throughput": 589.9742549385378,
    "output_throughput": 517.9887409624242,
    "total_throughput": 1107.9629959009621,
    "itl": 22.238019188198408,
    "ttft": 6206.430875715732,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 631,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.690241094790431,
    "arrivals": 8753,
    "finished_requests": 8738,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0559785240329802. Arrivals time: 0.03240408329293132 Scheduler time: 0.6492628562264144 Scheduler overhead time: 0.13066276954486966 Adapter cache time: 0.040271084289997816 Engine time: 0.13820556225255132 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-16/adapters_64_slots_32_rate_0.1-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-16/adapters_64_slots_32_rate_0.1-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 1080, 1080, 33, 1080, 33, 66, 33, 1080, 66, 1080, 33, 66, 1080, 1080, 1080, 33, 1080, 66, 66, 33, 33, 33, 1080, 33, 33, 33, 1080, 66, 33, 1080, 1080, 1080, 1080, 66, 66, 66, 1080, 33, 66, 66, 1080, 1080, 66, 1080, 33, 1080, 66, 66, 66, 1080, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 1080, 66]
Prompts retrieved: 25839 . Total input tokens: 5702576 . Total output tokens: 5075324
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 1.0900442567653954,
    "estimated_duration": 3599.8213768849396,
    "input_throughput": 589.9742730673502,
    "output_throughput": 517.9887568792556,
    "total_throughput": 1107.9630299466057,
    "itl": 22.233876852918662,
    "ttft": 6206.425871274801,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 631,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.028254113499988,
    "arrivals": 8753,
    "finished_requests": 8738,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0901026725769043. Arrivals time: 0.033322482369840145 Scheduler time: 0.684322030749172 Scheduler overhead time: 0.13145452365279198 Adapter cache time: 0.04002159973606467 Engine time: 0.1355436099693179 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-32/adapters_64_slots_32_rate_0.1-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-32/adapters_64_slots_32_rate_0.1-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 1080, 1080, 33, 1080, 33, 66, 33, 1080, 66, 1080, 33, 66, 1080, 1080, 1080, 33, 1080, 66, 66, 33, 33, 33, 1080, 33, 33, 33, 1080, 66, 33, 1080, 1080, 1080, 1080, 66, 66, 66, 1080, 33, 66, 66, 1080, 1080, 66, 1080, 33, 1080, 66, 66, 66, 1080, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 1080, 66]
Prompts retrieved: 25839 . Total input tokens: 5702576 . Total output tokens: 5075324
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.0623342520557344,
    "estimated_duration": 3599.8253979048313,
    "input_throughput": 589.9736140636415,
    "output_throughput": 517.9881782836669,
    "total_throughput": 1107.9617923473086,
    "itl": 22.238449916788213,
    "ttft": 6206.508000636519,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 631,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.652960002999785,
    "arrivals": 8753,
    "finished_requests": 8738,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0623983219265938. Arrivals time: 0.03289268724620342 Scheduler time: 0.6565828355960548 Scheduler overhead time: 0.13159736711531878 Adapter cache time: 0.03985306667163968 Engine time: 0.13621813990175724 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-8/adapters_64_slots_32_rate_0.05-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-8/adapters_64_slots_32_rate_0.05-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [21 21 22]
Adapter prompts. [135, 270, 540, 540, 135, 540, 135, 270, 135, 540, 270, 540, 135, 270, 540, 540, 540, 135, 540, 270, 270, 135, 135, 135, 540, 135, 135, 135, 540, 270, 135, 540, 540, 540, 540, 270, 270, 270, 540, 135, 270, 270, 540, 540, 270, 540, 135, 540, 270, 270, 270, 540, 270, 135, 135, 270, 270, 135, 270, 135, 135, 135, 540, 270]
Prompts retrieved: 20385 . Total input tokens: 4486853 . Total output tokens: 4030518
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 0.9518318031914532,
    "estimated_duration": 3599.74632674799,
    "input_throughput": 465.6203098383885,
    "output_throughput": 416.84131708124335,
    "total_throughput": 882.4616269196318,
    "itl": 22.14167751060702,
    "ttft": 5799.824384478351,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2810,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 18.580869379779163,
    "arrivals": 6874,
    "finished_requests": 6863,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9519288972951472. Arrivals time: 0.028431924059987068 Scheduler time: 0.5474637006409466 Scheduler overhead time: 0.1305425907485187 Adapter cache time: 0.044216825161129236 Engine time: 0.1362445722334087 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-16/adapters_64_slots_32_rate_0.05-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-16/adapters_64_slots_32_rate_0.05-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [21 21 22]
Adapter prompts. [135, 270, 540, 540, 135, 540, 135, 270, 135, 540, 270, 540, 135, 270, 540, 540, 540, 135, 540, 270, 270, 135, 135, 135, 540, 135, 135, 135, 540, 270, 135, 540, 540, 540, 540, 270, 270, 270, 540, 135, 270, 270, 540, 540, 270, 540, 135, 540, 270, 270, 270, 540, 270, 135, 135, 270, 270, 135, 270, 135, 135, 135, 540, 270]
Prompts retrieved: 20385 . Total input tokens: 4486853 . Total output tokens: 4030518
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 0.9466997729614377,
    "estimated_duration": 3599.7516562843484,
    "input_throughput": 465.61962047406354,
    "output_throughput": 416.8406999356269,
    "total_throughput": 882.4603204096904,
    "itl": 22.156153765830013,
    "ttft": 5800.239482933722,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2811,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.517575227492014,
    "arrivals": 6874,
    "finished_requests": 6863,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9467523801140487. Arrivals time: 0.028780122753232718 Scheduler time: 0.5424968167208135 Scheduler overhead time: 0.13103719521313906 Adapter cache time: 0.0438668723218143 Engine time: 0.13542499020695686 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-32/adapters_64_slots_32_rate_0.05-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-32/adapters_64_slots_32_rate_0.05-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [21 21 22]
Adapter prompts. [135, 270, 540, 540, 135, 540, 135, 270, 135, 540, 270, 540, 135, 270, 540, 540, 540, 135, 540, 270, 270, 135, 135, 135, 540, 135, 135, 135, 540, 270, 135, 540, 540, 540, 540, 270, 270, 270, 540, 135, 270, 270, 540, 540, 270, 540, 135, 540, 270, 270, 270, 540, 270, 135, 135, 270, 270, 135, 270, 135, 135, 135, 540, 270]
Prompts retrieved: 20385 . Total input tokens: 4486853 . Total output tokens: 4030518
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 0.950336751062423,
    "estimated_duration": 3599.7397941058903,
    "input_throughput": 465.62115482469653,
    "output_throughput": 416.8420735456804,
    "total_throughput": 882.463228370377,
    "itl": 22.161683689307846,
    "ttft": 5800.32780543891,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2810,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 21.058438460375413,
    "arrivals": 6874,
    "finished_requests": 6863,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9504079041071236. Arrivals time: 0.02892946731299162 Scheduler time: 0.546404636465013 Scheduler overhead time: 0.1306976149789989 Adapter cache time: 0.043711991515010595 Engine time: 0.13533111521974206 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-16/adapters_64_slots_32_rate_0.05-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-16/adapters_64_slots_32_rate_0.05-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [21 21 22]
Adapter prompts. [135, 270, 540, 540, 135, 540, 135, 270, 135, 540, 270, 540, 135, 270, 540, 540, 540, 135, 540, 270, 270, 135, 135, 135, 540, 135, 135, 135, 540, 270, 135, 540, 540, 540, 540, 270, 270, 270, 540, 135, 270, 270, 540, 540, 270, 540, 135, 540, 270, 270, 270, 540, 270, 135, 135, 270, 270, 135, 270, 135, 135, 135, 540, 270]
Prompts retrieved: 20385 . Total input tokens: 4486853 . Total output tokens: 4030518
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 0.9448742372915149,
    "estimated_duration": 3599.740136666359,
    "input_throughput": 465.6211105149978,
    "output_throughput": 416.84203387792365,
    "total_throughput": 882.4631443929214,
    "itl": 22.143813426637767,
    "ttft": 5799.984399887795,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2810,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.214592917478168,
    "arrivals": 6874,
    "finished_requests": 6863,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9449270702898502. Arrivals time: 0.028949156869202852 Scheduler time: 0.5430884417146444 Scheduler overhead time: 0.1311409338377416 Adapter cache time: 0.043655223213136196 Engine time: 0.13317850418388844 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-32/adapters_64_slots_32_rate_0.05-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-32/adapters_64_slots_32_rate_0.05-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [21 21 22]
Adapter prompts. [135, 270, 540, 540, 135, 540, 135, 270, 135, 540, 270, 540, 135, 270, 540, 540, 540, 135, 540, 270, 270, 135, 135, 135, 540, 135, 135, 135, 540, 270, 135, 540, 540, 540, 540, 270, 270, 270, 540, 135, 270, 270, 540, 540, 270, 540, 135, 540, 270, 270, 270, 540, 270, 135, 135, 270, 270, 135, 270, 135, 135, 135, 540, 270]
Prompts retrieved: 20385 . Total input tokens: 4486853 . Total output tokens: 4030518
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 0.9509675232693553,
    "estimated_duration": 3599.740142388899,
    "input_throughput": 465.6211097747956,
    "output_throughput": 416.84203321526604,
    "total_throughput": 882.4631429900617,
    "itl": 22.156901990160733,
    "ttft": 5800.099446873855,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2810,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.864991017417267,
    "arrivals": 6874,
    "finished_requests": 6863,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9510308969765902. Arrivals time: 0.028943856246769428 Scheduler time: 0.547785019967705 Scheduler overhead time: 0.12979361601173878 Adapter cache time: 0.043863257858902216 Engine time: 0.13533543329685926 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-16/adapters_64_slots_32_rate_0.05-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-16/adapters_64_slots_32_rate_0.05-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [21 21 22]
Adapter prompts. [135, 270, 540, 540, 135, 540, 135, 270, 135, 540, 270, 540, 135, 270, 540, 540, 540, 135, 540, 270, 270, 135, 135, 135, 540, 135, 135, 135, 540, 270, 135, 540, 540, 540, 540, 270, 270, 270, 540, 135, 270, 270, 540, 540, 270, 540, 135, 540, 270, 270, 270, 540, 270, 135, 135, 270, 270, 135, 270, 135, 135, 135, 540, 270]
Prompts retrieved: 20385 . Total input tokens: 4486853 . Total output tokens: 4030518
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 0.9496228261850774,
    "estimated_duration": 3599.734701703492,
    "input_throughput": 465.62181352053994,
    "output_throughput": 416.8426632356856,
    "total_throughput": 882.4644767562256,
    "itl": 22.13454803576784,
    "ttft": 5799.809004138361,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2810,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.938817843004482,
    "arrivals": 6874,
    "finished_requests": 6863,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9496749611571431. Arrivals time: 0.02923691412433982 Scheduler time: 0.5453639896586537 Scheduler overhead time: 0.13116601016372442 Adapter cache time: 0.04398523876443505 Engine time: 0.1345489756204188 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-32/adapters_64_slots_32_rate_0.05-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-32/adapters_64_slots_32_rate_0.05-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [21 21 22]
Adapter prompts. [135, 270, 540, 540, 135, 540, 135, 270, 135, 540, 270, 540, 135, 270, 540, 540, 540, 135, 540, 270, 270, 135, 135, 135, 540, 135, 135, 135, 540, 270, 135, 540, 540, 540, 540, 270, 270, 270, 540, 135, 270, 270, 540, 540, 270, 540, 135, 540, 270, 270, 270, 540, 270, 135, 135, 270, 270, 135, 270, 135, 135, 135, 540, 270]
Prompts retrieved: 20385 . Total input tokens: 4486853 . Total output tokens: 4030518
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 0.9481017161160707,
    "estimated_duration": 3599.7555382209493,
    "input_throughput": 465.61911835500916,
    "output_throughput": 416.8402504192215,
    "total_throughput": 882.4593687742307,
    "itl": 22.158162306422078,
    "ttft": 5800.130015356122,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2812,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.68888655528446,
    "arrivals": 6874,
    "finished_requests": 6863,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9481716169975698. Arrivals time: 0.028734109364449978 Scheduler time: 0.5443546352908015 Scheduler overhead time: 0.1311386083252728 Adapter cache time: 0.04367152927443385 Engine time: 0.1350161931477487 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-8/adapters_64_slots_32_rate_0.05-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-8/adapters_64_slots_32_rate_0.05-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [21 21 22]
Adapter prompts. [66, 270, 540, 540, 66, 540, 66, 270, 66, 540, 270, 540, 66, 270, 540, 540, 540, 66, 540, 270, 270, 66, 66, 66, 540, 66, 66, 66, 540, 270, 66, 540, 540, 540, 540, 270, 270, 270, 540, 66, 270, 270, 540, 540, 270, 540, 66, 540, 270, 270, 270, 540, 270, 66, 66, 270, 270, 66, 270, 66, 66, 66, 540, 270]
Prompts retrieved: 18936 . Total input tokens: 4162529 . Total output tokens: 3739621
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 0.9151737722568214,
    "estimated_duration": 3599.6214810313836,
    "input_throughput": 435.48356633066027,
    "output_throughput": 385.64054785067475,
    "total_throughput": 821.124114181335,
    "itl": 21.68008071504638,
    "ttft": 3410.3415586202746,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2207,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.593586733513915,
    "arrivals": 6405,
    "finished_requests": 6399,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.915225877892226. Arrivals time: 0.027505061589181423 Scheduler time: 0.5130487796850502 Scheduler overhead time: 0.1321776839904487 Adapter cache time: 0.04152378020808101 Engine time: 0.1352132074534893 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-16/adapters_64_slots_32_rate_0.05-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-16/adapters_64_slots_32_rate_0.05-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [21 21 22]
Adapter prompts. [66, 270, 540, 540, 66, 540, 66, 270, 66, 540, 270, 540, 66, 270, 540, 540, 540, 66, 540, 270, 270, 66, 66, 66, 540, 66, 66, 66, 540, 270, 66, 540, 540, 540, 540, 270, 270, 270, 540, 66, 270, 270, 540, 540, 270, 540, 66, 540, 270, 270, 270, 540, 270, 66, 66, 270, 270, 66, 270, 66, 66, 66, 540, 270]
Prompts retrieved: 18936 . Total input tokens: 4162529 . Total output tokens: 3739621
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 0.9123297748155892,
    "estimated_duration": 3599.6346071372836,
    "input_throughput": 435.48197833520146,
    "output_throughput": 385.63914160831325,
    "total_throughput": 821.1211199435147,
    "itl": 21.68848846154748,
    "ttft": 3410.8011063850818,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2207,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.12722190466213,
    "arrivals": 6405,
    "finished_requests": 6399,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9123917338438332. Arrivals time: 0.0277851945720613 Scheduler time: 0.5106074931100011 Scheduler overhead time: 0.13134329579770565 Adapter cache time: 0.041438027285039425 Engine time: 0.13568365713581443 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-32/adapters_64_slots_32_rate_0.05-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-32/adapters_64_slots_32_rate_0.05-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [21 21 22]
Adapter prompts. [66, 270, 540, 540, 66, 540, 66, 270, 66, 540, 270, 540, 66, 270, 540, 540, 540, 66, 540, 270, 270, 66, 66, 66, 540, 66, 66, 66, 540, 270, 66, 540, 540, 540, 540, 270, 270, 270, 540, 66, 270, 270, 540, 540, 270, 540, 66, 540, 270, 270, 270, 540, 270, 66, 66, 270, 270, 66, 270, 66, 66, 66, 540, 270]
Prompts retrieved: 18936 . Total input tokens: 4162529 . Total output tokens: 3739621
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 0.9184521678835154,
    "estimated_duration": 3599.6231153377657,
    "input_throughput": 435.48336861174664,
    "output_throughput": 385.6403727615645,
    "total_throughput": 821.1237413733111,
    "itl": 21.688578811745714,
    "ttft": 3410.8186473134747,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2208,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.567453277054895,
    "arrivals": 6405,
    "finished_requests": 6399,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9185173599980772. Arrivals time: 0.027678835671395063 Scheduler time: 0.5154881472699344 Scheduler overhead time: 0.13189034210518003 Adapter cache time: 0.041550163179636 Engine time: 0.13563335593789816 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-16/adapters_64_slots_32_rate_0.05-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-16/adapters_64_slots_32_rate_0.05-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [21 21 22]
Adapter prompts. [66, 270, 540, 540, 66, 540, 66, 270, 66, 540, 270, 540, 66, 270, 540, 540, 540, 66, 540, 270, 270, 66, 66, 66, 540, 66, 66, 66, 540, 270, 66, 540, 540, 540, 540, 270, 270, 270, 540, 66, 270, 270, 540, 540, 270, 540, 66, 540, 270, 270, 270, 540, 270, 66, 66, 270, 270, 66, 270, 66, 66, 66, 540, 270]
Prompts retrieved: 18936 . Total input tokens: 4162529 . Total output tokens: 3739621
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 0.9213297301903367,
    "estimated_duration": 3599.634987797871,
    "input_throughput": 435.4819322830806,
    "output_throughput": 385.6391008270611,
    "total_throughput": 821.1210331101416,
    "itl": 21.680325098979317,
    "ttft": 3410.65045964268,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2208,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.05912279225918,
    "arrivals": 6405,
    "finished_requests": 6399,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9214001530781388. Arrivals time: 0.028357342351228 Scheduler time: 0.5165608748793602 Scheduler overhead time: 0.13410060806199908 Adapter cache time: 0.041241704020649195 Engine time: 0.13499819627031684 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-32/adapters_64_slots_32_rate_0.05-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-32/adapters_64_slots_32_rate_0.05-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [21 21 22]
Adapter prompts. [66, 270, 540, 540, 66, 540, 66, 270, 66, 540, 270, 540, 66, 270, 540, 540, 540, 66, 540, 270, 270, 66, 66, 66, 540, 66, 66, 66, 540, 270, 66, 540, 540, 540, 540, 270, 270, 270, 540, 66, 270, 270, 540, 540, 270, 540, 66, 540, 270, 270, 270, 540, 270, 66, 66, 270, 270, 66, 270, 66, 66, 66, 540, 270]
Prompts retrieved: 18936 . Total input tokens: 4162529 . Total output tokens: 3739621
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 0.9120100578293204,
    "estimated_duration": 3599.6292302460615,
    "input_throughput": 435.4826288297599,
    "output_throughput": 385.6397176508951,
    "total_throughput": 821.122346480655,
    "itl": 21.688304136768988,
    "ttft": 3410.8922260397635,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2207,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.400777315376025,
    "arrivals": 6405,
    "finished_requests": 6399,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9120752536691725. Arrivals time: 0.02774693677201867 Scheduler time: 0.5112272761762142 Scheduler overhead time: 0.13167551578953862 Adapter cache time: 0.041303697507828474 Engine time: 0.1340572088956833 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-16/adapters_64_slots_32_rate_0.05-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-16/adapters_64_slots_32_rate_0.05-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [21 21 22]
Adapter prompts. [66, 270, 540, 540, 66, 540, 66, 270, 66, 540, 270, 540, 66, 270, 540, 540, 540, 66, 540, 270, 270, 66, 66, 66, 540, 66, 66, 66, 540, 270, 66, 540, 540, 540, 540, 270, 270, 270, 540, 66, 270, 270, 540, 540, 270, 540, 66, 540, 270, 270, 270, 540, 270, 66, 66, 270, 270, 66, 270, 66, 66, 66, 540, 270]
Prompts retrieved: 18936 . Total input tokens: 4162529 . Total output tokens: 3739621
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 0.916302417870611,
    "estimated_duration": 3599.619921714889,
    "input_throughput": 435.4837549774404,
    "output_throughput": 385.6407149059973,
    "total_throughput": 821.1244698834378,
    "itl": 21.6761776164313,
    "ttft": 3410.309613691883,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2207,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.089313515839939,
    "arrivals": 6405,
    "finished_requests": 6399,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9163513239473104. Arrivals time: 0.02773666614666581 Scheduler time: 0.5136811900883913 Scheduler overhead time: 0.13146505784243345 Adapter cache time: 0.04127258528023958 Engine time: 0.1362709947861731 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-32/adapters_64_slots_32_rate_0.05-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-32/adapters_64_slots_32_rate_0.05-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [21 21 22]
Adapter prompts. [66, 270, 540, 540, 66, 540, 66, 270, 66, 540, 270, 540, 66, 270, 540, 540, 540, 66, 540, 270, 270, 66, 66, 66, 540, 66, 66, 66, 540, 270, 66, 540, 540, 540, 540, 270, 270, 270, 540, 66, 270, 270, 540, 540, 270, 540, 66, 540, 270, 270, 270, 540, 270, 66, 66, 270, 270, 66, 270, 66, 66, 66, 540, 270]
Prompts retrieved: 18936 . Total input tokens: 4162529 . Total output tokens: 3739621
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 0.9138802788220346,
    "estimated_duration": 3599.6349198894627,
    "input_throughput": 435.48194049860393,
    "output_throughput": 385.6391081022815,
    "total_throughput": 821.1210486008855,
    "itl": 21.691805940488734,
    "ttft": 3410.8128843317845,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2208,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.26340526178447,
    "arrivals": 6405,
    "finished_requests": 6399,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9139578500762582. Arrivals time: 0.027727456763386726 Scheduler time: 0.5117431716062129 Scheduler overhead time: 0.13167203776538372 Adapter cache time: 0.04151664301753044 Engine time: 0.1350487545132637 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-8/adapters_64_slots_32_rate_0.05-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-8/adapters_64_slots_32_rate_0.05-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [21 21 22]
Adapter prompts. [33, 270, 540, 540, 33, 540, 33, 270, 33, 540, 270, 540, 33, 270, 540, 540, 540, 33, 540, 270, 270, 33, 33, 33, 540, 33, 33, 33, 540, 270, 33, 540, 540, 540, 540, 270, 270, 270, 540, 33, 270, 270, 540, 540, 270, 540, 33, 540, 270, 270, 270, 540, 270, 33, 33, 270, 270, 33, 270, 33, 33, 33, 540, 270]
Prompts retrieved: 18243 . Total input tokens: 4019758 . Total output tokens: 3602542
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 0.9094840884208679,
    "estimated_duration": 3597.856182414124,
    "input_throughput": 409.56195169848803,
    "output_throughput": 373.22698071243747,
    "total_throughput": 782.7889324109254,
    "itl": 21.555511194070515,
    "ttft": 6486.067740507618,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1824,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.061034074277007,
    "arrivals": 6141,
    "finished_requests": 6130,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9095330704003572. Arrivals time: 0.02776504075154662 Scheduler time: 0.5062758880667388 Scheduler overhead time: 0.13262436026707292 Adapter cache time: 0.04033067589625716 Engine time: 0.13666626624763012 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-16/adapters_64_slots_32_rate_0.05-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-16/adapters_64_slots_32_rate_0.05-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [21 21 22]
Adapter prompts. [33, 270, 540, 540, 33, 540, 33, 270, 33, 540, 270, 540, 33, 270, 540, 540, 540, 33, 540, 270, 270, 33, 33, 33, 540, 33, 33, 33, 540, 270, 33, 540, 540, 540, 540, 270, 270, 270, 540, 33, 270, 270, 540, 540, 270, 540, 33, 540, 270, 270, 270, 540, 270, 33, 33, 270, 270, 33, 270, 33, 33, 33, 540, 270]
Prompts retrieved: 18243 . Total input tokens: 4019758 . Total output tokens: 3602542
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 0.9050781782716513,
    "estimated_duration": 3597.8554115574652,
    "input_throughput": 409.5620394489731,
    "output_throughput": 373.22706067799203,
    "total_throughput": 782.7891001269651,
    "itl": 21.56582499046247,
    "ttft": 6486.610290554093,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1825,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.327626652302959,
    "arrivals": 6141,
    "finished_requests": 6130,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9051455492153764. Arrivals time: 0.027336749713867903 Scheduler time: 0.5037679839879274 Scheduler overhead time: 0.1309198304079473 Adapter cache time: 0.039951044134795666 Engine time: 0.13725837459787726 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-32/adapters_64_slots_32_rate_0.05-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-32/adapters_64_slots_32_rate_0.05-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [21 21 22]
Adapter prompts. [33, 270, 540, 540, 33, 540, 33, 270, 33, 540, 270, 540, 33, 270, 540, 540, 540, 33, 540, 270, 270, 33, 33, 33, 540, 33, 33, 33, 540, 270, 33, 540, 540, 540, 540, 270, 270, 270, 540, 33, 270, 270, 540, 540, 270, 540, 33, 540, 270, 270, 270, 540, 270, 33, 33, 270, 270, 33, 270, 33, 33, 33, 540, 270]
Prompts retrieved: 18243 . Total input tokens: 4019758 . Total output tokens: 3602542
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 0.9003907362930477,
    "estimated_duration": 3597.845101768829,
    "input_throughput": 409.5632130676089,
    "output_throughput": 373.22813017709495,
    "total_throughput": 782.7913432447039,
    "itl": 21.567931335474977,
    "ttft": 6486.420878472424,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1825,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.68450036147586,
    "arrivals": 6141,
    "finished_requests": 6130,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9004496550187469. Arrivals time: 0.027233448810875416 Scheduler time: 0.49965326208621264 Scheduler overhead time: 0.13114191824570298 Adapter cache time: 0.040041991509497166 Engine time: 0.1365005816332996 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-16/adapters_64_slots_32_rate_0.05-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-16/adapters_64_slots_32_rate_0.05-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [21 21 22]
Adapter prompts. [33, 270, 540, 540, 33, 540, 33, 270, 33, 540, 270, 540, 33, 270, 540, 540, 540, 33, 540, 270, 270, 33, 33, 33, 540, 33, 33, 33, 540, 270, 33, 540, 540, 540, 540, 270, 270, 270, 540, 33, 270, 270, 540, 540, 270, 540, 33, 540, 270, 270, 270, 540, 270, 33, 33, 270, 270, 33, 270, 33, 33, 33, 540, 270]
Prompts retrieved: 18243 . Total input tokens: 4019758 . Total output tokens: 3602542
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 0.9094387833029032,
    "estimated_duration": 3597.8562840592062,
    "input_throughput": 409.5619401277206,
    "output_throughput": 373.2269701681899,
    "total_throughput": 782.7889102959106,
    "itl": 21.559138033055145,
    "ttft": 6486.211863056204,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1826,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.433055161563878,
    "arrivals": 6141,
    "finished_requests": 6130,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9095351793803275. Arrivals time: 0.02720068208873272 Scheduler time: 0.5077797719277442 Scheduler overhead time: 0.13241948978975415 Adapter cache time: 0.040054593700915575 Engine time: 0.13590472331270576 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-32/adapters_64_slots_32_rate_0.05-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-32/adapters_64_slots_32_rate_0.05-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [21 21 22]
Adapter prompts. [33, 270, 540, 540, 33, 540, 33, 270, 33, 540, 270, 540, 33, 270, 540, 540, 540, 33, 540, 270, 270, 33, 33, 33, 540, 33, 33, 33, 540, 270, 33, 540, 540, 540, 540, 270, 270, 270, 540, 33, 270, 270, 540, 540, 270, 540, 33, 540, 270, 270, 270, 540, 270, 33, 33, 270, 270, 33, 270, 33, 33, 33, 540, 270]
Prompts retrieved: 18243 . Total input tokens: 4019758 . Total output tokens: 3602542
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 0.9028118909336627,
    "estimated_duration": 3597.841846368937,
    "input_throughput": 409.5635836486674,
    "output_throughput": 373.2284678814374,
    "total_throughput": 782.7920515301048,
    "itl": 21.567206057008516,
    "ttft": 6486.359302403443,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1825,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.54987419667631,
    "arrivals": 6141,
    "finished_requests": 6130,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9028842630796134. Arrivals time: 0.02737416699528694 Scheduler time: 0.5026135984808207 Scheduler overhead time: 0.13169096037745476 Adapter cache time: 0.039984509348869324 Engine time: 0.13539844984188676 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-16/adapters_64_slots_32_rate_0.05-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-16/adapters_64_slots_32_rate_0.05-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [21 21 22]
Adapter prompts. [33, 270, 540, 540, 33, 540, 33, 270, 33, 540, 270, 540, 33, 270, 540, 540, 540, 33, 540, 270, 270, 33, 33, 33, 540, 33, 33, 33, 540, 270, 33, 540, 540, 540, 540, 270, 270, 270, 540, 33, 270, 270, 540, 540, 270, 540, 33, 540, 270, 270, 270, 540, 270, 33, 33, 270, 270, 33, 270, 33, 33, 33, 540, 270]
Prompts retrieved: 18243 . Total input tokens: 4019758 . Total output tokens: 3602542
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 0.9018377899192274,
    "estimated_duration": 3597.849169998287,
    "input_throughput": 409.56274995838737,
    "output_throughput": 373.2277081533797,
    "total_throughput": 782.7904581117671,
    "itl": 21.555383043669966,
    "ttft": 6486.007548933626,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1826,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.65703963748224,
    "arrivals": 6141,
    "finished_requests": 6130,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9018871518783271. Arrivals time: 0.02742216782644391 Scheduler time: 0.5014097183011472 Scheduler overhead time: 0.13122144900262356 Adapter cache time: 0.03990513924509287 Engine time: 0.13594645587727427 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-32/adapters_64_slots_32_rate_0.05-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-32/adapters_64_slots_32_rate_0.05-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [21 21 22]
Adapter prompts. [33, 270, 540, 540, 33, 540, 33, 270, 33, 540, 270, 540, 33, 270, 540, 540, 540, 33, 540, 270, 270, 33, 33, 33, 540, 33, 33, 33, 540, 270, 33, 540, 540, 540, 540, 270, 270, 270, 540, 33, 270, 270, 540, 540, 270, 540, 33, 540, 270, 270, 270, 540, 270, 33, 33, 270, 270, 33, 270, 33, 33, 33, 540, 270]
Prompts retrieved: 18243 . Total input tokens: 4019758 . Total output tokens: 3602542
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 0.9005759190768003,
    "estimated_duration": 3597.8554752670307,
    "input_throughput": 409.5620321965919,
    "output_throughput": 373.22705406901787,
    "total_throughput": 782.7890862656097,
    "itl": 21.56604360742705,
    "ttft": 6486.391145392795,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1826,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.44217176832236,
    "arrivals": 6141,
    "finished_requests": 6130,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9006863301619887. Arrivals time: 0.027202190831303596 Scheduler time: 0.49906030716374516 Scheduler overhead time: 0.13206045795232058 Adapter cache time: 0.04007867118343711 Engine time: 0.1363006765022874 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-8/adapters_64_slots_32_rate_0.05-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-8/adapters_64_slots_32_rate_0.05-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 540, 540, 66, 540, 66, 135, 66, 540, 135, 540, 66, 135, 540, 540, 540, 66, 540, 135, 135, 66, 66, 66, 540, 66, 66, 66, 540, 135, 66, 540, 540, 540, 540, 135, 135, 135, 540, 66, 135, 135, 540, 540, 135, 540, 66, 540, 135, 135, 135, 540, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 540, 135]
Prompts retrieved: 16101 . Total input tokens: 3538570 . Total output tokens: 3185444
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 0.8569504250772297,
    "estimated_duration": 3599.894972664134,
    "input_throughput": 358.99213999668353,
    "output_throughput": 328.3543017159804,
    "total_throughput": 687.3464417126639,
    "itl": 21.29605030299028,
    "ttft": 4020.006307875196,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1534,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.143435455011463,
    "arrivals": 5423,
    "finished_requests": 5417,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8570142639800906. Arrivals time: 0.025820499751716852 Scheduler time: 0.4553480986505747 Scheduler overhead time: 0.13310006028041244 Adapter cache time: 0.037498552817851305 Engine time: 0.13858507480472326 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-16/adapters_64_slots_32_rate_0.05-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-16/adapters_64_slots_32_rate_0.05-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 540, 540, 66, 540, 66, 135, 66, 540, 135, 540, 66, 135, 540, 540, 540, 66, 540, 135, 135, 66, 66, 66, 540, 66, 66, 66, 540, 135, 66, 540, 540, 540, 540, 135, 135, 135, 540, 66, 135, 135, 540, 540, 135, 540, 66, 540, 135, 135, 135, 540, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 540, 135]
Prompts retrieved: 16101 . Total input tokens: 3538570 . Total output tokens: 3185444
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 0.855125340167433,
    "estimated_duration": 3599.9070782909907,
    "input_throughput": 358.9909327919427,
    "output_throughput": 328.353197538965,
    "total_throughput": 687.3441303309078,
    "itl": 21.302290858451343,
    "ttft": 4020.372606105098,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1534,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.20197901074765,
    "arrivals": 5423,
    "finished_requests": 5417,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8551801010034978. Arrivals time: 0.026766380295157433 Scheduler time: 0.4542305273935199 Scheduler overhead time: 0.13302645878866315 Adapter cache time: 0.037977153435349464 Engine time: 0.13670860463753343 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-32/adapters_64_slots_32_rate_0.05-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-32/adapters_64_slots_32_rate_0.05-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 540, 540, 66, 540, 66, 135, 66, 540, 135, 540, 66, 135, 540, 540, 540, 66, 540, 135, 135, 66, 66, 66, 540, 66, 66, 66, 540, 135, 66, 540, 540, 540, 540, 135, 135, 135, 540, 66, 135, 135, 540, 540, 135, 540, 66, 540, 135, 135, 135, 540, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 540, 135]
Prompts retrieved: 16101 . Total input tokens: 3538570 . Total output tokens: 3185444
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 0.8567207627929747,
    "estimated_duration": 3599.9102851774715,
    "input_throughput": 358.99061299420396,
    "output_throughput": 328.35290503405605,
    "total_throughput": 687.3435180282601,
    "itl": 21.307972365238047,
    "ttft": 4020.319778470652,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1533,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.49545876943028,
    "arrivals": 5423,
    "finished_requests": 5417,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8567929198034108. Arrivals time: 0.025279095862060785 Scheduler time: 0.4560540742240846 Scheduler overhead time: 0.13264000415802002 Adapter cache time: 0.03771663969382644 Engine time: 0.1383009422570467 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-16/adapters_64_slots_32_rate_0.05-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-16/adapters_64_slots_32_rate_0.05-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 540, 540, 66, 540, 66, 135, 66, 540, 135, 540, 66, 135, 540, 540, 540, 66, 540, 135, 135, 66, 66, 66, 540, 66, 66, 66, 540, 135, 66, 540, 540, 540, 540, 135, 135, 135, 540, 66, 135, 135, 540, 540, 135, 540, 66, 540, 135, 135, 135, 540, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 540, 135]
Prompts retrieved: 16101 . Total input tokens: 3538570 . Total output tokens: 3185444
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 0.8518346240743995,
    "estimated_duration": 3599.8987305373907,
    "input_throughput": 358.9917652508745,
    "output_throughput": 328.3539589524913,
    "total_throughput": 687.3457242033658,
    "itl": 21.29993327226311,
    "ttft": 4020.2450452683324,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1533,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.46122619492478,
    "arrivals": 5423,
    "finished_requests": 5417,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8518854849971831. Arrivals time: 0.02569684013724327 Scheduler time: 0.45323214307427406 Scheduler overhead time: 0.132516133133322 Adapter cache time: 0.03754488751292229 Engine time: 0.13630245625972748 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-32/adapters_64_slots_32_rate_0.05-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-32/adapters_64_slots_32_rate_0.05-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 540, 540, 66, 540, 66, 135, 66, 540, 135, 540, 66, 135, 540, 540, 540, 66, 540, 135, 135, 66, 66, 66, 540, 66, 66, 66, 540, 135, 66, 540, 540, 540, 540, 135, 135, 135, 540, 66, 135, 135, 540, 540, 135, 540, 66, 540, 135, 135, 135, 540, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 540, 135]
Prompts retrieved: 16101 . Total input tokens: 3538570 . Total output tokens: 3185444
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 0.8844536440446973,
    "estimated_duration": 3599.9092453646886,
    "input_throughput": 358.99071668654807,
    "output_throughput": 328.352999876877,
    "total_throughput": 687.3437165634251,
    "itl": 21.306755154270952,
    "ttft": 4020.1794205037418,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1534,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.392261049980176,
    "arrivals": 5423,
    "finished_requests": 5417,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8845378267578781. Arrivals time: 0.027086966671049595 Scheduler time: 0.48071067268028855 Scheduler overhead time: 0.13316136598587036 Adapter cache time: 0.037759493570774794 Engine time: 0.13846106408163905 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-16/adapters_64_slots_32_rate_0.05-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-16/adapters_64_slots_32_rate_0.05-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 540, 540, 66, 540, 66, 135, 66, 540, 135, 540, 66, 135, 540, 540, 540, 66, 540, 135, 135, 66, 66, 66, 540, 66, 66, 66, 540, 135, 66, 540, 540, 540, 540, 135, 135, 135, 540, 66, 135, 135, 540, 540, 135, 540, 66, 540, 135, 135, 135, 540, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 540, 135]
Prompts retrieved: 16101 . Total input tokens: 3538570 . Total output tokens: 3185444
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 0.8583306977525353,
    "estimated_duration": 3599.9126784256077,
    "input_throughput": 358.9903743346329,
    "output_throughput": 328.3526867426562,
    "total_throughput": 687.3430610772891,
    "itl": 21.29314943262286,
    "ttft": 4020.193625115727,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1534,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.792934722835396,
    "arrivals": 5423,
    "finished_requests": 5417,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8584035229869187. Arrivals time: 0.02561422437429428 Scheduler time: 0.45793572068214417 Scheduler overhead time: 0.13320172764360905 Adapter cache time: 0.03770943684503436 Engine time: 0.13745741080492735 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-32/adapters_64_slots_32_rate_0.05-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-32/adapters_64_slots_32_rate_0.05-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 540, 540, 66, 540, 66, 135, 66, 540, 135, 540, 66, 135, 540, 540, 540, 66, 540, 135, 135, 66, 66, 66, 540, 66, 66, 66, 540, 135, 66, 540, 540, 540, 540, 135, 135, 135, 540, 66, 135, 135, 540, 540, 135, 540, 66, 540, 135, 135, 135, 540, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 540, 135]
Prompts retrieved: 16101 . Total input tokens: 3538570 . Total output tokens: 3185444
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 0.8599999500438571,
    "estimated_duration": 3599.90799336245,
    "input_throughput": 358.9908415389559,
    "output_throughput": 328.3531140738764,
    "total_throughput": 687.3439556128324,
    "itl": 21.30250534659451,
    "ttft": 4020.373438052471,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1534,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.291602102145434,
    "arrivals": 5423,
    "finished_requests": 5417,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8600480100139976. Arrivals time: 0.02578162355348468 Scheduler time: 0.4554603174328804 Scheduler overhead time: 0.13306213961914182 Adapter cache time: 0.038020582403987646 Engine time: 0.1375336511991918 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-8/adapters_64_slots_32_rate_0.05-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-8/adapters_64_slots_32_rate_0.05-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 540, 540, 33, 540, 33, 135, 33, 540, 135, 540, 33, 135, 540, 540, 540, 33, 540, 135, 135, 33, 33, 33, 540, 33, 33, 33, 540, 135, 33, 540, 540, 540, 540, 135, 135, 135, 540, 33, 135, 135, 540, 540, 135, 540, 33, 540, 135, 135, 135, 540, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 540, 135]
Prompts retrieved: 15408 . Total input tokens: 3381381 . Total output tokens: 3050672
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 0.8354060482233763,
    "estimated_duration": 3598.5165285543603,
    "input_throughput": 342.1723897137852,
    "output_throughput": 308.8078076569027,
    "total_throughput": 650.9801973706878,
    "itl": 21.259324587261805,
    "ttft": 2131.9192417457207,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1151,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.610882795774556,
    "arrivals": 5154,
    "finished_requests": 5151,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8354756264016032. Arrivals time: 0.025172322522848845 Scheduler time: 0.4356653173454106 Scheduler overhead time: 0.13328813156113029 Adapter cache time: 0.036091127432882786 Engine time: 0.1384310876019299 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-16/adapters_64_slots_32_rate_0.05-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-16/adapters_64_slots_32_rate_0.05-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 540, 540, 33, 540, 33, 135, 33, 540, 135, 540, 33, 135, 540, 540, 540, 33, 540, 135, 135, 33, 33, 33, 540, 33, 33, 33, 540, 135, 33, 540, 540, 540, 540, 135, 135, 135, 540, 33, 135, 135, 540, 540, 135, 540, 33, 540, 135, 135, 135, 540, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 540, 135]
Prompts retrieved: 15408 . Total input tokens: 3381381 . Total output tokens: 3050672
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 0.8299648966640234,
    "estimated_duration": 3598.5188480201246,
    "input_throughput": 342.172169162726,
    "output_throughput": 308.8076086113598,
    "total_throughput": 650.9797777740858,
    "itl": 21.26352759018133,
    "ttft": 2131.8694141210863,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1151,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.402940942314453,
    "arrivals": 5154,
    "finished_requests": 5151,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8300240589305758. Arrivals time: 0.02525918697938323 Scheduler time: 0.43114558048546314 Scheduler overhead time: 0.13359061954542994 Adapter cache time: 0.03618134092539549 Engine time: 0.1366708753630519 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-32/adapters_64_slots_32_rate_0.05-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-32/adapters_64_slots_32_rate_0.05-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 540, 540, 33, 540, 33, 135, 33, 540, 135, 540, 33, 135, 540, 540, 540, 33, 540, 135, 135, 33, 33, 33, 540, 33, 33, 33, 540, 135, 33, 540, 540, 540, 540, 135, 135, 135, 540, 33, 135, 135, 540, 540, 135, 540, 33, 540, 135, 135, 135, 540, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 540, 135]
Prompts retrieved: 15408 . Total input tokens: 3381381 . Total output tokens: 3050672
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 0.836093416903168,
    "estimated_duration": 3598.519455883044,
    "input_throughput": 342.1721113629069,
    "output_throughput": 308.80755644749166,
    "total_throughput": 650.9796678103985,
    "itl": 21.265332879611595,
    "ttft": 2132.2479746961258,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1151,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.62741715280338,
    "arrivals": 5154,
    "finished_requests": 5151,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8362566106952727. Arrivals time: 0.024980255402624607 Scheduler time: 0.43764167884364724 Scheduler overhead time: 0.13388662412762642 Adapter cache time: 0.03621502872556448 Engine time: 0.13668656302616 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-16/adapters_64_slots_32_rate_0.05-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-16/adapters_64_slots_32_rate_0.05-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 540, 540, 33, 540, 33, 135, 33, 540, 135, 540, 33, 135, 540, 540, 540, 33, 540, 135, 135, 33, 33, 33, 540, 33, 33, 33, 540, 135, 33, 540, 540, 540, 540, 135, 135, 135, 540, 33, 135, 135, 540, 540, 135, 540, 33, 540, 135, 135, 135, 540, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 540, 135]
Prompts retrieved: 15408 . Total input tokens: 3381381 . Total output tokens: 3050672
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 0.8320448896847665,
    "estimated_duration": 3598.5188480201246,
    "input_throughput": 342.172169162726,
    "output_throughput": 308.8076086113598,
    "total_throughput": 650.9797777740858,
    "itl": 21.259573890314936,
    "ttft": 2131.974525486969,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1151,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.807394144763223,
    "arrivals": 5154,
    "finished_requests": 5151,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8321044477634132. Arrivals time: 0.024931782390922308 Scheduler time: 0.4338413500227034 Scheduler overhead time: 0.13255862100049853 Adapter cache time: 0.03626750409603119 Engine time: 0.13762429729104042 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-32/adapters_64_slots_32_rate_0.05-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-32/adapters_64_slots_32_rate_0.05-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 540, 540, 33, 540, 33, 135, 33, 540, 135, 540, 33, 135, 540, 540, 540, 33, 540, 135, 135, 33, 33, 33, 540, 33, 33, 33, 540, 135, 33, 540, 540, 540, 540, 135, 135, 135, 540, 33, 135, 135, 540, 540, 135, 540, 33, 540, 135, 135, 135, 540, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 540, 135]
Prompts retrieved: 15408 . Total input tokens: 3381381 . Total output tokens: 3050672
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 0.8331767753697932,
    "estimated_duration": 3598.519455883044,
    "input_throughput": 342.1721113629069,
    "output_throughput": 308.80755644749166,
    "total_throughput": 650.9796678103985,
    "itl": 21.265109805425585,
    "ttft": 2132.153736136404,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1151,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.538563884035678,
    "arrivals": 5154,
    "finished_requests": 5151,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8332295101135969. Arrivals time: 0.02497623162344098 Scheduler time: 0.43530477909371257 Scheduler overhead time: 0.13262965669855475 Adapter cache time: 0.036142741329967976 Engine time: 0.1375354314222932 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-16/adapters_64_slots_32_rate_0.05-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-16/adapters_64_slots_32_rate_0.05-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 540, 540, 33, 540, 33, 135, 33, 540, 135, 540, 33, 135, 540, 540, 540, 33, 540, 135, 135, 33, 33, 33, 540, 33, 33, 33, 540, 135, 33, 540, 540, 540, 540, 135, 135, 135, 540, 33, 135, 135, 540, 540, 135, 540, 33, 540, 135, 135, 135, 540, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 540, 135]
Prompts retrieved: 15408 . Total input tokens: 3381381 . Total output tokens: 3050672
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 0.8313540150411427,
    "estimated_duration": 3598.516071578178,
    "input_throughput": 342.1724331663165,
    "output_throughput": 308.8078468724599,
    "total_throughput": 650.9802800387764,
    "itl": 21.256198523844553,
    "ttft": 2131.678631674351,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1151,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.3478930025966465,
    "arrivals": 5154,
    "finished_requests": 5151,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8314023436978459. Arrivals time: 0.024415662046521902 Scheduler time: 0.4326893459074199 Scheduler overhead time: 0.1332514462992549 Adapter cache time: 0.0361186065711081 Engine time: 0.13804045831784606 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-32/adapters_64_slots_32_rate_0.05-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-32/adapters_64_slots_32_rate_0.05-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 540, 540, 33, 540, 33, 135, 33, 540, 135, 540, 33, 135, 540, 540, 540, 33, 540, 135, 135, 33, 33, 33, 540, 33, 33, 33, 540, 135, 33, 540, 540, 540, 540, 135, 135, 135, 540, 33, 135, 135, 540, 540, 135, 540, 33, 540, 135, 135, 135, 540, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 540, 135]
Prompts retrieved: 15408 . Total input tokens: 3381381 . Total output tokens: 3050672
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 0.8391137821599841,
    "estimated_duration": 3598.5190416486907,
    "input_throughput": 342.17215075117787,
    "output_throughput": 308.8075919950869,
    "total_throughput": 650.9797427462648,
    "itl": 21.260830790210782,
    "ttft": 2132.0777845171206,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1151,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.470008098576214,
    "arrivals": 5154,
    "finished_requests": 5151,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8391842301934958. Arrivals time: 0.02520536771044135 Scheduler time: 0.4376267925836146 Scheduler overhead time: 0.13288572570309043 Adapter cache time: 0.03617309592664242 Engine time: 0.14030114468187094 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-8/adapters_64_slots_32_rate_0.05-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-8/adapters_64_slots_32_rate_0.05-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 540, 540, 33, 540, 33, 66, 33, 540, 66, 540, 33, 66, 540, 540, 540, 33, 540, 66, 66, 33, 33, 33, 540, 33, 33, 33, 540, 66, 33, 540, 540, 540, 540, 66, 66, 66, 540, 33, 66, 66, 540, 540, 66, 540, 33, 540, 66, 66, 66, 540, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 540, 66]
Prompts retrieved: 13959 . Total input tokens: 3065593 . Total output tokens: 2758665
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 0.7946692239493132,
    "estimated_duration": 3599.3991099276723,
    "input_throughput": 316.8487197917091,
    "output_throughput": 274.13631271910486,
    "total_throughput": 590.9850325108139,
    "itl": 20.982683240618396,
    "ttft": 3883.4479021289108,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 725,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.793996548163792,
    "arrivals": 4678,
    "finished_requests": 4673,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7948130271397531. Arrivals time: 0.023973744362592697 Scheduler time: 0.39711258094757795 Scheduler overhead time: 0.13333941251039505 Adapter cache time: 0.03410337818786502 Engine time: 0.13883534725755453 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-16/adapters_64_slots_32_rate_0.05-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-16/adapters_64_slots_32_rate_0.05-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 540, 540, 33, 540, 33, 66, 33, 540, 66, 540, 33, 66, 540, 540, 540, 33, 540, 66, 66, 33, 33, 33, 540, 33, 33, 33, 540, 66, 33, 540, 540, 540, 540, 66, 66, 66, 540, 33, 66, 66, 540, 540, 66, 540, 33, 540, 66, 66, 66, 540, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 540, 66]
Prompts retrieved: 13959 . Total input tokens: 3065593 . Total output tokens: 2758665
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 0.8005781201645732,
    "estimated_duration": 3599.4041943214334,
    "input_throughput": 316.8482722221761,
    "output_throughput": 274.13592548363954,
    "total_throughput": 590.9841977058156,
    "itl": 20.984973295413887,
    "ttft": 3883.2829334156845,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 725,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.300241632997066,
    "arrivals": 4678,
    "finished_requests": 4673,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8006285759620368. Arrivals time: 0.023820968344807625 Scheduler time: 0.40230429312214255 Scheduler overhead time: 0.13366448786109686 Adapter cache time: 0.034143400844186544 Engine time: 0.13934407429769635 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-32/adapters_64_slots_32_rate_0.05-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-32/adapters_64_slots_32_rate_0.05-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 540, 540, 33, 540, 33, 66, 33, 540, 66, 540, 33, 66, 540, 540, 540, 33, 540, 66, 66, 33, 33, 33, 540, 33, 33, 33, 540, 66, 33, 540, 540, 540, 540, 66, 66, 66, 540, 33, 66, 66, 540, 540, 66, 540, 33, 540, 66, 66, 66, 540, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 540, 66]
Prompts retrieved: 13959 . Total input tokens: 3065593 . Total output tokens: 2758665
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 0.795509051065892,
    "estimated_duration": 3599.411787774726,
    "input_throughput": 316.84760378724906,
    "output_throughput": 274.1353471562714,
    "total_throughput": 590.9829509435204,
    "itl": 20.985648065774516,
    "ttft": 3883.5414292161563,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 725,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.4433308548108,
    "arrivals": 4678,
    "finished_requests": 4673,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7956855609081686. Arrivals time: 0.023767651990056038 Scheduler time: 0.3979396387003362 Scheduler overhead time: 0.13349656481295824 Adapter cache time: 0.034023893531411886 Engine time: 0.1390985087491572 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-16/adapters_64_slots_32_rate_0.05-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-16/adapters_64_slots_32_rate_0.05-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 540, 540, 33, 540, 33, 66, 33, 540, 66, 540, 33, 66, 540, 540, 540, 33, 540, 66, 66, 33, 33, 33, 540, 33, 33, 33, 540, 66, 33, 540, 540, 540, 540, 66, 66, 66, 540, 33, 66, 66, 540, 540, 66, 540, 33, 540, 66, 66, 66, 540, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 540, 66]
Prompts retrieved: 13959 . Total input tokens: 3065593 . Total output tokens: 2758665
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 0.8244909779168665,
    "estimated_duration": 3599.405050372428,
    "input_throughput": 316.84819686575617,
    "output_throughput": 274.1358602855503,
    "total_throughput": 590.9840571513065,
    "itl": 20.981891782070665,
    "ttft": 3883.496136689145,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 724,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.920426270235321,
    "arrivals": 4678,
    "finished_requests": 4673,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.824540609959513. Arrivals time: 0.024220702704042196 Scheduler time: 0.4233416449278593 Scheduler overhead time: 0.1343182185664773 Adapter cache time: 0.03405846143141389 Engine time: 0.14067302271723747 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-32/adapters_64_slots_32_rate_0.05-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-32/adapters_64_slots_32_rate_0.05-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 540, 540, 33, 540, 33, 66, 33, 540, 66, 540, 33, 66, 540, 540, 540, 33, 540, 66, 66, 33, 33, 33, 540, 33, 33, 33, 540, 66, 33, 540, 540, 540, 540, 66, 66, 66, 540, 33, 66, 66, 540, 540, 66, 540, 33, 540, 66, 66, 66, 540, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 540, 66]
Prompts retrieved: 13959 . Total input tokens: 3065593 . Total output tokens: 2758665
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 0.798854841850698,
    "estimated_duration": 3599.4086835532144,
    "input_throughput": 316.8478770446738,
    "output_throughput": 274.13558357756074,
    "total_throughput": 590.9834606222345,
    "itl": 20.98311544872037,
    "ttft": 3883.316645154565,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 724,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.381249067322377,
    "arrivals": 4678,
    "finished_requests": 4673,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.798903132788837. Arrivals time: 0.02411387860774994 Scheduler time: 0.40012180572375655 Scheduler overhead time: 0.133825923781842 Adapter cache time: 0.03414246952161193 Engine time: 0.1392253483645618 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-16/adapters_64_slots_32_rate_0.05-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-16/adapters_64_slots_32_rate_0.05-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 540, 540, 33, 540, 33, 66, 33, 540, 66, 540, 33, 66, 540, 540, 540, 33, 540, 66, 66, 33, 33, 33, 540, 33, 33, 33, 540, 66, 33, 540, 540, 540, 540, 66, 66, 66, 540, 33, 66, 66, 540, 540, 66, 540, 33, 540, 66, 66, 66, 540, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 540, 66]
Prompts retrieved: 13959 . Total input tokens: 3065593 . Total output tokens: 2758665
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 0.7930564139969647,
    "estimated_duration": 3599.4124338289716,
    "input_throughput": 316.8475469166504,
    "output_throughput": 274.1352979520448,
    "total_throughput": 590.9828448686952,
    "itl": 20.979200531933945,
    "ttft": 3883.4138578371962,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 724,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.621958760973044,
    "arrivals": 4678,
    "finished_requests": 4673,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7931422940455377. Arrivals time: 0.02363299997523427 Scheduler time: 0.39581881556659937 Scheduler overhead time: 0.13530432805418968 Adapter cache time: 0.03404782712459564 Engine time: 0.13722718134522438 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-32/adapters_64_slots_32_rate_0.05-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-32/adapters_64_slots_32_rate_0.05-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 540, 540, 33, 540, 33, 66, 33, 540, 66, 540, 33, 66, 540, 540, 540, 33, 540, 66, 66, 33, 33, 33, 540, 33, 33, 33, 540, 66, 33, 540, 540, 540, 540, 66, 66, 66, 540, 33, 66, 66, 540, 540, 66, 540, 33, 540, 66, 66, 66, 540, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 540, 66]
Prompts retrieved: 13959 . Total input tokens: 3065593 . Total output tokens: 2758665
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 0.8280330006964505,
    "estimated_duration": 3599.4059943686184,
    "input_throughput": 316.84811376774184,
    "output_throughput": 274.13578838946296,
    "total_throughput": 590.9839021572047,
    "itl": 20.983637693299777,
    "ttft": 3883.3475305679613,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 724,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.336718874350217,
    "arrivals": 4678,
    "finished_requests": 4673,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8280806336551905. Arrivals time: 0.0250796633772552 Scheduler time: 0.4248035061173141 Scheduler overhead time: 0.13472346775233746 Adapter cache time: 0.034301388543099165 Engine time: 0.14057690557092428 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-8/adapters_64_slots_32_rate_0.025-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-8/adapters_64_slots_32_rate_0.025-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 270, 270, 66, 270, 66, 135, 66, 270, 135, 270, 66, 135, 270, 270, 270, 66, 270, 135, 135, 66, 66, 66, 270, 66, 66, 66, 270, 135, 66, 270, 270, 270, 270, 135, 135, 135, 270, 66, 135, 135, 270, 270, 135, 270, 66, 270, 135, 135, 135, 270, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 270, 135]
Prompts retrieved: 10161 . Total input tokens: 2255137 . Total output tokens: 2013818
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 0.7127333292737603,
    "estimated_duration": 3599.854937979588,
    "input_throughput": 222.07478183792665,
    "output_throughput": 200.40224187613933,
    "total_throughput": 422.477023714066,
    "itl": 20.594486473362693,
    "ttft": 4398.632832399782,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1284,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.490333197023926,
    "arrivals": 3301,
    "finished_requests": 3297,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7127995928749442. Arrivals time: 0.02077997848391533 Scheduler time: 0.3216909966431558 Scheduler overhead time: 0.132250739261508 Adapter cache time: 0.03178845485672355 Engine time: 0.13920583482831717 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-16/adapters_64_slots_32_rate_0.025-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-16/adapters_64_slots_32_rate_0.025-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 270, 270, 66, 270, 66, 135, 66, 270, 135, 270, 66, 135, 270, 270, 270, 66, 270, 135, 135, 66, 66, 66, 270, 66, 66, 66, 270, 135, 66, 270, 270, 270, 270, 135, 135, 135, 270, 66, 135, 135, 270, 270, 135, 270, 66, 270, 135, 135, 135, 270, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 270, 135]
Prompts retrieved: 10161 . Total input tokens: 2255137 . Total output tokens: 2013818
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 0.71409404091537,
    "estimated_duration": 3599.849628836513,
    "input_throughput": 222.07510935904884,
    "output_throughput": 200.4025374340888,
    "total_throughput": 422.47764679313764,
    "itl": 20.597021312063802,
    "ttft": 4399.19134948344,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1284,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.38804808279496,
    "arrivals": 3301,
    "finished_requests": 3297,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7141766627319157. Arrivals time: 0.020575241651386023 Scheduler time: 0.32496723672375083 Scheduler overhead time: 0.1330176773481071 Adapter cache time: 0.0317226555198431 Engine time: 0.13675879873335361 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-32/adapters_64_slots_32_rate_0.025-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-32/adapters_64_slots_32_rate_0.025-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 270, 270, 66, 270, 66, 135, 66, 270, 135, 270, 66, 135, 270, 270, 270, 66, 270, 135, 135, 66, 66, 66, 270, 66, 66, 66, 270, 135, 66, 270, 270, 270, 270, 135, 135, 135, 270, 66, 135, 135, 270, 270, 135, 270, 66, 270, 135, 135, 135, 270, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 270, 135]
Prompts retrieved: 10161 . Total input tokens: 2255137 . Total output tokens: 2013818
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 0.7155876881442964,
    "estimated_duration": 3599.8510578556948,
    "input_throughput": 222.0750212027374,
    "output_throughput": 200.4024578810558,
    "total_throughput": 422.4774790837932,
    "itl": 20.59992047533402,
    "ttft": 4399.225066503264,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1285,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.649802761063867,
    "arrivals": 3301,
    "finished_requests": 3297,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7157467640936375. Arrivals time: 0.020957533735781908 Scheduler time: 0.3260727231390774 Scheduler overhead time: 0.13211686769500375 Adapter cache time: 0.031890786718577147 Engine time: 0.13760277116671205 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-16/adapters_64_slots_32_rate_0.025-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-16/adapters_64_slots_32_rate_0.025-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 270, 270, 66, 270, 66, 135, 66, 270, 135, 270, 66, 135, 270, 270, 270, 66, 270, 135, 135, 66, 66, 66, 270, 66, 66, 66, 270, 135, 66, 270, 270, 270, 270, 135, 135, 135, 270, 66, 135, 135, 270, 270, 135, 270, 66, 270, 135, 135, 135, 270, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 270, 135]
Prompts retrieved: 10161 . Total input tokens: 2255137 . Total output tokens: 2013818
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 0.7134944777935743,
    "estimated_duration": 3599.8647907140585,
    "input_throughput": 222.07417402513778,
    "output_throughput": 200.40169338051763,
    "total_throughput": 422.4758674056554,
    "itl": 20.596441552140703,
    "ttft": 4398.637266839938,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1286,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.809433790044878,
    "arrivals": 3301,
    "finished_requests": 3297,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7135426858440042. Arrivals time: 0.020928841084241867 Scheduler time: 0.32195462053641677 Scheduler overhead time: 0.13348155934363604 Adapter cache time: 0.03157153818756342 Engine time: 0.13832612754777074 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-32/adapters_64_slots_32_rate_0.025-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-32/adapters_64_slots_32_rate_0.025-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 270, 270, 66, 270, 66, 135, 66, 270, 135, 270, 66, 135, 270, 270, 270, 66, 270, 135, 135, 66, 66, 66, 270, 66, 66, 66, 270, 135, 66, 270, 270, 270, 270, 135, 135, 135, 270, 66, 135, 135, 270, 270, 135, 270, 66, 270, 135, 135, 135, 270, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 270, 135]
Prompts retrieved: 10161 . Total input tokens: 2255137 . Total output tokens: 2013818
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 0.7108313571661711,
    "estimated_duration": 3599.8651603351736,
    "input_throughput": 222.074151223366,
    "output_throughput": 200.40167280399766,
    "total_throughput": 422.4758240273636,
    "itl": 20.59988889860896,
    "ttft": 4399.1821834589,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1285,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.561363726649391,
    "arrivals": 3301,
    "finished_requests": 3297,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7108918982557952. Arrivals time: 0.020930724684149027 Scheduler time: 0.3205634946934879 Scheduler overhead time: 0.13375324197113514 Adapter cache time: 0.03136238269507885 Engine time: 0.13690937543287873 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-16/adapters_64_slots_32_rate_0.025-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-16/adapters_64_slots_32_rate_0.025-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 270, 270, 66, 270, 66, 135, 66, 270, 135, 270, 66, 135, 270, 270, 270, 66, 270, 135, 135, 66, 66, 66, 270, 66, 66, 66, 270, 135, 66, 270, 270, 270, 270, 135, 135, 135, 270, 66, 135, 135, 270, 270, 135, 270, 66, 270, 135, 135, 135, 270, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 270, 135]
Prompts retrieved: 10161 . Total input tokens: 2255137 . Total output tokens: 2013818
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 0.7204572320915759,
    "estimated_duration": 3599.850072489818,
    "input_throughput": 222.0750819900323,
    "output_throughput": 200.40251273604687,
    "total_throughput": 422.47759472607913,
    "itl": 20.588717766497115,
    "ttft": 4398.638288105619,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1285,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.20333840863312,
    "arrivals": 3301,
    "finished_requests": 3297,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7205193052068353. Arrivals time: 0.021071018185466528 Scheduler time: 0.3264471688307822 Scheduler overhead time: 0.13421370601281524 Adapter cache time: 0.031803933903574944 Engine time: 0.13909212313592434 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-32/adapters_64_slots_32_rate_0.025-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-32/adapters_64_slots_32_rate_0.025-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 270, 270, 66, 270, 66, 135, 66, 270, 135, 270, 66, 135, 270, 270, 270, 66, 270, 135, 135, 66, 66, 66, 270, 66, 66, 66, 270, 135, 66, 270, 270, 270, 270, 135, 135, 135, 270, 66, 135, 135, 270, 270, 135, 270, 66, 270, 135, 135, 135, 270, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 270, 135]
Prompts retrieved: 10161 . Total input tokens: 2255137 . Total output tokens: 2013818
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 0.7115656319074333,
    "estimated_duration": 3599.8561198851994,
    "input_throughput": 222.07470892628183,
    "output_throughput": 200.40217608002797,
    "total_throughput": 422.47688500630983,
    "itl": 20.598769687237187,
    "ttft": 4399.050982239324,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1284,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.464020150154791,
    "arrivals": 3301,
    "finished_requests": 3297,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7116143847815692. Arrivals time: 0.020599999465048313 Scheduler time: 0.3220336209051311 Scheduler overhead time: 0.13214190909639 Adapter cache time: 0.031879310961812735 Engine time: 0.13782917615026236 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-8/adapters_64_slots_32_rate_0.025-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-8/adapters_64_slots_32_rate_0.025-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 270, 270, 33, 270, 33, 135, 33, 270, 135, 270, 33, 135, 270, 270, 270, 33, 270, 135, 135, 33, 33, 33, 270, 33, 33, 33, 270, 135, 33, 270, 270, 270, 270, 135, 135, 135, 270, 33, 135, 135, 270, 270, 135, 270, 33, 270, 135, 135, 135, 270, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 270, 135]
Prompts retrieved: 9468 . Total input tokens: 2094336 . Total output tokens: 1877251
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 0.6985720470547676,
    "estimated_duration": 3599.356608832235,
    "input_throughput": 200.28523937612454,
    "output_throughput": 182.79572476522753,
    "total_throughput": 383.08096414135207,
    "itl": 20.54875375982749,
    "ttft": 5887.693720381388,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1038,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.863680575164189,
    "arrivals": 3076,
    "finished_requests": 3071,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6986239957623184. Arrivals time: 0.021072104573249817 Scheduler time: 0.30666871182620525 Scheduler overhead time: 0.13268205663189292 Adapter cache time: 0.030795206781476736 Engine time: 0.14027447951957583 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-16/adapters_64_slots_32_rate_0.025-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-16/adapters_64_slots_32_rate_0.025-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 270, 270, 33, 270, 33, 135, 33, 270, 135, 270, 33, 135, 270, 270, 270, 33, 270, 135, 135, 33, 33, 33, 270, 33, 33, 33, 270, 135, 33, 270, 270, 270, 270, 135, 135, 135, 270, 33, 135, 135, 270, 270, 135, 270, 33, 270, 135, 135, 135, 270, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 270, 135]
Prompts retrieved: 9468 . Total input tokens: 2094336 . Total output tokens: 1877251
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 0.6878883540630341,
    "estimated_duration": 3599.37243410685,
    "input_throughput": 200.28435878680722,
    "output_throughput": 182.79492107164043,
    "total_throughput": 383.07927985844765,
    "itl": 20.721067275292985,
    "ttft": 5888.144522569347,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1032,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.534973114468168,
    "arrivals": 3076,
    "finished_requests": 3071,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6879505999386311. Arrivals time: 0.020327189471572638 Scheduler time: 0.30276061687618494 Scheduler overhead time: 0.1307869264855981 Adapter cache time: 0.030429321341216564 Engine time: 0.13706032279878855 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-32/adapters_64_slots_32_rate_0.025-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-32/adapters_64_slots_32_rate_0.025-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 270, 270, 33, 270, 33, 135, 33, 270, 135, 270, 33, 135, 270, 270, 270, 33, 270, 135, 135, 33, 33, 33, 270, 33, 33, 33, 270, 135, 33, 270, 270, 270, 270, 135, 135, 135, 270, 33, 135, 135, 270, 270, 135, 270, 33, 270, 135, 135, 135, 270, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 270, 135]
Prompts retrieved: 9468 . Total input tokens: 2094336 . Total output tokens: 1877251
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 0.7055356269702315,
    "estimated_duration": 3599.3724174528884,
    "input_throughput": 200.28435971350433,
    "output_throughput": 182.79492191741556,
    "total_throughput": 383.0792816309199,
    "itl": 20.719897960114203,
    "ttft": 5888.147393287734,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1032,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.736425483515504,
    "arrivals": 3076,
    "finished_requests": 3071,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7056207791902125. Arrivals time: 0.0207546460442245 Scheduler time: 0.31496149906888604 Scheduler overhead time: 0.13203378301113844 Adapter cache time: 0.03096785256639123 Engine time: 0.13959815120324492 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-16/adapters_64_slots_32_rate_0.025-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-16/adapters_64_slots_32_rate_0.025-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 270, 270, 33, 270, 33, 135, 33, 270, 135, 270, 33, 135, 270, 270, 270, 33, 270, 135, 135, 33, 33, 33, 270, 33, 33, 33, 270, 135, 33, 270, 270, 270, 270, 135, 135, 135, 270, 33, 135, 135, 270, 270, 135, 270, 33, 270, 135, 135, 135, 270, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 270, 135]
Prompts retrieved: 9468 . Total input tokens: 2094336 . Total output tokens: 1877251
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 0.6968477945774794,
    "estimated_duration": 3599.356380344144,
    "input_throughput": 200.28525209028427,
    "output_throughput": 182.7957363691483,
    "total_throughput": 383.0809884594326,
    "itl": 20.55109021216187,
    "ttft": 5887.709218650275,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1038,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.090175741398696,
    "arrivals": 3076,
    "finished_requests": 3071,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6969030206091702. Arrivals time: 0.02081745443865657 Scheduler time: 0.3059257371351123 Scheduler overhead time: 0.13317395839840174 Adapter cache time: 0.030863888561725616 Engine time: 0.13829601043835282 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-32/adapters_64_slots_32_rate_0.025-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-32/adapters_64_slots_32_rate_0.025-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 270, 270, 33, 270, 33, 135, 33, 270, 135, 270, 33, 135, 270, 270, 270, 33, 270, 135, 135, 33, 33, 33, 270, 33, 33, 33, 270, 135, 33, 270, 270, 270, 270, 135, 135, 135, 270, 33, 135, 135, 270, 270, 135, 270, 33, 270, 135, 135, 135, 270, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 270, 135]
Prompts retrieved: 9468 . Total input tokens: 2094336 . Total output tokens: 1877251
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 0.6879431679844856,
    "estimated_duration": 3599.3724174528884,
    "input_throughput": 200.28435971350433,
    "output_throughput": 182.79492191741556,
    "total_throughput": 383.0792816309199,
    "itl": 20.71958596116864,
    "ttft": 5888.034654872443,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1032,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.662277534287441,
    "arrivals": 3076,
    "finished_requests": 3071,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6879922589287162. Arrivals time: 0.020462035201489925 Scheduler time: 0.30137195996940136 Scheduler overhead time: 0.1314048175700009 Adapter cache time: 0.030453260987997055 Engine time: 0.13744320115074515 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-16/adapters_64_slots_32_rate_0.025-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-16/adapters_64_slots_32_rate_0.025-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 270, 270, 33, 270, 33, 135, 33, 270, 135, 270, 33, 135, 270, 270, 270, 33, 270, 135, 135, 33, 33, 33, 270, 33, 33, 33, 270, 135, 33, 270, 270, 270, 270, 135, 135, 135, 270, 33, 135, 135, 270, 270, 135, 270, 33, 270, 135, 135, 135, 270, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 270, 135]
Prompts retrieved: 9468 . Total input tokens: 2094336 . Total output tokens: 1877251
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 0.6917806281708181,
    "estimated_duration": 3599.356380344144,
    "input_throughput": 200.28525209028427,
    "output_throughput": 182.7957363691483,
    "total_throughput": 383.0809884594326,
    "itl": 20.547415560937505,
    "ttft": 5887.638091812845,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1038,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.62650993631218,
    "arrivals": 3076,
    "finished_requests": 3071,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6918769921176136. Arrivals time: 0.020597958471626043 Scheduler time: 0.30260338773950934 Scheduler overhead time: 0.13195253163576126 Adapter cache time: 0.030716046690940857 Engine time: 0.1387977972626686 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-32/adapters_64_slots_32_rate_0.025-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-32/adapters_64_slots_32_rate_0.025-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 270, 270, 33, 270, 33, 135, 33, 270, 135, 270, 33, 135, 270, 270, 270, 33, 270, 135, 135, 33, 33, 33, 270, 33, 33, 33, 270, 135, 33, 270, 270, 270, 270, 135, 135, 135, 270, 33, 135, 135, 270, 270, 135, 270, 33, 270, 135, 135, 135, 270, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 270, 135]
Prompts retrieved: 9468 . Total input tokens: 2094336 . Total output tokens: 1877251
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 0.6868664361536503,
    "estimated_duration": 3599.3724174528884,
    "input_throughput": 200.28435971350433,
    "output_throughput": 182.79492191741556,
    "total_throughput": 383.0792816309199,
    "itl": 20.720183349766902,
    "ttft": 5887.94256785415,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1032,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.595171569064278,
    "arrivals": 3076,
    "finished_requests": 3071,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6869295341894031. Arrivals time: 0.020636199973523617 Scheduler time: 0.3019979386590421 Scheduler overhead time: 0.13055703230202198 Adapter cache time: 0.030428624711930752 Engine time: 0.13648909702897072 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-8/adapters_64_slots_32_rate_0.025-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-8/adapters_64_slots_32_rate_0.025-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 270, 270, 33, 270, 33, 66, 33, 270, 66, 270, 33, 66, 270, 270, 270, 33, 270, 66, 66, 33, 33, 33, 270, 33, 33, 33, 270, 66, 33, 270, 270, 270, 270, 66, 66, 66, 270, 33, 66, 66, 270, 270, 66, 270, 33, 270, 66, 66, 66, 270, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 270, 66]
Prompts retrieved: 8019 . Total input tokens: 1777244 . Total output tokens: 1590756
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 0.6689143017865717,
    "estimated_duration": 3599.42803109981,
    "input_throughput": 173.1200053497391,
    "output_throughput": 160.7410941407864,
    "total_throughput": 333.8610994905255,
    "itl": 20.342382197881435,
    "ttft": 16707.986708787343,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 719,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.754322093972091,
    "arrivals": 2591,
    "finished_requests": 2579,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6689633717760444. Arrivals time: 0.019534521270543337 Scheduler time: 0.28363681910559535 Scheduler overhead time: 0.1326100379228592 Adapter cache time: 0.028571083210408688 Engine time: 0.13819604041054845 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-16/adapters_64_slots_32_rate_0.025-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-16/adapters_64_slots_32_rate_0.025-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 270, 270, 33, 270, 33, 66, 33, 270, 66, 270, 33, 66, 270, 270, 270, 33, 270, 66, 66, 33, 33, 33, 270, 33, 33, 33, 270, 66, 33, 270, 270, 270, 270, 66, 66, 66, 270, 33, 66, 66, 270, 270, 66, 270, 33, 270, 66, 66, 66, 270, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 270, 66]
Prompts retrieved: 8019 . Total input tokens: 1777244 . Total output tokens: 1590756
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 0.6653991178609431,
    "estimated_duration": 3599.447118767625,
    "input_throughput": 173.1190873039823,
    "output_throughput": 160.74024173970705,
    "total_throughput": 333.85932904368934,
    "itl": 20.342665784996953,
    "ttft": 16708.11667300599,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 719,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.257773444433703,
    "arrivals": 2591,
    "finished_requests": 2579,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6654477696865797. Arrivals time: 0.019436008296906948 Scheduler time: 0.281181747559458 Scheduler overhead time: 0.13123351242393255 Adapter cache time: 0.028779943007975817 Engine time: 0.13793663261458278 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-32/adapters_64_slots_32_rate_0.025-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-32/adapters_64_slots_32_rate_0.025-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 270, 270, 33, 270, 33, 66, 33, 270, 66, 270, 33, 66, 270, 270, 270, 33, 270, 66, 66, 33, 33, 33, 270, 33, 33, 33, 270, 66, 33, 270, 270, 270, 270, 66, 66, 66, 270, 33, 66, 66, 270, 270, 66, 270, 33, 270, 66, 66, 66, 270, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 270, 66]
Prompts retrieved: 8019 . Total input tokens: 1777244 . Total output tokens: 1590756
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 0.6622368958778679,
    "estimated_duration": 3599.4283813392813,
    "input_throughput": 173.11998850443683,
    "output_throughput": 160.74107850000408,
    "total_throughput": 333.8610670044409,
    "itl": 20.344881713661408,
    "ttft": 16708.32976099695,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 720,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.406368100731658,
    "arrivals": 2591,
    "finished_requests": 2579,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6622854666784406. Arrivals time: 0.019031845964491367 Scheduler time: 0.27880080603063107 Scheduler overhead time: 0.13109583873301744 Adapter cache time: 0.02853084821254015 Engine time: 0.13815862964838743 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-16/adapters_64_slots_32_rate_0.025-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-16/adapters_64_slots_32_rate_0.025-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 270, 270, 33, 270, 33, 66, 33, 270, 66, 270, 33, 66, 270, 270, 270, 33, 270, 66, 66, 33, 33, 33, 270, 33, 33, 33, 270, 66, 33, 270, 270, 270, 270, 66, 66, 66, 270, 33, 66, 66, 270, 270, 66, 270, 33, 270, 66, 66, 66, 270, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 270, 66]
Prompts retrieved: 8019 . Total input tokens: 1777244 . Total output tokens: 1590756
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 0.6672105100005865,
    "estimated_duration": 3599.4337312699067,
    "input_throughput": 173.11973119176002,
    "output_throughput": 160.74083958641853,
    "total_throughput": 333.86057077817856,
    "itl": 20.340805791440882,
    "ttft": 16708.057648721682,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 720,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.949031204432242,
    "arrivals": 2591,
    "finished_requests": 2579,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6672837738879025. Arrivals time: 0.019650581292808056 Scheduler time: 0.2821168410591781 Scheduler overhead time: 0.13177103735506535 Adapter cache time: 0.028587143402546644 Engine time: 0.13783007394522429 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-32/adapters_64_slots_32_rate_0.025-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-32/adapters_64_slots_32_rate_0.025-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 270, 270, 33, 270, 33, 66, 33, 270, 66, 270, 33, 66, 270, 270, 270, 33, 270, 66, 66, 33, 33, 33, 270, 33, 33, 33, 270, 66, 33, 270, 270, 270, 270, 66, 66, 66, 270, 33, 66, 66, 270, 270, 66, 270, 33, 270, 66, 66, 66, 270, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 270, 66]
Prompts retrieved: 8019 . Total input tokens: 1777244 . Total output tokens: 1590756
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 0.6607081638649106,
    "estimated_duration": 3599.4499694214965,
    "input_throughput": 173.11895019897997,
    "output_throughput": 160.74011443837034,
    "total_throughput": 333.8590646373503,
    "itl": 20.344541311450214,
    "ttft": 16708.40024213629,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 719,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.352985234661054,
    "arrivals": 2591,
    "finished_requests": 2579,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.660768480040133. Arrivals time: 0.01889342861250043 Scheduler time: 0.2780945375561714 Scheduler overhead time: 0.13134459080174565 Adapter cache time: 0.02868581609800458 Engine time: 0.13720642169937491 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-16/adapters_64_slots_32_rate_0.025-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-16/adapters_64_slots_32_rate_0.025-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 270, 270, 33, 270, 33, 66, 33, 270, 66, 270, 33, 66, 270, 270, 270, 33, 270, 66, 66, 33, 33, 33, 270, 33, 33, 33, 270, 66, 33, 270, 270, 270, 270, 66, 66, 66, 270, 33, 66, 66, 270, 270, 66, 270, 33, 270, 66, 66, 66, 270, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 270, 66]
Prompts retrieved: 8019 . Total input tokens: 1777244 . Total output tokens: 1590756
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 0.673975873272866,
    "estimated_duration": 3599.4461898059303,
    "input_throughput": 173.1191319833558,
    "output_throughput": 160.74028322429092,
    "total_throughput": 333.8594152076467,
    "itl": 20.339864043972153,
    "ttft": 16707.941640941022,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 719,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.590039156270191,
    "arrivals": 2591,
    "finished_requests": 2579,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6740627898834646. Arrivals time: 0.019235550425946712 Scheduler time: 0.28530601039528847 Scheduler overhead time: 0.13619143469259143 Adapter cache time: 0.028398932423442602 Engine time: 0.13788731256499887 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-32/adapters_64_slots_32_rate_0.025-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-32/adapters_64_slots_32_rate_0.025-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 270, 270, 33, 270, 33, 66, 33, 270, 66, 270, 33, 66, 270, 270, 270, 33, 270, 66, 66, 33, 33, 33, 270, 33, 33, 33, 270, 66, 33, 270, 270, 270, 270, 66, 66, 66, 270, 33, 66, 66, 270, 270, 66, 270, 33, 270, 66, 66, 66, 270, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 270, 66]
Prompts retrieved: 8019 . Total input tokens: 1777244 . Total output tokens: 1590756
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 0.6664369245991111,
    "estimated_duration": 3599.4485179105004,
    "input_throughput": 173.11902001080213,
    "output_throughput": 160.7401792583122,
    "total_throughput": 333.85919926911436,
    "itl": 20.34295147058594,
    "ttft": 16708.163810019443,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 719,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.300377471800919,
    "arrivals": 2591,
    "finished_requests": 2579,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6664876360446215. Arrivals time: 0.019161997828632593 Scheduler time: 0.2808504132553935 Scheduler overhead time: 0.13126213429495692 Adapter cache time: 0.02866586623713374 Engine time: 0.13729535834863782 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-8/adapters_64_slots_32_rate_0.0125-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-8/adapters_64_slots_32_rate_0.0125-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 135, 135, 33, 135, 33, 66, 33, 135, 66, 135, 33, 66, 135, 135, 135, 33, 135, 66, 66, 33, 33, 33, 135, 33, 33, 33, 135, 66, 33, 135, 135, 135, 135, 66, 66, 66, 135, 33, 66, 66, 135, 135, 66, 135, 33, 135, 66, 66, 66, 135, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 135, 66]
Prompts retrieved: 5049 . Total input tokens: 1143301 . Total output tokens: 982410
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 0.5529788499698043,
    "estimated_duration": 3599.293695716341,
    "input_throughput": 116.92293977033827,
    "output_throughput": 96.55227646846298,
    "total_throughput": 213.47521623880124,
    "itl": 19.869068340805224,
    "ttft": 8787.754134271969,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 663,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.384027188182882,
    "arrivals": 1645,
    "finished_requests": 1641,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.553026249166578. Arrivals time: 0.01570017682388425 Scheduler time: 0.20993439154699445 Scheduler overhead time: 0.11915571196004748 Adapter cache time: 0.023835135158151388 Engine time: 0.1240541348233819 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-16/adapters_64_slots_32_rate_0.0125-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-16/adapters_64_slots_32_rate_0.0125-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 135, 135, 33, 135, 33, 66, 33, 135, 66, 135, 33, 66, 135, 135, 135, 33, 135, 66, 66, 33, 33, 33, 135, 33, 33, 33, 135, 66, 33, 135, 135, 135, 135, 66, 66, 66, 135, 33, 66, 66, 135, 135, 66, 135, 33, 135, 66, 66, 66, 135, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 135, 66]
Prompts retrieved: 5049 . Total input tokens: 1143301 . Total output tokens: 982410
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 0.5406787288375199,
    "estimated_duration": 3599.2815129339615,
    "input_throughput": 116.92333552897101,
    "output_throughput": 96.55260327684633,
    "total_throughput": 213.47593880581732,
    "itl": 19.87219447354218,
    "ttft": 8788.007880529933,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 663,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.836415706989361,
    "arrivals": 1645,
    "finished_requests": 1641,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.5407409020699561. Arrivals time: 0.01584190782159567 Scheduler time: 0.20152147533372045 Scheduler overhead time: 0.11716683069244027 Adapter cache time: 0.023783710319548845 Engine time: 0.12299610208719969 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-32/adapters_64_slots_32_rate_0.0125-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-32/adapters_64_slots_32_rate_0.0125-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 135, 135, 33, 135, 33, 66, 33, 135, 66, 135, 33, 66, 135, 135, 135, 33, 135, 66, 66, 33, 33, 33, 135, 33, 33, 33, 135, 66, 33, 135, 135, 135, 135, 66, 66, 66, 135, 33, 66, 66, 135, 135, 66, 135, 33, 135, 66, 66, 66, 135, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 135, 66]
Prompts retrieved: 5049 . Total input tokens: 1143301 . Total output tokens: 982410
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 0.5381735870614648,
    "estimated_duration": 3599.284217545315,
    "input_throughput": 116.92324766922955,
    "output_throughput": 96.55253072429107,
    "total_throughput": 213.47577839352064,
    "itl": 19.873068183598512,
    "ttft": 8788.083233956771,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 663,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.964828788773187,
    "arrivals": 1645,
    "finished_requests": 1641,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.5382331251166761. Arrivals time: 0.0153352664783597 Scheduler time: 0.19857528060674667 Scheduler overhead time: 0.11762441135942936 Adapter cache time: 0.02365904301404953 Engine time: 0.12280482240021229 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-16/adapters_64_slots_32_rate_0.0125-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-16/adapters_64_slots_32_rate_0.0125-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 135, 135, 33, 135, 33, 66, 33, 135, 66, 135, 33, 66, 135, 135, 135, 33, 135, 66, 66, 33, 33, 33, 135, 33, 33, 33, 135, 66, 33, 135, 135, 135, 135, 66, 66, 66, 135, 33, 66, 66, 135, 135, 66, 135, 33, 135, 66, 66, 66, 135, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 135, 66]
Prompts retrieved: 5049 . Total input tokens: 1143301 . Total output tokens: 982410
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 0.5411659087985754,
    "estimated_duration": 3599.2965342992343,
    "input_throughput": 116.92284755913714,
    "output_throughput": 96.55220032257233,
    "total_throughput": 213.4750478817095,
    "itl": 19.869850094820748,
    "ttft": 8787.739620655962,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 663,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.542112860647023,
    "arrivals": 1645,
    "finished_requests": 1641,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.541215498931706. Arrivals time: 0.015792990569025278 Scheduler time: 0.2009392180480063 Scheduler overhead time: 0.11801586346700788 Adapter cache time: 0.02378438226878643 Engine time: 0.1228502825833857 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-32/adapters_64_slots_32_rate_0.0125-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-32/adapters_64_slots_32_rate_0.0125-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 135, 135, 33, 135, 33, 66, 33, 135, 66, 135, 33, 66, 135, 135, 135, 33, 135, 66, 66, 33, 33, 33, 135, 33, 33, 33, 135, 66, 33, 135, 135, 135, 135, 66, 66, 66, 135, 33, 66, 66, 135, 135, 66, 135, 33, 135, 66, 66, 66, 135, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 135, 66]
Prompts retrieved: 5049 . Total input tokens: 1143301 . Total output tokens: 982410
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 0.5431937873363495,
    "estimated_duration": 3599.283181959432,
    "input_throughput": 116.92328131039046,
    "output_throughput": 96.55255850438859,
    "total_throughput": 213.47583981477905,
    "itl": 19.872728021067353,
    "ttft": 8788.094588367105,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 663,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.920919947330871,
    "arrivals": 1645,
    "finished_requests": 1641,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.5432416261173785. Arrivals time: 0.01579871354624629 Scheduler time: 0.2009099735878408 Scheduler overhead time: 0.11788408365100622 Adapter cache time: 0.024015291593968868 Engine time: 0.12489884486421943 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-16/adapters_64_slots_32_rate_0.0125-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-16/adapters_64_slots_32_rate_0.0125-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 135, 135, 33, 135, 33, 66, 33, 135, 66, 135, 33, 66, 135, 135, 135, 33, 135, 66, 66, 33, 33, 33, 135, 33, 33, 33, 135, 66, 33, 135, 135, 135, 135, 66, 66, 66, 135, 33, 66, 66, 135, 135, 66, 135, 33, 135, 66, 66, 66, 135, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 135, 66]
Prompts retrieved: 5049 . Total input tokens: 1143301 . Total output tokens: 982410
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 0.5459012128412724,
    "estimated_duration": 3599.2909738069225,
    "input_throughput": 116.92302819154493,
    "output_throughput": 96.55234948466328,
    "total_throughput": 213.4753776762082,
    "itl": 19.868140881230314,
    "ttft": 8787.637272759917,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 663,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.232539583598244,
    "arrivals": 1645,
    "finished_requests": 1641,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.5459479717537761. Arrivals time: 0.016030712984502316 Scheduler time: 0.20453524263575673 Scheduler overhead time: 0.1174395252019167 Adapter cache time: 0.023723706603050232 Engine time: 0.12402046471834183 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-32/adapters_64_slots_32_rate_0.0125-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-32/adapters_64_slots_32_rate_0.0125-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 135, 135, 33, 135, 33, 66, 33, 135, 66, 135, 33, 66, 135, 135, 135, 33, 135, 66, 66, 33, 33, 33, 135, 33, 33, 33, 135, 66, 33, 135, 135, 135, 135, 66, 66, 66, 135, 33, 66, 66, 135, 135, 66, 135, 33, 135, 66, 66, 66, 135, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 135, 66]
Prompts retrieved: 5049 . Total input tokens: 1143301 . Total output tokens: 982410
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 0.5407587508670986,
    "estimated_duration": 3599.2823534907257,
    "input_throughput": 116.92330822333314,
    "output_throughput": 96.55258072847812,
    "total_throughput": 213.47588895181124,
    "itl": 19.872437821450408,
    "ttft": 8788.04875247082,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 663,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.874732816945793,
    "arrivals": 1645,
    "finished_requests": 1641,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.5408172658644617. Arrivals time: 0.015770655125379562 Scheduler time: 0.20104646915569901 Scheduler overhead time: 0.11862851493060589 Adapter cache time: 0.023650615010410547 Engine time: 0.12179965432733297 
