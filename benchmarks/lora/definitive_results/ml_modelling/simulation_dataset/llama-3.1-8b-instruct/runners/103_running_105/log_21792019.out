INFO 05-31 19:30:52 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 05-31 19:30:52 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-8/adapters_128_slots_64_rate_0.1-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-8/adapters_128_slots_64_rate_0.1-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [42 43 43]
Adapter prompts. [1080, 270, 1080, 1080, 66, 66, 1080, 66, 270, 270, 270, 66, 1080, 270, 66, 1080, 270, 66, 66, 66, 66, 270, 270, 1080, 270, 66, 270, 270, 270, 270, 1080, 270, 66, 270, 66, 1080, 1080, 66, 270, 270, 66, 270, 66, 270, 270, 1080, 1080, 1080, 1080, 270, 270, 66, 270, 1080, 1080, 270, 66, 66, 66, 1080, 270, 270, 270, 270, 1080, 270, 1080, 66, 66, 270, 66, 1080, 1080, 66, 66, 270, 270, 270, 66, 1080, 66, 1080, 270, 66, 1080, 1080, 270, 270, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 66, 1080, 66, 66, 1080, 270, 1080, 1080, 270, 1080, 66, 270, 1080, 66, 1080, 270, 66, 270, 270, 1080, 1080, 66, 66, 1080, 66, 66, 66, 270, 66]
Prompts retrieved: 60822 . Total input tokens: 13504370 . Total output tokens: 11961085
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.8128005950711668,
    "estimated_duration": 3599.6047774165686,
    "input_throughput": 1388.89414509226,
    "output_throughput": 1234.5716473877533,
    "total_throughput": 2623.465792480013,
    "itl": 29.310593110953597,
    "ttft": 5334.035392806201,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4418,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 29.21362310315215,
    "arrivals": 20438,
    "finished_requests": 20408,
    "scheduler_time": 0.18972745716367684
}
#Debug simulation 
Total elapsed time: 1.8128958512097597. Arrivals time: 0.05882206046953797 Scheduler time: 1.3905609427019954 Scheduler overhead time: 0.10796805657446384 Adapter cache time: 0.09188636811450124 Engine time: 0.11088041588664055 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-16/adapters_128_slots_64_rate_0.1-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-16/adapters_128_slots_64_rate_0.1-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [42 43 43]
Adapter prompts. [1080, 270, 1080, 1080, 66, 66, 1080, 66, 270, 270, 270, 66, 1080, 270, 66, 1080, 270, 66, 66, 66, 66, 270, 270, 1080, 270, 66, 270, 270, 270, 270, 1080, 270, 66, 270, 66, 1080, 1080, 66, 270, 270, 66, 270, 66, 270, 270, 1080, 1080, 1080, 1080, 270, 270, 66, 270, 1080, 1080, 270, 66, 66, 66, 1080, 270, 270, 270, 270, 1080, 270, 1080, 66, 66, 270, 66, 1080, 1080, 66, 66, 270, 270, 270, 66, 1080, 66, 1080, 270, 66, 1080, 1080, 270, 270, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 66, 1080, 66, 66, 1080, 270, 1080, 1080, 270, 1080, 66, 270, 1080, 66, 1080, 270, 66, 270, 270, 1080, 1080, 66, 66, 1080, 66, 66, 66, 270, 66]
Prompts retrieved: 60822 . Total input tokens: 13504370 . Total output tokens: 11961085
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.8451866190880537,
    "estimated_duration": 3599.6062102607075,
    "input_throughput": 1388.8935922348865,
    "output_throughput": 1234.5711559593453,
    "total_throughput": 2623.464748194232,
    "itl": 29.34904514658793,
    "ttft": 5334.276643454973,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4424,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 32.30856547191648,
    "arrivals": 20438,
    "finished_requests": 20408,
    "scheduler_time": 0.1926533553235971
}
#Debug simulation 
Total elapsed time: 1.8452800088562071. Arrivals time: 0.05891637271270156 Scheduler time: 1.422746195923537 Scheduler overhead time: 0.10982295544818044 Adapter cache time: 0.09178069746121764 Engine time: 0.1089648762717843 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-32/adapters_128_slots_64_rate_0.1-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-32/adapters_128_slots_64_rate_0.1-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [42 43 43]
Adapter prompts. [1080, 270, 1080, 1080, 66, 66, 1080, 66, 270, 270, 270, 66, 1080, 270, 66, 1080, 270, 66, 66, 66, 66, 270, 270, 1080, 270, 66, 270, 270, 270, 270, 1080, 270, 66, 270, 66, 1080, 1080, 66, 270, 270, 66, 270, 66, 270, 270, 1080, 1080, 1080, 1080, 270, 270, 66, 270, 1080, 1080, 270, 66, 66, 66, 1080, 270, 270, 270, 270, 1080, 270, 1080, 66, 66, 270, 66, 1080, 1080, 66, 66, 270, 270, 270, 66, 1080, 66, 1080, 270, 66, 1080, 1080, 270, 270, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 66, 1080, 66, 66, 1080, 270, 1080, 1080, 270, 1080, 66, 270, 1080, 66, 1080, 270, 66, 270, 270, 1080, 1080, 66, 66, 1080, 66, 66, 66, 270, 66]
Prompts retrieved: 60822 . Total input tokens: 13504370 . Total output tokens: 11961085
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.813907579984516,
    "estimated_duration": 3599.620506177123,
    "input_throughput": 1388.8880762348886,
    "output_throughput": 1234.5662528519138,
    "total_throughput": 2623.4543290868023,
    "itl": 29.360086675372436,
    "ttft": 5334.397382385767,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4421,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 33.15136363145556,
    "arrivals": 20438,
    "finished_requests": 20408,
    "scheduler_time": 0.1936620139899148
}
#Debug simulation 
Total elapsed time: 1.8140326659195125. Arrivals time: 0.058401142712682486 Scheduler time: 1.3929905551485717 Scheduler overhead time: 0.10927721066400409 Adapter cache time: 0.09213788947090507 Engine time: 0.10815103491768241 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-16/adapters_128_slots_64_rate_0.1-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-16/adapters_128_slots_64_rate_0.1-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [42 43 43]
Adapter prompts. [1080, 270, 1080, 1080, 66, 66, 1080, 66, 270, 270, 270, 66, 1080, 270, 66, 1080, 270, 66, 66, 66, 66, 270, 270, 1080, 270, 66, 270, 270, 270, 270, 1080, 270, 66, 270, 66, 1080, 1080, 66, 270, 270, 66, 270, 66, 270, 270, 1080, 1080, 1080, 1080, 270, 270, 66, 270, 1080, 1080, 270, 66, 66, 66, 1080, 270, 270, 270, 270, 1080, 270, 1080, 66, 66, 270, 66, 1080, 1080, 66, 66, 270, 270, 270, 66, 1080, 66, 1080, 270, 66, 1080, 1080, 270, 270, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 66, 1080, 66, 66, 1080, 270, 1080, 1080, 270, 1080, 66, 270, 1080, 66, 1080, 270, 66, 270, 270, 1080, 1080, 66, 66, 1080, 66, 66, 66, 270, 66]
Prompts retrieved: 60822 . Total input tokens: 13504370 . Total output tokens: 11961085
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 1.8245552070438862,
    "estimated_duration": 3599.6087669894546,
    "input_throughput": 1388.8926057320737,
    "output_throughput": 1234.570279068614,
    "total_throughput": 2623.4628848006873,
    "itl": 29.324177021575416,
    "ttft": 5334.003346938736,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4419,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 30.32341895776419,
    "arrivals": 20438,
    "finished_requests": 20408,
    "scheduler_time": 0.19073765868000847
}
#Debug simulation 
Total elapsed time: 1.8246370758861303. Arrivals time: 0.05877932161092758 Scheduler time: 1.400820932816714 Scheduler overhead time: 0.10972902923822403 Adapter cache time: 0.09219993371516466 Engine time: 0.11018941178917885 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-32/adapters_128_slots_64_rate_0.1-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-32/adapters_128_slots_64_rate_0.1-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [42 43 43]
Adapter prompts. [1080, 270, 1080, 1080, 66, 66, 1080, 66, 270, 270, 270, 66, 1080, 270, 66, 1080, 270, 66, 66, 66, 66, 270, 270, 1080, 270, 66, 270, 270, 270, 270, 1080, 270, 66, 270, 66, 1080, 1080, 66, 270, 270, 66, 270, 66, 270, 270, 1080, 1080, 1080, 1080, 270, 270, 66, 270, 1080, 1080, 270, 66, 66, 66, 1080, 270, 270, 270, 270, 1080, 270, 1080, 66, 66, 270, 66, 1080, 1080, 66, 66, 270, 270, 270, 66, 1080, 66, 1080, 270, 66, 1080, 1080, 270, 270, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 66, 1080, 66, 66, 1080, 270, 1080, 1080, 270, 1080, 66, 270, 1080, 66, 1080, 270, 66, 270, 270, 1080, 1080, 66, 66, 1080, 66, 66, 66, 270, 66]
Prompts retrieved: 60822 . Total input tokens: 13504370 . Total output tokens: 11961085
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 1.8321154308505356,
    "estimated_duration": 3599.6037056407527,
    "input_throughput": 1388.8945586331045,
    "output_throughput": 1234.5720149793392,
    "total_throughput": 2623.4665736124434,
    "itl": 29.357875488790317,
    "ttft": 5334.520700875714,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4421,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 32.86098534984183,
    "arrivals": 20438,
    "finished_requests": 20408,
    "scheduler_time": 0.19325498935974444
}
#Debug simulation 
Total elapsed time: 1.8321987581439316. Arrivals time: 0.05873078294098377 Scheduler time: 1.408827682491392 Scheduler overhead time: 0.11020871484652162 Adapter cache time: 0.09198453230783343 Engine time: 0.10959914932027459 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-16/adapters_128_slots_64_rate_0.1-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-16/adapters_128_slots_64_rate_0.1-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [42 43 43]
Adapter prompts. [1080, 270, 1080, 1080, 66, 66, 1080, 66, 270, 270, 270, 66, 1080, 270, 66, 1080, 270, 66, 66, 66, 66, 270, 270, 1080, 270, 66, 270, 270, 270, 270, 1080, 270, 66, 270, 66, 1080, 1080, 66, 270, 270, 66, 270, 66, 270, 270, 1080, 1080, 1080, 1080, 270, 270, 66, 270, 1080, 1080, 270, 66, 66, 66, 1080, 270, 270, 270, 270, 1080, 270, 1080, 66, 66, 270, 66, 1080, 1080, 66, 66, 270, 270, 270, 66, 1080, 66, 1080, 270, 66, 1080, 1080, 270, 270, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 66, 1080, 66, 66, 1080, 270, 1080, 1080, 270, 1080, 66, 270, 1080, 66, 1080, 270, 66, 270, 270, 1080, 1080, 66, 66, 1080, 66, 66, 66, 270, 66]
Prompts retrieved: 60822 . Total input tokens: 13504370 . Total output tokens: 11961085
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.814050868153572,
    "estimated_duration": 3599.6150815611136,
    "input_throughput": 1388.8901692877075,
    "output_throughput": 1234.568113341913,
    "total_throughput": 2623.4582826296205,
    "itl": 29.296736852847392,
    "ttft": 5333.976646829757,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4420,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 28.216930557324414,
    "arrivals": 20438,
    "finished_requests": 20408,
    "scheduler_time": 0.1887014517811914
}
#Debug simulation 
Total elapsed time: 1.8141879439353943. Arrivals time: 0.058456676080822945 Scheduler time: 1.3933015423826873 Scheduler overhead time: 0.10963549371808767 Adapter cache time: 0.09220570232719183 Engine time: 0.10778900189325213 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-32/adapters_128_slots_64_rate_0.1-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-32/adapters_128_slots_64_rate_0.1-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [42 43 43]
Adapter prompts. [1080, 270, 1080, 1080, 66, 66, 1080, 66, 270, 270, 270, 66, 1080, 270, 66, 1080, 270, 66, 66, 66, 66, 270, 270, 1080, 270, 66, 270, 270, 270, 270, 1080, 270, 66, 270, 66, 1080, 1080, 66, 270, 270, 66, 270, 66, 270, 270, 1080, 1080, 1080, 1080, 270, 270, 66, 270, 1080, 1080, 270, 66, 66, 66, 1080, 270, 270, 270, 270, 1080, 270, 1080, 66, 66, 270, 66, 1080, 1080, 66, 66, 270, 270, 270, 66, 1080, 66, 1080, 270, 66, 1080, 1080, 270, 270, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 66, 1080, 66, 66, 1080, 270, 1080, 1080, 270, 1080, 66, 270, 1080, 66, 1080, 270, 66, 270, 270, 1080, 1080, 66, 66, 1080, 66, 66, 66, 270, 66]
Prompts retrieved: 60822 . Total input tokens: 13504370 . Total output tokens: 11961085
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.8565411819145083,
    "estimated_duration": 3599.6155518826176,
    "input_throughput": 1388.8899878169632,
    "output_throughput": 1234.5679520347057,
    "total_throughput": 2623.457939851669,
    "itl": 29.353425394200762,
    "ttft": 5334.287108885923,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4422,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 32.551498922483546,
    "arrivals": 20438,
    "finished_requests": 20408,
    "scheduler_time": 0.1929335313084601
}
#Debug simulation 
Total elapsed time: 1.8566214367747307. Arrivals time: 0.059024471789598465 Scheduler time: 1.4339723042212427 Scheduler overhead time: 0.10907167242839932 Adapter cache time: 0.09348561195656657 Engine time: 0.10819538123905659 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-8/adapters_128_slots_64_rate_0.1-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-8/adapters_128_slots_64_rate_0.1-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 270, 1080, 1080, 33, 33, 1080, 33, 270, 270, 270, 33, 1080, 270, 33, 1080, 270, 33, 33, 33, 33, 270, 270, 1080, 270, 33, 270, 270, 270, 270, 1080, 270, 33, 270, 33, 1080, 1080, 33, 270, 270, 33, 270, 33, 270, 270, 1080, 1080, 1080, 1080, 270, 270, 33, 270, 1080, 1080, 270, 33, 33, 33, 1080, 270, 270, 270, 270, 1080, 270, 1080, 33, 33, 270, 33, 1080, 1080, 33, 33, 270, 270, 270, 33, 1080, 33, 1080, 270, 33, 1080, 1080, 270, 270, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 270, 1080, 1080, 270, 1080, 33, 270, 1080, 33, 1080, 270, 33, 270, 270, 1080, 1080, 33, 33, 1080, 33, 33, 33, 270, 33]
Prompts retrieved: 59436 . Total input tokens: 13204866 . Total output tokens: 11688792
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.8272069348022342,
    "estimated_duration": 3600.0098222976753,
    "input_throughput": 1366.2159946166146,
    "output_throughput": 1187.3803714434828,
    "total_throughput": 2553.5963660600974,
    "itl": 28.625511817994752,
    "ttft": 6714.007450524866,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3482,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 23.02440824924847,
    "arrivals": 19983,
    "finished_requests": 19946,
    "scheduler_time": 0.12966824884486228
}
#Debug simulation 
Total elapsed time: 1.8272930248640478. Arrivals time: 0.05847066594287753 Scheduler time: 1.3982889563776553 Scheduler overhead time: 0.11141325440257788 Adapter cache time: 0.09128714399412274 Engine time: 0.11387038696557283 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-16/adapters_128_slots_64_rate_0.1-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-16/adapters_128_slots_64_rate_0.1-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 270, 1080, 1080, 33, 33, 1080, 33, 270, 270, 270, 33, 1080, 270, 33, 1080, 270, 33, 33, 33, 33, 270, 270, 1080, 270, 33, 270, 270, 270, 270, 1080, 270, 33, 270, 33, 1080, 1080, 33, 270, 270, 33, 270, 33, 270, 270, 1080, 1080, 1080, 1080, 270, 270, 33, 270, 1080, 1080, 270, 33, 33, 33, 1080, 270, 270, 270, 270, 1080, 270, 1080, 33, 33, 270, 33, 1080, 1080, 33, 33, 270, 270, 270, 33, 1080, 33, 1080, 270, 33, 1080, 1080, 270, 270, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 270, 1080, 1080, 270, 1080, 33, 270, 1080, 33, 1080, 270, 33, 270, 270, 1080, 1080, 33, 33, 1080, 33, 33, 33, 270, 33]
Prompts retrieved: 59436 . Total input tokens: 13204866 . Total output tokens: 11688792
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.8245982420630753,
    "estimated_duration": 3600.0141592202654,
    "input_throughput": 1366.2143487416963,
    "output_throughput": 1187.378941011121,
    "total_throughput": 2553.5932897528173,
    "itl": 28.656108132727823,
    "ttft": 6714.24439663679,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3481,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 25.43199568442469,
    "arrivals": 19983,
    "finished_requests": 19946,
    "scheduler_time": 0.1313459688100042
}
#Debug simulation 
Total elapsed time: 1.8247210807166994. Arrivals time: 0.05945792328566313 Scheduler time: 1.3934221202507615 Scheduler overhead time: 0.11317532090470195 Adapter cache time: 0.09222033573314548 Engine time: 0.11155637027695775 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-32/adapters_128_slots_64_rate_0.1-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-32/adapters_128_slots_64_rate_0.1-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 270, 1080, 1080, 33, 33, 1080, 33, 270, 270, 270, 33, 1080, 270, 33, 1080, 270, 33, 33, 33, 33, 270, 270, 1080, 270, 33, 270, 270, 270, 270, 1080, 270, 33, 270, 33, 1080, 1080, 33, 270, 270, 33, 270, 33, 270, 270, 1080, 1080, 1080, 1080, 270, 270, 33, 270, 1080, 1080, 270, 33, 33, 33, 1080, 270, 270, 270, 270, 1080, 270, 1080, 33, 33, 270, 33, 1080, 1080, 33, 33, 270, 270, 270, 33, 1080, 33, 1080, 270, 33, 1080, 1080, 270, 270, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 270, 1080, 1080, 270, 1080, 33, 270, 1080, 33, 1080, 270, 33, 270, 270, 1080, 1080, 33, 33, 1080, 33, 33, 33, 270, 33]
Prompts retrieved: 59436 . Total input tokens: 13204866 . Total output tokens: 11688792
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.8176971320062876,
    "estimated_duration": 3600.036854555212,
    "input_throughput": 1366.2057358597992,
    "output_throughput": 1187.3714555425374,
    "total_throughput": 2553.5771914023367,
    "itl": 28.65903828947941,
    "ttft": 6714.2454024881945,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3480,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 26.107140665078425,
    "arrivals": 19983,
    "finished_requests": 19946,
    "scheduler_time": 0.13182438225690685
}
#Debug simulation 
Total elapsed time: 1.8177886279299855. Arrivals time: 0.05875457311049104 Scheduler time: 1.3920045583508909 Scheduler overhead time: 0.11129662208259106 Adapter cache time: 0.09158493299037218 Engine time: 0.11017691483721137 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-16/adapters_128_slots_64_rate_0.1-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-16/adapters_128_slots_64_rate_0.1-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 270, 1080, 1080, 33, 33, 1080, 33, 270, 270, 270, 33, 1080, 270, 33, 1080, 270, 33, 33, 33, 33, 270, 270, 1080, 270, 33, 270, 270, 270, 270, 1080, 270, 33, 270, 33, 1080, 1080, 33, 270, 270, 33, 270, 33, 270, 270, 1080, 1080, 1080, 1080, 270, 270, 33, 270, 1080, 1080, 270, 33, 33, 33, 1080, 270, 270, 270, 270, 1080, 270, 1080, 33, 33, 270, 33, 1080, 1080, 33, 33, 270, 270, 270, 33, 1080, 33, 1080, 270, 33, 1080, 1080, 270, 270, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 270, 1080, 1080, 270, 1080, 33, 270, 1080, 33, 1080, 270, 33, 270, 270, 1080, 1080, 33, 33, 1080, 33, 33, 33, 270, 33]
Prompts retrieved: 59436 . Total input tokens: 13204866 . Total output tokens: 11688792
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 1.8325211531482637,
    "estimated_duration": 3600.0165335248334,
    "input_throughput": 1366.2134476877875,
    "output_throughput": 1187.3781579038166,
    "total_throughput": 2553.591605591604,
    "itl": 28.63786598434631,
    "ttft": 6714.129351172717,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3480,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 23.873580715321626,
    "arrivals": 19983,
    "finished_requests": 19946,
    "scheduler_time": 0.13032175652154096
}
#Debug simulation 
Total elapsed time: 1.8326288373209536. Arrivals time: 0.05887163383886218 Scheduler time: 1.4022629517130554 Scheduler overhead time: 0.11196554824709892 Adapter cache time: 0.09168605739250779 Engine time: 0.11358204158023 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-32/adapters_128_slots_64_rate_0.1-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-32/adapters_128_slots_64_rate_0.1-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 270, 1080, 1080, 33, 33, 1080, 33, 270, 270, 270, 33, 1080, 270, 33, 1080, 270, 33, 33, 33, 33, 270, 270, 1080, 270, 33, 270, 270, 270, 270, 1080, 270, 33, 270, 33, 1080, 1080, 33, 270, 270, 33, 270, 33, 270, 270, 1080, 1080, 1080, 1080, 270, 270, 33, 270, 1080, 1080, 270, 33, 33, 33, 1080, 270, 270, 270, 270, 1080, 270, 1080, 33, 33, 270, 33, 1080, 1080, 33, 33, 270, 270, 270, 33, 1080, 33, 1080, 270, 33, 1080, 1080, 270, 270, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 270, 1080, 1080, 270, 1080, 33, 270, 1080, 33, 1080, 270, 33, 270, 270, 1080, 1080, 33, 33, 1080, 33, 33, 33, 270, 33]
Prompts retrieved: 59436 . Total input tokens: 13204866 . Total output tokens: 11688792
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 1.8270931239239872,
    "estimated_duration": 3600.0166032977445,
    "input_throughput": 1366.2134212088292,
    "output_throughput": 1187.3781348909142,
    "total_throughput": 2553.5915560997432,
    "itl": 28.65901080320498,
    "ttft": 6714.188788087427,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3482,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 25.888525312757917,
    "arrivals": 19983,
    "finished_requests": 19946,
    "scheduler_time": 0.1317540358021731
}
#Debug simulation 
Total elapsed time: 1.8272236692719162. Arrivals time: 0.0586733459495008 Scheduler time: 1.3994762394577265 Scheduler overhead time: 0.1119901118800044 Adapter cache time: 0.0915388516150415 Engine time: 0.11150686675682664 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-16/adapters_128_slots_64_rate_0.1-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-16/adapters_128_slots_64_rate_0.1-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 270, 1080, 1080, 33, 33, 1080, 33, 270, 270, 270, 33, 1080, 270, 33, 1080, 270, 33, 33, 33, 33, 270, 270, 1080, 270, 33, 270, 270, 270, 270, 1080, 270, 33, 270, 33, 1080, 1080, 33, 270, 270, 33, 270, 33, 270, 270, 1080, 1080, 1080, 1080, 270, 270, 33, 270, 1080, 1080, 270, 33, 33, 33, 1080, 270, 270, 270, 270, 1080, 270, 1080, 33, 33, 270, 33, 1080, 1080, 33, 33, 270, 270, 270, 33, 1080, 33, 1080, 270, 33, 1080, 1080, 270, 270, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 270, 1080, 1080, 270, 1080, 33, 270, 1080, 33, 1080, 270, 33, 270, 270, 1080, 1080, 33, 33, 1080, 33, 33, 33, 270, 33]
Prompts retrieved: 59436 . Total input tokens: 13204866 . Total output tokens: 11688792
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.81687130080536,
    "estimated_duration": 3600.0248124278296,
    "input_throughput": 1366.2103058348296,
    "output_throughput": 1187.3754273146953,
    "total_throughput": 2553.585733149525,
    "itl": 28.619458628535575,
    "ttft": 6714.00380167165,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3482,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 22.228812715068454,
    "arrivals": 19983,
    "finished_requests": 19946,
    "scheduler_time": 0.12930963678918256
}
#Debug simulation 
Total elapsed time: 1.8169431248679757. Arrivals time: 0.05821791337803006 Scheduler time: 1.3901958419010043 Scheduler overhead time: 0.1119684036821127 Adapter cache time: 0.09099258203059435 Engine time: 0.1110761514864862 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-32/adapters_128_slots_64_rate_0.1-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-32/adapters_128_slots_64_rate_0.1-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 270, 1080, 1080, 33, 33, 1080, 33, 270, 270, 270, 33, 1080, 270, 33, 1080, 270, 33, 33, 33, 33, 270, 270, 1080, 270, 33, 270, 270, 270, 270, 1080, 270, 33, 270, 33, 1080, 1080, 33, 270, 270, 33, 270, 33, 270, 270, 1080, 1080, 1080, 1080, 270, 270, 33, 270, 1080, 1080, 270, 33, 33, 33, 1080, 270, 270, 270, 270, 1080, 270, 1080, 33, 33, 270, 33, 1080, 1080, 33, 33, 270, 270, 270, 33, 1080, 33, 1080, 270, 33, 1080, 1080, 270, 270, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 270, 1080, 1080, 270, 1080, 33, 270, 1080, 33, 1080, 270, 33, 270, 270, 1080, 1080, 33, 33, 1080, 33, 33, 33, 270, 33]
Prompts retrieved: 59436 . Total input tokens: 13204866 . Total output tokens: 11688792
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.8086517178453505,
    "estimated_duration": 3600.021307513204,
    "input_throughput": 1366.211635952091,
    "output_throughput": 1187.3765833216034,
    "total_throughput": 2553.5882192736944,
    "itl": 28.65746173561126,
    "ttft": 6714.21023522073,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3479,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 25.620623913724753,
    "arrivals": 19983,
    "finished_requests": 19946,
    "scheduler_time": 0.13156488893224724
}
#Debug simulation 
Total elapsed time: 1.808734823949635. Arrivals time: 0.05847342172637582 Scheduler time: 1.3828484085388482 Scheduler overhead time: 0.11156923091039062 Adapter cache time: 0.09077714895829558 Engine time: 0.11109897401183844 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-8/adapters_128_slots_64_rate_0.1-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-8/adapters_128_slots_64_rate_0.1-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [42 43 43]
Adapter prompts. [1080, 135, 1080, 1080, 66, 66, 1080, 66, 135, 135, 135, 66, 1080, 135, 66, 1080, 135, 66, 66, 66, 66, 135, 135, 1080, 135, 66, 135, 135, 135, 135, 1080, 135, 66, 135, 66, 1080, 1080, 66, 135, 135, 66, 135, 66, 135, 135, 1080, 1080, 1080, 1080, 135, 135, 66, 135, 1080, 1080, 135, 66, 66, 66, 1080, 135, 135, 135, 135, 1080, 135, 1080, 66, 66, 135, 66, 1080, 1080, 66, 66, 135, 135, 135, 66, 1080, 66, 1080, 135, 66, 1080, 1080, 135, 135, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 66, 1080, 66, 66, 1080, 135, 1080, 1080, 135, 1080, 66, 135, 1080, 66, 1080, 135, 66, 135, 135, 1080, 1080, 66, 66, 1080, 66, 66, 66, 135, 66]
Prompts retrieved: 55017 . Total input tokens: 12206255 . Total output tokens: 10821498
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.7007195940241218,
    "estimated_duration": 3600.020034950074,
    "input_throughput": 1279.1414923511286,
    "output_throughput": 1115.5568471872948,
    "total_throughput": 2394.6983395384236,
    "itl": 27.60369299038882,
    "ttft": 7018.423472223108,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2653,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.542721161763268,
    "arrivals": 18589,
    "finished_requests": 18553,
    "scheduler_time": 0.019591391820805076
}
#Debug simulation 
Total elapsed time: 1.7008069572038949. Arrivals time: 0.0553319058381021 Scheduler time: 1.2792459866032004 Scheduler overhead time: 0.11389731196686625 Adapter cache time: 0.08174130786210299 Engine time: 0.1151245697401464 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-16/adapters_128_slots_64_rate_0.1-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-16/adapters_128_slots_64_rate_0.1-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [42 43 43]
Adapter prompts. [1080, 135, 1080, 1080, 66, 66, 1080, 66, 135, 135, 135, 66, 1080, 135, 66, 1080, 135, 66, 66, 66, 66, 135, 135, 1080, 135, 66, 135, 135, 135, 135, 1080, 135, 66, 135, 66, 1080, 1080, 66, 135, 135, 66, 135, 66, 135, 135, 1080, 1080, 1080, 1080, 135, 135, 66, 135, 1080, 1080, 135, 66, 66, 66, 1080, 135, 135, 135, 135, 1080, 135, 1080, 66, 66, 135, 66, 1080, 1080, 66, 66, 135, 135, 135, 66, 1080, 66, 1080, 135, 66, 1080, 1080, 135, 135, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 66, 1080, 66, 66, 1080, 135, 1080, 1080, 135, 1080, 66, 135, 1080, 66, 1080, 135, 66, 135, 135, 1080, 1080, 66, 66, 1080, 66, 66, 66, 135, 66]
Prompts retrieved: 55017 . Total input tokens: 12206255 . Total output tokens: 10821498
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.7242261180654168,
    "estimated_duration": 3600.0087022391463,
    "input_throughput": 1279.145519047164,
    "output_throughput": 1115.5603589241596,
    "total_throughput": 2394.7058779713234,
    "itl": 27.62207062234452,
    "ttft": 6825.1547475784,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2653,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.374258284470574,
    "arrivals": 18589,
    "finished_requests": 18553,
    "scheduler_time": 0.019827908903223366
}
#Debug simulation 
Total elapsed time: 1.7243010611273348. Arrivals time: 0.05520859733223915 Scheduler time: 1.302407696377486 Scheduler overhead time: 0.11530456971377134 Adapter cache time: 0.08215988799929619 Engine time: 0.11360602639615536 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-32/adapters_128_slots_64_rate_0.1-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-32/adapters_128_slots_64_rate_0.1-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [42 43 43]
Adapter prompts. [1080, 135, 1080, 1080, 66, 66, 1080, 66, 135, 135, 135, 66, 1080, 135, 66, 1080, 135, 66, 66, 66, 66, 135, 135, 1080, 135, 66, 135, 135, 135, 135, 1080, 135, 66, 135, 66, 1080, 1080, 66, 135, 135, 66, 135, 66, 135, 135, 1080, 1080, 1080, 1080, 135, 135, 66, 135, 1080, 1080, 135, 66, 66, 66, 1080, 135, 135, 135, 135, 1080, 135, 1080, 66, 66, 135, 66, 1080, 1080, 66, 66, 135, 135, 135, 66, 1080, 66, 1080, 135, 66, 1080, 1080, 135, 135, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 66, 1080, 66, 66, 1080, 135, 1080, 1080, 135, 1080, 66, 135, 1080, 66, 1080, 135, 66, 135, 135, 1080, 1080, 66, 66, 1080, 66, 66, 66, 135, 66]
Prompts retrieved: 55017 . Total input tokens: 12206255 . Total output tokens: 10821498
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.7089804410934448,
    "estimated_duration": 3600.0299072605517,
    "input_throughput": 1279.137984579726,
    "output_throughput": 1115.5537880117229,
    "total_throughput": 2394.691772591449,
    "itl": 27.628206773050625,
    "ttft": 7018.597484922964,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2653,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.893023324385403,
    "arrivals": 18589,
    "finished_requests": 18553,
    "scheduler_time": 0.019849092051442516
}
#Debug simulation 
Total elapsed time: 1.709069661796093. Arrivals time: 0.055205087177455425 Scheduler time: 1.2883899095468223 Scheduler overhead time: 0.11471005622297525 Adapter cache time: 0.08235300984233618 Engine time: 0.11307659978047013 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-16/adapters_128_slots_64_rate_0.1-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-16/adapters_128_slots_64_rate_0.1-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [42 43 43]
Adapter prompts. [1080, 135, 1080, 1080, 66, 66, 1080, 66, 135, 135, 135, 66, 1080, 135, 66, 1080, 135, 66, 66, 66, 66, 135, 135, 1080, 135, 66, 135, 135, 135, 135, 1080, 135, 66, 135, 66, 1080, 1080, 66, 135, 135, 66, 135, 66, 135, 135, 1080, 1080, 1080, 1080, 135, 135, 66, 135, 1080, 1080, 135, 66, 66, 66, 1080, 135, 135, 135, 135, 1080, 135, 1080, 66, 66, 135, 66, 1080, 1080, 66, 66, 135, 135, 135, 66, 1080, 66, 1080, 135, 66, 1080, 1080, 135, 135, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 66, 1080, 66, 66, 1080, 135, 1080, 1080, 135, 1080, 66, 135, 1080, 66, 1080, 135, 66, 135, 135, 1080, 1080, 66, 66, 1080, 66, 66, 66, 135, 66]
Prompts retrieved: 55017 . Total input tokens: 12206255 . Total output tokens: 10821498
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 1.6991802877746522,
    "estimated_duration": 3600.010991052373,
    "input_throughput": 1279.1447057926516,
    "output_throughput": 1115.5596496737403,
    "total_throughput": 2394.704355466392,
    "itl": 27.60607615076954,
    "ttft": 6824.981055692099,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2653,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 18.129024071409816,
    "arrivals": 18589,
    "finished_requests": 18553,
    "scheduler_time": 0.019691678035827293
}
#Debug simulation 
Total elapsed time: 1.6992672900669277. Arrivals time: 0.05501570925116539 Scheduler time: 1.2798628085292876 Scheduler overhead time: 0.1140774367377162 Adapter cache time: 0.08167978981509805 Engine time: 0.11305603571236134 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-32/adapters_128_slots_64_rate_0.1-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-32/adapters_128_slots_64_rate_0.1-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [42 43 43]
Adapter prompts. [1080, 135, 1080, 1080, 66, 66, 1080, 66, 135, 135, 135, 66, 1080, 135, 66, 1080, 135, 66, 66, 66, 66, 135, 135, 1080, 135, 66, 135, 135, 135, 135, 1080, 135, 66, 135, 66, 1080, 1080, 66, 135, 135, 66, 135, 66, 135, 135, 1080, 1080, 1080, 1080, 135, 135, 66, 135, 1080, 1080, 135, 66, 66, 66, 1080, 135, 135, 135, 135, 1080, 135, 1080, 66, 66, 135, 66, 1080, 1080, 66, 66, 135, 135, 135, 66, 1080, 66, 1080, 135, 66, 1080, 1080, 135, 135, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 66, 1080, 66, 66, 1080, 135, 1080, 1080, 135, 1080, 66, 135, 1080, 66, 1080, 135, 66, 135, 135, 1080, 1080, 66, 66, 1080, 66, 66, 66, 135, 66]
Prompts retrieved: 55017 . Total input tokens: 12206255 . Total output tokens: 10821498
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 1.7207512692548335,
    "estimated_duration": 3600.0282369544334,
    "input_throughput": 1279.1385780617381,
    "output_throughput": 1115.554305595529,
    "total_throughput": 2394.6928836572674,
    "itl": 27.627096061557364,
    "ttft": 7018.687147630279,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2653,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.707239216961995,
    "arrivals": 18589,
    "finished_requests": 18553,
    "scheduler_time": 0.019852427995478625
}
#Debug simulation 
Total elapsed time: 1.7208317941986024. Arrivals time: 0.055758490692824125 Scheduler time: 1.2957855858840048 Scheduler overhead time: 0.11491705710068345 Adapter cache time: 0.08221962582319975 Engine time: 0.11653443332761526 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-16/adapters_128_slots_64_rate_0.1-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-16/adapters_128_slots_64_rate_0.1-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [42 43 43]
Adapter prompts. [1080, 135, 1080, 1080, 66, 66, 1080, 66, 135, 135, 135, 66, 1080, 135, 66, 1080, 135, 66, 66, 66, 66, 135, 135, 1080, 135, 66, 135, 135, 135, 135, 1080, 135, 66, 135, 66, 1080, 1080, 66, 135, 135, 66, 135, 66, 135, 135, 1080, 1080, 1080, 1080, 135, 135, 66, 135, 1080, 1080, 135, 66, 66, 66, 1080, 135, 135, 135, 135, 1080, 135, 1080, 66, 66, 135, 66, 1080, 1080, 66, 66, 135, 135, 135, 66, 1080, 66, 1080, 135, 66, 1080, 1080, 135, 135, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 66, 1080, 66, 66, 1080, 135, 1080, 1080, 135, 1080, 66, 135, 1080, 66, 1080, 135, 66, 135, 135, 1080, 1080, 66, 66, 1080, 66, 66, 66, 135, 66]
Prompts retrieved: 55017 . Total input tokens: 12206255 . Total output tokens: 10821498
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.7017866647802293,
    "estimated_duration": 3600.0096163280714,
    "input_throughput": 1279.1451942556002,
    "output_throughput": 1115.5600756689803,
    "total_throughput": 2394.7052699245805,
    "itl": 27.5970211698977,
    "ttft": 6824.951870501315,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2652,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.930158334394203,
    "arrivals": 18589,
    "finished_requests": 18553,
    "scheduler_time": 0.01952500692012703
}
#Debug simulation 
Total elapsed time: 1.701868106611073. Arrivals time: 0.054619993548840284 Scheduler time: 1.280939415562898 Scheduler overhead time: 0.1149576110765338 Adapter cache time: 0.0817383318208158 Engine time: 0.11415397329255939 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-32/adapters_128_slots_64_rate_0.1-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-32/adapters_128_slots_64_rate_0.1-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [42 43 43]
Adapter prompts. [1080, 135, 1080, 1080, 66, 66, 1080, 66, 135, 135, 135, 66, 1080, 135, 66, 1080, 135, 66, 66, 66, 66, 135, 135, 1080, 135, 66, 135, 135, 135, 135, 1080, 135, 66, 135, 66, 1080, 1080, 66, 135, 135, 66, 135, 66, 135, 135, 1080, 1080, 1080, 1080, 135, 135, 66, 135, 1080, 1080, 135, 66, 66, 66, 1080, 135, 135, 135, 135, 1080, 135, 1080, 66, 66, 135, 66, 1080, 1080, 66, 66, 135, 135, 135, 66, 1080, 66, 1080, 135, 66, 1080, 1080, 135, 135, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 66, 1080, 66, 66, 1080, 135, 1080, 1080, 135, 1080, 66, 135, 1080, 66, 1080, 135, 66, 135, 135, 1080, 1080, 66, 66, 1080, 66, 66, 66, 135, 66]
Prompts retrieved: 55017 . Total input tokens: 12206255 . Total output tokens: 10821498
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.717681793961674,
    "estimated_duration": 3600.008354269207,
    "input_throughput": 1279.1456426869295,
    "output_throughput": 1115.5604667520956,
    "total_throughput": 2394.706109439025,
    "itl": 27.623922405290422,
    "ttft": 6825.148133666414,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2653,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.52932556224994,
    "arrivals": 18589,
    "finished_requests": 18553,
    "scheduler_time": 0.01985255311748253
}
#Debug simulation 
Total elapsed time: 1.7177712628617883. Arrivals time: 0.05581118352711201 Scheduler time: 1.2965242522768676 Scheduler overhead time: 0.11394618405029178 Adapter cache time: 0.08192579634487629 Engine time: 0.1142083527520299 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-8/adapters_128_slots_64_rate_0.1-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-8/adapters_128_slots_64_rate_0.1-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 135, 1080, 1080, 33, 33, 1080, 33, 135, 135, 135, 33, 1080, 135, 33, 1080, 135, 33, 33, 33, 33, 135, 135, 1080, 135, 33, 135, 135, 135, 135, 1080, 135, 33, 135, 33, 1080, 1080, 33, 135, 135, 33, 135, 33, 135, 135, 1080, 1080, 1080, 1080, 135, 135, 33, 135, 1080, 1080, 135, 33, 33, 33, 1080, 135, 135, 135, 135, 1080, 135, 1080, 33, 33, 135, 33, 1080, 1080, 33, 33, 135, 135, 135, 33, 1080, 33, 1080, 135, 33, 1080, 1080, 135, 135, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 135, 1080, 1080, 135, 1080, 33, 135, 1080, 33, 1080, 135, 33, 135, 135, 1080, 1080, 33, 33, 1080, 33, 33, 33, 135, 33]
Prompts retrieved: 53631 . Total input tokens: 11894948 . Total output tokens: 10558244
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.6770135490223765,
    "estimated_duration": 3599.8421128653035,
    "input_throughput": 1231.7884676532528,
    "output_throughput": 1095.437209845084,
    "total_throughput": 2327.2256774983366,
    "itl": 27.626557902418686,
    "ttft": 7205.612321356139,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2089,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.813322467743797,
    "arrivals": 18102,
    "finished_requests": 18066,
    "scheduler_time": 0.019876196837761064
}
#Debug simulation 
Total elapsed time: 1.6770917540416121. Arrivals time: 0.05346754984930158 Scheduler time: 1.2634464730508626 Scheduler overhead time: 0.11380246840417385 Adapter cache time: 0.0794396186247468 Engine time: 0.1117778797633946 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-16/adapters_128_slots_64_rate_0.1-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-16/adapters_128_slots_64_rate_0.1-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 135, 1080, 1080, 33, 33, 1080, 33, 135, 135, 135, 33, 1080, 135, 33, 1080, 135, 33, 33, 33, 33, 135, 135, 1080, 135, 33, 135, 135, 135, 135, 1080, 135, 33, 135, 33, 1080, 1080, 33, 135, 135, 33, 135, 33, 135, 135, 1080, 1080, 1080, 1080, 135, 135, 33, 135, 1080, 1080, 135, 33, 33, 33, 1080, 135, 135, 135, 135, 1080, 135, 1080, 33, 33, 135, 33, 1080, 1080, 33, 33, 135, 135, 135, 33, 1080, 33, 1080, 135, 33, 1080, 1080, 135, 135, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 135, 1080, 1080, 135, 1080, 33, 135, 1080, 33, 1080, 135, 33, 135, 135, 1080, 1080, 33, 33, 1080, 33, 33, 33, 135, 33]
Prompts retrieved: 53631 . Total input tokens: 11894948 . Total output tokens: 10558244
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.6876137498766184,
    "estimated_duration": 3599.841878425122,
    "input_throughput": 1231.800215052761,
    "output_throughput": 1095.547563807262,
    "total_throughput": 2327.3477788600226,
    "itl": 27.372433932325436,
    "ttft": 7006.386817610468,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2067,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.089097991757786,
    "arrivals": 18102,
    "finished_requests": 18067,
    "scheduler_time": 0.01679680434826276
}
#Debug simulation 
Total elapsed time: 1.687692719977349. Arrivals time: 0.05415370035916567 Scheduler time: 1.26653873315081 Scheduler overhead time: 0.11533375969156623 Adapter cache time: 0.07921762904152274 Engine time: 0.1164547516964376 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-32/adapters_128_slots_64_rate_0.1-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-32/adapters_128_slots_64_rate_0.1-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 135, 1080, 1080, 33, 33, 1080, 33, 135, 135, 135, 33, 1080, 135, 33, 1080, 135, 33, 33, 33, 33, 135, 135, 1080, 135, 33, 135, 135, 135, 135, 1080, 135, 33, 135, 33, 1080, 1080, 33, 135, 135, 33, 135, 33, 135, 135, 1080, 1080, 1080, 1080, 135, 135, 33, 135, 1080, 1080, 135, 33, 33, 33, 1080, 135, 135, 135, 135, 1080, 135, 1080, 33, 33, 135, 33, 1080, 1080, 33, 33, 135, 135, 135, 33, 1080, 33, 1080, 135, 33, 1080, 1080, 135, 135, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 135, 1080, 1080, 135, 1080, 33, 135, 1080, 33, 1080, 135, 33, 135, 135, 1080, 1080, 33, 33, 1080, 33, 33, 33, 135, 33]
Prompts retrieved: 53631 . Total input tokens: 11894948 . Total output tokens: 10558244
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.6843021931126714,
    "estimated_duration": 3599.834145976549,
    "input_throughput": 1231.8028609612747,
    "output_throughput": 1095.5499170448982,
    "total_throughput": 2327.352778006173,
    "itl": 27.375587044595253,
    "ttft": 7006.491212612552,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2066,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.483876694594214,
    "arrivals": 18102,
    "finished_requests": 18067,
    "scheduler_time": 0.016910309217425496
}
#Debug simulation 
Total elapsed time: 1.6843840102665126. Arrivals time: 0.053928127977997065 Scheduler time: 1.265150631312281 Scheduler overhead time: 0.11571597121655941 Adapter cache time: 0.07971611572429538 Engine time: 0.11390798026695848 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-16/adapters_128_slots_64_rate_0.1-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-16/adapters_128_slots_64_rate_0.1-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 135, 1080, 1080, 33, 33, 1080, 33, 135, 135, 135, 33, 1080, 135, 33, 1080, 135, 33, 33, 33, 33, 135, 135, 1080, 135, 33, 135, 135, 135, 135, 1080, 135, 33, 135, 33, 1080, 1080, 33, 135, 135, 33, 135, 33, 135, 135, 1080, 1080, 1080, 1080, 135, 135, 33, 135, 1080, 1080, 135, 33, 33, 33, 1080, 135, 135, 135, 135, 1080, 135, 1080, 33, 33, 135, 33, 1080, 1080, 33, 33, 135, 135, 135, 33, 1080, 33, 1080, 135, 33, 1080, 1080, 135, 135, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 135, 1080, 1080, 135, 1080, 33, 135, 1080, 33, 1080, 135, 33, 135, 135, 1080, 1080, 33, 33, 1080, 33, 33, 33, 135, 33]
Prompts retrieved: 53631 . Total input tokens: 11894948 . Total output tokens: 10558244
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 1.6665274780243635,
    "estimated_duration": 3599.8185550319163,
    "input_throughput": 1231.7965286893982,
    "output_throughput": 1095.4443785750855,
    "total_throughput": 2327.2409072644837,
    "itl": 27.502299548212992,
    "ttft": 7205.551286050097,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2061,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.098474878422248,
    "arrivals": 18102,
    "finished_requests": 18066,
    "scheduler_time": 0.01804081261299623
}
#Debug simulation 
Total elapsed time: 1.6666066790930927. Arrivals time: 0.05296031525358558 Scheduler time: 1.2534010419622064 Scheduler overhead time: 0.11467515723779798 Adapter cache time: 0.0782084702514112 Engine time: 0.11199031118303537 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-32/adapters_128_slots_64_rate_0.1-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-32/adapters_128_slots_64_rate_0.1-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 135, 1080, 1080, 33, 33, 1080, 33, 135, 135, 135, 33, 1080, 135, 33, 1080, 135, 33, 33, 33, 33, 135, 135, 1080, 135, 33, 135, 135, 135, 135, 1080, 135, 33, 135, 33, 1080, 1080, 33, 135, 135, 33, 135, 33, 135, 135, 1080, 1080, 1080, 1080, 135, 135, 33, 135, 1080, 1080, 135, 33, 33, 33, 1080, 135, 135, 135, 135, 1080, 135, 1080, 33, 33, 135, 33, 1080, 1080, 33, 33, 135, 135, 135, 33, 1080, 33, 1080, 135, 33, 1080, 1080, 135, 135, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 135, 1080, 1080, 135, 1080, 33, 135, 1080, 33, 1080, 135, 33, 135, 135, 1080, 1080, 33, 33, 1080, 33, 33, 33, 135, 33]
Prompts retrieved: 53631 . Total input tokens: 11894948 . Total output tokens: 10558244
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 1.6819721600040793,
    "estimated_duration": 3599.8325150954465,
    "input_throughput": 1231.8034190216842,
    "output_throughput": 1095.5504133767827,
    "total_throughput": 2327.353832398467,
    "itl": 27.373440671485024,
    "ttft": 7006.491228401471,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2067,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.350077501986812,
    "arrivals": 18102,
    "finished_requests": 18067,
    "scheduler_time": 0.01685034596081189
}
#Debug simulation 
Total elapsed time: 1.682056485209614. Arrivals time: 0.054332129657268524 Scheduler time: 1.2613001218996942 Scheduler overhead time: 0.11490036873146892 Adapter cache time: 0.07927990891039371 Engine time: 0.11639468837529421 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-16/adapters_128_slots_64_rate_0.1-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-16/adapters_128_slots_64_rate_0.1-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 135, 1080, 1080, 33, 33, 1080, 33, 135, 135, 135, 33, 1080, 135, 33, 1080, 135, 33, 33, 33, 33, 135, 135, 1080, 135, 33, 135, 135, 135, 135, 1080, 135, 33, 135, 33, 1080, 1080, 33, 135, 135, 33, 135, 33, 135, 135, 1080, 1080, 1080, 1080, 135, 135, 33, 135, 1080, 1080, 135, 33, 33, 33, 1080, 135, 135, 135, 135, 1080, 135, 1080, 33, 33, 135, 33, 1080, 1080, 33, 33, 135, 135, 135, 33, 1080, 33, 1080, 135, 33, 1080, 1080, 135, 135, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 135, 1080, 1080, 135, 1080, 33, 135, 1080, 33, 1080, 135, 33, 135, 135, 1080, 1080, 33, 33, 1080, 33, 33, 33, 135, 33]
Prompts retrieved: 53631 . Total input tokens: 11894948 . Total output tokens: 10558244
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.6731222947128117,
    "estimated_duration": 3599.8317245311964,
    "input_throughput": 1231.8036895398143,
    "output_throughput": 1095.5506539721932,
    "total_throughput": 2327.3543435120073,
    "itl": 27.35064910040211,
    "ttft": 7006.371772387139,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2066,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.189180663219373,
    "arrivals": 18102,
    "finished_requests": 18067,
    "scheduler_time": 0.016578718212028797
}
#Debug simulation 
Total elapsed time: 1.673212737776339. Arrivals time: 0.0534127508290112 Scheduler time: 1.2568988800048828 Scheduler overhead time: 0.11590895336121321 Adapter cache time: 0.07884235680103302 Engine time: 0.11220072954893112 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-32/adapters_128_slots_64_rate_0.1-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-32/adapters_128_slots_64_rate_0.1-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 135, 1080, 1080, 33, 33, 1080, 33, 135, 135, 135, 33, 1080, 135, 33, 1080, 135, 33, 33, 33, 33, 135, 135, 1080, 135, 33, 135, 135, 135, 135, 1080, 135, 33, 135, 33, 1080, 1080, 33, 135, 135, 33, 135, 33, 135, 135, 1080, 1080, 1080, 1080, 135, 135, 33, 135, 1080, 1080, 135, 33, 33, 33, 1080, 135, 135, 135, 135, 1080, 135, 1080, 33, 33, 135, 33, 1080, 1080, 33, 33, 135, 135, 135, 33, 1080, 33, 1080, 135, 33, 1080, 1080, 135, 135, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 135, 1080, 1080, 135, 1080, 33, 135, 1080, 33, 1080, 135, 33, 135, 135, 1080, 1080, 33, 33, 1080, 33, 33, 33, 135, 33]
Prompts retrieved: 53631 . Total input tokens: 11894948 . Total output tokens: 10558244
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.683790560811758,
    "estimated_duration": 3599.8459728669973,
    "input_throughput": 1231.798814011044,
    "output_throughput": 1095.5463177384424,
    "total_throughput": 2327.3451317494864,
    "itl": 27.373603587867294,
    "ttft": 7006.419599153203,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2067,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.209444939065436,
    "arrivals": 18102,
    "finished_requests": 18067,
    "scheduler_time": 0.016809063894390377
}
#Debug simulation 
Total elapsed time: 1.6838749218732119. Arrivals time: 0.0554340910166502 Scheduler time: 1.2652085195295513 Scheduler overhead time: 0.11573308473452926 Adapter cache time: 0.07943628821521997 Engine time: 0.11229301383718848 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-8/adapters_128_slots_64_rate_0.1-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-8/adapters_128_slots_64_rate_0.1-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 66, 1080, 1080, 33, 33, 1080, 33, 66, 66, 66, 33, 1080, 66, 33, 1080, 66, 33, 33, 33, 33, 66, 66, 1080, 66, 33, 66, 66, 66, 66, 1080, 66, 33, 66, 33, 1080, 1080, 33, 66, 66, 33, 66, 33, 66, 66, 1080, 1080, 1080, 1080, 66, 66, 33, 66, 1080, 1080, 66, 33, 33, 33, 1080, 66, 66, 66, 66, 1080, 66, 1080, 33, 33, 66, 33, 1080, 1080, 33, 33, 66, 66, 66, 33, 1080, 33, 1080, 66, 33, 1080, 1080, 66, 66, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 66, 1080, 1080, 66, 1080, 33, 66, 1080, 33, 1080, 66, 33, 66, 66, 1080, 1080, 33, 33, 1080, 33, 33, 33, 66, 33]
Prompts retrieved: 50664 . Total input tokens: 11225019 . Total output tokens: 9959693
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.585039108991623,
    "estimated_duration": 3600.018588723075,
    "input_throughput": 1186.0060982391874,
    "output_throughput": 1020.2213987185955,
    "total_throughput": 2206.227496957783,
    "itl": 26.47716635763404,
    "ttft": 5289.749997766302,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1079,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.134789345474145,
    "arrivals": 17157,
    "finished_requests": 17132,
    "scheduler_time": 0.0008610864568898731
}
#Debug simulation 
Total elapsed time: 1.585128745995462. Arrivals time: 0.05198271106928587 Scheduler time: 1.1709004025906324 Scheduler overhead time: 0.11758897127583623 Adapter cache time: 0.0717091104015708 Engine time: 0.11595946596935391 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-16/adapters_128_slots_64_rate_0.1-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-16/adapters_128_slots_64_rate_0.1-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 66, 1080, 1080, 33, 33, 1080, 33, 66, 66, 66, 33, 1080, 66, 33, 1080, 66, 33, 33, 33, 33, 66, 66, 1080, 66, 33, 66, 66, 66, 66, 1080, 66, 33, 66, 33, 1080, 1080, 33, 66, 66, 33, 66, 33, 66, 66, 1080, 1080, 1080, 1080, 66, 66, 33, 66, 1080, 1080, 66, 33, 33, 33, 1080, 66, 66, 66, 66, 1080, 66, 1080, 33, 33, 66, 33, 1080, 1080, 33, 33, 66, 66, 66, 33, 1080, 33, 1080, 66, 33, 1080, 1080, 66, 66, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 66, 1080, 1080, 66, 1080, 33, 66, 1080, 33, 1080, 66, 33, 66, 66, 1080, 1080, 33, 33, 1080, 33, 33, 33, 66, 33]
Prompts retrieved: 50664 . Total input tokens: 11225019 . Total output tokens: 9959693
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.600330827292055,
    "estimated_duration": 3600.024393762962,
    "input_throughput": 1186.004185804172,
    "output_throughput": 1020.2197536114337,
    "total_throughput": 2206.223939415606,
    "itl": 26.484570085532578,
    "ttft": 5289.7502139359185,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1080,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.889989053681504,
    "arrivals": 17157,
    "finished_requests": 17132,
    "scheduler_time": 0.0008563327848434799
}
#Debug simulation 
Total elapsed time: 1.6004090113565326. Arrivals time: 0.05215500248596072 Scheduler time: 1.182537020649761 Scheduler overhead time: 0.11796337040141225 Adapter cache time: 0.07183847669512033 Engine time: 0.11805195547640324 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-32/adapters_128_slots_64_rate_0.1-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-32/adapters_128_slots_64_rate_0.1-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 66, 1080, 1080, 33, 33, 1080, 33, 66, 66, 66, 33, 1080, 66, 33, 1080, 66, 33, 33, 33, 33, 66, 66, 1080, 66, 33, 66, 66, 66, 66, 1080, 66, 33, 66, 33, 1080, 1080, 33, 66, 66, 33, 66, 33, 66, 66, 1080, 1080, 1080, 1080, 66, 66, 33, 66, 1080, 1080, 66, 33, 33, 33, 1080, 66, 66, 66, 66, 1080, 66, 1080, 33, 33, 66, 33, 1080, 1080, 33, 33, 66, 66, 66, 33, 1080, 33, 1080, 66, 33, 1080, 1080, 66, 66, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 66, 1080, 1080, 66, 1080, 33, 66, 1080, 33, 1080, 66, 33, 66, 66, 1080, 1080, 33, 33, 1080, 33, 33, 33, 66, 33]
Prompts retrieved: 50664 . Total input tokens: 11225019 . Total output tokens: 9959693
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.5826375498436391,
    "estimated_duration": 3600.005696082631,
    "input_throughput": 1186.010345663075,
    "output_throughput": 1020.2250524204998,
    "total_throughput": 2206.2353980835746,
    "itl": 26.484828218971327,
    "ttft": 5080.281365555962,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1079,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.0954952553427,
    "arrivals": 17157,
    "finished_requests": 17132,
    "scheduler_time": 0.0008651312649311222
}
#Debug simulation 
Total elapsed time: 1.5827183621004224. Arrivals time: 0.050675350707024336 Scheduler time: 1.1682029394432902 Scheduler overhead time: 0.12059095315635204 Adapter cache time: 0.07101167924702168 Engine time: 0.11508870543912053 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-16/adapters_128_slots_64_rate_0.1-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-16/adapters_128_slots_64_rate_0.1-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 66, 1080, 1080, 33, 33, 1080, 33, 66, 66, 66, 33, 1080, 66, 33, 1080, 66, 33, 33, 33, 33, 66, 66, 1080, 66, 33, 66, 66, 66, 66, 1080, 66, 33, 66, 33, 1080, 1080, 33, 66, 66, 33, 66, 33, 66, 66, 1080, 1080, 1080, 1080, 66, 66, 33, 66, 1080, 1080, 66, 33, 33, 33, 1080, 66, 66, 66, 66, 1080, 66, 1080, 33, 33, 66, 33, 1080, 1080, 33, 33, 66, 66, 66, 33, 1080, 33, 1080, 66, 33, 1080, 1080, 66, 66, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 66, 1080, 1080, 66, 1080, 33, 66, 1080, 33, 1080, 66, 33, 66, 66, 1080, 1080, 33, 33, 1080, 33, 33, 33, 66, 33]
Prompts retrieved: 50664 . Total input tokens: 11225019 . Total output tokens: 9959693
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 1.6027889759279788,
    "estimated_duration": 3600.017372367264,
    "input_throughput": 1186.0064989609784,
    "output_throughput": 1020.2217434258839,
    "total_throughput": 2206.2282423868623,
    "itl": 26.33959810081294,
    "ttft": 5289.535300095224,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1081,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.364684341843226,
    "arrivals": 17157,
    "finished_requests": 17132,
    "scheduler_time": 0.0007724341779758841
}
#Debug simulation 
Total elapsed time: 1.602886961773038. Arrivals time: 0.05154251353815198 Scheduler time: 1.1807253770530224 Scheduler overhead time: 0.12166961096227169 Adapter cache time: 0.07287701638415456 Engine time: 0.11841613752767444 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-32/adapters_128_slots_64_rate_0.1-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-32/adapters_128_slots_64_rate_0.1-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 66, 1080, 1080, 33, 33, 1080, 33, 66, 66, 66, 33, 1080, 66, 33, 1080, 66, 33, 33, 33, 33, 66, 66, 1080, 66, 33, 66, 66, 66, 66, 1080, 66, 33, 66, 33, 1080, 1080, 33, 66, 66, 33, 66, 33, 66, 66, 1080, 1080, 1080, 1080, 66, 66, 33, 66, 1080, 1080, 66, 33, 33, 33, 1080, 66, 66, 66, 66, 1080, 66, 1080, 33, 33, 66, 33, 1080, 1080, 33, 33, 66, 66, 66, 33, 1080, 33, 1080, 66, 33, 1080, 1080, 66, 66, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 66, 1080, 1080, 66, 1080, 33, 66, 1080, 33, 1080, 66, 33, 66, 66, 1080, 1080, 33, 33, 1080, 33, 33, 33, 66, 33]
Prompts retrieved: 50664 . Total input tokens: 11225019 . Total output tokens: 9959693
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 1.5962193422019482,
    "estimated_duration": 3600.0153034776986,
    "input_throughput": 1186.0071805459895,
    "output_throughput": 1020.2223297362026,
    "total_throughput": 2206.229510282192,
    "itl": 26.485572492701365,
    "ttft": 5289.989965944594,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1079,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.016169376699267,
    "arrivals": 17157,
    "finished_requests": 17132,
    "scheduler_time": 0.0008546648128254272
}
#Debug simulation 
Total elapsed time: 1.5962999071925879. Arrivals time: 0.051608175970613956 Scheduler time: 1.1803503804840147 Scheduler overhead time: 0.11784216435626149 Adapter cache time: 0.07147985883057117 Engine time: 0.11783064622431993 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-16/adapters_128_slots_64_rate_0.1-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-16/adapters_128_slots_64_rate_0.1-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 66, 1080, 1080, 33, 33, 1080, 33, 66, 66, 66, 33, 1080, 66, 33, 1080, 66, 33, 33, 33, 33, 66, 66, 1080, 66, 33, 66, 66, 66, 66, 1080, 66, 33, 66, 33, 1080, 1080, 33, 66, 66, 33, 66, 33, 66, 66, 1080, 1080, 1080, 1080, 66, 66, 33, 66, 1080, 1080, 66, 33, 33, 33, 1080, 66, 66, 66, 66, 1080, 66, 1080, 33, 33, 66, 33, 1080, 1080, 33, 33, 66, 66, 66, 33, 1080, 33, 1080, 66, 33, 1080, 1080, 66, 66, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 66, 1080, 1080, 66, 1080, 33, 66, 1080, 33, 1080, 66, 33, 66, 66, 1080, 1080, 33, 33, 1080, 33, 33, 33, 66, 33]
Prompts retrieved: 50664 . Total input tokens: 11225019 . Total output tokens: 9959693
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.6059722397476435,
    "estimated_duration": 3600.01213184822,
    "input_throughput": 1186.008225424506,
    "output_throughput": 1020.2232285574001,
    "total_throughput": 2206.231453981906,
    "itl": 26.475138853678015,
    "ttft": 5289.785070457141,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1079,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.888250694875571,
    "arrivals": 17157,
    "finished_requests": 17132,
    "scheduler_time": 0.000852162854798348
}
#Debug simulation 
Total elapsed time: 1.606064556632191. Arrivals time: 0.051921009086072445 Scheduler time: 1.1836228375323117 Scheduler overhead time: 0.12139778817072511 Adapter cache time: 0.07225272106006742 Engine time: 0.1193937137722969 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-32/adapters_128_slots_64_rate_0.1-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-32/adapters_128_slots_64_rate_0.1-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 66, 1080, 1080, 33, 33, 1080, 33, 66, 66, 66, 33, 1080, 66, 33, 1080, 66, 33, 33, 33, 33, 66, 66, 1080, 66, 33, 66, 66, 66, 66, 1080, 66, 33, 66, 33, 1080, 1080, 33, 66, 66, 33, 66, 33, 66, 66, 1080, 1080, 1080, 1080, 66, 66, 33, 66, 1080, 1080, 66, 33, 33, 33, 1080, 66, 66, 66, 66, 1080, 66, 1080, 33, 33, 66, 33, 1080, 1080, 33, 33, 66, 66, 66, 33, 1080, 33, 1080, 66, 33, 1080, 1080, 66, 66, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 66, 1080, 1080, 66, 1080, 33, 66, 1080, 33, 1080, 66, 33, 66, 66, 1080, 1080, 33, 33, 1080, 33, 33, 33, 66, 33]
Prompts retrieved: 50664 . Total input tokens: 11225019 . Total output tokens: 9959693
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.5974993840791285,
    "estimated_duration": 3600.004224498898,
    "input_throughput": 1186.0108304718203,
    "output_throughput": 1020.2254694607301,
    "total_throughput": 2206.2362999325505,
    "itl": 26.48544433811506,
    "ttft": 5080.516822742879,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1079,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.946992239709959,
    "arrivals": 17157,
    "finished_requests": 17132,
    "scheduler_time": 0.0008627544289079258
}
#Debug simulation 
Total elapsed time: 1.5975818228907883. Arrivals time: 0.05135983554646373 Scheduler time: 1.1847888315096498 Scheduler overhead time: 0.11743710841983557 Adapter cache time: 0.07158983685076237 Engine time: 0.11539933690801263 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-8/adapters_128_slots_64_rate_0.05-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-8/adapters_128_slots_64_rate_0.05-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 135, 135, 540, 135, 270, 270, 270, 135, 540, 270, 135, 540, 270, 135, 135, 135, 135, 270, 270, 540, 270, 135, 270, 270, 270, 270, 540, 270, 135, 270, 135, 540, 540, 135, 270, 270, 135, 270, 135, 270, 270, 540, 540, 540, 540, 270, 270, 135, 270, 540, 540, 270, 135, 135, 135, 540, 270, 270, 270, 270, 540, 270, 540, 135, 135, 270, 135, 540, 540, 135, 135, 270, 270, 270, 135, 540, 135, 540, 270, 135, 540, 540, 270, 270, 135, 135, 135, 540, 540, 540, 540, 540, 540, 540, 540, 135, 540, 135, 135, 540, 270, 540, 540, 270, 540, 135, 270, 540, 135, 540, 270, 135, 270, 270, 540, 540, 135, 135, 540, 135, 135, 135, 270, 135]
Prompts retrieved: 40500 . Total input tokens: 8963977 . Total output tokens: 7950192
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.3888978171162307,
    "estimated_duration": 3599.556093324244,
    "input_throughput": 925.3452130326233,
    "output_throughput": 809.5451006873668,
    "total_throughput": 1734.8903137199902,
    "itl": 25.624273461384888,
    "ttft": 5545.562640217979,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5578,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 36.88401758021489,
    "arrivals": 13744,
    "finished_requests": 13723,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3889793241396546. Arrivals time: 0.044720429461449385 Scheduler time: 0.9606168433092535 Scheduler overhead time: 0.120608726516366 Adapter cache time: 0.08565654279664159 Engine time: 0.11869599856436253 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-16/adapters_128_slots_64_rate_0.05-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-16/adapters_128_slots_64_rate_0.05-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 135, 135, 540, 135, 270, 270, 270, 135, 540, 270, 135, 540, 270, 135, 135, 135, 135, 270, 270, 540, 270, 135, 270, 270, 270, 270, 540, 270, 135, 270, 135, 540, 540, 135, 270, 270, 135, 270, 135, 270, 270, 540, 540, 540, 540, 270, 270, 135, 270, 540, 540, 270, 135, 135, 135, 540, 270, 270, 270, 270, 540, 270, 540, 135, 135, 270, 135, 540, 540, 135, 135, 270, 270, 270, 135, 540, 135, 540, 270, 135, 540, 540, 270, 270, 135, 135, 135, 540, 540, 540, 540, 540, 540, 540, 540, 135, 540, 135, 135, 540, 270, 540, 540, 270, 540, 135, 270, 540, 135, 540, 270, 135, 270, 270, 540, 540, 135, 135, 540, 135, 135, 135, 270, 135]
Prompts retrieved: 40500 . Total input tokens: 8963977 . Total output tokens: 7950192
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.3915680488571525,
    "estimated_duration": 3599.5428027104404,
    "input_throughput": 925.3486296903867,
    "output_throughput": 809.5480897756704,
    "total_throughput": 1734.8967194660572,
    "itl": 25.657323628534893,
    "ttft": 5545.890664508885,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5575,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 40.81562298722901,
    "arrivals": 13744,
    "finished_requests": 13723,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3916473528370261. Arrivals time: 0.0445729517377913 Scheduler time: 0.9639304489828646 Scheduler overhead time: 0.11950405593961477 Adapter cache time: 0.08628695132210851 Engine time: 0.11905928608030081 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-32/adapters_128_slots_64_rate_0.05-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-32/adapters_128_slots_64_rate_0.05-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 135, 135, 540, 135, 270, 270, 270, 135, 540, 270, 135, 540, 270, 135, 135, 135, 135, 270, 270, 540, 270, 135, 270, 270, 270, 270, 540, 270, 135, 270, 135, 540, 540, 135, 270, 270, 135, 270, 135, 270, 270, 540, 540, 540, 540, 270, 270, 135, 270, 540, 540, 270, 135, 135, 135, 540, 270, 270, 270, 270, 540, 270, 540, 135, 135, 270, 135, 540, 540, 135, 135, 270, 270, 270, 135, 540, 135, 540, 270, 135, 540, 540, 270, 270, 135, 135, 135, 540, 540, 540, 540, 540, 540, 540, 540, 135, 540, 135, 135, 540, 270, 540, 540, 270, 540, 135, 270, 540, 135, 540, 270, 135, 270, 270, 540, 540, 135, 135, 540, 135, 135, 135, 270, 135]
Prompts retrieved: 40500 . Total input tokens: 8963977 . Total output tokens: 7950192
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.4025163417682052,
    "estimated_duration": 3599.5596301643413,
    "input_throughput": 925.3443038108325,
    "output_throughput": 809.5443052479612,
    "total_throughput": 1734.8886090587937,
    "itl": 25.670148936302137,
    "ttft": 5545.996316850248,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5576,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 41.93411913816299,
    "arrivals": 13744,
    "finished_requests": 13723,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.402595133986324. Arrivals time: 0.04505749838426709 Scheduler time: 0.9706692458130419 Scheduler overhead time: 0.12040947051718831 Adapter cache time: 0.08630155026912689 Engine time: 0.12161576095968485 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-16/adapters_128_slots_64_rate_0.05-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-16/adapters_128_slots_64_rate_0.05-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 135, 135, 540, 135, 270, 270, 270, 135, 540, 270, 135, 540, 270, 135, 135, 135, 135, 270, 270, 540, 270, 135, 270, 270, 270, 270, 540, 270, 135, 270, 135, 540, 540, 135, 270, 270, 135, 270, 135, 270, 270, 540, 540, 540, 540, 270, 270, 135, 270, 540, 540, 270, 135, 135, 135, 540, 270, 270, 270, 270, 540, 270, 540, 135, 135, 270, 135, 540, 540, 135, 135, 270, 270, 270, 135, 540, 135, 540, 270, 135, 540, 540, 270, 270, 135, 135, 135, 540, 540, 540, 540, 540, 540, 540, 540, 135, 540, 135, 135, 540, 270, 540, 540, 270, 540, 135, 270, 540, 135, 540, 270, 135, 270, 270, 540, 540, 135, 135, 540, 135, 135, 135, 270, 135]
Prompts retrieved: 40500 . Total input tokens: 8963977 . Total output tokens: 7950192
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 1.3876417172141373,
    "estimated_duration": 3599.5529562505208,
    "input_throughput": 925.3460194872548,
    "output_throughput": 809.5458062201633,
    "total_throughput": 1734.891825707418,
    "itl": 25.635193595729564,
    "ttft": 5545.593810108696,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5575,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 38.34181321278788,
    "arrivals": 13744,
    "finished_requests": 13723,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3877540552057326. Arrivals time: 0.04423961555585265 Scheduler time: 0.9555856082588434 Scheduler overhead time: 0.12445947108790278 Adapter cache time: 0.0862388419918716 Engine time: 0.11827266309410334 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-32/adapters_128_slots_64_rate_0.05-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-32/adapters_128_slots_64_rate_0.05-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 135, 135, 540, 135, 270, 270, 270, 135, 540, 270, 135, 540, 270, 135, 135, 135, 135, 270, 270, 540, 270, 135, 270, 270, 270, 270, 540, 270, 135, 270, 135, 540, 540, 135, 270, 270, 135, 270, 135, 270, 270, 540, 540, 540, 540, 270, 270, 135, 270, 540, 540, 270, 135, 135, 135, 540, 270, 270, 270, 270, 540, 270, 540, 135, 135, 270, 135, 540, 540, 135, 135, 270, 270, 270, 135, 540, 135, 540, 270, 135, 540, 540, 270, 270, 135, 135, 135, 540, 540, 540, 540, 540, 540, 540, 540, 135, 540, 135, 135, 540, 270, 540, 540, 270, 540, 135, 270, 540, 135, 540, 270, 135, 270, 270, 540, 540, 135, 135, 540, 135, 135, 135, 270, 135]
Prompts retrieved: 40500 . Total input tokens: 8963977 . Total output tokens: 7950192
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 1.4071125299669802,
    "estimated_duration": 3599.557078197777,
    "input_throughput": 925.3449598492484,
    "output_throughput": 809.5448791880195,
    "total_throughput": 1734.8898390372678,
    "itl": 25.66561834548815,
    "ttft": 5546.062079954631,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5574,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 41.55292314700738,
    "arrivals": 13744,
    "finished_requests": 13723,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4071992081589997. Arrivals time: 0.045024219900369644 Scheduler time: 0.9755312288179994 Scheduler overhead time: 0.11986268311738968 Adapter cache time: 0.08706841291859746 Engine time: 0.12122967233881354 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-16/adapters_128_slots_64_rate_0.05-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-16/adapters_128_slots_64_rate_0.05-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 135, 135, 540, 135, 270, 270, 270, 135, 540, 270, 135, 540, 270, 135, 135, 135, 135, 270, 270, 540, 270, 135, 270, 270, 270, 270, 540, 270, 135, 270, 135, 540, 540, 135, 270, 270, 135, 270, 135, 270, 270, 540, 540, 540, 540, 270, 270, 135, 270, 540, 540, 270, 135, 135, 135, 540, 270, 270, 270, 270, 540, 270, 540, 135, 135, 270, 135, 540, 540, 135, 135, 270, 270, 270, 135, 540, 135, 540, 270, 135, 540, 540, 270, 270, 135, 135, 135, 540, 540, 540, 540, 540, 540, 540, 540, 135, 540, 135, 135, 540, 270, 540, 540, 270, 540, 135, 270, 540, 135, 540, 270, 135, 270, 270, 540, 540, 135, 135, 540, 135, 135, 135, 270, 135]
Prompts retrieved: 40500 . Total input tokens: 8963977 . Total output tokens: 7950192
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.4028385961428285,
    "estimated_duration": 3599.5393228098187,
    "input_throughput": 925.349524282995,
    "output_throughput": 809.5488724166275,
    "total_throughput": 1734.8983966996227,
    "itl": 25.604373740857753,
    "ttft": 5545.521822418883,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5580,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 35.62227884838722,
    "arrivals": 13744,
    "finished_requests": 13723,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4029484721831977. Arrivals time: 0.04468523524701595 Scheduler time: 0.9725192510522902 Scheduler overhead time: 0.12187000084668398 Adapter cache time: 0.08589905686676502 Engine time: 0.1189484503120184 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-32/adapters_128_slots_64_rate_0.05-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-32/adapters_128_slots_64_rate_0.05-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 135, 135, 540, 135, 270, 270, 270, 135, 540, 270, 135, 540, 270, 135, 135, 135, 135, 270, 270, 540, 270, 135, 270, 270, 270, 270, 540, 270, 135, 270, 135, 540, 540, 135, 270, 270, 135, 270, 135, 270, 270, 540, 540, 540, 540, 270, 270, 135, 270, 540, 540, 270, 135, 135, 135, 540, 270, 270, 270, 270, 540, 270, 540, 135, 135, 270, 135, 540, 540, 135, 135, 270, 270, 270, 135, 540, 135, 540, 270, 135, 540, 540, 270, 270, 135, 135, 135, 540, 540, 540, 540, 540, 540, 540, 540, 135, 540, 135, 135, 540, 270, 540, 540, 270, 540, 135, 270, 540, 135, 540, 270, 135, 270, 270, 540, 540, 135, 135, 540, 135, 135, 135, 270, 135]
Prompts retrieved: 40500 . Total input tokens: 8963977 . Total output tokens: 7950192
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.396418709307909,
    "estimated_duration": 3599.544919563253,
    "input_throughput": 925.348085503026,
    "output_throughput": 809.5476136893348,
    "total_throughput": 1734.8956991923608,
    "itl": 25.660364895335892,
    "ttft": 5545.776334368819,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5576,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 41.15623889178,
    "arrivals": 13744,
    "finished_requests": 13723,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3964876332320273. Arrivals time: 0.044979173224419355 Scheduler time: 0.9640504536218941 Scheduler overhead time: 0.1198176946491003 Adapter cache time: 0.08610879443585873 Engine time: 0.12281189346686006 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-8/adapters_128_slots_64_rate_0.05-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-8/adapters_128_slots_64_rate_0.05-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 66, 66, 540, 66, 270, 270, 270, 66, 540, 270, 66, 540, 270, 66, 66, 66, 66, 270, 270, 540, 270, 66, 270, 270, 270, 270, 540, 270, 66, 270, 66, 540, 540, 66, 270, 270, 66, 270, 66, 270, 270, 540, 540, 540, 540, 270, 270, 66, 270, 540, 540, 270, 66, 66, 66, 540, 270, 270, 270, 270, 540, 270, 540, 66, 66, 270, 66, 540, 540, 66, 66, 270, 270, 270, 66, 540, 66, 540, 270, 66, 540, 540, 270, 270, 66, 66, 66, 540, 540, 540, 540, 540, 540, 540, 540, 66, 540, 66, 66, 540, 270, 540, 540, 270, 540, 66, 270, 540, 66, 540, 270, 66, 270, 270, 540, 540, 66, 66, 540, 66, 66, 66, 270, 66]
Prompts retrieved: 37602 . Total input tokens: 8318515 . Total output tokens: 7370897
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.3232892770320177,
    "estimated_duration": 3599.924242625069,
    "input_throughput": 863.9562364045904,
    "output_throughput": 758.0159514718442,
    "total_throughput": 1621.9721878764346,
    "itl": 24.91633148750744,
    "ttft": 5983.0808389399135,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4324,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 28.592056654149,
    "arrivals": 12728,
    "finished_requests": 12707,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3233601641841233. Arrivals time: 0.042181896045804024 Scheduler time: 0.9005939750932157 Scheduler overhead time: 0.12283623917028308 Adapter cache time: 0.07884243130683899 Engine time: 0.11916456837207079 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-16/adapters_128_slots_64_rate_0.05-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-16/adapters_128_slots_64_rate_0.05-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 66, 66, 540, 66, 270, 270, 270, 66, 540, 270, 66, 540, 270, 66, 66, 66, 66, 270, 270, 540, 270, 66, 270, 270, 270, 270, 540, 270, 66, 270, 66, 540, 540, 66, 270, 270, 66, 270, 66, 270, 270, 540, 540, 540, 540, 270, 270, 66, 270, 540, 540, 270, 66, 66, 66, 540, 270, 270, 270, 270, 540, 270, 540, 66, 66, 270, 66, 540, 540, 66, 66, 270, 270, 270, 66, 540, 66, 540, 270, 66, 540, 540, 270, 270, 66, 66, 66, 540, 540, 540, 540, 540, 540, 540, 540, 66, 540, 66, 66, 540, 270, 540, 540, 270, 540, 66, 270, 540, 66, 540, 270, 66, 270, 270, 540, 540, 66, 66, 540, 66, 66, 66, 270, 66]
Prompts retrieved: 37602 . Total input tokens: 8318515 . Total output tokens: 7370897
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.3303027749061584,
    "estimated_duration": 3599.937975002729,
    "input_throughput": 863.9529407441088,
    "output_throughput": 758.0130599327704,
    "total_throughput": 1621.9660006768793,
    "itl": 24.940801582021354,
    "ttft": 5983.3225117518205,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4323,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 31.674895224705306,
    "arrivals": 12728,
    "finished_requests": 12707,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3303979272022843. Arrivals time: 0.042360300198197365 Scheduler time: 0.9041928462684155 Scheduler overhead time: 0.12358652288094163 Adapter cache time: 0.07855250453576446 Engine time: 0.12179781449958682 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-32/adapters_128_slots_64_rate_0.05-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-32/adapters_128_slots_64_rate_0.05-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 66, 66, 540, 66, 270, 270, 270, 66, 540, 270, 66, 540, 270, 66, 66, 66, 66, 270, 270, 540, 270, 66, 270, 270, 270, 270, 540, 270, 66, 270, 66, 540, 540, 66, 270, 270, 66, 270, 66, 270, 270, 540, 540, 540, 540, 270, 270, 66, 270, 540, 540, 270, 66, 66, 66, 540, 270, 270, 270, 270, 540, 270, 540, 66, 66, 270, 66, 540, 540, 66, 66, 270, 270, 270, 66, 540, 66, 540, 270, 66, 540, 540, 270, 270, 66, 66, 66, 540, 540, 540, 540, 540, 540, 540, 540, 66, 540, 66, 66, 540, 270, 540, 540, 270, 540, 66, 270, 540, 66, 540, 270, 66, 270, 270, 540, 540, 66, 66, 540, 66, 66, 66, 270, 66]
Prompts retrieved: 37602 . Total input tokens: 8318515 . Total output tokens: 7370897
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.328027359675616,
    "estimated_duration": 3599.9250533854006,
    "input_throughput": 863.956041827916,
    "output_throughput": 758.0157807546057,
    "total_throughput": 1621.9718225825218,
    "itl": 24.948972835450103,
    "ttft": 5983.489254867653,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4326,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 32.56356133239014,
    "arrivals": 12728,
    "finished_requests": 12707,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3281060098670423. Arrivals time: 0.04234424885362387 Scheduler time: 0.9016668242402375 Scheduler overhead time: 0.12158235348761082 Adapter cache time: 0.07987065799534321 Engine time: 0.12316291499882936 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-16/adapters_128_slots_64_rate_0.05-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-16/adapters_128_slots_64_rate_0.05-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 66, 66, 540, 66, 270, 270, 270, 66, 540, 270, 66, 540, 270, 66, 66, 66, 66, 270, 270, 540, 270, 66, 270, 270, 270, 270, 540, 270, 66, 270, 66, 540, 540, 66, 270, 270, 66, 270, 66, 270, 270, 540, 540, 540, 540, 270, 270, 66, 270, 540, 540, 270, 66, 66, 66, 540, 270, 270, 270, 270, 540, 270, 540, 66, 66, 270, 66, 540, 540, 66, 66, 270, 270, 270, 66, 540, 66, 540, 270, 66, 540, 540, 270, 270, 66, 66, 66, 540, 540, 540, 540, 540, 540, 540, 540, 66, 540, 66, 66, 540, 270, 540, 540, 270, 540, 66, 270, 540, 66, 540, 270, 66, 270, 270, 540, 540, 66, 66, 540, 66, 66, 66, 270, 66]
Prompts retrieved: 37602 . Total input tokens: 8318515 . Total output tokens: 7370897
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 1.3372602937743068,
    "estimated_duration": 3599.932894031848,
    "input_throughput": 863.9541601334319,
    "output_throughput": 758.0141297977925,
    "total_throughput": 1621.9682899312245,
    "itl": 24.92425650289887,
    "ttft": 5983.149449941274,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4324,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 29.786357517075533,
    "arrivals": 12728,
    "finished_requests": 12707,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3373490259982646. Arrivals time: 0.042533460073173046 Scheduler time: 0.9107104605063796 Scheduler overhead time: 0.12256743852049112 Adapter cache time: 0.07953727152198553 Engine time: 0.12240033084526658 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-32/adapters_128_slots_64_rate_0.05-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-32/adapters_128_slots_64_rate_0.05-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 66, 66, 540, 66, 270, 270, 270, 66, 540, 270, 66, 540, 270, 66, 66, 66, 66, 270, 270, 540, 270, 66, 270, 270, 270, 270, 540, 270, 66, 270, 66, 540, 540, 66, 270, 270, 66, 270, 66, 270, 270, 540, 540, 540, 540, 270, 270, 66, 270, 540, 540, 270, 66, 66, 66, 540, 270, 270, 270, 270, 540, 270, 540, 66, 66, 270, 66, 540, 540, 66, 66, 270, 270, 270, 66, 540, 66, 540, 270, 66, 540, 540, 270, 270, 66, 66, 66, 540, 540, 540, 540, 540, 540, 540, 540, 66, 540, 66, 66, 540, 270, 540, 540, 270, 540, 66, 270, 540, 66, 540, 270, 66, 270, 270, 540, 540, 66, 66, 540, 66, 66, 66, 270, 66]
Prompts retrieved: 37602 . Total input tokens: 8318515 . Total output tokens: 7370897
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 1.3266943451017141,
    "estimated_duration": 3599.9265400889444,
    "input_throughput": 863.9556850299384,
    "output_throughput": 758.0154677080102,
    "total_throughput": 1621.9711527379486,
    "itl": 24.94675848569479,
    "ttft": 5983.284935058746,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4323,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 32.26003577897935,
    "arrivals": 12728,
    "finished_requests": 12707,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3267727978527546. Arrivals time: 0.04226843733340502 Scheduler time: 0.9026124030351639 Scheduler overhead time: 0.12256560381501913 Adapter cache time: 0.07889078604057431 Engine time: 0.12065295595675707 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-16/adapters_128_slots_64_rate_0.05-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-16/adapters_128_slots_64_rate_0.05-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 66, 66, 540, 66, 270, 270, 270, 66, 540, 270, 66, 540, 270, 66, 66, 66, 66, 270, 270, 540, 270, 66, 270, 270, 270, 270, 540, 270, 66, 270, 66, 540, 540, 66, 270, 270, 66, 270, 66, 270, 270, 540, 540, 540, 540, 270, 270, 66, 270, 540, 540, 270, 66, 66, 66, 540, 270, 270, 270, 270, 540, 270, 540, 66, 66, 270, 66, 540, 540, 66, 66, 270, 270, 270, 66, 540, 66, 540, 270, 66, 540, 540, 270, 270, 66, 66, 66, 540, 540, 540, 540, 540, 540, 540, 540, 66, 540, 66, 66, 540, 270, 540, 540, 270, 540, 66, 270, 540, 66, 540, 270, 66, 270, 270, 540, 540, 66, 66, 540, 66, 66, 66, 270, 66]
Prompts retrieved: 37602 . Total input tokens: 8318515 . Total output tokens: 7370897
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.3540948270820081,
    "estimated_duration": 3599.9320885119446,
    "input_throughput": 863.9543534515985,
    "output_throughput": 758.0142994108445,
    "total_throughput": 1621.9686528624432,
    "itl": 24.904659858619173,
    "ttft": 5983.040135183555,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4322,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 27.591306305148418,
    "arrivals": 12728,
    "finished_requests": 12707,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3541774908080697. Arrivals time: 0.04270045505836606 Scheduler time: 0.9246507044881582 Scheduler overhead time: 0.12363754585385323 Adapter cache time: 0.07954602316021919 Engine time: 0.12291229283437133 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-32/adapters_128_slots_64_rate_0.05-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-32/adapters_128_slots_64_rate_0.05-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 66, 66, 540, 66, 270, 270, 270, 66, 540, 270, 66, 540, 270, 66, 66, 66, 66, 270, 270, 540, 270, 66, 270, 270, 270, 270, 540, 270, 66, 270, 66, 540, 540, 66, 270, 270, 66, 270, 66, 270, 270, 540, 540, 540, 540, 270, 270, 66, 270, 540, 540, 270, 66, 66, 66, 540, 270, 270, 270, 270, 540, 270, 540, 66, 66, 270, 66, 540, 540, 66, 66, 270, 270, 270, 66, 540, 66, 540, 270, 66, 540, 540, 270, 270, 66, 66, 66, 540, 540, 540, 540, 540, 540, 540, 540, 66, 540, 66, 66, 540, 270, 540, 540, 270, 540, 66, 270, 540, 66, 540, 270, 66, 270, 270, 540, 540, 66, 66, 540, 66, 66, 66, 270, 66]
Prompts retrieved: 37602 . Total input tokens: 8318515 . Total output tokens: 7370897
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.329277342185378,
    "estimated_duration": 3599.945690615595,
    "input_throughput": 863.9510890699454,
    "output_throughput": 758.0114353151178,
    "total_throughput": 1621.962524385063,
    "itl": 24.943798000117383,
    "ttft": 5983.386158203998,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4323,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 31.934654694517715,
    "arrivals": 12728,
    "finished_requests": 12707,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3293640809133649. Arrivals time: 0.042500413954257965 Scheduler time: 0.9037704123184085 Scheduler overhead time: 0.12210348481312394 Adapter cache time: 0.07954070344567299 Engine time: 0.121850551571697 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-8/adapters_128_slots_64_rate_0.05-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-8/adapters_128_slots_64_rate_0.05-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 33, 33, 540, 33, 270, 270, 270, 33, 540, 270, 33, 540, 270, 33, 33, 33, 33, 270, 270, 540, 270, 33, 270, 270, 270, 270, 540, 270, 33, 270, 33, 540, 540, 33, 270, 270, 33, 270, 33, 270, 270, 540, 540, 540, 540, 270, 270, 33, 270, 540, 540, 270, 33, 33, 33, 540, 270, 270, 270, 270, 540, 270, 540, 33, 33, 270, 33, 540, 540, 33, 33, 270, 270, 270, 33, 540, 33, 540, 270, 33, 540, 540, 270, 270, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 270, 540, 540, 270, 540, 33, 270, 540, 33, 540, 270, 33, 270, 270, 540, 540, 33, 33, 540, 33, 33, 33, 270, 33]
Prompts retrieved: 36216 . Total input tokens: 8005148 . Total output tokens: 7098911
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.3026326978579164,
    "estimated_duration": 3599.9597780169033,
    "input_throughput": 834.1648754904227,
    "output_throughput": 732.5595736107742,
    "total_throughput": 1566.724449101197,
    "itl": 24.62102536720271,
    "ttft": 7084.609008014678,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3517,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 23.255842565366663,
    "arrivals": 12269,
    "finished_requests": 12245,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.302711070049554. Arrivals time: 0.04097722377628088 Scheduler time: 0.8779765563085675 Scheduler overhead time: 0.12399794813245535 Adapter cache time: 0.07587929908186197 Engine time: 0.12346500949934125 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-16/adapters_128_slots_64_rate_0.05-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-16/adapters_128_slots_64_rate_0.05-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 33, 33, 540, 33, 270, 270, 270, 33, 540, 270, 33, 540, 270, 33, 33, 33, 33, 270, 270, 540, 270, 33, 270, 270, 270, 270, 540, 270, 33, 270, 33, 540, 540, 33, 270, 270, 33, 270, 33, 270, 270, 540, 540, 540, 540, 270, 270, 33, 270, 540, 540, 270, 33, 33, 33, 540, 270, 270, 270, 270, 540, 270, 540, 33, 33, 270, 33, 540, 540, 33, 33, 270, 270, 270, 33, 540, 33, 540, 270, 33, 540, 540, 270, 270, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 270, 540, 540, 270, 540, 33, 270, 540, 33, 540, 270, 33, 270, 270, 540, 540, 33, 33, 540, 33, 33, 33, 270, 33]
Prompts retrieved: 36216 . Total input tokens: 8005148 . Total output tokens: 7098911
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.299962173216045,
    "estimated_duration": 3599.9380534183874,
    "input_throughput": 834.169909437326,
    "output_throughput": 732.5639943986848,
    "total_throughput": 1566.7339038360108,
    "itl": 24.641330638976225,
    "ttft": 7084.857342224761,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3517,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 25.753439422523815,
    "arrivals": 12269,
    "finished_requests": 12245,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3000522102229297. Arrivals time: 0.0409715729765594 Scheduler time: 0.87716333149001 Scheduler overhead time: 0.12425613310188055 Adapter cache time: 0.07581191044300795 Engine time: 0.1211913414299488 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-32/adapters_128_slots_64_rate_0.05-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-32/adapters_128_slots_64_rate_0.05-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 33, 33, 540, 33, 270, 270, 270, 33, 540, 270, 33, 540, 270, 33, 33, 33, 33, 270, 270, 540, 270, 33, 270, 270, 270, 270, 540, 270, 33, 270, 33, 540, 540, 33, 270, 270, 33, 270, 33, 270, 270, 540, 540, 540, 540, 270, 270, 33, 270, 540, 540, 270, 33, 33, 33, 540, 270, 270, 270, 270, 540, 270, 540, 33, 33, 270, 33, 540, 540, 33, 33, 270, 270, 270, 33, 540, 33, 540, 270, 33, 540, 540, 270, 270, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 270, 540, 540, 270, 540, 33, 270, 540, 33, 540, 270, 33, 270, 270, 540, 540, 33, 33, 540, 33, 33, 33, 270, 33]
Prompts retrieved: 36216 . Total input tokens: 8005148 . Total output tokens: 7098911
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.3008547518402338,
    "estimated_duration": 3599.955354956205,
    "input_throughput": 834.1659003814318,
    "output_throughput": 732.5604736651192,
    "total_throughput": 1566.726374046551,
    "itl": 24.64738728673181,
    "ttft": 7084.8970002437,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3516,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 26.449143498368475,
    "arrivals": 12269,
    "finished_requests": 12245,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3009348548948765. Arrivals time: 0.040945813059806824 Scheduler time: 0.8779122973792255 Scheduler overhead time: 0.12386793410405517 Adapter cache time: 0.07621614495292306 Engine time: 0.12179318023845553 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-16/adapters_128_slots_64_rate_0.05-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-16/adapters_128_slots_64_rate_0.05-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 33, 33, 540, 33, 270, 270, 270, 33, 540, 270, 33, 540, 270, 33, 33, 33, 33, 270, 270, 540, 270, 33, 270, 270, 270, 270, 540, 270, 33, 270, 33, 540, 540, 33, 270, 270, 33, 270, 33, 270, 270, 540, 540, 540, 540, 270, 270, 33, 270, 540, 540, 270, 33, 33, 33, 540, 270, 270, 270, 270, 540, 270, 540, 33, 33, 270, 33, 540, 540, 33, 33, 270, 270, 270, 33, 540, 33, 540, 270, 33, 540, 540, 270, 270, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 270, 540, 540, 270, 540, 33, 270, 540, 33, 540, 270, 33, 270, 270, 540, 540, 33, 33, 540, 33, 33, 33, 270, 33]
Prompts retrieved: 36216 . Total input tokens: 8005148 . Total output tokens: 7098911
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 1.3138271030038595,
    "estimated_duration": 3599.9514094181877,
    "input_throughput": 834.1668146252364,
    "output_throughput": 732.5612765496224,
    "total_throughput": 1566.728091174859,
    "itl": 24.625741163156,
    "ttft": 7084.758828950942,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3516,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.238059303593392,
    "arrivals": 12269,
    "finished_requests": 12245,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3139042682014406. Arrivals time: 0.04155262792482972 Scheduler time: 0.8853274872526526 Scheduler overhead time: 0.12446661153808236 Adapter cache time: 0.07614224450662732 Engine time: 0.12462350353598595 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-32/adapters_128_slots_64_rate_0.05-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-32/adapters_128_slots_64_rate_0.05-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 33, 33, 540, 33, 270, 270, 270, 33, 540, 270, 33, 540, 270, 33, 33, 33, 33, 270, 270, 540, 270, 33, 270, 270, 270, 270, 540, 270, 33, 270, 33, 540, 540, 33, 270, 270, 33, 270, 33, 270, 270, 540, 540, 540, 540, 270, 270, 33, 270, 540, 540, 270, 33, 33, 33, 540, 270, 270, 270, 270, 540, 270, 540, 33, 33, 270, 33, 540, 540, 33, 33, 270, 270, 270, 33, 540, 33, 540, 270, 33, 540, 540, 270, 270, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 270, 540, 540, 270, 540, 33, 270, 540, 33, 540, 270, 33, 270, 270, 540, 540, 33, 33, 540, 33, 33, 33, 270, 33]
Prompts retrieved: 36216 . Total input tokens: 8005148 . Total output tokens: 7098911
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 1.307019972242415,
    "estimated_duration": 3599.9485399368614,
    "input_throughput": 834.1674795308792,
    "output_throughput": 732.5618604665535,
    "total_throughput": 1566.7293399974326,
    "itl": 24.645672520309347,
    "ttft": 7084.975125314046,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3518,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 26.240159274135614,
    "arrivals": 12269,
    "finished_requests": 12245,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3070969809778035. Arrivals time: 0.04107398446649313 Scheduler time: 0.882380414288491 Scheduler overhead time: 0.12302276398986578 Adapter cache time: 0.07629770785570145 Engine time: 0.12362206354737282 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-16/adapters_128_slots_64_rate_0.05-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-16/adapters_128_slots_64_rate_0.05-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 33, 33, 540, 33, 270, 270, 270, 33, 540, 270, 33, 540, 270, 33, 33, 33, 33, 270, 270, 540, 270, 33, 270, 270, 270, 270, 540, 270, 33, 270, 33, 540, 540, 33, 270, 270, 33, 270, 33, 270, 270, 540, 540, 540, 540, 270, 270, 33, 270, 540, 540, 270, 33, 33, 33, 540, 270, 270, 270, 270, 540, 270, 540, 33, 33, 270, 33, 540, 540, 33, 33, 270, 270, 270, 33, 540, 33, 540, 270, 33, 540, 540, 270, 270, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 270, 540, 540, 270, 540, 33, 270, 540, 33, 540, 270, 33, 270, 270, 540, 540, 33, 33, 540, 33, 33, 33, 270, 33]
Prompts retrieved: 36216 . Total input tokens: 8005148 . Total output tokens: 7098911
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.2982991370372474,
    "estimated_duration": 3599.95715357275,
    "input_throughput": 834.1654836140856,
    "output_throughput": 732.5601076620442,
    "total_throughput": 1566.7255912761298,
    "itl": 24.6123480976189,
    "ttft": 7084.5691884486705,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3517,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 22.452249947988452,
    "arrivals": 12269,
    "finished_requests": 12245,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.298384833149612. Arrivals time: 0.04141602525487542 Scheduler time: 0.875820626039058 Scheduler overhead time: 0.12264888966456056 Adapter cache time: 0.07648267364129424 Engine time: 0.12165495427325368 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-32/adapters_128_slots_64_rate_0.05-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-32/adapters_128_slots_64_rate_0.05-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 33, 33, 540, 33, 270, 270, 270, 33, 540, 270, 33, 540, 270, 33, 33, 33, 33, 270, 270, 540, 270, 33, 270, 270, 270, 270, 540, 270, 33, 270, 33, 540, 540, 33, 270, 270, 33, 270, 33, 270, 270, 540, 540, 540, 540, 270, 270, 33, 270, 540, 540, 270, 33, 33, 33, 540, 270, 270, 270, 270, 540, 270, 540, 33, 33, 270, 33, 540, 540, 33, 33, 270, 270, 270, 33, 540, 33, 540, 270, 33, 540, 540, 270, 270, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 270, 540, 540, 270, 540, 33, 270, 540, 33, 540, 270, 33, 270, 270, 540, 540, 33, 33, 540, 33, 33, 33, 270, 33]
Prompts retrieved: 36216 . Total input tokens: 8005148 . Total output tokens: 7098911
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.3068026937544346,
    "estimated_duration": 3599.949360847877,
    "input_throughput": 834.1672893122943,
    "output_throughput": 732.561693417509,
    "total_throughput": 1566.7289827298034,
    "itl": 24.64186020705066,
    "ttft": 7084.888778322054,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3518,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 25.9725638819494,
    "arrivals": 12269,
    "finished_requests": 12245,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3068675468675792. Arrivals time: 0.041155397426337004 Scheduler time: 0.8833337649703026 Scheduler overhead time: 0.12344174087047577 Adapter cache time: 0.07581554213538766 Engine time: 0.12295476859435439 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-8/adapters_128_slots_64_rate_0.05-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-8/adapters_128_slots_64_rate_0.05-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [42 43 43]
Adapter prompts. [540, 135, 540, 540, 66, 66, 540, 66, 135, 135, 135, 66, 540, 135, 66, 540, 135, 66, 66, 66, 66, 135, 135, 540, 135, 66, 135, 135, 135, 135, 540, 135, 66, 135, 66, 540, 540, 66, 135, 135, 66, 135, 66, 135, 135, 540, 540, 540, 540, 135, 135, 66, 135, 540, 540, 135, 66, 66, 66, 540, 135, 135, 135, 135, 540, 135, 540, 66, 66, 135, 66, 540, 540, 66, 66, 135, 135, 135, 66, 540, 66, 540, 135, 66, 540, 540, 135, 135, 66, 66, 66, 540, 540, 540, 540, 540, 540, 540, 540, 66, 540, 66, 66, 540, 135, 540, 540, 135, 540, 66, 135, 540, 66, 540, 135, 66, 135, 135, 540, 540, 66, 66, 540, 66, 66, 66, 135, 66]
Prompts retrieved: 31797 . Total input tokens: 7032599 . Total output tokens: 6263072
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.2195957410149276,
    "estimated_duration": 3599.9978789848074,
    "input_throughput": 725.3373717921071,
    "output_throughput": 648.203715236091,
    "total_throughput": 1373.541087028198,
    "itl": 23.781446111017054,
    "ttft": 6063.016674984523,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3027,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.01576213971196,
    "arrivals": 10761,
    "finished_requests": 10743,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2196501228027046. Arrivals time: 0.03809562977403402 Scheduler time: 0.797500645276159 Scheduler overhead time: 0.12670536525547504 Adapter cache time: 0.06851788237690926 Engine time: 0.12732580909505486 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-16/adapters_128_slots_64_rate_0.05-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-16/adapters_128_slots_64_rate_0.05-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [42 43 43]
Adapter prompts. [540, 135, 540, 540, 66, 66, 540, 66, 135, 135, 135, 66, 540, 135, 66, 540, 135, 66, 66, 66, 66, 135, 135, 540, 135, 66, 135, 135, 135, 135, 540, 135, 66, 135, 66, 540, 540, 66, 135, 135, 66, 135, 66, 135, 135, 540, 540, 540, 540, 135, 135, 66, 135, 540, 540, 135, 66, 66, 66, 540, 135, 135, 135, 135, 540, 135, 540, 66, 66, 135, 66, 540, 540, 66, 66, 135, 135, 135, 66, 540, 66, 540, 135, 66, 540, 540, 135, 135, 66, 66, 66, 540, 540, 540, 540, 540, 540, 540, 540, 66, 540, 66, 66, 540, 135, 540, 540, 135, 540, 66, 135, 540, 66, 540, 135, 66, 135, 135, 540, 540, 66, 66, 540, 66, 66, 66, 135, 66]
Prompts retrieved: 31797 . Total input tokens: 7032599 . Total output tokens: 6263072
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.2096229838207364,
    "estimated_duration": 3599.9986439960894,
    "input_throughput": 725.3372176555844,
    "output_throughput": 648.2035774907183,
    "total_throughput": 1373.5407951463026,
    "itl": 23.803700477044913,
    "ttft": 6063.104976657395,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3027,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 22.1602641355846,
    "arrivals": 10761,
    "finished_requests": 10743,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2097139349207282. Arrivals time: 0.03790915198624134 Scheduler time: 0.7915258589200675 Scheduler overhead time: 0.12553066667169333 Adapter cache time: 0.06842701975256205 Engine time: 0.12485585641115904 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-32/adapters_128_slots_64_rate_0.05-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-32/adapters_128_slots_64_rate_0.05-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [42 43 43]
Adapter prompts. [540, 135, 540, 540, 66, 66, 540, 66, 135, 135, 135, 66, 540, 135, 66, 540, 135, 66, 66, 66, 66, 135, 135, 540, 135, 66, 135, 135, 135, 135, 540, 135, 66, 135, 66, 540, 540, 66, 135, 135, 66, 135, 66, 135, 135, 540, 540, 540, 540, 135, 135, 66, 135, 540, 540, 135, 66, 66, 66, 540, 135, 135, 135, 135, 540, 135, 540, 66, 66, 135, 66, 540, 540, 66, 66, 135, 135, 135, 66, 540, 66, 540, 135, 66, 540, 540, 135, 135, 66, 66, 66, 540, 540, 540, 540, 540, 540, 540, 540, 66, 540, 66, 66, 540, 135, 540, 540, 135, 540, 66, 135, 540, 66, 540, 135, 66, 135, 135, 540, 540, 66, 66, 540, 66, 66, 66, 135, 66]
Prompts retrieved: 31797 . Total input tokens: 7032599 . Total output tokens: 6263072
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.2319555692374706,
    "estimated_duration": 3600.0155158382977,
    "input_throughput": 725.3338182882677,
    "output_throughput": 648.200539618123,
    "total_throughput": 1373.5343579063906,
    "itl": 23.80803546575208,
    "ttft": 6063.290459070694,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3027,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 22.764808609807336,
    "arrivals": 10761,
    "finished_requests": 10743,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2320328201167285. Arrivals time: 0.03780202195048332 Scheduler time: 0.8101303372532129 Scheduler overhead time: 0.12768203346058726 Adapter cache time: 0.06933033838868141 Engine time: 0.12471085786819458 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-16/adapters_128_slots_64_rate_0.05-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-16/adapters_128_slots_64_rate_0.05-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [42 43 43]
Adapter prompts. [540, 135, 540, 540, 66, 66, 540, 66, 135, 135, 135, 66, 540, 135, 66, 540, 135, 66, 66, 66, 66, 135, 135, 540, 135, 66, 135, 135, 135, 135, 540, 135, 66, 135, 66, 540, 540, 66, 135, 135, 66, 135, 66, 135, 135, 540, 540, 540, 540, 135, 135, 66, 135, 540, 540, 135, 66, 66, 66, 540, 135, 135, 135, 135, 540, 135, 540, 66, 66, 135, 66, 540, 540, 66, 66, 135, 135, 135, 66, 540, 66, 540, 135, 66, 540, 540, 135, 135, 66, 66, 66, 540, 540, 540, 540, 540, 540, 540, 540, 66, 540, 66, 66, 540, 135, 540, 540, 135, 540, 66, 135, 540, 66, 540, 135, 66, 135, 135, 540, 540, 66, 66, 540, 66, 66, 66, 135, 66]
Prompts retrieved: 31797 . Total input tokens: 7032599 . Total output tokens: 6263072
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 1.210966101847589,
    "estimated_duration": 3599.9986897198896,
    "input_throughput": 725.3372084430326,
    "output_throughput": 648.2035692578456,
    "total_throughput": 1373.5407777008784,
    "itl": 23.790879560986458,
    "ttft": 6062.963159694029,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3025,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.781486855964662,
    "arrivals": 10761,
    "finished_requests": 10743,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.211047135759145. Arrivals time: 0.037906928919255733 Scheduler time: 0.7909797807224095 Scheduler overhead time: 0.1268247002735734 Adapter cache time: 0.06900460179895163 Engine time: 0.12470932118594646 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-32/adapters_128_slots_64_rate_0.05-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-32/adapters_128_slots_64_rate_0.05-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [42 43 43]
Adapter prompts. [540, 135, 540, 540, 66, 66, 540, 66, 135, 135, 135, 66, 540, 135, 66, 540, 135, 66, 66, 66, 66, 135, 135, 540, 135, 66, 135, 135, 135, 135, 540, 135, 66, 135, 66, 540, 540, 66, 135, 135, 66, 135, 66, 135, 135, 540, 540, 540, 540, 135, 135, 66, 135, 540, 540, 135, 66, 66, 66, 540, 135, 135, 135, 135, 540, 135, 540, 66, 66, 135, 66, 540, 540, 66, 66, 135, 135, 135, 66, 540, 66, 540, 135, 66, 540, 540, 135, 135, 66, 66, 66, 540, 540, 540, 540, 540, 540, 540, 540, 66, 540, 66, 66, 540, 135, 540, 540, 135, 540, 66, 135, 540, 66, 540, 135, 66, 135, 135, 540, 540, 66, 66, 540, 66, 66, 66, 135, 66]
Prompts retrieved: 31797 . Total input tokens: 7032599 . Total output tokens: 6263072
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 1.2055140319280326,
    "estimated_duration": 3599.9999065583224,
    "input_throughput": 725.3369632713063,
    "output_throughput": 648.2033501581135,
    "total_throughput": 1373.5403134294197,
    "itl": 23.804097674845966,
    "ttft": 6063.28251301358,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3027,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 22.56121242519507,
    "arrivals": 10761,
    "finished_requests": 10743,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2055974109098315. Arrivals time: 0.03745487565174699 Scheduler time: 0.7889050268568099 Scheduler overhead time: 0.12567627150565386 Adapter cache time: 0.06925941770896316 Engine time: 0.12273243023082614 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-16/adapters_128_slots_64_rate_0.05-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-16/adapters_128_slots_64_rate_0.05-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [42 43 43]
Adapter prompts. [540, 135, 540, 540, 66, 66, 540, 66, 135, 135, 135, 66, 540, 135, 66, 540, 135, 66, 66, 66, 66, 135, 135, 540, 135, 66, 135, 135, 135, 135, 540, 135, 66, 135, 66, 540, 540, 66, 135, 135, 66, 135, 66, 135, 135, 540, 540, 540, 540, 135, 135, 66, 135, 540, 540, 135, 66, 66, 66, 540, 135, 135, 135, 135, 540, 135, 540, 66, 66, 135, 66, 540, 540, 66, 66, 135, 135, 135, 66, 540, 66, 540, 135, 66, 540, 540, 135, 135, 66, 66, 66, 540, 540, 540, 540, 540, 540, 540, 540, 66, 540, 66, 66, 540, 135, 540, 540, 135, 540, 66, 135, 540, 66, 540, 135, 66, 135, 135, 540, 540, 66, 66, 540, 66, 66, 66, 135, 66]
Prompts retrieved: 31797 . Total input tokens: 7032599 . Total output tokens: 6263072
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.2213957668282092,
    "estimated_duration": 3600.0131753853016,
    "input_throughput": 725.3342898447942,
    "output_throughput": 648.200961028496,
    "total_throughput": 1373.5352508732901,
    "itl": 23.778161849635225,
    "ttft": 6062.803436843705,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3028,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.330512608049045,
    "arrivals": 10761,
    "finished_requests": 10743,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2214575237594545. Arrivals time: 0.03852487588301301 Scheduler time: 0.7984214597381651 Scheduler overhead time: 0.12601636070758104 Adapter cache time: 0.06884165899828076 Engine time: 0.12770060263574123 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-32/adapters_128_slots_64_rate_0.05-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-32/adapters_128_slots_64_rate_0.05-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [42 43 43]
Adapter prompts. [540, 135, 540, 540, 66, 66, 540, 66, 135, 135, 135, 66, 540, 135, 66, 540, 135, 66, 66, 66, 66, 135, 135, 540, 135, 66, 135, 135, 135, 135, 540, 135, 66, 135, 66, 540, 540, 66, 135, 135, 66, 135, 66, 135, 135, 540, 540, 540, 540, 135, 135, 66, 135, 540, 540, 135, 66, 66, 66, 540, 135, 135, 135, 135, 540, 135, 540, 66, 66, 135, 66, 540, 540, 66, 66, 135, 135, 135, 66, 540, 66, 540, 135, 66, 540, 540, 135, 135, 66, 66, 66, 540, 540, 540, 540, 540, 540, 540, 540, 66, 540, 66, 66, 540, 135, 540, 540, 135, 540, 66, 135, 540, 66, 540, 135, 66, 135, 135, 540, 540, 66, 66, 540, 66, 66, 66, 135, 66]
Prompts retrieved: 31797 . Total input tokens: 7032599 . Total output tokens: 6263072
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.2187897679395974,
    "estimated_duration": 3600.009612440493,
    "input_throughput": 725.3350077112225,
    "output_throughput": 648.201602555741,
    "total_throughput": 1373.5366102669634,
    "itl": 23.80448332706904,
    "ttft": 6063.310482832056,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3027,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 22.341668217983464,
    "arrivals": 10761,
    "finished_requests": 10743,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2188638057559729. Arrivals time: 0.038346993271261454 Scheduler time: 0.799063706304878 Scheduler overhead time: 0.12600657809525728 Adapter cache time: 0.06891831522807479 Engine time: 0.1249311538413167 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-8/adapters_128_slots_64_rate_0.05-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-8/adapters_128_slots_64_rate_0.05-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 135, 540, 540, 33, 33, 540, 33, 135, 135, 135, 33, 540, 135, 33, 540, 135, 33, 33, 33, 33, 135, 135, 540, 135, 33, 135, 135, 135, 135, 540, 135, 33, 135, 33, 540, 540, 33, 135, 135, 33, 135, 33, 135, 135, 540, 540, 540, 540, 135, 135, 33, 135, 540, 540, 135, 33, 33, 33, 540, 135, 135, 135, 135, 540, 135, 540, 33, 33, 135, 33, 540, 540, 33, 33, 135, 135, 135, 33, 540, 33, 540, 135, 33, 540, 540, 135, 135, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 135, 540, 540, 135, 540, 33, 135, 540, 33, 540, 135, 33, 135, 135, 540, 540, 33, 33, 540, 33, 33, 33, 135, 33]
Prompts retrieved: 30411 . Total input tokens: 6728052 . Total output tokens: 5988477
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.1709063341841102,
    "estimated_duration": 3600.020163614252,
    "input_throughput": 695.5169377402116,
    "output_throughput": 612.4529585374435,
    "total_throughput": 1307.9698962776552,
    "itl": 23.415743791238526,
    "ttft": 4600.2618815313945,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2212,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.626648778673665,
    "arrivals": 10263,
    "finished_requests": 10250,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1709850342012942. Arrivals time: 0.03689913218840957 Scheduler time: 0.751606616191566 Scheduler overhead time: 0.12806326523423195 Adapter cache time: 0.06497788382694125 Engine time: 0.12692733528092504 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-16/adapters_128_slots_64_rate_0.05-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-16/adapters_128_slots_64_rate_0.05-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 135, 540, 540, 33, 33, 540, 33, 135, 135, 135, 33, 540, 135, 33, 540, 135, 33, 33, 33, 33, 135, 135, 540, 135, 33, 135, 135, 135, 135, 540, 135, 33, 135, 33, 540, 540, 33, 135, 135, 33, 135, 33, 135, 135, 540, 540, 540, 540, 135, 135, 33, 135, 540, 540, 135, 33, 33, 33, 540, 135, 135, 135, 135, 540, 135, 540, 33, 33, 135, 33, 540, 540, 33, 33, 135, 135, 135, 33, 540, 33, 540, 135, 33, 540, 540, 135, 135, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 135, 540, 540, 135, 540, 33, 135, 540, 33, 540, 135, 33, 135, 135, 540, 540, 33, 33, 540, 33, 33, 33, 135, 33]
Prompts retrieved: 30411 . Total input tokens: 6728052 . Total output tokens: 5988477
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.179391257930547,
    "estimated_duration": 3600.010696806526,
    "input_throughput": 695.518766713977,
    "output_throughput": 612.4545690811024,
    "total_throughput": 1307.9733357950793,
    "itl": 23.428693946178917,
    "ttft": 4249.986542757982,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2213,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.187736965878557,
    "arrivals": 10263,
    "finished_requests": 10250,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1794684082269669. Arrivals time: 0.03715278347954154 Scheduler time: 0.757993842009455 Scheduler overhead time: 0.1278727101162076 Adapter cache time: 0.06580521445721388 Engine time: 0.12755260663107038 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-32/adapters_128_slots_64_rate_0.05-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-32/adapters_128_slots_64_rate_0.05-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 135, 540, 540, 33, 33, 540, 33, 135, 135, 135, 33, 540, 135, 33, 540, 135, 33, 33, 33, 33, 135, 135, 540, 135, 33, 135, 135, 135, 135, 540, 135, 33, 135, 33, 540, 540, 33, 135, 135, 33, 135, 33, 135, 135, 540, 540, 540, 540, 135, 135, 33, 135, 540, 540, 135, 33, 33, 33, 540, 135, 135, 135, 135, 540, 135, 540, 33, 33, 135, 33, 540, 540, 33, 33, 135, 135, 135, 33, 540, 33, 540, 135, 33, 540, 540, 135, 135, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 135, 540, 540, 135, 540, 33, 135, 540, 33, 540, 135, 33, 135, 135, 540, 540, 33, 33, 540, 33, 33, 33, 135, 33]
Prompts retrieved: 30411 . Total input tokens: 6728052 . Total output tokens: 5988477
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.1801087851636112,
    "estimated_duration": 3600.005965931498,
    "input_throughput": 695.519680715897,
    "output_throughput": 612.4553739258871,
    "total_throughput": 1307.9750546417843,
    "itl": 23.429063347048576,
    "ttft": 4250.205668768939,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2213,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.62663051426384,
    "arrivals": 10263,
    "finished_requests": 10250,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1801860411651433. Arrivals time: 0.036672091111540794 Scheduler time: 0.7588678817264736 Scheduler overhead time: 0.12685595452785492 Adapter cache time: 0.06534712249413133 Engine time: 0.12938790069893003 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-16/adapters_128_slots_64_rate_0.05-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-16/adapters_128_slots_64_rate_0.05-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 135, 540, 540, 33, 33, 540, 33, 135, 135, 135, 33, 540, 135, 33, 540, 135, 33, 33, 33, 33, 135, 135, 540, 135, 33, 135, 135, 135, 135, 540, 135, 33, 135, 33, 540, 540, 33, 135, 135, 33, 135, 33, 135, 135, 540, 540, 540, 540, 135, 135, 33, 135, 540, 540, 135, 33, 33, 33, 540, 135, 135, 135, 135, 540, 135, 540, 33, 33, 135, 33, 540, 540, 33, 33, 135, 135, 135, 33, 540, 33, 540, 135, 33, 540, 540, 135, 135, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 135, 540, 540, 135, 540, 33, 135, 540, 33, 540, 135, 33, 135, 135, 540, 540, 33, 33, 540, 33, 33, 33, 135, 33]
Prompts retrieved: 30411 . Total input tokens: 6728052 . Total output tokens: 5988477
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 1.1764706349931657,
    "estimated_duration": 3600.0167654270062,
    "input_throughput": 695.5175942640394,
    "output_throughput": 612.453536654149,
    "total_throughput": 1307.9711309181885,
    "itl": 23.420284925268863,
    "ttft": 4600.1863274189,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2212,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.216539468486111,
    "arrivals": 10263,
    "finished_requests": 10250,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1765461056493223. Arrivals time: 0.03670491557568312 Scheduler time: 0.7568936813622713 Scheduler overhead time: 0.12860387982800603 Adapter cache time: 0.06542798038572073 Engine time: 0.12646052706986666 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-32/adapters_128_slots_64_rate_0.05-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-32/adapters_128_slots_64_rate_0.05-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 135, 540, 540, 33, 33, 540, 33, 135, 135, 135, 33, 540, 135, 33, 540, 135, 33, 33, 33, 33, 135, 135, 540, 135, 33, 135, 135, 135, 135, 540, 135, 33, 135, 33, 540, 540, 33, 135, 135, 33, 135, 33, 135, 135, 540, 540, 540, 540, 135, 135, 33, 135, 540, 540, 135, 33, 33, 33, 540, 135, 135, 135, 135, 540, 135, 540, 33, 33, 135, 33, 540, 540, 33, 33, 135, 135, 135, 33, 540, 33, 540, 135, 33, 540, 540, 135, 135, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 135, 540, 540, 135, 540, 33, 135, 540, 33, 540, 135, 33, 135, 135, 540, 540, 33, 33, 540, 33, 33, 33, 135, 33]
Prompts retrieved: 30411 . Total input tokens: 6728052 . Total output tokens: 5988477
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 1.1845465269871056,
    "estimated_duration": 3600.0196382520144,
    "input_throughput": 695.5170392391954,
    "output_throughput": 612.4530479146383,
    "total_throughput": 1307.9700871538337,
    "itl": 23.427453468259884,
    "ttft": 4600.40383445661,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2212,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.476316809537533,
    "arrivals": 10263,
    "finished_requests": 10250,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1846261033788323. Arrivals time: 0.03724703937768936 Scheduler time: 0.7644621636718512 Scheduler overhead time: 0.12839392572641373 Adapter cache time: 0.06531095737591386 Engine time: 0.12619729479774833 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-16/adapters_128_slots_64_rate_0.05-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-16/adapters_128_slots_64_rate_0.05-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 135, 540, 540, 33, 33, 540, 33, 135, 135, 135, 33, 540, 135, 33, 540, 135, 33, 33, 33, 33, 135, 135, 540, 135, 33, 135, 135, 135, 135, 540, 135, 33, 135, 33, 540, 540, 33, 135, 135, 33, 135, 33, 135, 135, 540, 540, 540, 540, 135, 135, 33, 135, 540, 540, 135, 33, 33, 33, 540, 135, 135, 135, 135, 540, 135, 540, 33, 33, 135, 33, 540, 540, 33, 33, 135, 135, 135, 33, 540, 33, 540, 135, 33, 540, 540, 135, 135, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 135, 540, 540, 135, 540, 33, 135, 540, 33, 540, 135, 33, 135, 135, 540, 540, 33, 33, 540, 33, 33, 33, 135, 33]
Prompts retrieved: 30411 . Total input tokens: 6728052 . Total output tokens: 5988477
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.1670584380626678,
    "estimated_duration": 3600.0012878939606,
    "input_throughput": 695.520584512011,
    "output_throughput": 612.4561697837216,
    "total_throughput": 1307.9767542957327,
    "itl": 23.408482557966195,
    "ttft": 4249.828063176131,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2212,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.121233120542795,
    "arrivals": 10263,
    "finished_requests": 10250,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1671266951598227. Arrivals time: 0.03644843306392431 Scheduler time: 0.7505029537715018 Scheduler overhead time: 0.12708898168057203 Adapter cache time: 0.06510087568312883 Engine time: 0.12585054710507393 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-32/adapters_128_slots_64_rate_0.05-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-32/adapters_128_slots_64_rate_0.05-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 135, 540, 540, 33, 33, 540, 33, 135, 135, 135, 33, 540, 135, 33, 540, 135, 33, 33, 33, 33, 135, 135, 540, 135, 33, 135, 135, 135, 135, 540, 135, 33, 135, 33, 540, 540, 33, 135, 135, 33, 135, 33, 135, 135, 540, 540, 540, 540, 135, 135, 33, 135, 540, 540, 135, 33, 33, 33, 540, 135, 135, 135, 135, 540, 135, 540, 33, 33, 135, 33, 540, 540, 33, 33, 135, 135, 135, 33, 540, 33, 540, 135, 33, 540, 540, 135, 135, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 135, 540, 540, 135, 540, 33, 135, 540, 33, 540, 135, 33, 135, 135, 540, 540, 33, 33, 540, 33, 33, 33, 135, 33]
Prompts retrieved: 30411 . Total input tokens: 6728052 . Total output tokens: 5988477
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.1695016757585108,
    "estimated_duration": 3600.00443001409,
    "input_throughput": 695.5199774546389,
    "output_throughput": 612.4556352258073,
    "total_throughput": 1307.9756126804464,
    "itl": 23.428157990059184,
    "ttft": 4250.160731327081,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2212,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.312901357188508,
    "arrivals": 10263,
    "finished_requests": 10250,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1695793769322336. Arrivals time: 0.03659449703991413 Scheduler time: 0.752408938948065 Scheduler overhead time: 0.12647626036778092 Adapter cache time: 0.06501336488872766 Engine time: 0.12686228891834617 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-8/adapters_128_slots_64_rate_0.05-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-8/adapters_128_slots_64_rate_0.05-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 66, 540, 540, 33, 33, 540, 33, 66, 66, 66, 33, 540, 66, 33, 540, 66, 33, 33, 33, 33, 66, 66, 540, 66, 33, 66, 66, 66, 66, 540, 66, 33, 66, 33, 540, 540, 33, 66, 66, 33, 66, 33, 66, 66, 540, 540, 540, 540, 66, 66, 33, 66, 540, 540, 66, 33, 33, 33, 540, 66, 66, 66, 66, 540, 66, 540, 33, 33, 66, 33, 540, 540, 33, 33, 66, 66, 66, 33, 540, 33, 540, 66, 33, 540, 540, 66, 66, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 66, 540, 540, 66, 540, 33, 66, 540, 33, 540, 66, 33, 66, 66, 540, 540, 33, 33, 540, 33, 33, 33, 66, 33]
Prompts retrieved: 27444 . Total input tokens: 6052547 . Total output tokens: 5400284
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.1113173048943281,
    "estimated_duration": 3599.9267519024274,
    "input_throughput": 630.3792150217361,
    "output_throughput": 555.080182935389,
    "total_throughput": 1185.459397957125,
    "itl": 22.86164458084828,
    "ttft": 4291.746588612244,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1416,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.363171189241346,
    "arrivals": 9311,
    "finished_requests": 9300,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1113951751030982. Arrivals time: 0.03394947201013565 Scheduler time: 0.6969140530563891 Scheduler overhead time: 0.12962881941348314 Adapter cache time: 0.05945843178778887 Engine time: 0.127919711638242 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-16/adapters_128_slots_64_rate_0.05-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-16/adapters_128_slots_64_rate_0.05-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 66, 540, 540, 33, 33, 540, 33, 66, 66, 66, 33, 540, 66, 33, 540, 66, 33, 33, 33, 33, 66, 66, 540, 66, 33, 66, 66, 66, 66, 540, 66, 33, 66, 33, 540, 540, 33, 66, 66, 33, 66, 33, 66, 66, 540, 540, 540, 540, 66, 66, 33, 66, 540, 540, 66, 33, 33, 33, 540, 66, 66, 66, 66, 540, 66, 540, 33, 33, 66, 33, 540, 540, 33, 33, 66, 66, 66, 33, 540, 33, 540, 66, 33, 540, 540, 66, 66, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 66, 540, 540, 66, 540, 33, 66, 540, 33, 540, 66, 33, 66, 66, 540, 540, 33, 33, 540, 33, 33, 33, 66, 33]
Prompts retrieved: 27444 . Total input tokens: 6052547 . Total output tokens: 5400284
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.109272648114711,
    "estimated_duration": 3599.9472771778196,
    "input_throughput": 630.3756208838241,
    "output_throughput": 555.0770181185896,
    "total_throughput": 1185.4526390024137,
    "itl": 22.86733394920531,
    "ttft": 4291.86321276489,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1416,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.354277313575063,
    "arrivals": 9311,
    "finished_requests": 9300,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1093353270553052. Arrivals time: 0.03454615781083703 Scheduler time: 0.6939236670732498 Scheduler overhead time: 0.12878599669784307 Adapter cache time: 0.05960282310843468 Engine time: 0.12843657843768597 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-32/adapters_128_slots_64_rate_0.05-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-32/adapters_128_slots_64_rate_0.05-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 66, 540, 540, 33, 33, 540, 33, 66, 66, 66, 33, 540, 66, 33, 540, 66, 33, 33, 33, 33, 66, 66, 540, 66, 33, 66, 66, 66, 66, 540, 66, 33, 66, 33, 540, 540, 33, 66, 66, 33, 66, 33, 66, 66, 540, 540, 540, 540, 66, 66, 33, 66, 540, 540, 66, 33, 33, 33, 540, 66, 66, 66, 66, 540, 66, 540, 33, 33, 66, 33, 540, 540, 33, 33, 66, 66, 66, 33, 540, 33, 540, 66, 33, 540, 540, 66, 66, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 66, 540, 540, 66, 540, 33, 66, 540, 33, 540, 66, 33, 66, 66, 540, 540, 33, 33, 540, 33, 33, 33, 66, 33]
Prompts retrieved: 27444 . Total input tokens: 6052547 . Total output tokens: 5400284
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.1093009025789797,
    "estimated_duration": 3599.948181703836,
    "input_throughput": 630.375462495114,
    "output_throughput": 555.0768786494699,
    "total_throughput": 1185.452341144584,
    "itl": 22.869951667187408,
    "ttft": 4292.007383389124,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1416,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.634289698046526,
    "arrivals": 9311,
    "finished_requests": 9300,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.109360915608704. Arrivals time: 0.03520123474299908 Scheduler time: 0.6950570759363472 Scheduler overhead time: 0.12886517168954015 Adapter cache time: 0.06009063217788935 Engine time: 0.12685524253174663 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-16/adapters_128_slots_64_rate_0.05-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-16/adapters_128_slots_64_rate_0.05-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 66, 540, 540, 33, 33, 540, 33, 66, 66, 66, 33, 540, 66, 33, 540, 66, 33, 33, 33, 33, 66, 66, 540, 66, 33, 66, 66, 66, 66, 540, 66, 33, 66, 33, 540, 540, 33, 66, 66, 33, 66, 33, 66, 66, 540, 540, 540, 540, 66, 66, 33, 66, 540, 540, 66, 33, 33, 33, 540, 66, 66, 66, 66, 540, 66, 540, 33, 33, 66, 33, 540, 540, 33, 33, 66, 66, 66, 33, 540, 33, 540, 66, 33, 540, 540, 66, 66, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 66, 540, 540, 66, 540, 33, 66, 540, 33, 540, 66, 33, 66, 66, 540, 540, 33, 33, 540, 33, 33, 33, 66, 33]
Prompts retrieved: 27444 . Total input tokens: 6052547 . Total output tokens: 5400284
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 1.1157767581753433,
    "estimated_duration": 3599.929702084048,
    "input_throughput": 630.3786984190998,
    "output_throughput": 555.0797280411301,
    "total_throughput": 1185.45842646023,
    "itl": 22.863781972144004,
    "ttft": 4291.867394530341,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1416,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.680990141518459,
    "arrivals": 9311,
    "finished_requests": 9300,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1158513501286507. Arrivals time: 0.03474438516423106 Scheduler time: 0.6974355224519968 Scheduler overhead time: 0.12876866199076176 Adapter cache time: 0.0598391043022275 Engine time: 0.1316145332530141 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-32/adapters_128_slots_64_rate_0.05-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-32/adapters_128_slots_64_rate_0.05-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 66, 540, 540, 33, 33, 540, 33, 66, 66, 66, 33, 540, 66, 33, 540, 66, 33, 33, 33, 33, 66, 66, 540, 66, 33, 66, 66, 66, 66, 540, 66, 33, 66, 33, 540, 540, 33, 66, 66, 33, 66, 33, 66, 66, 540, 540, 540, 540, 66, 66, 33, 66, 540, 540, 66, 33, 33, 33, 540, 66, 66, 66, 66, 540, 66, 540, 33, 33, 66, 33, 540, 540, 33, 33, 66, 66, 66, 33, 540, 33, 540, 66, 33, 540, 540, 66, 66, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 66, 540, 540, 66, 540, 33, 66, 540, 33, 540, 66, 33, 66, 66, 540, 540, 33, 33, 540, 33, 33, 33, 66, 33]
Prompts retrieved: 27444 . Total input tokens: 6052547 . Total output tokens: 5400284
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 1.1070289672352374,
    "estimated_duration": 3599.9350404851357,
    "input_throughput": 630.3777636204738,
    "output_throughput": 555.0789049045484,
    "total_throughput": 1185.4566685250222,
    "itl": 22.86868789191238,
    "ttft": 4292.034614235598,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1416,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.533837867388396,
    "arrivals": 9311,
    "finished_requests": 9300,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1071039061062038. Arrivals time: 0.033818282186985016 Scheduler time: 0.6918828175403178 Scheduler overhead time: 0.12990533141419291 Adapter cache time: 0.05971328215673566 Engine time: 0.1281203906983137 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-16/adapters_128_slots_64_rate_0.05-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-16/adapters_128_slots_64_rate_0.05-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 66, 540, 540, 33, 33, 540, 33, 66, 66, 66, 33, 540, 66, 33, 540, 66, 33, 33, 33, 33, 66, 66, 540, 66, 33, 66, 66, 66, 66, 540, 66, 33, 66, 33, 540, 540, 33, 66, 66, 33, 66, 33, 66, 66, 540, 540, 540, 540, 66, 66, 33, 66, 540, 540, 66, 33, 33, 33, 540, 66, 66, 66, 66, 540, 66, 540, 33, 33, 66, 33, 540, 540, 33, 33, 66, 66, 66, 33, 540, 33, 540, 66, 33, 540, 540, 66, 66, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 66, 540, 540, 66, 540, 33, 66, 540, 33, 540, 66, 33, 66, 66, 540, 540, 33, 33, 540, 33, 33, 33, 66, 33]
Prompts retrieved: 27444 . Total input tokens: 6052547 . Total output tokens: 5400284
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.1065742243081331,
    "estimated_duration": 3599.9478600058915,
    "input_throughput": 630.3755188266216,
    "output_throughput": 555.076928252158,
    "total_throughput": 1185.4524470787796,
    "itl": 22.859205097421327,
    "ttft": 4291.765244764116,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1416,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.039632051847972,
    "arrivals": 9311,
    "finished_requests": 9300,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1066346880979836. Arrivals time: 0.0344046032987535 Scheduler time: 0.6920068487524986 Scheduler overhead time: 0.12831574585288763 Adapter cache time: 0.05931979976594448 Engine time: 0.12938049109652638 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-32/adapters_128_slots_64_rate_0.05-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-32/adapters_128_slots_64_rate_0.05-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 66, 540, 540, 33, 33, 540, 33, 66, 66, 66, 33, 540, 66, 33, 540, 66, 33, 33, 33, 33, 66, 66, 540, 66, 33, 66, 66, 66, 66, 540, 66, 33, 66, 33, 540, 540, 33, 66, 66, 33, 66, 33, 66, 66, 540, 540, 540, 540, 66, 66, 33, 66, 540, 540, 66, 33, 33, 33, 540, 66, 66, 66, 66, 540, 66, 540, 33, 33, 66, 33, 540, 540, 33, 33, 66, 66, 66, 33, 540, 33, 540, 66, 33, 540, 540, 66, 66, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 66, 540, 540, 66, 540, 33, 66, 540, 33, 540, 66, 33, 66, 66, 540, 540, 33, 33, 540, 33, 33, 33, 66, 33]
Prompts retrieved: 27444 . Total input tokens: 6052547 . Total output tokens: 5400284
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.1058251028880477,
    "estimated_duration": 3599.942360838295,
    "input_throughput": 630.3764817699911,
    "output_throughput": 555.0777761715832,
    "total_throughput": 1185.4542579415743,
    "itl": 22.867548887614785,
    "ttft": 4292.071856691153,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1416,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.438149731792409,
    "arrivals": 9311,
    "finished_requests": 9300,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1059096129611135. Arrivals time: 0.03504460584372282 Scheduler time: 0.6898846765980124 Scheduler overhead time: 0.12931317230686545 Adapter cache time: 0.05962626822292805 Engine time: 0.12865062803030014 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-8/adapters_128_slots_64_rate_0.025-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-8/adapters_128_slots_64_rate_0.025-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [42 43 43]
Adapter prompts. [270, 135, 270, 270, 66, 66, 270, 66, 135, 135, 135, 66, 270, 135, 66, 270, 135, 66, 66, 66, 66, 135, 135, 270, 135, 66, 135, 135, 135, 135, 270, 135, 66, 135, 66, 270, 270, 66, 135, 135, 66, 135, 66, 135, 135, 270, 270, 270, 270, 135, 135, 66, 135, 270, 270, 135, 66, 66, 66, 270, 135, 135, 135, 135, 270, 135, 270, 66, 66, 135, 66, 270, 270, 66, 66, 135, 135, 135, 66, 270, 66, 270, 135, 66, 270, 270, 135, 135, 66, 66, 66, 270, 270, 270, 270, 270, 270, 270, 270, 66, 270, 66, 66, 270, 135, 270, 270, 135, 270, 66, 135, 270, 66, 270, 135, 66, 135, 135, 270, 270, 66, 66, 270, 66, 66, 66, 135, 66]
Prompts retrieved: 20187 . Total input tokens: 4474733 . Total output tokens: 3968333
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 0.9480140497907996,
    "estimated_duration": 3598.565456112734,
    "input_throughput": 457.5256501735344,
    "output_throughput": 406.486145059626,
    "total_throughput": 864.0117952331605,
    "itl": 22.198328881378877,
    "ttft": 3203.5032664406062,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2758,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 18.237024110117847,
    "arrivals": 6826,
    "finished_requests": 6820,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9480879320763052. Arrivals time: 0.02874408010393381 Scheduler time: 0.5361610171385109 Scheduler overhead time: 0.13065070193260908 Adapter cache time: 0.054879662580788136 Engine time: 0.1324822404421866 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-16/adapters_128_slots_64_rate_0.025-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-16/adapters_128_slots_64_rate_0.025-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [42 43 43]
Adapter prompts. [270, 135, 270, 270, 66, 66, 270, 66, 135, 135, 135, 66, 270, 135, 66, 270, 135, 66, 66, 66, 66, 135, 135, 270, 135, 66, 135, 135, 135, 135, 270, 135, 66, 135, 66, 270, 270, 66, 135, 135, 66, 135, 66, 135, 135, 270, 270, 270, 270, 135, 135, 66, 135, 270, 270, 135, 66, 66, 66, 270, 135, 135, 135, 135, 270, 135, 270, 66, 66, 135, 66, 270, 270, 66, 66, 135, 135, 135, 66, 270, 66, 270, 135, 66, 270, 270, 135, 135, 66, 66, 66, 270, 270, 270, 270, 270, 270, 270, 270, 66, 270, 66, 66, 270, 135, 270, 270, 135, 270, 66, 135, 270, 66, 270, 135, 66, 135, 135, 270, 270, 66, 66, 270, 66, 66, 66, 135, 66]
Prompts retrieved: 20187 . Total input tokens: 4474733 . Total output tokens: 3968333
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 0.9477676711976528,
    "estimated_duration": 3598.5629730850615,
    "input_throughput": 457.5259658686768,
    "output_throughput": 406.48642553723727,
    "total_throughput": 864.0123914059141,
    "itl": 22.212540854349594,
    "ttft": 3203.7558480620373,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2759,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.19671710636887,
    "arrivals": 6826,
    "finished_requests": 6820,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9478236879222095. Arrivals time: 0.028594647999852896 Scheduler time: 0.5377374100498855 Scheduler overhead time: 0.13080216338858008 Adapter cache time: 0.05472991615533829 Engine time: 0.13061667559668422 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-32/adapters_128_slots_64_rate_0.025-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-32/adapters_128_slots_64_rate_0.025-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [42 43 43]
Adapter prompts. [270, 135, 270, 270, 66, 66, 270, 66, 135, 135, 135, 66, 270, 135, 66, 270, 135, 66, 66, 66, 66, 135, 135, 270, 135, 66, 135, 135, 135, 135, 270, 135, 66, 135, 66, 270, 270, 66, 135, 135, 66, 135, 66, 135, 135, 270, 270, 270, 270, 135, 135, 66, 135, 270, 270, 135, 66, 66, 66, 270, 135, 135, 135, 135, 270, 135, 270, 66, 66, 135, 66, 270, 270, 66, 66, 135, 135, 135, 66, 270, 66, 270, 135, 66, 270, 270, 135, 135, 66, 66, 66, 270, 270, 270, 270, 270, 270, 270, 270, 66, 270, 66, 66, 270, 135, 270, 270, 135, 270, 66, 135, 270, 66, 270, 135, 66, 135, 135, 270, 270, 66, 66, 270, 66, 66, 66, 135, 66]
Prompts retrieved: 20187 . Total input tokens: 4474733 . Total output tokens: 3968333
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 0.954569976311177,
    "estimated_duration": 3598.564195711014,
    "input_throughput": 457.5258104224796,
    "output_throughput": 406.4862874319191,
    "total_throughput": 864.0120978543987,
    "itl": 22.21504324961701,
    "ttft": 3203.83401311431,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2759,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.747378295599706,
    "arrivals": 6826,
    "finished_requests": 6820,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9546298980712891. Arrivals time: 0.028800600208342075 Scheduler time: 0.5370068424381316 Scheduler overhead time: 0.13156091189011931 Adapter cache time: 0.05496836453676224 Engine time: 0.1371580041013658 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-16/adapters_128_slots_64_rate_0.025-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-16/adapters_128_slots_64_rate_0.025-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [42 43 43]
Adapter prompts. [270, 135, 270, 270, 66, 66, 270, 66, 135, 135, 135, 66, 270, 135, 66, 270, 135, 66, 66, 66, 66, 135, 135, 270, 135, 66, 135, 135, 135, 135, 270, 135, 66, 135, 66, 270, 270, 66, 135, 135, 66, 135, 66, 135, 135, 270, 270, 270, 270, 135, 135, 66, 135, 270, 270, 135, 66, 66, 66, 270, 135, 135, 135, 135, 270, 135, 270, 66, 66, 135, 66, 270, 270, 66, 66, 135, 135, 135, 66, 270, 66, 270, 135, 66, 270, 270, 135, 135, 66, 66, 66, 270, 270, 270, 270, 270, 270, 270, 270, 66, 270, 66, 66, 270, 135, 270, 270, 135, 270, 66, 135, 270, 66, 270, 135, 66, 135, 135, 270, 270, 66, 66, 270, 66, 66, 66, 135, 66]
Prompts retrieved: 20187 . Total input tokens: 4474733 . Total output tokens: 3968333
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 0.9449610412120819,
    "estimated_duration": 3598.5733884652254,
    "input_throughput": 457.52464164756054,
    "output_throughput": 406.4852490402768,
    "total_throughput": 864.0098906878374,
    "itl": 22.204556839870705,
    "ttft": 3203.5312664827134,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2759,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 18.961200440121296,
    "arrivals": 6826,
    "finished_requests": 6820,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9450203399173915. Arrivals time: 0.028915257193148136 Scheduler time: 0.5348662384785712 Scheduler overhead time: 0.13068562746047974 Adapter cache time: 0.05466791382059455 Engine time: 0.13092777132987976 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-32/adapters_128_slots_64_rate_0.025-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-32/adapters_128_slots_64_rate_0.025-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [42 43 43]
Adapter prompts. [270, 135, 270, 270, 66, 66, 270, 66, 135, 135, 135, 66, 270, 135, 66, 270, 135, 66, 66, 66, 66, 135, 135, 270, 135, 66, 135, 135, 135, 135, 270, 135, 66, 135, 66, 270, 270, 66, 135, 135, 66, 135, 66, 135, 135, 270, 270, 270, 270, 135, 135, 66, 135, 270, 270, 135, 66, 66, 66, 270, 135, 135, 135, 135, 270, 135, 270, 66, 66, 135, 66, 270, 270, 66, 66, 135, 135, 135, 66, 270, 66, 270, 135, 66, 270, 270, 135, 135, 66, 66, 66, 270, 270, 270, 270, 270, 270, 270, 270, 66, 270, 66, 66, 270, 135, 270, 270, 135, 270, 66, 135, 270, 66, 270, 135, 66, 135, 135, 270, 270, 66, 66, 270, 66, 66, 66, 135, 66]
Prompts retrieved: 20187 . Total input tokens: 4474733 . Total output tokens: 3968333
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 0.9518299358896911,
    "estimated_duration": 3598.5719204754423,
    "input_throughput": 457.52482828868216,
    "output_throughput": 406.4854148605538,
    "total_throughput": 864.010243149236,
    "itl": 22.216257842639468,
    "ttft": 3203.8319702944805,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2759,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.563044008412604,
    "arrivals": 6826,
    "finished_requests": 6820,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9519056980498135. Arrivals time: 0.029075537342578173 Scheduler time: 0.5392178324982524 Scheduler overhead time: 0.12975520454347134 Adapter cache time: 0.055112441536039114 Engine time: 0.13315991824492812 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-16/adapters_128_slots_64_rate_0.025-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-16/adapters_128_slots_64_rate_0.025-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [42 43 43]
Adapter prompts. [270, 135, 270, 270, 66, 66, 270, 66, 135, 135, 135, 66, 270, 135, 66, 270, 135, 66, 66, 66, 66, 135, 135, 270, 135, 66, 135, 135, 135, 135, 270, 135, 66, 135, 66, 270, 270, 66, 135, 135, 66, 135, 66, 135, 135, 270, 270, 270, 270, 135, 135, 66, 135, 270, 270, 135, 66, 66, 66, 270, 135, 135, 135, 135, 270, 135, 270, 66, 66, 135, 66, 270, 270, 66, 66, 135, 135, 135, 66, 270, 66, 270, 135, 66, 270, 270, 135, 135, 66, 66, 66, 270, 270, 270, 270, 270, 270, 270, 270, 66, 270, 66, 66, 270, 135, 270, 270, 135, 270, 66, 135, 270, 66, 270, 135, 66, 135, 135, 270, 270, 66, 66, 270, 66, 66, 66, 135, 66]
Prompts retrieved: 20187 . Total input tokens: 4474733 . Total output tokens: 3968333
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 0.9487969167530537,
    "estimated_duration": 3598.5782457830355,
    "input_throughput": 457.5240240862798,
    "output_throughput": 406.48470037135684,
    "total_throughput": 864.0087244576366,
    "itl": 22.195410310157044,
    "ttft": 3203.4001588501833,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2759,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.61323787503534,
    "arrivals": 6826,
    "finished_requests": 6820,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9488988700322807. Arrivals time: 0.02878059446811676 Scheduler time: 0.5391014777123928 Scheduler overhead time: 0.13075028453022242 Adapter cache time: 0.05409904709085822 Engine time: 0.13112614443525672 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-32/adapters_128_slots_64_rate_0.025-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-32/adapters_128_slots_64_rate_0.025-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [42 43 43]
Adapter prompts. [270, 135, 270, 270, 66, 66, 270, 66, 135, 135, 135, 66, 270, 135, 66, 270, 135, 66, 66, 66, 66, 135, 135, 270, 135, 66, 135, 135, 135, 135, 270, 135, 66, 135, 66, 270, 270, 66, 135, 135, 66, 135, 66, 135, 135, 270, 270, 270, 270, 135, 135, 66, 135, 270, 270, 135, 66, 66, 66, 270, 135, 135, 135, 135, 270, 135, 270, 66, 66, 135, 66, 270, 270, 66, 66, 135, 135, 135, 66, 270, 66, 270, 135, 66, 270, 270, 135, 135, 66, 66, 66, 270, 270, 270, 270, 270, 270, 270, 270, 66, 270, 66, 66, 270, 135, 270, 270, 135, 270, 66, 135, 270, 66, 270, 135, 66, 135, 135, 270, 270, 66, 66, 270, 66, 66, 66, 135, 66]
Prompts retrieved: 20187 . Total input tokens: 4474733 . Total output tokens: 3968333
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 0.9575789282098413,
    "estimated_duration": 3598.5795683807823,
    "input_throughput": 457.52385593097523,
    "output_throughput": 406.4845509747022,
    "total_throughput": 864.0084069056774,
    "itl": 22.21176960561102,
    "ttft": 3203.783034631454,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2759,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.361933229919703,
    "arrivals": 6826,
    "finished_requests": 6820,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9576472048647702. Arrivals time: 0.029098862782120705 Scheduler time: 0.5411352408118546 Scheduler overhead time: 0.13141017127782106 Adapter cache time: 0.05501291714608669 Engine time: 0.13574840780347586 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-8/adapters_128_slots_64_rate_0.025-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-8/adapters_128_slots_64_rate_0.025-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [42 43 43]
Adapter prompts. [270, 135, 270, 270, 33, 33, 270, 33, 135, 135, 135, 33, 270, 135, 33, 270, 135, 33, 33, 33, 33, 135, 135, 270, 135, 33, 135, 135, 135, 135, 270, 135, 33, 135, 33, 270, 270, 33, 135, 135, 33, 135, 33, 135, 135, 270, 270, 270, 270, 135, 135, 33, 135, 270, 270, 135, 33, 33, 33, 270, 135, 135, 135, 135, 270, 135, 270, 33, 33, 135, 33, 270, 270, 33, 33, 135, 135, 135, 33, 270, 33, 270, 135, 33, 270, 270, 135, 135, 33, 33, 33, 270, 270, 270, 270, 270, 270, 270, 270, 33, 270, 33, 33, 270, 135, 270, 270, 135, 270, 33, 135, 270, 33, 270, 135, 33, 135, 135, 270, 270, 33, 33, 270, 33, 33, 33, 135, 33]
Prompts retrieved: 18801 . Total input tokens: 4165516 . Total output tokens: 3700813
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 0.9183911508880556,
    "estimated_duration": 3600.001878982243,
    "input_throughput": 428.26644313748835,
    "output_throughput": 376.3295258009732,
    "total_throughput": 804.5959689384615,
    "itl": 21.67794771850854,
    "ttft": 6291.128167681578,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2148,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.203454600628856,
    "arrivals": 6333,
    "finished_requests": 6322,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9184650178067386. Arrivals time: 0.027710474096238613 Scheduler time: 0.5045091691426933 Scheduler overhead time: 0.13090883614495397 Adapter cache time: 0.05219414783641696 Engine time: 0.13758242456242442 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-16/adapters_128_slots_64_rate_0.025-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-16/adapters_128_slots_64_rate_0.025-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [42 43 43]
Adapter prompts. [270, 135, 270, 270, 33, 33, 270, 33, 135, 135, 135, 33, 270, 135, 33, 270, 135, 33, 33, 33, 33, 135, 135, 270, 135, 33, 135, 135, 135, 135, 270, 135, 33, 135, 33, 270, 270, 33, 135, 135, 33, 135, 33, 135, 135, 270, 270, 270, 270, 135, 135, 33, 135, 270, 270, 135, 33, 33, 33, 270, 135, 135, 135, 135, 270, 135, 270, 33, 33, 135, 33, 270, 270, 33, 33, 135, 135, 135, 33, 270, 33, 270, 135, 33, 270, 270, 135, 135, 33, 33, 33, 270, 270, 270, 270, 270, 270, 270, 270, 33, 270, 33, 33, 270, 135, 270, 270, 135, 270, 33, 135, 270, 33, 270, 135, 33, 135, 135, 270, 270, 33, 33, 270, 33, 33, 33, 135, 33]
Prompts retrieved: 18801 . Total input tokens: 4165516 . Total output tokens: 3700813
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 0.9279751931317151,
    "estimated_duration": 3600.0049032919637,
    "input_throughput": 428.2660833573209,
    "output_throughput": 376.3292096522252,
    "total_throughput": 804.595293009546,
    "itl": 21.689807055583632,
    "ttft": 6291.223431065862,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2148,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.706147498022489,
    "arrivals": 6333,
    "finished_requests": 6322,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9280274282209575. Arrivals time: 0.02801865478977561 Scheduler time: 0.5142832612618804 Scheduler overhead time: 0.13240440795198083 Adapter cache time: 0.05244051245972514 Engine time: 0.13495593471452594 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-32/adapters_128_slots_64_rate_0.025-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-32/adapters_128_slots_64_rate_0.025-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [42 43 43]
Adapter prompts. [270, 135, 270, 270, 33, 33, 270, 33, 135, 135, 135, 33, 270, 135, 33, 270, 135, 33, 33, 33, 33, 135, 135, 270, 135, 33, 135, 135, 135, 135, 270, 135, 33, 135, 33, 270, 270, 33, 135, 135, 33, 135, 33, 135, 135, 270, 270, 270, 270, 135, 135, 33, 135, 270, 270, 135, 33, 33, 33, 270, 135, 135, 135, 135, 270, 135, 270, 33, 33, 135, 33, 270, 270, 33, 33, 135, 135, 135, 33, 270, 33, 270, 135, 33, 270, 270, 135, 135, 33, 33, 33, 270, 270, 270, 270, 270, 270, 270, 270, 33, 270, 33, 33, 270, 135, 270, 270, 135, 270, 33, 135, 270, 33, 270, 135, 33, 135, 135, 270, 270, 33, 33, 270, 33, 33, 33, 135, 33]
Prompts retrieved: 18801 . Total input tokens: 4165516 . Total output tokens: 3700813
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 0.9229119149968028,
    "estimated_duration": 3600.0032830487808,
    "input_throughput": 428.2662761058123,
    "output_throughput": 376.3293790256364,
    "total_throughput": 804.5956551314488,
    "itl": 21.695163052597582,
    "ttft": 6291.4639696273225,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2150,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.146887600430905,
    "arrivals": 6333,
    "finished_requests": 6322,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9229855490848422. Arrivals time: 0.027508202474564314 Scheduler time: 0.5134847746230662 Scheduler overhead time: 0.13059709034860134 Adapter cache time: 0.052352338563650846 Engine time: 0.13298182329162955 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-16/adapters_128_slots_64_rate_0.025-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-16/adapters_128_slots_64_rate_0.025-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [42 43 43]
Adapter prompts. [270, 135, 270, 270, 33, 33, 270, 33, 135, 135, 135, 33, 270, 135, 33, 270, 135, 33, 33, 33, 33, 135, 135, 270, 135, 33, 135, 135, 135, 135, 270, 135, 33, 135, 33, 270, 270, 33, 135, 135, 33, 135, 33, 135, 135, 270, 270, 270, 270, 135, 135, 33, 135, 270, 270, 135, 33, 33, 33, 270, 135, 135, 135, 135, 270, 135, 270, 33, 33, 135, 33, 270, 270, 33, 33, 135, 135, 135, 33, 270, 33, 270, 135, 33, 270, 270, 135, 135, 33, 33, 33, 270, 270, 270, 270, 270, 270, 270, 270, 33, 270, 33, 33, 270, 135, 270, 270, 135, 270, 33, 135, 270, 33, 270, 135, 33, 135, 135, 270, 270, 33, 33, 270, 33, 33, 33, 135, 33]
Prompts retrieved: 18801 . Total input tokens: 4165516 . Total output tokens: 3700813
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 0.9236533138900995,
    "estimated_duration": 3600.0154306762647,
    "input_throughput": 428.26483099556594,
    "output_throughput": 376.32810916743836,
    "total_throughput": 804.5929401630043,
    "itl": 21.686266219918757,
    "ttft": 6291.355472439539,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2149,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.804634902416957,
    "arrivals": 6333,
    "finished_requests": 6322,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9237027480266988. Arrivals time: 0.02819172153249383 Scheduler time: 0.510388673748821 Scheduler overhead time: 0.13196143694221973 Adapter cache time: 0.0522447070106864 Engine time: 0.13511050026863813 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-32/adapters_128_slots_64_rate_0.025-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-32/adapters_128_slots_64_rate_0.025-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [42 43 43]
Adapter prompts. [270, 135, 270, 270, 33, 33, 270, 33, 135, 135, 135, 33, 270, 135, 33, 270, 135, 33, 33, 33, 33, 135, 135, 270, 135, 33, 135, 135, 135, 135, 270, 135, 33, 135, 33, 270, 270, 33, 135, 135, 33, 135, 33, 135, 135, 270, 270, 270, 270, 135, 135, 33, 135, 270, 270, 135, 33, 33, 33, 270, 135, 135, 135, 135, 270, 135, 270, 33, 33, 135, 33, 270, 270, 33, 33, 135, 135, 135, 33, 270, 33, 270, 135, 33, 270, 270, 135, 135, 33, 33, 33, 270, 270, 270, 270, 270, 270, 270, 270, 33, 270, 33, 33, 270, 135, 270, 270, 135, 270, 33, 135, 270, 33, 270, 135, 33, 135, 135, 270, 270, 33, 33, 270, 33, 33, 33, 135, 33]
Prompts retrieved: 18801 . Total input tokens: 4165516 . Total output tokens: 3700813
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 0.9256578818894923,
    "estimated_duration": 3600.008212673061,
    "input_throughput": 428.26568966497433,
    "output_throughput": 376.3288637039108,
    "total_throughput": 804.5945533688852,
    "itl": 21.69193869771088,
    "ttft": 6291.374809884804,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2149,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.00314977637459,
    "arrivals": 6333,
    "finished_requests": 6322,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9257341329939663. Arrivals time: 0.0278142592869699 Scheduler time: 0.5162068963982165 Scheduler overhead time: 0.13112954143434763 Adapter cache time: 0.05254834471270442 Engine time: 0.1322250277735293 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-16/adapters_128_slots_64_rate_0.025-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-16/adapters_128_slots_64_rate_0.025-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [42 43 43]
Adapter prompts. [270, 135, 270, 270, 33, 33, 270, 33, 135, 135, 135, 33, 270, 135, 33, 270, 135, 33, 33, 33, 33, 135, 135, 270, 135, 33, 135, 135, 135, 135, 270, 135, 33, 135, 33, 270, 270, 33, 135, 135, 33, 135, 33, 135, 135, 270, 270, 270, 270, 135, 135, 33, 135, 270, 270, 135, 33, 33, 33, 270, 135, 135, 135, 135, 270, 135, 270, 33, 33, 135, 33, 270, 270, 33, 33, 135, 135, 135, 33, 270, 33, 270, 135, 33, 270, 270, 135, 135, 33, 33, 33, 270, 270, 270, 270, 270, 270, 270, 270, 33, 270, 33, 33, 270, 135, 270, 270, 135, 270, 33, 135, 270, 33, 270, 135, 33, 135, 135, 270, 270, 33, 33, 270, 33, 33, 33, 135, 33]
Prompts retrieved: 18801 . Total input tokens: 4165516 . Total output tokens: 3700813
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 0.9285717350430787,
    "estimated_duration": 3599.9994721735293,
    "input_throughput": 428.26672945847673,
    "output_throughput": 376.32977739911615,
    "total_throughput": 804.5965068575929,
    "itl": 21.676289004468337,
    "ttft": 6291.134878088681,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2148,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.712662180346227,
    "arrivals": 6333,
    "finished_requests": 6322,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9286215640604496. Arrivals time: 0.027673671022057533 Scheduler time: 0.5162410121411085 Scheduler overhead time: 0.1311526265926659 Adapter cache time: 0.052792598493397236 Engine time: 0.13494557049125433 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-32/adapters_128_slots_64_rate_0.025-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-32/adapters_128_slots_64_rate_0.025-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [42 43 43]
Adapter prompts. [270, 135, 270, 270, 33, 33, 270, 33, 135, 135, 135, 33, 270, 135, 33, 270, 135, 33, 33, 33, 33, 135, 135, 270, 135, 33, 135, 135, 135, 135, 270, 135, 33, 135, 33, 270, 270, 33, 135, 135, 33, 135, 33, 135, 135, 270, 270, 270, 270, 135, 135, 33, 135, 270, 270, 135, 33, 33, 33, 270, 135, 135, 135, 135, 270, 135, 270, 33, 33, 135, 33, 270, 270, 33, 33, 135, 135, 135, 33, 270, 33, 270, 135, 33, 270, 270, 135, 135, 33, 33, 33, 270, 270, 270, 270, 270, 270, 270, 270, 33, 270, 33, 33, 270, 135, 270, 270, 135, 270, 33, 135, 270, 33, 270, 135, 33, 135, 135, 270, 270, 33, 33, 270, 33, 33, 33, 135, 33]
Prompts retrieved: 18801 . Total input tokens: 4165516 . Total output tokens: 3700813
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 0.9186636377125978,
    "estimated_duration": 3600.0122122325743,
    "input_throughput": 428.26521386822355,
    "output_throughput": 376.3284456081939,
    "total_throughput": 804.5936594764174,
    "itl": 21.689563841083448,
    "ttft": 6291.444553963771,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2149,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.841184144261897,
    "arrivals": 6333,
    "finished_requests": 6322,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9187414646148682. Arrivals time: 0.027576708234846592 Scheduler time: 0.5100803393870592 Scheduler overhead time: 0.13148427847772837 Adapter cache time: 0.052226150408387184 Engine time: 0.13181919371709228 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-8/adapters_128_slots_64_rate_0.025-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-8/adapters_128_slots_64_rate_0.025-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [42 43 43]
Adapter prompts. [270, 66, 270, 270, 33, 33, 270, 33, 66, 66, 66, 33, 270, 66, 33, 270, 66, 33, 33, 33, 33, 66, 66, 270, 66, 33, 66, 66, 66, 66, 270, 66, 33, 66, 33, 270, 270, 33, 66, 66, 33, 66, 33, 66, 66, 270, 270, 270, 270, 66, 66, 33, 66, 270, 270, 66, 33, 33, 33, 270, 66, 66, 66, 66, 270, 66, 270, 33, 33, 66, 33, 270, 270, 33, 33, 66, 66, 66, 33, 270, 33, 270, 66, 33, 270, 270, 66, 66, 33, 33, 33, 270, 270, 270, 270, 270, 270, 270, 270, 33, 270, 33, 33, 270, 66, 270, 270, 66, 270, 33, 66, 270, 33, 270, 66, 33, 66, 66, 270, 270, 33, 33, 270, 33, 33, 33, 66, 33]
Prompts retrieved: 15834 . Total input tokens: 3488360 . Total output tokens: 3129530
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 0.8726283288560808,
    "estimated_duration": 3599.433297480416,
    "input_throughput": 355.0992321193179,
    "output_throughput": 326.82839290937034,
    "total_throughput": 681.9276250286882,
    "itl": 21.35930598284824,
    "ttft": 7426.336731407705,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1417,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.369783598273296,
    "arrivals": 5359,
    "finished_requests": 5348,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8726784847676754. Arrivals time: 0.02534253615885973 Scheduler time: 0.4634402538649738 Scheduler overhead time: 0.13497334672138095 Adapter cache time: 0.04648458072915673 Engine time: 0.13566954340785742 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-16/adapters_128_slots_64_rate_0.025-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-16/adapters_128_slots_64_rate_0.025-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [42 43 43]
Adapter prompts. [270, 66, 270, 270, 33, 33, 270, 33, 66, 66, 66, 33, 270, 66, 33, 270, 66, 33, 33, 33, 33, 66, 66, 270, 66, 33, 66, 66, 66, 66, 270, 66, 33, 66, 33, 270, 270, 33, 66, 66, 33, 66, 33, 66, 66, 270, 270, 270, 270, 66, 66, 33, 66, 270, 270, 66, 33, 33, 33, 270, 66, 66, 66, 66, 270, 66, 270, 33, 33, 66, 33, 270, 270, 33, 33, 66, 66, 66, 33, 270, 33, 270, 66, 33, 270, 270, 66, 66, 33, 33, 33, 270, 270, 270, 270, 270, 270, 270, 270, 33, 270, 33, 33, 270, 66, 270, 270, 66, 270, 33, 66, 270, 33, 270, 66, 33, 66, 66, 270, 270, 33, 33, 270, 33, 33, 33, 66, 33]
Prompts retrieved: 15834 . Total input tokens: 3488360 . Total output tokens: 3129530
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 0.8634986453689635,
    "estimated_duration": 3599.4508706524553,
    "input_throughput": 355.0974984604568,
    "output_throughput": 326.8267972738742,
    "total_throughput": 681.9242957343309,
    "itl": 21.366041489518977,
    "ttft": 7426.50668824972,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1417,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.360661234515645,
    "arrivals": 5359,
    "finished_requests": 5348,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8635722971521318. Arrivals time: 0.025208058301359415 Scheduler time: 0.4604274616576731 Scheduler overhead time: 0.1318763350136578 Adapter cache time: 0.046410171780735254 Engine time: 0.13317699590697885 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-32/adapters_128_slots_64_rate_0.025-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-32/adapters_128_slots_64_rate_0.025-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [42 43 43]
Adapter prompts. [270, 66, 270, 270, 33, 33, 270, 33, 66, 66, 66, 33, 270, 66, 33, 270, 66, 33, 33, 33, 33, 66, 66, 270, 66, 33, 66, 66, 66, 66, 270, 66, 33, 66, 33, 270, 270, 33, 66, 66, 33, 66, 33, 66, 66, 270, 270, 270, 270, 66, 66, 33, 66, 270, 270, 66, 33, 33, 33, 270, 66, 66, 66, 66, 270, 66, 270, 33, 33, 66, 33, 270, 270, 33, 33, 66, 66, 66, 33, 270, 33, 270, 66, 33, 270, 270, 66, 66, 33, 33, 33, 270, 270, 270, 270, 270, 270, 270, 270, 33, 270, 33, 33, 270, 66, 270, 270, 66, 270, 33, 66, 270, 33, 270, 66, 33, 66, 66, 270, 270, 33, 33, 270, 33, 33, 33, 66, 33]
Prompts retrieved: 15834 . Total input tokens: 3488360 . Total output tokens: 3129530
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 0.8710279511287808,
    "estimated_duration": 3599.4348843841544,
    "input_throughput": 355.0990755646594,
    "output_throughput": 326.8282488186408,
    "total_throughput": 681.9273243833002,
    "itl": 21.366418882101453,
    "ttft": 7426.727017002088,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1417,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.640656965025606,
    "arrivals": 5359,
    "finished_requests": 5348,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8710958659648895. Arrivals time: 0.025947218760848045 Scheduler time: 0.4644127730280161 Scheduler overhead time: 0.13177979085594416 Adapter cache time: 0.04663734417408705 Engine time: 0.1360774552449584 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-16/adapters_128_slots_64_rate_0.025-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-16/adapters_128_slots_64_rate_0.025-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [42 43 43]
Adapter prompts. [270, 66, 270, 270, 33, 33, 270, 33, 66, 66, 66, 33, 270, 66, 33, 270, 66, 33, 33, 33, 33, 66, 66, 270, 66, 33, 66, 66, 66, 66, 270, 66, 33, 66, 33, 270, 270, 33, 66, 66, 33, 66, 33, 66, 66, 270, 270, 270, 270, 66, 66, 33, 66, 270, 270, 66, 33, 33, 33, 270, 66, 66, 66, 66, 270, 66, 270, 33, 33, 66, 33, 270, 270, 33, 33, 66, 66, 66, 33, 270, 33, 270, 66, 33, 270, 270, 66, 66, 33, 33, 33, 270, 270, 270, 270, 270, 270, 270, 270, 33, 270, 33, 33, 270, 66, 270, 270, 66, 270, 33, 66, 270, 33, 270, 66, 33, 66, 66, 270, 270, 33, 33, 270, 33, 33, 33, 66, 33]
Prompts retrieved: 15834 . Total input tokens: 3488360 . Total output tokens: 3129530
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 0.8667165022343397,
    "estimated_duration": 3599.449093526564,
    "input_throughput": 355.09767377977425,
    "output_throughput": 326.8269586353349,
    "total_throughput": 681.9246324151092,
    "itl": 21.35763651520604,
    "ttft": 7426.455671616165,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1417,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.737350017498303,
    "arrivals": 5359,
    "finished_requests": 5348,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8667904711328447. Arrivals time: 0.025784227065742016 Scheduler time: 0.4604984656907618 Scheduler overhead time: 0.13250763714313507 Adapter cache time: 0.04654812440276146 Engine time: 0.135094890370965 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-32/adapters_128_slots_64_rate_0.025-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-32/adapters_128_slots_64_rate_0.025-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [42 43 43]
Adapter prompts. [270, 66, 270, 270, 33, 33, 270, 33, 66, 66, 66, 33, 270, 66, 33, 270, 66, 33, 33, 33, 33, 66, 66, 270, 66, 33, 66, 66, 66, 66, 270, 66, 33, 66, 33, 270, 270, 33, 66, 66, 33, 66, 33, 66, 66, 270, 270, 270, 270, 66, 66, 33, 66, 270, 270, 66, 33, 33, 33, 270, 66, 66, 66, 66, 270, 66, 270, 33, 33, 66, 33, 270, 270, 33, 33, 66, 66, 66, 33, 270, 33, 270, 66, 33, 270, 270, 66, 66, 33, 33, 33, 270, 270, 270, 270, 270, 270, 270, 270, 33, 270, 33, 33, 270, 66, 270, 270, 66, 270, 33, 66, 270, 33, 270, 66, 33, 66, 66, 270, 270, 33, 33, 270, 33, 33, 33, 66, 33]
Prompts retrieved: 15834 . Total input tokens: 3488360 . Total output tokens: 3129530
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 0.8685449161566794,
    "estimated_duration": 3599.4475481968807,
    "input_throughput": 355.09782623177375,
    "output_throughput": 326.8270989500342,
    "total_throughput": 681.924925181808,
    "itl": 21.364773669648265,
    "ttft": 7426.7296466244325,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1417,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.547661352725605,
    "arrivals": 5359,
    "finished_requests": 5348,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.868598538916558. Arrivals time: 0.025856364984065294 Scheduler time: 0.4584587747231126 Scheduler overhead time: 0.13264587195590138 Adapter cache time: 0.04907154059037566 Engine time: 0.13633275171741843 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-16/adapters_128_slots_64_rate_0.025-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-16/adapters_128_slots_64_rate_0.025-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [42 43 43]
Adapter prompts. [270, 66, 270, 270, 33, 33, 270, 33, 66, 66, 66, 33, 270, 66, 33, 270, 66, 33, 33, 33, 33, 66, 66, 270, 66, 33, 66, 66, 66, 66, 270, 66, 33, 66, 33, 270, 270, 33, 66, 66, 33, 66, 33, 66, 66, 270, 270, 270, 270, 66, 66, 33, 66, 270, 270, 66, 33, 33, 33, 270, 66, 66, 66, 66, 270, 66, 270, 33, 33, 66, 33, 270, 270, 33, 33, 66, 66, 66, 33, 270, 33, 270, 66, 33, 270, 270, 66, 66, 33, 33, 33, 270, 270, 270, 270, 270, 270, 270, 270, 33, 270, 33, 33, 270, 66, 270, 270, 66, 270, 33, 66, 270, 33, 270, 66, 33, 66, 66, 270, 270, 33, 33, 270, 33, 33, 33, 66, 33]
Prompts retrieved: 15834 . Total input tokens: 3488360 . Total output tokens: 3129530
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 0.8614872852340341,
    "estimated_duration": 3599.4402836343556,
    "input_throughput": 355.0985429071893,
    "output_throughput": 326.82775856811594,
    "total_throughput": 681.9263014753053,
    "itl": 21.356480190650142,
    "ttft": 7426.502243904542,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1417,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.046015972788544,
    "arrivals": 5359,
    "finished_requests": 5348,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8615827802568674. Arrivals time: 0.025975797791033983 Scheduler time: 0.4574267975986004 Scheduler overhead time: 0.13152707321569324 Adapter cache time: 0.04633438168093562 Engine time: 0.13421396259218454 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-32/adapters_128_slots_64_rate_0.025-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-32/adapters_128_slots_64_rate_0.025-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [42 43 43]
Adapter prompts. [270, 66, 270, 270, 33, 33, 270, 33, 66, 66, 66, 33, 270, 66, 33, 270, 66, 33, 33, 33, 33, 66, 66, 270, 66, 33, 66, 66, 66, 66, 270, 66, 33, 66, 33, 270, 270, 33, 66, 66, 33, 66, 33, 66, 66, 270, 270, 270, 270, 66, 66, 33, 66, 270, 270, 66, 33, 33, 33, 270, 66, 66, 66, 66, 270, 66, 270, 33, 33, 66, 33, 270, 270, 33, 33, 66, 66, 66, 33, 270, 33, 270, 66, 33, 270, 270, 66, 66, 33, 33, 33, 270, 270, 270, 270, 270, 270, 270, 270, 33, 270, 33, 33, 270, 66, 270, 270, 66, 270, 33, 66, 270, 33, 270, 66, 33, 66, 66, 270, 270, 33, 33, 270, 33, 33, 33, 66, 33]
Prompts retrieved: 15834 . Total input tokens: 3488360 . Total output tokens: 3129530
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 0.8639975180849433,
    "estimated_duration": 3599.43714069197,
    "input_throughput": 355.0988529707404,
    "output_throughput": 326.82804394629454,
    "total_throughput": 681.9268969170349,
    "itl": 21.367123210123886,
    "ttft": 7426.620399629904,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1417,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.44451699877149,
    "arrivals": 5359,
    "finished_requests": 5348,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8640498793683946. Arrivals time: 0.025652998127043247 Scheduler time: 0.45717182382941246 Scheduler overhead time: 0.13161224173381925 Adapter cache time: 0.04646610002964735 Engine time: 0.13460007403045893 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-8/adapters_128_slots_64_rate_0.0125-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-8/adapters_128_slots_64_rate_0.0125-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [42 43 43]
Adapter prompts. [135, 66, 135, 135, 33, 33, 135, 33, 66, 66, 66, 33, 135, 66, 33, 135, 66, 33, 33, 33, 33, 66, 66, 135, 66, 33, 66, 66, 66, 66, 135, 66, 33, 66, 33, 135, 135, 33, 66, 66, 33, 66, 33, 66, 66, 135, 135, 135, 135, 66, 66, 33, 66, 135, 135, 66, 33, 33, 33, 135, 66, 66, 66, 66, 135, 66, 135, 33, 33, 66, 33, 135, 135, 33, 33, 66, 66, 66, 33, 135, 33, 135, 66, 33, 135, 135, 66, 66, 33, 33, 33, 135, 135, 135, 135, 135, 135, 135, 135, 33, 135, 33, 33, 135, 66, 135, 135, 66, 135, 33, 66, 135, 33, 135, 66, 33, 66, 66, 135, 135, 33, 33, 135, 33, 33, 33, 66, 33]
Prompts retrieved: 10029 . Total input tokens: 2210239 . Total output tokens: 1976283
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 0.7212614207528532,
    "estimated_duration": 3598.3645890415346,
    "input_throughput": 222.43993908721768,
    "output_throughput": 202.45752812781222,
    "total_throughput": 424.8974672150299,
    "itl": 20.67250718466105,
    "ttft": 3312.416654667821,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1368,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.045775555707738,
    "arrivals": 3297,
    "finished_requests": 3294,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7213105410337448. Arrivals time: 0.02060629241168499 Scheduler time: 0.326501979958266 Scheduler overhead time: 0.1324761020950973 Adapter cache time: 0.03810239676386118 Engine time: 0.13625729456543922 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-16/adapters_128_slots_64_rate_0.0125-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-16/adapters_128_slots_64_rate_0.0125-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [42 43 43]
Adapter prompts. [135, 66, 135, 135, 33, 33, 135, 33, 66, 66, 66, 33, 135, 66, 33, 135, 66, 33, 33, 33, 33, 66, 66, 135, 66, 33, 66, 66, 66, 66, 135, 66, 33, 66, 33, 135, 135, 33, 66, 66, 33, 66, 33, 66, 66, 135, 135, 135, 135, 66, 66, 33, 66, 135, 135, 66, 33, 33, 33, 135, 66, 66, 66, 66, 135, 66, 135, 33, 33, 66, 33, 135, 135, 33, 33, 66, 66, 66, 33, 135, 33, 135, 66, 33, 135, 135, 66, 66, 33, 33, 33, 135, 135, 135, 135, 135, 135, 135, 135, 33, 135, 33, 33, 135, 66, 135, 135, 66, 135, 33, 66, 135, 33, 135, 66, 33, 66, 66, 135, 135, 33, 33, 135, 33, 33, 33, 66, 33]
Prompts retrieved: 10029 . Total input tokens: 2210239 . Total output tokens: 1976283
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 0.718772497959435,
    "estimated_duration": 3598.361692686244,
    "input_throughput": 222.44011813122418,
    "output_throughput": 202.45769108778757,
    "total_throughput": 424.8978092190118,
    "itl": 20.6783603618671,
    "ttft": 3312.523093548758,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1368,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.033966898694562,
    "arrivals": 3297,
    "finished_requests": 3294,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.718869948759675. Arrivals time: 0.020790215581655502 Scheduler time: 0.32530564023181796 Scheduler overhead time: 0.1323158210143447 Adapter cache time: 0.03769936040043831 Engine time: 0.1356888278387487 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-32/adapters_128_slots_64_rate_0.0125-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-32/adapters_128_slots_64_rate_0.0125-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [42 43 43]
Adapter prompts. [135, 66, 135, 135, 33, 33, 135, 33, 66, 66, 66, 33, 135, 66, 33, 135, 66, 33, 33, 33, 33, 66, 66, 135, 66, 33, 66, 66, 66, 66, 135, 66, 33, 66, 33, 135, 135, 33, 66, 66, 33, 66, 33, 66, 66, 135, 135, 135, 135, 66, 66, 33, 66, 135, 135, 66, 33, 33, 33, 135, 66, 66, 66, 66, 135, 66, 135, 33, 33, 66, 33, 135, 135, 33, 33, 66, 66, 66, 33, 135, 33, 135, 66, 33, 135, 135, 66, 66, 33, 33, 33, 135, 135, 135, 135, 135, 135, 135, 135, 33, 135, 33, 33, 135, 66, 135, 135, 66, 135, 33, 66, 135, 33, 135, 66, 33, 66, 66, 135, 135, 33, 33, 135, 33, 33, 33, 66, 33]
Prompts retrieved: 10029 . Total input tokens: 2210239 . Total output tokens: 1976283
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 0.7204961283132434,
    "estimated_duration": 3598.373783700263,
    "input_throughput": 222.43937070287228,
    "output_throughput": 202.45701080304553,
    "total_throughput": 424.8963815059178,
    "itl": 20.680104160605268,
    "ttft": 3312.6722359509886,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1368,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.311572819105264,
    "arrivals": 3297,
    "finished_requests": 3294,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7205478730611503. Arrivals time: 0.021011290606111288 Scheduler time: 0.32626763731241226 Scheduler overhead time: 0.13263836642727256 Adapter cache time: 0.0376868243329227 Engine time: 0.13594794599339366 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-16/adapters_128_slots_64_rate_0.0125-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-16/adapters_128_slots_64_rate_0.0125-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [42 43 43]
Adapter prompts. [135, 66, 135, 135, 33, 33, 135, 33, 66, 66, 66, 33, 135, 66, 33, 135, 66, 33, 33, 33, 33, 66, 66, 135, 66, 33, 66, 66, 66, 66, 135, 66, 33, 66, 33, 135, 135, 33, 66, 66, 33, 66, 33, 66, 66, 135, 135, 135, 135, 66, 66, 33, 66, 135, 135, 66, 33, 33, 33, 135, 66, 66, 66, 66, 135, 66, 135, 33, 33, 66, 33, 135, 135, 33, 33, 66, 66, 66, 33, 135, 33, 135, 66, 33, 135, 135, 66, 66, 33, 33, 33, 135, 135, 135, 135, 135, 135, 135, 135, 33, 135, 33, 33, 135, 66, 135, 135, 66, 135, 33, 66, 135, 33, 135, 66, 33, 66, 66, 135, 135, 33, 33, 135, 33, 33, 33, 66, 33]
Prompts retrieved: 10029 . Total input tokens: 2210239 . Total output tokens: 1976283
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 0.719305703882128,
    "estimated_duration": 3598.3564108103287,
    "input_throughput": 222.44044464171077,
    "output_throughput": 202.45798826691058,
    "total_throughput": 424.8984329086214,
    "itl": 20.67470165408959,
    "ttft": 3312.407815365056,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1368,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.416208565570445,
    "arrivals": 3297,
    "finished_requests": 3294,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7193532679229975. Arrivals time: 0.02084489306434989 Scheduler time: 0.3248575930483639 Scheduler overhead time: 0.13178096618503332 Adapter cache time: 0.03767574019730091 Engine time: 0.13733177445828915 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-32/adapters_128_slots_64_rate_0.0125-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-32/adapters_128_slots_64_rate_0.0125-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [42 43 43]
Adapter prompts. [135, 66, 135, 135, 33, 33, 135, 33, 66, 66, 66, 33, 135, 66, 33, 135, 66, 33, 33, 33, 33, 66, 66, 135, 66, 33, 66, 66, 66, 66, 135, 66, 33, 66, 33, 135, 135, 33, 66, 66, 33, 66, 33, 66, 66, 135, 135, 135, 135, 66, 66, 33, 66, 135, 135, 66, 33, 33, 33, 135, 66, 66, 66, 66, 135, 66, 135, 33, 33, 66, 33, 135, 135, 33, 33, 66, 66, 66, 33, 135, 33, 135, 66, 33, 135, 135, 66, 66, 33, 33, 33, 135, 135, 135, 135, 135, 135, 135, 135, 33, 135, 33, 33, 135, 66, 135, 135, 66, 135, 33, 66, 135, 33, 135, 66, 33, 66, 66, 135, 135, 33, 33, 135, 33, 33, 33, 66, 33]
Prompts retrieved: 10029 . Total input tokens: 2210239 . Total output tokens: 1976283
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 0.7209213790483773,
    "estimated_duration": 3598.3695193585313,
    "input_throughput": 222.43963431045515,
    "output_throughput": 202.4572507300112,
    "total_throughput": 424.8968850404663,
    "itl": 20.678246719718146,
    "ttft": 3312.558008210574,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1368,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.219405675511723,
    "arrivals": 3297,
    "finished_requests": 3294,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7210111417807639. Arrivals time: 0.02084277104586363 Scheduler time: 0.32770500564947724 Scheduler overhead time: 0.13220741041004658 Adapter cache time: 0.03801549365743995 Engine time: 0.13503374392166734 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-16/adapters_128_slots_64_rate_0.0125-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-16/adapters_128_slots_64_rate_0.0125-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [42 43 43]
Adapter prompts. [135, 66, 135, 135, 33, 33, 135, 33, 66, 66, 66, 33, 135, 66, 33, 135, 66, 33, 33, 33, 33, 66, 66, 135, 66, 33, 66, 66, 66, 66, 135, 66, 33, 66, 33, 135, 135, 33, 66, 66, 33, 66, 33, 66, 66, 135, 135, 135, 135, 66, 66, 33, 66, 135, 135, 66, 33, 33, 33, 135, 66, 66, 66, 66, 135, 66, 135, 33, 33, 66, 33, 135, 135, 33, 33, 66, 66, 66, 33, 135, 33, 135, 66, 33, 135, 135, 66, 66, 33, 33, 33, 135, 135, 135, 135, 135, 135, 135, 135, 33, 135, 33, 33, 135, 66, 135, 135, 66, 135, 33, 66, 135, 33, 135, 66, 33, 66, 66, 135, 135, 33, 33, 135, 33, 33, 33, 66, 33]
Prompts retrieved: 10029 . Total input tokens: 2210239 . Total output tokens: 1976283
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 0.72335713962093,
    "estimated_duration": 3598.369687165531,
    "input_throughput": 222.43962393716643,
    "output_throughput": 202.45724128858444,
    "total_throughput": 424.8968652257509,
    "itl": 20.672553127054503,
    "ttft": 3312.192157528692,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1368,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.733203846700546,
    "arrivals": 3297,
    "finished_requests": 3294,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7234092499129474. Arrivals time: 0.020957372151315212 Scheduler time: 0.32849330734461546 Scheduler overhead time: 0.13249399652704597 Adapter cache time: 0.03761233435943723 Engine time: 0.1368424012325704 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-32/adapters_128_slots_64_rate_0.0125-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-32/adapters_128_slots_64_rate_0.0125-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [42 43 43]
Adapter prompts. [135, 66, 135, 135, 33, 33, 135, 33, 66, 66, 66, 33, 135, 66, 33, 135, 66, 33, 33, 33, 33, 66, 66, 135, 66, 33, 66, 66, 66, 66, 135, 66, 33, 66, 33, 135, 135, 33, 66, 66, 33, 66, 33, 66, 66, 135, 135, 135, 135, 66, 66, 33, 66, 135, 135, 66, 33, 33, 33, 135, 66, 66, 66, 66, 135, 66, 135, 33, 33, 66, 33, 135, 135, 33, 33, 66, 66, 66, 33, 135, 33, 135, 66, 33, 135, 135, 66, 66, 33, 33, 33, 135, 135, 135, 135, 135, 135, 135, 135, 33, 135, 33, 33, 135, 66, 135, 135, 66, 135, 33, 66, 135, 33, 135, 66, 33, 66, 66, 135, 135, 33, 33, 135, 33, 33, 33, 66, 33]
Prompts retrieved: 10029 . Total input tokens: 2210239 . Total output tokens: 1976283
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 0.7226133542135358,
    "estimated_duration": 3598.3651732793433,
    "input_throughput": 222.43990297142165,
    "output_throughput": 202.45749525640068,
    "total_throughput": 424.89739822782235,
    "itl": 20.678859686068385,
    "ttft": 3312.4420808995465,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1368,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.117504024617295,
    "arrivals": 3297,
    "finished_requests": 3294,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.722663929220289. Arrivals time: 0.021259179804474115 Scheduler time: 0.32814908120781183 Scheduler overhead time: 0.1317606852389872 Adapter cache time: 0.037892695516347885 Engine time: 0.13656697561964393 
