INFO 05-31 19:31:05 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 05-31 19:31:05 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-32/adapters_192_slots_96_rate_0.1-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-32/adapters_192_slots_96_rate_0.1-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [64 64 64]
Adapter prompts. [1080, 66, 1080, 66, 1080, 66, 1080, 66, 66, 66, 540, 540, 540, 540, 1080, 540, 66, 1080, 66, 540, 540, 66, 1080, 1080, 66, 540, 66, 540, 66, 66, 540, 66, 66, 540, 540, 1080, 540, 66, 540, 1080, 1080, 540, 1080, 66, 540, 540, 1080, 540, 66, 66, 540, 1080, 66, 540, 66, 1080, 1080, 540, 1080, 1080, 1080, 66, 540, 1080, 66, 540, 66, 540, 66, 66, 540, 1080, 1080, 66, 66, 66, 1080, 1080, 1080, 540, 66, 66, 66, 66, 66, 1080, 66, 540, 66, 1080, 1080, 66, 1080, 66, 540, 540, 1080, 66, 66, 66, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 540, 66, 1080, 540, 540, 540, 1080, 540, 66, 540, 1080, 1080, 540, 1080, 540, 66, 1080, 540, 66, 540, 540, 66, 540, 1080, 66, 540, 1080, 66, 540, 1080, 1080, 540, 66, 1080, 540, 66, 66, 540, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 540, 66, 1080, 1080, 540, 1080, 66, 1080, 1080, 1080, 66, 1080, 1080, 1080, 540, 540, 540, 540, 540, 540, 66, 1080, 540, 1080, 66, 1080, 540, 66, 540, 66, 66, 540, 540, 540, 1080, 540, 66, 66]
Prompts retrieved: 107904 . Total input tokens: 24063071 . Total output tokens: 21246663
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 2.783014782704413,
    "estimated_duration": 3600.0598490550888,
    "input_throughput": 2487.5814223895595,
    "output_throughput": 2156.6460907692517,
    "total_throughput": 4644.227513158811,
    "itl": 54.65535726304114,
    "ttft": 12122.991494988284,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10337,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 75.90828861827049,
    "arrivals": 36267,
    "finished_requests": 36146,
    "scheduler_time": 19.56798188580406
}
#Debug simulation 
Total elapsed time: 2.783131966833025. Arrivals time: 0.09135009255260229 Scheduler time: 2.3686437443830073 Scheduler overhead time: 0.06804645992815495 Adapter cache time: 0.152590814512223 Engine time: 0.06943823583424091 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-8/adapters_192_slots_96_rate_0.1-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-8/adapters_192_slots_96_rate_0.1-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [64 64 64]
Adapter prompts. [1080, 33, 1080, 33, 1080, 33, 1080, 33, 33, 33, 540, 540, 540, 540, 1080, 540, 33, 1080, 33, 540, 540, 33, 1080, 1080, 33, 540, 33, 540, 33, 33, 540, 33, 33, 540, 540, 1080, 540, 33, 540, 1080, 1080, 540, 1080, 33, 540, 540, 1080, 540, 33, 33, 540, 1080, 33, 540, 33, 1080, 1080, 540, 1080, 1080, 1080, 33, 540, 1080, 33, 540, 33, 540, 33, 33, 540, 1080, 1080, 33, 33, 33, 1080, 1080, 1080, 540, 33, 33, 33, 33, 33, 1080, 33, 540, 33, 1080, 1080, 33, 1080, 33, 540, 540, 1080, 33, 33, 33, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 540, 33, 1080, 540, 540, 540, 1080, 540, 33, 540, 1080, 1080, 540, 1080, 540, 33, 1080, 540, 33, 540, 540, 33, 540, 1080, 33, 540, 1080, 33, 540, 1080, 1080, 540, 33, 1080, 540, 33, 33, 540, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 540, 33, 1080, 1080, 540, 1080, 33, 1080, 1080, 1080, 33, 1080, 1080, 1080, 540, 540, 540, 540, 540, 540, 33, 1080, 540, 1080, 33, 1080, 540, 33, 540, 33, 33, 540, 540, 540, 1080, 540, 33, 33]
Prompts retrieved: 105792 . Total input tokens: 23602021 . Total output tokens: 20831043
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 2.7828271626494825,
    "estimated_duration": 3600.0284401732247,
    "input_throughput": 2451.330078818869,
    "output_throughput": 2106.4764142905233,
    "total_throughput": 4557.806493109392,
    "itl": 50.95743706891655,
    "ttft": 12660.490408962927,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9074,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 60.000999555918824,
    "arrivals": 35501,
    "finished_requests": 35377,
    "scheduler_time": 17.999226056513294
}
#Debug simulation 
Total elapsed time: 2.782932471949607. Arrivals time: 0.09191224258393049 Scheduler time: 2.359375406522304 Scheduler overhead time: 0.07271942449733615 Adapter cache time: 0.15165519248694181 Engine time: 0.0721391518600285 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-16/adapters_192_slots_96_rate_0.1-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-16/adapters_192_slots_96_rate_0.1-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [64 64 64]
Adapter prompts. [1080, 33, 1080, 33, 1080, 33, 1080, 33, 33, 33, 540, 540, 540, 540, 1080, 540, 33, 1080, 33, 540, 540, 33, 1080, 1080, 33, 540, 33, 540, 33, 33, 540, 33, 33, 540, 540, 1080, 540, 33, 540, 1080, 1080, 540, 1080, 33, 540, 540, 1080, 540, 33, 33, 540, 1080, 33, 540, 33, 1080, 1080, 540, 1080, 1080, 1080, 33, 540, 1080, 33, 540, 33, 540, 33, 33, 540, 1080, 1080, 33, 33, 33, 1080, 1080, 1080, 540, 33, 33, 33, 33, 33, 1080, 33, 540, 33, 1080, 1080, 33, 1080, 33, 540, 540, 1080, 33, 33, 33, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 540, 33, 1080, 540, 540, 540, 1080, 540, 33, 540, 1080, 1080, 540, 1080, 540, 33, 1080, 540, 33, 540, 540, 33, 540, 1080, 33, 540, 1080, 33, 540, 1080, 1080, 540, 33, 1080, 540, 33, 33, 540, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 540, 33, 1080, 1080, 540, 1080, 33, 1080, 1080, 1080, 33, 1080, 1080, 1080, 540, 540, 540, 540, 540, 540, 33, 1080, 540, 1080, 33, 1080, 540, 33, 540, 33, 33, 540, 540, 540, 1080, 540, 33, 33]
Prompts retrieved: 105792 . Total input tokens: 23602021 . Total output tokens: 20831043
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 2.7394393370486796,
    "estimated_duration": 3600.0209362187165,
    "input_throughput": 2451.335188419541,
    "output_throughput": 2106.4808050714287,
    "total_throughput": 4557.81599349097,
    "itl": 51.1749890636532,
    "ttft": 12661.162358326636,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9075,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 66.13846848795521,
    "arrivals": 35501,
    "finished_requests": 35377,
    "scheduler_time": 18.052703898183346
}
#Debug simulation 
Total elapsed time: 2.7395071922801435. Arrivals time: 0.08793152356520295 Scheduler time: 2.316161684691906 Scheduler overhead time: 0.07110003754496574 Adapter cache time: 0.15529840160161257 Engine time: 0.0727030704729259 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-32/adapters_192_slots_96_rate_0.1-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-32/adapters_192_slots_96_rate_0.1-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [64 64 64]
Adapter prompts. [1080, 33, 1080, 33, 1080, 33, 1080, 33, 33, 33, 540, 540, 540, 540, 1080, 540, 33, 1080, 33, 540, 540, 33, 1080, 1080, 33, 540, 33, 540, 33, 33, 540, 33, 33, 540, 540, 1080, 540, 33, 540, 1080, 1080, 540, 1080, 33, 540, 540, 1080, 540, 33, 33, 540, 1080, 33, 540, 33, 1080, 1080, 540, 1080, 1080, 1080, 33, 540, 1080, 33, 540, 33, 540, 33, 33, 540, 1080, 1080, 33, 33, 33, 1080, 1080, 1080, 540, 33, 33, 33, 33, 33, 1080, 33, 540, 33, 1080, 1080, 33, 1080, 33, 540, 540, 1080, 33, 33, 33, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 540, 33, 1080, 540, 540, 540, 1080, 540, 33, 540, 1080, 1080, 540, 1080, 540, 33, 1080, 540, 33, 540, 540, 33, 540, 1080, 33, 540, 1080, 33, 540, 1080, 1080, 540, 33, 1080, 540, 33, 33, 540, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 540, 33, 1080, 1080, 540, 1080, 33, 1080, 1080, 1080, 33, 1080, 1080, 1080, 540, 540, 540, 540, 540, 540, 33, 1080, 540, 1080, 33, 1080, 540, 33, 540, 33, 33, 540, 540, 540, 1080, 540, 33, 33]
Prompts retrieved: 105792 . Total input tokens: 23602021 . Total output tokens: 20831043
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 2.7514695753343403,
    "estimated_duration": 3600.0111974730617,
    "input_throughput": 2451.3418197683354,
    "output_throughput": 2106.4865035205894,
    "total_throughput": 4557.828323288925,
    "itl": 51.237299494295435,
    "ttft": 12661.42705627342,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9069,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 67.83353718688399,
    "arrivals": 35501,
    "finished_requests": 35377,
    "scheduler_time": 18.06750592985124
}
#Debug simulation 
Total elapsed time: 2.7515672333538532. Arrivals time: 0.09521014709025621 Scheduler time: 2.325821017380804 Scheduler overhead time: 0.07211924903094769 Adapter cache time: 0.15173904690891504 Engine time: 0.07167765870690346 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-16/adapters_192_slots_96_rate_0.1-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-16/adapters_192_slots_96_rate_0.1-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [64 64 64]
Adapter prompts. [1080, 33, 1080, 33, 1080, 33, 1080, 33, 33, 33, 540, 540, 540, 540, 1080, 540, 33, 1080, 33, 540, 540, 33, 1080, 1080, 33, 540, 33, 540, 33, 33, 540, 33, 33, 540, 540, 1080, 540, 33, 540, 1080, 1080, 540, 1080, 33, 540, 540, 1080, 540, 33, 33, 540, 1080, 33, 540, 33, 1080, 1080, 540, 1080, 1080, 1080, 33, 540, 1080, 33, 540, 33, 540, 33, 33, 540, 1080, 1080, 33, 33, 33, 1080, 1080, 1080, 540, 33, 33, 33, 33, 33, 1080, 33, 540, 33, 1080, 1080, 33, 1080, 33, 540, 540, 1080, 33, 33, 33, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 540, 33, 1080, 540, 540, 540, 1080, 540, 33, 540, 1080, 1080, 540, 1080, 540, 33, 1080, 540, 33, 540, 540, 33, 540, 1080, 33, 540, 1080, 33, 540, 1080, 1080, 540, 33, 1080, 540, 33, 33, 540, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 540, 33, 1080, 1080, 540, 1080, 33, 1080, 1080, 1080, 33, 1080, 1080, 1080, 540, 540, 540, 540, 540, 540, 33, 1080, 540, 1080, 33, 1080, 540, 33, 540, 33, 33, 540, 540, 540, 1080, 540, 33, 33]
Prompts retrieved: 105792 . Total input tokens: 23602021 . Total output tokens: 20831043
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 2.762790886685252,
    "estimated_duration": 3600.003946258441,
    "input_throughput": 2451.3467573200464,
    "output_throughput": 2106.49074645642,
    "total_throughput": 4557.837503776466,
    "itl": 51.02991052929536,
    "ttft": 12559.78979383061,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9072,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 61.97270067785177,
    "arrivals": 35501,
    "finished_requests": 35377,
    "scheduler_time": 18.01638401365827
}
#Debug simulation 
Total elapsed time: 2.762860754970461. Arrivals time: 0.08924105344340205 Scheduler time: 2.3415970131754875 Scheduler overhead time: 0.0722598391585052 Adapter cache time: 0.15248524583876133 Engine time: 0.07242453936487436 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-32/adapters_192_slots_96_rate_0.1-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-32/adapters_192_slots_96_rate_0.1-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [64 64 64]
Adapter prompts. [1080, 33, 1080, 33, 1080, 33, 1080, 33, 33, 33, 540, 540, 540, 540, 1080, 540, 33, 1080, 33, 540, 540, 33, 1080, 1080, 33, 540, 33, 540, 33, 33, 540, 33, 33, 540, 540, 1080, 540, 33, 540, 1080, 1080, 540, 1080, 33, 540, 540, 1080, 540, 33, 33, 540, 1080, 33, 540, 33, 1080, 1080, 540, 1080, 1080, 1080, 33, 540, 1080, 33, 540, 33, 540, 33, 33, 540, 1080, 1080, 33, 33, 33, 1080, 1080, 1080, 540, 33, 33, 33, 33, 33, 1080, 33, 540, 33, 1080, 1080, 33, 1080, 33, 540, 540, 1080, 33, 33, 33, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 540, 33, 1080, 540, 540, 540, 1080, 540, 33, 540, 1080, 1080, 540, 1080, 540, 33, 1080, 540, 33, 540, 540, 33, 540, 1080, 33, 540, 1080, 33, 540, 1080, 1080, 540, 33, 1080, 540, 33, 33, 540, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 540, 33, 1080, 1080, 540, 1080, 33, 1080, 1080, 1080, 33, 1080, 1080, 1080, 540, 540, 540, 540, 540, 540, 33, 1080, 540, 1080, 33, 1080, 540, 33, 540, 33, 33, 540, 540, 540, 1080, 540, 33, 33]
Prompts retrieved: 105792 . Total input tokens: 23602021 . Total output tokens: 20831043
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 2.7594083780422807,
    "estimated_duration": 3600.047771931222,
    "input_throughput": 2451.316915515808,
    "output_throughput": 2106.465102803885,
    "total_throughput": 4557.782018319694,
    "itl": 51.211911031934,
    "ttft": 12661.429758816641,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9068,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 67.2099607335928,
    "arrivals": 35501,
    "finished_requests": 35377,
    "scheduler_time": 18.06236792013549
}
#Debug simulation 
Total elapsed time: 2.759496937971562. Arrivals time: 0.09201388899236917 Scheduler time: 2.332124167121947 Scheduler overhead time: 0.07193907164037228 Adapter cache time: 0.1557497875764966 Engine time: 0.07263041427358985 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-16/adapters_192_slots_96_rate_0.1-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-16/adapters_192_slots_96_rate_0.1-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [64 64 64]
Adapter prompts. [1080, 33, 1080, 33, 1080, 33, 1080, 33, 33, 33, 540, 540, 540, 540, 1080, 540, 33, 1080, 33, 540, 540, 33, 1080, 1080, 33, 540, 33, 540, 33, 33, 540, 33, 33, 540, 540, 1080, 540, 33, 540, 1080, 1080, 540, 1080, 33, 540, 540, 1080, 540, 33, 33, 540, 1080, 33, 540, 33, 1080, 1080, 540, 1080, 1080, 1080, 33, 540, 1080, 33, 540, 33, 540, 33, 33, 540, 1080, 1080, 33, 33, 33, 1080, 1080, 1080, 540, 33, 33, 33, 33, 33, 1080, 33, 540, 33, 1080, 1080, 33, 1080, 33, 540, 540, 1080, 33, 33, 33, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 540, 33, 1080, 540, 540, 540, 1080, 540, 33, 540, 1080, 1080, 540, 1080, 540, 33, 1080, 540, 33, 540, 540, 33, 540, 1080, 33, 540, 1080, 33, 540, 1080, 1080, 540, 33, 1080, 540, 33, 33, 540, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 540, 33, 1080, 1080, 540, 1080, 33, 1080, 1080, 1080, 33, 1080, 1080, 1080, 540, 540, 540, 540, 540, 540, 33, 1080, 540, 1080, 33, 1080, 540, 33, 540, 33, 33, 540, 540, 540, 1080, 540, 33, 33]
Prompts retrieved: 105792 . Total input tokens: 23602021 . Total output tokens: 20831043
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 2.783504187129438,
    "estimated_duration": 3600.0065185314074,
    "input_throughput": 2451.3450057862747,
    "output_throughput": 2106.489241328811,
    "total_throughput": 4557.834247115086,
    "itl": 50.885919862254674,
    "ttft": 12559.400784482614,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9074,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 57.92769861474364,
    "arrivals": 35501,
    "finished_requests": 35377,
    "scheduler_time": 17.98102364376642
}
#Debug simulation 
Total elapsed time: 2.783614296000451. Arrivals time: 0.08991361688822508 Scheduler time: 2.3576645785942674 Scheduler overhead time: 0.07221654709428549 Adapter cache time: 0.15700928447768092 Engine time: 0.07190318033099174 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-32/adapters_192_slots_96_rate_0.1-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-32/adapters_192_slots_96_rate_0.1-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [64 64 64]
Adapter prompts. [1080, 33, 1080, 33, 1080, 33, 1080, 33, 33, 33, 540, 540, 540, 540, 1080, 540, 33, 1080, 33, 540, 540, 33, 1080, 1080, 33, 540, 33, 540, 33, 33, 540, 33, 33, 540, 540, 1080, 540, 33, 540, 1080, 1080, 540, 1080, 33, 540, 540, 1080, 540, 33, 33, 540, 1080, 33, 540, 33, 1080, 1080, 540, 1080, 1080, 1080, 33, 540, 1080, 33, 540, 33, 540, 33, 33, 540, 1080, 1080, 33, 33, 33, 1080, 1080, 1080, 540, 33, 33, 33, 33, 33, 1080, 33, 540, 33, 1080, 1080, 33, 1080, 33, 540, 540, 1080, 33, 33, 33, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 540, 33, 1080, 540, 540, 540, 1080, 540, 33, 540, 1080, 1080, 540, 1080, 540, 33, 1080, 540, 33, 540, 540, 33, 540, 1080, 33, 540, 1080, 33, 540, 1080, 1080, 540, 33, 1080, 540, 33, 33, 540, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 540, 33, 1080, 1080, 540, 1080, 33, 1080, 1080, 1080, 33, 1080, 1080, 1080, 540, 540, 540, 540, 540, 540, 33, 1080, 540, 1080, 33, 1080, 540, 33, 540, 33, 33, 540, 540, 540, 1080, 540, 33, 33]
Prompts retrieved: 105792 . Total input tokens: 23602021 . Total output tokens: 20831043
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 2.7865982558578253,
    "estimated_duration": 3600.0153897728096,
    "input_throughput": 2451.3389651250686,
    "output_throughput": 2106.4840504691765,
    "total_throughput": 4557.823015594246,
    "itl": 51.19146179667927,
    "ttft": 12661.256100003813,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9071,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 66.62645528854429,
    "arrivals": 35501,
    "finished_requests": 35377,
    "scheduler_time": 18.056961191985575
}
#Debug simulation 
Total elapsed time: 2.786763709038496. Arrivals time: 0.09245771775022149 Scheduler time: 2.3588136029429734 Scheduler overhead time: 0.07179156364873052 Adapter cache time: 0.15615339437499642 Engine time: 0.07291050674393773 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-8/adapters_192_slots_96_rate_0.1-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-8/adapters_192_slots_96_rate_0.1-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [64 64 64]
Adapter prompts. [1080, 135, 1080, 135, 1080, 135, 1080, 135, 135, 135, 270, 270, 270, 270, 1080, 270, 135, 1080, 135, 270, 270, 135, 1080, 1080, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 1080, 270, 135, 270, 1080, 1080, 270, 1080, 135, 270, 270, 1080, 270, 135, 135, 270, 1080, 135, 270, 135, 1080, 1080, 270, 1080, 1080, 1080, 135, 270, 1080, 135, 270, 135, 270, 135, 135, 270, 1080, 1080, 135, 135, 135, 1080, 1080, 1080, 270, 135, 135, 135, 135, 135, 1080, 135, 270, 135, 1080, 1080, 135, 1080, 135, 270, 270, 1080, 135, 135, 135, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 270, 135, 1080, 270, 270, 270, 1080, 270, 135, 270, 1080, 1080, 270, 1080, 270, 135, 1080, 270, 135, 270, 270, 135, 270, 1080, 135, 270, 1080, 135, 270, 1080, 1080, 270, 135, 1080, 270, 135, 135, 270, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 270, 135, 1080, 1080, 270, 1080, 135, 1080, 1080, 1080, 135, 1080, 1080, 1080, 270, 270, 270, 270, 270, 270, 135, 1080, 270, 1080, 135, 1080, 270, 135, 270, 135, 135, 270, 270, 270, 1080, 270, 135, 135]
Prompts retrieved: 95040 . Total input tokens: 21194895 . Total output tokens: 18691204
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 2.584243359044194,
    "estimated_duration": 3600.002371298073,
    "input_throughput": 2171.6641250936236,
    "output_throughput": 1921.4629010107572,
    "total_throughput": 4093.127026104381,
    "itl": 44.59406804737932,
    "ttft": 13409.4934300178,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8549,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 56.52948481414406,
    "arrivals": 31858,
    "finished_requests": 31740,
    "scheduler_time": 13.422989372451175
}
#Debug simulation 
Total elapsed time: 2.5843505612574518. Arrivals time: 0.0844517108052969 Scheduler time: 2.1439623688347638 Scheduler overhead time: 0.07893959945067763 Adapter cache time: 0.15836636302992702 Engine time: 0.08032531384378672 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-16/adapters_192_slots_96_rate_0.1-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-16/adapters_192_slots_96_rate_0.1-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [64 64 64]
Adapter prompts. [1080, 135, 1080, 135, 1080, 135, 1080, 135, 135, 135, 270, 270, 270, 270, 1080, 270, 135, 1080, 135, 270, 270, 135, 1080, 1080, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 1080, 270, 135, 270, 1080, 1080, 270, 1080, 135, 270, 270, 1080, 270, 135, 135, 270, 1080, 135, 270, 135, 1080, 1080, 270, 1080, 1080, 1080, 135, 270, 1080, 135, 270, 135, 270, 135, 135, 270, 1080, 1080, 135, 135, 135, 1080, 1080, 1080, 270, 135, 135, 135, 135, 135, 1080, 135, 270, 135, 1080, 1080, 135, 1080, 135, 270, 270, 1080, 135, 135, 135, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 270, 135, 1080, 270, 270, 270, 1080, 270, 135, 270, 1080, 1080, 270, 1080, 270, 135, 1080, 270, 135, 270, 270, 135, 270, 1080, 135, 270, 1080, 135, 270, 1080, 1080, 270, 135, 1080, 270, 135, 135, 270, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 270, 135, 1080, 1080, 270, 1080, 135, 1080, 1080, 1080, 135, 1080, 1080, 1080, 270, 270, 270, 270, 270, 270, 135, 1080, 270, 1080, 135, 1080, 270, 135, 270, 135, 135, 270, 270, 270, 1080, 270, 135, 135]
Prompts retrieved: 95040 . Total input tokens: 21194895 . Total output tokens: 18691204
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 2.5964000737294555,
    "estimated_duration": 3599.9928016353056,
    "input_throughput": 2171.589897748903,
    "output_throughput": 1921.4416197881994,
    "total_throughput": 4093.0315175371024,
    "itl": 44.76024174286154,
    "ttft": 13522.837204733336,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8549,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 62.46401169129907,
    "arrivals": 31858,
    "finished_requests": 31739,
    "scheduler_time": 13.4757892528134
}
#Debug simulation 
Total elapsed time: 2.59648643899709. Arrivals time: 0.0842323019169271 Scheduler time: 2.1578016844578087 Scheduler overhead time: 0.07958610961213708 Adapter cache time: 0.15740270167589188 Engine time: 0.07919040927663445 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-32/adapters_192_slots_96_rate_0.1-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-32/adapters_192_slots_96_rate_0.1-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [64 64 64]
Adapter prompts. [1080, 135, 1080, 135, 1080, 135, 1080, 135, 135, 135, 270, 270, 270, 270, 1080, 270, 135, 1080, 135, 270, 270, 135, 1080, 1080, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 1080, 270, 135, 270, 1080, 1080, 270, 1080, 135, 270, 270, 1080, 270, 135, 135, 270, 1080, 135, 270, 135, 1080, 1080, 270, 1080, 1080, 1080, 135, 270, 1080, 135, 270, 135, 270, 135, 135, 270, 1080, 1080, 135, 135, 135, 1080, 1080, 1080, 270, 135, 135, 135, 135, 135, 1080, 135, 270, 135, 1080, 1080, 135, 1080, 135, 270, 270, 1080, 135, 135, 135, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 270, 135, 1080, 270, 270, 270, 1080, 270, 135, 270, 1080, 1080, 270, 1080, 270, 135, 1080, 270, 135, 270, 270, 135, 270, 1080, 135, 270, 1080, 135, 270, 1080, 1080, 270, 135, 1080, 270, 135, 135, 270, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 270, 135, 1080, 1080, 270, 1080, 135, 1080, 1080, 1080, 135, 1080, 1080, 1080, 270, 270, 270, 270, 270, 270, 135, 1080, 270, 1080, 135, 1080, 270, 135, 270, 135, 135, 270, 270, 270, 1080, 270, 135, 135]
Prompts retrieved: 95040 . Total input tokens: 21194895 . Total output tokens: 18691204
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 2.6042652120813727,
    "estimated_duration": 3599.991094064022,
    "input_throughput": 2171.4956497781204,
    "output_throughput": 1921.3114197434716,
    "total_throughput": 4092.807069521592,
    "itl": 44.81094307982168,
    "ttft": 13635.962210986945,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8552,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 64.17084917107576,
    "arrivals": 31858,
    "finished_requests": 31738,
    "scheduler_time": 13.490956208133671
}
#Debug simulation 
Total elapsed time: 2.6043560951948166. Arrivals time: 0.08451368100941181 Scheduler time: 2.1668358533643186 Scheduler overhead time: 0.07902311254292727 Adapter cache time: 0.1574945282191038 Engine time: 0.07829462178051472 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-16/adapters_192_slots_96_rate_0.1-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-16/adapters_192_slots_96_rate_0.1-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [64 64 64]
Adapter prompts. [1080, 135, 1080, 135, 1080, 135, 1080, 135, 135, 135, 270, 270, 270, 270, 1080, 270, 135, 1080, 135, 270, 270, 135, 1080, 1080, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 1080, 270, 135, 270, 1080, 1080, 270, 1080, 135, 270, 270, 1080, 270, 135, 135, 270, 1080, 135, 270, 135, 1080, 1080, 270, 1080, 1080, 1080, 135, 270, 1080, 135, 270, 135, 270, 135, 135, 270, 1080, 1080, 135, 135, 135, 1080, 1080, 1080, 270, 135, 135, 135, 135, 135, 1080, 135, 270, 135, 1080, 1080, 135, 1080, 135, 270, 270, 1080, 135, 135, 135, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 270, 135, 1080, 270, 270, 270, 1080, 270, 135, 270, 1080, 1080, 270, 1080, 270, 135, 1080, 270, 135, 270, 270, 135, 270, 1080, 135, 270, 1080, 135, 270, 1080, 1080, 270, 135, 1080, 270, 135, 135, 270, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 270, 135, 1080, 1080, 270, 1080, 135, 1080, 1080, 1080, 135, 1080, 1080, 1080, 270, 270, 270, 270, 270, 270, 135, 1080, 270, 1080, 135, 1080, 270, 135, 270, 135, 135, 270, 270, 270, 1080, 270, 135, 135]
Prompts retrieved: 95040 . Total input tokens: 21194895 . Total output tokens: 18691204
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 2.588630656711757,
    "estimated_duration": 3599.99928018352,
    "input_throughput": 2171.665989778047,
    "output_throughput": 1921.4645508616247,
    "total_throughput": 4093.1305406396714,
    "itl": 44.654273634233284,
    "ttft": 13409.694308207516,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8555,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 58.579202746364544,
    "arrivals": 31858,
    "finished_requests": 31740,
    "scheduler_time": 13.441125675493607
}
#Debug simulation 
Total elapsed time: 2.58871957892552. Arrivals time: 0.0871099391952157 Scheduler time: 2.1470127035863698 Scheduler overhead time: 0.07982728770002723 Adapter cache time: 0.15704599069431424 Engine time: 0.07932351808995008 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-32/adapters_192_slots_96_rate_0.1-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-32/adapters_192_slots_96_rate_0.1-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [64 64 64]
Adapter prompts. [1080, 135, 1080, 135, 1080, 135, 1080, 135, 135, 135, 270, 270, 270, 270, 1080, 270, 135, 1080, 135, 270, 270, 135, 1080, 1080, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 1080, 270, 135, 270, 1080, 1080, 270, 1080, 135, 270, 270, 1080, 270, 135, 135, 270, 1080, 135, 270, 135, 1080, 1080, 270, 1080, 1080, 1080, 135, 270, 1080, 135, 270, 135, 270, 135, 135, 270, 1080, 1080, 135, 135, 135, 1080, 1080, 1080, 270, 135, 135, 135, 135, 135, 1080, 135, 270, 135, 1080, 1080, 135, 1080, 135, 270, 270, 1080, 135, 135, 135, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 270, 135, 1080, 270, 270, 270, 1080, 270, 135, 270, 1080, 1080, 270, 1080, 270, 135, 1080, 270, 135, 270, 270, 135, 270, 1080, 135, 270, 1080, 135, 270, 1080, 1080, 270, 135, 1080, 270, 135, 135, 270, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 270, 135, 1080, 1080, 270, 1080, 135, 1080, 1080, 1080, 135, 1080, 1080, 1080, 270, 270, 270, 270, 270, 270, 135, 1080, 270, 1080, 135, 1080, 270, 135, 270, 135, 135, 270, 270, 270, 1080, 270, 135, 135]
Prompts retrieved: 95040 . Total input tokens: 21194895 . Total output tokens: 18691204
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 2.580718664918095,
    "estimated_duration": 3599.992871351524,
    "input_throughput": 2171.494577728198,
    "output_throughput": 1921.3104712074894,
    "total_throughput": 4092.8050489356874,
    "itl": 44.79387028190253,
    "ttft": 13635.910985572193,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8554,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 63.59935801878546,
    "arrivals": 31858,
    "finished_requests": 31738,
    "scheduler_time": 13.485925833394676
}
#Debug simulation 
Total elapsed time: 2.580788442865014. Arrivals time: 0.08329221932217479 Scheduler time: 2.1419231523759663 Scheduler overhead time: 0.0788818090222776 Adapter cache time: 0.15834268182516098 Engine time: 0.08028679387643933 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-16/adapters_192_slots_96_rate_0.1-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-16/adapters_192_slots_96_rate_0.1-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [64 64 64]
Adapter prompts. [1080, 135, 1080, 135, 1080, 135, 1080, 135, 135, 135, 270, 270, 270, 270, 1080, 270, 135, 1080, 135, 270, 270, 135, 1080, 1080, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 1080, 270, 135, 270, 1080, 1080, 270, 1080, 135, 270, 270, 1080, 270, 135, 135, 270, 1080, 135, 270, 135, 1080, 1080, 270, 1080, 1080, 1080, 135, 270, 1080, 135, 270, 135, 270, 135, 135, 270, 1080, 1080, 135, 135, 135, 1080, 1080, 1080, 270, 135, 135, 135, 135, 135, 1080, 135, 270, 135, 1080, 1080, 135, 1080, 135, 270, 270, 1080, 135, 135, 135, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 270, 135, 1080, 270, 270, 270, 1080, 270, 135, 270, 1080, 1080, 270, 1080, 270, 135, 1080, 270, 135, 270, 270, 135, 270, 1080, 135, 270, 1080, 135, 270, 1080, 1080, 270, 135, 1080, 270, 135, 135, 270, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 270, 135, 1080, 1080, 270, 1080, 135, 1080, 1080, 1080, 135, 1080, 1080, 1080, 270, 270, 270, 270, 270, 270, 135, 1080, 270, 1080, 135, 1080, 270, 135, 270, 135, 135, 270, 270, 270, 1080, 270, 135, 135]
Prompts retrieved: 95040 . Total input tokens: 21194895 . Total output tokens: 18691204
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 2.5834753392264247,
    "estimated_duration": 3600.0128406429285,
    "input_throughput": 2171.6594762489176,
    "output_throughput": 1921.5689793941315,
    "total_throughput": 4093.228455643049,
    "itl": 44.54218083711952,
    "ttft": 13296.314008298968,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8554,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 54.60805972564652,
    "arrivals": 31858,
    "finished_requests": 31741,
    "scheduler_time": 13.405738943510915
}
#Debug simulation 
Total elapsed time: 2.5835679131560028. Arrivals time: 0.08611020538955927 Scheduler time: 2.1432775035500526 Scheduler overhead time: 0.07929271878674626 Adapter cache time: 0.15820370987057686 Engine time: 0.07843632763251662 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-32/adapters_192_slots_96_rate_0.1-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-32/adapters_192_slots_96_rate_0.1-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [64 64 64]
Adapter prompts. [1080, 135, 1080, 135, 1080, 135, 1080, 135, 135, 135, 270, 270, 270, 270, 1080, 270, 135, 1080, 135, 270, 270, 135, 1080, 1080, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 1080, 270, 135, 270, 1080, 1080, 270, 1080, 135, 270, 270, 1080, 270, 135, 135, 270, 1080, 135, 270, 135, 1080, 1080, 270, 1080, 1080, 1080, 135, 270, 1080, 135, 270, 135, 270, 135, 135, 270, 1080, 1080, 135, 135, 135, 1080, 1080, 1080, 270, 135, 135, 135, 135, 135, 1080, 135, 270, 135, 1080, 1080, 135, 1080, 135, 270, 270, 1080, 135, 135, 135, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 270, 135, 1080, 270, 270, 270, 1080, 270, 135, 270, 1080, 1080, 270, 1080, 270, 135, 1080, 270, 135, 270, 270, 135, 270, 1080, 135, 270, 1080, 135, 270, 1080, 1080, 270, 135, 1080, 270, 135, 135, 270, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 270, 135, 1080, 1080, 270, 1080, 135, 1080, 1080, 1080, 135, 1080, 1080, 1080, 270, 270, 270, 270, 270, 270, 135, 1080, 270, 1080, 135, 1080, 270, 135, 270, 135, 135, 270, 270, 270, 1080, 270, 135, 135]
Prompts retrieved: 95040 . Total input tokens: 21194895 . Total output tokens: 18691204
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 2.6155898300930858,
    "estimated_duration": 3600.014298178957,
    "input_throughput": 2171.65693035016,
    "output_throughput": 1921.4565351862784,
    "total_throughput": 4093.1134655364385,
    "itl": 44.77558589162104,
    "ttft": 13410.047034276371,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8552,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 62.988468720014026,
    "arrivals": 31858,
    "finished_requests": 31740,
    "scheduler_time": 13.480687816858879
}
#Debug simulation 
Total elapsed time: 2.61566232284531. Arrivals time: 0.08302543964236975 Scheduler time: 2.177268436178565 Scheduler overhead time: 0.07939904183149338 Adapter cache time: 0.1574516068212688 Engine time: 0.0803406904451549 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-8/adapters_192_slots_96_rate_0.1-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-8/adapters_192_slots_96_rate_0.1-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [64 64 64]
Adapter prompts. [1080, 66, 1080, 66, 1080, 66, 1080, 66, 66, 66, 270, 270, 270, 270, 1080, 270, 66, 1080, 66, 270, 270, 66, 1080, 1080, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 1080, 270, 66, 270, 1080, 1080, 270, 1080, 66, 270, 270, 1080, 270, 66, 66, 270, 1080, 66, 270, 66, 1080, 1080, 270, 1080, 1080, 1080, 66, 270, 1080, 66, 270, 66, 270, 66, 66, 270, 1080, 1080, 66, 66, 66, 1080, 1080, 1080, 270, 66, 66, 66, 66, 66, 1080, 66, 270, 66, 1080, 1080, 66, 1080, 66, 270, 270, 1080, 66, 66, 66, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 270, 66, 1080, 270, 270, 270, 1080, 270, 66, 270, 1080, 1080, 270, 1080, 270, 66, 1080, 270, 66, 270, 270, 66, 270, 1080, 66, 270, 1080, 66, 270, 1080, 1080, 270, 66, 1080, 270, 66, 66, 270, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 270, 66, 1080, 1080, 270, 1080, 66, 1080, 1080, 1080, 66, 1080, 1080, 1080, 270, 270, 270, 270, 270, 270, 66, 1080, 270, 1080, 66, 1080, 270, 66, 270, 66, 66, 270, 270, 270, 1080, 270, 66, 66]
Prompts retrieved: 90624 . Total input tokens: 20192551 . Total output tokens: 17811724
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 2.4747059550136328,
    "estimated_duration": 3600.0149003017323,
    "input_throughput": 2073.8514163855966,
    "output_throughput": 1816.5272036657113,
    "total_throughput": 3890.3786200513077,
    "itl": 40.637581036859785,
    "ttft": 11672.793896472058,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6465,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 42.74922439155625,
    "arrivals": 30402,
    "finished_requests": 30304,
    "scheduler_time": 10.527424134864978
}
#Debug simulation 
Total elapsed time: 2.4748534839600325. Arrivals time: 0.08417937438935041 Scheduler time: 2.0308753070421517 Scheduler overhead time: 0.08552931668236852 Adapter cache time: 0.14884027279913425 Engine time: 0.08429062180221081 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-16/adapters_192_slots_96_rate_0.1-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-16/adapters_192_slots_96_rate_0.1-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [64 64 64]
Adapter prompts. [1080, 66, 1080, 66, 1080, 66, 1080, 66, 66, 66, 270, 270, 270, 270, 1080, 270, 66, 1080, 66, 270, 270, 66, 1080, 1080, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 1080, 270, 66, 270, 1080, 1080, 270, 1080, 66, 270, 270, 1080, 270, 66, 66, 270, 1080, 66, 270, 66, 1080, 1080, 270, 1080, 1080, 1080, 66, 270, 1080, 66, 270, 66, 270, 66, 66, 270, 1080, 1080, 66, 66, 66, 1080, 1080, 1080, 270, 66, 66, 66, 66, 66, 1080, 66, 270, 66, 1080, 1080, 66, 1080, 66, 270, 270, 1080, 66, 66, 66, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 270, 66, 1080, 270, 270, 270, 1080, 270, 66, 270, 1080, 1080, 270, 1080, 270, 66, 1080, 270, 66, 270, 270, 66, 270, 1080, 66, 270, 1080, 66, 270, 1080, 1080, 270, 66, 1080, 270, 66, 66, 270, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 270, 66, 1080, 1080, 270, 1080, 66, 1080, 1080, 1080, 66, 1080, 1080, 1080, 270, 270, 270, 270, 270, 270, 66, 1080, 270, 1080, 66, 1080, 270, 66, 270, 66, 66, 270, 270, 270, 1080, 270, 66, 66]
Prompts retrieved: 90624 . Total input tokens: 20192551 . Total output tokens: 17811724
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 2.480123361106962,
    "estimated_duration": 3599.9906889532363,
    "input_throughput": 2073.8653638492733,
    "output_throughput": 1816.5394205231923,
    "total_throughput": 3890.4047843724657,
    "itl": 40.742922678203385,
    "ttft": 11673.21585513791,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6467,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 47.16809720756811,
    "arrivals": 30402,
    "finished_requests": 30304,
    "scheduler_time": 10.566652225134938
}
#Debug simulation 
Total elapsed time: 2.4801957001909614. Arrivals time: 0.08132121292874217 Scheduler time: 2.0297017926350236 Scheduler overhead time: 0.08575089136138558 Adapter cache time: 0.150725819170475 Engine time: 0.09167997259646654 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-32/adapters_192_slots_96_rate_0.1-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-32/adapters_192_slots_96_rate_0.1-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [64 64 64]
Adapter prompts. [1080, 66, 1080, 66, 1080, 66, 1080, 66, 66, 66, 270, 270, 270, 270, 1080, 270, 66, 1080, 66, 270, 270, 66, 1080, 1080, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 1080, 270, 66, 270, 1080, 1080, 270, 1080, 66, 270, 270, 1080, 270, 66, 66, 270, 1080, 66, 270, 66, 1080, 1080, 270, 1080, 1080, 1080, 66, 270, 1080, 66, 270, 66, 270, 66, 66, 270, 1080, 1080, 66, 66, 66, 1080, 1080, 1080, 270, 66, 66, 66, 66, 66, 1080, 66, 270, 66, 1080, 1080, 66, 1080, 66, 270, 270, 1080, 66, 66, 66, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 270, 66, 1080, 270, 270, 270, 1080, 270, 66, 270, 1080, 1080, 270, 1080, 270, 66, 1080, 270, 66, 270, 270, 66, 270, 1080, 66, 270, 1080, 66, 270, 1080, 1080, 270, 66, 1080, 270, 66, 66, 270, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 270, 66, 1080, 1080, 270, 1080, 66, 1080, 1080, 1080, 66, 1080, 1080, 1080, 270, 270, 270, 270, 270, 270, 66, 1080, 270, 1080, 66, 1080, 270, 66, 270, 66, 66, 270, 270, 270, 1080, 270, 66, 66]
Prompts retrieved: 90624 . Total input tokens: 20192551 . Total output tokens: 17811724
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 2.4807626167312264,
    "estimated_duration": 3600.002049918765,
    "input_throughput": 2073.858819099414,
    "output_throughput": 1816.5336878481962,
    "total_throughput": 3890.3925069476104,
    "itl": 40.76860094234125,
    "ttft": 11673.1241088778,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6465,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 48.40117610080452,
    "arrivals": 30402,
    "finished_requests": 30304,
    "scheduler_time": 10.577706050024005
}
#Debug simulation 
Total elapsed time: 2.480835650116205. Arrivals time: 0.0804219045676291 Scheduler time: 2.03590272879228 Scheduler overhead time: 0.08470425009727478 Adapter cache time: 0.1504127294756472 Engine time: 0.08832028834149241 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-16/adapters_192_slots_96_rate_0.1-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-16/adapters_192_slots_96_rate_0.1-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [64 64 64]
Adapter prompts. [1080, 66, 1080, 66, 1080, 66, 1080, 66, 66, 66, 270, 270, 270, 270, 1080, 270, 66, 1080, 66, 270, 270, 66, 1080, 1080, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 1080, 270, 66, 270, 1080, 1080, 270, 1080, 66, 270, 270, 1080, 270, 66, 66, 270, 1080, 66, 270, 66, 1080, 1080, 270, 1080, 1080, 1080, 66, 270, 1080, 66, 270, 66, 270, 66, 66, 270, 1080, 1080, 66, 66, 66, 1080, 1080, 1080, 270, 66, 66, 66, 66, 66, 1080, 66, 270, 66, 1080, 1080, 66, 1080, 66, 270, 270, 1080, 66, 66, 66, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 270, 66, 1080, 270, 270, 270, 1080, 270, 66, 270, 1080, 1080, 270, 1080, 270, 66, 1080, 270, 66, 270, 270, 66, 270, 1080, 66, 270, 1080, 66, 270, 1080, 1080, 270, 66, 1080, 270, 66, 66, 270, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 270, 66, 1080, 1080, 270, 1080, 66, 1080, 1080, 1080, 66, 1080, 1080, 1080, 270, 270, 270, 270, 270, 270, 66, 1080, 270, 1080, 66, 1080, 270, 66, 270, 66, 66, 270, 270, 270, 1080, 270, 66, 66]
Prompts retrieved: 90624 . Total input tokens: 20192551 . Total output tokens: 17811724
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 2.477048716042191,
    "estimated_duration": 3599.988429945077,
    "input_throughput": 2073.866665208672,
    "output_throughput": 1816.5405604094594,
    "total_throughput": 3890.4072256181316,
    "itl": 40.674757887029635,
    "ttft": 11672.948646453493,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6461,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 44.18815343947768,
    "arrivals": 30402,
    "finished_requests": 30304,
    "scheduler_time": 10.540104649460268
}
#Debug simulation 
Total elapsed time: 2.477126603014767. Arrivals time: 0.07968984451144934 Scheduler time: 2.0361956264823675 Scheduler overhead time: 0.08525714883580804 Adapter cache time: 0.15027130022644997 Engine time: 0.08465400151908398 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-32/adapters_192_slots_96_rate_0.1-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-32/adapters_192_slots_96_rate_0.1-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [64 64 64]
Adapter prompts. [1080, 66, 1080, 66, 1080, 66, 1080, 66, 66, 66, 270, 270, 270, 270, 1080, 270, 66, 1080, 66, 270, 270, 66, 1080, 1080, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 1080, 270, 66, 270, 1080, 1080, 270, 1080, 66, 270, 270, 1080, 270, 66, 66, 270, 1080, 66, 270, 66, 1080, 1080, 270, 1080, 1080, 1080, 66, 270, 1080, 66, 270, 66, 270, 66, 66, 270, 1080, 1080, 66, 66, 66, 1080, 1080, 1080, 270, 66, 66, 66, 66, 66, 1080, 66, 270, 66, 1080, 1080, 66, 1080, 66, 270, 270, 1080, 66, 66, 66, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 270, 66, 1080, 270, 270, 270, 1080, 270, 66, 270, 1080, 1080, 270, 1080, 270, 66, 1080, 270, 66, 270, 270, 66, 270, 1080, 66, 270, 1080, 66, 270, 1080, 1080, 270, 66, 1080, 270, 66, 66, 270, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 270, 66, 1080, 1080, 270, 1080, 66, 1080, 1080, 1080, 66, 1080, 1080, 1080, 270, 270, 270, 270, 270, 270, 66, 1080, 270, 1080, 66, 1080, 270, 66, 270, 66, 66, 270, 270, 270, 1080, 270, 66, 66]
Prompts retrieved: 90624 . Total input tokens: 20192551 . Total output tokens: 17811724
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 2.4820290487259626,
    "estimated_duration": 3599.9883472575475,
    "input_throughput": 2073.8667128429684,
    "output_throughput": 1816.5406021332753,
    "total_throughput": 3890.4073149762435,
    "itl": 40.75683598724907,
    "ttft": 11673.286610501298,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6468,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 47.98885318160348,
    "arrivals": 30402,
    "finished_requests": 30304,
    "scheduler_time": 10.573875376442595
}
#Debug simulation 
Total elapsed time: 2.4820995526388288. Arrivals time: 0.08033066801726818 Scheduler time: 2.03840532945469 Scheduler overhead time: 0.08475833106786013 Adapter cache time: 0.15095187770202756 Engine time: 0.08683293452486396 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-16/adapters_192_slots_96_rate_0.1-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-16/adapters_192_slots_96_rate_0.1-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [64 64 64]
Adapter prompts. [1080, 66, 1080, 66, 1080, 66, 1080, 66, 66, 66, 270, 270, 270, 270, 1080, 270, 66, 1080, 66, 270, 270, 66, 1080, 1080, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 1080, 270, 66, 270, 1080, 1080, 270, 1080, 66, 270, 270, 1080, 270, 66, 66, 270, 1080, 66, 270, 66, 1080, 1080, 270, 1080, 1080, 1080, 66, 270, 1080, 66, 270, 66, 270, 66, 66, 270, 1080, 1080, 66, 66, 66, 1080, 1080, 1080, 270, 66, 66, 66, 66, 66, 1080, 66, 270, 66, 1080, 1080, 66, 1080, 66, 270, 270, 1080, 66, 66, 66, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 270, 66, 1080, 270, 270, 270, 1080, 270, 66, 270, 1080, 1080, 270, 1080, 270, 66, 1080, 270, 66, 270, 270, 66, 270, 1080, 66, 270, 1080, 66, 270, 1080, 1080, 270, 66, 1080, 270, 66, 66, 270, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 270, 66, 1080, 1080, 270, 1080, 66, 1080, 1080, 1080, 66, 1080, 1080, 1080, 270, 270, 270, 270, 270, 270, 66, 1080, 270, 1080, 66, 1080, 270, 66, 270, 66, 66, 270, 270, 270, 1080, 270, 66, 66]
Prompts retrieved: 90624 . Total input tokens: 20192551 . Total output tokens: 17811724
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 2.470915683545172,
    "estimated_duration": 3599.992609106378,
    "input_throughput": 2073.8642576972543,
    "output_throughput": 1816.5384516229044,
    "total_throughput": 3890.4027093201585,
    "itl": 40.60498327918839,
    "ttft": 11672.729983701474,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6462,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 41.25289711797118,
    "arrivals": 30402,
    "finished_requests": 30304,
    "scheduler_time": 10.513936326633392
}
#Debug simulation 
Total elapsed time: 2.470989486668259. Arrivals time: 0.07978302938863635 Scheduler time: 2.028826637659222 Scheduler overhead time: 0.08507127407938242 Adapter cache time: 0.15103129856288433 Engine time: 0.08530033240094781 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-32/adapters_192_slots_96_rate_0.1-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-32/adapters_192_slots_96_rate_0.1-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [64 64 64]
Adapter prompts. [1080, 66, 1080, 66, 1080, 66, 1080, 66, 66, 66, 270, 270, 270, 270, 1080, 270, 66, 1080, 66, 270, 270, 66, 1080, 1080, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 1080, 270, 66, 270, 1080, 1080, 270, 1080, 66, 270, 270, 1080, 270, 66, 66, 270, 1080, 66, 270, 66, 1080, 1080, 270, 1080, 1080, 1080, 66, 270, 1080, 66, 270, 66, 270, 66, 66, 270, 1080, 1080, 66, 66, 66, 1080, 1080, 1080, 270, 66, 66, 66, 66, 66, 1080, 66, 270, 66, 1080, 1080, 66, 1080, 66, 270, 270, 1080, 66, 66, 66, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 270, 66, 1080, 270, 270, 270, 1080, 270, 66, 270, 1080, 1080, 270, 1080, 270, 66, 1080, 270, 66, 270, 270, 66, 270, 1080, 66, 270, 1080, 66, 270, 1080, 1080, 270, 66, 1080, 270, 66, 66, 270, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 270, 66, 1080, 1080, 270, 1080, 66, 1080, 1080, 1080, 66, 1080, 1080, 1080, 270, 270, 270, 270, 270, 270, 66, 1080, 270, 1080, 66, 1080, 270, 66, 270, 66, 66, 270, 270, 270, 1080, 270, 66, 66]
Prompts retrieved: 90624 . Total input tokens: 20192551 . Total output tokens: 17811724
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 2.526520204730332,
    "estimated_duration": 3600.005765577091,
    "input_throughput": 2073.856678616512,
    "output_throughput": 1816.531812957165,
    "total_throughput": 3890.388491573677,
    "itl": 40.74822242213093,
    "ttft": 11673.238906970688,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6467,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 47.54277614867147,
    "arrivals": 30402,
    "finished_requests": 30304,
    "scheduler_time": 10.569923172356646
}
#Debug simulation 
Total elapsed time: 2.526622084900737. Arrivals time: 0.08078183000907302 Scheduler time: 2.082978674210608 Scheduler overhead time: 0.08538531372323632 Adapter cache time: 0.15051832050085068 Engine time: 0.08586360886693001 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-8/adapters_192_slots_96_rate_0.1-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-8/adapters_192_slots_96_rate_0.1-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [64 64 64]
Adapter prompts. [1080, 33, 1080, 33, 1080, 33, 1080, 33, 33, 33, 270, 270, 270, 270, 1080, 270, 33, 1080, 33, 270, 270, 33, 1080, 1080, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 1080, 270, 33, 270, 1080, 1080, 270, 1080, 33, 270, 270, 1080, 270, 33, 33, 270, 1080, 33, 270, 33, 1080, 1080, 270, 1080, 1080, 1080, 33, 270, 1080, 33, 270, 33, 270, 33, 33, 270, 1080, 1080, 33, 33, 33, 1080, 1080, 1080, 270, 33, 33, 33, 33, 33, 1080, 33, 270, 33, 1080, 1080, 33, 1080, 33, 270, 270, 1080, 33, 33, 33, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 270, 33, 1080, 270, 270, 270, 1080, 270, 33, 270, 1080, 1080, 270, 1080, 270, 33, 1080, 270, 33, 270, 270, 33, 270, 1080, 33, 270, 1080, 33, 270, 1080, 1080, 270, 33, 1080, 270, 33, 33, 270, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 270, 33, 1080, 1080, 270, 1080, 33, 1080, 1080, 1080, 33, 1080, 1080, 1080, 270, 270, 270, 270, 270, 270, 33, 1080, 270, 1080, 33, 1080, 270, 33, 270, 33, 33, 270, 270, 270, 1080, 270, 33, 33]
Prompts retrieved: 88512 . Total input tokens: 19708270 . Total output tokens: 17406279
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 2.4177026990801096,
    "estimated_duration": 3600.0049385449934,
    "input_throughput": 2012.6797389695978,
    "output_throughput": 1750.5237097110826,
    "total_throughput": 3763.2034486806806,
    "itl": 38.57508196034736,
    "ttft": 11846.638943282982,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5332,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 35.257364958354714,
    "arrivals": 29640,
    "finished_requests": 29542,
    "scheduler_time": 8.702388323665499
}
#Debug simulation 
Total elapsed time: 2.4178080009296536. Arrivals time: 0.08061766671016812 Scheduler time: 1.9697843734174967 Scheduler overhead time: 0.08842246374115348 Adapter cache time: 0.1445457204245031 Engine time: 0.09156567743048072 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-16/adapters_192_slots_96_rate_0.1-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-16/adapters_192_slots_96_rate_0.1-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [64 64 64]
Adapter prompts. [1080, 33, 1080, 33, 1080, 33, 1080, 33, 33, 33, 270, 270, 270, 270, 1080, 270, 33, 1080, 33, 270, 270, 33, 1080, 1080, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 1080, 270, 33, 270, 1080, 1080, 270, 1080, 33, 270, 270, 1080, 270, 33, 33, 270, 1080, 33, 270, 33, 1080, 1080, 270, 1080, 1080, 1080, 33, 270, 1080, 33, 270, 33, 270, 33, 33, 270, 1080, 1080, 33, 33, 33, 1080, 1080, 1080, 270, 33, 33, 33, 33, 33, 1080, 33, 270, 33, 1080, 1080, 33, 1080, 33, 270, 270, 1080, 33, 33, 33, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 270, 33, 1080, 270, 270, 270, 1080, 270, 33, 270, 1080, 1080, 270, 1080, 270, 33, 1080, 270, 33, 270, 270, 33, 270, 1080, 33, 270, 1080, 33, 270, 1080, 1080, 270, 33, 1080, 270, 33, 33, 270, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 270, 33, 1080, 1080, 270, 1080, 33, 1080, 1080, 1080, 33, 1080, 1080, 1080, 270, 270, 270, 270, 270, 270, 33, 1080, 270, 1080, 33, 1080, 270, 33, 270, 33, 33, 270, 270, 270, 1080, 270, 33, 33]
Prompts retrieved: 88512 . Total input tokens: 19708270 . Total output tokens: 17406279
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 2.426294890232384,
    "estimated_duration": 3600.0400972045013,
    "input_throughput": 2012.6600827658526,
    "output_throughput": 1750.5066137717574,
    "total_throughput": 3763.1666965376103,
    "itl": 38.65393980355394,
    "ttft": 11846.824167878807,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5334,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 38.92587813430355,
    "arrivals": 29640,
    "finished_requests": 29542,
    "scheduler_time": 8.734800870999955
}
#Debug simulation 
Total elapsed time: 2.426424628123641. Arrivals time: 0.07990774791687727 Scheduler time: 1.9799421424977481 Scheduler overhead time: 0.08901478815823793 Adapter cache time: 0.1455253828316927 Engine time: 0.08899441454559565 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-32/adapters_192_slots_96_rate_0.1-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-32/adapters_192_slots_96_rate_0.1-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [64 64 64]
Adapter prompts. [1080, 33, 1080, 33, 1080, 33, 1080, 33, 33, 33, 270, 270, 270, 270, 1080, 270, 33, 1080, 33, 270, 270, 33, 1080, 1080, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 1080, 270, 33, 270, 1080, 1080, 270, 1080, 33, 270, 270, 1080, 270, 33, 33, 270, 1080, 33, 270, 33, 1080, 1080, 270, 1080, 1080, 1080, 33, 270, 1080, 33, 270, 33, 270, 33, 33, 270, 1080, 1080, 33, 33, 33, 1080, 1080, 1080, 270, 33, 33, 33, 33, 33, 1080, 33, 270, 33, 1080, 1080, 33, 1080, 33, 270, 270, 1080, 33, 33, 33, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 270, 33, 1080, 270, 270, 270, 1080, 270, 33, 270, 1080, 1080, 270, 1080, 270, 33, 1080, 270, 33, 270, 270, 33, 270, 1080, 33, 270, 1080, 33, 270, 1080, 1080, 270, 33, 1080, 270, 33, 33, 270, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 270, 33, 1080, 1080, 270, 1080, 33, 1080, 1080, 1080, 33, 1080, 1080, 1080, 270, 270, 270, 270, 270, 270, 33, 1080, 270, 1080, 33, 1080, 270, 33, 270, 33, 33, 270, 270, 270, 1080, 270, 33, 33]
Prompts retrieved: 88512 . Total input tokens: 19708270 . Total output tokens: 17406279
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 2.3989853439852595,
    "estimated_duration": 3600.004757802166,
    "input_throughput": 2012.6065067823342,
    "output_throughput": 1750.4785198804186,
    "total_throughput": 3763.0850266627526,
    "itl": 38.67522058414978,
    "ttft": 11968.331793685851,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5335,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 39.97069739116344,
    "arrivals": 29640,
    "finished_requests": 29541,
    "scheduler_time": 8.743813245189859
}
#Debug simulation 
Total elapsed time: 2.399056440219283. Arrivals time: 0.07825142983347178 Scheduler time: 1.9558766125701368 Scheduler overhead time: 0.08857127651572227 Adapter cache time: 0.1457824227400124 Engine time: 0.08808001456782222 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-16/adapters_192_slots_96_rate_0.1-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-16/adapters_192_slots_96_rate_0.1-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [64 64 64]
Adapter prompts. [1080, 33, 1080, 33, 1080, 33, 1080, 33, 33, 33, 270, 270, 270, 270, 1080, 270, 33, 1080, 33, 270, 270, 33, 1080, 1080, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 1080, 270, 33, 270, 1080, 1080, 270, 1080, 33, 270, 270, 1080, 270, 33, 33, 270, 1080, 33, 270, 33, 1080, 1080, 270, 1080, 1080, 1080, 33, 270, 1080, 33, 270, 33, 270, 33, 33, 270, 1080, 1080, 33, 33, 33, 1080, 1080, 1080, 270, 33, 33, 33, 33, 33, 1080, 33, 270, 33, 1080, 1080, 33, 1080, 33, 270, 270, 1080, 33, 33, 33, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 270, 33, 1080, 270, 270, 270, 1080, 270, 33, 270, 1080, 1080, 270, 1080, 270, 33, 1080, 270, 33, 270, 270, 33, 270, 1080, 33, 270, 1080, 33, 270, 1080, 1080, 270, 33, 1080, 270, 33, 33, 270, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 270, 33, 1080, 1080, 270, 1080, 33, 1080, 1080, 1080, 33, 1080, 1080, 1080, 270, 270, 270, 270, 270, 270, 33, 1080, 270, 1080, 33, 1080, 270, 33, 270, 33, 33, 270, 270, 270, 1080, 270, 33, 33]
Prompts retrieved: 88512 . Total input tokens: 19708270 . Total output tokens: 17406279
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 2.4208509298041463,
    "estimated_duration": 3600.0108614760593,
    "input_throughput": 2012.6764276008796,
    "output_throughput": 1750.5208296555327,
    "total_throughput": 3763.1972572564123,
    "itl": 38.59994495045956,
    "ttft": 11846.630238350008,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5331,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 36.392658188814686,
    "arrivals": 29640,
    "finished_requests": 29542,
    "scheduler_time": 8.712488042354474
}
#Debug simulation 
Total elapsed time: 2.4209421216510236. Arrivals time: 0.07897602999582887 Scheduler time: 1.9752046181820333 Scheduler overhead time: 0.08860509563237429 Adapter cache time: 0.14547357335686684 Engine time: 0.08992652501910925 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-32/adapters_192_slots_96_rate_0.1-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-32/adapters_192_slots_96_rate_0.1-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [64 64 64]
Adapter prompts. [1080, 33, 1080, 33, 1080, 33, 1080, 33, 33, 33, 270, 270, 270, 270, 1080, 270, 33, 1080, 33, 270, 270, 33, 1080, 1080, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 1080, 270, 33, 270, 1080, 1080, 270, 1080, 33, 270, 270, 1080, 270, 33, 33, 270, 1080, 33, 270, 33, 1080, 1080, 270, 1080, 1080, 1080, 33, 270, 1080, 33, 270, 33, 270, 33, 33, 270, 1080, 1080, 33, 33, 33, 1080, 1080, 1080, 270, 33, 33, 33, 33, 33, 1080, 33, 270, 33, 1080, 1080, 33, 1080, 33, 270, 270, 1080, 33, 33, 33, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 270, 33, 1080, 270, 270, 270, 1080, 270, 33, 270, 1080, 1080, 270, 1080, 270, 33, 1080, 270, 33, 270, 270, 33, 270, 1080, 33, 270, 1080, 33, 270, 1080, 1080, 270, 33, 1080, 270, 33, 33, 270, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 270, 33, 1080, 1080, 270, 1080, 33, 1080, 1080, 1080, 33, 1080, 1080, 1080, 270, 270, 270, 270, 270, 270, 33, 1080, 270, 1080, 33, 1080, 270, 33, 270, 33, 33, 270, 270, 270, 1080, 270, 33, 33]
Prompts retrieved: 88512 . Total input tokens: 19708270 . Total output tokens: 17406279
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 2.417322508059442,
    "estimated_duration": 3600.013387160405,
    "input_throughput": 2012.6750155546456,
    "output_throughput": 1750.519601531473,
    "total_throughput": 3763.1946170861183,
    "itl": 38.66522616462319,
    "ttft": 11846.855466772582,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5330,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 39.557765092547015,
    "arrivals": 29640,
    "finished_requests": 29542,
    "scheduler_time": 8.740210655699094
}
#Debug simulation 
Total elapsed time: 2.4174203011207283. Arrivals time: 0.07964948238804936 Scheduler time: 1.967202989384532 Scheduler overhead time: 0.08923905342817307 Adapter cache time: 0.14643169520422816 Engine time: 0.09108872711658478 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-16/adapters_192_slots_96_rate_0.1-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-16/adapters_192_slots_96_rate_0.1-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [64 64 64]
Adapter prompts. [1080, 33, 1080, 33, 1080, 33, 1080, 33, 33, 33, 270, 270, 270, 270, 1080, 270, 33, 1080, 33, 270, 270, 33, 1080, 1080, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 1080, 270, 33, 270, 1080, 1080, 270, 1080, 33, 270, 270, 1080, 270, 33, 33, 270, 1080, 33, 270, 33, 1080, 1080, 270, 1080, 1080, 1080, 33, 270, 1080, 33, 270, 33, 270, 33, 33, 270, 1080, 1080, 33, 33, 33, 1080, 1080, 1080, 270, 33, 33, 33, 33, 33, 1080, 33, 270, 33, 1080, 1080, 33, 1080, 33, 270, 270, 1080, 33, 33, 33, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 270, 33, 1080, 270, 270, 270, 1080, 270, 33, 270, 1080, 1080, 270, 1080, 270, 33, 1080, 270, 33, 270, 270, 33, 270, 1080, 33, 270, 1080, 33, 270, 1080, 1080, 270, 33, 1080, 270, 33, 33, 270, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 270, 33, 1080, 1080, 270, 1080, 33, 1080, 1080, 1080, 33, 1080, 1080, 1080, 270, 270, 270, 270, 270, 270, 33, 1080, 270, 1080, 33, 1080, 270, 33, 270, 33, 33, 270, 270, 270, 1080, 270, 33, 33]
Prompts retrieved: 88512 . Total input tokens: 19708270 . Total output tokens: 17406279
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 2.3730633049272,
    "estimated_duration": 3600.037567998311,
    "input_throughput": 2012.6614967600804,
    "output_throughput": 1750.5078435900803,
    "total_throughput": 3763.169340350161,
    "itl": 38.55200401693855,
    "ttft": 11846.522476616476,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5331,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 34.03268253418494,
    "arrivals": 29640,
    "finished_requests": 29542,
    "scheduler_time": 8.69187962074438
}
#Debug simulation 
Total elapsed time: 2.373160791117698. Arrivals time: 0.07813012786209583 Scheduler time: 1.9341589924879372 Scheduler overhead time: 0.08826945070177317 Adapter cache time: 0.14190540742129087 Engine time: 0.08777221385389566 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-32/adapters_192_slots_96_rate_0.1-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-32/adapters_192_slots_96_rate_0.1-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [64 64 64]
Adapter prompts. [1080, 33, 1080, 33, 1080, 33, 1080, 33, 33, 33, 270, 270, 270, 270, 1080, 270, 33, 1080, 33, 270, 270, 33, 1080, 1080, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 1080, 270, 33, 270, 1080, 1080, 270, 1080, 33, 270, 270, 1080, 270, 33, 33, 270, 1080, 33, 270, 33, 1080, 1080, 270, 1080, 1080, 1080, 33, 270, 1080, 33, 270, 33, 270, 33, 33, 270, 1080, 1080, 33, 33, 33, 1080, 1080, 1080, 270, 33, 33, 33, 33, 33, 1080, 33, 270, 33, 1080, 1080, 33, 1080, 33, 270, 270, 1080, 33, 33, 33, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 270, 33, 1080, 270, 270, 270, 1080, 270, 33, 270, 1080, 1080, 270, 1080, 270, 33, 1080, 270, 33, 270, 270, 33, 270, 1080, 33, 270, 1080, 33, 270, 1080, 1080, 270, 33, 1080, 270, 33, 33, 270, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 270, 33, 1080, 1080, 270, 1080, 33, 1080, 1080, 1080, 33, 1080, 1080, 1080, 270, 270, 270, 270, 270, 270, 33, 1080, 270, 1080, 33, 1080, 270, 33, 270, 33, 33, 270, 270, 270, 1080, 270, 33, 33]
Prompts retrieved: 88512 . Total input tokens: 19708270 . Total output tokens: 17406279
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 2.4009377202019095,
    "estimated_duration": 3600.0200443593353,
    "input_throughput": 2012.6712936926015,
    "output_throughput": 1750.516364450269,
    "total_throughput": 3763.1876581428705,
    "itl": 38.65783620751475,
    "ttft": 11846.831510352886,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5332,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 39.21969499830159,
    "arrivals": 29640,
    "finished_requests": 29542,
    "scheduler_time": 8.737198232816445
}
#Debug simulation 
Total elapsed time: 2.4010269101709127. Arrivals time: 0.0798600590787828 Scheduler time: 1.9544782326556742 Scheduler overhead time: 0.08897107327356935 Adapter cache time: 0.14381982991471887 Engine time: 0.09058099519461393 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-8/adapters_192_slots_96_rate_0.1-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-8/adapters_192_slots_96_rate_0.1-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [64 64 64]
Adapter prompts. [1080, 66, 1080, 66, 1080, 66, 1080, 66, 66, 66, 135, 135, 135, 135, 1080, 135, 66, 1080, 66, 135, 135, 66, 1080, 1080, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 1080, 135, 66, 135, 1080, 1080, 135, 1080, 66, 135, 135, 1080, 135, 66, 66, 135, 1080, 66, 135, 66, 1080, 1080, 135, 1080, 1080, 1080, 66, 135, 1080, 66, 135, 66, 135, 66, 66, 135, 1080, 1080, 66, 66, 66, 1080, 1080, 1080, 135, 66, 66, 66, 66, 66, 1080, 66, 135, 66, 1080, 1080, 66, 1080, 66, 135, 135, 1080, 66, 66, 66, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 135, 66, 1080, 135, 135, 135, 1080, 135, 66, 135, 1080, 1080, 135, 1080, 135, 66, 1080, 135, 66, 135, 135, 66, 135, 1080, 66, 135, 1080, 66, 135, 1080, 1080, 135, 66, 1080, 135, 66, 66, 135, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 135, 66, 1080, 1080, 135, 1080, 66, 1080, 1080, 1080, 66, 1080, 1080, 1080, 135, 135, 135, 135, 135, 135, 66, 1080, 135, 1080, 66, 1080, 135, 66, 135, 66, 66, 135, 135, 135, 1080, 135, 66, 66]
Prompts retrieved: 81984 . Total input tokens: 18281899 . Total output tokens: 16081374
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 2.297111986670643,
    "estimated_duration": 3600.0093051075246,
    "input_throughput": 1877.5876469014052,
    "output_throughput": 1645.408524804654,
    "total_throughput": 3522.996171706059,
    "itl": 35.70181463813267,
    "ttft": 10260.370495962754,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3835,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 25.358588637526246,
    "arrivals": 27529,
    "finished_requests": 27450,
    "scheduler_time": 5.909051149383496
}
#Debug simulation 
Total elapsed time: 2.297181128989905. Arrivals time: 0.07381594367325306 Scheduler time: 1.8571502515114844 Scheduler overhead time: 0.09530113311484456 Adapter cache time: 0.13060874538496137 Engine time: 0.09447600319981575 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-16/adapters_192_slots_96_rate_0.1-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-16/adapters_192_slots_96_rate_0.1-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [64 64 64]
Adapter prompts. [1080, 66, 1080, 66, 1080, 66, 1080, 66, 66, 66, 135, 135, 135, 135, 1080, 135, 66, 1080, 66, 135, 135, 66, 1080, 1080, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 1080, 135, 66, 135, 1080, 1080, 135, 1080, 66, 135, 135, 1080, 135, 66, 66, 135, 1080, 66, 135, 66, 1080, 1080, 135, 1080, 1080, 1080, 66, 135, 1080, 66, 135, 66, 135, 66, 66, 135, 1080, 1080, 66, 66, 66, 1080, 1080, 1080, 135, 66, 66, 66, 66, 66, 1080, 66, 135, 66, 1080, 1080, 66, 1080, 66, 135, 135, 1080, 66, 66, 66, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 135, 66, 1080, 135, 135, 135, 1080, 135, 66, 135, 1080, 1080, 135, 1080, 135, 66, 1080, 135, 66, 135, 135, 66, 135, 1080, 66, 135, 1080, 66, 135, 1080, 1080, 135, 66, 1080, 135, 66, 66, 135, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 135, 66, 1080, 1080, 135, 1080, 66, 1080, 1080, 1080, 66, 1080, 1080, 1080, 135, 135, 135, 135, 135, 135, 66, 1080, 135, 1080, 66, 1080, 135, 66, 135, 66, 66, 135, 135, 135, 1080, 135, 66, 66]
Prompts retrieved: 81984 . Total input tokens: 18281899 . Total output tokens: 16081374
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 2.268813442904502,
    "estimated_duration": 3600.0072503210813,
    "input_throughput": 1877.5884408002628,
    "output_throughput": 1645.17474220969,
    "total_throughput": 3522.7631830099526,
    "itl": 35.74932217075994,
    "ttft": 10391.295549177028,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3834,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 27.99509305349475,
    "arrivals": 27529,
    "finished_requests": 27449,
    "scheduler_time": 5.930722730380435
}
#Debug simulation 
Total elapsed time: 2.268891479820013. Arrivals time: 0.07382010668516159 Scheduler time: 1.829749689437449 Scheduler overhead time: 0.09470987599343061 Adapter cache time: 0.12978741899132729 Engine time: 0.09508818481117487 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-32/adapters_192_slots_96_rate_0.1-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-32/adapters_192_slots_96_rate_0.1-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [64 64 64]
Adapter prompts. [1080, 66, 1080, 66, 1080, 66, 1080, 66, 66, 66, 135, 135, 135, 135, 1080, 135, 66, 1080, 66, 135, 135, 66, 1080, 1080, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 1080, 135, 66, 135, 1080, 1080, 135, 1080, 66, 135, 135, 1080, 135, 66, 66, 135, 1080, 66, 135, 66, 1080, 1080, 135, 1080, 1080, 1080, 66, 135, 1080, 66, 135, 66, 135, 66, 66, 135, 1080, 1080, 66, 66, 66, 1080, 1080, 1080, 135, 66, 66, 66, 66, 66, 1080, 66, 135, 66, 1080, 1080, 66, 1080, 66, 135, 135, 1080, 66, 66, 66, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 135, 66, 1080, 135, 135, 135, 1080, 135, 66, 135, 1080, 1080, 135, 1080, 135, 66, 1080, 135, 66, 135, 135, 66, 135, 1080, 66, 135, 1080, 66, 135, 1080, 1080, 135, 66, 1080, 135, 66, 66, 135, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 135, 66, 1080, 1080, 135, 1080, 66, 1080, 1080, 1080, 66, 1080, 1080, 1080, 135, 135, 135, 135, 135, 135, 66, 1080, 135, 1080, 66, 1080, 135, 66, 135, 66, 66, 135, 135, 135, 1080, 135, 66, 66]
Prompts retrieved: 81984 . Total input tokens: 18281899 . Total output tokens: 16081374
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 2.274542558938265,
    "estimated_duration": 3600.0405915401216,
    "input_throughput": 1877.5710518053666,
    "output_throughput": 1645.1595056783108,
    "total_throughput": 3522.7305574836773,
    "itl": 35.762134323272505,
    "ttft": 10521.736298127187,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3833,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 28.73584973468555,
    "arrivals": 27529,
    "finished_requests": 27449,
    "scheduler_time": 5.93688047106924
}
#Debug simulation 
Total elapsed time: 2.274642406962812. Arrivals time: 0.07429603906348348 Scheduler time: 1.8350323801860213 Scheduler overhead time: 0.09453253634274006 Adapter cache time: 0.1296522719785571 Engine time: 0.09564292849972844 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-16/adapters_192_slots_96_rate_0.1-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-16/adapters_192_slots_96_rate_0.1-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [64 64 64]
Adapter prompts. [1080, 66, 1080, 66, 1080, 66, 1080, 66, 66, 66, 135, 135, 135, 135, 1080, 135, 66, 1080, 66, 135, 135, 66, 1080, 1080, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 1080, 135, 66, 135, 1080, 1080, 135, 1080, 66, 135, 135, 1080, 135, 66, 66, 135, 1080, 66, 135, 66, 1080, 1080, 135, 1080, 1080, 1080, 66, 135, 1080, 66, 135, 66, 135, 66, 66, 135, 1080, 1080, 66, 66, 66, 1080, 1080, 1080, 135, 66, 66, 66, 66, 66, 1080, 66, 135, 66, 1080, 1080, 66, 1080, 66, 135, 135, 1080, 66, 66, 66, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 135, 66, 1080, 135, 135, 135, 1080, 135, 66, 135, 1080, 1080, 135, 1080, 135, 66, 1080, 135, 66, 135, 135, 66, 135, 1080, 66, 135, 1080, 66, 135, 1080, 1080, 135, 66, 1080, 135, 66, 66, 135, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 135, 66, 1080, 1080, 135, 1080, 66, 1080, 1080, 1080, 66, 1080, 1080, 1080, 135, 135, 135, 135, 135, 135, 66, 1080, 135, 1080, 66, 1080, 135, 66, 135, 66, 66, 135, 135, 135, 1080, 135, 66, 66]
Prompts retrieved: 81984 . Total input tokens: 18281899 . Total output tokens: 16081374
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 2.272213477175683,
    "estimated_duration": 3600.029756899978,
    "input_throughput": 1877.5769803137766,
    "output_throughput": 1645.3991772281277,
    "total_throughput": 3522.9761575419043,
    "itl": 35.71721044062278,
    "ttft": 10260.412768290618,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3836,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 26.219832281750477,
    "arrivals": 27529,
    "finished_requests": 27450,
    "scheduler_time": 5.916142531865791
}
#Debug simulation 
Total elapsed time: 2.272297488991171. Arrivals time: 0.07402174081653357 Scheduler time: 1.8324306947179139 Scheduler overhead time: 0.09476521564647555 Adapter cache time: 0.13042294094339013 Engine time: 0.09476361842826009 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-32/adapters_192_slots_96_rate_0.1-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-32/adapters_192_slots_96_rate_0.1-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [64 64 64]
Adapter prompts. [1080, 66, 1080, 66, 1080, 66, 1080, 66, 66, 66, 135, 135, 135, 135, 1080, 135, 66, 1080, 66, 135, 135, 66, 1080, 1080, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 1080, 135, 66, 135, 1080, 1080, 135, 1080, 66, 135, 135, 1080, 135, 66, 66, 135, 1080, 66, 135, 66, 1080, 1080, 135, 1080, 1080, 1080, 66, 135, 1080, 66, 135, 66, 135, 66, 66, 135, 1080, 1080, 66, 66, 66, 1080, 1080, 1080, 135, 66, 66, 66, 66, 66, 1080, 66, 135, 66, 1080, 1080, 66, 1080, 66, 135, 135, 1080, 66, 66, 66, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 135, 66, 1080, 135, 135, 135, 1080, 135, 66, 135, 1080, 1080, 135, 1080, 135, 66, 1080, 135, 66, 135, 135, 66, 135, 1080, 66, 135, 1080, 66, 135, 1080, 1080, 135, 66, 1080, 135, 66, 66, 135, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 135, 66, 1080, 1080, 135, 1080, 66, 1080, 1080, 1080, 66, 1080, 1080, 1080, 135, 135, 135, 135, 135, 135, 66, 1080, 135, 1080, 66, 1080, 135, 66, 135, 66, 66, 135, 135, 135, 1080, 135, 66, 66]
Prompts retrieved: 81984 . Total input tokens: 18281899 . Total output tokens: 16081374
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 2.2723576868884265,
    "estimated_duration": 3600.0252418806785,
    "input_throughput": 1877.579057325964,
    "output_throughput": 1645.1665202508332,
    "total_throughput": 3522.745577576797,
    "itl": 35.755628518803164,
    "ttft": 10391.24917162291,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3836,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 28.49268967979696,
    "arrivals": 27529,
    "finished_requests": 27449,
    "scheduler_time": 5.934682722574827
}
#Debug simulation 
Total elapsed time: 2.272427821997553. Arrivals time: 0.07388345617800951 Scheduler time: 1.8325919415801764 Scheduler overhead time: 0.09480072930455208 Adapter cache time: 0.13065341534093022 Engine time: 0.09452901594340801 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-16/adapters_192_slots_96_rate_0.1-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-16/adapters_192_slots_96_rate_0.1-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [64 64 64]
Adapter prompts. [1080, 66, 1080, 66, 1080, 66, 1080, 66, 66, 66, 135, 135, 135, 135, 1080, 135, 66, 1080, 66, 135, 135, 66, 1080, 1080, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 1080, 135, 66, 135, 1080, 1080, 135, 1080, 66, 135, 135, 1080, 135, 66, 66, 135, 1080, 66, 135, 66, 1080, 1080, 135, 1080, 1080, 1080, 66, 135, 1080, 66, 135, 66, 135, 66, 66, 135, 1080, 1080, 66, 66, 66, 1080, 1080, 1080, 135, 66, 66, 66, 66, 66, 1080, 66, 135, 66, 1080, 1080, 66, 1080, 66, 135, 135, 1080, 66, 66, 66, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 135, 66, 1080, 135, 135, 135, 1080, 135, 66, 135, 1080, 1080, 135, 1080, 135, 66, 1080, 135, 66, 135, 135, 66, 135, 1080, 66, 135, 1080, 66, 135, 1080, 1080, 135, 66, 1080, 135, 66, 66, 135, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 135, 66, 1080, 1080, 135, 1080, 66, 1080, 1080, 1080, 66, 1080, 1080, 1080, 135, 135, 135, 135, 135, 135, 66, 1080, 135, 1080, 66, 1080, 135, 66, 135, 66, 66, 135, 135, 135, 1080, 135, 66, 66]
Prompts retrieved: 81984 . Total input tokens: 18281899 . Total output tokens: 16081374
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 2.2737664566375315,
    "estimated_duration": 3600.003735995516,
    "input_throughput": 1877.5905514805886,
    "output_throughput": 1645.4110702087833,
    "total_throughput": 3523.001621689372,
    "itl": 35.686431723501784,
    "ttft": 10260.149518616696,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3837,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.495104648971296,
    "arrivals": 27529,
    "finished_requests": 27450,
    "scheduler_time": 5.902074105756328
}
#Debug simulation 
Total elapsed time: 2.2738434709608555. Arrivals time: 0.07422560825943947 Scheduler time: 1.8308033072389662 Scheduler overhead time: 0.09639008715748787 Adapter cache time: 0.13086035661399364 Engine time: 0.09533704351633787 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-32/adapters_192_slots_96_rate_0.1-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-32/adapters_192_slots_96_rate_0.1-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [64 64 64]
Adapter prompts. [1080, 66, 1080, 66, 1080, 66, 1080, 66, 66, 66, 135, 135, 135, 135, 1080, 135, 66, 1080, 66, 135, 135, 66, 1080, 1080, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 1080, 135, 66, 135, 1080, 1080, 135, 1080, 66, 135, 135, 1080, 135, 66, 66, 135, 1080, 66, 135, 66, 1080, 1080, 135, 1080, 1080, 1080, 66, 135, 1080, 66, 135, 66, 135, 66, 66, 135, 1080, 1080, 66, 66, 66, 1080, 1080, 1080, 135, 66, 66, 66, 66, 66, 1080, 66, 135, 66, 1080, 1080, 66, 1080, 66, 135, 135, 1080, 66, 66, 66, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 135, 66, 1080, 135, 135, 135, 1080, 135, 66, 135, 1080, 1080, 135, 1080, 135, 66, 1080, 135, 66, 135, 135, 66, 135, 1080, 66, 135, 1080, 66, 135, 1080, 1080, 135, 66, 1080, 135, 66, 66, 135, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 135, 66, 1080, 1080, 135, 1080, 66, 1080, 1080, 1080, 66, 1080, 1080, 1080, 135, 135, 135, 135, 135, 135, 66, 1080, 135, 1080, 66, 1080, 135, 66, 135, 66, 66, 135, 135, 135, 1080, 135, 66, 66]
Prompts retrieved: 81984 . Total input tokens: 18281899 . Total output tokens: 16081374
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 2.300174637231976,
    "estimated_duration": 3600.007490044171,
    "input_throughput": 1877.5883157723833,
    "output_throughput": 1645.1746326581479,
    "total_throughput": 3522.762948430531,
    "itl": 35.75352342018542,
    "ttft": 10391.385763961525,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3836,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 28.233119988517043,
    "arrivals": 27529,
    "finished_requests": 27449,
    "scheduler_time": 5.9326877982245
}
#Debug simulation 
Total elapsed time: 2.3002448212355375. Arrivals time: 0.0743561228737235 Scheduler time: 1.8548483666963875 Scheduler overhead time: 0.09588649962097406 Adapter cache time: 0.13142723590135574 Engine time: 0.09726065397262573 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-8/adapters_192_slots_96_rate_0.1-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-8/adapters_192_slots_96_rate_0.1-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [64 64 64]
Adapter prompts. [1080, 33, 1080, 33, 1080, 33, 1080, 33, 33, 33, 135, 135, 135, 135, 1080, 135, 33, 1080, 33, 135, 135, 33, 1080, 1080, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 1080, 135, 33, 135, 1080, 1080, 135, 1080, 33, 135, 135, 1080, 135, 33, 33, 135, 1080, 33, 135, 33, 1080, 1080, 135, 1080, 1080, 1080, 33, 135, 1080, 33, 135, 33, 135, 33, 33, 135, 1080, 1080, 33, 33, 33, 1080, 1080, 1080, 135, 33, 33, 33, 33, 33, 1080, 33, 135, 33, 1080, 1080, 33, 1080, 33, 135, 135, 1080, 33, 33, 33, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 135, 33, 1080, 135, 135, 135, 1080, 135, 33, 135, 1080, 1080, 135, 1080, 135, 33, 1080, 135, 33, 135, 135, 33, 135, 1080, 33, 135, 1080, 33, 135, 1080, 1080, 135, 33, 1080, 135, 33, 33, 135, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 135, 33, 1080, 1080, 135, 1080, 33, 1080, 1080, 1080, 33, 1080, 1080, 1080, 135, 135, 135, 135, 135, 135, 33, 1080, 135, 1080, 33, 1080, 135, 33, 135, 33, 33, 135, 135, 135, 1080, 135, 33, 33]
Prompts retrieved: 79872 . Total input tokens: 17791949 . Total output tokens: 15666598
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 2.228319870773703,
    "estimated_duration": 3600.015228115954,
    "input_throughput": 1828.7392088186884,
    "output_throughput": 1594.3385336744275,
    "total_throughput": 3423.077742493116,
    "itl": 34.54357835462166,
    "ttft": 9340.228675807284,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2792,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 18.461846017204092,
    "arrivals": 26760,
    "finished_requests": 26691,
    "scheduler_time": 4.687143699689643
}
#Debug simulation 
Total elapsed time: 2.2283988958224654. Arrivals time: 0.07242860598489642 Scheduler time: 1.7877849712967873 Scheduler overhead time: 0.09734308905899525 Adapter cache time: 0.12613746291026473 Engine time: 0.09776256373152137 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-16/adapters_192_slots_96_rate_0.1-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-16/adapters_192_slots_96_rate_0.1-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [64 64 64]
Adapter prompts. [1080, 33, 1080, 33, 1080, 33, 1080, 33, 33, 33, 135, 135, 135, 135, 1080, 135, 33, 1080, 33, 135, 135, 33, 1080, 1080, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 1080, 135, 33, 135, 1080, 1080, 135, 1080, 33, 135, 135, 1080, 135, 33, 33, 135, 1080, 33, 135, 33, 1080, 1080, 135, 1080, 1080, 1080, 33, 135, 1080, 33, 135, 33, 135, 33, 33, 135, 1080, 1080, 33, 33, 33, 1080, 1080, 1080, 135, 33, 33, 33, 33, 33, 1080, 33, 135, 33, 1080, 1080, 33, 1080, 33, 135, 135, 1080, 33, 33, 33, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 135, 33, 1080, 135, 135, 135, 1080, 135, 33, 135, 1080, 1080, 135, 1080, 135, 33, 1080, 135, 33, 135, 135, 33, 135, 1080, 33, 135, 1080, 33, 135, 1080, 1080, 135, 33, 1080, 135, 33, 33, 135, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 135, 33, 1080, 1080, 135, 1080, 33, 1080, 1080, 1080, 33, 1080, 1080, 1080, 135, 135, 135, 135, 135, 135, 33, 1080, 135, 1080, 33, 1080, 135, 33, 135, 33, 33, 135, 135, 135, 1080, 135, 33, 33]
Prompts retrieved: 79872 . Total input tokens: 17791949 . Total output tokens: 15666598
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 2.232152195647359,
    "estimated_duration": 3600.00038486636,
    "input_throughput": 1828.7467489380265,
    "output_throughput": 1594.3451073306117,
    "total_throughput": 3423.091856268638,
    "itl": 34.40830967734529,
    "ttft": 9340.074510798604,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2792,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.37545741502151,
    "arrivals": 26760,
    "finished_requests": 26691,
    "scheduler_time": 4.623150332084917
}
#Debug simulation 
Total elapsed time: 2.232221888843924. Arrivals time: 0.07288790494203568 Scheduler time: 1.7928195791319013 Scheduler overhead time: 0.09766473853960633 Adapter cache time: 0.12568351021036506 Engine time: 0.0961798089556396 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-32/adapters_192_slots_96_rate_0.1-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-32/adapters_192_slots_96_rate_0.1-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [64 64 64]
Adapter prompts. [1080, 33, 1080, 33, 1080, 33, 1080, 33, 33, 33, 135, 135, 135, 135, 1080, 135, 33, 1080, 33, 135, 135, 33, 1080, 1080, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 1080, 135, 33, 135, 1080, 1080, 135, 1080, 33, 135, 135, 1080, 135, 33, 33, 135, 1080, 33, 135, 33, 1080, 1080, 135, 1080, 1080, 1080, 33, 135, 1080, 33, 135, 33, 135, 33, 33, 135, 1080, 1080, 33, 33, 33, 1080, 1080, 1080, 135, 33, 33, 33, 33, 33, 1080, 33, 135, 33, 1080, 1080, 33, 1080, 33, 135, 135, 1080, 33, 33, 33, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 135, 33, 1080, 135, 135, 135, 1080, 135, 33, 135, 1080, 1080, 135, 1080, 135, 33, 1080, 135, 33, 135, 135, 33, 135, 1080, 33, 135, 1080, 33, 135, 1080, 1080, 135, 33, 1080, 135, 33, 33, 135, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 135, 33, 1080, 1080, 135, 1080, 33, 1080, 1080, 1080, 33, 1080, 1080, 1080, 135, 135, 135, 135, 135, 135, 33, 1080, 135, 1080, 33, 1080, 135, 33, 135, 33, 33, 135, 135, 135, 1080, 135, 33, 33]
Prompts retrieved: 79872 . Total input tokens: 17791949 . Total output tokens: 15666598
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 2.213459173217416,
    "estimated_duration": 3600.0060420688524,
    "input_throughput": 1828.7438751676648,
    "output_throughput": 1594.3426019089513,
    "total_throughput": 3423.086477076616,
    "itl": 34.41840736917539,
    "ttft": 9340.150711193888,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2792,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.916486752438587,
    "arrivals": 26760,
    "finished_requests": 26691,
    "scheduler_time": 4.627316817865419
}
#Debug simulation 
Total elapsed time: 2.2135391519404948. Arrivals time: 0.0722672282718122 Scheduler time: 1.7743679820559919 Scheduler overhead time: 0.0969568844884634 Adapter cache time: 0.12639933405444026 Engine time: 0.09681250620633364 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-16/adapters_192_slots_96_rate_0.1-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-16/adapters_192_slots_96_rate_0.1-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [64 64 64]
Adapter prompts. [1080, 33, 1080, 33, 1080, 33, 1080, 33, 33, 33, 135, 135, 135, 135, 1080, 135, 33, 1080, 33, 135, 135, 33, 1080, 1080, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 1080, 135, 33, 135, 1080, 1080, 135, 1080, 33, 135, 135, 1080, 135, 33, 33, 135, 1080, 33, 135, 33, 1080, 1080, 135, 1080, 1080, 1080, 33, 135, 1080, 33, 135, 33, 135, 33, 33, 135, 1080, 1080, 33, 33, 33, 1080, 1080, 1080, 135, 33, 33, 33, 33, 33, 1080, 33, 135, 33, 1080, 1080, 33, 1080, 33, 135, 135, 1080, 33, 33, 33, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 135, 33, 1080, 135, 135, 135, 1080, 135, 33, 135, 1080, 1080, 135, 1080, 135, 33, 1080, 135, 33, 135, 135, 33, 135, 1080, 33, 135, 1080, 33, 135, 1080, 1080, 135, 33, 1080, 135, 33, 33, 135, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 135, 33, 1080, 1080, 135, 1080, 33, 1080, 1080, 1080, 33, 1080, 1080, 1080, 135, 135, 135, 135, 135, 135, 33, 1080, 135, 1080, 33, 1080, 135, 33, 135, 33, 33, 135, 135, 135, 1080, 135, 33, 33]
Prompts retrieved: 79872 . Total input tokens: 17791949 . Total output tokens: 15666598
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 2.2441012752242386,
    "estimated_duration": 3599.989368297498,
    "input_throughput": 1828.7523452085788,
    "output_throughput": 1594.349986292983,
    "total_throughput": 3423.102331501562,
    "itl": 34.38517135061707,
    "ttft": 9340.032321976769,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2792,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.02471840798905,
    "arrivals": 26760,
    "finished_requests": 26691,
    "scheduler_time": 4.612580748185104
}
#Debug simulation 
Total elapsed time: 2.2442026622593403. Arrivals time: 0.07309949025511742 Scheduler time: 1.8005810482427478 Scheduler overhead time: 0.09757030941545963 Adapter cache time: 0.12640523491427302 Engine time: 0.09925814624875784 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-32/adapters_192_slots_96_rate_0.1-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-32/adapters_192_slots_96_rate_0.1-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [64 64 64]
Adapter prompts. [1080, 33, 1080, 33, 1080, 33, 1080, 33, 33, 33, 135, 135, 135, 135, 1080, 135, 33, 1080, 33, 135, 135, 33, 1080, 1080, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 1080, 135, 33, 135, 1080, 1080, 135, 1080, 33, 135, 135, 1080, 135, 33, 33, 135, 1080, 33, 135, 33, 1080, 1080, 135, 1080, 1080, 1080, 33, 135, 1080, 33, 135, 33, 135, 33, 33, 135, 1080, 1080, 33, 33, 33, 1080, 1080, 1080, 135, 33, 33, 33, 33, 33, 1080, 33, 135, 33, 1080, 1080, 33, 1080, 33, 135, 135, 1080, 33, 33, 33, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 135, 33, 1080, 135, 135, 135, 1080, 135, 33, 135, 1080, 1080, 135, 1080, 135, 33, 1080, 135, 33, 135, 135, 33, 135, 1080, 33, 135, 1080, 33, 135, 1080, 1080, 135, 33, 1080, 135, 33, 33, 135, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 135, 33, 1080, 1080, 135, 1080, 33, 1080, 1080, 1080, 33, 1080, 1080, 1080, 135, 135, 135, 135, 135, 135, 33, 1080, 135, 1080, 33, 1080, 135, 33, 135, 33, 33, 135, 135, 135, 1080, 135, 33, 33]
Prompts retrieved: 79872 . Total input tokens: 17791949 . Total output tokens: 15666598
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 2.227726727258414,
    "estimated_duration": 3600.0153032769454,
    "input_throughput": 1828.7391706383364,
    "output_throughput": 1594.3385003878843,
    "total_throughput": 3423.0776710262207,
    "itl": 34.41339468873198,
    "ttft": 9340.122356686625,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2791,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.708801589790006,
    "arrivals": 26760,
    "finished_requests": 26691,
    "scheduler_time": 4.625684049890771
}
#Debug simulation 
Total elapsed time: 2.2278086631558836. Arrivals time: 0.07297304226085544 Scheduler time: 1.7843809914775193 Scheduler overhead time: 0.09799378225579858 Adapter cache time: 0.12598676141351461 Engine time: 0.09921588748693466 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-16/adapters_192_slots_96_rate_0.1-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-16/adapters_192_slots_96_rate_0.1-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [64 64 64]
Adapter prompts. [1080, 33, 1080, 33, 1080, 33, 1080, 33, 33, 33, 135, 135, 135, 135, 1080, 135, 33, 1080, 33, 135, 135, 33, 1080, 1080, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 1080, 135, 33, 135, 1080, 1080, 135, 1080, 33, 135, 135, 1080, 135, 33, 33, 135, 1080, 33, 135, 33, 1080, 1080, 135, 1080, 1080, 1080, 33, 135, 1080, 33, 135, 33, 135, 33, 33, 135, 1080, 1080, 33, 33, 33, 1080, 1080, 1080, 135, 33, 33, 33, 33, 33, 1080, 33, 135, 33, 1080, 1080, 33, 1080, 33, 135, 135, 1080, 33, 33, 33, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 135, 33, 1080, 135, 135, 135, 1080, 135, 33, 135, 1080, 1080, 135, 1080, 135, 33, 1080, 135, 33, 135, 135, 33, 135, 1080, 33, 135, 1080, 33, 135, 1080, 1080, 135, 33, 1080, 135, 33, 33, 135, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 135, 33, 1080, 1080, 135, 1080, 33, 1080, 1080, 1080, 33, 1080, 1080, 1080, 135, 135, 135, 135, 135, 135, 33, 1080, 135, 1080, 33, 1080, 135, 33, 135, 33, 33, 135, 135, 135, 1080, 135, 33, 33]
Prompts retrieved: 79872 . Total input tokens: 17791949 . Total output tokens: 15666598
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 2.2151466649957,
    "estimated_duration": 3599.9863205793163,
    "input_throughput": 1828.753893414954,
    "output_throughput": 1594.35133605629,
    "total_throughput": 3423.105229471244,
    "itl": 34.531646744024584,
    "ttft": 9340.19731004063,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2790,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.811139424193055,
    "arrivals": 26760,
    "finished_requests": 26691,
    "scheduler_time": 4.682105286598264
}
#Debug simulation 
Total elapsed time: 2.2152168108150363. Arrivals time: 0.07430338999256492 Scheduler time: 1.7762191519141197 Scheduler overhead time: 0.0979258636943996 Adapter cache time: 0.1244756793603301 Engine time: 0.09526021033525467 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-32/adapters_192_slots_96_rate_0.1-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-32/adapters_192_slots_96_rate_0.1-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [64 64 64]
Adapter prompts. [1080, 33, 1080, 33, 1080, 33, 1080, 33, 33, 33, 135, 135, 135, 135, 1080, 135, 33, 1080, 33, 135, 135, 33, 1080, 1080, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 1080, 135, 33, 135, 1080, 1080, 135, 1080, 33, 135, 135, 1080, 135, 33, 33, 135, 1080, 33, 135, 33, 1080, 1080, 135, 1080, 1080, 1080, 33, 135, 1080, 33, 135, 33, 135, 33, 33, 135, 1080, 1080, 33, 33, 33, 1080, 1080, 1080, 135, 33, 33, 33, 33, 33, 1080, 33, 135, 33, 1080, 1080, 33, 1080, 33, 135, 135, 1080, 33, 33, 33, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 135, 33, 1080, 135, 135, 135, 1080, 135, 33, 135, 1080, 1080, 135, 1080, 135, 33, 1080, 135, 33, 135, 135, 33, 135, 1080, 33, 135, 1080, 33, 135, 1080, 1080, 135, 33, 1080, 135, 33, 33, 135, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 135, 33, 1080, 1080, 135, 1080, 33, 1080, 1080, 1080, 33, 1080, 1080, 1080, 135, 135, 135, 135, 135, 135, 33, 1080, 135, 1080, 33, 1080, 135, 33, 135, 33, 33, 135, 135, 135, 1080, 135, 33, 33]
Prompts retrieved: 79872 . Total input tokens: 17791949 . Total output tokens: 15666598
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 2.2259872928261757,
    "estimated_duration": 3599.981266640163,
    "input_throughput": 1828.756460764676,
    "output_throughput": 1594.3535743331154,
    "total_throughput": 3423.1100350977913,
    "itl": 34.411308839047216,
    "ttft": 9340.030070963916,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2791,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.52964523201827,
    "arrivals": 26760,
    "finished_requests": 26691,
    "scheduler_time": 4.624123462850858
}
#Debug simulation 
Total elapsed time: 2.22607896104455. Arrivals time: 0.07274880958721042 Scheduler time: 1.786716828122735 Scheduler overhead time: 0.09713528910651803 Adapter cache time: 0.12558464985340834 Engine time: 0.09662521351128817 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-8/adapters_192_slots_96_rate_0.1-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-8/adapters_192_slots_96_rate_0.1-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [64 64 64]
Adapter prompts. [1080, 33, 1080, 33, 1080, 33, 1080, 33, 33, 33, 66, 66, 66, 66, 1080, 66, 33, 1080, 33, 66, 66, 33, 1080, 1080, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 1080, 66, 33, 66, 1080, 1080, 66, 1080, 33, 66, 66, 1080, 66, 33, 33, 66, 1080, 33, 66, 33, 1080, 1080, 66, 1080, 1080, 1080, 33, 66, 1080, 33, 66, 33, 66, 33, 33, 66, 1080, 1080, 33, 33, 33, 1080, 1080, 1080, 66, 33, 33, 33, 33, 33, 1080, 33, 66, 33, 1080, 1080, 33, 1080, 33, 66, 66, 1080, 33, 33, 33, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 66, 33, 1080, 66, 66, 66, 1080, 66, 33, 66, 1080, 1080, 66, 1080, 66, 33, 1080, 66, 33, 66, 66, 33, 66, 1080, 33, 66, 1080, 33, 66, 1080, 1080, 66, 33, 1080, 66, 33, 33, 66, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 66, 33, 1080, 1080, 66, 1080, 33, 1080, 1080, 1080, 33, 1080, 1080, 1080, 66, 66, 66, 66, 66, 66, 33, 1080, 66, 1080, 33, 1080, 66, 33, 66, 33, 33, 66, 66, 66, 1080, 66, 33, 33]
Prompts retrieved: 75456 . Total input tokens: 16817117 . Total output tokens: 14790284
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 2.131873407866806,
    "estimated_duration": 3599.871288526746,
    "input_throughput": 1705.6357041345316,
    "output_throughput": 1511.2565322374248,
    "total_throughput": 3216.892236371956,
    "itl": 32.60424686910101,
    "ttft": 7583.412202569525,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1693,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.194808491091537,
    "arrivals": 25342,
    "finished_requests": 25289,
    "scheduler_time": 2.7590788919031324
}
#Debug simulation 
Total elapsed time: 2.131940918043256. Arrivals time: 0.06919405004009604 Scheduler time: 1.6925196703523397 Scheduler overhead time: 0.10166430054232478 Adapter cache time: 0.11780419806018472 Engine time: 0.10148180834949017 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-16/adapters_192_slots_96_rate_0.1-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-16/adapters_192_slots_96_rate_0.1-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [64 64 64]
Adapter prompts. [1080, 33, 1080, 33, 1080, 33, 1080, 33, 33, 33, 66, 66, 66, 66, 1080, 66, 33, 1080, 33, 66, 66, 33, 1080, 1080, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 1080, 66, 33, 66, 1080, 1080, 66, 1080, 33, 66, 66, 1080, 66, 33, 33, 66, 1080, 33, 66, 33, 1080, 1080, 66, 1080, 1080, 1080, 33, 66, 1080, 33, 66, 33, 66, 33, 33, 66, 1080, 1080, 33, 33, 33, 1080, 1080, 1080, 66, 33, 33, 33, 33, 33, 1080, 33, 66, 33, 1080, 1080, 33, 1080, 33, 66, 66, 1080, 33, 33, 33, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 66, 33, 1080, 66, 66, 66, 1080, 66, 33, 66, 1080, 1080, 66, 1080, 66, 33, 1080, 66, 33, 66, 66, 33, 66, 1080, 33, 66, 1080, 33, 66, 1080, 1080, 66, 33, 1080, 66, 33, 33, 66, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 66, 33, 1080, 1080, 66, 1080, 33, 1080, 1080, 1080, 33, 1080, 1080, 1080, 66, 66, 66, 66, 66, 66, 33, 1080, 66, 1080, 33, 1080, 66, 33, 66, 33, 33, 66, 66, 66, 1080, 66, 33, 33]
Prompts retrieved: 75456 . Total input tokens: 16817117 . Total output tokens: 14790284
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 2.1747231921181083,
    "estimated_duration": 3599.8799138674226,
    "input_throughput": 1705.6316174179271,
    "output_throughput": 1511.2529112548498,
    "total_throughput": 3216.884528672777,
    "itl": 32.62111708471223,
    "ttft": 7583.340228950972,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1692,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.35501350058227,
    "arrivals": 25342,
    "finished_requests": 25289,
    "scheduler_time": 2.7660739915924992
}
#Debug simulation 
Total elapsed time: 2.174799133092165. Arrivals time: 0.07003740407526493 Scheduler time: 1.7345397458411753 Scheduler overhead time: 0.10181141598150134 Adapter cache time: 0.11646539811044931 Engine time: 0.10251141106709838 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-32/adapters_192_slots_96_rate_0.1-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-32/adapters_192_slots_96_rate_0.1-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [64 64 64]
Adapter prompts. [1080, 33, 1080, 33, 1080, 33, 1080, 33, 33, 33, 66, 66, 66, 66, 1080, 66, 33, 1080, 33, 66, 66, 33, 1080, 1080, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 1080, 66, 33, 66, 1080, 1080, 66, 1080, 33, 66, 66, 1080, 66, 33, 33, 66, 1080, 33, 66, 33, 1080, 1080, 66, 1080, 1080, 1080, 33, 66, 1080, 33, 66, 33, 66, 33, 33, 66, 1080, 1080, 33, 33, 33, 1080, 1080, 1080, 66, 33, 33, 33, 33, 33, 1080, 33, 66, 33, 1080, 1080, 33, 1080, 33, 66, 66, 1080, 33, 33, 33, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 66, 33, 1080, 66, 66, 66, 1080, 66, 33, 66, 1080, 1080, 66, 1080, 66, 33, 1080, 66, 33, 66, 66, 33, 66, 1080, 33, 66, 1080, 33, 66, 1080, 1080, 66, 33, 1080, 66, 33, 33, 66, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 66, 33, 1080, 1080, 66, 1080, 33, 1080, 1080, 1080, 33, 1080, 1080, 1080, 66, 66, 66, 66, 66, 66, 33, 1080, 66, 1080, 33, 1080, 66, 33, 66, 33, 33, 66, 66, 66, 1080, 66, 33, 33]
Prompts retrieved: 75456 . Total input tokens: 16817117 . Total output tokens: 14790284
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 2.1269239420071244,
    "estimated_duration": 3599.903198487464,
    "input_throughput": 1705.6205851812383,
    "output_throughput": 1511.2431362837226,
    "total_throughput": 3216.863721464961,
    "itl": 32.625367124245564,
    "ttft": 7583.447404903036,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1693,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.693646157514108,
    "arrivals": 25342,
    "finished_requests": 25289,
    "scheduler_time": 2.7683553884497645
}
#Debug simulation 
Total elapsed time: 2.126992018893361. Arrivals time: 0.06963141495361924 Scheduler time: 1.687755606137216 Scheduler overhead time: 0.10129862744361162 Adapter cache time: 0.11675793817266822 Engine time: 0.10267147328704596 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-16/adapters_192_slots_96_rate_0.1-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-16/adapters_192_slots_96_rate_0.1-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [64 64 64]
Adapter prompts. [1080, 33, 1080, 33, 1080, 33, 1080, 33, 33, 33, 66, 66, 66, 66, 1080, 66, 33, 1080, 33, 66, 66, 33, 1080, 1080, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 1080, 66, 33, 66, 1080, 1080, 66, 1080, 33, 66, 66, 1080, 66, 33, 33, 66, 1080, 33, 66, 33, 1080, 1080, 66, 1080, 1080, 1080, 33, 66, 1080, 33, 66, 33, 66, 33, 33, 66, 1080, 1080, 33, 33, 33, 1080, 1080, 1080, 66, 33, 33, 33, 33, 33, 1080, 33, 66, 33, 1080, 1080, 33, 1080, 33, 66, 66, 1080, 33, 33, 33, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 66, 33, 1080, 66, 66, 66, 1080, 66, 33, 66, 1080, 1080, 66, 1080, 66, 33, 1080, 66, 33, 66, 66, 33, 66, 1080, 33, 66, 1080, 33, 66, 1080, 1080, 66, 33, 1080, 66, 33, 33, 66, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 66, 33, 1080, 1080, 66, 1080, 33, 1080, 1080, 1080, 33, 1080, 1080, 1080, 66, 66, 66, 66, 66, 66, 33, 1080, 66, 1080, 33, 1080, 66, 33, 66, 33, 33, 66, 66, 66, 1080, 66, 33, 33]
Prompts retrieved: 75456 . Total input tokens: 16817117 . Total output tokens: 14790284
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 2.115282327402383,
    "estimated_duration": 3599.879113626858,
    "input_throughput": 1705.6319965738837,
    "output_throughput": 1511.2532472010982,
    "total_throughput": 3216.885243774982,
    "itl": 32.608514131725265,
    "ttft": 7583.490555774119,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1693,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.536794163375326,
    "arrivals": 25342,
    "finished_requests": 25289,
    "scheduler_time": 2.760987457556624
}
#Debug simulation 
Total elapsed time: 2.115360183175653. Arrivals time: 0.06889746896922588 Scheduler time: 1.6818627286702394 Scheduler overhead time: 0.10027984157204628 Adapter cache time: 0.11611426994204521 Engine time: 0.09961143182590604 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-32/adapters_192_slots_96_rate_0.1-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-32/adapters_192_slots_96_rate_0.1-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [64 64 64]
Adapter prompts. [1080, 33, 1080, 33, 1080, 33, 1080, 33, 33, 33, 66, 66, 66, 66, 1080, 66, 33, 1080, 33, 66, 66, 33, 1080, 1080, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 1080, 66, 33, 66, 1080, 1080, 66, 1080, 33, 66, 66, 1080, 66, 33, 33, 66, 1080, 33, 66, 33, 1080, 1080, 66, 1080, 1080, 1080, 33, 66, 1080, 33, 66, 33, 66, 33, 33, 66, 1080, 1080, 33, 33, 33, 1080, 1080, 1080, 66, 33, 33, 33, 33, 33, 1080, 33, 66, 33, 1080, 1080, 33, 1080, 33, 66, 66, 1080, 33, 33, 33, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 66, 33, 1080, 66, 66, 66, 1080, 66, 33, 66, 1080, 1080, 66, 1080, 66, 33, 1080, 66, 33, 66, 66, 33, 66, 1080, 33, 66, 1080, 33, 66, 1080, 1080, 66, 33, 1080, 66, 33, 33, 66, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 66, 33, 1080, 1080, 66, 1080, 33, 1080, 1080, 1080, 33, 1080, 1080, 1080, 66, 66, 66, 66, 66, 66, 33, 1080, 66, 1080, 33, 1080, 66, 33, 66, 33, 33, 66, 66, 66, 1080, 66, 33, 33]
Prompts retrieved: 75456 . Total input tokens: 16817117 . Total output tokens: 14790284
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 2.167499360162765,
    "estimated_duration": 3599.8751027640405,
    "input_throughput": 1705.633896933135,
    "output_throughput": 1511.2549309899196,
    "total_throughput": 3216.8888279230546,
    "itl": 32.62441883534571,
    "ttft": 7583.496010761976,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1693,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.570411437428367,
    "arrivals": 25342,
    "finished_requests": 25289,
    "scheduler_time": 2.7672317658003105
}
#Debug simulation 
Total elapsed time: 2.1675772382877767. Arrivals time: 0.07064744923263788 Scheduler time: 1.7266053552739322 Scheduler overhead time: 0.10195189621299505 Adapter cache time: 0.11699133226647973 Engine time: 0.10228104004636407 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-16/adapters_192_slots_96_rate_0.1-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-16/adapters_192_slots_96_rate_0.1-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [64 64 64]
Adapter prompts. [1080, 33, 1080, 33, 1080, 33, 1080, 33, 33, 33, 66, 66, 66, 66, 1080, 66, 33, 1080, 33, 66, 66, 33, 1080, 1080, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 1080, 66, 33, 66, 1080, 1080, 66, 1080, 33, 66, 66, 1080, 66, 33, 33, 66, 1080, 33, 66, 33, 1080, 1080, 66, 1080, 1080, 1080, 33, 66, 1080, 33, 66, 33, 66, 33, 33, 66, 1080, 1080, 33, 33, 33, 1080, 1080, 1080, 66, 33, 33, 33, 33, 33, 1080, 33, 66, 33, 1080, 1080, 33, 1080, 33, 66, 66, 1080, 33, 33, 33, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 66, 33, 1080, 66, 66, 66, 1080, 66, 33, 66, 1080, 1080, 66, 1080, 66, 33, 1080, 66, 33, 66, 66, 33, 66, 1080, 33, 66, 1080, 33, 66, 1080, 1080, 66, 33, 1080, 66, 33, 33, 66, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 66, 33, 1080, 1080, 66, 1080, 33, 1080, 1080, 1080, 33, 1080, 1080, 1080, 66, 66, 66, 66, 66, 66, 33, 1080, 66, 1080, 33, 1080, 66, 33, 66, 33, 33, 66, 66, 66, 1080, 66, 33, 33]
Prompts retrieved: 75456 . Total input tokens: 16817117 . Total output tokens: 14790284
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 2.125478769186884,
    "estimated_duration": 3599.891357538787,
    "input_throughput": 1705.6261953966048,
    "output_throughput": 1511.2481071427399,
    "total_throughput": 3216.8743025393446,
    "itl": 32.59801698554108,
    "ttft": 7583.168153020548,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1693,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.807978152386246,
    "arrivals": 25342,
    "finished_requests": 25289,
    "scheduler_time": 2.7565480095533266
}
#Debug simulation 
Total elapsed time: 2.12554810103029. Arrivals time: 0.06943038012832403 Scheduler time: 1.687799493316561 Scheduler overhead time: 0.10085263522341847 Adapter cache time: 0.11619755532592535 Engine time: 0.10241994773969054 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-32/adapters_192_slots_96_rate_0.1-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-32/adapters_192_slots_96_rate_0.1-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [64 64 64]
Adapter prompts. [1080, 33, 1080, 33, 1080, 33, 1080, 33, 33, 33, 66, 66, 66, 66, 1080, 66, 33, 1080, 33, 66, 66, 33, 1080, 1080, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 1080, 66, 33, 66, 1080, 1080, 66, 1080, 33, 66, 66, 1080, 66, 33, 33, 66, 1080, 33, 66, 33, 1080, 1080, 66, 1080, 1080, 1080, 33, 66, 1080, 33, 66, 33, 66, 33, 33, 66, 1080, 1080, 33, 33, 33, 1080, 1080, 1080, 66, 33, 33, 33, 33, 33, 1080, 33, 66, 33, 1080, 1080, 33, 1080, 33, 66, 66, 1080, 33, 33, 33, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 66, 33, 1080, 66, 66, 66, 1080, 66, 33, 66, 1080, 1080, 66, 1080, 66, 33, 1080, 66, 33, 66, 66, 33, 66, 1080, 33, 66, 1080, 33, 66, 1080, 1080, 66, 33, 1080, 66, 33, 33, 66, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 66, 33, 1080, 1080, 66, 1080, 33, 1080, 1080, 1080, 33, 1080, 1080, 1080, 66, 66, 66, 66, 66, 66, 33, 1080, 66, 1080, 33, 1080, 66, 33, 66, 33, 33, 66, 66, 66, 1080, 66, 33, 33]
Prompts retrieved: 75456 . Total input tokens: 16817117 . Total output tokens: 14790284
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 2.1486918050795794,
    "estimated_duration": 3599.8741621012828,
    "input_throughput": 1705.6343426226822,
    "output_throughput": 1511.2553258873986,
    "total_throughput": 3216.889668510081,
    "itl": 32.62312208104974,
    "ttft": 7583.458338316617,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1693,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.461674919705652,
    "arrivals": 25342,
    "finished_requests": 25289,
    "scheduler_time": 2.7667617340815145
}
#Debug simulation 
Total elapsed time: 2.1487684240564704. Arrivals time: 0.06999810179695487 Scheduler time: 1.7074545272625983 Scheduler overhead time: 0.10087468242272735 Adapter cache time: 0.11743917735293508 Engine time: 0.10388683248311281 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-8/adapters_192_slots_96_rate_0.05-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-8/adapters_192_slots_96_rate_0.05-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [64 64 64]
Adapter prompts. [540, 135, 540, 135, 540, 135, 540, 135, 135, 135, 270, 270, 270, 270, 540, 270, 135, 540, 135, 270, 270, 135, 540, 540, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 540, 270, 135, 270, 540, 540, 270, 540, 135, 270, 270, 540, 270, 135, 135, 270, 540, 135, 270, 135, 540, 540, 270, 540, 540, 540, 135, 270, 540, 135, 270, 135, 270, 135, 135, 270, 540, 540, 135, 135, 135, 540, 540, 540, 270, 135, 135, 135, 135, 135, 540, 135, 270, 135, 540, 540, 135, 540, 135, 270, 270, 540, 135, 135, 135, 540, 540, 270, 540, 270, 540, 540, 270, 270, 135, 540, 270, 270, 270, 540, 270, 135, 270, 540, 540, 270, 540, 270, 135, 540, 270, 135, 270, 270, 135, 270, 540, 135, 270, 540, 135, 270, 540, 540, 270, 135, 540, 270, 135, 135, 270, 540, 540, 540, 135, 540, 135, 540, 135, 270, 135, 540, 540, 270, 540, 135, 540, 540, 540, 135, 540, 540, 540, 270, 270, 270, 270, 270, 270, 135, 540, 270, 540, 135, 540, 270, 135, 270, 135, 135, 270, 270, 270, 540, 270, 135, 135]
Prompts retrieved: 60480 . Total input tokens: 13439077 . Total output tokens: 11901760
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 1.83812005398795,
    "estimated_duration": 3599.533004812037,
    "input_throughput": 1382.4382199989989,
    "output_throughput": 1206.2450862918897,
    "total_throughput": 2588.6833062908886,
    "itl": 30.86701188851541,
    "ttft": 9271.19385694159,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8159,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 53.95064529168281,
    "arrivals": 20309,
    "finished_requests": 20257,
    "scheduler_time": 0.28781298914417636
}
#Debug simulation 
Total elapsed time: 1.8381886258721352. Arrivals time: 0.05889766709879041 Scheduler time: 1.3744987230747938 Scheduler overhead time: 0.10606681369245052 Adapter cache time: 0.14410841977223754 Engine time: 0.10331818368285894 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-16/adapters_192_slots_96_rate_0.05-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-16/adapters_192_slots_96_rate_0.05-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [64 64 64]
Adapter prompts. [540, 135, 540, 135, 540, 135, 540, 135, 135, 135, 270, 270, 270, 270, 540, 270, 135, 540, 135, 270, 270, 135, 540, 540, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 540, 270, 135, 270, 540, 540, 270, 540, 135, 270, 270, 540, 270, 135, 135, 270, 540, 135, 270, 135, 540, 540, 270, 540, 540, 540, 135, 270, 540, 135, 270, 135, 270, 135, 135, 270, 540, 540, 135, 135, 135, 540, 540, 540, 270, 135, 135, 135, 135, 135, 540, 135, 270, 135, 540, 540, 135, 540, 135, 270, 270, 540, 135, 135, 135, 540, 540, 270, 540, 270, 540, 540, 270, 270, 135, 540, 270, 270, 270, 540, 270, 135, 270, 540, 540, 270, 540, 270, 135, 540, 270, 135, 270, 270, 135, 270, 540, 135, 270, 540, 135, 270, 540, 540, 270, 135, 540, 270, 135, 135, 270, 540, 540, 540, 135, 540, 135, 540, 135, 270, 135, 540, 540, 270, 540, 135, 540, 540, 540, 135, 540, 540, 540, 270, 270, 270, 270, 270, 270, 135, 540, 270, 540, 135, 540, 270, 135, 270, 135, 135, 270, 270, 270, 540, 270, 135, 135]
Prompts retrieved: 60480 . Total input tokens: 13439077 . Total output tokens: 11901760
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 1.8421049187891185,
    "estimated_duration": 3599.5206964376666,
    "input_throughput": 1382.4429471748065,
    "output_throughput": 1206.249210984413,
    "total_throughput": 2588.6921581592196,
    "itl": 30.946677854830945,
    "ttft": 9271.571691784859,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 59.493400883784545,
    "arrivals": 20309,
    "finished_requests": 20257,
    "scheduler_time": 0.29586165858644925
}
#Debug simulation 
Total elapsed time: 1.842190899886191. Arrivals time: 0.05984822893515229 Scheduler time: 1.3801868143491447 Scheduler overhead time: 0.10425830725580454 Adapter cache time: 0.14346937742084265 Engine time: 0.10366214951500297 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-32/adapters_192_slots_96_rate_0.05-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-32/adapters_192_slots_96_rate_0.05-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [64 64 64]
Adapter prompts. [540, 135, 540, 135, 540, 135, 540, 135, 135, 135, 270, 270, 270, 270, 540, 270, 135, 540, 135, 270, 270, 135, 540, 540, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 540, 270, 135, 270, 540, 540, 270, 540, 135, 270, 270, 540, 270, 135, 135, 270, 540, 135, 270, 135, 540, 540, 270, 540, 540, 540, 135, 270, 540, 135, 270, 135, 270, 135, 135, 270, 540, 540, 135, 135, 135, 540, 540, 540, 270, 135, 135, 135, 135, 135, 540, 135, 270, 135, 540, 540, 135, 540, 135, 270, 270, 540, 135, 135, 135, 540, 540, 270, 540, 270, 540, 540, 270, 270, 135, 540, 270, 270, 270, 540, 270, 135, 270, 540, 540, 270, 540, 270, 135, 540, 270, 135, 270, 270, 135, 270, 540, 135, 270, 540, 135, 270, 540, 540, 270, 135, 540, 270, 135, 135, 270, 540, 540, 540, 135, 540, 135, 540, 135, 270, 135, 540, 540, 270, 540, 135, 540, 540, 540, 135, 540, 540, 540, 270, 270, 270, 270, 270, 270, 135, 540, 270, 540, 135, 540, 270, 135, 270, 135, 135, 270, 270, 270, 540, 270, 135, 135]
Prompts retrieved: 60480 . Total input tokens: 13439077 . Total output tokens: 11901760
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 1.8561114268377423,
    "estimated_duration": 3599.5189482134133,
    "input_throughput": 1382.4436186034957,
    "output_throughput": 1206.2497968388443,
    "total_throughput": 2588.6934154423398,
    "itl": 30.97344622836941,
    "ttft": 9271.755031972436,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 61.0648366324096,
    "arrivals": 20309,
    "finished_requests": 20257,
    "scheduler_time": 0.29818942516222957
}
#Debug simulation 
Total elapsed time: 1.8561927108094096. Arrivals time: 0.06028445530682802 Scheduler time: 1.3911845809780061 Scheduler overhead time: 0.1058498783968389 Adapter cache time: 0.14252004958689213 Engine time: 0.10547159239649773 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-16/adapters_192_slots_96_rate_0.05-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-16/adapters_192_slots_96_rate_0.05-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [64 64 64]
Adapter prompts. [540, 135, 540, 135, 540, 135, 540, 135, 135, 135, 270, 270, 270, 270, 540, 270, 135, 540, 135, 270, 270, 135, 540, 540, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 540, 270, 135, 270, 540, 540, 270, 540, 135, 270, 270, 540, 270, 135, 135, 270, 540, 135, 270, 135, 540, 540, 270, 540, 540, 540, 135, 270, 540, 135, 270, 135, 270, 135, 135, 270, 540, 540, 135, 135, 135, 540, 540, 540, 270, 135, 135, 135, 135, 135, 540, 135, 270, 135, 540, 540, 135, 540, 135, 270, 270, 540, 135, 135, 135, 540, 540, 270, 540, 270, 540, 540, 270, 270, 135, 540, 270, 270, 270, 540, 270, 135, 270, 540, 540, 270, 540, 270, 135, 540, 270, 135, 270, 270, 135, 270, 540, 135, 270, 540, 135, 270, 540, 540, 270, 135, 540, 270, 135, 135, 270, 540, 540, 540, 135, 540, 135, 540, 135, 270, 135, 540, 540, 270, 540, 135, 540, 540, 540, 135, 540, 540, 540, 270, 270, 270, 270, 270, 270, 135, 540, 270, 540, 135, 540, 270, 135, 270, 135, 135, 270, 270, 270, 540, 270, 135, 135]
Prompts retrieved: 60480 . Total input tokens: 13439077 . Total output tokens: 11901760
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 1.8472720352001488,
    "estimated_duration": 3599.539009345258,
    "input_throughput": 1382.4359138991908,
    "output_throughput": 1206.2430741068085,
    "total_throughput": 2588.6789880059996,
    "itl": 30.895960451861917,
    "ttft": 9271.372714308924,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8163,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 55.81849663662464,
    "arrivals": 20309,
    "finished_requests": 20257,
    "scheduler_time": 0.2904022923826459
}
#Debug simulation 
Total elapsed time: 1.8473739521577954. Arrivals time: 0.05955988308414817 Scheduler time: 1.3834353843703866 Scheduler overhead time: 0.10466381441801786 Adapter cache time: 0.14220507303252816 Engine time: 0.10642966395244002 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-32/adapters_192_slots_96_rate_0.05-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-32/adapters_192_slots_96_rate_0.05-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [64 64 64]
Adapter prompts. [540, 135, 540, 135, 540, 135, 540, 135, 135, 135, 270, 270, 270, 270, 540, 270, 135, 540, 135, 270, 270, 135, 540, 540, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 540, 270, 135, 270, 540, 540, 270, 540, 135, 270, 270, 540, 270, 135, 135, 270, 540, 135, 270, 135, 540, 540, 270, 540, 540, 540, 135, 270, 540, 135, 270, 135, 270, 135, 135, 270, 540, 540, 135, 135, 135, 540, 540, 540, 270, 135, 135, 135, 135, 135, 540, 135, 270, 135, 540, 540, 135, 540, 135, 270, 270, 540, 135, 135, 135, 540, 540, 270, 540, 270, 540, 540, 270, 270, 135, 540, 270, 270, 270, 540, 270, 135, 270, 540, 540, 270, 540, 270, 135, 540, 270, 135, 270, 270, 135, 270, 540, 135, 270, 540, 135, 270, 540, 540, 270, 135, 540, 270, 135, 135, 270, 540, 540, 540, 135, 540, 135, 540, 135, 270, 135, 540, 540, 270, 540, 135, 540, 540, 540, 135, 540, 540, 540, 270, 270, 270, 270, 270, 270, 135, 540, 270, 540, 135, 540, 270, 135, 270, 135, 135, 270, 270, 270, 540, 270, 135, 135]
Prompts retrieved: 60480 . Total input tokens: 13439077 . Total output tokens: 11901760
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 1.8501757900230587,
    "estimated_duration": 3599.5317000657556,
    "input_throughput": 1382.4387211006078,
    "output_throughput": 1206.2455235275975,
    "total_throughput": 2588.6842446282053,
    "itl": 30.96363981244853,
    "ttft": 9271.703962801674,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8158,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 60.500756174303206,
    "arrivals": 20309,
    "finished_requests": 20257,
    "scheduler_time": 0.2973689961258427
}
#Debug simulation 
Total elapsed time: 1.8502552122808993. Arrivals time: 0.05947011988610029 Scheduler time: 1.388145667500794 Scheduler overhead time: 0.10417529661208391 Adapter cache time: 0.14411732694134116 Engine time: 0.10352787747979164 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-16/adapters_192_slots_96_rate_0.05-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-16/adapters_192_slots_96_rate_0.05-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [64 64 64]
Adapter prompts. [540, 135, 540, 135, 540, 135, 540, 135, 135, 135, 270, 270, 270, 270, 540, 270, 135, 540, 135, 270, 270, 135, 540, 540, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 540, 270, 135, 270, 540, 540, 270, 540, 135, 270, 270, 540, 270, 135, 135, 270, 540, 135, 270, 135, 540, 540, 270, 540, 540, 540, 135, 270, 540, 135, 270, 135, 270, 135, 135, 270, 540, 540, 135, 135, 135, 540, 540, 540, 270, 135, 135, 135, 135, 135, 540, 135, 270, 135, 540, 540, 135, 540, 135, 270, 270, 540, 135, 135, 135, 540, 540, 270, 540, 270, 540, 540, 270, 270, 135, 540, 270, 270, 270, 540, 270, 135, 270, 540, 540, 270, 540, 270, 135, 540, 270, 135, 270, 270, 135, 270, 540, 135, 270, 540, 135, 270, 540, 540, 270, 135, 540, 270, 135, 135, 270, 540, 540, 540, 135, 540, 135, 540, 135, 270, 135, 540, 540, 270, 540, 135, 540, 540, 540, 135, 540, 540, 540, 270, 270, 270, 270, 270, 270, 135, 540, 270, 540, 135, 540, 270, 135, 270, 135, 135, 270, 270, 270, 540, 270, 135, 135]
Prompts retrieved: 60480 . Total input tokens: 13439077 . Total output tokens: 11901760
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 1.8409784780815244,
    "estimated_duration": 3599.5302747591995,
    "input_throughput": 1382.4392685050807,
    "output_throughput": 1206.2460011648227,
    "total_throughput": 2588.6852696699034,
    "itl": 30.84573738535399,
    "ttft": 9271.006047582305,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8163,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 52.11194663788311,
    "arrivals": 20309,
    "finished_requests": 20257,
    "scheduler_time": 0.28498149791124855
}
#Debug simulation 
Total elapsed time: 1.8410891680978239. Arrivals time: 0.05941245472058654 Scheduler time: 1.3761742734350264 Scheduler overhead time: 0.10473080165684223 Adapter cache time: 0.14462768007069826 Engine time: 0.10500264726579189 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-32/adapters_192_slots_96_rate_0.05-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-32/adapters_192_slots_96_rate_0.05-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [64 64 64]
Adapter prompts. [540, 135, 540, 135, 540, 135, 540, 135, 135, 135, 270, 270, 270, 270, 540, 270, 135, 540, 135, 270, 270, 135, 540, 540, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 540, 270, 135, 270, 540, 540, 270, 540, 135, 270, 270, 540, 270, 135, 135, 270, 540, 135, 270, 135, 540, 540, 270, 540, 540, 540, 135, 270, 540, 135, 270, 135, 270, 135, 135, 270, 540, 540, 135, 135, 135, 540, 540, 540, 270, 135, 135, 135, 135, 135, 540, 135, 270, 135, 540, 540, 135, 540, 135, 270, 270, 540, 135, 135, 135, 540, 540, 270, 540, 270, 540, 540, 270, 270, 135, 540, 270, 270, 270, 540, 270, 135, 270, 540, 540, 270, 540, 270, 135, 540, 270, 135, 270, 270, 135, 270, 540, 135, 270, 540, 135, 270, 540, 540, 270, 135, 540, 270, 135, 135, 270, 540, 540, 540, 135, 540, 135, 540, 135, 270, 135, 540, 540, 270, 540, 135, 540, 540, 540, 135, 540, 540, 540, 270, 270, 270, 270, 270, 270, 135, 540, 270, 540, 135, 540, 270, 135, 270, 135, 135, 270, 270, 270, 540, 270, 135, 135]
Prompts retrieved: 60480 . Total input tokens: 13439077 . Total output tokens: 11901760
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 1.8472019080072641,
    "estimated_duration": 3599.5314483036354,
    "input_throughput": 1382.4388177925548,
    "output_throughput": 1206.2456078960588,
    "total_throughput": 2588.6844256886134,
    "itl": 30.953076584464267,
    "ttft": 9271.666111596278,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8159,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 59.956036503292296,
    "arrivals": 20309,
    "finished_requests": 20257,
    "scheduler_time": 0.29651003722506974
}
#Debug simulation 
Total elapsed time: 1.8472743518650532. Arrivals time: 0.059468837920576334 Scheduler time: 1.3833982874639332 Scheduler overhead time: 0.10433418489992619 Adapter cache time: 0.14409311534836888 Engine time: 0.10503522073850036 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-8/adapters_192_slots_96_rate_0.05-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-8/adapters_192_slots_96_rate_0.05-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [64 64 64]
Adapter prompts. [540, 66, 540, 66, 540, 66, 540, 66, 66, 66, 270, 270, 270, 270, 540, 270, 66, 540, 66, 270, 270, 66, 540, 540, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 540, 270, 66, 270, 540, 540, 270, 540, 66, 270, 270, 540, 270, 66, 66, 270, 540, 66, 270, 66, 540, 540, 270, 540, 540, 540, 66, 270, 540, 66, 270, 66, 270, 66, 66, 270, 540, 540, 66, 66, 66, 540, 540, 540, 270, 66, 66, 66, 66, 66, 540, 66, 270, 66, 540, 540, 66, 540, 66, 270, 270, 540, 66, 66, 66, 540, 540, 270, 540, 270, 540, 540, 270, 270, 66, 540, 270, 270, 270, 540, 270, 66, 270, 540, 540, 270, 540, 270, 66, 540, 270, 66, 270, 270, 66, 270, 540, 66, 270, 540, 66, 270, 540, 540, 270, 66, 540, 270, 66, 66, 270, 540, 540, 540, 66, 540, 66, 540, 66, 270, 66, 540, 540, 270, 540, 66, 540, 540, 540, 66, 540, 540, 540, 270, 270, 270, 270, 270, 270, 66, 540, 270, 540, 66, 540, 270, 66, 270, 66, 66, 270, 270, 270, 540, 270, 66, 66]
Prompts retrieved: 56064 . Total input tokens: 12445053 . Total output tokens: 11033924
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 1.7605936168693006,
    "estimated_duration": 3600.013464331136,
    "input_throughput": 1292.4134995879658,
    "output_throughput": 1146.8784883467388,
    "total_throughput": 2439.2919879347046,
    "itl": 29.774656484445607,
    "ttft": 6715.014439348501,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6468,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 42.7690616186521,
    "arrivals": 18908,
    "finished_requests": 18873,
    "scheduler_time": 0.1494808100916764
}
#Debug simulation 
Total elapsed time: 1.760679897852242. Arrivals time: 0.055926756002008915 Scheduler time: 1.3057792903855443 Scheduler overhead time: 0.1071245213970542 Adapter cache time: 0.13080384163185954 Engine time: 0.10871594259515405 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-16/adapters_192_slots_96_rate_0.05-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-16/adapters_192_slots_96_rate_0.05-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [64 64 64]
Adapter prompts. [540, 66, 540, 66, 540, 66, 540, 66, 66, 66, 270, 270, 270, 270, 540, 270, 66, 540, 66, 270, 270, 66, 540, 540, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 540, 270, 66, 270, 540, 540, 270, 540, 66, 270, 270, 540, 270, 66, 66, 270, 540, 66, 270, 66, 540, 540, 270, 540, 540, 540, 66, 270, 540, 66, 270, 66, 270, 66, 66, 270, 540, 540, 66, 66, 66, 540, 540, 540, 270, 66, 66, 66, 66, 66, 540, 66, 270, 66, 540, 540, 66, 540, 66, 270, 270, 540, 66, 66, 66, 540, 540, 270, 540, 270, 540, 540, 270, 270, 66, 540, 270, 270, 270, 540, 270, 66, 270, 540, 540, 270, 540, 270, 66, 540, 270, 66, 270, 270, 66, 270, 540, 66, 270, 540, 66, 270, 540, 540, 270, 66, 540, 270, 66, 66, 270, 540, 540, 540, 66, 540, 66, 540, 66, 270, 66, 540, 540, 270, 540, 66, 540, 540, 540, 66, 540, 540, 540, 270, 270, 270, 270, 270, 270, 66, 540, 270, 540, 66, 540, 270, 66, 270, 66, 66, 270, 270, 270, 540, 270, 66, 66]
Prompts retrieved: 56064 . Total input tokens: 12445053 . Total output tokens: 11033924
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 1.756455393973738,
    "estimated_duration": 3600.0166019811463,
    "input_throughput": 1292.412373165041,
    "output_throughput": 1146.8774887670984,
    "total_throughput": 2439.2898619321395,
    "itl": 29.832505499878508,
    "ttft": 6715.478215522501,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6468,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 47.16198713974887,
    "arrivals": 18908,
    "finished_requests": 18873,
    "scheduler_time": 0.15311334030679596
}
#Debug simulation 
Total elapsed time: 1.75652715889737. Arrivals time: 0.055723427794873714 Scheduler time: 1.3026249697431922 Scheduler overhead time: 0.10670879064127803 Adapter cache time: 0.13144662138074636 Engine time: 0.10758139425888658 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-32/adapters_192_slots_96_rate_0.05-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-32/adapters_192_slots_96_rate_0.05-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [64 64 64]
Adapter prompts. [540, 66, 540, 66, 540, 66, 540, 66, 66, 66, 270, 270, 270, 270, 540, 270, 66, 540, 66, 270, 270, 66, 540, 540, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 540, 270, 66, 270, 540, 540, 270, 540, 66, 270, 270, 540, 270, 66, 66, 270, 540, 66, 270, 66, 540, 540, 270, 540, 540, 540, 66, 270, 540, 66, 270, 66, 270, 66, 66, 270, 540, 540, 66, 66, 66, 540, 540, 540, 270, 66, 66, 66, 66, 66, 540, 66, 270, 66, 540, 540, 66, 540, 66, 270, 270, 540, 66, 66, 66, 540, 540, 270, 540, 270, 540, 540, 270, 270, 66, 540, 270, 270, 270, 540, 270, 66, 270, 540, 540, 270, 540, 270, 66, 540, 270, 66, 270, 270, 66, 270, 540, 66, 270, 540, 66, 270, 540, 540, 270, 66, 540, 270, 66, 66, 270, 540, 540, 540, 66, 540, 66, 540, 66, 270, 66, 540, 540, 270, 540, 66, 540, 540, 540, 66, 540, 540, 540, 270, 270, 270, 270, 270, 270, 66, 540, 270, 540, 66, 540, 270, 66, 270, 66, 66, 270, 270, 270, 540, 270, 66, 66]
Prompts retrieved: 56064 . Total input tokens: 12445053 . Total output tokens: 11033924
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 1.771059712395072,
    "estimated_duration": 3600.012061785377,
    "input_throughput": 1292.4140031054656,
    "output_throughput": 1146.878935164564,
    "total_throughput": 2439.2929382700295,
    "itl": 29.85128409867798,
    "ttft": 6715.658742580702,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6470,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 48.42446840372694,
    "arrivals": 18908,
    "finished_requests": 18873,
    "scheduler_time": 0.15420965027599678
}
#Debug simulation 
Total elapsed time: 1.7711325851269066. Arrivals time: 0.055701743345707655 Scheduler time: 1.3194751455448568 Scheduler overhead time: 0.10682470398023725 Adapter cache time: 0.13100403267890215 Engine time: 0.10586275951936841 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-16/adapters_192_slots_96_rate_0.05-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-16/adapters_192_slots_96_rate_0.05-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [64 64 64]
Adapter prompts. [540, 66, 540, 66, 540, 66, 540, 66, 66, 66, 270, 270, 270, 270, 540, 270, 66, 540, 66, 270, 270, 66, 540, 540, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 540, 270, 66, 270, 540, 540, 270, 540, 66, 270, 270, 540, 270, 66, 66, 270, 540, 66, 270, 66, 540, 540, 270, 540, 540, 540, 66, 270, 540, 66, 270, 66, 270, 66, 66, 270, 540, 540, 66, 66, 66, 540, 540, 540, 270, 66, 66, 66, 66, 66, 540, 66, 270, 66, 540, 540, 66, 540, 66, 270, 270, 540, 66, 66, 66, 540, 540, 270, 540, 270, 540, 540, 270, 270, 66, 540, 270, 270, 270, 540, 270, 66, 270, 540, 540, 270, 540, 270, 66, 540, 270, 66, 270, 270, 66, 270, 540, 66, 270, 540, 66, 270, 540, 540, 270, 66, 540, 270, 66, 66, 270, 540, 540, 540, 66, 540, 66, 540, 66, 270, 66, 540, 540, 270, 540, 66, 540, 540, 540, 66, 540, 540, 540, 270, 270, 270, 270, 270, 270, 66, 540, 270, 540, 66, 540, 270, 66, 270, 66, 66, 270, 270, 270, 540, 270, 66, 66]
Prompts retrieved: 56064 . Total input tokens: 12445053 . Total output tokens: 11033924
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 1.7672924986109138,
    "estimated_duration": 3600.0310846582315,
    "input_throughput": 1292.4071738790844,
    "output_throughput": 1146.8728749579575,
    "total_throughput": 2439.2800488370417,
    "itl": 29.795055471407036,
    "ttft": 6715.262706824776,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6465,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 44.15260740041423,
    "arrivals": 18908,
    "finished_requests": 18873,
    "scheduler_time": 0.15065789109969902
}
#Debug simulation 
Total elapsed time: 1.7673711497336626. Arrivals time: 0.056163582019507885 Scheduler time: 1.3117252332158387 Scheduler overhead time: 0.1072687185369432 Adapter cache time: 0.13191830040886998 Engine time: 0.10806234274059534 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-32/adapters_192_slots_96_rate_0.05-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-32/adapters_192_slots_96_rate_0.05-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [64 64 64]
Adapter prompts. [540, 66, 540, 66, 540, 66, 540, 66, 66, 66, 270, 270, 270, 270, 540, 270, 66, 540, 66, 270, 270, 66, 540, 540, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 540, 270, 66, 270, 540, 540, 270, 540, 66, 270, 270, 540, 270, 66, 66, 270, 540, 66, 270, 66, 540, 540, 270, 540, 540, 540, 66, 270, 540, 66, 270, 66, 270, 66, 66, 270, 540, 540, 66, 66, 66, 540, 540, 540, 270, 66, 66, 66, 66, 66, 540, 66, 270, 66, 540, 540, 66, 540, 66, 270, 270, 540, 66, 66, 66, 540, 540, 270, 540, 270, 540, 540, 270, 270, 66, 540, 270, 270, 270, 540, 270, 66, 270, 540, 540, 270, 540, 270, 66, 540, 270, 66, 270, 270, 66, 270, 540, 66, 270, 540, 66, 270, 540, 540, 270, 66, 540, 270, 66, 66, 270, 540, 540, 540, 66, 540, 66, 540, 66, 270, 66, 540, 540, 270, 540, 66, 540, 540, 540, 66, 540, 540, 540, 270, 270, 270, 270, 270, 270, 66, 540, 270, 540, 66, 540, 270, 66, 270, 66, 66, 270, 270, 270, 540, 270, 66, 66]
Prompts retrieved: 56064 . Total input tokens: 12445053 . Total output tokens: 11033924
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 1.7574401679448783,
    "estimated_duration": 3600.012922351318,
    "input_throughput": 1292.4136941600543,
    "output_throughput": 1146.8786610086177,
    "total_throughput": 2439.2923551686717,
    "itl": 29.843987774180594,
    "ttft": 6715.50318618746,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6471,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 47.98662119584922,
    "arrivals": 18908,
    "finished_requests": 18873,
    "scheduler_time": 0.15375387957334197
}
#Debug simulation 
Total elapsed time: 1.7575107938610017. Arrivals time: 0.05583947664126754 Scheduler time: 1.3041308573447168 Scheduler overhead time: 0.10649451473727822 Adapter cache time: 0.13156769191846251 Engine time: 0.10751996003091335 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-16/adapters_192_slots_96_rate_0.05-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-16/adapters_192_slots_96_rate_0.05-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [64 64 64]
Adapter prompts. [540, 66, 540, 66, 540, 66, 540, 66, 66, 66, 270, 270, 270, 270, 540, 270, 66, 540, 66, 270, 270, 66, 540, 540, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 540, 270, 66, 270, 540, 540, 270, 540, 66, 270, 270, 540, 270, 66, 66, 270, 540, 66, 270, 66, 540, 540, 270, 540, 540, 540, 66, 270, 540, 66, 270, 66, 270, 66, 66, 270, 540, 540, 66, 66, 66, 540, 540, 540, 270, 66, 66, 66, 66, 66, 540, 66, 270, 66, 540, 540, 66, 540, 66, 270, 270, 540, 66, 66, 66, 540, 540, 270, 540, 270, 540, 540, 270, 270, 66, 540, 270, 270, 270, 540, 270, 66, 270, 540, 540, 270, 540, 270, 66, 540, 270, 66, 270, 270, 66, 270, 540, 66, 270, 540, 66, 270, 540, 540, 270, 66, 540, 270, 66, 66, 270, 540, 540, 540, 66, 540, 66, 540, 66, 270, 66, 540, 540, 270, 540, 66, 540, 540, 540, 66, 540, 540, 540, 270, 270, 270, 270, 270, 270, 66, 540, 270, 540, 66, 540, 270, 66, 270, 66, 66, 270, 270, 270, 540, 270, 66, 66]
Prompts retrieved: 56064 . Total input tokens: 12445053 . Total output tokens: 11033924
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 1.775271951686591,
    "estimated_duration": 3600.0123453519736,
    "input_throughput": 1292.4139013043036,
    "output_throughput": 1146.8788448269415,
    "total_throughput": 2439.292746131245,
    "itl": 29.75570944120116,
    "ttft": 6715.127754503673,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6466,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 41.278432801733466,
    "arrivals": 18908,
    "finished_requests": 18873,
    "scheduler_time": 0.148221123082794
}
#Debug simulation 
Total elapsed time: 1.775370717048645. Arrivals time: 0.05881806509569287 Scheduler time: 1.316790519747883 Scheduler overhead time: 0.10743425320833921 Adapter cache time: 0.1316307312808931 Engine time: 0.10838683461770415 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-32/adapters_192_slots_96_rate_0.05-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-32/adapters_192_slots_96_rate_0.05-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [64 64 64]
Adapter prompts. [540, 66, 540, 66, 540, 66, 540, 66, 66, 66, 270, 270, 270, 270, 540, 270, 66, 540, 66, 270, 270, 66, 540, 540, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 540, 270, 66, 270, 540, 540, 270, 540, 66, 270, 270, 540, 270, 66, 66, 270, 540, 66, 270, 66, 540, 540, 270, 540, 540, 540, 66, 270, 540, 66, 270, 66, 270, 66, 66, 270, 540, 540, 66, 66, 66, 540, 540, 540, 270, 66, 66, 66, 66, 66, 540, 66, 270, 66, 540, 540, 66, 540, 66, 270, 270, 540, 66, 66, 66, 540, 540, 270, 540, 270, 540, 540, 270, 270, 66, 540, 270, 270, 270, 540, 270, 66, 270, 540, 540, 270, 540, 270, 66, 540, 270, 66, 270, 270, 66, 270, 540, 66, 270, 540, 66, 270, 540, 540, 270, 66, 540, 270, 66, 66, 270, 540, 540, 540, 66, 540, 66, 540, 66, 270, 66, 540, 540, 270, 540, 66, 540, 540, 540, 66, 540, 540, 540, 270, 270, 270, 270, 270, 270, 66, 540, 270, 540, 66, 540, 270, 66, 270, 66, 66, 270, 270, 270, 540, 270, 66, 66]
Prompts retrieved: 56064 . Total input tokens: 12445053 . Total output tokens: 11033924
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 1.76828394504264,
    "estimated_duration": 3600.0242269379733,
    "input_throughput": 1292.4096357977548,
    "output_throughput": 1146.875059646963,
    "total_throughput": 2439.2846954447177,
    "itl": 29.835139744893418,
    "ttft": 6715.5841200966715,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6467,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 47.52625756727372,
    "arrivals": 18908,
    "finished_requests": 18873,
    "scheduler_time": 0.15348608825661056
}
#Debug simulation 
Total elapsed time: 1.7683605570346117. Arrivals time: 0.05624341545626521 Scheduler time: 1.3128508073277771 Scheduler overhead time: 0.10715626552700996 Adapter cache time: 0.1323577486909926 Engine time: 0.10709629021584988 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-8/adapters_192_slots_96_rate_0.05-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-8/adapters_192_slots_96_rate_0.05-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [64 64 64]
Adapter prompts. [540, 33, 540, 33, 540, 33, 540, 33, 33, 33, 270, 270, 270, 270, 540, 270, 33, 540, 33, 270, 270, 33, 540, 540, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 540, 270, 33, 270, 540, 540, 270, 540, 33, 270, 270, 540, 270, 33, 33, 270, 540, 33, 270, 33, 540, 540, 270, 540, 540, 540, 33, 270, 540, 33, 270, 33, 270, 33, 33, 270, 540, 540, 33, 33, 33, 540, 540, 540, 270, 33, 33, 33, 33, 33, 540, 33, 270, 33, 540, 540, 33, 540, 33, 270, 270, 540, 33, 33, 33, 540, 540, 270, 540, 270, 540, 540, 270, 270, 33, 540, 270, 270, 270, 540, 270, 33, 270, 540, 540, 270, 540, 270, 33, 540, 270, 33, 270, 270, 33, 270, 540, 33, 270, 540, 33, 270, 540, 540, 270, 33, 540, 270, 33, 33, 270, 540, 540, 540, 33, 540, 33, 540, 33, 270, 33, 540, 540, 270, 540, 33, 540, 540, 540, 33, 540, 540, 540, 270, 270, 270, 270, 270, 270, 33, 540, 270, 540, 33, 540, 270, 33, 270, 33, 33, 270, 270, 270, 540, 270, 33, 33]
Prompts retrieved: 53952 . Total input tokens: 11982307 . Total output tokens: 10622496
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 1.6966639989987016,
    "estimated_duration": 3599.6402521956497,
    "input_throughput": 1252.0678968546642,
    "output_throughput": 1080.8560654434339,
    "total_throughput": 2332.923962298098,
    "itl": 28.61614671275577,
    "ttft": 7348.8401968310845,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5113,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 33.80924738035724,
    "arrivals": 18247,
    "finished_requests": 18210,
    "scheduler_time": 0.022512453054693474
}
#Debug simulation 
Total elapsed time: 1.6967338640242815. Arrivals time: 0.05466605722904205 Scheduler time: 1.2417980073951185 Scheduler overhead time: 0.11129215778782964 Adapter cache time: 0.12479444220662117 Engine time: 0.11005638726055622 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-16/adapters_192_slots_96_rate_0.05-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-16/adapters_192_slots_96_rate_0.05-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [64 64 64]
Adapter prompts. [540, 33, 540, 33, 540, 33, 540, 33, 33, 33, 270, 270, 270, 270, 540, 270, 33, 540, 33, 270, 270, 33, 540, 540, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 540, 270, 33, 270, 540, 540, 270, 540, 33, 270, 270, 540, 270, 33, 33, 270, 540, 33, 270, 33, 540, 540, 270, 540, 540, 540, 33, 270, 540, 33, 270, 33, 270, 33, 33, 270, 540, 540, 33, 33, 33, 540, 540, 540, 270, 33, 33, 33, 33, 33, 540, 33, 270, 33, 540, 540, 33, 540, 33, 270, 270, 540, 33, 33, 33, 540, 540, 270, 540, 270, 540, 540, 270, 270, 33, 540, 270, 270, 270, 540, 270, 33, 270, 540, 540, 270, 540, 270, 33, 540, 270, 33, 270, 270, 33, 270, 540, 33, 270, 540, 33, 270, 540, 540, 270, 33, 540, 270, 33, 33, 270, 540, 540, 540, 33, 540, 33, 540, 33, 270, 33, 540, 540, 270, 540, 33, 540, 540, 540, 33, 540, 540, 540, 270, 270, 270, 270, 270, 270, 33, 540, 270, 540, 33, 540, 270, 33, 270, 33, 33, 270, 270, 270, 540, 270, 33, 33]
Prompts retrieved: 53952 . Total input tokens: 11982307 . Total output tokens: 10622496
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 1.7146285059861839,
    "estimated_duration": 3599.6621052765304,
    "input_throughput": 1252.0602957131632,
    "output_throughput": 1080.8495037067132,
    "total_throughput": 2332.9097994198764,
    "itl": 28.661853460625107,
    "ttft": 7349.131459174293,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5113,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 37.26792827318788,
    "arrivals": 18247,
    "finished_requests": 18210,
    "scheduler_time": 0.02312255207293515
}
#Debug simulation 
Total elapsed time: 1.714724242221564. Arrivals time: 0.05753160919994116 Scheduler time: 1.2541449279524386 Scheduler overhead time: 0.10976614523679018 Adapter cache time: 0.12617314280942082 Engine time: 0.11306669702753425 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-32/adapters_192_slots_96_rate_0.05-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-32/adapters_192_slots_96_rate_0.05-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [64 64 64]
Adapter prompts. [540, 33, 540, 33, 540, 33, 540, 33, 33, 33, 270, 270, 270, 270, 540, 270, 33, 540, 33, 270, 270, 33, 540, 540, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 540, 270, 33, 270, 540, 540, 270, 540, 33, 270, 270, 540, 270, 33, 33, 270, 540, 33, 270, 33, 540, 540, 270, 540, 540, 540, 33, 270, 540, 33, 270, 33, 270, 33, 33, 270, 540, 540, 33, 33, 33, 540, 540, 540, 270, 33, 33, 33, 33, 33, 540, 33, 270, 33, 540, 540, 33, 540, 33, 270, 270, 540, 33, 33, 33, 540, 540, 270, 540, 270, 540, 540, 270, 270, 33, 540, 270, 270, 270, 540, 270, 33, 270, 540, 540, 270, 540, 270, 33, 540, 270, 33, 270, 270, 33, 270, 540, 33, 270, 540, 33, 270, 540, 540, 270, 33, 540, 270, 33, 33, 270, 540, 540, 540, 33, 540, 33, 540, 33, 270, 33, 540, 540, 270, 540, 33, 540, 540, 540, 33, 540, 540, 540, 270, 270, 270, 270, 270, 270, 33, 540, 270, 540, 33, 540, 270, 33, 270, 33, 33, 270, 270, 270, 540, 270, 33, 33]
Prompts retrieved: 53952 . Total input tokens: 11982307 . Total output tokens: 10622496
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 1.6971126548014581,
    "estimated_duration": 3599.657672247397,
    "input_throughput": 1252.0618376430557,
    "output_throughput": 1080.8508347881034,
    "total_throughput": 2332.912672431159,
    "itl": 28.67080622979129,
    "ttft": 7349.232245278444,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5112,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 38.243211703803674,
    "arrivals": 18247,
    "finished_requests": 18210,
    "scheduler_time": 0.023281383816560683
}
#Debug simulation 
Total elapsed time: 1.697187309153378. Arrivals time: 0.05481992242857814 Scheduler time: 1.2412755959667265 Scheduler overhead time: 0.11027543665841222 Adapter cache time: 0.1256518317386508 Engine time: 0.1110758245922625 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-16/adapters_192_slots_96_rate_0.05-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-16/adapters_192_slots_96_rate_0.05-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [64 64 64]
Adapter prompts. [540, 33, 540, 33, 540, 33, 540, 33, 33, 33, 270, 270, 270, 270, 540, 270, 33, 540, 33, 270, 270, 33, 540, 540, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 540, 270, 33, 270, 540, 540, 270, 540, 33, 270, 270, 540, 270, 33, 33, 270, 540, 33, 270, 33, 540, 540, 270, 540, 540, 540, 33, 270, 540, 33, 270, 33, 270, 33, 33, 270, 540, 540, 33, 33, 33, 540, 540, 540, 270, 33, 33, 33, 33, 33, 540, 33, 270, 33, 540, 540, 33, 540, 33, 270, 270, 540, 33, 33, 33, 540, 540, 270, 540, 270, 540, 540, 270, 270, 33, 540, 270, 270, 270, 540, 270, 33, 270, 540, 540, 270, 540, 270, 33, 540, 270, 33, 270, 270, 33, 270, 540, 33, 270, 540, 33, 270, 540, 540, 270, 33, 540, 270, 33, 33, 270, 540, 540, 540, 33, 540, 33, 540, 33, 270, 33, 540, 540, 270, 540, 33, 540, 540, 540, 33, 540, 540, 540, 270, 270, 270, 270, 270, 270, 33, 540, 270, 540, 33, 540, 270, 33, 270, 33, 33, 270, 270, 270, 540, 270, 33, 33]
Prompts retrieved: 53952 . Total input tokens: 11982307 . Total output tokens: 10622496
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 1.674494334962219,
    "estimated_duration": 3599.63177571003,
    "input_throughput": 1252.07084524944,
    "output_throughput": 1080.8586106651305,
    "total_throughput": 2332.9294559145706,
    "itl": 28.628232285140474,
    "ttft": 7349.017830402427,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5112,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 34.87796894107139,
    "arrivals": 18247,
    "finished_requests": 18210,
    "scheduler_time": 0.022676038470365395
}
#Debug simulation 
Total elapsed time: 1.6745637962594628. Arrivals time: 0.05401929607614875 Scheduler time: 1.2250750958919525 Scheduler overhead time: 0.1094286423176527 Adapter cache time: 0.12456629052758217 Engine time: 0.1074932343326509 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-32/adapters_192_slots_96_rate_0.05-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-32/adapters_192_slots_96_rate_0.05-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [64 64 64]
Adapter prompts. [540, 33, 540, 33, 540, 33, 540, 33, 33, 33, 270, 270, 270, 270, 540, 270, 33, 540, 33, 270, 270, 33, 540, 540, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 540, 270, 33, 270, 540, 540, 270, 540, 33, 270, 270, 540, 270, 33, 33, 270, 540, 33, 270, 33, 540, 540, 270, 540, 540, 540, 33, 270, 540, 33, 270, 33, 270, 33, 33, 270, 540, 540, 33, 33, 33, 540, 540, 540, 270, 33, 33, 33, 33, 33, 540, 33, 270, 33, 540, 540, 33, 540, 33, 270, 270, 540, 33, 33, 33, 540, 540, 270, 540, 270, 540, 540, 270, 270, 33, 540, 270, 270, 270, 540, 270, 33, 270, 540, 540, 270, 540, 270, 33, 540, 270, 33, 270, 270, 33, 270, 540, 33, 270, 540, 33, 270, 540, 540, 270, 33, 540, 270, 33, 33, 270, 540, 540, 540, 33, 540, 33, 540, 33, 270, 33, 540, 540, 270, 540, 33, 540, 540, 540, 33, 540, 540, 540, 270, 270, 270, 270, 270, 270, 33, 540, 270, 540, 33, 540, 270, 33, 270, 33, 33, 270, 270, 270, 540, 270, 33, 33]
Prompts retrieved: 53952 . Total input tokens: 11982307 . Total output tokens: 10622496
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 1.6993100959807634,
    "estimated_duration": 3599.646833582523,
    "input_throughput": 1252.0656076458606,
    "output_throughput": 1080.8540892684784,
    "total_throughput": 2332.919696914339,
    "itl": 28.666571247746987,
    "ttft": 7349.1943834366075,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5112,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 37.8877986287329,
    "arrivals": 18247,
    "finished_requests": 18210,
    "scheduler_time": 0.023231178148047628
}
#Debug simulation 
Total elapsed time: 1.6993790082633495. Arrivals time: 0.05471550952643156 Scheduler time: 1.2446261490695179 Scheduler overhead time: 0.10966862924396992 Adapter cache time: 0.12508550053462386 Engine time: 0.1114351311698556 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-16/adapters_192_slots_96_rate_0.05-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-16/adapters_192_slots_96_rate_0.05-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [64 64 64]
Adapter prompts. [540, 33, 540, 33, 540, 33, 540, 33, 33, 33, 270, 270, 270, 270, 540, 270, 33, 540, 33, 270, 270, 33, 540, 540, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 540, 270, 33, 270, 540, 540, 270, 540, 33, 270, 270, 540, 270, 33, 33, 270, 540, 33, 270, 33, 540, 540, 270, 540, 540, 540, 33, 270, 540, 33, 270, 33, 270, 33, 33, 270, 540, 540, 33, 33, 33, 540, 540, 540, 270, 33, 33, 33, 33, 33, 540, 33, 270, 33, 540, 540, 33, 540, 33, 270, 270, 540, 33, 33, 33, 540, 540, 270, 540, 270, 540, 540, 270, 270, 33, 540, 270, 270, 270, 540, 270, 33, 270, 540, 540, 270, 540, 270, 33, 540, 270, 33, 270, 270, 33, 270, 540, 33, 270, 540, 33, 270, 540, 540, 270, 33, 540, 270, 33, 33, 270, 540, 540, 540, 33, 540, 33, 540, 33, 270, 33, 540, 540, 270, 540, 33, 540, 540, 540, 33, 540, 540, 540, 270, 270, 270, 270, 270, 270, 33, 540, 270, 540, 33, 540, 270, 33, 270, 33, 33, 270, 270, 270, 540, 270, 33, 33]
Prompts retrieved: 53952 . Total input tokens: 11982307 . Total output tokens: 10622496
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 1.6923628621734679,
    "estimated_duration": 3599.647754387398,
    "input_throughput": 1252.065287362268,
    "output_throughput": 1080.8538127815045,
    "total_throughput": 2332.9191001437725,
    "itl": 28.60267705000856,
    "ttft": 7348.784041617232,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5114,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 32.64737169008095,
    "arrivals": 18247,
    "finished_requests": 18210,
    "scheduler_time": 0.022310546150624496
}
#Debug simulation 
Total elapsed time: 1.6924471533857286. Arrivals time: 0.05469196802005172 Scheduler time: 1.2386446907185018 Scheduler overhead time: 0.11027670744806528 Adapter cache time: 0.12501154281198978 Engine time: 0.10962519980967045 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-32/adapters_192_slots_96_rate_0.05-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-32/adapters_192_slots_96_rate_0.05-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [64 64 64]
Adapter prompts. [540, 33, 540, 33, 540, 33, 540, 33, 33, 33, 270, 270, 270, 270, 540, 270, 33, 540, 33, 270, 270, 33, 540, 540, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 540, 270, 33, 270, 540, 540, 270, 540, 33, 270, 270, 540, 270, 33, 33, 270, 540, 33, 270, 33, 540, 540, 270, 540, 540, 540, 33, 270, 540, 33, 270, 33, 270, 33, 33, 270, 540, 540, 33, 33, 33, 540, 540, 540, 270, 33, 33, 33, 33, 33, 540, 33, 270, 33, 540, 540, 33, 540, 33, 270, 270, 540, 33, 33, 33, 540, 540, 270, 540, 270, 540, 540, 270, 270, 33, 540, 270, 270, 270, 540, 270, 33, 270, 540, 540, 270, 540, 270, 33, 540, 270, 33, 270, 270, 33, 270, 540, 33, 270, 540, 33, 270, 540, 540, 270, 33, 540, 270, 33, 33, 270, 540, 540, 540, 33, 540, 33, 540, 33, 270, 33, 540, 540, 270, 540, 33, 540, 540, 540, 33, 540, 540, 540, 270, 270, 270, 270, 270, 270, 33, 540, 270, 540, 33, 540, 270, 33, 270, 33, 33, 270, 270, 270, 540, 270, 33, 33]
Prompts retrieved: 53952 . Total input tokens: 11982307 . Total output tokens: 10622496
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 1.7291778400540352,
    "estimated_duration": 3599.6316764562844,
    "input_throughput": 1252.0708797731725,
    "output_throughput": 1080.8586404679759,
    "total_throughput": 2332.9295202411486,
    "itl": 28.664903829233825,
    "ttft": 7349.276859170861,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5114,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 37.5703368729357,
    "arrivals": 18247,
    "finished_requests": 18210,
    "scheduler_time": 0.0231597893313154
}
#Debug simulation 
Total elapsed time: 1.7292653950862586. Arrivals time: 0.056672238279134035 Scheduler time: 1.2699165372177958 Scheduler overhead time: 0.11003196332603693 Adapter cache time: 0.12630094634369016 Engine time: 0.11255288124084473 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-8/adapters_192_slots_96_rate_0.05-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-8/adapters_192_slots_96_rate_0.05-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [64 64 64]
Adapter prompts. [540, 66, 540, 66, 540, 66, 540, 66, 66, 66, 135, 135, 135, 135, 540, 135, 66, 540, 66, 135, 135, 66, 540, 540, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 540, 135, 66, 135, 540, 540, 135, 540, 66, 135, 135, 540, 135, 66, 66, 135, 540, 66, 135, 66, 540, 540, 135, 540, 540, 540, 66, 135, 540, 66, 135, 66, 135, 66, 66, 135, 540, 540, 66, 66, 66, 540, 540, 540, 135, 66, 66, 66, 66, 66, 540, 66, 135, 66, 540, 540, 66, 540, 66, 135, 135, 540, 66, 66, 66, 540, 540, 135, 540, 135, 540, 540, 135, 135, 66, 540, 135, 135, 135, 540, 135, 66, 135, 540, 540, 135, 540, 135, 66, 540, 135, 66, 135, 135, 66, 135, 540, 66, 135, 540, 66, 135, 540, 540, 135, 66, 540, 135, 66, 66, 135, 540, 540, 540, 66, 540, 66, 540, 66, 135, 66, 540, 540, 135, 540, 66, 540, 540, 540, 66, 540, 540, 540, 135, 135, 135, 135, 135, 135, 66, 540, 135, 540, 66, 540, 135, 66, 135, 66, 66, 135, 135, 135, 540, 135, 66, 66]
Prompts retrieved: 47424 . Total input tokens: 10491539 . Total output tokens: 9348294
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 1.5626134192571044,
    "estimated_duration": 3600.0059127774957,
    "input_throughput": 1099.2631945281448,
    "output_throughput": 954.0809329810362,
    "total_throughput": 2053.344127509181,
    "itl": 27.275907270045195,
    "ttft": 4974.543630119418,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4436,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 29.33264646572722,
    "arrivals": 16073,
    "finished_requests": 16050,
    "scheduler_time": 0.0016064153664965433
}
#Debug simulation 
Total elapsed time: 1.5626864209771156. Arrivals time: 0.049601564183831215 Scheduler time: 1.1149931657128036 Scheduler overhead time: 0.11320426873862743 Adapter cache time: 0.11334851244464517 Engine time: 0.11560451705008745 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-16/adapters_192_slots_96_rate_0.05-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-16/adapters_192_slots_96_rate_0.05-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [64 64 64]
Adapter prompts. [540, 66, 540, 66, 540, 66, 540, 66, 66, 66, 135, 135, 135, 135, 540, 135, 66, 540, 66, 135, 135, 66, 540, 540, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 540, 135, 66, 135, 540, 540, 135, 540, 66, 135, 135, 540, 135, 66, 66, 135, 540, 66, 135, 66, 540, 540, 135, 540, 540, 540, 66, 135, 540, 66, 135, 66, 135, 66, 66, 135, 540, 540, 66, 66, 66, 540, 540, 540, 135, 66, 66, 66, 66, 66, 540, 66, 135, 66, 540, 540, 66, 540, 66, 135, 135, 540, 66, 66, 66, 540, 540, 135, 540, 135, 540, 540, 135, 135, 66, 540, 135, 135, 135, 540, 135, 66, 135, 540, 540, 135, 540, 135, 66, 540, 135, 66, 135, 135, 66, 135, 540, 66, 135, 540, 66, 135, 540, 540, 135, 66, 540, 135, 66, 66, 135, 540, 540, 540, 66, 540, 66, 540, 66, 135, 66, 540, 540, 135, 540, 66, 540, 540, 540, 66, 540, 540, 540, 135, 135, 135, 135, 135, 135, 66, 540, 135, 540, 66, 540, 135, 66, 135, 66, 66, 135, 135, 135, 540, 135, 66, 66]
Prompts retrieved: 47424 . Total input tokens: 10491539 . Total output tokens: 9348294
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 1.5522089102305472,
    "estimated_duration": 3600.0190782232867,
    "input_throughput": 1099.2591744688943,
    "output_throughput": 954.0774438604147,
    "total_throughput": 2053.336618329309,
    "itl": 27.04467532307352,
    "ttft": 5198.149083320508,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4418,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 32.21750954928721,
    "arrivals": 16073,
    "finished_requests": 16050,
    "scheduler_time": 0.0012943395373009306
}
#Debug simulation 
Total elapsed time: 1.552288023289293. Arrivals time: 0.04934514546766877 Scheduler time: 1.1048784763552248 Scheduler overhead time: 0.1147225690074265 Adapter cache time: 0.11268370039761066 Engine time: 0.11462163273245096 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-32/adapters_192_slots_96_rate_0.05-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-32/adapters_192_slots_96_rate_0.05-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [64 64 64]
Adapter prompts. [540, 66, 540, 66, 540, 66, 540, 66, 66, 66, 135, 135, 135, 135, 540, 135, 66, 540, 66, 135, 135, 66, 540, 540, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 540, 135, 66, 135, 540, 540, 135, 540, 66, 135, 135, 540, 135, 66, 66, 135, 540, 66, 135, 66, 540, 540, 135, 540, 540, 540, 66, 135, 540, 66, 135, 66, 135, 66, 66, 135, 540, 540, 66, 66, 66, 540, 540, 540, 135, 66, 66, 66, 66, 66, 540, 66, 135, 66, 540, 540, 66, 540, 66, 135, 135, 540, 66, 66, 66, 540, 540, 135, 540, 135, 540, 540, 135, 135, 66, 540, 135, 135, 135, 540, 135, 66, 135, 540, 540, 135, 540, 135, 66, 540, 135, 66, 135, 135, 66, 135, 540, 66, 135, 540, 66, 135, 540, 540, 135, 66, 540, 135, 66, 66, 135, 540, 540, 540, 66, 540, 66, 540, 66, 135, 66, 540, 540, 135, 540, 66, 540, 540, 540, 66, 540, 540, 540, 135, 135, 135, 135, 135, 135, 66, 540, 135, 540, 66, 540, 135, 66, 135, 66, 66, 135, 135, 135, 540, 135, 66, 66]
Prompts retrieved: 47424 . Total input tokens: 10491539 . Total output tokens: 9348294
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 1.5617832490243018,
    "estimated_duration": 3600.0071350880366,
    "input_throughput": 1099.2628212952764,
    "output_throughput": 954.0806090419056,
    "total_throughput": 2053.343430337182,
    "itl": 27.051377101690722,
    "ttft": 4974.662339092871,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4419,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 33.07882087368649,
    "arrivals": 16073,
    "finished_requests": 16050,
    "scheduler_time": 0.0013039720033975993
}
#Debug simulation 
Total elapsed time: 1.5619054748676717. Arrivals time: 0.050264141988009214 Scheduler time: 1.1115689715370536 Scheduler overhead time: 0.11459495639428496 Adapter cache time: 0.11311430484056473 Engine time: 0.11626944784075022 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-16/adapters_192_slots_96_rate_0.05-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-16/adapters_192_slots_96_rate_0.05-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [64 64 64]
Adapter prompts. [540, 66, 540, 66, 540, 66, 540, 66, 66, 66, 135, 135, 135, 135, 540, 135, 66, 540, 66, 135, 135, 66, 540, 540, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 540, 135, 66, 135, 540, 540, 135, 540, 66, 135, 135, 540, 135, 66, 66, 135, 540, 66, 135, 66, 540, 540, 135, 540, 540, 540, 66, 135, 540, 66, 135, 66, 135, 66, 66, 135, 540, 540, 66, 66, 66, 540, 540, 540, 135, 66, 66, 66, 66, 66, 540, 66, 135, 66, 540, 540, 66, 540, 66, 135, 135, 540, 66, 66, 66, 540, 540, 135, 540, 135, 540, 540, 135, 135, 66, 540, 135, 135, 135, 540, 135, 66, 135, 540, 540, 135, 540, 135, 66, 540, 135, 66, 135, 135, 66, 135, 540, 66, 135, 540, 66, 135, 540, 540, 135, 66, 540, 135, 66, 66, 135, 540, 540, 540, 66, 540, 66, 540, 66, 135, 66, 540, 540, 135, 540, 66, 540, 540, 540, 66, 540, 540, 540, 135, 135, 135, 135, 135, 135, 66, 540, 135, 540, 66, 540, 135, 66, 135, 66, 66, 135, 135, 135, 540, 135, 66, 66]
Prompts retrieved: 47424 . Total input tokens: 10491539 . Total output tokens: 9348294
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 1.5637792963534594,
    "estimated_duration": 3600.0009497031037,
    "input_throughput": 1099.2647100069148,
    "output_throughput": 954.0822483069799,
    "total_throughput": 2053.3469583138944,
    "itl": 27.02522653859082,
    "ttft": 4974.302881117363,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4417,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 30.177381902445127,
    "arrivals": 16073,
    "finished_requests": 16050,
    "scheduler_time": 0.0012869587852235753
}
#Debug simulation 
Total elapsed time: 1.5638489671982825. Arrivals time: 0.04981185728684068 Scheduler time: 1.1129933493211865 Scheduler overhead time: 0.11454395670443773 Adapter cache time: 0.11221334990113974 Engine time: 0.11788715049624443 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-32/adapters_192_slots_96_rate_0.05-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-32/adapters_192_slots_96_rate_0.05-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [64 64 64]
Adapter prompts. [540, 66, 540, 66, 540, 66, 540, 66, 66, 66, 135, 135, 135, 135, 540, 135, 66, 540, 66, 135, 135, 66, 540, 540, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 540, 135, 66, 135, 540, 540, 135, 540, 66, 135, 135, 540, 135, 66, 66, 135, 540, 66, 135, 66, 540, 540, 135, 540, 540, 540, 66, 135, 540, 66, 135, 66, 135, 66, 66, 135, 540, 540, 66, 66, 66, 540, 540, 540, 135, 66, 66, 66, 66, 66, 540, 66, 135, 66, 540, 540, 66, 540, 66, 135, 135, 540, 66, 66, 66, 540, 540, 135, 540, 135, 540, 540, 135, 135, 66, 540, 135, 135, 135, 540, 135, 66, 135, 540, 540, 135, 540, 135, 66, 540, 135, 66, 135, 135, 66, 135, 540, 66, 135, 540, 66, 135, 540, 540, 135, 66, 540, 135, 66, 66, 135, 540, 540, 540, 66, 540, 66, 540, 66, 135, 66, 540, 540, 135, 540, 66, 540, 540, 540, 66, 540, 540, 540, 135, 135, 135, 135, 135, 135, 66, 540, 135, 540, 66, 540, 135, 66, 135, 66, 66, 135, 135, 135, 540, 135, 66, 66]
Prompts retrieved: 47424 . Total input tokens: 10491539 . Total output tokens: 9348294
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 1.5503306710161269,
    "estimated_duration": 3600.0251320833027,
    "input_throughput": 1099.2573259370315,
    "output_throughput": 954.0758394684793,
    "total_throughput": 2053.333165405511,
    "itl": 27.049935121327525,
    "ttft": 5198.213615184917,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4417,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 32.76095086959329,
    "arrivals": 16073,
    "finished_requests": 16050,
    "scheduler_time": 0.0013209852215716232
}
#Debug simulation 
Total elapsed time: 1.5504077831283212. Arrivals time: 0.04945847578346729 Scheduler time: 1.1040869038552046 Scheduler overhead time: 0.1139607043005526 Adapter cache time: 0.11256676074117422 Engine time: 0.114098752848804 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-16/adapters_192_slots_96_rate_0.05-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-16/adapters_192_slots_96_rate_0.05-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [64 64 64]
Adapter prompts. [540, 66, 540, 66, 540, 66, 540, 66, 66, 66, 135, 135, 135, 135, 540, 135, 66, 540, 66, 135, 135, 66, 540, 540, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 540, 135, 66, 135, 540, 540, 135, 540, 66, 135, 135, 540, 135, 66, 66, 135, 540, 66, 135, 66, 540, 540, 135, 540, 540, 540, 66, 135, 540, 66, 135, 66, 135, 66, 66, 135, 540, 540, 66, 66, 66, 540, 540, 540, 135, 66, 66, 66, 66, 66, 540, 66, 135, 66, 540, 540, 66, 540, 66, 135, 135, 540, 66, 66, 66, 540, 540, 135, 540, 135, 540, 540, 135, 135, 66, 540, 135, 135, 135, 540, 135, 66, 135, 540, 540, 135, 540, 135, 66, 540, 135, 66, 135, 135, 66, 135, 540, 66, 135, 540, 66, 135, 540, 540, 135, 66, 540, 135, 66, 66, 135, 540, 540, 540, 66, 540, 66, 540, 66, 135, 66, 540, 540, 135, 540, 66, 540, 540, 540, 66, 540, 540, 540, 135, 135, 135, 135, 135, 135, 66, 540, 135, 540, 66, 540, 135, 66, 135, 66, 66, 135, 135, 135, 540, 135, 66, 66]
Prompts retrieved: 47424 . Total input tokens: 10491539 . Total output tokens: 9348294
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 1.5532354731112719,
    "estimated_duration": 3600.013175112197,
    "input_throughput": 1099.2609769759151,
    "output_throughput": 954.0790083061169,
    "total_throughput": 2053.339985282032,
    "itl": 27.264235893358105,
    "ttft": 5198.304026155429,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4435,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 28.312689371432985,
    "arrivals": 16073,
    "finished_requests": 16050,
    "scheduler_time": 0.001551330903933223
}
#Debug simulation 
Total elapsed time: 1.553341875784099. Arrivals time: 0.04970560548827052 Scheduler time: 1.1083220057189465 Scheduler overhead time: 0.11396475089713931 Adapter cache time: 0.11220524599775672 Engine time: 0.1136430511251092 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-32/adapters_192_slots_96_rate_0.05-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-32/adapters_192_slots_96_rate_0.05-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [64 64 64]
Adapter prompts. [540, 66, 540, 66, 540, 66, 540, 66, 66, 66, 135, 135, 135, 135, 540, 135, 66, 540, 66, 135, 135, 66, 540, 540, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 540, 135, 66, 135, 540, 540, 135, 540, 66, 135, 135, 540, 135, 66, 66, 135, 540, 66, 135, 66, 540, 540, 135, 540, 540, 540, 66, 135, 540, 66, 135, 66, 135, 66, 66, 135, 540, 540, 66, 66, 66, 540, 540, 540, 135, 66, 66, 66, 66, 66, 540, 66, 135, 66, 540, 540, 66, 540, 66, 135, 135, 540, 66, 66, 66, 540, 540, 135, 540, 135, 540, 540, 135, 135, 66, 540, 135, 135, 135, 540, 135, 66, 135, 540, 540, 135, 540, 135, 66, 540, 135, 66, 135, 135, 66, 135, 540, 66, 135, 540, 66, 135, 540, 540, 135, 66, 540, 135, 66, 66, 135, 540, 540, 540, 66, 540, 66, 540, 66, 135, 66, 540, 540, 135, 540, 66, 540, 540, 540, 66, 540, 540, 540, 135, 135, 135, 135, 135, 135, 66, 540, 135, 540, 66, 540, 135, 66, 135, 66, 66, 135, 135, 135, 540, 135, 66, 66]
Prompts retrieved: 47424 . Total input tokens: 10491539 . Total output tokens: 9348294
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 1.5595781048759818,
    "estimated_duration": 3600.0010571634707,
    "input_throughput": 1099.2646771937607,
    "output_throughput": 954.0822198275358,
    "total_throughput": 2053.3468970212966,
    "itl": 27.046884330868682,
    "ttft": 4974.552257711263,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4416,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 32.45773281954374,
    "arrivals": 16073,
    "finished_requests": 16050,
    "scheduler_time": 0.0013193172495535705
}
#Debug simulation 
Total elapsed time: 1.5596488369628787. Arrivals time: 0.04975905083119869 Scheduler time: 1.1109986454248428 Scheduler overhead time: 0.11471279803663492 Adapter cache time: 0.11122997011989355 Engine time: 0.11633509723469615 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-8/adapters_192_slots_96_rate_0.05-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-8/adapters_192_slots_96_rate_0.05-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [64 64 64]
Adapter prompts. [540, 33, 540, 33, 540, 33, 540, 33, 33, 33, 135, 135, 135, 135, 540, 135, 33, 540, 33, 135, 135, 33, 540, 540, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 540, 135, 33, 135, 540, 540, 135, 540, 33, 135, 135, 540, 135, 33, 33, 135, 540, 33, 135, 33, 540, 540, 135, 540, 540, 540, 33, 135, 540, 33, 135, 33, 135, 33, 33, 135, 540, 540, 33, 33, 33, 540, 540, 540, 135, 33, 33, 33, 33, 33, 540, 33, 135, 33, 540, 540, 33, 540, 33, 135, 135, 540, 33, 33, 33, 540, 540, 135, 540, 135, 540, 540, 135, 135, 33, 540, 135, 135, 135, 540, 135, 33, 135, 540, 540, 135, 540, 135, 33, 540, 135, 33, 135, 135, 33, 135, 540, 33, 135, 540, 33, 135, 540, 540, 135, 33, 540, 135, 33, 33, 135, 540, 540, 540, 33, 540, 33, 540, 33, 135, 33, 540, 540, 135, 540, 33, 540, 540, 540, 33, 540, 540, 540, 135, 135, 135, 135, 135, 135, 33, 540, 135, 540, 33, 540, 135, 33, 135, 33, 33, 135, 135, 135, 540, 135, 33, 33]
Prompts retrieved: 45312 . Total input tokens: 10015822 . Total output tokens: 8930376
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 1.535270824097097,
    "estimated_duration": 3599.9860031395515,
    "input_throughput": 1039.7984871984222,
    "output_throughput": 928.2449979210272,
    "total_throughput": 1968.0434851194493,
    "itl": 26.699595119181193,
    "ttft": 4962.8388580914025,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3411,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 22.554927207980136,
    "arrivals": 15374,
    "finished_requests": 15353,
    "scheduler_time": 5.78366645981649e-05
}
#Debug simulation 
Total elapsed time: 1.5353495590388775. Arrivals time: 0.04797579301521182 Scheduler time: 1.090219670906663 Scheduler overhead time: 0.11566866328939795 Adapter cache time: 0.10729319741949439 Engine time: 0.11737959086894989 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-16/adapters_192_slots_96_rate_0.05-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-16/adapters_192_slots_96_rate_0.05-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [64 64 64]
Adapter prompts. [540, 33, 540, 33, 540, 33, 540, 33, 33, 33, 135, 135, 135, 135, 540, 135, 33, 540, 33, 135, 135, 33, 540, 540, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 540, 135, 33, 135, 540, 540, 135, 540, 33, 135, 135, 540, 135, 33, 33, 135, 540, 33, 135, 33, 540, 540, 135, 540, 540, 540, 33, 135, 540, 33, 135, 33, 135, 33, 33, 135, 540, 540, 33, 33, 33, 540, 540, 540, 135, 33, 33, 33, 33, 33, 540, 33, 135, 33, 540, 540, 33, 540, 33, 135, 135, 540, 33, 33, 33, 540, 540, 135, 540, 135, 540, 540, 135, 135, 33, 540, 135, 135, 135, 540, 135, 33, 135, 540, 540, 135, 540, 135, 33, 540, 135, 33, 135, 135, 33, 135, 540, 33, 135, 540, 33, 135, 540, 540, 135, 33, 540, 135, 33, 33, 135, 540, 540, 540, 33, 540, 33, 540, 33, 135, 33, 540, 540, 135, 540, 33, 540, 540, 540, 33, 540, 540, 540, 135, 135, 135, 135, 135, 135, 33, 540, 135, 540, 33, 540, 135, 33, 135, 33, 33, 135, 135, 135, 540, 135, 33, 33]
Prompts retrieved: 45312 . Total input tokens: 10015822 . Total output tokens: 8930376
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 1.5044112163595855,
    "estimated_duration": 3599.9914548091006,
    "input_throughput": 1039.7969125730874,
    "output_throughput": 928.2435922274158,
    "total_throughput": 1968.0405048005032,
    "itl": 26.726543457523135,
    "ttft": 4963.067660963845,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3413,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.913207581093875,
    "arrivals": 15374,
    "finished_requests": 15353,
    "scheduler_time": 6.271545864844062e-05
}
#Debug simulation 
Total elapsed time: 1.5044981082901359. Arrivals time: 0.04759050626307726 Scheduler time: 1.0636870511807501 Scheduler overhead time: 0.1159476856701076 Adapter cache time: 0.10598497139289975 Engine time: 0.11460884800180793 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-32/adapters_192_slots_96_rate_0.05-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-32/adapters_192_slots_96_rate_0.05-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [64 64 64]
Adapter prompts. [540, 33, 540, 33, 540, 33, 540, 33, 33, 33, 135, 135, 135, 135, 540, 135, 33, 540, 33, 135, 135, 33, 540, 540, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 540, 135, 33, 135, 540, 540, 135, 540, 33, 135, 135, 540, 135, 33, 33, 135, 540, 33, 135, 33, 540, 540, 135, 540, 540, 540, 33, 135, 540, 33, 135, 33, 135, 33, 33, 135, 540, 540, 33, 33, 33, 540, 540, 540, 135, 33, 33, 33, 33, 33, 540, 33, 135, 33, 540, 540, 33, 540, 33, 135, 135, 540, 33, 33, 33, 540, 540, 135, 540, 135, 540, 540, 135, 135, 33, 540, 135, 135, 135, 540, 135, 33, 135, 540, 540, 135, 540, 135, 33, 540, 135, 33, 135, 135, 33, 135, 540, 33, 135, 540, 33, 135, 540, 540, 135, 33, 540, 135, 33, 33, 135, 540, 540, 540, 33, 540, 33, 540, 33, 135, 33, 540, 540, 135, 540, 33, 540, 540, 540, 33, 540, 540, 540, 135, 135, 135, 135, 135, 135, 33, 540, 135, 540, 33, 540, 135, 33, 135, 33, 33, 135, 135, 135, 540, 135, 33, 33]
Prompts retrieved: 45312 . Total input tokens: 10015822 . Total output tokens: 8930376
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 1.5430175429210067,
    "estimated_duration": 3600.0071057469277,
    "input_throughput": 1039.79239208289,
    "output_throughput": 928.2395567123949,
    "total_throughput": 1968.0319487952852,
    "itl": 26.73170344535294,
    "ttft": 4962.977617913519,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3411,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 25.565270859846684,
    "arrivals": 15374,
    "finished_requests": 15353,
    "scheduler_time": 6.354944465746703e-05
}
#Debug simulation 
Total elapsed time: 1.543113224208355. Arrivals time: 0.048399931751191616 Scheduler time: 1.0892494088038802 Scheduler overhead time: 0.12133644055575132 Adapter cache time: 0.10781969968229532 Engine time: 0.11848718114197254 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-16/adapters_192_slots_96_rate_0.05-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-16/adapters_192_slots_96_rate_0.05-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [64 64 64]
Adapter prompts. [540, 33, 540, 33, 540, 33, 540, 33, 33, 33, 135, 135, 135, 135, 540, 135, 33, 540, 33, 135, 135, 33, 540, 540, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 540, 135, 33, 135, 540, 540, 135, 540, 33, 135, 135, 540, 135, 33, 33, 135, 540, 33, 135, 33, 540, 540, 135, 540, 540, 540, 33, 135, 540, 33, 135, 33, 135, 33, 33, 135, 540, 540, 33, 33, 33, 540, 540, 540, 135, 33, 33, 33, 33, 33, 540, 33, 135, 33, 540, 540, 33, 540, 33, 135, 135, 540, 33, 33, 33, 540, 540, 135, 540, 135, 540, 540, 135, 135, 33, 540, 135, 135, 135, 540, 135, 33, 135, 540, 540, 135, 540, 135, 33, 540, 135, 33, 135, 135, 33, 135, 540, 33, 135, 540, 33, 135, 540, 540, 135, 33, 540, 135, 33, 33, 135, 540, 540, 540, 33, 540, 33, 540, 33, 135, 33, 540, 540, 135, 540, 33, 540, 540, 540, 33, 540, 540, 540, 135, 135, 135, 135, 135, 135, 33, 540, 135, 540, 33, 540, 135, 33, 135, 33, 33, 135, 135, 135, 540, 135, 33, 33]
Prompts retrieved: 45312 . Total input tokens: 10015822 . Total output tokens: 8930376
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 1.5073530320078135,
    "estimated_duration": 3600.010991188273,
    "input_throughput": 1039.7912698495525,
    "output_throughput": 928.238554876467,
    "total_throughput": 1968.0298247260193,
    "itl": 26.708462368199147,
    "ttft": 4962.886317867792,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3412,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 23.297875552085003,
    "arrivals": 15374,
    "finished_requests": 15353,
    "scheduler_time": 5.141502053371909e-05
}
#Debug simulation 
Total elapsed time: 1.5074319588020444. Arrivals time: 0.047463450115174055 Scheduler time: 1.0663824793882668 Scheduler overhead time: 0.11582864448428154 Adapter cache time: 0.10681114811450243 Engine time: 0.11429492104798555 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-32/adapters_192_slots_96_rate_0.05-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-32/adapters_192_slots_96_rate_0.05-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [64 64 64]
Adapter prompts. [540, 33, 540, 33, 540, 33, 540, 33, 33, 33, 135, 135, 135, 135, 540, 135, 33, 540, 33, 135, 135, 33, 540, 540, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 540, 135, 33, 135, 540, 540, 135, 540, 33, 135, 135, 540, 135, 33, 33, 135, 540, 33, 135, 33, 540, 540, 135, 540, 540, 540, 33, 135, 540, 33, 135, 33, 135, 33, 33, 135, 540, 540, 33, 33, 33, 540, 540, 540, 135, 33, 33, 33, 33, 33, 540, 33, 135, 33, 540, 540, 33, 540, 33, 135, 135, 540, 33, 33, 33, 540, 540, 135, 540, 135, 540, 540, 135, 135, 33, 540, 135, 135, 135, 540, 135, 33, 135, 540, 540, 135, 540, 135, 33, 540, 135, 33, 135, 135, 33, 135, 540, 33, 135, 540, 33, 135, 540, 540, 135, 33, 540, 135, 33, 33, 135, 540, 540, 540, 33, 540, 33, 540, 33, 135, 33, 540, 540, 135, 540, 33, 540, 540, 540, 33, 540, 540, 540, 135, 135, 135, 135, 135, 135, 33, 540, 135, 540, 33, 540, 135, 33, 135, 33, 33, 135, 135, 135, 540, 135, 33, 33]
Prompts retrieved: 45312 . Total input tokens: 10015822 . Total output tokens: 8930376
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 1.5235342746600509,
    "estimated_duration": 3599.991178318564,
    "input_throughput": 1039.7969924327292,
    "output_throughput": 928.2436635194151,
    "total_throughput": 1968.0406559521446,
    "itl": 26.728591788084298,
    "ttft": 4963.048451335943,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3410,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 25.317353095953177,
    "arrivals": 15374,
    "finished_requests": 15353,
    "scheduler_time": 5.86706506071913e-05
}
#Debug simulation 
Total elapsed time: 1.5236200536601245. Arrivals time: 0.04776816489174962 Scheduler time: 1.0793533762916923 Scheduler overhead time: 0.1161243305541575 Adapter cache time: 0.10664233472198248 Engine time: 0.11706378357484937 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-16/adapters_192_slots_96_rate_0.05-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-16/adapters_192_slots_96_rate_0.05-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [64 64 64]
Adapter prompts. [540, 33, 540, 33, 540, 33, 540, 33, 33, 33, 135, 135, 135, 135, 540, 135, 33, 540, 33, 135, 135, 33, 540, 540, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 540, 135, 33, 135, 540, 540, 135, 540, 33, 135, 135, 540, 135, 33, 33, 135, 540, 33, 135, 33, 540, 540, 135, 540, 540, 540, 33, 135, 540, 33, 135, 33, 135, 33, 33, 135, 540, 540, 33, 33, 33, 540, 540, 540, 135, 33, 33, 33, 33, 33, 540, 33, 135, 33, 540, 540, 33, 540, 33, 135, 135, 540, 33, 33, 33, 540, 540, 135, 540, 135, 540, 540, 135, 135, 33, 540, 135, 135, 135, 540, 135, 33, 135, 540, 540, 135, 540, 135, 33, 540, 135, 33, 135, 135, 33, 135, 540, 33, 135, 540, 33, 135, 540, 540, 135, 33, 540, 135, 33, 33, 135, 540, 540, 540, 33, 540, 33, 540, 33, 135, 33, 540, 540, 135, 540, 33, 540, 540, 540, 33, 540, 540, 540, 135, 135, 135, 135, 135, 135, 33, 540, 135, 540, 33, 540, 135, 33, 135, 33, 33, 135, 135, 135, 540, 135, 33, 33]
Prompts retrieved: 45312 . Total input tokens: 10015822 . Total output tokens: 8930376
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 1.537056586239487,
    "estimated_duration": 3600.00999199244,
    "input_throughput": 1039.7915584473913,
    "output_throughput": 928.2388125124452,
    "total_throughput": 1968.0303709598365,
    "itl": 26.69107470446641,
    "ttft": 4962.845752227058,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3412,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 21.781938249228457,
    "arrivals": 15374,
    "finished_requests": 15353,
    "scheduler_time": 5.70026785891385e-05
}
#Debug simulation 
Total elapsed time: 1.5371418320573866. Arrivals time: 0.048477912321686745 Scheduler time: 1.0859534377232194 Scheduler overhead time: 0.11689481418579817 Adapter cache time: 0.10913200257346034 Engine time: 0.11986706871539354 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-32/adapters_192_slots_96_rate_0.05-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-32/adapters_192_slots_96_rate_0.05-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [64 64 64]
Adapter prompts. [540, 33, 540, 33, 540, 33, 540, 33, 33, 33, 135, 135, 135, 135, 540, 135, 33, 540, 33, 135, 135, 33, 540, 540, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 540, 135, 33, 135, 540, 540, 135, 540, 33, 135, 135, 540, 135, 33, 33, 135, 540, 33, 135, 33, 540, 540, 135, 540, 540, 540, 33, 135, 540, 33, 135, 33, 135, 33, 33, 135, 540, 540, 33, 33, 33, 540, 540, 540, 135, 33, 33, 33, 33, 33, 540, 33, 135, 33, 540, 540, 33, 540, 33, 135, 135, 540, 33, 33, 33, 540, 540, 135, 540, 135, 540, 540, 135, 135, 33, 540, 135, 135, 135, 540, 135, 33, 135, 540, 540, 135, 540, 135, 33, 540, 135, 33, 135, 135, 33, 135, 540, 33, 135, 540, 33, 135, 540, 540, 135, 33, 540, 135, 33, 33, 135, 540, 540, 540, 33, 540, 33, 540, 33, 135, 33, 540, 540, 135, 540, 33, 540, 540, 540, 33, 540, 540, 540, 135, 135, 135, 135, 135, 135, 33, 540, 135, 540, 33, 540, 135, 33, 135, 33, 33, 135, 135, 135, 540, 135, 33, 33]
Prompts retrieved: 45312 . Total input tokens: 10015822 . Total output tokens: 8930376
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 1.5304966759867966,
    "estimated_duration": 3600.007874991682,
    "input_throughput": 1039.7921699014753,
    "output_throughput": 928.2393583674373,
    "total_throughput": 1968.0315282689126,
    "itl": 26.72759736497472,
    "ttft": 4963.097857647967,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3411,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 25.099050095286955,
    "arrivals": 15374,
    "finished_requests": 15353,
    "scheduler_time": 6.271545864844062e-05
}
#Debug simulation 
Total elapsed time: 1.5305759799666703. Arrivals time: 0.047959207091480494 Scheduler time: 1.085432207211852 Scheduler overhead time: 0.11643264442682266 Adapter cache time: 0.10670693032443523 Engine time: 0.11712150694802403 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-8/adapters_192_slots_96_rate_0.05-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-8/adapters_192_slots_96_rate_0.05-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [64 64 64]
Adapter prompts. [540, 33, 540, 33, 540, 33, 540, 33, 33, 33, 66, 66, 66, 66, 540, 66, 33, 540, 33, 66, 66, 33, 540, 540, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 540, 66, 33, 66, 540, 540, 66, 540, 33, 66, 66, 540, 66, 33, 33, 66, 540, 33, 66, 33, 540, 540, 66, 540, 540, 540, 33, 66, 540, 33, 66, 33, 66, 33, 33, 66, 540, 540, 33, 33, 33, 540, 540, 540, 66, 33, 33, 33, 33, 33, 540, 33, 66, 33, 540, 540, 33, 540, 33, 66, 66, 540, 33, 33, 33, 540, 540, 66, 540, 66, 540, 540, 66, 66, 33, 540, 66, 66, 66, 540, 66, 33, 66, 540, 540, 66, 540, 66, 33, 540, 66, 33, 66, 66, 33, 66, 540, 33, 66, 540, 33, 66, 540, 540, 66, 33, 540, 66, 33, 33, 66, 540, 540, 540, 33, 540, 33, 540, 33, 66, 33, 540, 540, 66, 540, 33, 540, 540, 540, 33, 540, 540, 540, 66, 66, 66, 66, 66, 66, 33, 540, 66, 540, 33, 540, 66, 33, 66, 33, 33, 66, 66, 66, 540, 66, 33, 33]
Prompts retrieved: 40896 . Total input tokens: 9030280 . Total output tokens: 8064424
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 1.4450303940102458,
    "estimated_duration": 3599.899541772724,
    "input_throughput": 934.9344227374243,
    "output_throughput": 827.2383619164924,
    "total_throughput": 1762.1727846539166,
    "itl": 25.787252971184092,
    "ttft": 7828.926063808706,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2062,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.634787423881143,
    "arrivals": 13872,
    "finished_requests": 13842,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4451235979795456. Arrivals time: 0.04462338238954544 Scheduler time: 0.997638946864754 Scheduler overhead time: 0.12417299812659621 Adapter cache time: 0.09670104272663593 Engine time: 0.12116332771256566 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-16/adapters_192_slots_96_rate_0.05-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-16/adapters_192_slots_96_rate_0.05-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [64 64 64]
Adapter prompts. [540, 33, 540, 33, 540, 33, 540, 33, 33, 33, 66, 66, 66, 66, 540, 66, 33, 540, 33, 66, 66, 33, 540, 540, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 540, 66, 33, 66, 540, 540, 66, 540, 33, 66, 66, 540, 66, 33, 33, 66, 540, 33, 66, 33, 540, 540, 66, 540, 540, 540, 33, 66, 540, 33, 66, 33, 66, 33, 33, 66, 540, 540, 33, 33, 33, 540, 540, 540, 66, 33, 33, 33, 33, 33, 540, 33, 66, 33, 540, 540, 33, 540, 33, 66, 66, 540, 33, 33, 33, 540, 540, 66, 540, 66, 540, 540, 66, 66, 33, 540, 66, 66, 66, 540, 66, 33, 66, 540, 540, 66, 540, 66, 33, 540, 66, 33, 66, 66, 33, 66, 540, 33, 66, 540, 33, 66, 540, 540, 66, 33, 540, 66, 33, 33, 66, 540, 540, 540, 33, 540, 33, 540, 33, 66, 33, 540, 540, 66, 540, 33, 540, 540, 540, 33, 540, 540, 540, 66, 66, 66, 66, 66, 66, 33, 540, 66, 540, 33, 540, 66, 33, 66, 33, 33, 66, 66, 66, 540, 66, 33, 33]
Prompts retrieved: 40896 . Total input tokens: 9030280 . Total output tokens: 8064424
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 1.4208328970707953,
    "estimated_duration": 3599.9217229783358,
    "input_throughput": 935.0814431639957,
    "output_throughput": 827.2338203888,
    "total_throughput": 1762.3152635527956,
    "itl": 25.540272317318326,
    "ttft": 7568.995227443123,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2030,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.834846044303594,
    "arrivals": 13872,
    "finished_requests": 13843,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4209139021113515. Arrivals time: 0.04512950498610735 Scheduler time: 0.9791413340717554 Scheduler overhead time: 0.12004274828359485 Adapter cache time: 0.09555005701258779 Engine time: 0.12199466861784458 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-32/adapters_192_slots_96_rate_0.05-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-32/adapters_192_slots_96_rate_0.05-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [64 64 64]
Adapter prompts. [540, 33, 540, 33, 540, 33, 540, 33, 33, 33, 66, 66, 66, 66, 540, 66, 33, 540, 33, 66, 66, 33, 540, 540, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 540, 66, 33, 66, 540, 540, 66, 540, 33, 66, 66, 540, 66, 33, 33, 66, 540, 33, 66, 33, 540, 540, 66, 540, 540, 540, 33, 66, 540, 33, 66, 33, 66, 33, 33, 66, 540, 540, 33, 33, 33, 540, 540, 540, 66, 33, 33, 33, 33, 33, 540, 33, 66, 33, 540, 540, 33, 540, 33, 66, 66, 540, 33, 33, 33, 540, 540, 66, 540, 66, 540, 540, 66, 66, 33, 540, 66, 66, 66, 540, 66, 33, 66, 540, 540, 66, 540, 66, 33, 540, 66, 33, 66, 66, 33, 66, 540, 33, 66, 540, 33, 66, 540, 540, 66, 33, 540, 66, 33, 33, 66, 540, 540, 540, 33, 540, 33, 540, 33, 66, 33, 540, 540, 66, 540, 33, 540, 540, 540, 33, 540, 540, 540, 66, 66, 66, 66, 66, 66, 33, 540, 66, 540, 33, 540, 66, 33, 66, 33, 33, 66, 66, 66, 540, 66, 33, 33]
Prompts retrieved: 40896 . Total input tokens: 9030280 . Total output tokens: 8064424
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 1.4052490256726742,
    "estimated_duration": 3599.90455971155,
    "input_throughput": 934.933119524058,
    "output_throughput": 827.2372088216184,
    "total_throughput": 1762.1703283456764,
    "itl": 25.544861491810337,
    "ttft": 7828.563204737179,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2031,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.242225479986201,
    "arrivals": 13872,
    "finished_requests": 13842,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4053267617709935. Arrivals time: 0.044310209807008505 Scheduler time: 0.9672027667984366 Scheduler overhead time: 0.11955120973289013 Adapter cache time: 0.09563076961785555 Engine time: 0.12002152111381292 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-16/adapters_192_slots_96_rate_0.05-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-16/adapters_192_slots_96_rate_0.05-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [64 64 64]
Adapter prompts. [540, 33, 540, 33, 540, 33, 540, 33, 33, 33, 66, 66, 66, 66, 540, 66, 33, 540, 33, 66, 66, 33, 540, 540, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 540, 66, 33, 66, 540, 540, 66, 540, 33, 66, 66, 540, 66, 33, 33, 66, 540, 33, 66, 33, 540, 540, 66, 540, 540, 540, 33, 66, 540, 33, 66, 33, 66, 33, 33, 66, 540, 540, 33, 33, 33, 540, 540, 540, 66, 33, 33, 33, 33, 33, 540, 33, 66, 33, 540, 540, 33, 540, 33, 66, 66, 540, 33, 33, 33, 540, 540, 66, 540, 66, 540, 540, 66, 66, 33, 540, 66, 66, 66, 540, 66, 33, 66, 540, 540, 66, 540, 66, 33, 540, 66, 33, 66, 66, 33, 66, 540, 33, 66, 540, 33, 66, 540, 540, 66, 33, 540, 66, 33, 33, 66, 540, 540, 540, 33, 540, 33, 540, 33, 66, 33, 540, 540, 66, 540, 33, 540, 540, 540, 33, 540, 540, 540, 66, 66, 66, 66, 66, 66, 33, 540, 66, 540, 33, 540, 66, 33, 66, 33, 33, 66, 66, 66, 540, 66, 33, 33]
Prompts retrieved: 40896 . Total input tokens: 9030280 . Total output tokens: 8064424
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 1.406861828174442,
    "estimated_duration": 3599.9155987209683,
    "input_throughput": 935.0830339455738,
    "output_throughput": 827.2352276975771,
    "total_throughput": 1762.318261643151,
    "itl": 25.790640031136963,
    "ttft": 7569.337478271098,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2062,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.079870821843166,
    "arrivals": 13872,
    "finished_requests": 13843,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.406917029991746. Arrivals time: 0.044427793473005295 Scheduler time: 0.9732835884205997 Scheduler overhead time: 0.11786177288740873 Adapter cache time: 0.09418100956827402 Engine time: 0.11926516192033887 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-32/adapters_192_slots_96_rate_0.05-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-32/adapters_192_slots_96_rate_0.05-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [64 64 64]
Adapter prompts. [540, 33, 540, 33, 540, 33, 540, 33, 33, 33, 66, 66, 66, 66, 540, 66, 33, 540, 33, 66, 66, 33, 540, 540, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 540, 66, 33, 66, 540, 540, 66, 540, 33, 66, 66, 540, 66, 33, 33, 66, 540, 33, 66, 33, 540, 540, 66, 540, 540, 540, 33, 66, 540, 33, 66, 33, 66, 33, 33, 66, 540, 540, 33, 33, 33, 540, 540, 540, 66, 33, 33, 33, 33, 33, 540, 33, 66, 33, 540, 540, 33, 540, 33, 66, 66, 540, 33, 33, 33, 540, 540, 66, 540, 66, 540, 540, 66, 66, 33, 540, 66, 66, 66, 540, 66, 33, 66, 540, 540, 66, 540, 66, 33, 540, 66, 33, 66, 66, 33, 66, 540, 33, 66, 540, 33, 66, 540, 540, 66, 33, 540, 66, 33, 33, 66, 540, 540, 540, 33, 540, 33, 540, 33, 66, 33, 540, 540, 66, 540, 33, 540, 540, 540, 33, 540, 540, 540, 66, 66, 66, 66, 66, 66, 33, 540, 66, 540, 33, 540, 66, 33, 66, 33, 33, 66, 66, 66, 540, 66, 33, 33]
Prompts retrieved: 40896 . Total input tokens: 9030280 . Total output tokens: 8064424
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 1.4143321360461414,
    "estimated_duration": 3599.9259918171806,
    "input_throughput": 935.080334332315,
    "output_throughput": 827.2328394442266,
    "total_throughput": 1762.3131737765416,
    "itl": 25.54180070184569,
    "ttft": 7569.043487909019,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2030,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.08999585168871,
    "arrivals": 13872,
    "finished_requests": 13843,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4144011791795492. Arrivals time: 0.04409876745194197 Scheduler time: 0.9733770317398012 Scheduler overhead time: 0.1194446855224669 Adapter cache time: 0.09574942756444216 Engine time: 0.12310453224927187 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-16/adapters_192_slots_96_rate_0.05-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-16/adapters_192_slots_96_rate_0.05-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [64 64 64]
Adapter prompts. [540, 33, 540, 33, 540, 33, 540, 33, 33, 33, 66, 66, 66, 66, 540, 66, 33, 540, 33, 66, 66, 33, 540, 540, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 540, 66, 33, 66, 540, 540, 66, 540, 33, 66, 66, 540, 66, 33, 33, 66, 540, 33, 66, 33, 540, 540, 66, 540, 540, 540, 33, 66, 540, 33, 66, 33, 66, 33, 33, 66, 540, 540, 33, 33, 33, 540, 540, 540, 66, 33, 33, 33, 33, 33, 540, 33, 66, 33, 540, 540, 33, 540, 33, 66, 66, 540, 33, 33, 33, 540, 540, 66, 540, 66, 540, 540, 66, 66, 33, 540, 66, 66, 66, 540, 66, 33, 66, 540, 540, 66, 540, 66, 33, 540, 66, 33, 66, 66, 33, 66, 540, 33, 66, 540, 33, 66, 540, 540, 66, 33, 540, 66, 33, 33, 66, 540, 540, 540, 33, 540, 33, 540, 33, 66, 33, 540, 540, 66, 540, 33, 540, 540, 540, 33, 540, 540, 540, 66, 66, 66, 66, 66, 66, 33, 540, 66, 540, 33, 540, 66, 33, 66, 33, 33, 66, 66, 66, 540, 66, 33, 33]
Prompts retrieved: 40896 . Total input tokens: 9030280 . Total output tokens: 8064424
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 1.407045615836978,
    "estimated_duration": 3599.9082946795884,
    "input_throughput": 934.9321495145373,
    "output_throughput": 827.2363505484954,
    "total_throughput": 1762.1685000630328,
    "itl": 25.78374952402708,
    "ttft": 7828.743361090555,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2062,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.163644979457088,
    "arrivals": 13872,
    "finished_requests": 13842,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4071149318479002. Arrivals time: 0.044205715879797935 Scheduler time: 0.9710288816131651 Scheduler overhead time: 0.11723763449117541 Adapter cache time: 0.09516892582178116 Engine time: 0.12109646527096629 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-32/adapters_192_slots_96_rate_0.05-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-32/adapters_192_slots_96_rate_0.05-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [64 64 64]
Adapter prompts. [540, 33, 540, 33, 540, 33, 540, 33, 33, 33, 66, 66, 66, 66, 540, 66, 33, 540, 33, 66, 66, 33, 540, 540, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 540, 66, 33, 66, 540, 540, 66, 540, 33, 66, 66, 540, 66, 33, 33, 66, 540, 33, 66, 33, 540, 540, 66, 540, 540, 540, 33, 66, 540, 33, 66, 33, 66, 33, 33, 66, 540, 540, 33, 33, 33, 540, 540, 540, 66, 33, 33, 33, 33, 33, 540, 33, 66, 33, 540, 540, 33, 540, 33, 66, 66, 540, 33, 33, 33, 540, 540, 66, 540, 66, 540, 540, 66, 66, 33, 540, 66, 66, 66, 540, 66, 33, 66, 540, 540, 66, 540, 66, 33, 540, 66, 33, 66, 66, 33, 66, 540, 33, 66, 540, 33, 66, 540, 540, 66, 33, 540, 66, 33, 33, 66, 540, 540, 540, 33, 540, 33, 540, 33, 66, 33, 540, 540, 66, 540, 33, 540, 540, 540, 33, 540, 540, 540, 66, 66, 66, 66, 66, 66, 33, 540, 66, 540, 33, 540, 66, 33, 66, 33, 33, 66, 66, 66, 540, 66, 33, 33]
Prompts retrieved: 40896 . Total input tokens: 9030280 . Total output tokens: 8064424
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 1.4224769533611834,
    "estimated_duration": 3599.9008040561534,
    "input_throughput": 934.9340949083274,
    "output_throughput": 827.2380718503675,
    "total_throughput": 1762.1721667586949,
    "itl": 25.541248345449183,
    "ttft": 7828.366315657097,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2032,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.968570324182206,
    "arrivals": 13872,
    "finished_requests": 13842,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.422551166266203. Arrivals time: 0.044530516024678946 Scheduler time: 0.9842566205188632 Scheduler overhead time: 0.12001230800524354 Adapter cache time: 0.09522288665175438 Engine time: 0.11990197282284498 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-8/adapters_192_slots_96_rate_0.025-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-8/adapters_192_slots_96_rate_0.025-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [64 64 64]
Adapter prompts. [270, 66, 270, 66, 270, 66, 270, 66, 66, 66, 135, 135, 135, 135, 270, 135, 66, 270, 66, 135, 135, 66, 270, 270, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 270, 135, 66, 135, 270, 270, 135, 270, 66, 135, 135, 270, 135, 66, 66, 135, 270, 66, 135, 66, 270, 270, 135, 270, 270, 270, 66, 135, 270, 66, 135, 66, 135, 66, 66, 135, 270, 270, 66, 66, 66, 270, 270, 270, 135, 66, 66, 66, 66, 66, 270, 66, 135, 66, 270, 270, 66, 270, 66, 135, 135, 270, 66, 66, 66, 270, 270, 135, 270, 135, 270, 270, 135, 135, 66, 270, 135, 135, 135, 270, 135, 66, 135, 270, 270, 135, 270, 135, 66, 270, 135, 66, 135, 135, 66, 135, 270, 66, 135, 270, 66, 135, 270, 270, 135, 66, 270, 135, 66, 66, 135, 270, 270, 270, 66, 270, 66, 270, 66, 135, 66, 270, 270, 135, 270, 66, 270, 270, 270, 66, 270, 270, 270, 135, 135, 135, 135, 135, 135, 66, 270, 135, 270, 66, 270, 135, 66, 135, 66, 66, 135, 135, 135, 270, 135, 66, 66]
Prompts retrieved: 30144 . Total input tokens: 6624692 . Total output tokens: 5935147
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 1.1839401847682893,
    "estimated_duration": 3599.2323281460494,
    "input_throughput": 688.9330206914561,
    "output_throughput": 608.3063832469436,
    "total_throughput": 1297.2394039383998,
    "itl": 23.82568280953961,
    "ttft": 4997.506098497392,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4031,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 26.654620807788127,
    "arrivals": 10170,
    "finished_requests": 10156,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1840100078843534. Arrivals time: 0.03695606393739581 Scheduler time: 0.7461786703206599 Scheduler overhead time: 0.12467211298644543 Adapter cache time: 0.08680339343845844 Engine time: 0.127483572345227 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-16/adapters_192_slots_96_rate_0.025-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-16/adapters_192_slots_96_rate_0.025-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [64 64 64]
Adapter prompts. [270, 66, 270, 66, 270, 66, 270, 66, 66, 66, 135, 135, 135, 135, 270, 135, 66, 270, 66, 135, 135, 66, 270, 270, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 270, 135, 66, 135, 270, 270, 135, 270, 66, 135, 135, 270, 135, 66, 66, 135, 270, 66, 135, 66, 270, 270, 135, 270, 270, 270, 66, 135, 270, 66, 135, 66, 135, 66, 66, 135, 270, 270, 66, 66, 66, 270, 270, 270, 135, 66, 66, 66, 66, 66, 270, 66, 135, 66, 270, 270, 66, 270, 66, 135, 135, 270, 66, 66, 66, 270, 270, 135, 270, 135, 270, 270, 135, 135, 66, 270, 135, 135, 135, 270, 135, 66, 135, 270, 270, 135, 270, 135, 66, 270, 135, 66, 135, 135, 66, 135, 270, 66, 135, 270, 66, 135, 270, 270, 135, 66, 270, 135, 66, 66, 135, 270, 270, 270, 66, 270, 66, 270, 66, 135, 66, 270, 270, 135, 270, 66, 270, 270, 270, 66, 270, 270, 270, 135, 135, 135, 135, 135, 135, 66, 270, 135, 270, 66, 270, 135, 66, 135, 66, 66, 135, 135, 135, 270, 135, 66, 66]
Prompts retrieved: 30144 . Total input tokens: 6624692 . Total output tokens: 5935147
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 1.1767724826931953,
    "estimated_duration": 3599.2438335609986,
    "input_throughput": 688.9308184343594,
    "output_throughput": 608.3044387225716,
    "total_throughput": 1297.2352571569309,
    "itl": 23.84710719029647,
    "ttft": 4997.8785205933345,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4033,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 29.42513873259925,
    "arrivals": 10170,
    "finished_requests": 10156,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.176841162610799. Arrivals time: 0.036266057286411524 Scheduler time: 0.7440654616802931 Scheduler overhead time: 0.12436691205948591 Adapter cache time: 0.08670287486165762 Engine time: 0.12402481539174914 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-32/adapters_192_slots_96_rate_0.025-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-32/adapters_192_slots_96_rate_0.025-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [64 64 64]
Adapter prompts. [270, 66, 270, 66, 270, 66, 270, 66, 66, 66, 135, 135, 135, 135, 270, 135, 66, 270, 66, 135, 135, 66, 270, 270, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 270, 135, 66, 135, 270, 270, 135, 270, 66, 135, 135, 270, 135, 66, 66, 135, 270, 66, 135, 66, 270, 270, 135, 270, 270, 270, 66, 135, 270, 66, 135, 66, 135, 66, 66, 135, 270, 270, 66, 66, 66, 270, 270, 270, 135, 66, 66, 66, 66, 66, 270, 66, 135, 66, 270, 270, 66, 270, 66, 135, 135, 270, 66, 66, 66, 270, 270, 135, 270, 135, 270, 270, 135, 135, 66, 270, 135, 135, 135, 270, 135, 66, 135, 270, 270, 135, 270, 135, 66, 270, 135, 66, 135, 135, 66, 135, 270, 66, 135, 270, 66, 135, 270, 270, 135, 66, 270, 135, 66, 66, 135, 270, 270, 270, 66, 270, 66, 270, 66, 135, 66, 270, 270, 135, 270, 66, 270, 270, 270, 66, 270, 270, 270, 135, 135, 135, 135, 135, 135, 66, 270, 135, 270, 66, 270, 135, 66, 135, 66, 66, 135, 135, 135, 270, 135, 66, 66]
Prompts retrieved: 30144 . Total input tokens: 6624692 . Total output tokens: 5935147
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 1.1913170157931745,
    "estimated_duration": 3599.2493108896447,
    "input_throughput": 688.929770021154,
    "output_throughput": 608.3035130063902,
    "total_throughput": 1297.2332830275443,
    "itl": 23.85515071991174,
    "ttft": 4997.893149430133,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4033,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 30.20752467227297,
    "arrivals": 10170,
    "finished_requests": 10156,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1913741547614336. Arrivals time: 0.03651424078270793 Scheduler time: 0.7556103323586285 Scheduler overhead time: 0.12407752498984337 Adapter cache time: 0.08702288148924708 Engine time: 0.12656758166849613 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-16/adapters_192_slots_96_rate_0.025-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-16/adapters_192_slots_96_rate_0.025-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [64 64 64]
Adapter prompts. [270, 66, 270, 66, 270, 66, 270, 66, 66, 66, 135, 135, 135, 135, 270, 135, 66, 270, 66, 135, 135, 66, 270, 270, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 270, 135, 66, 135, 270, 270, 135, 270, 66, 135, 135, 270, 135, 66, 66, 135, 270, 66, 135, 66, 270, 270, 135, 270, 270, 270, 66, 135, 270, 66, 135, 66, 135, 66, 66, 135, 270, 270, 66, 66, 66, 270, 270, 270, 135, 66, 66, 66, 66, 66, 270, 66, 135, 66, 270, 270, 66, 270, 66, 135, 135, 270, 66, 66, 66, 270, 270, 135, 270, 135, 270, 270, 135, 135, 66, 270, 135, 135, 135, 270, 135, 66, 135, 270, 270, 135, 270, 135, 66, 270, 135, 66, 135, 135, 66, 135, 270, 66, 135, 270, 66, 135, 270, 270, 135, 66, 270, 135, 66, 66, 135, 270, 270, 270, 66, 270, 66, 270, 66, 135, 66, 270, 270, 135, 270, 66, 270, 270, 270, 66, 270, 270, 270, 135, 135, 135, 135, 135, 135, 66, 270, 135, 270, 66, 270, 135, 66, 135, 66, 66, 135, 135, 135, 270, 135, 66, 66]
Prompts retrieved: 30144 . Total input tokens: 6624692 . Total output tokens: 5935147
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 1.1865414278581738,
    "estimated_duration": 3599.2428454881133,
    "input_throughput": 688.9310075613205,
    "output_throughput": 608.304605715783,
    "total_throughput": 1297.2356132771035,
    "itl": 23.832754257255914,
    "ttft": 4997.815862730627,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4033,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 27.589910605881254,
    "arrivals": 10170,
    "finished_requests": 10156,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1866165427491069. Arrivals time: 0.036550332326442 Scheduler time: 0.7485998552292585 Scheduler overhead time: 0.12487798044458032 Adapter cache time: 0.08619305957108736 Engine time: 0.12853828817605972 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-32/adapters_192_slots_96_rate_0.025-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-32/adapters_192_slots_96_rate_0.025-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [64 64 64]
Adapter prompts. [270, 66, 270, 66, 270, 66, 270, 66, 66, 66, 135, 135, 135, 135, 270, 135, 66, 270, 66, 135, 135, 66, 270, 270, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 270, 135, 66, 135, 270, 270, 135, 270, 66, 135, 135, 270, 135, 66, 66, 135, 270, 66, 135, 66, 270, 270, 135, 270, 270, 270, 66, 135, 270, 66, 135, 66, 135, 66, 66, 135, 270, 270, 66, 66, 66, 270, 270, 270, 135, 66, 66, 66, 66, 66, 270, 66, 135, 66, 270, 270, 66, 270, 66, 135, 135, 270, 66, 66, 66, 270, 270, 135, 270, 135, 270, 270, 135, 135, 66, 270, 135, 135, 135, 270, 135, 66, 135, 270, 270, 135, 270, 135, 66, 270, 135, 66, 135, 135, 66, 135, 270, 66, 135, 270, 66, 135, 270, 270, 135, 66, 270, 135, 66, 66, 135, 270, 270, 270, 66, 270, 66, 270, 66, 135, 66, 270, 270, 135, 270, 66, 270, 270, 270, 66, 270, 270, 270, 135, 135, 135, 135, 135, 135, 66, 270, 135, 270, 66, 270, 135, 66, 135, 66, 66, 135, 135, 135, 270, 135, 66, 66]
Prompts retrieved: 30144 . Total input tokens: 6624692 . Total output tokens: 5935147
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 1.179253004025668,
    "estimated_duration": 3599.2337338393163,
    "input_throughput": 688.932751626266,
    "output_throughput": 608.3061456707676,
    "total_throughput": 1297.2388972970336,
    "itl": 23.849093569499544,
    "ttft": 4997.967659696838,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4030,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 29.91461396385111,
    "arrivals": 10170,
    "finished_requests": 10156,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1793555920012295. Arrivals time: 0.03631053538993001 Scheduler time: 0.7413475112989545 Scheduler overhead time: 0.12584514869377017 Adapter cache time: 0.08681226009503007 Engine time: 0.1270387633703649 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-16/adapters_192_slots_96_rate_0.025-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-16/adapters_192_slots_96_rate_0.025-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [64 64 64]
Adapter prompts. [270, 66, 270, 66, 270, 66, 270, 66, 66, 66, 135, 135, 135, 135, 270, 135, 66, 270, 66, 135, 135, 66, 270, 270, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 270, 135, 66, 135, 270, 270, 135, 270, 66, 135, 135, 270, 135, 66, 66, 135, 270, 66, 135, 66, 270, 270, 135, 270, 270, 270, 66, 135, 270, 66, 135, 66, 135, 66, 66, 135, 270, 270, 66, 66, 66, 270, 270, 270, 135, 66, 66, 66, 66, 66, 270, 66, 135, 66, 270, 270, 66, 270, 66, 135, 135, 270, 66, 66, 66, 270, 270, 135, 270, 135, 270, 270, 135, 135, 66, 270, 135, 135, 135, 270, 135, 66, 135, 270, 270, 135, 270, 135, 66, 270, 135, 66, 135, 135, 66, 135, 270, 66, 135, 270, 66, 135, 270, 270, 135, 66, 270, 135, 66, 66, 135, 270, 270, 270, 66, 270, 66, 270, 66, 135, 66, 270, 270, 135, 270, 66, 270, 270, 270, 66, 270, 270, 270, 135, 135, 135, 135, 135, 135, 66, 270, 135, 270, 66, 270, 135, 66, 135, 66, 66, 135, 135, 135, 270, 135, 66, 66]
Prompts retrieved: 30144 . Total input tokens: 6624692 . Total output tokens: 5935147
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 1.1728449589572847,
    "estimated_duration": 3599.2425632742184,
    "input_throughput": 688.9310615798812,
    "output_throughput": 608.3046534124885,
    "total_throughput": 1297.2357149923696,
    "itl": 23.818657613019464,
    "ttft": 4997.540111983738,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4031,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 25.733585311442145,
    "arrivals": 10170,
    "finished_requests": 10156,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1729002818465233. Arrivals time: 0.03642441565170884 Scheduler time: 0.7394126779399812 Scheduler overhead time: 0.1248970590531826 Adapter cache time: 0.08540803845971823 Engine time: 0.124868243932724 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-32/adapters_192_slots_96_rate_0.025-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-32/adapters_192_slots_96_rate_0.025-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [64 64 64]
Adapter prompts. [270, 66, 270, 66, 270, 66, 270, 66, 66, 66, 135, 135, 135, 135, 270, 135, 66, 270, 66, 135, 135, 66, 270, 270, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 270, 135, 66, 135, 270, 270, 135, 270, 66, 135, 135, 270, 135, 66, 66, 135, 270, 66, 135, 66, 270, 270, 135, 270, 270, 270, 66, 135, 270, 66, 135, 66, 135, 66, 66, 135, 270, 270, 66, 66, 66, 270, 270, 270, 135, 66, 66, 66, 66, 66, 270, 66, 135, 66, 270, 270, 66, 270, 66, 135, 135, 270, 66, 66, 66, 270, 270, 135, 270, 135, 270, 270, 135, 135, 66, 270, 135, 135, 135, 270, 135, 66, 135, 270, 270, 135, 270, 135, 66, 270, 135, 66, 135, 135, 66, 135, 270, 66, 135, 270, 66, 135, 270, 270, 135, 66, 270, 135, 66, 66, 135, 270, 270, 270, 66, 270, 66, 270, 66, 135, 66, 270, 270, 135, 270, 66, 270, 270, 270, 66, 270, 270, 270, 135, 135, 135, 135, 135, 135, 66, 270, 135, 270, 66, 270, 135, 66, 135, 66, 66, 135, 135, 135, 270, 135, 66, 66]
Prompts retrieved: 30144 . Total input tokens: 6624692 . Total output tokens: 5935147
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 1.1855731308460236,
    "estimated_duration": 3599.24086375956,
    "input_throughput": 688.9313868841557,
    "output_throughput": 608.304940646023,
    "total_throughput": 1297.2363275301789,
    "itl": 23.851031338896085,
    "ttft": 4997.9353216730315,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4032,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 29.652296887264907,
    "arrivals": 10170,
    "finished_requests": 10156,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.185636478010565. Arrivals time: 0.036493421997874975 Scheduler time: 0.7498401962220669 Scheduler overhead time: 0.12466466147452593 Adapter cache time: 0.08615958830341697 Engine time: 0.12680100230500102 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-8/adapters_192_slots_96_rate_0.025-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-8/adapters_192_slots_96_rate_0.025-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [64 64 64]
Adapter prompts. [270, 33, 270, 33, 270, 33, 270, 33, 33, 33, 135, 135, 135, 135, 270, 135, 33, 270, 33, 135, 135, 33, 270, 270, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 270, 135, 33, 135, 270, 270, 135, 270, 33, 135, 135, 270, 135, 33, 33, 135, 270, 33, 135, 33, 270, 270, 135, 270, 270, 270, 33, 135, 270, 33, 135, 33, 135, 33, 33, 135, 270, 270, 33, 33, 33, 270, 270, 270, 135, 33, 33, 33, 33, 33, 270, 33, 135, 33, 270, 270, 33, 270, 33, 135, 135, 270, 33, 33, 33, 270, 270, 135, 270, 135, 270, 270, 135, 135, 33, 270, 135, 135, 135, 270, 135, 33, 135, 270, 270, 135, 270, 135, 33, 270, 135, 33, 135, 135, 33, 135, 270, 33, 135, 270, 33, 135, 270, 270, 135, 33, 270, 135, 33, 33, 135, 270, 270, 270, 33, 270, 33, 270, 33, 135, 33, 270, 270, 135, 270, 33, 270, 270, 270, 33, 270, 270, 270, 135, 135, 135, 135, 135, 135, 33, 270, 135, 270, 33, 270, 135, 33, 135, 33, 33, 135, 135, 135, 270, 135, 33, 33]
Prompts retrieved: 28032 . Total input tokens: 6164867 . Total output tokens: 5513241
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 1.1412345161661506,
    "estimated_duration": 3599.772605665885,
    "input_throughput": 640.7738078703775,
    "output_throughput": 568.6209169929955,
    "total_throughput": 1209.3947248633729,
    "itl": 23.44276411713747,
    "ttft": 5753.61742715584,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3129,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.690227860970694,
    "arrivals": 9452,
    "finished_requests": 9437,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1413240772671998. Arrivals time: 0.03510833019390702 Scheduler time: 0.7092035859823227 Scheduler overhead time: 0.1255426718853414 Adapter cache time: 0.08056594803929329 Engine time: 0.12843635119497776 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-16/adapters_192_slots_96_rate_0.025-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-16/adapters_192_slots_96_rate_0.025-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [64 64 64]
Adapter prompts. [270, 33, 270, 33, 270, 33, 270, 33, 33, 33, 135, 135, 135, 135, 270, 135, 33, 270, 33, 135, 135, 33, 270, 270, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 270, 135, 33, 135, 270, 270, 135, 270, 33, 135, 135, 270, 135, 33, 33, 135, 270, 33, 135, 33, 270, 270, 135, 270, 270, 270, 33, 135, 270, 33, 135, 33, 135, 33, 33, 135, 270, 270, 33, 33, 33, 270, 270, 270, 135, 33, 33, 33, 33, 33, 270, 33, 135, 33, 270, 270, 33, 270, 33, 135, 135, 270, 33, 33, 33, 270, 270, 135, 270, 135, 270, 270, 135, 135, 33, 270, 135, 135, 135, 270, 135, 33, 135, 270, 270, 135, 270, 135, 33, 270, 135, 33, 135, 135, 33, 135, 270, 33, 135, 270, 33, 135, 270, 270, 135, 33, 270, 135, 33, 33, 135, 270, 270, 270, 33, 270, 33, 270, 33, 135, 33, 270, 270, 135, 270, 33, 270, 270, 270, 33, 270, 270, 270, 135, 135, 135, 135, 135, 135, 33, 270, 135, 270, 33, 270, 135, 33, 135, 33, 33, 135, 135, 135, 270, 135, 33, 33]
Prompts retrieved: 28032 . Total input tokens: 6164867 . Total output tokens: 5513241
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 1.14212451223284,
    "estimated_duration": 3599.786332750043,
    "input_throughput": 640.7713644042453,
    "output_throughput": 568.6187486678616,
    "total_throughput": 1209.390113072107,
    "itl": 23.462994220667216,
    "ttft": 5754.019606788432,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3129,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 22.793377198869788,
    "arrivals": 9452,
    "finished_requests": 9437,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.142181282863021. Arrivals time: 0.03496898477897048 Scheduler time: 0.7105160048231483 Scheduler overhead time: 0.12582656042650342 Adapter cache time: 0.08081356715410948 Engine time: 0.12768534012138844 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-32/adapters_192_slots_96_rate_0.025-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-32/adapters_192_slots_96_rate_0.025-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [64 64 64]
Adapter prompts. [270, 33, 270, 33, 270, 33, 270, 33, 33, 33, 135, 135, 135, 135, 270, 135, 33, 270, 33, 135, 135, 33, 270, 270, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 270, 135, 33, 135, 270, 270, 135, 270, 33, 135, 135, 270, 135, 33, 33, 135, 270, 33, 135, 33, 270, 270, 135, 270, 270, 270, 33, 135, 270, 33, 135, 33, 135, 33, 33, 135, 270, 270, 33, 33, 33, 270, 270, 270, 135, 33, 33, 33, 33, 33, 270, 33, 135, 33, 270, 270, 33, 270, 33, 135, 135, 270, 33, 33, 33, 270, 270, 135, 270, 135, 270, 270, 135, 135, 33, 270, 135, 135, 135, 270, 135, 33, 135, 270, 270, 135, 270, 135, 33, 270, 135, 33, 135, 135, 33, 135, 270, 33, 135, 270, 33, 135, 270, 270, 135, 33, 270, 135, 33, 33, 135, 270, 270, 270, 33, 270, 33, 270, 33, 135, 33, 270, 270, 135, 270, 33, 270, 270, 270, 33, 270, 270, 270, 135, 135, 135, 135, 135, 135, 33, 270, 135, 270, 33, 270, 135, 33, 135, 33, 33, 135, 135, 135, 270, 135, 33, 33]
Prompts retrieved: 28032 . Total input tokens: 6164867 . Total output tokens: 5513241
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 1.1463963566347957,
    "estimated_duration": 3599.784833096703,
    "input_throughput": 640.771631346566,
    "output_throughput": 568.6189855517437,
    "total_throughput": 1209.3906168983096,
    "itl": 23.46538549854075,
    "ttft": 5754.073837839609,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3130,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 23.400131431916318,
    "arrivals": 9452,
    "finished_requests": 9437,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1464639035984874. Arrivals time: 0.0348446206189692 Scheduler time: 0.7145891040563583 Scheduler overhead time: 0.12581959879025817 Adapter cache time: 0.08073995867744088 Engine time: 0.12791973492130637 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-16/adapters_192_slots_96_rate_0.025-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-16/adapters_192_slots_96_rate_0.025-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [64 64 64]
Adapter prompts. [270, 33, 270, 33, 270, 33, 270, 33, 33, 33, 135, 135, 135, 135, 270, 135, 33, 270, 33, 135, 135, 33, 270, 270, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 270, 135, 33, 135, 270, 270, 135, 270, 33, 135, 135, 270, 135, 33, 33, 135, 270, 33, 135, 33, 270, 270, 135, 270, 270, 270, 33, 135, 270, 33, 135, 33, 135, 33, 33, 135, 270, 270, 33, 33, 33, 270, 270, 270, 135, 33, 33, 33, 33, 33, 270, 33, 135, 33, 270, 270, 33, 270, 33, 135, 135, 270, 33, 33, 33, 270, 270, 135, 270, 135, 270, 270, 135, 135, 33, 270, 135, 135, 135, 270, 135, 33, 135, 270, 270, 135, 270, 135, 33, 270, 135, 33, 135, 135, 33, 135, 270, 33, 135, 270, 33, 135, 270, 270, 135, 33, 270, 135, 33, 33, 135, 270, 270, 270, 33, 270, 33, 270, 33, 135, 33, 270, 270, 135, 270, 33, 270, 270, 270, 33, 270, 270, 270, 135, 135, 135, 135, 135, 135, 33, 270, 135, 270, 33, 270, 135, 33, 135, 33, 33, 135, 135, 135, 270, 135, 33, 33]
Prompts retrieved: 28032 . Total input tokens: 6164867 . Total output tokens: 5513241
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 1.1516229631379247,
    "estimated_duration": 3599.761988406471,
    "input_throughput": 640.7756977902571,
    "output_throughput": 568.6225941027053,
    "total_throughput": 1209.3982918929623,
    "itl": 23.447484512141234,
    "ttft": 5753.843483813594,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3129,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 21.38016824803837,
    "arrivals": 9452,
    "finished_requests": 9437,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1517421309836209. Arrivals time: 0.03560129692777991 Scheduler time: 0.7136971526779234 Scheduler overhead time: 0.12701121484860778 Adapter cache time: 0.08144067227840424 Engine time: 0.1311179748736322 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-32/adapters_192_slots_96_rate_0.025-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-32/adapters_192_slots_96_rate_0.025-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [64 64 64]
Adapter prompts. [270, 33, 270, 33, 270, 33, 270, 33, 33, 33, 135, 135, 135, 135, 270, 135, 33, 270, 33, 135, 135, 33, 270, 270, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 270, 135, 33, 135, 270, 270, 135, 270, 33, 135, 135, 270, 135, 33, 33, 135, 270, 33, 135, 33, 270, 270, 135, 270, 270, 270, 33, 135, 270, 33, 135, 33, 135, 33, 33, 135, 270, 270, 33, 33, 33, 270, 270, 270, 135, 33, 33, 33, 33, 33, 270, 33, 135, 33, 270, 270, 33, 270, 33, 135, 135, 270, 33, 33, 33, 270, 270, 135, 270, 135, 270, 270, 135, 135, 33, 270, 135, 135, 135, 270, 135, 33, 135, 270, 270, 135, 270, 135, 33, 270, 135, 33, 135, 135, 33, 135, 270, 33, 135, 270, 33, 135, 270, 270, 135, 33, 270, 135, 33, 33, 135, 270, 270, 270, 33, 270, 33, 270, 33, 135, 33, 270, 270, 135, 270, 33, 270, 270, 270, 33, 270, 270, 270, 135, 135, 135, 135, 135, 135, 33, 270, 135, 270, 33, 270, 135, 33, 135, 33, 33, 135, 135, 135, 270, 135, 33, 33]
Prompts retrieved: 28032 . Total input tokens: 6164867 . Total output tokens: 5513241
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 1.1285802368074656,
    "estimated_duration": 3599.7661205601016,
    "input_throughput": 640.7749622470197,
    "output_throughput": 568.6219413836569,
    "total_throughput": 1209.3969036306767,
    "itl": 23.462721755889778,
    "ttft": 5753.969623773882,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 23.173341116551814,
    "arrivals": 9452,
    "finished_requests": 9437,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.128627489786595. Arrivals time: 0.034664883743971586 Scheduler time: 0.6977579835802317 Scheduler overhead time: 0.12627686839550734 Adapter cache time: 0.08055179100483656 Engine time: 0.1270913938060403 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-16/adapters_192_slots_96_rate_0.025-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-16/adapters_192_slots_96_rate_0.025-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [64 64 64]
Adapter prompts. [270, 33, 270, 33, 270, 33, 270, 33, 33, 33, 135, 135, 135, 135, 270, 135, 33, 270, 33, 135, 135, 33, 270, 270, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 270, 135, 33, 135, 270, 270, 135, 270, 33, 135, 135, 270, 135, 33, 33, 135, 270, 33, 135, 33, 270, 270, 135, 270, 270, 270, 33, 135, 270, 33, 135, 33, 135, 33, 33, 135, 270, 270, 33, 33, 33, 270, 270, 270, 135, 33, 33, 33, 33, 33, 270, 33, 135, 33, 270, 270, 33, 270, 33, 135, 135, 270, 33, 33, 33, 270, 270, 135, 270, 135, 270, 270, 135, 135, 33, 270, 135, 135, 135, 270, 135, 33, 135, 270, 270, 135, 270, 135, 33, 270, 135, 33, 135, 135, 33, 135, 270, 33, 135, 270, 33, 135, 270, 270, 135, 33, 270, 135, 33, 33, 135, 270, 270, 270, 33, 270, 33, 270, 33, 135, 33, 270, 270, 135, 270, 33, 270, 270, 270, 33, 270, 270, 270, 135, 135, 135, 135, 135, 135, 33, 270, 135, 270, 33, 270, 135, 33, 135, 33, 33, 135, 135, 135, 270, 135, 33, 33]
Prompts retrieved: 28032 . Total input tokens: 6164867 . Total output tokens: 5513241
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 1.134329198859632,
    "estimated_duration": 3599.7751268282796,
    "input_throughput": 640.7733590937816,
    "output_throughput": 568.6205187498769,
    "total_throughput": 1209.3938778436584,
    "itl": 23.437459912346842,
    "ttft": 5753.629408427826,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3129,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.975288623046755,
    "arrivals": 9452,
    "finished_requests": 9437,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.134382776916027. Arrivals time: 0.034618718549609184 Scheduler time: 0.7035551248118281 Scheduler overhead time: 0.12647391902282834 Adapter cache time: 0.08000435028225183 Engine time: 0.12707954412326217 
