INFO 05-31 19:30:52 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 05-31 19:30:52 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.025_size_8-8-8/adapters_128_slots_64_rate_0.8-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.025_size_8-8-8/adapters_128_slots_64_rate_0.8-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [42 43 43]
Adapter prompts. [8640, 540, 8640, 8640, 270, 270, 8640, 270, 540, 540, 540, 270, 8640, 540, 270, 8640, 540, 270, 270, 270, 270, 540, 540, 8640, 540, 270, 540, 540, 540, 540, 8640, 540, 270, 540, 270, 8640, 8640, 270, 540, 540, 270, 540, 270, 540, 540, 8640, 8640, 8640, 8640, 540, 540, 270, 540, 8640, 8640, 540, 270, 270, 270, 8640, 540, 540, 540, 540, 8640, 540, 8640, 270, 270, 540, 270, 8640, 8640, 270, 270, 540, 540, 540, 270, 8640, 270, 8640, 540, 270, 8640, 8640, 540, 540, 270, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 270, 8640, 270, 270, 8640, 540, 8640, 8640, 540, 8640, 270, 540, 8640, 270, 8640, 540, 270, 540, 540, 8640, 8640, 270, 270, 8640, 270, 270, 270, 540, 270]
Prompts retrieved: 406080 . Total input tokens: 90338405 . Total output tokens: 79955162
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 6.9151678630150855,
    "estimated_duration": 3600.095962229022,
    "input_throughput": 5630.701018160928,
    "output_throughput": 4911.585464808546,
    "total_throughput": 10542.286482969474,
    "itl": 117.2137370508598,
    "ttft": 1388501.3692270773,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1111,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.34638643449655,
    "arrivals": 135164,
    "finished_requests": 81935,
    "scheduler_time": 115.86773575544203
}
#Debug simulation 
Total elapsed time: 6.91530461423099. Arrivals time: 0.2523577902466059 Scheduler time: 6.522913904394954 Scheduler overhead time: 0.047981398180127144 Adapter cache time: 0.020623760763555765 Engine time: 0.04864785773679614 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.025_size_8-8-16/adapters_128_slots_64_rate_0.8-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.025_size_8-8-16/adapters_128_slots_64_rate_0.8-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [42 43 43]
Adapter prompts. [8640, 540, 8640, 8640, 270, 270, 8640, 270, 540, 540, 540, 270, 8640, 540, 270, 8640, 540, 270, 270, 270, 270, 540, 540, 8640, 540, 270, 540, 540, 540, 540, 8640, 540, 270, 540, 270, 8640, 8640, 270, 540, 540, 270, 540, 270, 540, 540, 8640, 8640, 8640, 8640, 540, 540, 270, 540, 8640, 8640, 540, 270, 270, 270, 8640, 540, 540, 540, 540, 8640, 540, 8640, 270, 270, 540, 270, 8640, 8640, 270, 270, 540, 540, 540, 270, 8640, 270, 8640, 540, 270, 8640, 8640, 540, 540, 270, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 270, 8640, 270, 270, 8640, 540, 8640, 8640, 540, 8640, 270, 540, 8640, 270, 8640, 540, 270, 540, 540, 8640, 8640, 270, 270, 8640, 270, 270, 270, 540, 270]
Prompts retrieved: 406080 . Total input tokens: 90338405 . Total output tokens: 79955162
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 6.59803547617048,
    "estimated_duration": 3600.076980739247,
    "input_throughput": 5472.930747151455,
    "output_throughput": 4778.782812712882,
    "total_throughput": 10251.713559864336,
    "itl": 109.55532657278417,
    "ttft": 1425883.4502842624,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1280,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.347241968326237,
    "arrivals": 135164,
    "finished_requests": 79663,
    "scheduler_time": 117.72540054655461
}
#Debug simulation 
Total elapsed time: 6.598164869938046. Arrivals time: 0.2465130789205432 Scheduler time: 6.203526735771447 Scheduler overhead time: 0.05058804526925087 Adapter cache time: 0.022538532968610525 Engine time: 0.051385358441621065 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.025_size_8-8-32/adapters_128_slots_64_rate_0.8-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.025_size_8-8-32/adapters_128_slots_64_rate_0.8-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [42 43 43]
Adapter prompts. [8640, 540, 8640, 8640, 270, 270, 8640, 270, 540, 540, 540, 270, 8640, 540, 270, 8640, 540, 270, 270, 270, 270, 540, 540, 8640, 540, 270, 540, 540, 540, 540, 8640, 540, 270, 540, 270, 8640, 8640, 270, 540, 540, 270, 540, 270, 540, 540, 8640, 8640, 8640, 8640, 540, 540, 270, 540, 8640, 8640, 540, 270, 270, 270, 8640, 540, 540, 540, 540, 8640, 540, 8640, 270, 270, 540, 270, 8640, 8640, 270, 270, 540, 540, 540, 270, 8640, 270, 8640, 540, 270, 8640, 8640, 540, 540, 270, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 270, 8640, 270, 270, 8640, 540, 8640, 8640, 540, 8640, 270, 540, 8640, 270, 8640, 540, 270, 540, 540, 8640, 8640, 270, 270, 8640, 270, 270, 270, 540, 270]
Prompts retrieved: 406080 . Total input tokens: 90338405 . Total output tokens: 79955162
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 6.096532069146633,
    "estimated_duration": 3600.002423186403,
    "input_throughput": 5168.429576647702,
    "output_throughput": 4518.465847476387,
    "total_throughput": 9686.895424124088,
    "itl": 97.26338348847793,
    "ttft": 1499049.3409230683,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1699,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.73355856578312,
    "arrivals": 135164,
    "finished_requests": 75243,
    "scheduler_time": 121.41300810595109
}
#Debug simulation 
Total elapsed time: 6.096706462092698. Arrivals time: 0.23770676273852587 Scheduler time: 5.6928683472797275 Scheduler overhead time: 0.05536420829594135 Adapter cache time: 0.028104607947170734 Engine time: 0.05660892464220524 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.025_size_8-16-16/adapters_128_slots_64_rate_0.8-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.025_size_8-16-16/adapters_128_slots_64_rate_0.8-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [42 43 43]
Adapter prompts. [8640, 540, 8640, 8640, 270, 270, 8640, 270, 540, 540, 540, 270, 8640, 540, 270, 8640, 540, 270, 270, 270, 270, 540, 540, 8640, 540, 270, 540, 540, 540, 540, 8640, 540, 270, 540, 270, 8640, 8640, 270, 540, 540, 270, 540, 270, 540, 540, 8640, 8640, 8640, 8640, 540, 540, 270, 540, 8640, 8640, 540, 270, 270, 270, 8640, 540, 540, 540, 540, 8640, 540, 8640, 270, 270, 540, 270, 8640, 8640, 270, 270, 540, 540, 540, 270, 8640, 270, 8640, 540, 270, 8640, 8640, 540, 540, 270, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 270, 8640, 270, 270, 8640, 540, 8640, 8640, 540, 8640, 270, 540, 8640, 270, 8640, 540, 270, 540, 540, 8640, 8640, 270, 270, 8640, 270, 270, 270, 540, 270]
Prompts retrieved: 406080 . Total input tokens: 90338405 . Total output tokens: 79955162
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 6.615143530070782,
    "estimated_duration": 3600.0463845090835,
    "input_throughput": 5473.481420903143,
    "output_throughput": 4778.935647615568,
    "total_throughput": 10252.417068518711,
    "itl": 109.54095175013971,
    "ttft": 1425656.9230134226,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1280,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.680895901136127,
    "arrivals": 135164,
    "finished_requests": 79669,
    "scheduler_time": 117.74161599434319
}
#Debug simulation 
Total elapsed time: 6.615258230827749. Arrivals time: 0.24805814772844315 Scheduler time: 6.218765429686755 Scheduler overhead time: 0.05073709413409233 Adapter cache time: 0.022315664682537317 Engine time: 0.051729277707636356 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.025_size_8-16-32/adapters_128_slots_64_rate_0.8-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.025_size_8-16-32/adapters_128_slots_64_rate_0.8-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [42 43 43]
Adapter prompts. [8640, 540, 8640, 8640, 270, 270, 8640, 270, 540, 540, 540, 270, 8640, 540, 270, 8640, 540, 270, 270, 270, 270, 540, 540, 8640, 540, 270, 540, 540, 540, 540, 8640, 540, 270, 540, 270, 8640, 8640, 270, 540, 540, 270, 540, 270, 540, 540, 8640, 8640, 8640, 8640, 540, 540, 270, 540, 8640, 8640, 540, 270, 270, 270, 8640, 540, 540, 540, 540, 8640, 540, 8640, 270, 270, 540, 270, 8640, 8640, 270, 270, 540, 540, 540, 270, 8640, 270, 8640, 540, 270, 8640, 8640, 540, 540, 270, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 270, 8640, 270, 270, 8640, 540, 8640, 8640, 540, 8640, 270, 540, 8640, 270, 8640, 540, 270, 540, 540, 8640, 8640, 270, 270, 8640, 270, 270, 270, 540, 270]
Prompts retrieved: 406080 . Total input tokens: 90338405 . Total output tokens: 79955162
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 6.108079415280372,
    "estimated_duration": 3600.076002618746,
    "input_throughput": 5168.417829641715,
    "output_throughput": 4518.800710920105,
    "total_throughput": 9687.21854056182,
    "itl": 97.25508350930504,
    "ttft": 1499009.7309727601,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1685,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.495343253644938,
    "arrivals": 135164,
    "finished_requests": 75249,
    "scheduler_time": 121.42366199062192
}
#Debug simulation 
Total elapsed time: 6.108198101166636. Arrivals time: 0.24139680434018373 Scheduler time: 5.700691462028772 Scheduler overhead time: 0.05558023834601045 Adapter cache time: 0.02781450469046831 Engine time: 0.056899527087807655 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.025_size_16-16-16/adapters_128_slots_64_rate_0.8-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.025_size_16-16-16/adapters_128_slots_64_rate_0.8-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [42 43 43]
Adapter prompts. [8640, 540, 8640, 8640, 270, 270, 8640, 270, 540, 540, 540, 270, 8640, 540, 270, 8640, 540, 270, 270, 270, 270, 540, 540, 8640, 540, 270, 540, 540, 540, 540, 8640, 540, 270, 540, 270, 8640, 8640, 270, 540, 540, 270, 540, 270, 540, 540, 8640, 8640, 8640, 8640, 540, 540, 270, 540, 8640, 8640, 540, 270, 270, 270, 8640, 540, 540, 540, 540, 8640, 540, 8640, 270, 270, 540, 270, 8640, 8640, 270, 270, 540, 540, 540, 270, 8640, 270, 8640, 540, 270, 8640, 8640, 540, 540, 270, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 270, 8640, 270, 270, 8640, 540, 8640, 8640, 540, 8640, 270, 540, 8640, 270, 8640, 540, 270, 540, 540, 8640, 8640, 270, 270, 8640, 270, 270, 270, 540, 270]
Prompts retrieved: 406080 . Total input tokens: 90338405 . Total output tokens: 79955162
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 6.628331888001412,
    "estimated_duration": 3600.0458713874705,
    "input_throughput": 5473.667754240433,
    "output_throughput": 4779.801595519161,
    "total_throughput": 10253.469349759594,
    "itl": 109.5148137661102,
    "ttft": 1425378.1740628965,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1250,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.979901175713126,
    "arrivals": 135164,
    "finished_requests": 79682,
    "scheduler_time": 117.75904640299242
}
#Debug simulation 
Total elapsed time: 6.628439662978053. Arrivals time: 0.2507908307015896 Scheduler time: 6.22878982918337 Scheduler overhead time: 0.050981353502720594 Adapter cache time: 0.022669809870421886 Engine time: 0.051622495986521244 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.025_size_16-16-32/adapters_128_slots_64_rate_0.8-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.025_size_16-16-32/adapters_128_slots_64_rate_0.8-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [42 43 43]
Adapter prompts. [8640, 540, 8640, 8640, 270, 270, 8640, 270, 540, 540, 540, 270, 8640, 540, 270, 8640, 540, 270, 270, 270, 270, 540, 540, 8640, 540, 270, 540, 540, 540, 540, 8640, 540, 270, 540, 270, 8640, 8640, 270, 540, 540, 270, 540, 270, 540, 540, 8640, 8640, 8640, 8640, 540, 540, 270, 540, 8640, 8640, 540, 270, 270, 270, 8640, 540, 540, 540, 540, 8640, 540, 8640, 270, 270, 540, 270, 8640, 8640, 270, 270, 540, 540, 540, 270, 8640, 270, 8640, 540, 270, 8640, 8640, 540, 540, 270, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 270, 8640, 270, 270, 8640, 540, 8640, 8640, 540, 8640, 270, 540, 8640, 270, 8640, 540, 270, 540, 540, 8640, 8640, 270, 270, 8640, 270, 270, 270, 540, 270]
Prompts retrieved: 406080 . Total input tokens: 90338405 . Total output tokens: 79955162
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 6.103075155988336,
    "estimated_duration": 3600.0126187616456,
    "input_throughput": 5168.944381756358,
    "output_throughput": 4518.989715540528,
    "total_throughput": 9687.934097296886,
    "itl": 97.25113093627657,
    "ttft": 1498933.4066561933,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1684,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.393857692368154,
    "arrivals": 135164,
    "finished_requests": 75252,
    "scheduler_time": 121.42518157171857
}
#Debug simulation 
Total elapsed time: 6.103186738211662. Arrivals time: 0.2387331584468484 Scheduler time: 5.698127262759954 Scheduler overhead time: 0.05544473044574261 Adapter cache time: 0.028313436079770327 Engine time: 0.05663692019879818 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-8/adapters_128_slots_64_rate_0.8-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-8/adapters_128_slots_64_rate_0.8-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [42 43 43]
Adapter prompts. [8640, 540, 8640, 8640, 135, 135, 8640, 135, 540, 540, 540, 135, 8640, 540, 135, 8640, 540, 135, 135, 135, 135, 540, 540, 8640, 540, 135, 540, 540, 540, 540, 8640, 540, 135, 540, 135, 8640, 8640, 135, 540, 540, 135, 540, 135, 540, 540, 8640, 8640, 8640, 8640, 540, 540, 135, 540, 8640, 8640, 540, 135, 135, 135, 8640, 540, 540, 540, 540, 8640, 540, 8640, 135, 135, 540, 135, 8640, 8640, 135, 135, 540, 540, 540, 135, 8640, 135, 8640, 540, 135, 8640, 8640, 540, 540, 135, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 135, 8640, 135, 135, 8640, 540, 8640, 8640, 540, 8640, 135, 540, 8640, 135, 8640, 540, 135, 540, 540, 8640, 8640, 135, 135, 8640, 135, 135, 135, 540, 135]
Prompts retrieved: 400410 . Total input tokens: 89102245 . Total output tokens: 78834433
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 6.541170237120241,
    "estimated_duration": 3600.0878772210717,
    "input_throughput": 5651.466490230517,
    "output_throughput": 4909.200720300838,
    "total_throughput": 10560.667210531354,
    "itl": 116.88954522725142,
    "ttft": 1374700.109088565,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1356,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.966426647324337,
    "arrivals": 133259,
    "finished_requests": 82015,
    "scheduler_time": 115.38153124958566
}
#Debug simulation 
Total elapsed time: 6.541302734985948. Arrivals time: 0.2509096381254494 Scheduler time: 6.148248237092048 Scheduler overhead time: 0.04800214618444443 Adapter cache time: 0.022640309296548367 Engine time: 0.049001782201230526 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-16/adapters_128_slots_64_rate_0.8-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-16/adapters_128_slots_64_rate_0.8-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [42 43 43]
Adapter prompts. [8640, 540, 8640, 8640, 135, 135, 8640, 135, 540, 540, 540, 135, 8640, 540, 135, 8640, 540, 135, 135, 135, 135, 540, 540, 8640, 540, 135, 540, 540, 540, 540, 8640, 540, 135, 540, 135, 8640, 8640, 135, 540, 540, 135, 540, 135, 540, 540, 8640, 8640, 8640, 8640, 540, 540, 135, 540, 8640, 8640, 540, 135, 135, 135, 8640, 540, 540, 540, 540, 8640, 540, 8640, 135, 135, 540, 135, 8640, 8640, 135, 135, 540, 540, 540, 135, 8640, 135, 8640, 540, 135, 8640, 8640, 540, 540, 135, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 135, 8640, 135, 135, 8640, 540, 8640, 8640, 540, 8640, 135, 540, 8640, 135, 8640, 540, 135, 540, 540, 8640, 8640, 135, 135, 8640, 135, 135, 135, 540, 135]
Prompts retrieved: 400410 . Total input tokens: 89102245 . Total output tokens: 78834433
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 6.286041100975126,
    "estimated_duration": 3600.0816743803166,
    "input_throughput": 5498.744414849277,
    "output_throughput": 4774.640287281472,
    "total_throughput": 10273.38470213075,
    "itl": 109.26910202714976,
    "ttft": 1413356.534777426,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1526,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.14535475932982,
    "arrivals": 133259,
    "finished_requests": 79788,
    "scheduler_time": 117.25010735950046
}
#Debug simulation 
Total elapsed time: 6.286154332570732. Arrivals time: 0.24941576831042767 Scheduler time: 5.885591546539217 Scheduler overhead time: 0.050616088323295116 Adapter cache time: 0.02518492005765438 Engine time: 0.051761583890765905 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-32/adapters_128_slots_64_rate_0.8-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-32/adapters_128_slots_64_rate_0.8-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [42 43 43]
Adapter prompts. [8640, 540, 8640, 8640, 135, 135, 8640, 135, 540, 540, 540, 135, 8640, 540, 135, 8640, 540, 135, 135, 135, 135, 540, 540, 8640, 540, 135, 540, 540, 540, 540, 8640, 540, 135, 540, 135, 8640, 8640, 135, 540, 540, 135, 540, 135, 540, 540, 8640, 8640, 8640, 8640, 540, 540, 135, 540, 8640, 8640, 540, 135, 135, 135, 8640, 540, 540, 540, 540, 8640, 540, 8640, 135, 135, 540, 135, 8640, 8640, 135, 135, 540, 540, 540, 135, 8640, 135, 8640, 540, 135, 8640, 8640, 540, 540, 135, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 135, 8640, 135, 135, 8640, 540, 8640, 8640, 540, 8640, 135, 540, 8640, 135, 8640, 540, 135, 540, 540, 8640, 8640, 135, 135, 8640, 135, 135, 135, 540, 135]
Prompts retrieved: 400410 . Total input tokens: 89102245 . Total output tokens: 78834433
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 5.8503575208596885,
    "estimated_duration": 3600.016172534361,
    "input_throughput": 5190.753625655175,
    "output_throughput": 4513.503612557705,
    "total_throughput": 9704.25723821288,
    "itl": 97.0212691821469,
    "ttft": 1487681.133237653,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1976,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.82709115314269,
    "arrivals": 133259,
    "finished_requests": 75327,
    "scheduler_time": 120.96719254909783
}
#Debug simulation 
Total elapsed time: 5.850497831590474. Arrivals time: 0.24014807119965553 Scheduler time: 5.441084035206586 Scheduler overhead time: 0.0553630948998034 Adapter cache time: 0.03101887833327055 Engine time: 0.056904117576777935 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.0125_size_8-16-16/adapters_128_slots_64_rate_0.8-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.0125_size_8-16-16/adapters_128_slots_64_rate_0.8-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [42 43 43]
Adapter prompts. [8640, 540, 8640, 8640, 135, 135, 8640, 135, 540, 540, 540, 135, 8640, 540, 135, 8640, 540, 135, 135, 135, 135, 540, 540, 8640, 540, 135, 540, 540, 540, 540, 8640, 540, 135, 540, 135, 8640, 8640, 135, 540, 540, 135, 540, 135, 540, 540, 8640, 8640, 8640, 8640, 540, 540, 135, 540, 8640, 8640, 540, 135, 135, 135, 8640, 540, 540, 540, 540, 8640, 540, 8640, 135, 135, 540, 135, 8640, 8640, 135, 135, 540, 540, 540, 135, 8640, 135, 8640, 540, 135, 8640, 8640, 540, 540, 135, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 135, 8640, 135, 135, 8640, 540, 8640, 8640, 540, 8640, 135, 540, 8640, 135, 8640, 540, 135, 540, 540, 8640, 8640, 135, 135, 8640, 135, 135, 135, 540, 135]
Prompts retrieved: 400410 . Total input tokens: 89102245 . Total output tokens: 78834433
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 6.267284756992012,
    "estimated_duration": 3600.1034042675838,
    "input_throughput": 5499.70452974477,
    "output_throughput": 4775.269782423788,
    "total_throughput": 10274.974312168559,
    "itl": 109.24389119582216,
    "ttft": 1413349.7125818224,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1528,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.389048181995864,
    "arrivals": 133259,
    "finished_requests": 79800,
    "scheduler_time": 117.27003279674386
}
#Debug simulation 
Total elapsed time: 6.2673946102149785. Arrivals time: 0.2508144732564688 Scheduler time: 5.865616263821721 Scheduler overhead time: 0.050417736638337374 Adapter cache time: 0.025202244520187378 Engine time: 0.05180092342197895 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.0125_size_8-16-32/adapters_128_slots_64_rate_0.8-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.0125_size_8-16-32/adapters_128_slots_64_rate_0.8-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [42 43 43]
Adapter prompts. [8640, 540, 8640, 8640, 135, 135, 8640, 135, 540, 540, 540, 135, 8640, 540, 135, 8640, 540, 135, 135, 135, 135, 540, 540, 8640, 540, 135, 540, 540, 540, 540, 8640, 540, 135, 540, 135, 8640, 8640, 135, 540, 540, 135, 540, 135, 540, 540, 8640, 8640, 8640, 8640, 540, 540, 135, 540, 8640, 8640, 540, 135, 135, 135, 8640, 540, 540, 540, 540, 8640, 540, 8640, 135, 135, 540, 135, 8640, 8640, 135, 135, 540, 540, 540, 135, 8640, 135, 8640, 540, 135, 8640, 8640, 540, 540, 135, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 135, 8640, 135, 135, 8640, 540, 8640, 8640, 540, 8640, 135, 540, 8640, 135, 8640, 540, 135, 540, 540, 8640, 8640, 135, 135, 8640, 135, 135, 135, 540, 135]
Prompts retrieved: 400410 . Total input tokens: 89102245 . Total output tokens: 78834433
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 5.8535644733347,
    "estimated_duration": 3600.0897560477392,
    "input_throughput": 5191.299458188334,
    "output_throughput": 4513.958568033132,
    "total_throughput": 9705.258026221465,
    "itl": 97.02020481148271,
    "ttft": 1487455.2399772631,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1953,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.498948586000791,
    "arrivals": 133259,
    "finished_requests": 75337,
    "scheduler_time": 120.97762279722582
}
#Debug simulation 
Total elapsed time: 5.853701169136912. Arrivals time: 0.24310530023649335 Scheduler time: 5.440235285554081 Scheduler overhead time: 0.05544529715552926 Adapter cache time: 0.031121844425797462 Engine time: 0.057668779511004686 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.0125_size_16-16-16/adapters_128_slots_64_rate_0.8-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.0125_size_16-16-16/adapters_128_slots_64_rate_0.8-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [42 43 43]
Adapter prompts. [8640, 540, 8640, 8640, 135, 135, 8640, 135, 540, 540, 540, 135, 8640, 540, 135, 8640, 540, 135, 135, 135, 135, 540, 540, 8640, 540, 135, 540, 540, 540, 540, 8640, 540, 135, 540, 135, 8640, 8640, 135, 540, 540, 135, 540, 135, 540, 540, 8640, 8640, 8640, 8640, 540, 540, 135, 540, 8640, 8640, 540, 135, 135, 135, 8640, 540, 540, 540, 540, 8640, 540, 8640, 135, 135, 540, 135, 8640, 8640, 135, 135, 540, 540, 540, 135, 8640, 135, 8640, 540, 135, 8640, 8640, 540, 540, 135, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 135, 8640, 135, 135, 8640, 540, 8640, 8640, 540, 8640, 135, 540, 8640, 135, 8640, 540, 135, 540, 540, 8640, 8640, 135, 135, 8640, 135, 135, 135, 540, 135]
Prompts retrieved: 400410 . Total input tokens: 89102245 . Total output tokens: 78834433
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 6.310782803222537,
    "estimated_duration": 3600.074312554034,
    "input_throughput": 5500.471179427296,
    "output_throughput": 4776.188074796004,
    "total_throughput": 10276.659254223301,
    "itl": 109.22708572107646,
    "ttft": 1412882.4808628797,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1537,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.81208648565711,
    "arrivals": 133259,
    "finished_requests": 79810,
    "scheduler_time": 117.28055476248029
}
#Debug simulation 
Total elapsed time: 6.310913363005966. Arrivals time: 0.2563796606846154 Scheduler time: 5.9029825907200575 Scheduler overhead time: 0.05054223211482167 Adapter cache time: 0.025317830964922905 Engine time: 0.05197989381849766 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.0125_size_16-16-32/adapters_128_slots_64_rate_0.8-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.0125_size_16-16-32/adapters_128_slots_64_rate_0.8-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [42 43 43]
Adapter prompts. [8640, 540, 8640, 8640, 135, 135, 8640, 135, 540, 540, 540, 135, 8640, 540, 135, 8640, 540, 135, 135, 135, 135, 540, 540, 8640, 540, 135, 540, 540, 540, 540, 8640, 540, 135, 540, 135, 8640, 8640, 135, 540, 540, 135, 540, 135, 540, 540, 8640, 8640, 8640, 8640, 540, 540, 135, 540, 8640, 8640, 540, 135, 135, 135, 8640, 540, 540, 540, 540, 8640, 540, 8640, 135, 135, 540, 135, 8640, 8640, 135, 135, 540, 540, 540, 135, 8640, 135, 8640, 540, 135, 8640, 8640, 540, 540, 135, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 135, 8640, 135, 135, 8640, 540, 8640, 8640, 540, 8640, 135, 540, 8640, 135, 8640, 540, 135, 540, 540, 8640, 8640, 135, 135, 8640, 135, 135, 135, 540, 135]
Prompts retrieved: 400410 . Total input tokens: 89102245 . Total output tokens: 78834433
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 5.863055091816932,
    "estimated_duration": 3600.082115369916,
    "input_throughput": 5190.8577085553,
    "output_throughput": 4513.960092915884,
    "total_throughput": 9704.817801471185,
    "itl": 97.01378286766278,
    "ttft": 1487469.8357547019,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1979,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.572539294790195,
    "arrivals": 133259,
    "finished_requests": 75334,
    "scheduler_time": 120.97844689009166
}
#Debug simulation 
Total elapsed time: 5.863187312148511. Arrivals time: 0.24495376832783222 Scheduler time: 5.4484564061276615 Scheduler overhead time: 0.05544503824785352 Adapter cache time: 0.031008671037852764 Engine time: 0.05731092672795057 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-8/adapters_128_slots_64_rate_0.8-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-8/adapters_128_slots_64_rate_0.8-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [42 43 43]
Adapter prompts. [8640, 540, 8640, 8640, 66, 66, 8640, 66, 540, 540, 540, 66, 8640, 540, 66, 8640, 540, 66, 66, 66, 66, 540, 540, 8640, 540, 66, 540, 540, 540, 540, 8640, 540, 66, 540, 66, 8640, 8640, 66, 540, 540, 66, 540, 66, 540, 540, 8640, 8640, 8640, 8640, 540, 540, 66, 540, 8640, 8640, 540, 66, 66, 66, 8640, 540, 540, 540, 540, 8640, 540, 8640, 66, 66, 540, 66, 8640, 8640, 66, 66, 540, 540, 540, 66, 8640, 66, 8640, 540, 66, 8640, 8640, 540, 540, 66, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 66, 8640, 66, 66, 8640, 540, 8640, 8640, 540, 8640, 66, 540, 8640, 66, 8640, 540, 66, 540, 540, 8640, 8640, 66, 66, 8640, 66, 66, 66, 540, 66]
Prompts retrieved: 397512 . Total input tokens: 88456960 . Total output tokens: 78246833
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 6.335931747686118,
    "estimated_duration": 3600.000399093429,
    "input_throughput": 5628.671598231708,
    "output_throughput": 4913.116677557616,
    "total_throughput": 10541.788275789324,
    "itl": 117.3354544693113,
    "ttft": 1369749.1058199576,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1319,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.721767513142181,
    "arrivals": 132319,
    "finished_requests": 82066,
    "scheduler_time": 115.04492253586061
}
#Debug simulation 
Total elapsed time: 6.33604317670688. Arrivals time: 0.2677199519239366 Scheduler time: 5.9272843901999295 Scheduler overhead time: 0.047571965493261814 Adapter cache time: 0.02262916648760438 Engine time: 0.04864348843693733 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-16/adapters_128_slots_64_rate_0.8-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-16/adapters_128_slots_64_rate_0.8-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [42 43 43]
Adapter prompts. [8640, 540, 8640, 8640, 66, 66, 8640, 66, 540, 540, 540, 66, 8640, 540, 66, 8640, 540, 66, 66, 66, 66, 540, 540, 8640, 540, 66, 540, 540, 540, 540, 8640, 540, 66, 540, 66, 8640, 8640, 66, 540, 540, 66, 540, 66, 540, 540, 8640, 8640, 8640, 8640, 540, 540, 66, 540, 8640, 8640, 540, 66, 66, 66, 8640, 540, 540, 540, 540, 8640, 540, 8640, 66, 66, 540, 66, 8640, 8640, 66, 66, 540, 540, 540, 66, 8640, 66, 8640, 540, 66, 8640, 8640, 540, 540, 66, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 66, 8640, 66, 66, 8640, 540, 8640, 8640, 540, 8640, 66, 540, 8640, 66, 8640, 540, 66, 540, 540, 8640, 8640, 66, 66, 8640, 66, 66, 66, 540, 66]
Prompts retrieved: 397512 . Total input tokens: 88456960 . Total output tokens: 78246833
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 6.1335757449269295,
    "estimated_duration": 3600.0200900776244,
    "input_throughput": 5469.124201352849,
    "output_throughput": 4778.081113327649,
    "total_throughput": 10247.2053146805,
    "itl": 109.67544809364941,
    "ttft": 1407455.3905311176,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1517,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.053193946531865,
    "arrivals": 132319,
    "finished_requests": 79768,
    "scheduler_time": 116.91251953685938
}
#Debug simulation 
Total elapsed time: 6.133696622215211. Arrivals time: 0.25045366445556283 Scheduler time: 5.73256722651422 Scheduler overhead time: 0.050142440013587475 Adapter cache time: 0.025319647043943405 Engine time: 0.05159100377932191 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-32/adapters_128_slots_64_rate_0.8-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-32/adapters_128_slots_64_rate_0.8-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [42 43 43]
Adapter prompts. [8640, 540, 8640, 8640, 66, 66, 8640, 66, 540, 540, 540, 66, 8640, 540, 66, 8640, 540, 66, 66, 66, 66, 540, 540, 8640, 540, 66, 540, 540, 540, 540, 8640, 540, 66, 540, 66, 8640, 8640, 66, 540, 540, 66, 540, 66, 540, 540, 8640, 8640, 8640, 8640, 540, 540, 66, 540, 8640, 8640, 540, 66, 66, 66, 8640, 540, 540, 540, 540, 8640, 540, 8640, 66, 66, 540, 66, 8640, 8640, 66, 66, 540, 540, 540, 66, 8640, 66, 8640, 540, 66, 8640, 8640, 540, 540, 66, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 66, 8640, 66, 66, 8640, 540, 8640, 8640, 540, 8640, 66, 540, 8640, 66, 8640, 540, 66, 540, 540, 8640, 8640, 66, 66, 8640, 66, 66, 66, 540, 66]
Prompts retrieved: 397512 . Total input tokens: 88456960 . Total output tokens: 78246833
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 5.802599775139242,
    "estimated_duration": 3600.0264717757373,
    "input_throughput": 5160.219833282727,
    "output_throughput": 4519.230657760979,
    "total_throughput": 9679.450491043706,
    "itl": 97.48948268551644,
    "ttft": 1482311.8843131883,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2055,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.362572565986463,
    "arrivals": 132319,
    "finished_requests": 75329,
    "scheduler_time": 120.56635762672634
}
#Debug simulation 
Total elapsed time: 5.802711667958647. Arrivals time: 0.28322935895994306 Scheduler time: 5.3497359091416 Scheduler overhead time: 0.05493238940834999 Adapter cache time: 0.03186693787574768 Engine time: 0.056929160840809345 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.00625_size_8-16-16/adapters_128_slots_64_rate_0.8-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.00625_size_8-16-16/adapters_128_slots_64_rate_0.8-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [42 43 43]
Adapter prompts. [8640, 540, 8640, 8640, 66, 66, 8640, 66, 540, 540, 540, 66, 8640, 540, 66, 8640, 540, 66, 66, 66, 66, 540, 540, 8640, 540, 66, 540, 540, 540, 540, 8640, 540, 66, 540, 66, 8640, 8640, 66, 540, 540, 66, 540, 66, 540, 540, 8640, 8640, 8640, 8640, 540, 540, 66, 540, 8640, 8640, 540, 66, 66, 66, 8640, 540, 540, 540, 540, 8640, 540, 8640, 66, 66, 540, 66, 8640, 8640, 66, 66, 540, 540, 540, 66, 8640, 66, 8640, 540, 66, 8640, 8640, 540, 540, 66, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 66, 8640, 66, 66, 8640, 540, 8640, 8640, 540, 8640, 66, 540, 8640, 66, 8640, 540, 66, 540, 540, 8640, 8640, 66, 66, 8640, 66, 66, 66, 540, 66]
Prompts retrieved: 397512 . Total input tokens: 88456960 . Total output tokens: 78246833
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 6.124185051303357,
    "estimated_duration": 3600.026272244063,
    "input_throughput": 5470.061191449261,
    "output_throughput": 4779.0098457463755,
    "total_throughput": 10249.071037195637,
    "itl": 109.6485625043098,
    "ttft": 1407247.6304677133,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1522,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.356297540245672,
    "arrivals": 132319,
    "finished_requests": 79785,
    "scheduler_time": 116.93604787534022
}
#Debug simulation 
Total elapsed time: 6.124301271047443. Arrivals time: 0.26211922196671367 Scheduler time: 5.711979991290718 Scheduler overhead time: 0.05022797826677561 Adapter cache time: 0.025065006222575903 Engine time: 0.05142096243798733 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.00625_size_8-16-32/adapters_128_slots_64_rate_0.8-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.00625_size_8-16-32/adapters_128_slots_64_rate_0.8-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [42 43 43]
Adapter prompts. [8640, 540, 8640, 8640, 66, 66, 8640, 66, 540, 540, 540, 66, 8640, 540, 66, 8640, 540, 66, 66, 66, 66, 540, 540, 8640, 540, 66, 540, 540, 540, 540, 8640, 540, 66, 540, 66, 8640, 8640, 66, 540, 540, 66, 540, 66, 540, 540, 8640, 8640, 8640, 8640, 540, 540, 66, 540, 8640, 8640, 540, 66, 66, 66, 8640, 540, 540, 540, 540, 8640, 540, 8640, 66, 66, 540, 66, 8640, 8640, 66, 66, 540, 540, 540, 66, 8640, 66, 8640, 540, 66, 8640, 8640, 540, 540, 66, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 66, 8640, 66, 66, 8640, 540, 8640, 8640, 540, 8640, 66, 540, 8640, 66, 8640, 540, 66, 540, 540, 8640, 8640, 66, 66, 8640, 66, 66, 66, 540, 66]
Prompts retrieved: 397512 . Total input tokens: 88456960 . Total output tokens: 78246833
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 5.753078267443925,
    "estimated_duration": 3600.054876140644,
    "input_throughput": 5160.204396638272,
    "output_throughput": 4519.369165128353,
    "total_throughput": 9679.573561766625,
    "itl": 97.48701319756294,
    "ttft": 1482163.802368165,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2041,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.111567857879848,
    "arrivals": 132319,
    "finished_requests": 75331,
    "scheduler_time": 120.57442286459741
}
#Debug simulation 
Total elapsed time: 5.753218946047127. Arrivals time: 0.254407103639096 Scheduler time: 5.328323339112103 Scheduler overhead time: 0.05513506243005395 Adapter cache time: 0.03196619916707277 Engine time: 0.0573858255520463 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.00625_size_16-16-16/adapters_128_slots_64_rate_0.8-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.00625_size_16-16-16/adapters_128_slots_64_rate_0.8-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [42 43 43]
Adapter prompts. [8640, 540, 8640, 8640, 66, 66, 8640, 66, 540, 540, 540, 66, 8640, 540, 66, 8640, 540, 66, 66, 66, 66, 540, 540, 8640, 540, 66, 540, 540, 540, 540, 8640, 540, 66, 540, 66, 8640, 8640, 66, 540, 540, 66, 540, 66, 540, 540, 8640, 8640, 8640, 8640, 540, 540, 66, 540, 8640, 8640, 540, 66, 66, 66, 8640, 540, 540, 540, 540, 8640, 540, 8640, 66, 66, 540, 66, 8640, 8640, 66, 66, 540, 540, 540, 66, 8640, 66, 8640, 540, 66, 8640, 8640, 540, 540, 66, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 66, 8640, 66, 66, 8640, 540, 8640, 8640, 540, 8640, 66, 540, 8640, 66, 8640, 540, 66, 540, 540, 8640, 8640, 66, 66, 8640, 66, 66, 66, 540, 66]
Prompts retrieved: 397512 . Total input tokens: 88456960 . Total output tokens: 78246833
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 6.126192701980472,
    "estimated_duration": 3600.0155381448917,
    "input_throughput": 5470.9124978247,
    "output_throughput": 4779.762980930626,
    "total_throughput": 10250.675478755325,
    "itl": 109.63129690144855,
    "ttft": 1406992.3487870498,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1508,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.62695277838054,
    "arrivals": 132319,
    "finished_requests": 79802,
    "scheduler_time": 116.9496638240189
}
#Debug simulation 
Total elapsed time: 6.126334268134087. Arrivals time: 0.25352947646752 Scheduler time: 5.722373158670962 Scheduler overhead time: 0.050134116783738136 Adapter cache time: 0.02518657734617591 Engine time: 0.051473223604261875 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.00625_size_16-16-32/adapters_128_slots_64_rate_0.8-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.00625_size_16-16-32/adapters_128_slots_64_rate_0.8-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [42 43 43]
Adapter prompts. [8640, 540, 8640, 8640, 66, 66, 8640, 66, 540, 540, 540, 66, 8640, 540, 66, 8640, 540, 66, 66, 66, 66, 540, 540, 8640, 540, 66, 540, 540, 540, 540, 8640, 540, 66, 540, 66, 8640, 8640, 66, 540, 540, 66, 540, 66, 540, 540, 8640, 8640, 8640, 8640, 540, 540, 66, 540, 8640, 8640, 540, 66, 66, 66, 8640, 540, 540, 540, 540, 8640, 540, 8640, 66, 66, 540, 66, 8640, 8640, 66, 66, 540, 540, 540, 66, 8640, 66, 8640, 540, 66, 8640, 8640, 540, 540, 66, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 66, 8640, 66, 66, 8640, 540, 8640, 8640, 540, 8640, 66, 540, 8640, 66, 8640, 540, 66, 540, 540, 8640, 8640, 66, 66, 8640, 66, 66, 66, 540, 66]
Prompts retrieved: 397512 . Total input tokens: 88456960 . Total output tokens: 78246833
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 5.736510727088898,
    "estimated_duration": 3600.070384214925,
    "input_throughput": 5160.357720075872,
    "output_throughput": 4519.648580023044,
    "total_throughput": 9680.006300098916,
    "itl": 97.48546085178371,
    "ttft": 1482003.1195582354,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2046,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.02167152065754,
    "arrivals": 132319,
    "finished_requests": 75333,
    "scheduler_time": 120.57665521594853
}
#Debug simulation 
Total elapsed time: 5.736624862998724. Arrivals time: 0.25506441621109843 Scheduler time: 5.312312797177583 Scheduler overhead time: 0.05511804763227701 Adapter cache time: 0.031690571922808886 Engine time: 0.05652198567986488 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-8/adapters_128_slots_64_rate_0.8-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-8/adapters_128_slots_64_rate_0.8-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [42 43 43]
Adapter prompts. [8640, 540, 8640, 8640, 33, 33, 8640, 33, 540, 540, 540, 33, 8640, 540, 33, 8640, 540, 33, 33, 33, 33, 540, 540, 8640, 540, 33, 540, 540, 540, 540, 8640, 540, 33, 540, 33, 8640, 8640, 33, 540, 540, 33, 540, 33, 540, 540, 8640, 8640, 8640, 8640, 540, 540, 33, 540, 8640, 8640, 540, 33, 33, 33, 8640, 540, 540, 540, 540, 8640, 540, 8640, 33, 33, 540, 33, 8640, 8640, 33, 33, 540, 540, 540, 33, 8640, 33, 8640, 540, 33, 8640, 8640, 540, 540, 33, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 33, 8640, 33, 33, 8640, 540, 8640, 8640, 540, 8640, 33, 540, 8640, 33, 8640, 540, 33, 540, 540, 8640, 8640, 33, 33, 8640, 33, 33, 33, 540, 33]
Prompts retrieved: 396126 . Total input tokens: 88155553 . Total output tokens: 77962584
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 6.2514358651824296,
    "estimated_duration": 3600.0638375079097,
    "input_throughput": 5642.000230212688,
    "output_throughput": 4914.190080653293,
    "total_throughput": 10556.19031086598,
    "itl": 117.22404620954084,
    "ttft": 1370878.3785747155,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1327,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.774666785397782,
    "arrivals": 131875,
    "finished_requests": 81981,
    "scheduler_time": 114.88655376477618
}
#Debug simulation 
Total elapsed time: 6.251578342169523. Arrivals time: 0.253692620433867 Scheduler time: 5.856559996027499 Scheduler overhead time: 0.047973543871194124 Adapter cache time: 0.02234564907848835 Engine time: 0.048616528045386076 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-16/adapters_128_slots_64_rate_0.8-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-16/adapters_128_slots_64_rate_0.8-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [42 43 43]
Adapter prompts. [8640, 540, 8640, 8640, 33, 33, 8640, 33, 540, 540, 540, 33, 8640, 540, 33, 8640, 540, 33, 33, 33, 33, 540, 540, 8640, 540, 33, 540, 540, 540, 540, 8640, 540, 33, 540, 33, 8640, 8640, 33, 540, 540, 33, 540, 33, 540, 540, 8640, 8640, 8640, 8640, 540, 540, 33, 540, 8640, 8640, 540, 33, 33, 33, 8640, 540, 540, 540, 540, 8640, 540, 8640, 33, 33, 540, 33, 8640, 8640, 33, 33, 540, 540, 540, 33, 8640, 33, 8640, 540, 33, 8640, 8640, 540, 540, 33, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 33, 8640, 33, 33, 8640, 540, 8640, 8640, 540, 8640, 33, 540, 8640, 33, 8640, 540, 33, 540, 540, 8640, 8640, 33, 33, 8640, 33, 33, 33, 540, 33]
Prompts retrieved: 396126 . Total input tokens: 88155553 . Total output tokens: 77962584
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 6.058989643119276,
    "estimated_duration": 3600.0608320090832,
    "input_throughput": 5485.348143125537,
    "output_throughput": 4778.300923987442,
    "total_throughput": 10263.649067112978,
    "itl": 109.6004146606569,
    "ttft": 1408910.2816149185,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1575,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.505366398510395,
    "arrivals": 131875,
    "finished_requests": 79725,
    "scheduler_time": 116.71972772211967
}
#Debug simulation 
Total elapsed time: 6.059101255144924. Arrivals time: 0.2522794404067099 Scheduler time: 5.656008766964078 Scheduler overhead time: 0.05018796352669597 Adapter cache time: 0.02543817274272442 Engine time: 0.05159424897283316 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-32/adapters_128_slots_64_rate_0.8-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-32/adapters_128_slots_64_rate_0.8-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [42 43 43]
Adapter prompts. [8640, 540, 8640, 8640, 33, 33, 8640, 33, 540, 540, 540, 33, 8640, 540, 33, 8640, 540, 33, 33, 33, 33, 540, 540, 8640, 540, 33, 540, 540, 540, 540, 8640, 540, 33, 540, 33, 8640, 8640, 33, 540, 540, 33, 540, 33, 540, 540, 8640, 8640, 8640, 8640, 540, 540, 33, 540, 8640, 8640, 540, 33, 33, 33, 8640, 540, 540, 540, 540, 8640, 540, 8640, 33, 33, 540, 33, 8640, 8640, 33, 33, 540, 540, 540, 33, 8640, 33, 8640, 540, 33, 8640, 8640, 540, 540, 33, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 33, 8640, 33, 33, 8640, 540, 8640, 8640, 540, 8640, 33, 540, 8640, 33, 8640, 540, 33, 540, 540, 8640, 8640, 33, 33, 8640, 33, 33, 33, 540, 33]
Prompts retrieved: 396126 . Total input tokens: 88155553 . Total output tokens: 77962584
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 5.673791870940477,
    "estimated_duration": 3600.0438129079694,
    "input_throughput": 5187.727141830046,
    "output_throughput": 4521.319696621175,
    "total_throughput": 9709.04683845122,
    "itl": 97.2440372093077,
    "ttft": 1482617.6390275536,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2085,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.621942831142487,
    "arrivals": 131875,
    "finished_requests": 75433,
    "scheduler_time": 120.51993004012579
}
#Debug simulation 
Total elapsed time: 5.673907043877989. Arrivals time: 0.2433433854021132 Scheduler time: 5.260917723644525 Scheduler overhead time: 0.05501349316909909 Adapter cache time: 0.03218898456543684 Engine time: 0.056739137042313814 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.003125_size_8-16-16/adapters_128_slots_64_rate_0.8-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.003125_size_8-16-16/adapters_128_slots_64_rate_0.8-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [42 43 43]
Adapter prompts. [8640, 540, 8640, 8640, 33, 33, 8640, 33, 540, 540, 540, 33, 8640, 540, 33, 8640, 540, 33, 33, 33, 33, 540, 540, 8640, 540, 33, 540, 540, 540, 540, 8640, 540, 33, 540, 33, 8640, 8640, 33, 540, 540, 33, 540, 33, 540, 540, 8640, 8640, 8640, 8640, 540, 540, 33, 540, 8640, 8640, 540, 33, 33, 33, 8640, 540, 540, 540, 540, 8640, 540, 8640, 33, 33, 540, 33, 8640, 8640, 33, 33, 540, 540, 540, 33, 8640, 33, 8640, 540, 33, 8640, 8640, 540, 540, 33, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 33, 8640, 33, 33, 8640, 540, 8640, 8640, 540, 8640, 33, 540, 8640, 33, 8640, 540, 33, 540, 540, 8640, 8640, 33, 33, 8640, 33, 33, 33, 540, 33]
Prompts retrieved: 396126 . Total input tokens: 88155553 . Total output tokens: 77962584
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 6.060578136704862,
    "estimated_duration": 3600.074068358307,
    "input_throughput": 5486.226845606735,
    "output_throughput": 4779.091394596167,
    "total_throughput": 10265.318240202902,
    "itl": 109.58203327635962,
    "ttft": 1408676.5386217493,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1572,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.73935175204662,
    "arrivals": 131875,
    "finished_requests": 79738,
    "scheduler_time": 116.73785594711192
}
#Debug simulation 
Total elapsed time: 6.060712028760463. Arrivals time: 0.25008236337453127 Scheduler time: 5.65902931150049 Scheduler overhead time: 0.05037497403100133 Adapter cache time: 0.02601845469325781 Engine time: 0.05153460707515478 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.003125_size_8-16-32/adapters_128_slots_64_rate_0.8-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.003125_size_8-16-32/adapters_128_slots_64_rate_0.8-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [42 43 43]
Adapter prompts. [8640, 540, 8640, 8640, 33, 33, 8640, 33, 540, 540, 540, 33, 8640, 540, 33, 8640, 540, 33, 33, 33, 33, 540, 540, 8640, 540, 33, 540, 540, 540, 540, 8640, 540, 33, 540, 33, 8640, 8640, 33, 540, 540, 33, 540, 33, 540, 540, 8640, 8640, 8640, 8640, 540, 540, 33, 540, 8640, 8640, 540, 33, 33, 33, 8640, 540, 540, 540, 540, 8640, 540, 8640, 33, 33, 540, 33, 8640, 8640, 33, 33, 540, 540, 540, 33, 8640, 33, 8640, 540, 33, 8640, 8640, 540, 540, 33, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 33, 8640, 33, 33, 8640, 540, 8640, 8640, 540, 8640, 33, 540, 8640, 33, 8640, 540, 33, 540, 540, 8640, 8640, 33, 33, 8640, 33, 33, 33, 540, 33]
Prompts retrieved: 396126 . Total input tokens: 88155553 . Total output tokens: 77962584
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 5.7230164706707,
    "estimated_duration": 3600.10699710539,
    "input_throughput": 5188.019971355656,
    "output_throughput": 4521.333397337217,
    "total_throughput": 9709.353368692873,
    "itl": 97.23984931015733,
    "ttft": 1482677.08523996,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2086,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.487004673438763,
    "arrivals": 131875,
    "finished_requests": 75437,
    "scheduler_time": 120.52356642310932
}
#Debug simulation 
Total elapsed time: 5.723156267777085. Arrivals time: 0.24938091170042753 Scheduler time: 5.303759195376188 Scheduler overhead time: 0.05483352858573198 Adapter cache time: 0.03210053453221917 Engine time: 0.05711152032017708 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.003125_size_16-16-16/adapters_128_slots_64_rate_0.8-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.003125_size_16-16-16/adapters_128_slots_64_rate_0.8-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [42 43 43]
Adapter prompts. [8640, 540, 8640, 8640, 33, 33, 8640, 33, 540, 540, 540, 33, 8640, 540, 33, 8640, 540, 33, 33, 33, 33, 540, 540, 8640, 540, 33, 540, 540, 540, 540, 8640, 540, 33, 540, 33, 8640, 8640, 33, 540, 540, 33, 540, 33, 540, 540, 8640, 8640, 8640, 8640, 540, 540, 33, 540, 8640, 8640, 540, 33, 33, 33, 8640, 540, 540, 540, 540, 8640, 540, 8640, 33, 33, 540, 33, 8640, 8640, 33, 33, 540, 540, 540, 33, 8640, 33, 8640, 540, 33, 8640, 8640, 540, 540, 33, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 33, 8640, 33, 33, 8640, 540, 8640, 8640, 540, 8640, 33, 540, 8640, 33, 8640, 540, 33, 540, 540, 8640, 8640, 33, 33, 8640, 33, 33, 33, 540, 33]
Prompts retrieved: 396126 . Total input tokens: 88155553 . Total output tokens: 77962584
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 6.052729508839548,
    "estimated_duration": 3600.106709603001,
    "input_throughput": 5487.334569085167,
    "output_throughput": 4780.024701517157,
    "total_throughput": 10267.359270602323,
    "itl": 109.56332282943569,
    "ttft": 1408437.0298308837,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1597,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.195121742091393,
    "arrivals": 131875,
    "finished_requests": 79754,
    "scheduler_time": 116.75274855446087
}
#Debug simulation 
Total elapsed time: 6.052871598862112. Arrivals time: 0.25251181749626994 Scheduler time: 5.6495175319723785 Scheduler overhead time: 0.050245318561792374 Adapter cache time: 0.02548115560784936 Engine time: 0.05160652892664075 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.003125_size_16-16-32/adapters_128_slots_64_rate_0.8-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.003125_size_16-16-32/adapters_128_slots_64_rate_0.8-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [42 43 43]
Adapter prompts. [8640, 540, 8640, 8640, 33, 33, 8640, 33, 540, 540, 540, 33, 8640, 540, 33, 8640, 540, 33, 33, 33, 33, 540, 540, 8640, 540, 33, 540, 540, 540, 540, 8640, 540, 33, 540, 33, 8640, 8640, 33, 540, 540, 33, 540, 33, 540, 540, 8640, 8640, 8640, 8640, 540, 540, 33, 540, 8640, 8640, 540, 33, 33, 33, 8640, 540, 540, 540, 540, 8640, 540, 8640, 33, 33, 540, 33, 8640, 8640, 33, 33, 540, 540, 540, 33, 8640, 33, 8640, 540, 33, 8640, 8640, 540, 540, 33, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 33, 8640, 33, 33, 8640, 540, 8640, 8640, 540, 8640, 33, 540, 8640, 33, 8640, 540, 33, 540, 540, 8640, 8640, 33, 33, 8640, 33, 33, 33, 540, 33]
Prompts retrieved: 396126 . Total input tokens: 88155553 . Total output tokens: 77962584
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 5.706954021006823,
    "estimated_duration": 3600.0617046460557,
    "input_throughput": 5187.987743625705,
    "output_throughput": 4521.335559052675,
    "total_throughput": 9709.32330267838,
    "itl": 97.23663443672233,
    "ttft": 1482629.542497642,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2078,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.288495011143077,
    "arrivals": 131875,
    "finished_requests": 75437,
    "scheduler_time": 120.52674261938586
}
#Debug simulation 
Total elapsed time: 5.707069667056203. Arrivals time: 0.24703696882352233 Scheduler time: 5.2901512938551605 Scheduler overhead time: 0.05491761211305857 Adapter cache time: 0.03222516272217035 Engine time: 0.056933395098894835 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-8/adapters_128_slots_64_rate_0.8-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-8/adapters_128_slots_64_rate_0.8-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [42 43 43]
Adapter prompts. [8640, 270, 8640, 8640, 135, 135, 8640, 135, 270, 270, 270, 135, 8640, 270, 135, 8640, 270, 135, 135, 135, 135, 270, 270, 8640, 270, 135, 270, 270, 270, 270, 8640, 270, 135, 270, 135, 8640, 8640, 135, 270, 270, 135, 270, 135, 270, 270, 8640, 8640, 8640, 8640, 270, 270, 135, 270, 8640, 8640, 270, 135, 135, 135, 8640, 270, 270, 270, 270, 8640, 270, 8640, 135, 135, 270, 135, 8640, 8640, 135, 135, 270, 270, 270, 135, 8640, 135, 8640, 270, 135, 8640, 8640, 270, 270, 135, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 135, 8640, 135, 135, 8640, 270, 8640, 8640, 270, 8640, 135, 270, 8640, 135, 8640, 270, 135, 270, 270, 8640, 8640, 135, 135, 8640, 135, 135, 135, 270, 135]
Prompts retrieved: 388800 . Total input tokens: 86543313 . Total output tokens: 76539775
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 6.177859358955175,
    "estimated_duration": 3600.1120434837508,
    "input_throughput": 5592.97065113437,
    "output_throughput": 4907.1661622244,
    "total_throughput": 10500.13681335877,
    "itl": 117.37281747634636,
    "ttft": 1355515.4160063604,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1994,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.185143609708533,
    "arrivals": 129404,
    "finished_requests": 81696,
    "scheduler_time": 113.79036401120428
}
#Debug simulation 
Total elapsed time: 6.1779828811995685. Arrivals time: 0.259071531239897 Scheduler time: 5.770874580834061 Scheduler overhead time: 0.04772540973499417 Adapter cache time: 0.02925992291420698 Engine time: 0.048794680275022984 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-16/adapters_128_slots_64_rate_0.8-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-16/adapters_128_slots_64_rate_0.8-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [42 43 43]
Adapter prompts. [8640, 270, 8640, 8640, 135, 135, 8640, 135, 270, 270, 270, 135, 8640, 270, 135, 8640, 270, 135, 135, 135, 135, 270, 270, 8640, 270, 135, 270, 270, 270, 270, 8640, 270, 135, 270, 135, 8640, 8640, 135, 270, 270, 135, 270, 135, 270, 270, 8640, 8640, 8640, 8640, 270, 270, 135, 270, 8640, 8640, 270, 135, 135, 135, 8640, 270, 270, 270, 270, 8640, 270, 8640, 135, 135, 270, 135, 8640, 8640, 135, 135, 270, 270, 270, 135, 8640, 135, 8640, 270, 135, 8640, 8640, 270, 270, 135, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 135, 8640, 135, 135, 8640, 270, 8640, 8640, 270, 8640, 135, 270, 8640, 135, 8640, 270, 135, 270, 270, 8640, 8640, 135, 135, 8640, 135, 135, 135, 270, 135]
Prompts retrieved: 388800 . Total input tokens: 86543313 . Total output tokens: 76539775
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 5.967773937154561,
    "estimated_duration": 3600.0661563535327,
    "input_throughput": 5447.231008627672,
    "output_throughput": 4780.985752060098,
    "total_throughput": 10228.21676068777,
    "itl": 109.54385952134228,
    "ttft": 1390953.1595333128,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2269,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.536907212710652,
    "arrivals": 129404,
    "finished_requests": 79525,
    "scheduler_time": 115.7688792957541
}
#Debug simulation 
Total elapsed time: 5.967890269123018. Arrivals time: 0.2550093620084226 Scheduler time: 5.55489335861057 Scheduler overhead time: 0.05000613769516349 Adapter cache time: 0.03319223551079631 Engine time: 0.05142584349960089 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-32/adapters_128_slots_64_rate_0.8-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-32/adapters_128_slots_64_rate_0.8-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [42 43 43]
Adapter prompts. [8640, 270, 8640, 8640, 135, 135, 8640, 135, 270, 270, 270, 135, 8640, 270, 135, 8640, 270, 135, 135, 135, 135, 270, 270, 8640, 270, 135, 270, 270, 270, 270, 8640, 270, 135, 270, 135, 8640, 8640, 135, 270, 270, 135, 270, 135, 270, 270, 8640, 8640, 8640, 8640, 270, 270, 135, 270, 8640, 8640, 270, 135, 135, 135, 8640, 270, 270, 270, 270, 8640, 270, 8640, 135, 135, 270, 135, 8640, 8640, 135, 135, 270, 270, 270, 135, 8640, 135, 8640, 270, 135, 8640, 8640, 270, 270, 135, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 135, 8640, 135, 135, 8640, 270, 8640, 8640, 270, 8640, 135, 270, 8640, 135, 8640, 270, 135, 270, 270, 8640, 8640, 135, 135, 8640, 135, 135, 135, 270, 135]
Prompts retrieved: 388800 . Total input tokens: 86543313 . Total output tokens: 76539775
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 5.7094596130773425,
    "estimated_duration": 3600.0247667066983,
    "input_throughput": 5206.605847088915,
    "output_throughput": 4577.834339477667,
    "total_throughput": 9784.44018656658,
    "itl": 96.10894421210743,
    "ttft": 1451293.6549402124,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2430,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 18.19287853933864,
    "arrivals": 129404,
    "finished_requests": 76046,
    "scheduler_time": 120.6831377687652
}
#Debug simulation 
Total elapsed time: 5.709567627869546. Arrivals time: 0.2477065180428326 Scheduler time: 5.287128963042051 Scheduler overhead time: 0.05480955773964524 Adapter cache time: 0.03696459252387285 Engine time: 0.05709311040118337 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.0125_size_8-16-16/adapters_128_slots_64_rate_0.8-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.0125_size_8-16-16/adapters_128_slots_64_rate_0.8-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [42 43 43]
Adapter prompts. [8640, 270, 8640, 8640, 135, 135, 8640, 135, 270, 270, 270, 135, 8640, 270, 135, 8640, 270, 135, 135, 135, 135, 270, 270, 8640, 270, 135, 270, 270, 270, 270, 8640, 270, 135, 270, 135, 8640, 8640, 135, 270, 270, 135, 270, 135, 270, 270, 8640, 8640, 8640, 8640, 270, 270, 135, 270, 8640, 8640, 270, 135, 135, 135, 8640, 270, 270, 270, 270, 8640, 270, 8640, 135, 135, 270, 135, 8640, 8640, 135, 135, 270, 270, 270, 135, 8640, 135, 8640, 270, 135, 8640, 8640, 270, 270, 135, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 135, 8640, 135, 135, 8640, 270, 8640, 8640, 270, 8640, 135, 270, 8640, 135, 8640, 270, 135, 270, 270, 8640, 8640, 135, 135, 8640, 135, 135, 135, 270, 135]
Prompts retrieved: 388800 . Total input tokens: 86543313 . Total output tokens: 76539775
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 5.985242378432304,
    "estimated_duration": 3600.0058483809694,
    "input_throughput": 5448.476704231259,
    "output_throughput": 4782.631397041543,
    "total_throughput": 10231.108101272801,
    "itl": 109.50739634919438,
    "ttft": 1390337.2410650486,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2277,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.460743149905825,
    "arrivals": 129404,
    "finished_requests": 79554,
    "scheduler_time": 115.79455286412407
}
#Debug simulation 
Total elapsed time: 5.985354273114353. Arrivals time: 0.2582363369874656 Scheduler time: 5.568689392879605 Scheduler overhead time: 0.05000080447643995 Adapter cache time: 0.03329010168090463 Engine time: 0.051611737348139286 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.0125_size_8-16-32/adapters_128_slots_64_rate_0.8-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.0125_size_8-16-32/adapters_128_slots_64_rate_0.8-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [42 43 43]
Adapter prompts. [8640, 270, 8640, 8640, 135, 135, 8640, 135, 270, 270, 270, 135, 8640, 270, 135, 8640, 270, 135, 135, 135, 135, 270, 270, 8640, 270, 135, 270, 270, 270, 270, 8640, 270, 135, 270, 135, 8640, 8640, 135, 270, 270, 135, 270, 135, 270, 270, 8640, 8640, 8640, 8640, 270, 270, 135, 270, 8640, 8640, 270, 135, 135, 135, 8640, 270, 270, 270, 270, 8640, 270, 8640, 135, 135, 270, 135, 8640, 8640, 135, 135, 270, 270, 270, 135, 8640, 135, 8640, 270, 135, 8640, 8640, 270, 270, 135, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 135, 8640, 135, 135, 8640, 270, 8640, 8640, 270, 8640, 135, 270, 8640, 135, 8640, 270, 135, 270, 270, 8640, 8640, 135, 135, 8640, 135, 135, 135, 270, 135]
Prompts retrieved: 388800 . Total input tokens: 86543313 . Total output tokens: 76539775
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 5.74705905187875,
    "estimated_duration": 3600.081773457088,
    "input_throughput": 5206.808950342149,
    "output_throughput": 4578.080731808815,
    "total_throughput": 9784.889682150962,
    "itl": 96.10378002183012,
    "ttft": 1451193.7826443957,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2426,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.980796536542385,
    "arrivals": 129404,
    "finished_requests": 76053,
    "scheduler_time": 120.68636265875656
}
#Debug simulation 
Total elapsed time: 5.74717364879325. Arrivals time: 0.2583780586719513 Scheduler time: 5.312949401792139 Scheduler overhead time: 0.05532536702230573 Adapter cache time: 0.03765575448051095 Engine time: 0.056969999335706234 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.0125_size_16-16-16/adapters_128_slots_64_rate_0.8-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.0125_size_16-16-16/adapters_128_slots_64_rate_0.8-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [42 43 43]
Adapter prompts. [8640, 270, 8640, 8640, 135, 135, 8640, 135, 270, 270, 270, 135, 8640, 270, 135, 8640, 270, 135, 135, 135, 135, 270, 270, 8640, 270, 135, 270, 270, 270, 270, 8640, 270, 135, 270, 135, 8640, 8640, 135, 270, 270, 135, 270, 135, 270, 270, 8640, 8640, 8640, 8640, 270, 270, 135, 270, 8640, 8640, 270, 135, 135, 135, 8640, 270, 270, 270, 270, 8640, 270, 8640, 135, 135, 270, 135, 8640, 8640, 135, 135, 270, 270, 270, 135, 8640, 135, 8640, 270, 135, 8640, 8640, 270, 270, 135, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 135, 8640, 135, 135, 8640, 270, 8640, 8640, 270, 8640, 135, 270, 8640, 135, 8640, 270, 135, 270, 270, 8640, 8640, 135, 135, 8640, 135, 135, 135, 270, 135]
Prompts retrieved: 388800 . Total input tokens: 86543313 . Total output tokens: 76539775
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 5.965071285143495,
    "estimated_duration": 3600.012574642054,
    "input_throughput": 5449.850963909689,
    "output_throughput": 4784.523010093264,
    "total_throughput": 10234.373974002952,
    "itl": 109.47550759782924,
    "ttft": 1389896.656760155,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2274,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.517036218858221,
    "arrivals": 129404,
    "finished_requests": 79579,
    "scheduler_time": 115.81861109069047
}
#Debug simulation 
Total elapsed time: 5.965188977308571. Arrivals time: 0.2537056030705571 Scheduler time: 5.553612653166056 Scheduler overhead time: 0.049902438186109066 Adapter cache time: 0.033120575826615095 Engine time: 0.05141426296904683 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.0125_size_16-16-32/adapters_128_slots_64_rate_0.8-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.0125_size_16-16-32/adapters_128_slots_64_rate_0.8-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [42 43 43]
Adapter prompts. [8640, 270, 8640, 8640, 135, 135, 8640, 135, 270, 270, 270, 135, 8640, 270, 135, 8640, 270, 135, 135, 135, 135, 270, 270, 8640, 270, 135, 270, 270, 270, 270, 8640, 270, 135, 270, 135, 8640, 8640, 135, 270, 270, 135, 270, 135, 270, 270, 8640, 8640, 8640, 8640, 270, 270, 135, 270, 8640, 8640, 270, 135, 135, 135, 8640, 270, 270, 270, 270, 8640, 270, 8640, 135, 135, 270, 135, 8640, 8640, 135, 135, 270, 270, 270, 135, 8640, 135, 8640, 270, 135, 8640, 8640, 270, 270, 135, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 135, 8640, 135, 135, 8640, 270, 8640, 8640, 270, 8640, 135, 270, 8640, 135, 8640, 270, 135, 270, 270, 8640, 8640, 135, 135, 8640, 135, 135, 135, 270, 135]
Prompts retrieved: 388800 . Total input tokens: 86543313 . Total output tokens: 76539775
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 5.714839791879058,
    "estimated_duration": 3600.0707814583266,
    "input_throughput": 5207.1706746849695,
    "output_throughput": 4578.423314589155,
    "total_throughput": 9785.593989274124,
    "itl": 96.09622817694904,
    "ttft": 1450946.3427312505,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2426,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.833173858597767,
    "arrivals": 129404,
    "finished_requests": 76060,
    "scheduler_time": 120.69053307040016
}
#Debug simulation 
Total elapsed time: 5.7149566961452365. Arrivals time: 0.24949723947793245 Scheduler time: 5.289897832553834 Scheduler overhead time: 0.054937812965363264 Adapter cache time: 0.037413302809000015 Engine time: 0.05727419350296259 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.00625_size_8-8-8/adapters_128_slots_64_rate_0.8-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.00625_size_8-8-8/adapters_128_slots_64_rate_0.8-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [42 43 43]
Adapter prompts. [8640, 270, 8640, 8640, 66, 66, 8640, 66, 270, 270, 270, 66, 8640, 270, 66, 8640, 270, 66, 66, 66, 66, 270, 270, 8640, 270, 66, 270, 270, 270, 270, 8640, 270, 66, 270, 66, 8640, 8640, 66, 270, 270, 66, 270, 66, 270, 270, 8640, 8640, 8640, 8640, 270, 270, 66, 270, 8640, 8640, 270, 66, 66, 66, 8640, 270, 270, 270, 270, 8640, 270, 8640, 66, 66, 270, 66, 8640, 8640, 66, 66, 270, 270, 270, 66, 8640, 66, 8640, 270, 66, 8640, 8640, 270, 270, 66, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 66, 8640, 66, 66, 8640, 270, 8640, 8640, 270, 8640, 66, 270, 8640, 66, 8640, 270, 66, 270, 270, 8640, 8640, 66, 66, 8640, 66, 66, 66, 270, 66]
Prompts retrieved: 385902 . Total input tokens: 85902462 . Total output tokens: 75982338
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 6.102383033372462,
    "estimated_duration": 3600.0672411912797,
    "input_throughput": 5701.617393459512,
    "output_throughput": 4951.423350109836,
    "total_throughput": 10653.040743569347,
    "itl": 115.62591732301767,
    "ttft": 1330492.7891391704,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2028,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.409965516794838,
    "arrivals": 128419,
    "finished_requests": 82574,
    "scheduler_time": 114.06114033448166
}
#Debug simulation 
Total elapsed time: 6.10250686109066. Arrivals time: 0.2670742147602141 Scheduler time: 5.686892058234662 Scheduler overhead time: 0.047102652955800295 Adapter cache time: 0.03018426150083542 Engine time: 0.048960421700030565 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.00625_size_8-8-16/adapters_128_slots_64_rate_0.8-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.00625_size_8-8-16/adapters_128_slots_64_rate_0.8-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [42 43 43]
Adapter prompts. [8640, 270, 8640, 8640, 66, 66, 8640, 66, 270, 270, 270, 66, 8640, 270, 66, 8640, 270, 66, 66, 66, 66, 270, 270, 8640, 270, 66, 270, 270, 270, 270, 8640, 270, 66, 270, 66, 8640, 8640, 66, 270, 270, 66, 270, 66, 270, 270, 8640, 8640, 8640, 8640, 270, 270, 66, 270, 8640, 8640, 270, 66, 66, 66, 8640, 270, 270, 270, 270, 8640, 270, 8640, 66, 66, 270, 66, 8640, 8640, 66, 66, 270, 270, 270, 66, 8640, 66, 8640, 270, 66, 8640, 8640, 270, 270, 66, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 66, 8640, 66, 66, 8640, 270, 8640, 8640, 270, 8640, 66, 270, 8640, 66, 8640, 270, 66, 270, 270, 8640, 8640, 66, 66, 8640, 66, 66, 66, 270, 66]
Prompts retrieved: 385902 . Total input tokens: 85902462 . Total output tokens: 75982338
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 5.997234547976404,
    "estimated_duration": 3600.115647875661,
    "input_throughput": 5581.849575265101,
    "output_throughput": 4851.838304224185,
    "total_throughput": 10433.687879489285,
    "itl": 107.30533933122362,
    "ttft": 1359292.529306378,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2054,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.995001251743876,
    "arrivals": 128419,
    "finished_requests": 80849,
    "scheduler_time": 116.62781706377048
}
#Debug simulation 
Total elapsed time: 5.997346119955182. Arrivals time: 0.27340963622555137 Scheduler time: 5.566011349670589 Scheduler overhead time: 0.04985703527927399 Adapter cache time: 0.03229943895712495 Engine time: 0.05210721353068948 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.00625_size_8-8-32/adapters_128_slots_64_rate_0.8-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.00625_size_8-8-32/adapters_128_slots_64_rate_0.8-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [42 43 43]
Adapter prompts. [8640, 270, 8640, 8640, 66, 66, 8640, 66, 270, 270, 270, 66, 8640, 270, 66, 8640, 270, 66, 66, 66, 66, 270, 270, 8640, 270, 66, 270, 270, 270, 270, 8640, 270, 66, 270, 66, 8640, 8640, 66, 270, 270, 66, 270, 66, 270, 270, 8640, 8640, 8640, 8640, 270, 270, 66, 270, 8640, 8640, 270, 66, 66, 66, 8640, 270, 270, 270, 270, 8640, 270, 8640, 66, 66, 270, 66, 8640, 8640, 66, 66, 270, 270, 270, 66, 8640, 66, 8640, 270, 66, 8640, 8640, 270, 270, 66, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 66, 8640, 66, 66, 8640, 270, 8640, 8640, 270, 8640, 66, 270, 8640, 66, 8640, 270, 66, 270, 270, 8640, 8640, 66, 66, 8640, 66, 66, 66, 270, 66]
Prompts retrieved: 385902 . Total input tokens: 85902462 . Total output tokens: 75982338
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 5.7673234371468425,
    "estimated_duration": 3600.0109891483476,
    "input_throughput": 5362.226131583769,
    "output_throughput": 4658.46966871826,
    "total_throughput": 10020.69580030203,
    "itl": 93.81092865548568,
    "ttft": 1415656.9874865601,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1988,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.905207163286136,
    "arrivals": 128419,
    "finished_requests": 77656,
    "scheduler_time": 121.951433216232
}
#Debug simulation 
Total elapsed time: 5.76745618134737. Arrivals time: 0.23707971768453717 Scheduler time: 5.356848644092679 Scheduler overhead time: 0.055231973528862 Adapter cache time: 0.03396997740492225 Engine time: 0.05799006624147296 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.00625_size_8-16-16/adapters_128_slots_64_rate_0.8-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.00625_size_8-16-16/adapters_128_slots_64_rate_0.8-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [42 43 43]
Adapter prompts. [8640, 270, 8640, 8640, 66, 66, 8640, 66, 270, 270, 270, 66, 8640, 270, 66, 8640, 270, 66, 66, 66, 66, 270, 270, 8640, 270, 66, 270, 270, 270, 270, 8640, 270, 66, 270, 66, 8640, 8640, 66, 270, 270, 66, 270, 66, 270, 270, 8640, 8640, 8640, 8640, 270, 270, 66, 270, 8640, 8640, 270, 66, 66, 66, 8640, 270, 270, 270, 270, 8640, 270, 8640, 66, 66, 270, 66, 8640, 8640, 66, 66, 270, 270, 270, 66, 8640, 66, 8640, 270, 66, 8640, 8640, 270, 270, 66, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 66, 8640, 66, 66, 8640, 270, 8640, 8640, 270, 8640, 66, 270, 8640, 66, 8640, 270, 66, 270, 270, 8640, 8640, 66, 66, 8640, 66, 66, 66, 270, 66]
Prompts retrieved: 385902 . Total input tokens: 85902462 . Total output tokens: 75982338
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 5.9856477421708405,
    "estimated_duration": 3600.0429716598615,
    "input_throughput": 5583.084468220349,
    "output_throughput": 4852.679020091036,
    "total_throughput": 10435.763488311384,
    "itl": 107.27662951323502,
    "ttft": 1358916.5510845587,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2053,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.011309765591568,
    "arrivals": 128419,
    "finished_requests": 80867,
    "scheduler_time": 116.64596934883075
}
#Debug simulation 
Total elapsed time: 5.9857592969201505. Arrivals time: 0.2547644325532019 Scheduler time: 5.5736716305837035 Scheduler overhead time: 0.04986870475113392 Adapter cache time: 0.03186582215130329 Engine time: 0.05203307420015335 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.00625_size_8-16-32/adapters_128_slots_64_rate_0.8-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.00625_size_8-16-32/adapters_128_slots_64_rate_0.8-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [42 43 43]
Adapter prompts. [8640, 270, 8640, 8640, 66, 66, 8640, 66, 270, 270, 270, 66, 8640, 270, 66, 8640, 270, 66, 66, 66, 66, 270, 270, 8640, 270, 66, 270, 270, 270, 270, 8640, 270, 66, 270, 66, 8640, 8640, 66, 270, 270, 66, 270, 66, 270, 270, 8640, 8640, 8640, 8640, 270, 270, 66, 270, 8640, 8640, 270, 66, 66, 66, 8640, 270, 270, 270, 270, 8640, 270, 8640, 66, 66, 270, 66, 8640, 8640, 66, 66, 270, 270, 270, 66, 8640, 66, 8640, 270, 66, 8640, 8640, 270, 270, 66, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 66, 8640, 66, 66, 8640, 270, 8640, 8640, 270, 8640, 66, 270, 8640, 66, 8640, 270, 66, 270, 270, 8640, 8640, 66, 66, 8640, 66, 66, 66, 270, 66]
Prompts retrieved: 385902 . Total input tokens: 85902462 . Total output tokens: 75982338
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 5.78420869493857,
    "estimated_duration": 3600.0141838658205,
    "input_throughput": 5363.104425124015,
    "output_throughput": 4658.937477293321,
    "total_throughput": 10022.041902417335,
    "itl": 93.8050237040154,
    "ttft": 1415494.3338153597,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1985,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.737860974124377,
    "arrivals": 128419,
    "finished_requests": 77665,
    "scheduler_time": 121.95627730907586
}
#Debug simulation 
Total elapsed time: 5.784353464376181. Arrivals time: 0.2484449576586485 Scheduler time: 5.360820344183594 Scheduler overhead time: 0.055275407154113054 Adapter cache time: 0.03370631206780672 Engine time: 0.05977997649461031 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.00625_size_16-16-16/adapters_128_slots_64_rate_0.8-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.00625_size_16-16-16/adapters_128_slots_64_rate_0.8-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [42 43 43]
Adapter prompts. [8640, 270, 8640, 8640, 66, 66, 8640, 66, 270, 270, 270, 66, 8640, 270, 66, 8640, 270, 66, 66, 66, 66, 270, 270, 8640, 270, 66, 270, 270, 270, 270, 8640, 270, 66, 270, 66, 8640, 8640, 66, 270, 270, 66, 270, 66, 270, 270, 8640, 8640, 8640, 8640, 270, 270, 66, 270, 8640, 8640, 270, 66, 66, 66, 8640, 270, 270, 270, 270, 8640, 270, 8640, 66, 66, 270, 66, 8640, 8640, 66, 66, 270, 270, 270, 66, 8640, 66, 8640, 270, 66, 8640, 8640, 270, 270, 66, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 66, 8640, 66, 66, 8640, 270, 8640, 8640, 270, 8640, 66, 270, 8640, 66, 8640, 270, 66, 270, 270, 8640, 8640, 66, 66, 8640, 66, 66, 66, 270, 66]
Prompts retrieved: 385902 . Total input tokens: 85902462 . Total output tokens: 75982338
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 5.994198861066252,
    "estimated_duration": 3600.043854299409,
    "input_throughput": 5584.931132432761,
    "output_throughput": 4854.400309354273,
    "total_throughput": 10439.331441787035,
    "itl": 107.25830535597956,
    "ttft": 1358514.8320979285,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2055,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.118957532873088,
    "arrivals": 128419,
    "finished_requests": 80887,
    "scheduler_time": 116.66157654477448
}
#Debug simulation 
Total elapsed time: 5.9943228042684495. Arrivals time: 0.25297240167856216 Scheduler time: 5.583808109164238 Scheduler overhead time: 0.04976112302392721 Adapter cache time: 0.03189597697928548 Engine time: 0.052015623077750206 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.00625_size_16-16-32/adapters_128_slots_64_rate_0.8-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.00625_size_16-16-32/adapters_128_slots_64_rate_0.8-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [42 43 43]
Adapter prompts. [8640, 270, 8640, 8640, 66, 66, 8640, 66, 270, 270, 270, 66, 8640, 270, 66, 8640, 270, 66, 66, 66, 66, 270, 270, 8640, 270, 66, 270, 270, 270, 270, 8640, 270, 66, 270, 66, 8640, 8640, 66, 270, 270, 66, 270, 66, 270, 270, 8640, 8640, 8640, 8640, 270, 270, 66, 270, 8640, 8640, 270, 66, 66, 66, 8640, 270, 270, 270, 270, 8640, 270, 8640, 66, 66, 270, 66, 8640, 8640, 66, 66, 270, 270, 270, 66, 8640, 66, 8640, 270, 66, 8640, 8640, 270, 270, 66, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 66, 8640, 66, 66, 8640, 270, 8640, 8640, 270, 8640, 66, 270, 8640, 66, 8640, 270, 66, 270, 270, 8640, 8640, 66, 66, 8640, 66, 66, 66, 270, 66]
Prompts retrieved: 385902 . Total input tokens: 85902462 . Total output tokens: 75982338
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 5.782271606847644,
    "estimated_duration": 3600.0536805804004,
    "input_throughput": 5363.093362787651,
    "output_throughput": 4658.847197327347,
    "total_throughput": 10021.940560115,
    "itl": 93.80409919907542,
    "ttft": 1415450.7948180798,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1986,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.618611852861688,
    "arrivals": 128419,
    "finished_requests": 77665,
    "scheduler_time": 121.95946583832294
}
#Debug simulation 
Total elapsed time: 5.782413206063211. Arrivals time: 0.24680216843262315 Scheduler time: 5.36174116237089 Scheduler overhead time: 0.0555541985668242 Adapter cache time: 0.03391461540013552 Engine time: 0.05807260749861598 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.003125_size_8-8-8/adapters_128_slots_64_rate_0.8-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.003125_size_8-8-8/adapters_128_slots_64_rate_0.8-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [42 43 43]
Adapter prompts. [8640, 270, 8640, 8640, 33, 33, 8640, 33, 270, 270, 270, 33, 8640, 270, 33, 8640, 270, 33, 33, 33, 33, 270, 270, 8640, 270, 33, 270, 270, 270, 270, 8640, 270, 33, 270, 33, 8640, 8640, 33, 270, 270, 33, 270, 33, 270, 270, 8640, 8640, 8640, 8640, 270, 270, 33, 270, 8640, 8640, 270, 33, 33, 33, 8640, 270, 270, 270, 270, 8640, 270, 8640, 33, 33, 270, 33, 8640, 8640, 33, 33, 270, 270, 270, 33, 8640, 33, 8640, 270, 33, 8640, 8640, 270, 270, 33, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 33, 8640, 33, 33, 8640, 270, 8640, 8640, 270, 8640, 33, 270, 8640, 33, 8640, 270, 33, 270, 270, 8640, 8640, 33, 33, 8640, 33, 33, 33, 270, 33]
Prompts retrieved: 384516 . Total input tokens: 85597564 . Total output tokens: 75716412
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 6.109999143052846,
    "estimated_duration": 3600.034153432519,
    "input_throughput": 5729.447866580255,
    "output_throughput": 4999.78256673986,
    "total_throughput": 10729.230433320115,
    "itl": 114.94300938360523,
    "ttft": 1320031.3148800756,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1768,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.690739168487799,
    "arrivals": 127927,
    "finished_requests": 83414,
    "scheduler_time": 114.9250187660309
}
#Debug simulation 
Total elapsed time: 6.110134474933147. Arrivals time: 0.2590965828858316 Scheduler time: 5.7041207402944565 Scheduler overhead time: 0.046978714410215616 Adapter cache time: 0.028631422203034163 Engine time: 0.049016337376087904 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.003125_size_8-8-16/adapters_128_slots_64_rate_0.8-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.003125_size_8-8-16/adapters_128_slots_64_rate_0.8-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [42 43 43]
Adapter prompts. [8640, 270, 8640, 8640, 33, 33, 8640, 33, 270, 270, 270, 33, 8640, 270, 33, 8640, 270, 33, 33, 33, 33, 270, 270, 8640, 270, 33, 270, 270, 270, 270, 8640, 270, 33, 270, 33, 8640, 8640, 33, 270, 270, 33, 270, 33, 270, 270, 8640, 8640, 8640, 8640, 270, 270, 33, 270, 8640, 8640, 270, 33, 33, 33, 8640, 270, 270, 270, 270, 8640, 270, 8640, 33, 33, 270, 33, 8640, 8640, 33, 33, 270, 270, 270, 33, 8640, 33, 8640, 270, 33, 8640, 8640, 270, 270, 33, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 33, 8640, 33, 33, 8640, 270, 8640, 8640, 270, 8640, 33, 270, 8640, 33, 8640, 270, 33, 270, 270, 8640, 8640, 33, 33, 8640, 33, 33, 33, 270, 33]
Prompts retrieved: 384516 . Total input tokens: 85597564 . Total output tokens: 75716412
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 6.0171662722714245,
    "estimated_duration": 3600.0423304033975,
    "input_throughput": 5613.620381440203,
    "output_throughput": 4900.280991424686,
    "total_throughput": 10513.90137286489,
    "itl": 106.67400381575271,
    "ttft": 1348707.9757572722,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1746,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.74694474446569,
    "arrivals": 127927,
    "finished_requests": 81730,
    "scheduler_time": 117.60927003565776
}
#Debug simulation 
Total elapsed time: 6.017275621183217. Arrivals time: 0.2554052220657468 Scheduler time: 5.606031837873161 Scheduler overhead time: 0.04995874362066388 Adapter cache time: 0.029922278597950935 Engine time: 0.05228222627192736 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.003125_size_8-8-32/adapters_128_slots_64_rate_0.8-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.003125_size_8-8-32/adapters_128_slots_64_rate_0.8-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [42 43 43]
Adapter prompts. [8640, 270, 8640, 8640, 33, 33, 8640, 33, 270, 270, 270, 33, 8640, 270, 33, 8640, 270, 33, 33, 33, 33, 270, 270, 8640, 270, 33, 270, 270, 270, 270, 8640, 270, 33, 270, 33, 8640, 8640, 33, 270, 270, 33, 270, 33, 270, 270, 8640, 8640, 8640, 8640, 270, 270, 33, 270, 8640, 8640, 270, 33, 33, 33, 8640, 270, 270, 270, 270, 8640, 270, 8640, 33, 33, 270, 33, 8640, 8640, 33, 33, 270, 270, 270, 33, 8640, 33, 8640, 270, 33, 8640, 8640, 270, 270, 33, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 33, 8640, 33, 33, 8640, 270, 8640, 8640, 270, 8640, 33, 270, 8640, 33, 8640, 270, 33, 270, 270, 8640, 8640, 33, 33, 8640, 33, 33, 33, 270, 33]
Prompts retrieved: 384516 . Total input tokens: 85597564 . Total output tokens: 75716412
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 5.837814402766526,
    "estimated_duration": 3600.042372666936,
    "input_throughput": 5379.262518416929,
    "output_throughput": 4698.67386240483,
    "total_throughput": 10077.936380821759,
    "itl": 93.45827699962922,
    "ttft": 1407412.830329459,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1700,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.755305090313565,
    "arrivals": 127927,
    "finished_requests": 78330,
    "scheduler_time": 122.82928336189185
}
#Debug simulation 
Total elapsed time: 5.837951596826315. Arrivals time: 0.2505463627167046 Scheduler time: 5.415507223457098 Scheduler overhead time: 0.05546752829104662 Adapter cache time: 0.03146239556372166 Engine time: 0.05849035317078233 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.003125_size_8-16-16/adapters_128_slots_64_rate_0.8-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.003125_size_8-16-16/adapters_128_slots_64_rate_0.8-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [42 43 43]
Adapter prompts. [8640, 270, 8640, 8640, 33, 33, 8640, 33, 270, 270, 270, 33, 8640, 270, 33, 8640, 270, 33, 33, 33, 33, 270, 270, 8640, 270, 33, 270, 270, 270, 270, 8640, 270, 33, 270, 33, 8640, 8640, 33, 270, 270, 33, 270, 33, 270, 270, 8640, 8640, 8640, 8640, 270, 270, 33, 270, 8640, 8640, 270, 33, 33, 33, 8640, 270, 270, 270, 270, 8640, 270, 8640, 33, 33, 270, 33, 8640, 8640, 33, 33, 270, 270, 270, 33, 8640, 33, 8640, 270, 33, 8640, 8640, 270, 270, 33, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 33, 8640, 33, 33, 8640, 270, 8640, 8640, 270, 8640, 33, 270, 8640, 33, 8640, 270, 33, 270, 270, 8640, 8640, 33, 33, 8640, 33, 33, 33, 270, 33]
Prompts retrieved: 384516 . Total input tokens: 85597564 . Total output tokens: 75716412
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 6.007938114926219,
    "estimated_duration": 3600.0790447009126,
    "input_throughput": 5615.786139406729,
    "output_throughput": 4901.736539917014,
    "total_throughput": 10517.522679323742,
    "itl": 106.6429724056555,
    "ttft": 1348327.878485709,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1744,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.91373830735697,
    "arrivals": 127927,
    "finished_requests": 81757,
    "scheduler_time": 117.63161407764339
}
#Debug simulation 
Total elapsed time: 6.008076188154519. Arrivals time: 0.25346976751461625 Scheduler time: 5.599122107960284 Scheduler overhead time: 0.049954729154706 Adapter cache time: 0.029881907626986504 Engine time: 0.05194763699546456 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.003125_size_8-16-32/adapters_128_slots_64_rate_0.8-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.003125_size_8-16-32/adapters_128_slots_64_rate_0.8-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [42 43 43]
Adapter prompts. [8640, 270, 8640, 8640, 33, 33, 8640, 33, 270, 270, 270, 33, 8640, 270, 33, 8640, 270, 33, 33, 33, 33, 270, 270, 8640, 270, 33, 270, 270, 270, 270, 8640, 270, 33, 270, 33, 8640, 8640, 33, 270, 270, 33, 270, 33, 270, 270, 8640, 8640, 8640, 8640, 270, 270, 33, 270, 8640, 8640, 270, 33, 33, 33, 8640, 270, 270, 270, 270, 8640, 270, 8640, 33, 33, 270, 33, 8640, 8640, 33, 33, 270, 270, 270, 33, 8640, 33, 8640, 270, 33, 8640, 8640, 270, 270, 33, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 33, 8640, 33, 33, 8640, 270, 8640, 8640, 270, 8640, 33, 270, 8640, 33, 8640, 270, 33, 270, 270, 8640, 8640, 33, 33, 8640, 33, 33, 33, 270, 33]
Prompts retrieved: 384516 . Total input tokens: 85597564 . Total output tokens: 75716412
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 5.8227369100786746,
    "estimated_duration": 3600.011692448712,
    "input_throughput": 5379.460028038757,
    "output_throughput": 4698.954460476659,
    "total_throughput": 10078.414488515415,
    "itl": 93.45545004738133,
    "ttft": 1407340.9127175838,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1705,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.671725647602955,
    "arrivals": 127927,
    "finished_requests": 78335,
    "scheduler_time": 122.83299867718848
}
#Debug simulation 
Total elapsed time: 5.822850212920457. Arrivals time: 0.2527591693215072 Scheduler time: 5.398317355196923 Scheduler overhead time: 0.05546183791011572 Adapter cache time: 0.031520933378487825 Engine time: 0.05825446452945471 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.003125_size_16-16-16/adapters_128_slots_64_rate_0.8-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.003125_size_16-16-16/adapters_128_slots_64_rate_0.8-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [42 43 43]
Adapter prompts. [8640, 270, 8640, 8640, 33, 33, 8640, 33, 270, 270, 270, 33, 8640, 270, 33, 8640, 270, 33, 33, 33, 33, 270, 270, 8640, 270, 33, 270, 270, 270, 270, 8640, 270, 33, 270, 33, 8640, 8640, 33, 270, 270, 33, 270, 33, 270, 270, 8640, 8640, 8640, 8640, 270, 270, 33, 270, 8640, 8640, 270, 33, 33, 33, 8640, 270, 270, 270, 270, 8640, 270, 8640, 33, 33, 270, 33, 8640, 8640, 33, 33, 270, 270, 270, 33, 8640, 33, 8640, 270, 33, 8640, 8640, 270, 270, 33, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 33, 8640, 33, 33, 8640, 270, 8640, 8640, 270, 8640, 33, 270, 8640, 33, 8640, 270, 33, 270, 270, 8640, 8640, 33, 33, 8640, 33, 33, 33, 270, 33]
Prompts retrieved: 384516 . Total input tokens: 85597564 . Total output tokens: 75716412
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 6.005697712767869,
    "estimated_duration": 3600.052594706069,
    "input_throughput": 5615.556292074279,
    "output_throughput": 4901.607833715755,
    "total_throughput": 10517.164125790034,
    "itl": 106.50487522974174,
    "ttft": 1348288.2818786937,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1744,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.133558120355387,
    "arrivals": 127927,
    "finished_requests": 81754,
    "scheduler_time": 117.68657279000865
}
#Debug simulation 
Total elapsed time: 6.005836732685566. Arrivals time: 0.2553376220166683 Scheduler time: 5.594883951358497 Scheduler overhead time: 0.04988383688032627 Adapter cache time: 0.029845179058611393 Engine time: 0.052230092231184244 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.003125_size_16-16-32/adapters_128_slots_64_rate_0.8-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.003125_size_16-16-32/adapters_128_slots_64_rate_0.8-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [42 43 43]
Adapter prompts. [8640, 270, 8640, 8640, 33, 33, 8640, 33, 270, 270, 270, 33, 8640, 270, 33, 8640, 270, 33, 33, 33, 33, 270, 270, 8640, 270, 33, 270, 270, 270, 270, 8640, 270, 33, 270, 33, 8640, 8640, 33, 270, 270, 33, 270, 33, 270, 270, 8640, 8640, 8640, 8640, 270, 270, 33, 270, 8640, 8640, 270, 33, 33, 33, 8640, 270, 270, 270, 270, 8640, 270, 8640, 33, 33, 270, 33, 8640, 8640, 33, 33, 270, 270, 270, 33, 8640, 33, 8640, 270, 33, 8640, 8640, 270, 270, 33, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 33, 8640, 33, 33, 8640, 270, 8640, 8640, 270, 8640, 33, 270, 8640, 33, 8640, 270, 33, 270, 270, 8640, 8640, 33, 33, 8640, 33, 33, 33, 270, 33]
Prompts retrieved: 384516 . Total input tokens: 85597564 . Total output tokens: 75716412
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 5.809241412207484,
    "estimated_duration": 3600.0533623077336,
    "input_throughput": 5379.397761922558,
    "output_throughput": 4698.900071069,
    "total_throughput": 10078.297832991557,
    "itl": 93.45757180631128,
    "ttft": 1407333.298771219,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1703,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.543367860112134,
    "arrivals": 127927,
    "finished_requests": 78335,
    "scheduler_time": 122.83358098646187
}
#Debug simulation 
Total elapsed time: 5.80938616534695. Arrivals time: 0.25199297815561295 Scheduler time: 5.385656976141036 Scheduler overhead time: 0.055308455135673285 Adapter cache time: 0.031711784191429615 Engine time: 0.05832530790939927 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.0125-0.00625_size_8-8-8/adapters_128_slots_64_rate_0.8-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.0125-0.00625_size_8-8-8/adapters_128_slots_64_rate_0.8-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.8    ]. Counts: [42 43 43]
Adapter prompts. [8640, 135, 8640, 8640, 66, 66, 8640, 66, 135, 135, 135, 66, 8640, 135, 66, 8640, 135, 66, 66, 66, 66, 135, 135, 8640, 135, 66, 135, 135, 135, 135, 8640, 135, 66, 135, 66, 8640, 8640, 66, 135, 135, 66, 135, 66, 135, 135, 8640, 8640, 8640, 8640, 135, 135, 66, 135, 8640, 8640, 135, 66, 66, 66, 8640, 135, 135, 135, 135, 8640, 135, 8640, 66, 66, 135, 66, 8640, 8640, 66, 66, 135, 135, 135, 66, 8640, 66, 8640, 135, 66, 8640, 8640, 135, 135, 66, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 66, 8640, 66, 66, 8640, 135, 8640, 8640, 135, 8640, 66, 135, 8640, 66, 8640, 135, 66, 135, 135, 8640, 8640, 66, 66, 8640, 66, 66, 66, 135, 66]
Prompts retrieved: 380097 . Total input tokens: 84663238 . Total output tokens: 74831855
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 6.3153928141109645,
    "estimated_duration": 3600.1104796862805,
    "input_throughput": 5881.586723373325,
    "output_throughput": 5166.680885199081,
    "total_throughput": 11048.267608572405,
    "itl": 111.34314069562518,
    "ttft": 1263364.1013533683,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1462,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.667342004711053,
    "arrivals": 126456,
    "finished_requests": 85898,
    "scheduler_time": 116.46030845527696
}
#Debug simulation 
Total elapsed time: 6.315523934084922. Arrivals time: 0.26917974511161447 Scheduler time: 5.899504673201591 Scheduler overhead time: 0.048279883340001106 Adapter cache time: 0.025189070962369442 Engine time: 0.05038904957473278 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.0125-0.00625_size_8-8-16/adapters_128_slots_64_rate_0.8-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.0125-0.00625_size_8-8-16/adapters_128_slots_64_rate_0.8-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.8    ]. Counts: [42 43 43]
Adapter prompts. [8640, 135, 8640, 8640, 66, 66, 8640, 66, 135, 135, 135, 66, 8640, 135, 66, 8640, 135, 66, 66, 66, 66, 135, 135, 8640, 135, 66, 135, 135, 135, 135, 8640, 135, 66, 135, 66, 8640, 8640, 66, 135, 135, 66, 135, 66, 135, 135, 8640, 8640, 8640, 8640, 135, 135, 66, 135, 8640, 8640, 135, 66, 66, 66, 8640, 135, 135, 135, 135, 8640, 135, 8640, 66, 66, 135, 66, 8640, 8640, 66, 66, 135, 135, 135, 66, 8640, 66, 8640, 135, 66, 8640, 8640, 135, 135, 66, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 66, 8640, 66, 66, 8640, 135, 8640, 8640, 135, 8640, 66, 135, 8640, 66, 8640, 135, 66, 135, 135, 8640, 8640, 66, 66, 8640, 66, 66, 66, 135, 66]
Prompts retrieved: 380097 . Total input tokens: 84663238 . Total output tokens: 74831855
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 6.208589904010296,
    "estimated_duration": 3600.075541873983,
    "input_throughput": 5757.768624268933,
    "output_throughput": 5060.451867772974,
    "total_throughput": 10818.220492041908,
    "itl": 103.33738760046062,
    "ttft": 1293910.219293479,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1436,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.427815114427291,
    "arrivals": 126456,
    "finished_requests": 84088,
    "scheduler_time": 119.16782578849399
}
#Debug simulation 
Total elapsed time: 6.208718546200544. Arrivals time: 0.26226208824664354 Scheduler time: 5.791329530067742 Scheduler overhead time: 0.05112203070893884 Adapter cache time: 0.025906698312610388 Engine time: 0.053615028504282236 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.0125-0.00625_size_8-8-32/adapters_128_slots_64_rate_0.8-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.0125-0.00625_size_8-8-32/adapters_128_slots_64_rate_0.8-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.8    ]. Counts: [42 43 43]
Adapter prompts. [8640, 135, 8640, 8640, 66, 66, 8640, 66, 135, 135, 135, 66, 8640, 135, 66, 8640, 135, 66, 66, 66, 66, 135, 135, 8640, 135, 66, 135, 135, 135, 135, 8640, 135, 66, 135, 66, 8640, 8640, 66, 135, 135, 66, 135, 66, 135, 135, 8640, 8640, 8640, 8640, 135, 135, 66, 135, 8640, 8640, 135, 66, 66, 66, 8640, 135, 135, 135, 135, 8640, 135, 8640, 66, 66, 135, 66, 8640, 8640, 66, 66, 135, 135, 135, 66, 8640, 66, 8640, 135, 66, 8640, 8640, 135, 135, 66, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 66, 8640, 66, 66, 8640, 135, 8640, 8640, 135, 8640, 66, 135, 8640, 66, 8640, 135, 66, 135, 135, 8640, 8640, 66, 66, 8640, 66, 66, 66, 135, 66]
Prompts retrieved: 380097 . Total input tokens: 84663238 . Total output tokens: 74831855
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 5.941477658227086,
    "estimated_duration": 3600.004657230838,
    "input_throughput": 5508.308707370784,
    "output_throughput": 4842.2690134542845,
    "total_throughput": 10350.57772082507,
    "itl": 90.69075126238432,
    "ttft": 1357731.5897952192,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1365,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.174563376940696,
    "arrivals": 126456,
    "finished_requests": 80416,
    "scheduler_time": 124.48774575482068
}
#Debug simulation 
Total elapsed time: 5.941586496308446. Arrivals time: 0.2470739297568798 Scheduler time: 5.523237586021423 Scheduler overhead time: 0.05715177673846483 Adapter cache time: 0.027025243267416954 Engine time: 0.05988901015371084 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.0125-0.00625_size_8-16-16/adapters_128_slots_64_rate_0.8-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.0125-0.00625_size_8-16-16/adapters_128_slots_64_rate_0.8-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.8    ]. Counts: [42 43 43]
Adapter prompts. [8640, 135, 8640, 8640, 66, 66, 8640, 66, 135, 135, 135, 66, 8640, 135, 66, 8640, 135, 66, 66, 66, 66, 135, 135, 8640, 135, 66, 135, 135, 135, 135, 8640, 135, 66, 135, 66, 8640, 8640, 66, 135, 135, 66, 135, 66, 135, 135, 8640, 8640, 8640, 8640, 135, 135, 66, 135, 8640, 8640, 135, 66, 66, 66, 8640, 135, 135, 135, 135, 8640, 135, 8640, 66, 66, 135, 66, 8640, 8640, 66, 66, 135, 135, 135, 66, 8640, 66, 8640, 135, 66, 8640, 8640, 135, 135, 66, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 66, 8640, 66, 66, 8640, 135, 8640, 8640, 135, 8640, 66, 135, 8640, 66, 8640, 135, 66, 135, 135, 8640, 8640, 66, 66, 8640, 66, 66, 66, 135, 66]
Prompts retrieved: 380097 . Total input tokens: 84663238 . Total output tokens: 74831855
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 6.19211249705404,
    "estimated_duration": 3600.0908474559274,
    "input_throughput": 5759.513823006056,
    "output_throughput": 5061.391995948255,
    "total_throughput": 10820.90581895431,
    "itl": 103.32078603537202,
    "ttft": 1293713.828725964,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1435,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.741202916563578,
    "arrivals": 126456,
    "finished_requests": 84108,
    "scheduler_time": 119.18101482667312
}
#Debug simulation 
Total elapsed time: 6.192225266713649. Arrivals time: 0.2600966338068247 Scheduler time: 5.776941067073494 Scheduler overhead time: 0.050953300669789314 Adapter cache time: 0.026014886796474457 Engine time: 0.0538728735409677 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.0125-0.00625_size_8-16-32/adapters_128_slots_64_rate_0.8-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.0125-0.00625_size_8-16-32/adapters_128_slots_64_rate_0.8-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.8    ]. Counts: [42 43 43]
Adapter prompts. [8640, 135, 8640, 8640, 66, 66, 8640, 66, 135, 135, 135, 66, 8640, 135, 66, 8640, 135, 66, 66, 66, 66, 135, 135, 8640, 135, 66, 135, 135, 135, 135, 8640, 135, 66, 135, 66, 8640, 8640, 66, 135, 135, 66, 135, 66, 135, 135, 8640, 8640, 8640, 8640, 135, 135, 66, 135, 8640, 8640, 135, 66, 66, 66, 8640, 135, 135, 135, 135, 8640, 135, 8640, 66, 66, 135, 66, 8640, 8640, 66, 66, 135, 135, 135, 66, 8640, 66, 8640, 135, 66, 8640, 8640, 135, 135, 66, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 66, 8640, 66, 66, 8640, 135, 8640, 8640, 135, 8640, 66, 135, 8640, 66, 8640, 135, 66, 135, 135, 8640, 8640, 66, 66, 8640, 66, 66, 66, 135, 66]
Prompts retrieved: 380097 . Total input tokens: 84663238 . Total output tokens: 74831855
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 5.971338531002402,
    "estimated_duration": 3600.021679532484,
    "input_throughput": 5508.283495274732,
    "output_throughput": 4842.409171898072,
    "total_throughput": 10350.692667172803,
    "itl": 90.68676421694865,
    "ttft": 1357776.6939099978,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1365,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.078253889814864,
    "arrivals": 126456,
    "finished_requests": 80419,
    "scheduler_time": 124.49209228311739
}
#Debug simulation 
Total elapsed time: 5.971452358178794. Arrivals time: 0.2543971394188702 Scheduler time: 5.546528049279004 Scheduler overhead time: 0.056882480159401894 Adapter cache time: 0.02687653247267008 Engine time: 0.05968419974669814 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.0125-0.00625_size_16-16-16/adapters_128_slots_64_rate_0.8-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.0125-0.00625_size_16-16-16/adapters_128_slots_64_rate_0.8-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.8    ]. Counts: [42 43 43]
Adapter prompts. [8640, 135, 8640, 8640, 66, 66, 8640, 66, 135, 135, 135, 66, 8640, 135, 66, 8640, 135, 66, 66, 66, 66, 135, 135, 8640, 135, 66, 135, 135, 135, 135, 8640, 135, 66, 135, 66, 8640, 8640, 66, 135, 135, 66, 135, 66, 135, 135, 8640, 8640, 8640, 8640, 135, 135, 66, 135, 8640, 8640, 135, 66, 66, 66, 8640, 135, 135, 135, 135, 8640, 135, 8640, 66, 66, 135, 66, 8640, 8640, 66, 66, 135, 135, 135, 66, 8640, 66, 8640, 135, 66, 8640, 8640, 135, 135, 66, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 66, 8640, 66, 66, 8640, 135, 8640, 8640, 135, 8640, 66, 135, 8640, 66, 8640, 135, 66, 135, 135, 8640, 8640, 66, 66, 8640, 66, 66, 66, 135, 66]
Prompts retrieved: 380097 . Total input tokens: 84663238 . Total output tokens: 74831855
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 6.198740251827985,
    "estimated_duration": 3600.090391971155,
    "input_throughput": 5759.902041972435,
    "output_throughput": 5061.852069226046,
    "total_throughput": 10821.754111198481,
    "itl": 103.29846379482194,
    "ttft": 1293459.2104289932,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1435,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.160926549718829,
    "arrivals": 126456,
    "finished_requests": 84117,
    "scheduler_time": 119.19076376136077
}
#Debug simulation 
Total elapsed time: 6.198852913919836. Arrivals time: 0.2554523912258446 Scheduler time: 5.7878979947417974 Scheduler overhead time: 0.051276749931275845 Adapter cache time: 0.026082622352987528 Engine time: 0.05379021028056741 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.0125-0.00625_size_16-16-32/adapters_128_slots_64_rate_0.8-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.0125-0.00625_size_16-16-32/adapters_128_slots_64_rate_0.8-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.8    ]. Counts: [42 43 43]
Adapter prompts. [8640, 135, 8640, 8640, 66, 66, 8640, 66, 135, 135, 135, 66, 8640, 135, 66, 8640, 135, 66, 66, 66, 66, 135, 135, 8640, 135, 66, 135, 135, 135, 135, 8640, 135, 66, 135, 66, 8640, 8640, 66, 135, 135, 66, 135, 66, 135, 135, 8640, 8640, 8640, 8640, 135, 135, 66, 135, 8640, 8640, 135, 66, 66, 66, 8640, 135, 135, 135, 135, 8640, 135, 8640, 66, 66, 135, 66, 8640, 8640, 66, 66, 135, 135, 135, 66, 8640, 66, 8640, 135, 66, 8640, 8640, 135, 135, 66, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 66, 8640, 66, 66, 8640, 135, 8640, 8640, 135, 8640, 66, 135, 8640, 66, 8640, 135, 66, 135, 135, 8640, 8640, 66, 66, 8640, 66, 66, 66, 135, 66]
Prompts retrieved: 380097 . Total input tokens: 84663238 . Total output tokens: 74831855
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 5.966394962742925,
    "estimated_duration": 3600.0803634705812,
    "input_throughput": 5508.272593360414,
    "output_throughput": 4842.509399760643,
    "total_throughput": 10350.781993121056,
    "itl": 90.68703463184126,
    "ttft": 1357655.8594080263,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1364,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.988418400660077,
    "arrivals": 126456,
    "finished_requests": 80422,
    "scheduler_time": 124.49398664398477
}
#Debug simulation 
Total elapsed time: 5.966504544951022. Arrivals time: 0.25378330098465085 Scheduler time: 5.541687796358019 Scheduler overhead time: 0.05694256443530321 Adapter cache time: 0.027151250280439854 Engine time: 0.0598340667784214 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.0125-0.003125_size_8-8-8/adapters_128_slots_64_rate_0.8-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.0125-0.003125_size_8-8-8/adapters_128_slots_64_rate_0.8-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [42 43 43]
Adapter prompts. [8640, 135, 8640, 8640, 33, 33, 8640, 33, 135, 135, 135, 33, 8640, 135, 33, 8640, 135, 33, 33, 33, 33, 135, 135, 8640, 135, 33, 135, 135, 135, 135, 8640, 135, 33, 135, 33, 8640, 8640, 33, 135, 135, 33, 135, 33, 135, 135, 8640, 8640, 8640, 8640, 135, 135, 33, 135, 8640, 8640, 135, 33, 33, 33, 8640, 135, 135, 135, 135, 8640, 135, 8640, 33, 33, 135, 33, 8640, 8640, 33, 33, 135, 135, 135, 33, 8640, 33, 8640, 135, 33, 8640, 8640, 135, 135, 33, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 33, 8640, 33, 33, 8640, 135, 8640, 8640, 135, 8640, 33, 135, 8640, 33, 8640, 135, 33, 135, 135, 8640, 8640, 33, 33, 8640, 33, 33, 33, 135, 33]
Prompts retrieved: 378711 . Total input tokens: 84358862 . Total output tokens: 74555200
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 6.387219921685755,
    "estimated_duration": 3600.016653023912,
    "input_throughput": 5953.52745993468,
    "output_throughput": 5231.601355004871,
    "total_throughput": 11185.128814939551,
    "itl": 109.85788537595377,
    "ttft": 1238351.4699679418,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1126,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.445572569975802,
    "arrivals": 125984,
    "finished_requests": 86825,
    "scheduler_time": 116.64106762828186
}
#Debug simulation 
Total elapsed time: 6.387356426566839. Arrivals time: 0.26080156583338976 Scheduler time: 5.981091492809355 Scheduler overhead time: 0.04896886507049203 Adapter cache time: 0.02220017183572054 Engine time: 0.05110022285953164 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.0125-0.003125_size_8-8-16/adapters_128_slots_64_rate_0.8-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.0125-0.003125_size_8-8-16/adapters_128_slots_64_rate_0.8-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [42 43 43]
Adapter prompts. [8640, 135, 8640, 8640, 33, 33, 8640, 33, 135, 135, 135, 33, 8640, 135, 33, 8640, 135, 33, 33, 33, 33, 135, 135, 8640, 135, 33, 135, 135, 135, 135, 8640, 135, 33, 135, 33, 8640, 8640, 33, 135, 135, 33, 135, 33, 135, 135, 8640, 8640, 8640, 8640, 135, 135, 33, 135, 8640, 8640, 135, 33, 33, 33, 8640, 135, 135, 135, 135, 8640, 135, 8640, 33, 33, 135, 33, 8640, 8640, 33, 33, 135, 135, 135, 33, 8640, 33, 8640, 135, 33, 8640, 8640, 135, 135, 33, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 33, 8640, 33, 33, 8640, 135, 8640, 8640, 135, 8640, 33, 135, 8640, 33, 8640, 135, 33, 135, 135, 8640, 8640, 33, 33, 8640, 33, 33, 33, 135, 33]
Prompts retrieved: 378711 . Total input tokens: 84358862 . Total output tokens: 74555200
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 6.245906472671777,
    "estimated_duration": 3600.0467323699745,
    "input_throughput": 5819.896950672914,
    "output_throughput": 5115.098044262705,
    "total_throughput": 10934.994994935618,
    "itl": 102.09367905371828,
    "ttft": 1270783.4503533537,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1092,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.956878558155159,
    "arrivals": 125984,
    "finished_requests": 84866,
    "scheduler_time": 119.29273131413068
}
#Debug simulation 
Total elapsed time: 6.246043257880956. Arrivals time: 0.25653107883408666 Scheduler time: 5.83555740211159 Scheduler overhead time: 0.051847190130501986 Adapter cache time: 0.02307986654341221 Engine time: 0.05443765688687563 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.0125-0.003125_size_8-8-32/adapters_128_slots_64_rate_0.8-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.0125-0.003125_size_8-8-32/adapters_128_slots_64_rate_0.8-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [42 43 43]
Adapter prompts. [8640, 135, 8640, 8640, 33, 33, 8640, 33, 135, 135, 135, 33, 8640, 135, 33, 8640, 135, 33, 33, 33, 33, 135, 135, 8640, 135, 33, 135, 135, 135, 135, 8640, 135, 33, 135, 33, 8640, 8640, 33, 135, 135, 33, 135, 33, 135, 135, 8640, 8640, 8640, 8640, 135, 135, 33, 135, 8640, 8640, 135, 33, 33, 33, 8640, 135, 135, 135, 135, 8640, 135, 8640, 33, 33, 135, 33, 8640, 8640, 33, 33, 135, 135, 135, 33, 8640, 33, 8640, 135, 33, 8640, 8640, 135, 135, 33, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 33, 8640, 33, 33, 8640, 135, 8640, 8640, 135, 8640, 33, 135, 8640, 33, 8640, 135, 33, 135, 135, 8640, 8640, 33, 33, 8640, 33, 33, 33, 135, 33]
Prompts retrieved: 378711 . Total input tokens: 84358862 . Total output tokens: 74555200
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 6.014609450940043,
    "estimated_duration": 3600.0966036776967,
    "input_throughput": 5553.027654751722,
    "output_throughput": 4887.243298423215,
    "total_throughput": 10440.270953174937,
    "itl": 89.74707510119934,
    "ttft": 1336970.9368924103,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1045,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.810655922270394,
    "arrivals": 125984,
    "finished_requests": 80995,
    "scheduler_time": 124.63952564307432
}
#Debug simulation 
Total elapsed time: 6.014752320945263. Arrivals time: 0.2510144258849323 Scheduler time: 5.594686197116971 Scheduler overhead time: 0.05759466998279095 Adapter cache time: 0.023814581334590912 Engine time: 0.0602108845487237 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.0125-0.003125_size_8-16-16/adapters_128_slots_64_rate_0.8-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.0125-0.003125_size_8-16-16/adapters_128_slots_64_rate_0.8-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [42 43 43]
Adapter prompts. [8640, 135, 8640, 8640, 33, 33, 8640, 33, 135, 135, 135, 33, 8640, 135, 33, 8640, 135, 33, 33, 33, 33, 135, 135, 8640, 135, 33, 135, 135, 135, 135, 8640, 135, 33, 135, 33, 8640, 8640, 33, 135, 135, 33, 135, 33, 135, 135, 8640, 8640, 8640, 8640, 135, 135, 33, 135, 8640, 8640, 135, 33, 33, 33, 8640, 135, 135, 135, 135, 8640, 135, 8640, 33, 33, 135, 33, 8640, 8640, 33, 33, 135, 135, 135, 33, 8640, 33, 8640, 135, 33, 8640, 8640, 135, 135, 33, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 33, 8640, 33, 33, 8640, 135, 8640, 8640, 135, 8640, 33, 135, 8640, 33, 8640, 135, 33, 135, 135, 8640, 8640, 33, 33, 8640, 33, 33, 33, 135, 33]
Prompts retrieved: 378711 . Total input tokens: 84358862 . Total output tokens: 74555200
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 6.2430034331046045,
    "estimated_duration": 3600.017150532969,
    "input_throughput": 5820.970324237928,
    "output_throughput": 5116.026738170765,
    "total_throughput": 10936.997062408695,
    "itl": 102.07751775107077,
    "ttft": 1270493.1525931833,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1094,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.435181325310826,
    "arrivals": 125984,
    "finished_requests": 84878,
    "scheduler_time": 119.30368791695568
}
#Debug simulation 
Total elapsed time: 6.243143149185926. Arrivals time: 0.25617840653285384 Scheduler time: 5.833077883347869 Scheduler overhead time: 0.05184485111385584 Adapter cache time: 0.023176125716418028 Engine time: 0.05418072547763586 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.0125-0.003125_size_8-16-32/adapters_128_slots_64_rate_0.8-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.0125-0.003125_size_8-16-32/adapters_128_slots_64_rate_0.8-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [42 43 43]
Adapter prompts. [8640, 135, 8640, 8640, 33, 33, 8640, 33, 135, 135, 135, 33, 8640, 135, 33, 8640, 135, 33, 33, 33, 33, 135, 135, 8640, 135, 33, 135, 135, 135, 135, 8640, 135, 33, 135, 33, 8640, 8640, 33, 135, 135, 33, 135, 33, 135, 135, 8640, 8640, 8640, 8640, 135, 135, 33, 135, 8640, 8640, 135, 33, 33, 33, 8640, 135, 135, 135, 135, 8640, 135, 8640, 33, 33, 135, 33, 8640, 8640, 33, 33, 135, 135, 135, 33, 8640, 33, 8640, 135, 33, 8640, 8640, 135, 135, 33, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 33, 8640, 33, 33, 8640, 135, 8640, 8640, 135, 8640, 33, 135, 8640, 33, 8640, 135, 33, 135, 135, 8640, 8640, 33, 33, 8640, 33, 33, 33, 135, 33]
Prompts retrieved: 378711 . Total input tokens: 84358862 . Total output tokens: 74555200
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 6.047553930897266,
    "estimated_duration": 3600.0756731335077,
    "input_throughput": 5552.959386156391,
    "output_throughput": 4886.92477530251,
    "total_throughput": 10439.884161458902,
    "itl": 89.74481216067795,
    "ttft": 1336998.2843826641,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1046,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.7418915231200085,
    "arrivals": 125984,
    "finished_requests": 80992,
    "scheduler_time": 124.64120751827771
}
#Debug simulation 
Total elapsed time: 6.047682732809335. Arrivals time: 0.2564426106400788 Scheduler time: 5.621416038833559 Scheduler overhead time: 0.05742240929976106 Adapter cache time: 0.024317181203514338 Engine time: 0.060678721871227026 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.0125-0.003125_size_16-16-16/adapters_128_slots_64_rate_0.8-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.0125-0.003125_size_16-16-16/adapters_128_slots_64_rate_0.8-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [42 43 43]
Adapter prompts. [8640, 135, 8640, 8640, 33, 33, 8640, 33, 135, 135, 135, 33, 8640, 135, 33, 8640, 135, 33, 33, 33, 33, 135, 135, 8640, 135, 33, 135, 135, 135, 135, 8640, 135, 33, 135, 33, 8640, 8640, 33, 135, 135, 33, 135, 33, 135, 135, 8640, 8640, 8640, 8640, 135, 135, 33, 135, 8640, 8640, 135, 33, 33, 33, 8640, 135, 135, 135, 135, 8640, 135, 8640, 33, 33, 135, 33, 8640, 8640, 33, 33, 135, 135, 135, 33, 8640, 33, 8640, 135, 33, 8640, 8640, 135, 135, 33, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 33, 8640, 33, 33, 8640, 135, 8640, 8640, 135, 8640, 33, 135, 8640, 33, 8640, 135, 33, 135, 135, 8640, 8640, 33, 33, 8640, 33, 33, 33, 135, 33]
Prompts retrieved: 378711 . Total input tokens: 84358862 . Total output tokens: 74555200
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 6.268500702921301,
    "estimated_duration": 3600.010170072442,
    "input_throughput": 5821.5641095198,
    "output_throughput": 5116.5452678788815,
    "total_throughput": 10938.109377398681,
    "itl": 102.06504741964456,
    "ttft": 1270307.800259626,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1094,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.984009508984128,
    "arrivals": 125984,
    "finished_requests": 84888,
    "scheduler_time": 119.30951354033557
}
#Debug simulation 
Total elapsed time: 6.268630200996995. Arrivals time: 0.2597190155647695 Scheduler time: 5.85509747127071 Scheduler overhead time: 0.051793734543025494 Adapter cache time: 0.02285804320126772 Engine time: 0.054504277650266886 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.0125-0.003125_size_16-16-32/adapters_128_slots_64_rate_0.8-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.0125-0.003125_size_16-16-32/adapters_128_slots_64_rate_0.8-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [42 43 43]
Adapter prompts. [8640, 135, 8640, 8640, 33, 33, 8640, 33, 135, 135, 135, 33, 8640, 135, 33, 8640, 135, 33, 33, 33, 33, 135, 135, 8640, 135, 33, 135, 135, 135, 135, 8640, 135, 33, 135, 33, 8640, 8640, 33, 135, 135, 33, 135, 33, 135, 135, 8640, 8640, 8640, 8640, 135, 135, 33, 135, 8640, 8640, 135, 33, 33, 33, 8640, 135, 135, 135, 135, 8640, 135, 8640, 33, 33, 135, 33, 8640, 8640, 33, 33, 135, 135, 135, 33, 8640, 33, 8640, 135, 33, 8640, 8640, 135, 135, 33, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 33, 8640, 33, 33, 8640, 135, 8640, 8640, 135, 8640, 33, 135, 8640, 33, 8640, 135, 33, 135, 135, 8640, 8640, 33, 33, 8640, 33, 33, 33, 135, 33]
Prompts retrieved: 378711 . Total input tokens: 84358862 . Total output tokens: 74555200
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 6.043240113183856,
    "estimated_duration": 3600.0864969437102,
    "input_throughput": 5553.354069957113,
    "output_throughput": 4887.33479457705,
    "total_throughput": 10440.688864534164,
    "itl": 89.74526652363822,
    "ttft": 1336866.9099031931,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1045,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.670437593702242,
    "arrivals": 125984,
    "finished_requests": 80998,
    "scheduler_time": 124.64086637822135
}
#Debug simulation 
Total elapsed time: 6.043352527078241. Arrivals time: 0.2542958427220583 Scheduler time: 5.619079181924462 Scheduler overhead time: 0.0578817967325449 Adapter cache time: 0.02404822316020727 Engine time: 0.06052183313295245 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-8/adapters_128_slots_64_rate_0.8-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-8/adapters_128_slots_64_rate_0.8-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [42 43 43]
Adapter prompts. [8640, 66, 8640, 8640, 33, 33, 8640, 33, 66, 66, 66, 33, 8640, 66, 33, 8640, 66, 33, 33, 33, 33, 66, 66, 8640, 66, 33, 66, 66, 66, 66, 8640, 66, 33, 66, 33, 8640, 8640, 33, 66, 66, 33, 66, 33, 66, 66, 8640, 8640, 8640, 8640, 66, 66, 33, 66, 8640, 8640, 66, 33, 33, 33, 8640, 66, 66, 66, 66, 8640, 66, 8640, 33, 33, 66, 33, 8640, 8640, 33, 33, 66, 66, 66, 33, 8640, 33, 8640, 66, 33, 8640, 8640, 66, 66, 33, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 33, 8640, 33, 33, 8640, 66, 8640, 8640, 66, 8640, 33, 66, 8640, 33, 8640, 66, 33, 66, 66, 8640, 8640, 33, 33, 8640, 33, 33, 33, 66, 33]
Prompts retrieved: 375744 . Total input tokens: 83711741 . Total output tokens: 73955864
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 6.522004427853972,
    "estimated_duration": 3600.084937095119,
    "input_throughput": 6207.506875666125,
    "output_throughput": 5370.629953970209,
    "total_throughput": 11578.136829636333,
    "itl": 107.21997533810926,
    "ttft": 1175736.604647957,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 808,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.342826497815654,
    "arrivals": 125093,
    "finished_requests": 90127,
    "scheduler_time": 116.75178325664308
}
#Debug simulation 
Total elapsed time: 6.522116833832115. Arrivals time: 0.2675760453566909 Scheduler time: 6.109724411740899 Scheduler overhead time: 0.05006055161356926 Adapter cache time: 0.01861522626131773 Engine time: 0.05244285240769386 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-16/adapters_128_slots_64_rate_0.8-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-16/adapters_128_slots_64_rate_0.8-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [42 43 43]
Adapter prompts. [8640, 66, 8640, 8640, 33, 33, 8640, 33, 66, 66, 66, 33, 8640, 66, 33, 8640, 66, 33, 33, 33, 33, 66, 66, 8640, 66, 33, 66, 66, 66, 66, 8640, 66, 33, 66, 33, 8640, 8640, 33, 66, 66, 33, 66, 33, 66, 66, 8640, 8640, 8640, 8640, 66, 66, 33, 66, 8640, 8640, 66, 33, 33, 33, 8640, 66, 66, 66, 66, 8640, 66, 8640, 33, 33, 66, 33, 8640, 8640, 33, 33, 66, 66, 66, 33, 8640, 33, 8640, 66, 33, 8640, 8640, 66, 66, 33, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 33, 8640, 33, 33, 8640, 66, 8640, 8640, 66, 8640, 33, 66, 8640, 33, 8640, 66, 33, 66, 66, 8640, 8640, 33, 33, 8640, 33, 33, 33, 66, 33]
Prompts retrieved: 375744 . Total input tokens: 83711741 . Total output tokens: 73955864
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 6.400203224737197,
    "estimated_duration": 3600.091837979248,
    "input_throughput": 6063.8100310945,
    "output_throughput": 5246.916981596425,
    "total_throughput": 11310.727012690924,
    "itl": 99.80216935339638,
    "ttft": 1212465.6359201635,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 785,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.720758855710745,
    "arrivals": 125093,
    "finished_requests": 88040,
    "scheduler_time": 119.58749967192271
}
#Debug simulation 
Total elapsed time: 6.400314399972558. Arrivals time: 0.2681012200191617 Scheduler time: 5.978826173115522 Scheduler overhead time: 0.05321859149262309 Adapter cache time: 0.01926035899668932 Engine time: 0.05574643379077315 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-32/adapters_128_slots_64_rate_0.8-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-32/adapters_128_slots_64_rate_0.8-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [42 43 43]
Adapter prompts. [8640, 66, 8640, 8640, 33, 33, 8640, 33, 66, 66, 66, 33, 8640, 66, 33, 8640, 66, 33, 33, 33, 33, 66, 66, 8640, 66, 33, 66, 66, 66, 66, 8640, 66, 33, 66, 33, 8640, 8640, 33, 66, 66, 33, 66, 33, 66, 66, 8640, 8640, 8640, 8640, 66, 66, 33, 66, 8640, 8640, 66, 33, 33, 33, 8640, 66, 66, 66, 66, 8640, 66, 8640, 33, 33, 66, 33, 8640, 8640, 33, 33, 66, 66, 66, 33, 8640, 33, 8640, 66, 33, 8640, 8640, 66, 66, 33, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 33, 8640, 33, 33, 8640, 66, 8640, 8640, 66, 8640, 33, 66, 8640, 33, 8640, 66, 33, 66, 66, 8640, 8640, 33, 33, 8640, 33, 33, 33, 66, 33]
Prompts retrieved: 375744 . Total input tokens: 83711741 . Total output tokens: 73955864
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 6.131551935337484,
    "estimated_duration": 3600.0290962670274,
    "input_throughput": 5772.943341360835,
    "output_throughput": 4994.774075199935,
    "total_throughput": 10767.71741656077,
    "itl": 88.02948826622392,
    "ttft": 1285237.6424897918,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 742,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.549865587060369,
    "arrivals": 125093,
    "finished_requests": 83809,
    "scheduler_time": 125.02886334343246
}
#Debug simulation 
Total elapsed time: 6.131667050067335. Arrivals time: 0.2579062501899898 Scheduler time: 5.7059371983632445 Scheduler overhead time: 0.058702930342406034 Adapter cache time: 0.01968122087419033 Engine time: 0.06168989883735776 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.00625-0.003125_size_8-16-16/adapters_128_slots_64_rate_0.8-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.00625-0.003125_size_8-16-16/adapters_128_slots_64_rate_0.8-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [42 43 43]
Adapter prompts. [8640, 66, 8640, 8640, 33, 33, 8640, 33, 66, 66, 66, 33, 8640, 66, 33, 8640, 66, 33, 33, 33, 33, 66, 66, 8640, 66, 33, 66, 66, 66, 66, 8640, 66, 33, 66, 33, 8640, 8640, 33, 66, 66, 33, 66, 33, 66, 66, 8640, 8640, 8640, 8640, 66, 66, 33, 66, 8640, 8640, 66, 33, 33, 33, 8640, 66, 66, 66, 66, 8640, 66, 8640, 33, 33, 66, 33, 8640, 8640, 33, 33, 66, 66, 66, 33, 8640, 33, 8640, 66, 33, 8640, 8640, 66, 66, 33, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 33, 8640, 33, 33, 8640, 66, 8640, 8640, 66, 8640, 33, 66, 8640, 33, 8640, 66, 33, 66, 66, 8640, 8640, 33, 33, 8640, 33, 33, 33, 66, 33]
Prompts retrieved: 375744 . Total input tokens: 83711741 . Total output tokens: 73955864
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 6.416529558133334,
    "estimated_duration": 3600.055261900738,
    "input_throughput": 6064.689959362628,
    "output_throughput": 5247.78888811427,
    "total_throughput": 11312.478847476897,
    "itl": 99.7895176105232,
    "ttft": 1212275.105267932,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 784,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.324284841269245,
    "arrivals": 125093,
    "finished_requests": 88053,
    "scheduler_time": 119.59349035064618
}
#Debug simulation 
Total elapsed time: 6.41664162883535. Arrivals time: 0.2717522457242012 Scheduler time: 5.991196823306382 Scheduler overhead time: 0.05339048849418759 Adapter cache time: 0.019236853811889887 Engine time: 0.05580993974581361 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.00625-0.003125_size_8-16-32/adapters_128_slots_64_rate_0.8-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.00625-0.003125_size_8-16-32/adapters_128_slots_64_rate_0.8-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [42 43 43]
Adapter prompts. [8640, 66, 8640, 8640, 33, 33, 8640, 33, 66, 66, 66, 33, 8640, 66, 33, 8640, 66, 33, 33, 33, 33, 66, 66, 8640, 66, 33, 66, 66, 66, 66, 8640, 66, 33, 66, 33, 8640, 8640, 33, 66, 66, 33, 66, 33, 66, 66, 8640, 8640, 8640, 8640, 66, 66, 33, 66, 8640, 8640, 66, 33, 33, 33, 8640, 66, 66, 66, 66, 8640, 66, 8640, 33, 33, 66, 33, 8640, 8640, 33, 33, 66, 66, 66, 33, 8640, 33, 8640, 66, 33, 8640, 8640, 66, 66, 33, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 33, 8640, 33, 33, 8640, 66, 8640, 8640, 66, 8640, 33, 66, 8640, 33, 8640, 66, 33, 66, 66, 8640, 8640, 33, 33, 8640, 33, 33, 33, 66, 33]
Prompts retrieved: 375744 . Total input tokens: 83711741 . Total output tokens: 73955864
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 6.1235152538865805,
    "estimated_duration": 3600.0836253045895,
    "input_throughput": 5772.955343014183,
    "output_throughput": 4994.822029579557,
    "total_throughput": 10767.77737259374,
    "itl": 88.02853182311414,
    "ttft": 1285171.4978160567,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 742,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.494565300904244,
    "arrivals": 125093,
    "finished_requests": 83811,
    "scheduler_time": 125.03230108512518
}
#Debug simulation 
Total elapsed time: 6.1236469889990985. Arrivals time: 0.24905612180009484 Scheduler time: 5.706460929941386 Scheduler overhead time: 0.05873534828424454 Adapter cache time: 0.019778847228735685 Engine time: 0.06180704804137349 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.00625-0.003125_size_16-16-16/adapters_128_slots_64_rate_0.8-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.00625-0.003125_size_16-16-16/adapters_128_slots_64_rate_0.8-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [42 43 43]
Adapter prompts. [8640, 66, 8640, 8640, 33, 33, 8640, 33, 66, 66, 66, 33, 8640, 66, 33, 8640, 66, 33, 33, 33, 33, 66, 66, 8640, 66, 33, 66, 66, 66, 66, 8640, 66, 33, 66, 33, 8640, 8640, 33, 66, 66, 33, 66, 33, 66, 66, 8640, 8640, 8640, 8640, 66, 66, 33, 66, 8640, 8640, 66, 33, 33, 33, 8640, 66, 66, 66, 66, 8640, 66, 8640, 33, 33, 66, 33, 8640, 8640, 33, 33, 66, 66, 66, 33, 8640, 33, 8640, 66, 33, 8640, 8640, 66, 66, 33, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 33, 8640, 33, 33, 8640, 66, 8640, 8640, 66, 8640, 33, 66, 8640, 33, 8640, 66, 33, 66, 66, 8640, 8640, 33, 33, 8640, 33, 33, 33, 66, 33]
Prompts retrieved: 375744 . Total input tokens: 83711741 . Total output tokens: 73955864
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 6.375348962843418,
    "estimated_duration": 3600.0026916829593,
    "input_throughput": 6065.307409476501,
    "output_throughput": 5248.28218702452,
    "total_throughput": 11313.58959650102,
    "itl": 99.77929522797804,
    "ttft": 1212306.243477066,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 785,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.011377938347844,
    "arrivals": 125093,
    "finished_requests": 88062,
    "scheduler_time": 119.59401604525317
}
#Debug simulation 
Total elapsed time: 6.375474627129734. Arrivals time: 0.2632700065150857 Scheduler time: 5.959409422241151 Scheduler overhead time: 0.05291218310594559 Adapter cache time: 0.01925902348011732 Engine time: 0.05547550227493048 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.00625-0.003125_size_16-16-32/adapters_128_slots_64_rate_0.8-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.00625-0.003125_size_16-16-32/adapters_128_slots_64_rate_0.8-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [42 43 43]
Adapter prompts. [8640, 66, 8640, 8640, 33, 33, 8640, 33, 66, 66, 66, 33, 8640, 66, 33, 8640, 66, 33, 33, 33, 33, 66, 66, 8640, 66, 33, 66, 66, 66, 66, 8640, 66, 33, 66, 33, 8640, 8640, 33, 66, 66, 33, 66, 33, 66, 66, 8640, 8640, 8640, 8640, 66, 66, 33, 66, 8640, 8640, 66, 33, 33, 33, 8640, 66, 66, 66, 66, 8640, 66, 8640, 33, 33, 66, 33, 8640, 8640, 33, 33, 66, 66, 66, 33, 8640, 33, 8640, 66, 33, 8640, 8640, 66, 66, 33, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 33, 8640, 33, 33, 8640, 66, 8640, 8640, 66, 8640, 33, 66, 8640, 33, 8640, 66, 33, 66, 66, 8640, 8640, 33, 33, 8640, 33, 33, 33, 66, 33]
Prompts retrieved: 375744 . Total input tokens: 83711741 . Total output tokens: 73955864
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 6.130612867884338,
    "estimated_duration": 3600.0900575892415,
    "input_throughput": 5772.98780517654,
    "output_throughput": 4994.843104575379,
    "total_throughput": 10767.83090975192,
    "itl": 88.02741388497323,
    "ttft": 1285290.452992808,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 742,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.44982799075547,
    "arrivals": 125093,
    "finished_requests": 83812,
    "scheduler_time": 125.03303709078602
}
#Debug simulation 
Total elapsed time: 6.130759572144598. Arrivals time: 0.2610157276503742 Scheduler time: 5.701925363391638 Scheduler overhead time: 0.05876303790137172 Adapter cache time: 0.019698153715580702 Engine time: 0.06152637768536806 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.05_size_8-8-8/adapters_128_slots_64_rate_0.4-0.1-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.05_size_8-8-8/adapters_128_slots_64_rate_0.4-0.1-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [42 43 43]
Adapter prompts. [4320, 1080, 4320, 4320, 540, 540, 4320, 540, 1080, 1080, 1080, 540, 4320, 1080, 540, 4320, 1080, 540, 540, 540, 540, 1080, 1080, 4320, 1080, 540, 1080, 1080, 1080, 1080, 4320, 1080, 540, 1080, 540, 4320, 4320, 540, 1080, 1080, 540, 1080, 540, 1080, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 540, 1080, 4320, 4320, 1080, 540, 540, 540, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 540, 540, 1080, 540, 4320, 4320, 540, 540, 1080, 1080, 1080, 540, 4320, 540, 4320, 1080, 540, 4320, 4320, 1080, 1080, 540, 540, 540, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 540, 4320, 540, 540, 4320, 1080, 4320, 4320, 1080, 4320, 540, 1080, 4320, 540, 4320, 1080, 540, 1080, 1080, 4320, 4320, 540, 540, 4320, 540, 540, 540, 1080, 540]
Prompts retrieved: 254880 . Total input tokens: 56758504 . Total output tokens: 50230360
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 13.84723671991378,
    "estimated_duration": 3600.0918508295854,
    "input_throughput": 5601.158202492351,
    "output_throughput": 4898.081974196471,
    "total_throughput": 10499.240176688822,
    "itl": 111.74640152172628,
    "ttft": 213014.13600085024,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 654,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.324515506895331,
    "arrivals": 85226,
    "finished_requests": 81754,
    "scheduler_time": 70.56447991717562
}
#Debug simulation 
Total elapsed time: 13.84738213289529. Arrivals time: 0.21768009988591075 Scheduler time: 13.484329308383167 Scheduler overhead time: 0.052878689020872116 Adapter cache time: 0.015834393445402384 Engine time: 0.05297699756920338 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.05_size_8-8-16/adapters_128_slots_64_rate_0.4-0.1-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.05_size_8-8-16/adapters_128_slots_64_rate_0.4-0.1-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [42 43 43]
Adapter prompts. [4320, 1080, 4320, 4320, 540, 540, 4320, 540, 1080, 1080, 1080, 540, 4320, 1080, 540, 4320, 1080, 540, 540, 540, 540, 1080, 1080, 4320, 1080, 540, 1080, 1080, 1080, 1080, 4320, 1080, 540, 1080, 540, 4320, 4320, 540, 1080, 1080, 540, 1080, 540, 1080, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 540, 1080, 4320, 4320, 1080, 540, 540, 540, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 540, 540, 1080, 540, 4320, 4320, 540, 540, 1080, 1080, 1080, 540, 4320, 540, 4320, 1080, 540, 4320, 4320, 1080, 1080, 540, 540, 540, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 540, 4320, 540, 540, 4320, 1080, 4320, 4320, 1080, 4320, 540, 1080, 4320, 540, 4320, 1080, 540, 1080, 1080, 4320, 4320, 540, 540, 4320, 540, 540, 540, 1080, 540]
Prompts retrieved: 254880 . Total input tokens: 56758504 . Total output tokens: 50230360
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 11.649722909089178,
    "estimated_duration": 3600.0066666343128,
    "input_throughput": 5499.919259458207,
    "output_throughput": 4802.186940437713,
    "total_throughput": 10302.106199895921,
    "itl": 106.21586406803502,
    "ttft": 305607.73377074307,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 623,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.546353345033719,
    "arrivals": 85226,
    "finished_requests": 80181,
    "scheduler_time": 71.00333031939991
}
#Debug simulation 
Total elapsed time: 11.649901695083827. Arrivals time: 0.21722769271582365 Scheduler time: 11.281967668794096 Scheduler overhead time: 0.05475654732435942 Adapter cache time: 0.016255007591098547 Engine time: 0.0548519492149353 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.05_size_8-8-32/adapters_128_slots_64_rate_0.4-0.1-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.05_size_8-8-32/adapters_128_slots_64_rate_0.4-0.1-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [42 43 43]
Adapter prompts. [4320, 1080, 4320, 4320, 540, 540, 4320, 540, 1080, 1080, 1080, 540, 4320, 1080, 540, 4320, 1080, 540, 540, 540, 540, 1080, 1080, 4320, 1080, 540, 1080, 1080, 1080, 1080, 4320, 1080, 540, 1080, 540, 4320, 4320, 540, 1080, 1080, 540, 1080, 540, 1080, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 540, 1080, 4320, 4320, 1080, 540, 540, 540, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 540, 540, 1080, 540, 4320, 4320, 540, 540, 1080, 1080, 1080, 540, 4320, 540, 4320, 1080, 540, 4320, 4320, 1080, 1080, 540, 540, 540, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 540, 4320, 540, 540, 4320, 1080, 4320, 4320, 1080, 4320, 540, 1080, 4320, 540, 4320, 1080, 540, 1080, 1080, 4320, 4320, 540, 540, 4320, 540, 540, 540, 1080, 540]
Prompts retrieved: 254880 . Total input tokens: 56758504 . Total output tokens: 50230360
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 9.195709598250687,
    "estimated_duration": 3600.045460100892,
    "input_throughput": 5239.7743887021215,
    "output_throughput": 4574.24334845441,
    "total_throughput": 9814.017737156531,
    "itl": 95.41859447595202,
    "ttft": 528454.5605707623,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 828,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.205105350120016,
    "arrivals": 85226,
    "finished_requests": 76334,
    "scheduler_time": 73.22917072659536
}
#Debug simulation 
Total elapsed time: 9.195860903244466. Arrivals time: 0.2162337531335652 Scheduler time: 8.815578746143728 Scheduler overhead time: 0.05804729973897338 Adapter cache time: 0.01960923708975315 Engine time: 0.059496994595974684 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.05_size_8-16-16/adapters_128_slots_64_rate_0.4-0.1-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.05_size_8-16-16/adapters_128_slots_64_rate_0.4-0.1-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [42 43 43]
Adapter prompts. [4320, 1080, 4320, 4320, 540, 540, 4320, 540, 1080, 1080, 1080, 540, 4320, 1080, 540, 4320, 1080, 540, 540, 540, 540, 1080, 1080, 4320, 1080, 540, 1080, 1080, 1080, 1080, 4320, 1080, 540, 1080, 540, 4320, 4320, 540, 1080, 1080, 540, 1080, 540, 1080, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 540, 1080, 4320, 4320, 1080, 540, 540, 540, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 540, 540, 1080, 540, 4320, 4320, 540, 540, 1080, 1080, 1080, 540, 4320, 540, 4320, 1080, 540, 4320, 4320, 1080, 1080, 540, 540, 540, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 540, 4320, 540, 540, 4320, 1080, 4320, 4320, 1080, 4320, 540, 1080, 4320, 540, 4320, 1080, 540, 1080, 1080, 4320, 4320, 540, 540, 4320, 540, 540, 540, 1080, 540]
Prompts retrieved: 254880 . Total input tokens: 56758504 . Total output tokens: 50230360
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 11.67825895221904,
    "estimated_duration": 3600.1252232082297,
    "input_throughput": 5499.559813187872,
    "output_throughput": 4802.854325325757,
    "total_throughput": 10302.414138513628,
    "itl": 106.19547439378371,
    "ttft": 304801.5223625395,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 604,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.100215139407656,
    "arrivals": 85226,
    "finished_requests": 80187,
    "scheduler_time": 71.0174809070665
}
#Debug simulation 
Total elapsed time: 11.678396149072796. Arrivals time: 0.21629106998443604 Scheduler time: 11.31167014176026 Scheduler overhead time: 0.05434193182736635 Adapter cache time: 0.016096722334623337 Engine time: 0.05513862334191799 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.05_size_8-16-32/adapters_128_slots_64_rate_0.4-0.1-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.05_size_8-16-32/adapters_128_slots_64_rate_0.4-0.1-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [42 43 43]
Adapter prompts. [4320, 1080, 4320, 4320, 540, 540, 4320, 540, 1080, 1080, 1080, 540, 4320, 1080, 540, 4320, 1080, 540, 540, 540, 540, 1080, 1080, 4320, 1080, 540, 1080, 1080, 1080, 1080, 4320, 1080, 540, 1080, 540, 4320, 4320, 540, 1080, 1080, 540, 1080, 540, 1080, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 540, 1080, 4320, 4320, 1080, 540, 540, 540, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 540, 540, 1080, 540, 4320, 4320, 540, 540, 1080, 1080, 1080, 540, 4320, 540, 4320, 1080, 540, 4320, 4320, 1080, 1080, 540, 540, 540, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 540, 4320, 540, 540, 4320, 1080, 4320, 4320, 1080, 4320, 540, 1080, 4320, 540, 4320, 1080, 540, 1080, 1080, 4320, 4320, 540, 540, 4320, 540, 540, 540, 1080, 540]
Prompts retrieved: 254880 . Total input tokens: 56758504 . Total output tokens: 50230360
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 9.469215244986117,
    "estimated_duration": 3600.0517166567297,
    "input_throughput": 5237.914753489087,
    "output_throughput": 4574.369841356989,
    "total_throughput": 9812.284594846076,
    "itl": 95.1831835569955,
    "ttft": 527264.4226600121,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 853,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.336431737467671,
    "arrivals": 85226,
    "finished_requests": 76346,
    "scheduler_time": 73.22350945011422
}
#Debug simulation 
Total elapsed time: 9.469334410969168. Arrivals time: 0.21529342280700803 Scheduler time: 9.089464138261974 Scheduler overhead time: 0.05846370384097099 Adapter cache time: 0.01957053504884243 Engine time: 0.059609634801745415 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.05_size_16-16-16/adapters_128_slots_64_rate_0.4-0.1-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.05_size_16-16-16/adapters_128_slots_64_rate_0.4-0.1-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [42 43 43]
Adapter prompts. [4320, 1080, 4320, 4320, 540, 540, 4320, 540, 1080, 1080, 1080, 540, 4320, 1080, 540, 4320, 1080, 540, 540, 540, 540, 1080, 1080, 4320, 1080, 540, 1080, 1080, 1080, 1080, 4320, 1080, 540, 1080, 540, 4320, 4320, 540, 1080, 1080, 540, 1080, 540, 1080, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 540, 1080, 4320, 4320, 1080, 540, 540, 540, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 540, 540, 1080, 540, 4320, 4320, 540, 540, 1080, 1080, 1080, 540, 4320, 540, 4320, 1080, 540, 4320, 4320, 1080, 1080, 540, 540, 540, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 540, 4320, 540, 540, 4320, 1080, 4320, 4320, 1080, 4320, 540, 1080, 4320, 540, 4320, 1080, 540, 1080, 1080, 4320, 4320, 540, 540, 4320, 540, 540, 540, 1080, 540]
Prompts retrieved: 254880 . Total input tokens: 56758504 . Total output tokens: 50230360
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 11.57999103423208,
    "estimated_duration": 3600.115057513898,
    "input_throughput": 5497.759011532256,
    "output_throughput": 4802.197630855374,
    "total_throughput": 10299.95664238763,
    "itl": 106.17379979295798,
    "ttft": 306915.5401958508,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 629,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.015486271618847,
    "arrivals": 85226,
    "finished_requests": 80151,
    "scheduler_time": 70.98778923701789
}
#Debug simulation 
Total elapsed time: 11.580113787204027. Arrivals time: 0.2160878898575902 Scheduler time: 11.21469743270427 Scheduler overhead time: 0.05387264583259821 Adapter cache time: 0.016330423299223185 Engine time: 0.054379676934331656 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.05_size_16-16-32/adapters_128_slots_64_rate_0.4-0.1-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.05_size_16-16-32/adapters_128_slots_64_rate_0.4-0.1-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [42 43 43]
Adapter prompts. [4320, 1080, 4320, 4320, 540, 540, 4320, 540, 1080, 1080, 1080, 540, 4320, 1080, 540, 4320, 1080, 540, 540, 540, 540, 1080, 1080, 4320, 1080, 540, 1080, 1080, 1080, 1080, 4320, 1080, 540, 1080, 540, 4320, 4320, 540, 1080, 1080, 540, 1080, 540, 1080, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 540, 1080, 4320, 4320, 1080, 540, 540, 540, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 540, 540, 1080, 540, 4320, 4320, 540, 540, 1080, 1080, 1080, 540, 4320, 540, 4320, 1080, 540, 4320, 4320, 1080, 1080, 540, 540, 540, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 540, 4320, 540, 540, 4320, 1080, 4320, 4320, 1080, 4320, 540, 1080, 4320, 540, 4320, 1080, 540, 1080, 1080, 4320, 4320, 540, 540, 4320, 540, 540, 540, 1080, 540]
Prompts retrieved: 254880 . Total input tokens: 56758504 . Total output tokens: 50230360
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 9.108175934292376,
    "estimated_duration": 3600.0281637139715,
    "input_throughput": 5238.350685719335,
    "output_throughput": 4574.496434775236,
    "total_throughput": 9812.84712049457,
    "itl": 95.42974245096744,
    "ttft": 528784.5873715818,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 928,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.823352490328274,
    "arrivals": 85226,
    "finished_requests": 76321,
    "scheduler_time": 73.22983067385528
}
#Debug simulation 
Total elapsed time: 9.108294543344527. Arrivals time: 0.2150259055197239 Scheduler time: 8.727858267724514 Scheduler overhead time: 0.05835771327838302 Adapter cache time: 0.020704634487628937 Engine time: 0.05948042077943683 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.025_size_8-8-8/adapters_128_slots_64_rate_0.4-0.1-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.025_size_8-8-8/adapters_128_slots_64_rate_0.4-0.1-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [42 43 43]
Adapter prompts. [4320, 1080, 4320, 4320, 270, 270, 4320, 270, 1080, 1080, 1080, 270, 4320, 1080, 270, 4320, 1080, 270, 270, 270, 270, 1080, 1080, 4320, 1080, 270, 1080, 1080, 1080, 1080, 4320, 1080, 270, 1080, 270, 4320, 4320, 270, 1080, 1080, 270, 1080, 270, 1080, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 270, 1080, 4320, 4320, 1080, 270, 270, 270, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 270, 270, 1080, 270, 4320, 4320, 270, 270, 1080, 1080, 1080, 270, 4320, 270, 4320, 1080, 270, 4320, 4320, 1080, 1080, 270, 270, 270, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 270, 4320, 270, 270, 4320, 1080, 4320, 4320, 1080, 4320, 270, 1080, 4320, 270, 4320, 1080, 270, 1080, 1080, 4320, 4320, 270, 270, 4320, 270, 270, 270, 1080, 270]
Prompts retrieved: 243540 . Total input tokens: 54255415 . Total output tokens: 47942623
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 12.322788924910128,
    "estimated_duration": 3600.038112477979,
    "input_throughput": 5538.989137610685,
    "output_throughput": 4769.590338637014,
    "total_throughput": 10308.579476247698,
    "itl": 104.24652437879328,
    "ttft": 92130.75549575093,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 688,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.549337413981636,
    "arrivals": 81441,
    "finished_requests": 80032,
    "scheduler_time": 65.74123334071209
}
#Debug simulation 
Total elapsed time: 12.322900132741779. Arrivals time: 0.20849445974454284 Scheduler time: 11.961950212717056 Scheduler overhead time: 0.05509117525070906 Adapter cache time: 0.016324210911989212 Engine time: 0.056455307174474 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.025_size_8-8-16/adapters_128_slots_64_rate_0.4-0.1-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.025_size_8-8-16/adapters_128_slots_64_rate_0.4-0.1-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [42 43 43]
Adapter prompts. [4320, 1080, 4320, 4320, 270, 270, 4320, 270, 1080, 1080, 1080, 270, 4320, 1080, 270, 4320, 1080, 270, 270, 270, 270, 1080, 1080, 4320, 1080, 270, 1080, 1080, 1080, 1080, 4320, 1080, 270, 1080, 270, 4320, 4320, 270, 1080, 1080, 270, 1080, 270, 1080, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 270, 1080, 4320, 4320, 1080, 270, 270, 270, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 270, 270, 1080, 270, 4320, 4320, 270, 270, 1080, 1080, 1080, 270, 4320, 270, 4320, 1080, 270, 4320, 4320, 1080, 1080, 270, 270, 270, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 270, 4320, 270, 270, 4320, 1080, 4320, 4320, 1080, 4320, 270, 1080, 4320, 270, 4320, 1080, 270, 1080, 1080, 4320, 4320, 270, 270, 4320, 270, 270, 270, 1080, 270]
Prompts retrieved: 243540 . Total input tokens: 54255415 . Total output tokens: 47942623
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 10.778603127691895,
    "estimated_duration": 3600.0524516373603,
    "input_throughput": 5535.305462268116,
    "output_throughput": 4767.98580870484,
    "total_throughput": 10303.291270972955,
    "itl": 103.93673276848484,
    "ttft": 98523.20312332734,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 697,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.082621659408329,
    "arrivals": 81441,
    "finished_requests": 79968,
    "scheduler_time": 65.94797719453697
}
#Debug simulation 
Total elapsed time: 10.778718987945467. Arrivals time: 0.20730009814724326 Scheduler time: 10.419963949825615 Scheduler overhead time: 0.05489481007680297 Adapter cache time: 0.016542706172913313 Engine time: 0.055248314049094915 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.025_size_8-8-32/adapters_128_slots_64_rate_0.4-0.1-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.025_size_8-8-32/adapters_128_slots_64_rate_0.4-0.1-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [42 43 43]
Adapter prompts. [4320, 1080, 4320, 4320, 270, 270, 4320, 270, 1080, 1080, 1080, 270, 4320, 1080, 270, 4320, 1080, 270, 270, 270, 270, 1080, 1080, 4320, 1080, 270, 1080, 1080, 1080, 1080, 4320, 1080, 270, 1080, 270, 4320, 4320, 270, 1080, 1080, 270, 1080, 270, 1080, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 270, 1080, 4320, 4320, 1080, 270, 270, 270, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 270, 270, 1080, 270, 4320, 4320, 270, 270, 1080, 1080, 1080, 270, 4320, 270, 4320, 1080, 270, 4320, 4320, 1080, 1080, 270, 270, 270, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 270, 4320, 270, 270, 4320, 1080, 4320, 4320, 1080, 4320, 270, 1080, 4320, 270, 4320, 1080, 270, 1080, 1080, 4320, 4320, 270, 270, 4320, 270, 270, 270, 1080, 270]
Prompts retrieved: 243540 . Total input tokens: 54255415 . Total output tokens: 47942623
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 8.556187527254224,
    "estimated_duration": 3600.0346707286835,
    "input_throughput": 5308.544152473884,
    "output_throughput": 4575.107327137545,
    "total_throughput": 9883.65147961143,
    "itl": 94.83898458327745,
    "ttft": 296798.9016337801,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 838,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.277322051883698,
    "arrivals": 81441,
    "finished_requests": 76767,
    "scheduler_time": 67.2154777474812
}
#Debug simulation 
Total elapsed time: 8.556297445204109. Arrivals time: 0.21358142606914043 Scheduler time: 8.177476140670478 Scheduler overhead time: 0.058940249029546976 Adapter cache time: 0.01950807124376297 Engine time: 0.059886247385293245 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.025_size_8-16-16/adapters_128_slots_64_rate_0.4-0.1-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.025_size_8-16-16/adapters_128_slots_64_rate_0.4-0.1-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [42 43 43]
Adapter prompts. [4320, 1080, 4320, 4320, 270, 270, 4320, 270, 1080, 1080, 1080, 270, 4320, 1080, 270, 4320, 1080, 270, 270, 270, 270, 1080, 1080, 4320, 1080, 270, 1080, 1080, 1080, 1080, 4320, 1080, 270, 1080, 270, 4320, 4320, 270, 1080, 1080, 270, 1080, 270, 1080, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 270, 1080, 4320, 4320, 1080, 270, 270, 270, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 270, 270, 1080, 270, 4320, 4320, 270, 270, 1080, 1080, 1080, 270, 4320, 270, 4320, 1080, 270, 4320, 4320, 1080, 1080, 270, 270, 270, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 270, 4320, 270, 270, 4320, 1080, 4320, 4320, 1080, 4320, 270, 1080, 4320, 270, 4320, 1080, 270, 1080, 1080, 4320, 4320, 270, 270, 4320, 270, 270, 270, 1080, 270]
Prompts retrieved: 243540 . Total input tokens: 54255415 . Total output tokens: 47942623
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 10.601312530227005,
    "estimated_duration": 3600.070118709171,
    "input_throughput": 5538.9821149233285,
    "output_throughput": 4769.398493315035,
    "total_throughput": 10308.380608238363,
    "itl": 103.97042235330646,
    "ttft": 96877.15170310574,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 700,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.743612411115309,
    "arrivals": 81441,
    "finished_requests": 80006,
    "scheduler_time": 65.94494954264458
}
#Debug simulation 
Total elapsed time: 10.60142099717632. Arrivals time: 0.20128428423777223 Scheduler time: 10.248361349105835 Scheduler overhead time: 0.05482584051787853 Adapter cache time: 0.016697087325155735 Engine time: 0.05542116146534681 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.025_size_8-16-32/adapters_128_slots_64_rate_0.4-0.1-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.025_size_8-16-32/adapters_128_slots_64_rate_0.4-0.1-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [42 43 43]
Adapter prompts. [4320, 1080, 4320, 4320, 270, 270, 4320, 270, 1080, 1080, 1080, 270, 4320, 1080, 270, 4320, 1080, 270, 270, 270, 270, 1080, 1080, 4320, 1080, 270, 1080, 1080, 1080, 1080, 4320, 1080, 270, 1080, 270, 4320, 4320, 270, 1080, 1080, 270, 1080, 270, 1080, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 270, 1080, 4320, 4320, 1080, 270, 270, 270, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 270, 270, 1080, 270, 4320, 4320, 270, 270, 1080, 1080, 1080, 270, 4320, 270, 4320, 1080, 270, 4320, 4320, 1080, 1080, 270, 270, 270, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 270, 4320, 270, 270, 4320, 1080, 4320, 4320, 1080, 4320, 270, 1080, 4320, 270, 4320, 1080, 270, 1080, 1080, 4320, 4320, 270, 270, 4320, 270, 270, 270, 1080, 270]
Prompts retrieved: 243540 . Total input tokens: 54255415 . Total output tokens: 47942623
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 8.430980198085308,
    "estimated_duration": 3600.00926971582,
    "input_throughput": 5311.742156016584,
    "output_throughput": 4574.840442369215,
    "total_throughput": 9886.5825983858,
    "itl": 94.8144957958794,
    "ttft": 296169.39561244036,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 865,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.415635202475848,
    "arrivals": 81441,
    "finished_requests": 76782,
    "scheduler_time": 67.19213617803042
}
#Debug simulation 
Total elapsed time: 8.431098752189428. Arrivals time: 0.2026030202396214 Scheduler time: 8.064206041395664 Scheduler overhead time: 0.0582203334197402 Adapter cache time: 0.019684936851263046 Engine time: 0.05951342126354575 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.025_size_16-16-16/adapters_128_slots_64_rate_0.4-0.1-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.025_size_16-16-16/adapters_128_slots_64_rate_0.4-0.1-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [42 43 43]
Adapter prompts. [4320, 1080, 4320, 4320, 270, 270, 4320, 270, 1080, 1080, 1080, 270, 4320, 1080, 270, 4320, 1080, 270, 270, 270, 270, 1080, 1080, 4320, 1080, 270, 1080, 1080, 1080, 1080, 4320, 1080, 270, 1080, 270, 4320, 4320, 270, 1080, 1080, 270, 1080, 270, 1080, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 270, 1080, 4320, 4320, 1080, 270, 270, 270, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 270, 270, 1080, 270, 4320, 4320, 270, 270, 1080, 1080, 1080, 270, 4320, 270, 4320, 1080, 270, 4320, 4320, 1080, 1080, 270, 270, 270, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 270, 4320, 270, 270, 4320, 1080, 4320, 4320, 1080, 4320, 270, 1080, 4320, 270, 4320, 1080, 270, 1080, 1080, 4320, 4320, 270, 270, 4320, 270, 270, 270, 1080, 270]
Prompts retrieved: 243540 . Total input tokens: 54255415 . Total output tokens: 47942623
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 10.732069785706699,
    "estimated_duration": 3600.048905820496,
    "input_throughput": 5534.325649795334,
    "output_throughput": 4766.09469728563,
    "total_throughput": 10300.420347080964,
    "itl": 103.79234876829489,
    "ttft": 99379.0991423548,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 696,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.44320897463707,
    "arrivals": 81441,
    "finished_requests": 79952,
    "scheduler_time": 65.90825088007675
}
#Debug simulation 
Total elapsed time: 10.732203106861562. Arrivals time: 0.20545340608805418 Scheduler time: 10.37494480330497 Scheduler overhead time: 0.054678461980074644 Adapter cache time: 0.016767989844083786 Engine time: 0.05549100460484624 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.025_size_16-16-32/adapters_128_slots_64_rate_0.4-0.1-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.025_size_16-16-32/adapters_128_slots_64_rate_0.4-0.1-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [42 43 43]
Adapter prompts. [4320, 1080, 4320, 4320, 270, 270, 4320, 270, 1080, 1080, 1080, 270, 4320, 1080, 270, 4320, 1080, 270, 270, 270, 270, 1080, 1080, 4320, 1080, 270, 1080, 1080, 1080, 1080, 4320, 1080, 270, 1080, 270, 4320, 4320, 270, 1080, 1080, 270, 1080, 270, 1080, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 270, 1080, 4320, 4320, 1080, 270, 270, 270, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 270, 270, 1080, 270, 4320, 4320, 270, 270, 1080, 1080, 1080, 270, 4320, 270, 4320, 1080, 270, 4320, 4320, 1080, 1080, 270, 270, 270, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 270, 4320, 270, 270, 4320, 1080, 4320, 4320, 1080, 4320, 270, 1080, 4320, 270, 4320, 1080, 270, 1080, 1080, 4320, 4320, 270, 270, 4320, 270, 270, 270, 1080, 270]
Prompts retrieved: 243540 . Total input tokens: 54255415 . Total output tokens: 47942623
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 8.51312030525878,
    "estimated_duration": 3600.0899761157116,
    "input_throughput": 5311.010315533696,
    "output_throughput": 4574.4851126661615,
    "total_throughput": 9885.495428199858,
    "itl": 94.8197011608044,
    "ttft": 295792.4205361114,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 860,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.319798942506336,
    "arrivals": 81441,
    "finished_requests": 76794,
    "scheduler_time": 67.20867603036358
}
#Debug simulation 
Total elapsed time: 8.513230263255537. Arrivals time: 0.20810108678415418 Scheduler time: 8.140904682222754 Scheduler overhead time: 0.05812687613070011 Adapter cache time: 0.019785559736192226 Engine time: 0.05955791752785444 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-8/adapters_128_slots_64_rate_0.4-0.1-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-8/adapters_128_slots_64_rate_0.4-0.1-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [42 43 43]
Adapter prompts. [4320, 1080, 4320, 4320, 135, 135, 4320, 135, 1080, 1080, 1080, 135, 4320, 1080, 135, 4320, 1080, 135, 135, 135, 135, 1080, 1080, 4320, 1080, 135, 1080, 1080, 1080, 1080, 4320, 1080, 135, 1080, 135, 4320, 4320, 135, 1080, 1080, 135, 1080, 135, 1080, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 135, 1080, 4320, 4320, 1080, 135, 135, 135, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 135, 135, 1080, 135, 4320, 4320, 135, 135, 1080, 1080, 1080, 135, 4320, 135, 4320, 1080, 135, 4320, 4320, 1080, 1080, 135, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 135, 4320, 135, 135, 4320, 1080, 4320, 4320, 1080, 4320, 135, 1080, 4320, 135, 4320, 1080, 135, 1080, 1080, 4320, 4320, 135, 135, 4320, 135, 135, 135, 1080, 135]
Prompts retrieved: 237870 . Total input tokens: 53018804 . Total output tokens: 46839171
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 10.568368985783309,
    "estimated_duration": 3600.0598864577987,
    "input_throughput": 5419.942894116278,
    "output_throughput": 4711.966060289828,
    "total_throughput": 10131.908954406106,
    "itl": 101.25063797010786,
    "ttft": 70570.12247279275,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 756,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.998981228154246,
    "arrivals": 79515,
    "finished_requests": 78441,
    "scheduler_time": 64.10615003050891
}
#Debug simulation 
Total elapsed time: 10.568483557086438. Arrivals time: 0.2025654804892838 Scheduler time: 10.210893619805574 Scheduler overhead time: 0.05597404856234789 Adapter cache time: 0.017189913894981146 Engine time: 0.056868783198297024 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-16/adapters_128_slots_64_rate_0.4-0.1-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-16/adapters_128_slots_64_rate_0.4-0.1-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [42 43 43]
Adapter prompts. [4320, 1080, 4320, 4320, 135, 135, 4320, 135, 1080, 1080, 1080, 135, 4320, 1080, 135, 4320, 1080, 135, 135, 135, 135, 1080, 1080, 4320, 1080, 135, 1080, 1080, 1080, 1080, 4320, 1080, 135, 1080, 135, 4320, 4320, 135, 1080, 1080, 135, 1080, 135, 1080, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 135, 1080, 4320, 4320, 1080, 135, 135, 135, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 135, 135, 1080, 135, 4320, 4320, 135, 135, 1080, 1080, 1080, 135, 4320, 135, 4320, 1080, 135, 4320, 4320, 1080, 1080, 135, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 135, 4320, 135, 135, 4320, 1080, 4320, 4320, 1080, 4320, 135, 1080, 4320, 135, 4320, 1080, 135, 1080, 1080, 4320, 4320, 135, 135, 4320, 135, 135, 135, 1080, 135]
Prompts retrieved: 237870 . Total input tokens: 53018804 . Total output tokens: 46839171
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 10.08389350399375,
    "estimated_duration": 3600.0835007594724,
    "input_throughput": 5417.268792761539,
    "output_throughput": 4707.663029600469,
    "total_throughput": 10124.931822362007,
    "itl": 100.94577964991895,
    "ttft": 73603.86982469182,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 769,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.61583967871499,
    "arrivals": 79515,
    "finished_requests": 78392,
    "scheduler_time": 64.1359468536405
}
#Debug simulation 
Total elapsed time: 10.084039298817515. Arrivals time: 0.20385984145104885 Scheduler time: 9.725248501170427 Scheduler overhead time: 0.05555363232269883 Adapter cache time: 0.01753542060032487 Engine time: 0.05664281873032451 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-32/adapters_128_slots_64_rate_0.4-0.1-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-32/adapters_128_slots_64_rate_0.4-0.1-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [42 43 43]
Adapter prompts. [4320, 1080, 4320, 4320, 135, 135, 4320, 135, 1080, 1080, 1080, 135, 4320, 1080, 135, 4320, 1080, 135, 135, 135, 135, 1080, 1080, 4320, 1080, 135, 1080, 1080, 1080, 1080, 4320, 1080, 135, 1080, 135, 4320, 4320, 135, 1080, 1080, 135, 1080, 135, 1080, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 135, 1080, 4320, 4320, 1080, 135, 135, 135, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 135, 135, 1080, 135, 4320, 4320, 135, 135, 1080, 1080, 1080, 135, 4320, 135, 4320, 1080, 135, 4320, 4320, 1080, 1080, 135, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 135, 4320, 135, 135, 4320, 1080, 4320, 4320, 1080, 4320, 135, 1080, 4320, 135, 4320, 1080, 135, 1080, 1080, 4320, 4320, 135, 135, 4320, 135, 135, 135, 1080, 135]
Prompts retrieved: 237870 . Total input tokens: 53018804 . Total output tokens: 46839171
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 7.908462116960436,
    "estimated_duration": 3600.072285513065,
    "input_throughput": 5246.219103989005,
    "output_throughput": 4570.840998448136,
    "total_throughput": 9817.06010243714,
    "itl": 94.6737192921944,
    "ttft": 224795.55314874044,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 874,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.545846210205949,
    "arrivals": 79515,
    "finished_requests": 76018,
    "scheduler_time": 65.13293570500737
}
#Debug simulation 
Total elapsed time: 7.908599697984755. Arrivals time: 0.19995544804260135 Scheduler time: 7.544067167211324 Scheduler overhead time: 0.05807416047900915 Adapter cache time: 0.020476183388382196 Engine time: 0.05927953450009227 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.0125_size_8-16-16/adapters_128_slots_64_rate_0.4-0.1-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.0125_size_8-16-16/adapters_128_slots_64_rate_0.4-0.1-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [42 43 43]
Adapter prompts. [4320, 1080, 4320, 4320, 135, 135, 4320, 135, 1080, 1080, 1080, 135, 4320, 1080, 135, 4320, 1080, 135, 135, 135, 135, 1080, 1080, 4320, 1080, 135, 1080, 1080, 1080, 1080, 4320, 1080, 135, 1080, 135, 4320, 4320, 135, 1080, 1080, 135, 1080, 135, 1080, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 135, 1080, 4320, 4320, 1080, 135, 135, 135, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 135, 135, 1080, 135, 4320, 4320, 135, 135, 1080, 1080, 1080, 135, 4320, 135, 4320, 1080, 135, 4320, 4320, 1080, 1080, 135, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 135, 4320, 135, 135, 4320, 1080, 4320, 4320, 1080, 4320, 135, 1080, 4320, 135, 4320, 1080, 135, 1080, 1080, 4320, 4320, 135, 135, 4320, 135, 135, 135, 1080, 135]
Prompts retrieved: 237870 . Total input tokens: 53018804 . Total output tokens: 46839171
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 9.97672871593386,
    "estimated_duration": 3600.0820369806665,
    "input_throughput": 5415.070767762255,
    "output_throughput": 4705.21111074641,
    "total_throughput": 10120.281878508664,
    "itl": 100.8462492799093,
    "ttft": 74213.25991173205,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 786,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.337052683150384,
    "arrivals": 79515,
    "finished_requests": 78360,
    "scheduler_time": 64.06196435035271
}
#Debug simulation 
Total elapsed time: 9.976845039054751. Arrivals time: 0.20019039791077375 Scheduler time: 9.620158143341541 Scheduler overhead time: 0.055751155596226454 Adapter cache time: 0.018846754916012287 Engine time: 0.056708123069256544 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.0125_size_8-16-32/adapters_128_slots_64_rate_0.4-0.1-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.0125_size_8-16-32/adapters_128_slots_64_rate_0.4-0.1-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [42 43 43]
Adapter prompts. [4320, 1080, 4320, 4320, 135, 135, 4320, 135, 1080, 1080, 1080, 135, 4320, 1080, 135, 4320, 1080, 135, 135, 135, 135, 1080, 1080, 4320, 1080, 135, 1080, 1080, 1080, 1080, 4320, 1080, 135, 1080, 135, 4320, 4320, 135, 1080, 1080, 135, 1080, 135, 1080, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 135, 1080, 4320, 4320, 1080, 135, 135, 135, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 135, 135, 1080, 135, 4320, 4320, 135, 135, 1080, 1080, 1080, 135, 4320, 135, 4320, 1080, 135, 4320, 4320, 1080, 1080, 135, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 135, 4320, 135, 135, 4320, 1080, 4320, 4320, 1080, 4320, 135, 1080, 4320, 135, 4320, 1080, 135, 1080, 1080, 4320, 4320, 135, 135, 4320, 135, 135, 135, 1080, 135]
Prompts retrieved: 237870 . Total input tokens: 53018804 . Total output tokens: 46839171
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 7.9148540501482785,
    "estimated_duration": 3600.0010558893873,
    "input_throughput": 5249.460960319412,
    "output_throughput": 4571.1881037030535,
    "total_throughput": 9820.649064022466,
    "itl": 94.66028847798316,
    "ttft": 224005.84291205753,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 875,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.493392557776556,
    "arrivals": 79515,
    "finished_requests": 76040,
    "scheduler_time": 65.12963150998817
}
#Debug simulation 
Total elapsed time: 7.914966925047338. Arrivals time: 0.19754284992814064 Scheduler time: 7.553379262331873 Scheduler overhead time: 0.0580579056404531 Adapter cache time: 0.01967589044943452 Engine time: 0.059595405124127865 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.0125_size_16-16-16/adapters_128_slots_64_rate_0.4-0.1-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.0125_size_16-16-16/adapters_128_slots_64_rate_0.4-0.1-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [42 43 43]
Adapter prompts. [4320, 1080, 4320, 4320, 135, 135, 4320, 135, 1080, 1080, 1080, 135, 4320, 1080, 135, 4320, 1080, 135, 135, 135, 135, 1080, 1080, 4320, 1080, 135, 1080, 1080, 1080, 1080, 4320, 1080, 135, 1080, 135, 4320, 4320, 135, 1080, 1080, 135, 1080, 135, 1080, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 135, 1080, 4320, 4320, 1080, 135, 135, 135, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 135, 135, 1080, 135, 4320, 4320, 135, 135, 1080, 1080, 1080, 135, 4320, 135, 4320, 1080, 135, 4320, 4320, 1080, 1080, 135, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 135, 4320, 135, 135, 4320, 1080, 4320, 4320, 1080, 4320, 135, 1080, 4320, 135, 4320, 1080, 135, 1080, 1080, 4320, 4320, 135, 135, 4320, 135, 135, 135, 1080, 135]
Prompts retrieved: 237870 . Total input tokens: 53018804 . Total output tokens: 46839171
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 9.990225597750396,
    "estimated_duration": 3600.017340491343,
    "input_throughput": 5415.131138601491,
    "output_throughput": 4705.29511329745,
    "total_throughput": 10120.426251898942,
    "itl": 100.82350544505036,
    "ttft": 74338.97256180084,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 786,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.017761859288415,
    "arrivals": 79515,
    "finished_requests": 78359,
    "scheduler_time": 64.05861469408273
}
#Debug simulation 
Total elapsed time: 9.990375326946378. Arrivals time: 0.19987770589068532 Scheduler time: 9.634692520368844 Scheduler overhead time: 0.055528593715280294 Adapter cache time: 0.018005756195634604 Engine time: 0.056911107152700424 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.0125_size_16-16-32/adapters_128_slots_64_rate_0.4-0.1-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.0125_size_16-16-32/adapters_128_slots_64_rate_0.4-0.1-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [42 43 43]
Adapter prompts. [4320, 1080, 4320, 4320, 135, 135, 4320, 135, 1080, 1080, 1080, 135, 4320, 1080, 135, 4320, 1080, 135, 135, 135, 135, 1080, 1080, 4320, 1080, 135, 1080, 1080, 1080, 1080, 4320, 1080, 135, 1080, 135, 4320, 4320, 135, 1080, 1080, 135, 1080, 135, 1080, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 135, 1080, 4320, 4320, 1080, 135, 135, 135, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 135, 135, 1080, 135, 4320, 4320, 135, 135, 1080, 1080, 1080, 135, 4320, 135, 4320, 1080, 135, 4320, 4320, 1080, 1080, 135, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 135, 4320, 135, 135, 4320, 1080, 4320, 4320, 1080, 4320, 135, 1080, 4320, 135, 4320, 1080, 135, 1080, 1080, 4320, 4320, 135, 135, 4320, 135, 135, 135, 1080, 135]
Prompts retrieved: 237870 . Total input tokens: 53018804 . Total output tokens: 46839171
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 7.792949199210852,
    "estimated_duration": 3600.0413064569975,
    "input_throughput": 5248.75838677428,
    "output_throughput": 4571.801431966875,
    "total_throughput": 9820.559818741154,
    "itl": 94.69774988625817,
    "ttft": 223597.98939798697,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 901,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.634917700495591,
    "arrivals": 79515,
    "finished_requests": 76036,
    "scheduler_time": 65.11300010683367
}
#Debug simulation 
Total elapsed time: 7.79308392200619. Arrivals time: 0.1948577114380896 Scheduler time: 7.434121651109308 Scheduler overhead time: 0.058074173517525196 Adapter cache time: 0.019898380152881145 Engine time: 0.05937964841723442 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-8/adapters_128_slots_64_rate_0.4-0.1-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-8/adapters_128_slots_64_rate_0.4-0.1-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [42 43 43]
Adapter prompts. [4320, 1080, 4320, 4320, 66, 66, 4320, 66, 1080, 1080, 1080, 66, 4320, 1080, 66, 4320, 1080, 66, 66, 66, 66, 1080, 1080, 4320, 1080, 66, 1080, 1080, 1080, 1080, 4320, 1080, 66, 1080, 66, 4320, 4320, 66, 1080, 1080, 66, 1080, 66, 1080, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 66, 1080, 4320, 4320, 1080, 66, 66, 66, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 66, 66, 1080, 66, 4320, 4320, 66, 66, 1080, 1080, 1080, 66, 4320, 66, 4320, 1080, 66, 4320, 4320, 1080, 1080, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 66, 4320, 66, 66, 4320, 1080, 4320, 4320, 1080, 4320, 66, 1080, 4320, 66, 4320, 1080, 66, 1080, 1080, 4320, 4320, 66, 66, 4320, 66, 66, 66, 1080, 66]
Prompts retrieved: 234972 . Total input tokens: 52360555 . Total output tokens: 46269111
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 9.373655658215284,
    "estimated_duration": 3600.073671592554,
    "input_throughput": 5389.171936422471,
    "output_throughput": 4657.128861638898,
    "total_throughput": 10046.30079806137,
    "itl": 98.25949301721677,
    "ttft": 54051.38332661769,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 808,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.342826497815654,
    "arrivals": 78583,
    "finished_requests": 77761,
    "scheduler_time": 62.68360181354253
}
#Debug simulation 
Total elapsed time: 9.3737683291547. Arrivals time: 0.19822884118184447 Scheduler time: 9.015578653663397 Scheduler overhead time: 0.05826054746285081 Adapter cache time: 0.01786212343722582 Engine time: 0.05821075104176998 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-16/adapters_128_slots_64_rate_0.4-0.1-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-16/adapters_128_slots_64_rate_0.4-0.1-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [42 43 43]
Adapter prompts. [4320, 1080, 4320, 4320, 66, 66, 4320, 66, 1080, 1080, 1080, 66, 4320, 1080, 66, 4320, 1080, 66, 66, 66, 66, 1080, 1080, 4320, 1080, 66, 1080, 1080, 1080, 1080, 4320, 1080, 66, 1080, 66, 4320, 4320, 66, 1080, 1080, 66, 1080, 66, 1080, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 66, 1080, 4320, 4320, 1080, 66, 66, 66, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 66, 66, 1080, 66, 4320, 4320, 66, 66, 1080, 1080, 1080, 66, 4320, 66, 4320, 1080, 66, 4320, 4320, 1080, 1080, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 66, 4320, 66, 66, 4320, 1080, 4320, 4320, 1080, 4320, 66, 1080, 4320, 66, 4320, 1080, 66, 1080, 1080, 4320, 4320, 66, 66, 4320, 66, 66, 66, 1080, 66]
Prompts retrieved: 234972 . Total input tokens: 52360555 . Total output tokens: 46269111
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 9.21153077390045,
    "estimated_duration": 3600.0678561394234,
    "input_throughput": 5389.112587673579,
    "output_throughput": 4657.913869985282,
    "total_throughput": 10047.026457658862,
    "itl": 98.24461653230843,
    "ttft": 54911.66951615752,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 799,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.840674610291616,
    "arrivals": 78583,
    "finished_requests": 77744,
    "scheduler_time": 62.684960797127935
}
#Debug simulation 
Total elapsed time: 9.211644382216036. Arrivals time: 0.1968665304593742 Scheduler time: 8.856979799456894 Scheduler overhead time: 0.056874318048357964 Adapter cache time: 0.017532125115394592 Engine time: 0.05784345790743828 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-32/adapters_128_slots_64_rate_0.4-0.1-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-32/adapters_128_slots_64_rate_0.4-0.1-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [42 43 43]
Adapter prompts. [4320, 1080, 4320, 4320, 66, 66, 4320, 66, 1080, 1080, 1080, 66, 4320, 1080, 66, 4320, 1080, 66, 66, 66, 66, 1080, 1080, 4320, 1080, 66, 1080, 1080, 1080, 1080, 4320, 1080, 66, 1080, 66, 4320, 4320, 66, 1080, 1080, 66, 1080, 66, 1080, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 66, 1080, 4320, 4320, 1080, 66, 66, 66, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 66, 66, 1080, 66, 4320, 4320, 66, 66, 1080, 1080, 1080, 66, 4320, 66, 4320, 1080, 66, 4320, 4320, 1080, 1080, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 66, 4320, 66, 66, 4320, 1080, 4320, 4320, 1080, 4320, 66, 1080, 4320, 66, 4320, 1080, 66, 1080, 1080, 4320, 4320, 66, 66, 4320, 66, 66, 66, 1080, 66]
Prompts retrieved: 234972 . Total input tokens: 52360555 . Total output tokens: 46269111
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 7.448125234339386,
    "estimated_duration": 3600.0073220848717,
    "input_throughput": 5285.091195031588,
    "output_throughput": 4568.7312631560935,
    "total_throughput": 9853.82245818768,
    "itl": 94.3893610112447,
    "ttft": 152341.89055807647,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 874,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.571478306124942,
    "arrivals": 78583,
    "finished_requests": 76267,
    "scheduler_time": 63.47812482306873
}
#Debug simulation 
Total elapsed time: 7.448281532153487. Arrivals time: 0.19442025758326054 Scheduler time: 7.08934513758868 Scheduler overhead time: 0.05840131500735879 Adapter cache time: 0.019558165688067675 Engine time: 0.059728626161813736 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.00625_size_8-16-16/adapters_128_slots_64_rate_0.4-0.1-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.00625_size_8-16-16/adapters_128_slots_64_rate_0.4-0.1-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [42 43 43]
Adapter prompts. [4320, 1080, 4320, 4320, 66, 66, 4320, 66, 1080, 1080, 1080, 66, 4320, 1080, 66, 4320, 1080, 66, 66, 66, 66, 1080, 1080, 4320, 1080, 66, 1080, 1080, 1080, 1080, 4320, 1080, 66, 1080, 66, 4320, 4320, 66, 1080, 1080, 66, 1080, 66, 1080, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 66, 1080, 4320, 4320, 1080, 66, 66, 66, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 66, 66, 1080, 66, 4320, 4320, 66, 66, 1080, 1080, 1080, 66, 4320, 66, 4320, 1080, 66, 4320, 4320, 1080, 1080, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 66, 4320, 66, 66, 4320, 1080, 4320, 4320, 1080, 4320, 66, 1080, 4320, 66, 4320, 1080, 66, 1080, 1080, 4320, 4320, 66, 66, 4320, 66, 66, 66, 1080, 66]
Prompts retrieved: 234972 . Total input tokens: 52360555 . Total output tokens: 46269111
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 9.191650175023824,
    "estimated_duration": 3600.015975182478,
    "input_throughput": 5387.994423834969,
    "output_throughput": 4656.552391868284,
    "total_throughput": 10044.546815703252,
    "itl": 98.18509480577491,
    "ttft": 55373.869292023664,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 802,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.447524744039391,
    "arrivals": 78583,
    "finished_requests": 77729,
    "scheduler_time": 62.65896068270815
}
#Debug simulation 
Total elapsed time: 9.191786632873118. Arrivals time: 0.1966279256157577 Scheduler time: 8.837751861661673 Scheduler overhead time: 0.056511920876801014 Adapter cache time: 0.01774723408743739 Engine time: 0.05752511043101549 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.00625_size_8-16-32/adapters_128_slots_64_rate_0.4-0.1-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.00625_size_8-16-32/adapters_128_slots_64_rate_0.4-0.1-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [42 43 43]
Adapter prompts. [4320, 1080, 4320, 4320, 66, 66, 4320, 66, 1080, 1080, 1080, 66, 4320, 1080, 66, 4320, 1080, 66, 66, 66, 66, 1080, 1080, 4320, 1080, 66, 1080, 1080, 1080, 1080, 4320, 1080, 66, 1080, 66, 4320, 4320, 66, 1080, 1080, 66, 1080, 66, 1080, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 66, 1080, 4320, 4320, 1080, 66, 66, 66, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 66, 66, 1080, 66, 4320, 4320, 66, 66, 1080, 1080, 1080, 66, 4320, 66, 4320, 1080, 66, 4320, 4320, 1080, 1080, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 66, 4320, 66, 66, 4320, 1080, 4320, 4320, 1080, 4320, 66, 1080, 4320, 66, 4320, 1080, 66, 1080, 1080, 4320, 4320, 66, 66, 4320, 66, 66, 66, 1080, 66]
Prompts retrieved: 234972 . Total input tokens: 52360555 . Total output tokens: 46269111
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 7.447658707853407,
    "estimated_duration": 3600.0273407149984,
    "input_throughput": 5284.727086606355,
    "output_throughput": 4568.233083678115,
    "total_throughput": 9852.96017028447,
    "itl": 94.38765217029216,
    "ttft": 152554.2996362186,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 871,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.479108534897703,
    "arrivals": 78583,
    "finished_requests": 76262,
    "scheduler_time": 63.46823658386663
}
#Debug simulation 
Total elapsed time: 7.447770731989294. Arrivals time: 0.19435634650290012 Scheduler time: 7.089133762288839 Scheduler overhead time: 0.05821018107235432 Adapter cache time: 0.019724560901522636 Engine time: 0.0593188782222569 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.00625_size_16-16-16/adapters_128_slots_64_rate_0.4-0.1-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.00625_size_16-16-16/adapters_128_slots_64_rate_0.4-0.1-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [42 43 43]
Adapter prompts. [4320, 1080, 4320, 4320, 66, 66, 4320, 66, 1080, 1080, 1080, 66, 4320, 1080, 66, 4320, 1080, 66, 66, 66, 66, 1080, 1080, 4320, 1080, 66, 1080, 1080, 1080, 1080, 4320, 1080, 66, 1080, 66, 4320, 4320, 66, 1080, 1080, 66, 1080, 66, 1080, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 66, 1080, 4320, 4320, 1080, 66, 66, 66, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 66, 66, 1080, 66, 4320, 4320, 66, 66, 1080, 1080, 1080, 66, 4320, 66, 4320, 1080, 66, 4320, 4320, 1080, 1080, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 66, 4320, 66, 66, 4320, 1080, 4320, 4320, 1080, 4320, 66, 1080, 4320, 66, 4320, 1080, 66, 1080, 1080, 4320, 4320, 66, 66, 4320, 66, 66, 66, 1080, 66]
Prompts retrieved: 234972 . Total input tokens: 52360555 . Total output tokens: 46269111
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 9.178138541057706,
    "estimated_duration": 3600.0064653457403,
    "input_throughput": 5390.057819836843,
    "output_throughput": 4656.930525370573,
    "total_throughput": 10046.988345207417,
    "itl": 98.18129472801733,
    "ttft": 54191.01113676427,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 803,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.126288515278113,
    "arrivals": 78583,
    "finished_requests": 77759,
    "scheduler_time": 62.68812214529225
}
#Debug simulation 
Total elapsed time: 9.178252786863595. Arrivals time: 0.19612670736387372 Scheduler time: 8.825489821843803 Scheduler overhead time: 0.05633086059242487 Adapter cache time: 0.017465915996581316 Engine time: 0.05736101325601339 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.00625_size_16-16-32/adapters_128_slots_64_rate_0.4-0.1-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.00625_size_16-16-32/adapters_128_slots_64_rate_0.4-0.1-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [42 43 43]
Adapter prompts. [4320, 1080, 4320, 4320, 66, 66, 4320, 66, 1080, 1080, 1080, 66, 4320, 1080, 66, 4320, 1080, 66, 66, 66, 66, 1080, 1080, 4320, 1080, 66, 1080, 1080, 1080, 1080, 4320, 1080, 66, 1080, 66, 4320, 4320, 66, 1080, 1080, 66, 1080, 66, 1080, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 66, 1080, 4320, 4320, 1080, 66, 66, 66, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 66, 66, 1080, 66, 4320, 4320, 66, 66, 1080, 1080, 1080, 66, 4320, 66, 4320, 1080, 66, 4320, 4320, 1080, 1080, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 66, 4320, 66, 66, 4320, 1080, 4320, 4320, 1080, 4320, 66, 1080, 4320, 66, 4320, 1080, 66, 1080, 1080, 4320, 4320, 66, 66, 4320, 66, 66, 66, 1080, 66]
Prompts retrieved: 234972 . Total input tokens: 52360555 . Total output tokens: 46269111
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 7.4715607250109315,
    "estimated_duration": 3600.0410314692526,
    "input_throughput": 5286.866131143027,
    "output_throughput": 4569.134311584995,
    "total_throughput": 9856.000442728022,
    "itl": 94.38074087481176,
    "ttft": 151596.19732216376,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 861,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.348691547755177,
    "arrivals": 78583,
    "finished_requests": 76280,
    "scheduler_time": 63.46388121930054
}
#Debug simulation 
Total elapsed time: 7.471703046001494. Arrivals time: 0.19530187733471394 Scheduler time: 7.112887839321047 Scheduler overhead time: 0.05787211982533336 Adapter cache time: 0.019582318142056465 Engine time: 0.05930387834087014 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-8/adapters_128_slots_64_rate_0.4-0.1-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-8/adapters_128_slots_64_rate_0.4-0.1-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [42 43 43]
Adapter prompts. [4320, 1080, 4320, 4320, 33, 33, 4320, 33, 1080, 1080, 1080, 33, 4320, 1080, 33, 4320, 1080, 33, 33, 33, 33, 1080, 1080, 4320, 1080, 33, 1080, 1080, 1080, 1080, 4320, 1080, 33, 1080, 33, 4320, 4320, 33, 1080, 1080, 33, 1080, 33, 1080, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 33, 1080, 4320, 4320, 1080, 33, 33, 33, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 33, 33, 1080, 33, 4320, 4320, 33, 33, 1080, 1080, 1080, 33, 4320, 33, 4320, 1080, 33, 4320, 4320, 1080, 1080, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 33, 4320, 33, 33, 4320, 1080, 4320, 4320, 1080, 4320, 33, 1080, 4320, 33, 4320, 1080, 33, 1080, 1080, 4320, 4320, 33, 33, 4320, 33, 33, 33, 1080, 33]
Prompts retrieved: 233586 . Total input tokens: 52052598 . Total output tokens: 46004919
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 8.534726323094219,
    "estimated_duration": 3600.0851893045747,
    "input_throughput": 5346.171823150069,
    "output_throughput": 4625.659150920482,
    "total_throughput": 9971.83097407055,
    "itl": 96.63201752484649,
    "ttft": 50820.19067297409,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 790,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.223803135240551,
    "arrivals": 78101,
    "finished_requests": 77278,
    "scheduler_time": 61.92486268660507
}
#Debug simulation 
Total elapsed time: 8.53485965821892. Arrivals time: 0.19535220367833972 Scheduler time: 8.181919429916888 Scheduler overhead time: 0.05674497224390507 Adapter cache time: 0.017680326011031866 Engine time: 0.0574903916567564 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-16/adapters_128_slots_64_rate_0.4-0.1-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-16/adapters_128_slots_64_rate_0.4-0.1-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [42 43 43]
Adapter prompts. [4320, 1080, 4320, 4320, 33, 33, 4320, 33, 1080, 1080, 1080, 33, 4320, 1080, 33, 4320, 1080, 33, 33, 33, 33, 1080, 1080, 4320, 1080, 33, 1080, 1080, 1080, 1080, 4320, 1080, 33, 1080, 33, 4320, 4320, 33, 1080, 1080, 33, 1080, 33, 1080, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 33, 1080, 4320, 4320, 1080, 33, 33, 33, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 33, 33, 1080, 33, 4320, 4320, 33, 33, 1080, 1080, 1080, 33, 4320, 33, 4320, 1080, 33, 4320, 4320, 1080, 1080, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 33, 4320, 33, 33, 4320, 1080, 4320, 4320, 1080, 4320, 33, 1080, 4320, 33, 4320, 1080, 33, 1080, 1080, 4320, 4320, 33, 33, 4320, 33, 33, 33, 1080, 33]
Prompts retrieved: 233586 . Total input tokens: 52052598 . Total output tokens: 46004919
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 8.579371826257557,
    "estimated_duration": 3600.0876376614738,
    "input_throughput": 5346.365126961913,
    "output_throughput": 4625.860444557871,
    "total_throughput": 9972.225571519784,
    "itl": 96.69469326346751,
    "ttft": 51076.94753648566,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 785,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.745746833230378,
    "arrivals": 78101,
    "finished_requests": 77276,
    "scheduler_time": 61.93464422478891
}
#Debug simulation 
Total elapsed time: 8.579480063170195. Arrivals time: 0.1968687162734568 Scheduler time: 8.22509749000892 Scheduler overhead time: 0.05686598923057318 Adapter cache time: 0.017439681105315685 Engine time: 0.05769240856170654 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-32/adapters_128_slots_64_rate_0.4-0.1-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-32/adapters_128_slots_64_rate_0.4-0.1-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [42 43 43]
Adapter prompts. [4320, 1080, 4320, 4320, 33, 33, 4320, 33, 1080, 1080, 1080, 33, 4320, 1080, 33, 4320, 1080, 33, 33, 33, 33, 1080, 1080, 4320, 1080, 33, 1080, 1080, 1080, 1080, 4320, 1080, 33, 1080, 33, 4320, 4320, 33, 1080, 1080, 33, 1080, 33, 1080, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 33, 1080, 4320, 4320, 1080, 33, 33, 33, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 33, 33, 1080, 33, 4320, 4320, 33, 33, 1080, 1080, 1080, 33, 4320, 33, 4320, 1080, 33, 4320, 4320, 1080, 1080, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 33, 4320, 33, 33, 4320, 1080, 4320, 4320, 1080, 4320, 33, 1080, 4320, 33, 4320, 1080, 33, 1080, 1080, 4320, 4320, 33, 33, 4320, 33, 33, 33, 1080, 33]
Prompts retrieved: 233586 . Total input tokens: 52052598 . Total output tokens: 46004919
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 7.096614995971322,
    "estimated_duration": 3600.028567911631,
    "input_throughput": 5288.98080690658,
    "output_throughput": 4576.565349190425,
    "total_throughput": 9865.546156097005,
    "itl": 94.69547274307583,
    "ttft": 106684.4624302621,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 809,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.080709664728517,
    "arrivals": 78101,
    "finished_requests": 76466,
    "scheduler_time": 62.54560594684091
}
#Debug simulation 
Total elapsed time: 7.096728517208248. Arrivals time: 0.19373721675947309 Scheduler time: 6.741132513154298 Scheduler overhead time: 0.05772940535098314 Adapter cache time: 0.018919904716312885 Engine time: 0.05838406551629305 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.003125_size_8-16-16/adapters_128_slots_64_rate_0.4-0.1-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.003125_size_8-16-16/adapters_128_slots_64_rate_0.4-0.1-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [42 43 43]
Adapter prompts. [4320, 1080, 4320, 4320, 33, 33, 4320, 33, 1080, 1080, 1080, 33, 4320, 1080, 33, 4320, 1080, 33, 33, 33, 33, 1080, 1080, 4320, 1080, 33, 1080, 1080, 1080, 1080, 4320, 1080, 33, 1080, 33, 4320, 4320, 33, 1080, 1080, 33, 1080, 33, 1080, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 33, 1080, 4320, 4320, 1080, 33, 33, 33, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 33, 33, 1080, 33, 4320, 4320, 33, 33, 1080, 1080, 1080, 33, 4320, 33, 4320, 1080, 33, 4320, 4320, 1080, 1080, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 33, 4320, 33, 33, 4320, 1080, 4320, 4320, 1080, 4320, 33, 1080, 4320, 33, 4320, 1080, 33, 1080, 1080, 4320, 4320, 33, 33, 4320, 33, 33, 33, 1080, 33]
Prompts retrieved: 233586 . Total input tokens: 52052598 . Total output tokens: 46004919
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 8.491022615227848,
    "estimated_duration": 3600.0657188119953,
    "input_throughput": 5346.521842482279,
    "output_throughput": 4625.638891252041,
    "total_throughput": 9972.16073373432,
    "itl": 96.64699316411078,
    "ttft": 50433.97316410372,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 802,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.465571616692459,
    "arrivals": 78101,
    "finished_requests": 77281,
    "scheduler_time": 61.90708045618724
}
#Debug simulation 
Total elapsed time: 8.49114002706483. Arrivals time: 0.19882052298635244 Scheduler time: 8.134555995929986 Scheduler overhead time: 0.0568138537928462 Adapter cache time: 0.01775486394762993 Engine time: 0.0573638416826725 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.003125_size_8-16-32/adapters_128_slots_64_rate_0.4-0.1-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.003125_size_8-16-32/adapters_128_slots_64_rate_0.4-0.1-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [42 43 43]
Adapter prompts. [4320, 1080, 4320, 4320, 33, 33, 4320, 33, 1080, 1080, 1080, 33, 4320, 1080, 33, 4320, 1080, 33, 33, 33, 33, 1080, 1080, 4320, 1080, 33, 1080, 1080, 1080, 1080, 4320, 1080, 33, 1080, 33, 4320, 4320, 33, 1080, 1080, 33, 1080, 33, 1080, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 33, 1080, 4320, 4320, 1080, 33, 33, 33, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 33, 33, 1080, 33, 4320, 4320, 33, 33, 1080, 1080, 1080, 33, 4320, 33, 4320, 1080, 33, 4320, 4320, 1080, 1080, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 33, 4320, 33, 33, 4320, 1080, 4320, 4320, 1080, 4320, 33, 1080, 4320, 33, 4320, 1080, 33, 1080, 1080, 4320, 4320, 33, 33, 4320, 33, 33, 33, 1080, 33]
Prompts retrieved: 233586 . Total input tokens: 52052598 . Total output tokens: 46004919
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 7.107964579947293,
    "estimated_duration": 3600.0681107049313,
    "input_throughput": 5290.616570104414,
    "output_throughput": 4576.969794266906,
    "total_throughput": 9867.58636437132,
    "itl": 94.6914407619485,
    "ttft": 106353.07195722818,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 817,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.084011567439911,
    "arrivals": 78101,
    "finished_requests": 76480,
    "scheduler_time": 62.539369295064304
}
#Debug simulation 
Total elapsed time: 7.108101142104715. Arrivals time: 0.19309583166614175 Scheduler time: 6.752414332237095 Scheduler overhead time: 0.0576452212408185 Adapter cache time: 0.019182387739419937 Engine time: 0.05897082248702645 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.003125_size_16-16-16/adapters_128_slots_64_rate_0.4-0.1-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.003125_size_16-16-16/adapters_128_slots_64_rate_0.4-0.1-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [42 43 43]
Adapter prompts. [4320, 1080, 4320, 4320, 33, 33, 4320, 33, 1080, 1080, 1080, 33, 4320, 1080, 33, 4320, 1080, 33, 33, 33, 33, 1080, 1080, 4320, 1080, 33, 1080, 1080, 1080, 1080, 4320, 1080, 33, 1080, 33, 4320, 4320, 33, 1080, 1080, 33, 1080, 33, 1080, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 33, 1080, 4320, 4320, 1080, 33, 33, 33, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 33, 33, 1080, 33, 4320, 4320, 33, 33, 1080, 1080, 1080, 33, 4320, 33, 4320, 1080, 33, 4320, 4320, 1080, 1080, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 33, 4320, 33, 33, 4320, 1080, 4320, 4320, 1080, 4320, 33, 1080, 4320, 33, 4320, 1080, 33, 1080, 1080, 4320, 4320, 33, 33, 4320, 33, 33, 33, 1080, 33]
Prompts retrieved: 233586 . Total input tokens: 52052598 . Total output tokens: 46004919
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 8.479398646391928,
    "estimated_duration": 3600.0400317527115,
    "input_throughput": 5346.559991064606,
    "output_throughput": 4625.671896179591,
    "total_throughput": 9972.231887244197,
    "itl": 96.62202778707932,
    "ttft": 50386.6378134074,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 802,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.119904594337543,
    "arrivals": 78101,
    "finished_requests": 77281,
    "scheduler_time": 61.905094275246036
}
#Debug simulation 
Total elapsed time: 8.479509918019176. Arrivals time: 0.1960534225217998 Scheduler time: 8.125240524299443 Scheduler overhead time: 0.05701564345508814 Adapter cache time: 0.017642278224229813 Engine time: 0.05782911321148276 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.003125_size_16-16-32/adapters_128_slots_64_rate_0.4-0.1-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.1-0.003125_size_16-16-32/adapters_128_slots_64_rate_0.4-0.1-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [42 43 43]
Adapter prompts. [4320, 1080, 4320, 4320, 33, 33, 4320, 33, 1080, 1080, 1080, 33, 4320, 1080, 33, 4320, 1080, 33, 33, 33, 33, 1080, 1080, 4320, 1080, 33, 1080, 1080, 1080, 1080, 4320, 1080, 33, 1080, 33, 4320, 4320, 33, 1080, 1080, 33, 1080, 33, 1080, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 33, 1080, 4320, 4320, 1080, 33, 33, 33, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 33, 33, 1080, 33, 4320, 4320, 33, 33, 1080, 1080, 1080, 33, 4320, 33, 4320, 1080, 33, 4320, 4320, 1080, 1080, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 33, 4320, 33, 33, 4320, 1080, 4320, 4320, 1080, 4320, 33, 1080, 4320, 33, 4320, 1080, 33, 1080, 1080, 4320, 4320, 33, 33, 4320, 33, 33, 33, 1080, 33]
Prompts retrieved: 233586 . Total input tokens: 52052598 . Total output tokens: 46004919
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 7.1139448010362685,
    "estimated_duration": 3600.0569219107506,
    "input_throughput": 5290.833287683278,
    "output_throughput": 4577.37373531688,
    "total_throughput": 9868.207023000157,
    "itl": 94.69591089520061,
    "ttft": 106449.59767419769,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 811,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.983775833044229,
    "arrivals": 78101,
    "finished_requests": 76478,
    "scheduler_time": 62.547474480024796
}
#Debug simulation 
Total elapsed time: 7.114059412386268. Arrivals time: 0.19475645432248712 Scheduler time: 6.757041989360005 Scheduler overhead time: 0.05796000035479665 Adapter cache time: 0.018914578948169947 Engine time: 0.05853580171242356 
