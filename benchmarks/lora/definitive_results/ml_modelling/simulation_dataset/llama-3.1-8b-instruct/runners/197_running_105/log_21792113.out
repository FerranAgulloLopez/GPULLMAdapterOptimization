INFO 05-31 19:31:05 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 05-31 19:31:05 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-32/adapters_256_slots_16_rate_0.1-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-32/adapters_256_slots_16_rate_0.1-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 1080, 33, 1080, 1080, 33, 1080, 66, 1080, 33, 66, 33, 1080, 66, 66, 66, 66, 1080, 33, 33, 33, 66, 1080, 33, 1080, 1080, 66, 66, 66, 33, 1080, 33, 66, 66, 33, 66, 33, 33, 66, 66, 1080, 66, 33, 66, 1080, 66, 66, 1080, 66, 1080, 33, 1080, 1080, 66, 33, 33, 1080, 66, 33, 66, 66, 1080, 66, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 1080, 1080, 33, 1080, 33, 66, 1080, 1080, 1080, 66, 33, 1080, 66, 33, 33, 33, 33, 33, 1080, 66, 33, 1080, 33, 1080, 33, 33, 66, 66, 1080, 66, 1080, 33, 66, 33, 1080, 1080, 33, 1080, 66, 33, 1080, 33, 33, 1080, 1080, 66, 1080, 1080, 33, 1080, 66, 66, 33, 66, 1080, 1080, 33, 1080, 66, 33, 66, 1080, 33, 33, 33, 33, 33, 33, 1080, 33, 33, 33, 1080, 33, 66, 1080, 1080, 66, 33, 1080, 33, 66, 66, 33, 66, 33, 1080, 33, 33, 1080, 33, 1080, 1080, 66, 1080, 66, 33, 66, 1080, 66, 1080, 33, 1080, 33, 66, 1080, 66, 1080, 66, 1080, 66, 1080, 66, 33, 1080, 33, 1080, 66, 66, 33, 66, 1080, 66, 66, 1080, 33, 1080, 1080, 66, 33, 1080, 1080, 66, 66, 1080, 1080, 66, 66, 66, 66, 1080, 1080, 66, 66, 1080, 33, 1080, 66, 1080, 1080, 33, 1080, 66, 66, 1080, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 1080, 66, 33, 33, 33, 33]
Prompts retrieved: 101295 . Total input tokens: 22597536 . Total output tokens: 19905812
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.455476203002036,
    "estimated_duration": 3600.0096399753083,
    "input_throughput": 2282.9786089284944,
    "output_throughput": 1999.4543681414614,
    "total_throughput": 4282.432977069956,
    "itl": 28.543803584504648,
    "ttft": 117563.86783359863,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3778,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 28.37710601886376,
    "arrivals": 34024,
    "finished_requests": 33463,
    "scheduler_time": 19.941065922987896
}
#Debug simulation 
Total elapsed time: 4.455605344846845. Arrivals time: 0.09660207945853472 Scheduler time: 4.002578159794211 Scheduler overhead time: 0.13449852727353573 Adapter cache time: 0.03884277772158384 Engine time: 0.1252549597993493 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-16/adapters_256_slots_16_rate_0.1-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-16/adapters_256_slots_16_rate_0.1-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 1080, 33, 1080, 1080, 33, 1080, 66, 1080, 33, 66, 33, 1080, 66, 66, 66, 66, 1080, 33, 33, 33, 66, 1080, 33, 1080, 1080, 66, 66, 66, 33, 1080, 33, 66, 66, 33, 66, 33, 33, 66, 66, 1080, 66, 33, 66, 1080, 66, 66, 1080, 66, 1080, 33, 1080, 1080, 66, 33, 33, 1080, 66, 33, 66, 66, 1080, 66, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 1080, 1080, 33, 1080, 33, 66, 1080, 1080, 1080, 66, 33, 1080, 66, 33, 33, 33, 33, 33, 1080, 66, 33, 1080, 33, 1080, 33, 33, 66, 66, 1080, 66, 1080, 33, 66, 33, 1080, 1080, 33, 1080, 66, 33, 1080, 33, 33, 1080, 1080, 66, 1080, 1080, 33, 1080, 66, 66, 33, 66, 1080, 1080, 33, 1080, 66, 33, 66, 1080, 33, 33, 33, 33, 33, 33, 1080, 33, 33, 33, 1080, 33, 66, 1080, 1080, 66, 33, 1080, 33, 66, 66, 33, 66, 33, 1080, 33, 33, 1080, 33, 1080, 1080, 66, 1080, 66, 33, 66, 1080, 66, 1080, 33, 1080, 33, 66, 1080, 66, 1080, 66, 1080, 66, 1080, 66, 33, 1080, 33, 1080, 66, 66, 33, 66, 1080, 66, 66, 1080, 33, 1080, 1080, 66, 33, 1080, 1080, 66, 66, 1080, 1080, 66, 66, 66, 66, 1080, 1080, 66, 66, 1080, 33, 1080, 66, 1080, 1080, 33, 1080, 66, 66, 1080, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 1080, 66, 33, 33, 33, 33]
Prompts retrieved: 101295 . Total input tokens: 22597536 . Total output tokens: 19905812
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 4.360126605257392,
    "estimated_duration": 3600.0012554583964,
    "input_throughput": 2282.284204079759,
    "output_throughput": 1997.5701367038332,
    "total_throughput": 4279.854340783592,
    "itl": 28.525210661929812,
    "ttft": 119298.55018844776,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3800,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 25.960858487450373,
    "arrivals": 34024,
    "finished_requests": 33442,
    "scheduler_time": 19.88146133628794
}
#Debug simulation 
Total elapsed time: 4.360228247009218. Arrivals time: 0.09668978350237012 Scheduler time: 3.909307947382331 Scheduler overhead time: 0.13369934633374214 Adapter cache time: 0.03823501244187355 Engine time: 0.12497399561107159 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-32/adapters_256_slots_16_rate_0.1-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-32/adapters_256_slots_16_rate_0.1-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 1080, 33, 1080, 1080, 33, 1080, 66, 1080, 33, 66, 33, 1080, 66, 66, 66, 66, 1080, 33, 33, 33, 66, 1080, 33, 1080, 1080, 66, 66, 66, 33, 1080, 33, 66, 66, 33, 66, 33, 33, 66, 66, 1080, 66, 33, 66, 1080, 66, 66, 1080, 66, 1080, 33, 1080, 1080, 66, 33, 33, 1080, 66, 33, 66, 66, 1080, 66, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 1080, 1080, 33, 1080, 33, 66, 1080, 1080, 1080, 66, 33, 1080, 66, 33, 33, 33, 33, 33, 1080, 66, 33, 1080, 33, 1080, 33, 33, 66, 66, 1080, 66, 1080, 33, 66, 33, 1080, 1080, 33, 1080, 66, 33, 1080, 33, 33, 1080, 1080, 66, 1080, 1080, 33, 1080, 66, 66, 33, 66, 1080, 1080, 33, 1080, 66, 33, 66, 1080, 33, 33, 33, 33, 33, 33, 1080, 33, 33, 33, 1080, 33, 66, 1080, 1080, 66, 33, 1080, 33, 66, 66, 33, 66, 33, 1080, 33, 33, 1080, 33, 1080, 1080, 66, 1080, 66, 33, 66, 1080, 66, 1080, 33, 1080, 33, 66, 1080, 66, 1080, 66, 1080, 66, 1080, 66, 33, 1080, 33, 1080, 66, 66, 33, 66, 1080, 66, 66, 1080, 33, 1080, 1080, 66, 33, 1080, 1080, 66, 66, 1080, 1080, 66, 66, 66, 66, 1080, 1080, 66, 66, 1080, 33, 1080, 66, 1080, 1080, 33, 1080, 66, 66, 1080, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 1080, 66, 33, 33, 33, 33]
Prompts retrieved: 101295 . Total input tokens: 22597536 . Total output tokens: 19905812
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 4.326812273822725,
    "estimated_duration": 3600.018127484046,
    "input_throughput": 2280.5674052918735,
    "output_throughput": 1996.877722675261,
    "total_throughput": 4277.445127967135,
    "itl": 28.533534979163303,
    "ttft": 120806.7175423942,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3761,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 27.98599156844533,
    "arrivals": 34024,
    "finished_requests": 33434,
    "scheduler_time": 19.983061603427938
}
#Debug simulation 
Total elapsed time: 4.326914860866964. Arrivals time: 0.09396734787151217 Scheduler time: 3.8808240117505193 Scheduler overhead time: 0.13287588581442833 Adapter cache time: 0.03778168652206659 Engine time: 0.12415955914184451 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-16/adapters_256_slots_16_rate_0.1-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-16/adapters_256_slots_16_rate_0.1-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 1080, 33, 1080, 1080, 33, 1080, 66, 1080, 33, 66, 33, 1080, 66, 66, 66, 66, 1080, 33, 33, 33, 66, 1080, 33, 1080, 1080, 66, 66, 66, 33, 1080, 33, 66, 66, 33, 66, 33, 33, 66, 66, 1080, 66, 33, 66, 1080, 66, 66, 1080, 66, 1080, 33, 1080, 1080, 66, 33, 33, 1080, 66, 33, 66, 66, 1080, 66, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 1080, 1080, 33, 1080, 33, 66, 1080, 1080, 1080, 66, 33, 1080, 66, 33, 33, 33, 33, 33, 1080, 66, 33, 1080, 33, 1080, 33, 33, 66, 66, 1080, 66, 1080, 33, 66, 33, 1080, 1080, 33, 1080, 66, 33, 1080, 33, 33, 1080, 1080, 66, 1080, 1080, 33, 1080, 66, 66, 33, 66, 1080, 1080, 33, 1080, 66, 33, 66, 1080, 33, 33, 33, 33, 33, 33, 1080, 33, 33, 33, 1080, 33, 66, 1080, 1080, 66, 33, 1080, 33, 66, 66, 33, 66, 33, 1080, 33, 33, 1080, 33, 1080, 1080, 66, 1080, 66, 33, 66, 1080, 66, 1080, 33, 1080, 33, 66, 1080, 66, 1080, 66, 1080, 66, 1080, 66, 33, 1080, 33, 1080, 66, 66, 33, 66, 1080, 66, 66, 1080, 33, 1080, 1080, 66, 33, 1080, 1080, 66, 66, 1080, 1080, 66, 66, 66, 66, 1080, 1080, 66, 66, 1080, 33, 1080, 66, 1080, 1080, 33, 1080, 66, 66, 1080, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 1080, 66, 33, 33, 33, 33]
Prompts retrieved: 101295 . Total input tokens: 22597536 . Total output tokens: 19905812
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.346352003980428,
    "estimated_duration": 3600.0194260255707,
    "input_throughput": 2283.2929568590653,
    "output_throughput": 1999.289489375349,
    "total_throughput": 4282.582446234414,
    "itl": 28.53356380302802,
    "ttft": 115812.90309964678,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3802,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.271667416051297,
    "arrivals": 34024,
    "finished_requests": 33473,
    "scheduler_time": 19.78141326185096
}
#Debug simulation 
Total elapsed time: 4.346465041860938. Arrivals time: 0.09753981791436672 Scheduler time: 3.897283502854407 Scheduler overhead time: 0.13283676095306873 Adapter cache time: 0.03808482130989432 Engine time: 0.12344148382544518 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-32/adapters_256_slots_16_rate_0.1-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-32/adapters_256_slots_16_rate_0.1-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 1080, 33, 1080, 1080, 33, 1080, 66, 1080, 33, 66, 33, 1080, 66, 66, 66, 66, 1080, 33, 33, 33, 66, 1080, 33, 1080, 1080, 66, 66, 66, 33, 1080, 33, 66, 66, 33, 66, 33, 33, 66, 66, 1080, 66, 33, 66, 1080, 66, 66, 1080, 66, 1080, 33, 1080, 1080, 66, 33, 33, 1080, 66, 33, 66, 66, 1080, 66, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 1080, 1080, 33, 1080, 33, 66, 1080, 1080, 1080, 66, 33, 1080, 66, 33, 33, 33, 33, 33, 1080, 66, 33, 1080, 33, 1080, 33, 33, 66, 66, 1080, 66, 1080, 33, 66, 33, 1080, 1080, 33, 1080, 66, 33, 1080, 33, 33, 1080, 1080, 66, 1080, 1080, 33, 1080, 66, 66, 33, 66, 1080, 1080, 33, 1080, 66, 33, 66, 1080, 33, 33, 33, 33, 33, 33, 1080, 33, 33, 33, 1080, 33, 66, 1080, 1080, 66, 33, 1080, 33, 66, 66, 33, 66, 33, 1080, 33, 33, 1080, 33, 1080, 1080, 66, 1080, 66, 33, 66, 1080, 66, 1080, 33, 1080, 33, 66, 1080, 66, 1080, 66, 1080, 66, 1080, 66, 33, 1080, 33, 1080, 66, 66, 33, 66, 1080, 66, 66, 1080, 33, 1080, 1080, 66, 33, 1080, 1080, 66, 66, 1080, 1080, 66, 66, 66, 66, 1080, 1080, 66, 66, 1080, 33, 1080, 66, 1080, 1080, 33, 1080, 66, 66, 1080, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 1080, 66, 33, 33, 33, 33]
Prompts retrieved: 101295 . Total input tokens: 22597536 . Total output tokens: 19905812
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.376694979611784,
    "estimated_duration": 3600.0205556606684,
    "input_throughput": 2282.9716866690815,
    "output_throughput": 1999.448305560863,
    "total_throughput": 4282.419992229945,
    "itl": 28.53722996708757,
    "ttft": 117556.79939364134,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3778,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 27.853306679205144,
    "arrivals": 34024,
    "finished_requests": 33463,
    "scheduler_time": 19.937862499631184
}
#Debug simulation 
Total elapsed time: 4.376777562778443. Arrivals time: 0.09609472751617432 Scheduler time: 3.926760339178145 Scheduler overhead time: 0.13406644389033318 Adapter cache time: 0.03805488487705588 Engine time: 0.12454536510631442 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-8/adapters_256_slots_16_rate_0.05-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-8/adapters_256_slots_16_rate_0.05-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 540, 135, 540, 540, 135, 540, 270, 540, 135, 270, 135, 540, 270, 270, 270, 270, 540, 135, 135, 135, 270, 540, 135, 540, 540, 270, 270, 270, 135, 540, 135, 270, 270, 135, 270, 135, 135, 270, 270, 540, 270, 135, 270, 540, 270, 270, 540, 270, 540, 135, 540, 540, 270, 135, 135, 540, 270, 135, 270, 270, 540, 270, 135, 135, 540, 540, 540, 540, 540, 540, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 540, 540, 135, 540, 135, 270, 540, 540, 540, 270, 135, 540, 270, 135, 135, 135, 135, 135, 540, 270, 135, 540, 135, 540, 135, 135, 270, 270, 540, 270, 540, 135, 270, 135, 540, 540, 135, 540, 270, 135, 540, 135, 135, 540, 540, 270, 540, 540, 135, 540, 270, 270, 135, 270, 540, 540, 135, 540, 270, 135, 270, 540, 135, 135, 135, 135, 135, 135, 540, 135, 135, 135, 540, 135, 270, 540, 540, 270, 135, 540, 135, 270, 270, 135, 270, 135, 540, 135, 135, 540, 135, 540, 540, 270, 540, 270, 135, 270, 540, 270, 540, 135, 540, 135, 270, 540, 270, 540, 270, 540, 270, 540, 270, 135, 540, 135, 540, 270, 270, 135, 270, 540, 270, 270, 540, 135, 540, 540, 270, 135, 540, 540, 270, 270, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 540, 135, 540, 270, 540, 540, 135, 540, 270, 270, 540, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 540, 270, 135, 135, 135, 135]
Prompts retrieved: 80865 . Total input tokens: 18009757 . Total output tokens: 15867329
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 3.8050205716863275,
    "estimated_duration": 3599.7345209722353,
    "input_throughput": 1812.7820154463916,
    "output_throughput": 1579.9328997361542,
    "total_throughput": 3392.714915182546,
    "itl": 26.896777257495327,
    "ttft": 186006.31832288875,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3951,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 26.125628085232258,
    "arrivals": 27120,
    "finished_requests": 26412,
    "scheduler_time": 17.296127559696696
}
#Debug simulation 
Total elapsed time: 3.805115662049502. Arrivals time: 0.0810256446711719 Scheduler time: 3.358441690914333 Scheduler overhead time: 0.13688325602561235 Adapter cache time: 0.03968346584588289 Engine time: 0.12994282180443406 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-16/adapters_256_slots_16_rate_0.05-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-16/adapters_256_slots_16_rate_0.05-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 540, 135, 540, 540, 135, 540, 270, 540, 135, 270, 135, 540, 270, 270, 270, 270, 540, 135, 135, 135, 270, 540, 135, 540, 540, 270, 270, 270, 135, 540, 135, 270, 270, 135, 270, 135, 135, 270, 270, 540, 270, 135, 270, 540, 270, 270, 540, 270, 540, 135, 540, 540, 270, 135, 135, 540, 270, 135, 270, 270, 540, 270, 135, 135, 540, 540, 540, 540, 540, 540, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 540, 540, 135, 540, 135, 270, 540, 540, 540, 270, 135, 540, 270, 135, 135, 135, 135, 135, 540, 270, 135, 540, 135, 540, 135, 135, 270, 270, 540, 270, 540, 135, 270, 135, 540, 540, 135, 540, 270, 135, 540, 135, 135, 540, 540, 270, 540, 540, 135, 540, 270, 270, 135, 270, 540, 540, 135, 540, 270, 135, 270, 540, 135, 135, 135, 135, 135, 135, 540, 135, 135, 135, 540, 135, 270, 540, 540, 270, 135, 540, 135, 270, 270, 135, 270, 135, 540, 135, 135, 540, 135, 540, 540, 270, 540, 270, 135, 270, 540, 270, 540, 135, 540, 135, 270, 540, 270, 540, 270, 540, 270, 540, 270, 135, 540, 135, 540, 270, 270, 135, 270, 540, 270, 270, 540, 135, 540, 540, 270, 135, 540, 540, 270, 270, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 540, 135, 540, 270, 540, 540, 135, 540, 270, 270, 540, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 540, 270, 135, 135, 135, 135]
Prompts retrieved: 80865 . Total input tokens: 18009757 . Total output tokens: 15867329
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 3.812850866932422,
    "estimated_duration": 3599.7581208352817,
    "input_throughput": 1812.7165162102256,
    "output_throughput": 1579.026926031649,
    "total_throughput": 3391.7434422418746,
    "itl": 26.91959040220355,
    "ttft": 187064.64101606313,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3929,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 28.707070336820706,
    "arrivals": 27120,
    "finished_requests": 26404,
    "scheduler_time": 17.306654965719407
}
#Debug simulation 
Total elapsed time: 3.8129285806789994. Arrivals time: 0.07921568909659982 Scheduler time: 3.3695145901292562 Scheduler overhead time: 0.13697708863765 Adapter cache time: 0.03954619821161032 Engine time: 0.1287174802273512 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-32/adapters_256_slots_16_rate_0.05-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-32/adapters_256_slots_16_rate_0.05-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 540, 135, 540, 540, 135, 540, 270, 540, 135, 270, 135, 540, 270, 270, 270, 270, 540, 135, 135, 135, 270, 540, 135, 540, 540, 270, 270, 270, 135, 540, 135, 270, 270, 135, 270, 135, 135, 270, 270, 540, 270, 135, 270, 540, 270, 270, 540, 270, 540, 135, 540, 540, 270, 135, 135, 540, 270, 135, 270, 270, 540, 270, 135, 135, 540, 540, 540, 540, 540, 540, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 540, 540, 135, 540, 135, 270, 540, 540, 540, 270, 135, 540, 270, 135, 135, 135, 135, 135, 540, 270, 135, 540, 135, 540, 135, 135, 270, 270, 540, 270, 540, 135, 270, 135, 540, 540, 135, 540, 270, 135, 540, 135, 135, 540, 540, 270, 540, 540, 135, 540, 270, 270, 135, 270, 540, 540, 135, 540, 270, 135, 270, 540, 135, 135, 135, 135, 135, 135, 540, 135, 135, 135, 540, 135, 270, 540, 540, 270, 135, 540, 135, 270, 270, 135, 270, 135, 540, 135, 135, 540, 135, 540, 540, 270, 540, 270, 135, 270, 540, 270, 540, 135, 540, 135, 270, 540, 270, 540, 270, 540, 270, 540, 270, 135, 540, 135, 540, 270, 270, 135, 270, 540, 270, 270, 540, 135, 540, 540, 270, 135, 540, 540, 270, 270, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 540, 135, 540, 270, 540, 540, 135, 540, 270, 270, 540, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 540, 270, 135, 135, 135, 135]
Prompts retrieved: 80865 . Total input tokens: 18009757 . Total output tokens: 15867329
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 3.812882075086236,
    "estimated_duration": 3599.7554701070367,
    "input_throughput": 1814.0082164541677,
    "output_throughput": 1581.0037785235381,
    "total_throughput": 3395.011994977706,
    "itl": 26.9211055947106,
    "ttft": 184435.58486378824,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3950,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 29.638030159539824,
    "arrivals": 27120,
    "finished_requests": 26425,
    "scheduler_time": 17.33015397877875
}
#Debug simulation 
Total elapsed time: 3.813003691844642. Arrivals time: 0.08104595355689526 Scheduler time: 3.3667154451832175 Scheduler overhead time: 0.13736071484163404 Adapter cache time: 0.039617552887648344 Engine time: 0.12908561155200005 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-16/adapters_256_slots_16_rate_0.05-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-16/adapters_256_slots_16_rate_0.05-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 540, 135, 540, 540, 135, 540, 270, 540, 135, 270, 135, 540, 270, 270, 270, 270, 540, 135, 135, 135, 270, 540, 135, 540, 540, 270, 270, 270, 135, 540, 135, 270, 270, 135, 270, 135, 135, 270, 270, 540, 270, 135, 270, 540, 270, 270, 540, 270, 540, 135, 540, 540, 270, 135, 135, 540, 270, 135, 270, 270, 540, 270, 135, 135, 540, 540, 540, 540, 540, 540, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 540, 540, 135, 540, 135, 270, 540, 540, 540, 270, 135, 540, 270, 135, 135, 135, 135, 135, 540, 270, 135, 540, 135, 540, 135, 135, 270, 270, 540, 270, 540, 135, 270, 135, 540, 540, 135, 540, 270, 135, 540, 135, 135, 540, 540, 270, 540, 540, 135, 540, 270, 270, 135, 270, 540, 540, 135, 540, 270, 135, 270, 540, 135, 135, 135, 135, 135, 135, 540, 135, 135, 135, 540, 135, 270, 540, 540, 270, 135, 540, 135, 270, 270, 135, 270, 135, 540, 135, 135, 540, 135, 540, 540, 270, 540, 270, 135, 270, 540, 270, 540, 135, 540, 135, 270, 540, 270, 540, 270, 540, 270, 540, 270, 135, 540, 135, 540, 270, 270, 135, 270, 540, 270, 270, 540, 135, 540, 540, 270, 135, 540, 540, 270, 270, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 540, 135, 540, 270, 540, 540, 135, 540, 270, 270, 540, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 540, 270, 135, 135, 135, 135]
Prompts retrieved: 80865 . Total input tokens: 18009757 . Total output tokens: 15867329
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 3.8311756309121847,
    "estimated_duration": 3599.7542000957797,
    "input_throughput": 1813.4371507438784,
    "output_throughput": 1579.9317630766775,
    "total_throughput": 3393.368913820556,
    "itl": 26.902014386389414,
    "ttft": 186521.60800523622,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3935,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 26.915698619639358,
    "arrivals": 27120,
    "finished_requests": 26411,
    "scheduler_time": 17.369526716739767
}
#Debug simulation 
Total elapsed time: 3.8312576739117503. Arrivals time: 0.07945071021094918 Scheduler time: 3.386830721516162 Scheduler overhead time: 0.13754221331328154 Adapter cache time: 0.039887852035462856 Engine time: 0.1280783573165536 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-32/adapters_256_slots_16_rate_0.05-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-32/adapters_256_slots_16_rate_0.05-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 540, 135, 540, 540, 135, 540, 270, 540, 135, 270, 135, 540, 270, 270, 270, 270, 540, 135, 135, 135, 270, 540, 135, 540, 540, 270, 270, 270, 135, 540, 135, 270, 270, 135, 270, 135, 135, 270, 270, 540, 270, 135, 270, 540, 270, 270, 540, 270, 540, 135, 540, 540, 270, 135, 135, 540, 270, 135, 270, 270, 540, 270, 135, 135, 540, 540, 540, 540, 540, 540, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 540, 540, 135, 540, 135, 270, 540, 540, 540, 270, 135, 540, 270, 135, 135, 135, 135, 135, 540, 270, 135, 540, 135, 540, 135, 135, 270, 270, 540, 270, 540, 135, 270, 135, 540, 540, 135, 540, 270, 135, 540, 135, 135, 540, 540, 270, 540, 540, 135, 540, 270, 270, 135, 270, 540, 540, 135, 540, 270, 135, 270, 540, 135, 135, 135, 135, 135, 135, 540, 135, 135, 135, 540, 135, 270, 540, 540, 270, 135, 540, 135, 270, 270, 135, 270, 135, 540, 135, 135, 540, 135, 540, 540, 270, 540, 270, 135, 270, 540, 270, 540, 135, 540, 135, 270, 540, 270, 540, 270, 540, 270, 540, 270, 135, 540, 135, 540, 270, 270, 135, 270, 540, 270, 270, 540, 135, 540, 540, 270, 135, 540, 540, 270, 270, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 540, 135, 540, 270, 540, 540, 135, 540, 270, 270, 540, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 540, 270, 135, 135, 135, 135]
Prompts retrieved: 80865 . Total input tokens: 18009757 . Total output tokens: 15867329
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 3.7970664291642606,
    "estimated_duration": 3599.757946924147,
    "input_throughput": 1812.9241177386075,
    "output_throughput": 1580.2656967145986,
    "total_throughput": 3393.189814453206,
    "itl": 26.930062630520908,
    "ttft": 186222.04069786085,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3944,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 29.322392920214934,
    "arrivals": 27120,
    "finished_requests": 26411,
    "scheduler_time": 17.322490505645355
}
#Debug simulation 
Total elapsed time: 3.7971597779542208. Arrivals time: 0.08221817994490266 Scheduler time: 3.3475070293061435 Scheduler overhead time: 0.139926812145859 Adapter cache time: 0.039650367107242346 Engine time: 0.12840211065486073 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-16/adapters_256_slots_16_rate_0.05-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-16/adapters_256_slots_16_rate_0.05-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 540, 135, 540, 540, 135, 540, 270, 540, 135, 270, 135, 540, 270, 270, 270, 270, 540, 135, 135, 135, 270, 540, 135, 540, 540, 270, 270, 270, 135, 540, 135, 270, 270, 135, 270, 135, 135, 270, 270, 540, 270, 135, 270, 540, 270, 270, 540, 270, 540, 135, 540, 540, 270, 135, 135, 540, 270, 135, 270, 270, 540, 270, 135, 135, 540, 540, 540, 540, 540, 540, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 540, 540, 135, 540, 135, 270, 540, 540, 540, 270, 135, 540, 270, 135, 135, 135, 135, 135, 540, 270, 135, 540, 135, 540, 135, 135, 270, 270, 540, 270, 540, 135, 270, 135, 540, 540, 135, 540, 270, 135, 540, 135, 135, 540, 540, 270, 540, 540, 135, 540, 270, 270, 135, 270, 540, 540, 135, 540, 270, 135, 270, 540, 135, 135, 135, 135, 135, 135, 540, 135, 135, 135, 540, 135, 270, 540, 540, 270, 135, 540, 135, 270, 270, 135, 270, 135, 540, 135, 135, 540, 135, 540, 540, 270, 540, 270, 135, 270, 540, 270, 540, 135, 540, 135, 270, 540, 270, 540, 270, 540, 270, 540, 270, 135, 540, 135, 540, 270, 270, 135, 270, 540, 270, 270, 540, 135, 540, 540, 270, 135, 540, 540, 270, 270, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 540, 135, 540, 270, 540, 540, 135, 540, 270, 270, 540, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 540, 270, 135, 135, 135, 135]
Prompts retrieved: 80865 . Total input tokens: 18009757 . Total output tokens: 15867329
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 3.8259344836696982,
    "estimated_duration": 3599.7532029136864,
    "input_throughput": 1814.4546672569797,
    "output_throughput": 1579.899420714917,
    "total_throughput": 3394.3540879718967,
    "itl": 26.893168460273518,
    "ttft": 186148.93493436166,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3937,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 25.133496743028434,
    "arrivals": 27120,
    "finished_requests": 26411,
    "scheduler_time": 17.294481831914485
}
#Debug simulation 
Total elapsed time: 3.8260095100849867. Arrivals time: 0.07950720004737377 Scheduler time: 3.3800930017605424 Scheduler overhead time: 0.13856490654870868 Adapter cache time: 0.039797947742044926 Engine time: 0.12833158066496253 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-32/adapters_256_slots_16_rate_0.05-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-32/adapters_256_slots_16_rate_0.05-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 540, 135, 540, 540, 135, 540, 270, 540, 135, 270, 135, 540, 270, 270, 270, 270, 540, 135, 135, 135, 270, 540, 135, 540, 540, 270, 270, 270, 135, 540, 135, 270, 270, 135, 270, 135, 135, 270, 270, 540, 270, 135, 270, 540, 270, 270, 540, 270, 540, 135, 540, 540, 270, 135, 135, 540, 270, 135, 270, 270, 540, 270, 135, 135, 540, 540, 540, 540, 540, 540, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 540, 540, 135, 540, 135, 270, 540, 540, 540, 270, 135, 540, 270, 135, 135, 135, 135, 135, 540, 270, 135, 540, 135, 540, 135, 135, 270, 270, 540, 270, 540, 135, 270, 135, 540, 540, 135, 540, 270, 135, 540, 135, 135, 540, 540, 270, 540, 540, 135, 540, 270, 270, 135, 270, 540, 540, 135, 540, 270, 135, 270, 540, 135, 135, 135, 135, 135, 135, 540, 135, 135, 135, 540, 135, 270, 540, 540, 270, 135, 540, 135, 270, 270, 135, 270, 135, 540, 135, 135, 540, 135, 540, 540, 270, 540, 270, 135, 270, 540, 270, 540, 135, 540, 135, 270, 540, 270, 540, 270, 540, 270, 540, 270, 135, 540, 135, 540, 270, 270, 135, 270, 540, 270, 270, 540, 135, 540, 540, 270, 135, 540, 540, 270, 270, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 540, 135, 540, 270, 540, 540, 135, 540, 270, 270, 540, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 540, 270, 135, 135, 135, 135]
Prompts retrieved: 80865 . Total input tokens: 18009757 . Total output tokens: 15867329
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 3.786359202116728,
    "estimated_duration": 3599.733932271924,
    "input_throughput": 1813.3206850319277,
    "output_throughput": 1579.7439774697298,
    "total_throughput": 3393.0646625016575,
    "itl": 26.92975734085575,
    "ttft": 187917.30512296624,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3930,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 28.948774843552368,
    "arrivals": 27120,
    "finished_requests": 26402,
    "scheduler_time": 17.419338215071754
}
#Debug simulation 
Total elapsed time: 3.786453321110457. Arrivals time: 0.08134858077391982 Scheduler time: 3.3405750687234104 Scheduler overhead time: 0.13730449229478836 Adapter cache time: 0.039780520368367434 Engine time: 0.1281132185831666 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-8/adapters_256_slots_16_rate_0.05-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-8/adapters_256_slots_16_rate_0.05-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 540, 66, 540, 540, 66, 540, 270, 540, 66, 270, 66, 540, 270, 270, 270, 270, 540, 66, 66, 66, 270, 540, 66, 540, 540, 270, 270, 270, 66, 540, 66, 270, 270, 66, 270, 66, 66, 270, 270, 540, 270, 66, 270, 540, 270, 270, 540, 270, 540, 66, 540, 540, 270, 66, 66, 540, 270, 66, 270, 270, 540, 270, 66, 66, 540, 540, 540, 540, 540, 540, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 540, 540, 66, 540, 66, 270, 540, 540, 540, 270, 66, 540, 270, 66, 66, 66, 66, 66, 540, 270, 66, 540, 66, 540, 66, 66, 270, 270, 540, 270, 540, 66, 270, 66, 540, 540, 66, 540, 270, 66, 540, 66, 66, 540, 540, 270, 540, 540, 66, 540, 270, 270, 66, 270, 540, 540, 66, 540, 270, 66, 270, 540, 66, 66, 66, 66, 66, 66, 540, 66, 66, 66, 540, 66, 270, 540, 540, 270, 66, 540, 66, 270, 270, 66, 270, 66, 540, 66, 66, 540, 66, 540, 540, 270, 540, 270, 66, 270, 540, 270, 540, 66, 540, 66, 270, 540, 270, 540, 270, 540, 270, 540, 270, 66, 540, 66, 540, 270, 270, 66, 270, 540, 270, 270, 540, 66, 540, 540, 270, 66, 540, 540, 270, 270, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 540, 66, 540, 270, 540, 540, 66, 540, 270, 270, 540, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 540, 270, 66, 66, 66, 66]
Prompts retrieved: 75000 . Total input tokens: 16710763 . Total output tokens: 14711866
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 3.3166165347211063,
    "estimated_duration": 3600.009968036359,
    "input_throughput": 1688.774212843679,
    "output_throughput": 1470.3098177495215,
    "total_throughput": 3159.0840305932,
    "itl": 26.466620604957015,
    "ttft": 147550.56236273196,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4572,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 30.231934094072198,
    "arrivals": 25185,
    "finished_requests": 24643,
    "scheduler_time": 10.207514500955133
}
#Debug simulation 
Total elapsed time: 3.3166956841014326. Arrivals time: 0.07463707262650132 Scheduler time: 2.8723055440932512 Scheduler overhead time: 0.13817369332537055 Adapter cache time: 0.04264754708856344 Engine time: 0.1289210100658238 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-16/adapters_256_slots_16_rate_0.05-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-16/adapters_256_slots_16_rate_0.05-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 540, 66, 540, 540, 66, 540, 270, 540, 66, 270, 66, 540, 270, 270, 270, 270, 540, 66, 66, 66, 270, 540, 66, 540, 540, 270, 270, 270, 66, 540, 66, 270, 270, 66, 270, 66, 66, 270, 270, 540, 270, 66, 270, 540, 270, 270, 540, 270, 540, 66, 540, 540, 270, 66, 66, 540, 270, 66, 270, 270, 540, 270, 66, 66, 540, 540, 540, 540, 540, 540, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 540, 540, 66, 540, 66, 270, 540, 540, 540, 270, 66, 540, 270, 66, 66, 66, 66, 66, 540, 270, 66, 540, 66, 540, 66, 66, 270, 270, 540, 270, 540, 66, 270, 66, 540, 540, 66, 540, 270, 66, 540, 66, 66, 540, 540, 270, 540, 540, 66, 540, 270, 270, 66, 270, 540, 540, 66, 540, 270, 66, 270, 540, 66, 66, 66, 66, 66, 66, 540, 66, 66, 66, 540, 66, 270, 540, 540, 270, 66, 540, 66, 270, 270, 66, 270, 66, 540, 66, 66, 540, 66, 540, 540, 270, 540, 270, 66, 270, 540, 270, 540, 66, 540, 66, 270, 540, 270, 540, 270, 540, 270, 540, 270, 66, 540, 66, 540, 270, 270, 66, 270, 540, 270, 270, 540, 66, 540, 540, 270, 66, 540, 540, 270, 270, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 540, 66, 540, 270, 540, 540, 66, 540, 270, 270, 540, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 540, 270, 66, 66, 66, 66]
Prompts retrieved: 75000 . Total input tokens: 16710763 . Total output tokens: 14711866
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 3.2860550661571324,
    "estimated_duration": 3600.0013629324994,
    "input_throughput": 1688.4663052039996,
    "output_throughput": 1469.9902768062439,
    "total_throughput": 3158.4565820102434,
    "itl": 26.499102380843933,
    "ttft": 148266.76924025398,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4555,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 33.2892340963557,
    "arrivals": 25185,
    "finished_requests": 24639,
    "scheduler_time": 10.237872097478387
}
#Debug simulation 
Total elapsed time: 3.2861513318493962. Arrivals time: 0.0758683243766427 Scheduler time: 2.84286644263193 Scheduler overhead time: 0.13657690910622478 Adapter cache time: 0.042276880238205194 Engine time: 0.12862454308196902 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-32/adapters_256_slots_16_rate_0.05-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-32/adapters_256_slots_16_rate_0.05-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 540, 66, 540, 540, 66, 540, 270, 540, 66, 270, 66, 540, 270, 270, 270, 270, 540, 66, 66, 66, 270, 540, 66, 540, 540, 270, 270, 270, 66, 540, 66, 270, 270, 66, 270, 66, 66, 270, 270, 540, 270, 66, 270, 540, 270, 270, 540, 270, 540, 66, 540, 540, 270, 66, 66, 540, 270, 66, 270, 270, 540, 270, 66, 66, 540, 540, 540, 540, 540, 540, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 540, 540, 66, 540, 66, 270, 540, 540, 540, 270, 66, 540, 270, 66, 66, 66, 66, 66, 540, 270, 66, 540, 66, 540, 66, 66, 270, 270, 540, 270, 540, 66, 270, 66, 540, 540, 66, 540, 270, 66, 540, 66, 66, 540, 540, 270, 540, 540, 66, 540, 270, 270, 66, 270, 540, 540, 66, 540, 270, 66, 270, 540, 66, 66, 66, 66, 66, 66, 540, 66, 66, 66, 540, 66, 270, 540, 540, 270, 66, 540, 66, 270, 270, 66, 270, 66, 540, 66, 66, 540, 66, 540, 540, 270, 540, 270, 66, 270, 540, 270, 540, 66, 540, 66, 270, 540, 270, 540, 270, 540, 270, 540, 270, 66, 540, 66, 540, 270, 270, 66, 270, 540, 270, 270, 540, 66, 540, 540, 270, 66, 540, 540, 270, 270, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 540, 66, 540, 270, 540, 540, 66, 540, 270, 270, 540, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 540, 270, 66, 66, 66, 66]
Prompts retrieved: 75000 . Total input tokens: 16710763 . Total output tokens: 14711866
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 3.334441299084574,
    "estimated_duration": 3600.000918478154,
    "input_throughput": 1687.581236109306,
    "output_throughput": 1469.7826805657546,
    "total_throughput": 3157.363916675061,
    "itl": 26.503229949376472,
    "ttft": 149364.58986903922,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4555,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 34.190837303661844,
    "arrivals": 25185,
    "finished_requests": 24632,
    "scheduler_time": 10.250075183548391
}
#Debug simulation 
Total elapsed time: 3.334548231214285. Arrivals time: 0.07521226117387414 Scheduler time: 2.888027337845415 Scheduler overhead time: 0.13827010616660118 Adapter cache time: 0.042692305985838175 Engine time: 0.13025347515940666 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-16/adapters_256_slots_16_rate_0.05-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-16/adapters_256_slots_16_rate_0.05-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 540, 66, 540, 540, 66, 540, 270, 540, 66, 270, 66, 540, 270, 270, 270, 270, 540, 66, 66, 66, 270, 540, 66, 540, 540, 270, 270, 270, 66, 540, 66, 270, 270, 66, 270, 66, 66, 270, 270, 540, 270, 66, 270, 540, 270, 270, 540, 270, 540, 66, 540, 540, 270, 66, 66, 540, 270, 66, 270, 270, 540, 270, 66, 66, 540, 540, 540, 540, 540, 540, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 540, 540, 66, 540, 66, 270, 540, 540, 540, 270, 66, 540, 270, 66, 66, 66, 66, 66, 540, 270, 66, 540, 66, 540, 66, 66, 270, 270, 540, 270, 540, 66, 270, 66, 540, 540, 66, 540, 270, 66, 540, 66, 66, 540, 540, 270, 540, 540, 66, 540, 270, 270, 66, 270, 540, 540, 66, 540, 270, 66, 270, 540, 66, 66, 66, 66, 66, 66, 540, 66, 66, 66, 540, 66, 270, 540, 540, 270, 66, 540, 66, 270, 270, 66, 270, 66, 540, 66, 66, 540, 66, 540, 540, 270, 540, 270, 66, 270, 540, 270, 540, 66, 540, 66, 270, 540, 270, 540, 270, 540, 270, 540, 270, 66, 540, 66, 540, 270, 270, 66, 270, 540, 270, 270, 540, 66, 540, 540, 270, 66, 540, 540, 270, 270, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 540, 66, 540, 270, 540, 540, 66, 540, 270, 270, 540, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 540, 270, 66, 66, 66, 66]
Prompts retrieved: 75000 . Total input tokens: 16710763 . Total output tokens: 14711866
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 3.3299446403980255,
    "estimated_duration": 3600.0272101833775,
    "input_throughput": 1689.0375113832176,
    "output_throughput": 1470.8283273587488,
    "total_throughput": 3159.8658387419664,
    "itl": 26.472216308647027,
    "ttft": 147159.40287484467,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4577,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 31.329302024427818,
    "arrivals": 25185,
    "finished_requests": 24645,
    "scheduler_time": 10.20031255073382
}
#Debug simulation 
Total elapsed time: 3.330055008176714. Arrivals time: 0.07643312634900212 Scheduler time: 2.880672655533999 Scheduler overhead time: 0.1369516090489924 Adapter cache time: 0.04277619067579508 Engine time: 0.13320653839036822 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-32/adapters_256_slots_16_rate_0.05-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-32/adapters_256_slots_16_rate_0.05-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 540, 66, 540, 540, 66, 540, 270, 540, 66, 270, 66, 540, 270, 270, 270, 270, 540, 66, 66, 66, 270, 540, 66, 540, 540, 270, 270, 270, 66, 540, 66, 270, 270, 66, 270, 66, 66, 270, 270, 540, 270, 66, 270, 540, 270, 270, 540, 270, 540, 66, 540, 540, 270, 66, 66, 540, 270, 66, 270, 270, 540, 270, 66, 66, 540, 540, 540, 540, 540, 540, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 540, 540, 66, 540, 66, 270, 540, 540, 540, 270, 66, 540, 270, 66, 66, 66, 66, 66, 540, 270, 66, 540, 66, 540, 66, 66, 270, 270, 540, 270, 540, 66, 270, 66, 540, 540, 66, 540, 270, 66, 540, 66, 66, 540, 540, 270, 540, 540, 66, 540, 270, 270, 66, 270, 540, 540, 66, 540, 270, 66, 270, 540, 66, 66, 66, 66, 66, 66, 540, 66, 66, 66, 540, 66, 270, 540, 540, 270, 66, 540, 66, 270, 270, 66, 270, 66, 540, 66, 66, 540, 66, 540, 540, 270, 540, 270, 66, 270, 540, 270, 540, 66, 540, 66, 270, 540, 270, 540, 270, 540, 270, 540, 270, 66, 540, 66, 540, 270, 270, 66, 270, 540, 270, 270, 540, 66, 540, 540, 270, 66, 540, 540, 270, 270, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 540, 66, 540, 270, 540, 540, 66, 540, 270, 270, 540, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 540, 270, 66, 66, 66, 66]
Prompts retrieved: 75000 . Total input tokens: 16710763 . Total output tokens: 14711866
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 3.34638713626191,
    "estimated_duration": 3600.0150802923454,
    "input_throughput": 1688.7532036411083,
    "output_throughput": 1470.7849500369377,
    "total_throughput": 3159.538153678046,
    "itl": 26.506356736102962,
    "ttft": 148130.0979140268,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4545,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 33.79225508303494,
    "arrivals": 25185,
    "finished_requests": 24642,
    "scheduler_time": 10.304429363043232
}
#Debug simulation 
Total elapsed time: 3.346464464906603. Arrivals time: 0.07500260369852185 Scheduler time: 2.90086882840842 Scheduler overhead time: 0.1374908247962594 Adapter cache time: 0.042581882793456316 Engine time: 0.1308163721114397 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-16/adapters_256_slots_16_rate_0.05-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-16/adapters_256_slots_16_rate_0.05-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 540, 66, 540, 540, 66, 540, 270, 540, 66, 270, 66, 540, 270, 270, 270, 270, 540, 66, 66, 66, 270, 540, 66, 540, 540, 270, 270, 270, 66, 540, 66, 270, 270, 66, 270, 66, 66, 270, 270, 540, 270, 66, 270, 540, 270, 270, 540, 270, 540, 66, 540, 540, 270, 66, 66, 540, 270, 66, 270, 270, 540, 270, 66, 66, 540, 540, 540, 540, 540, 540, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 540, 540, 66, 540, 66, 270, 540, 540, 540, 270, 66, 540, 270, 66, 66, 66, 66, 66, 540, 270, 66, 540, 66, 540, 66, 66, 270, 270, 540, 270, 540, 66, 270, 66, 540, 540, 66, 540, 270, 66, 540, 66, 66, 540, 540, 270, 540, 540, 66, 540, 270, 270, 66, 270, 540, 540, 66, 540, 270, 66, 270, 540, 66, 66, 66, 66, 66, 66, 540, 66, 66, 66, 540, 66, 270, 540, 540, 270, 66, 540, 66, 270, 270, 66, 270, 66, 540, 66, 66, 540, 66, 540, 540, 270, 540, 270, 66, 270, 540, 270, 540, 66, 540, 66, 270, 540, 270, 540, 270, 540, 270, 540, 270, 66, 540, 66, 540, 270, 270, 66, 270, 540, 270, 270, 540, 66, 540, 540, 270, 66, 540, 540, 270, 270, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 540, 66, 540, 270, 540, 540, 66, 540, 270, 270, 540, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 540, 270, 66, 66, 66, 66]
Prompts retrieved: 75000 . Total input tokens: 16710763 . Total output tokens: 14711866
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 3.292806482873857,
    "estimated_duration": 3600.012309129622,
    "input_throughput": 1689.92616624438,
    "output_throughput": 1470.676915902003,
    "total_throughput": 3160.603082146383,
    "itl": 26.46134550922846,
    "ttft": 146116.48997768923,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4566,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 29.148983014647836,
    "arrivals": 25185,
    "finished_requests": 24656,
    "scheduler_time": 10.271569721879285
}
#Debug simulation 
Total elapsed time: 3.2929026219062507. Arrivals time: 0.07559873117133975 Scheduler time: 2.8492227708920836 Scheduler overhead time: 0.13676110468804836 Adapter cache time: 0.04251813795417547 Engine time: 0.12882727477699518 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-32/adapters_256_slots_16_rate_0.05-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-32/adapters_256_slots_16_rate_0.05-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 540, 66, 540, 540, 66, 540, 270, 540, 66, 270, 66, 540, 270, 270, 270, 270, 540, 66, 66, 66, 270, 540, 66, 540, 540, 270, 270, 270, 66, 540, 66, 270, 270, 66, 270, 66, 66, 270, 270, 540, 270, 66, 270, 540, 270, 270, 540, 270, 540, 66, 540, 540, 270, 66, 66, 540, 270, 66, 270, 270, 540, 270, 66, 66, 540, 540, 540, 540, 540, 540, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 540, 540, 66, 540, 66, 270, 540, 540, 540, 270, 66, 540, 270, 66, 66, 66, 66, 66, 540, 270, 66, 540, 66, 540, 66, 66, 270, 270, 540, 270, 540, 66, 270, 66, 540, 540, 66, 540, 270, 66, 540, 66, 66, 540, 540, 270, 540, 540, 66, 540, 270, 270, 66, 270, 540, 540, 66, 540, 270, 66, 270, 540, 66, 66, 66, 66, 66, 66, 540, 66, 66, 66, 540, 66, 270, 540, 540, 270, 66, 540, 66, 270, 270, 66, 270, 66, 540, 66, 66, 540, 66, 540, 540, 270, 540, 270, 66, 270, 540, 270, 540, 66, 540, 66, 270, 540, 270, 540, 270, 540, 270, 540, 270, 66, 540, 66, 540, 270, 270, 66, 270, 540, 270, 270, 540, 66, 540, 540, 270, 66, 540, 540, 270, 270, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 540, 66, 540, 270, 540, 540, 66, 540, 270, 270, 540, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 540, 270, 66, 66, 66, 66]
Prompts retrieved: 75000 . Total input tokens: 16710763 . Total output tokens: 14711866
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 3.314433317165822,
    "estimated_duration": 3600.004580597949,
    "input_throughput": 1688.5289626465826,
    "output_throughput": 1469.9895184913962,
    "total_throughput": 3158.5184811379786,
    "itl": 26.500366545884866,
    "ttft": 148134.02376890124,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4555,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 33.5575244878058,
    "arrivals": 25185,
    "finished_requests": 24640,
    "scheduler_time": 10.24012661002671
}
#Debug simulation 
Total elapsed time: 3.3145355829037726. Arrivals time: 0.07730347849428654 Scheduler time: 2.86804898455739 Scheduler overhead time: 0.13768812408670783 Adapter cache time: 0.042631753254681826 Engine time: 0.12884625559672713 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-8/adapters_256_slots_16_rate_0.05-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-8/adapters_256_slots_16_rate_0.05-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 540, 33, 540, 540, 33, 540, 270, 540, 33, 270, 33, 540, 270, 270, 270, 270, 540, 33, 33, 33, 270, 540, 33, 540, 540, 270, 270, 270, 33, 540, 33, 270, 270, 33, 270, 33, 33, 270, 270, 540, 270, 33, 270, 540, 270, 270, 540, 270, 540, 33, 540, 540, 270, 33, 33, 540, 270, 33, 270, 270, 540, 270, 33, 33, 540, 540, 540, 540, 540, 540, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 540, 540, 33, 540, 33, 270, 540, 540, 540, 270, 33, 540, 270, 33, 33, 33, 33, 33, 540, 270, 33, 540, 33, 540, 33, 33, 270, 270, 540, 270, 540, 33, 270, 33, 540, 540, 33, 540, 270, 33, 540, 33, 33, 540, 540, 270, 540, 540, 33, 540, 270, 270, 33, 270, 540, 540, 33, 540, 270, 33, 270, 540, 33, 33, 33, 33, 33, 33, 540, 33, 33, 33, 540, 33, 270, 540, 540, 270, 33, 540, 33, 270, 270, 33, 270, 33, 540, 33, 33, 540, 33, 540, 540, 270, 540, 270, 33, 270, 540, 270, 540, 33, 540, 33, 270, 540, 270, 540, 270, 540, 270, 540, 270, 33, 540, 33, 540, 270, 270, 33, 270, 540, 270, 270, 540, 33, 540, 540, 270, 33, 540, 540, 270, 270, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 540, 33, 540, 270, 540, 540, 33, 540, 270, 270, 540, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 540, 270, 33, 33, 33, 33]
Prompts retrieved: 72195 . Total input tokens: 16066339 . Total output tokens: 14169011
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 3.1254990566521883,
    "estimated_duration": 3599.874904809558,
    "input_throughput": 1623.9455966065764,
    "output_throughput": 1412.9652097644455,
    "total_throughput": 3036.910806371022,
    "itl": 26.239731275243297,
    "ttft": 144097.74967026222,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4278,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 28.287885838679376,
    "arrivals": 24188,
    "finished_requests": 23666,
    "scheduler_time": 8.161679177413472
}
#Debug simulation 
Total elapsed time: 3.125594652723521. Arrivals time: 0.07366271922364831 Scheduler time: 2.682427323423326 Scheduler overhead time: 0.13835322810336947 Adapter cache time: 0.04123923322185874 Engine time: 0.12966476427391171 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-16/adapters_256_slots_16_rate_0.05-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-16/adapters_256_slots_16_rate_0.05-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 540, 33, 540, 540, 33, 540, 270, 540, 33, 270, 33, 540, 270, 270, 270, 270, 540, 33, 33, 33, 270, 540, 33, 540, 540, 270, 270, 270, 33, 540, 33, 270, 270, 33, 270, 33, 33, 270, 270, 540, 270, 33, 270, 540, 270, 270, 540, 270, 540, 33, 540, 540, 270, 33, 33, 540, 270, 33, 270, 270, 540, 270, 33, 33, 540, 540, 540, 540, 540, 540, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 540, 540, 33, 540, 33, 270, 540, 540, 540, 270, 33, 540, 270, 33, 33, 33, 33, 33, 540, 270, 33, 540, 33, 540, 33, 33, 270, 270, 540, 270, 540, 33, 270, 33, 540, 540, 33, 540, 270, 33, 540, 33, 33, 540, 540, 270, 540, 540, 33, 540, 270, 270, 33, 270, 540, 540, 33, 540, 270, 33, 270, 540, 33, 33, 33, 33, 33, 33, 540, 33, 33, 33, 540, 33, 270, 540, 540, 270, 33, 540, 33, 270, 270, 33, 270, 33, 540, 33, 33, 540, 33, 540, 540, 270, 540, 270, 33, 270, 540, 270, 540, 33, 540, 33, 270, 540, 270, 540, 270, 540, 270, 540, 270, 33, 540, 33, 540, 270, 270, 33, 270, 540, 270, 270, 540, 33, 540, 540, 270, 33, 540, 540, 270, 270, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 540, 33, 540, 270, 540, 540, 33, 540, 270, 270, 540, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 540, 270, 33, 33, 33, 33]
Prompts retrieved: 72195 . Total input tokens: 16066339 . Total output tokens: 14169011
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 3.0698536708950996,
    "estimated_duration": 3599.865562398014,
    "input_throughput": 1624.4159396065413,
    "output_throughput": 1412.727756592182,
    "total_throughput": 3037.1436961987233,
    "itl": 26.25156222908487,
    "ttft": 137794.43875569894,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4653,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 34.007869153743535,
    "arrivals": 24188,
    "finished_requests": 23670,
    "scheduler_time": 7.163430349100852
}
#Debug simulation 
Total elapsed time: 3.0699453060515225. Arrivals time: 0.07286500837653875 Scheduler time: 2.6265894677489996 Scheduler overhead time: 0.13727018609642982 Adapter cache time: 0.0431996351107955 Engine time: 0.1297444007359445 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-32/adapters_256_slots_16_rate_0.05-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-32/adapters_256_slots_16_rate_0.05-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 540, 33, 540, 540, 33, 540, 270, 540, 33, 270, 33, 540, 270, 270, 270, 270, 540, 33, 33, 33, 270, 540, 33, 540, 540, 270, 270, 270, 33, 540, 33, 270, 270, 33, 270, 33, 33, 270, 270, 540, 270, 33, 270, 540, 270, 270, 540, 270, 540, 33, 540, 540, 270, 33, 33, 540, 270, 33, 270, 270, 540, 270, 33, 33, 540, 540, 540, 540, 540, 540, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 540, 540, 33, 540, 33, 270, 540, 540, 540, 270, 33, 540, 270, 33, 33, 33, 33, 33, 540, 270, 33, 540, 33, 540, 33, 33, 270, 270, 540, 270, 540, 33, 270, 33, 540, 540, 33, 540, 270, 33, 540, 33, 33, 540, 540, 270, 540, 540, 33, 540, 270, 270, 33, 270, 540, 540, 33, 540, 270, 33, 270, 540, 33, 33, 33, 33, 33, 33, 540, 33, 33, 33, 540, 33, 270, 540, 540, 270, 33, 540, 33, 270, 270, 33, 270, 33, 540, 33, 33, 540, 33, 540, 540, 270, 540, 270, 33, 270, 540, 270, 540, 33, 540, 33, 270, 540, 270, 540, 270, 540, 270, 540, 270, 33, 540, 33, 540, 270, 270, 33, 270, 540, 270, 270, 540, 33, 540, 540, 270, 33, 540, 540, 270, 270, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 540, 33, 540, 270, 540, 540, 33, 540, 270, 270, 540, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 540, 270, 33, 33, 33, 33]
Prompts retrieved: 72195 . Total input tokens: 16066339 . Total output tokens: 14169011
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 3.0836746231652796,
    "estimated_duration": 3599.8829779923026,
    "input_throughput": 1625.365612096436,
    "output_throughput": 1413.3378865658447,
    "total_throughput": 3038.7034986622807,
    "itl": 26.268729913689043,
    "ttft": 134548.35544932212,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4646,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 34.86936936964374,
    "arrivals": 24188,
    "finished_requests": 23692,
    "scheduler_time": 7.168599856067251
}
#Debug simulation 
Total elapsed time: 3.083766857162118. Arrivals time: 0.07592359557747841 Scheduler time: 2.637924739625305 Scheduler overhead time: 0.13776184618473053 Adapter cache time: 0.04299476929008961 Engine time: 0.12908156169578433 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-16/adapters_256_slots_16_rate_0.05-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-16/adapters_256_slots_16_rate_0.05-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 540, 33, 540, 540, 33, 540, 270, 540, 33, 270, 33, 540, 270, 270, 270, 270, 540, 33, 33, 33, 270, 540, 33, 540, 540, 270, 270, 270, 33, 540, 33, 270, 270, 33, 270, 33, 33, 270, 270, 540, 270, 33, 270, 540, 270, 270, 540, 270, 540, 33, 540, 540, 270, 33, 33, 540, 270, 33, 270, 270, 540, 270, 33, 33, 540, 540, 540, 540, 540, 540, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 540, 540, 33, 540, 33, 270, 540, 540, 540, 270, 33, 540, 270, 33, 33, 33, 33, 33, 540, 270, 33, 540, 33, 540, 33, 33, 270, 270, 540, 270, 540, 33, 270, 33, 540, 540, 33, 540, 270, 33, 540, 33, 33, 540, 540, 270, 540, 540, 33, 540, 270, 270, 33, 270, 540, 540, 33, 540, 270, 33, 270, 540, 33, 33, 33, 33, 33, 33, 540, 33, 33, 33, 540, 33, 270, 540, 540, 270, 33, 540, 33, 270, 270, 33, 270, 33, 540, 33, 33, 540, 33, 540, 540, 270, 540, 270, 33, 270, 540, 270, 540, 33, 540, 33, 270, 540, 270, 540, 270, 540, 270, 540, 270, 33, 540, 33, 540, 270, 270, 33, 270, 540, 270, 270, 540, 33, 540, 540, 270, 33, 540, 540, 270, 270, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 540, 33, 540, 270, 540, 540, 33, 540, 270, 270, 540, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 540, 270, 33, 33, 33, 33]
Prompts retrieved: 72195 . Total input tokens: 16066339 . Total output tokens: 14169011
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 3.077037296257913,
    "estimated_duration": 3599.8835941854454,
    "input_throughput": 1623.4316602457734,
    "output_throughput": 1412.4051144910648,
    "total_throughput": 3035.8367747368384,
    "itl": 26.239853749411747,
    "ttft": 138408.60945027755,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4651,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 31.835029477389575,
    "arrivals": 24188,
    "finished_requests": 23665,
    "scheduler_time": 7.128439212209489
}
#Debug simulation 
Total elapsed time: 3.0771336792968214. Arrivals time: 0.07397406361997128 Scheduler time: 2.6288695228286088 Scheduler overhead time: 0.1409488944336772 Adapter cache time: 0.043047480285167694 Engine time: 0.12992271780967712 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-32/adapters_256_slots_16_rate_0.05-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-32/adapters_256_slots_16_rate_0.05-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 540, 33, 540, 540, 33, 540, 270, 540, 33, 270, 33, 540, 270, 270, 270, 270, 540, 33, 33, 33, 270, 540, 33, 540, 540, 270, 270, 270, 33, 540, 33, 270, 270, 33, 270, 33, 33, 270, 270, 540, 270, 33, 270, 540, 270, 270, 540, 270, 540, 33, 540, 540, 270, 33, 33, 540, 270, 33, 270, 270, 540, 270, 33, 33, 540, 540, 540, 540, 540, 540, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 540, 540, 33, 540, 33, 270, 540, 540, 540, 270, 33, 540, 270, 33, 33, 33, 33, 33, 540, 270, 33, 540, 33, 540, 33, 33, 270, 270, 540, 270, 540, 33, 270, 33, 540, 540, 33, 540, 270, 33, 540, 33, 33, 540, 540, 270, 540, 540, 33, 540, 270, 270, 33, 270, 540, 540, 33, 540, 270, 33, 270, 540, 33, 33, 33, 33, 33, 33, 540, 33, 33, 33, 540, 33, 270, 540, 540, 270, 33, 540, 33, 270, 270, 33, 270, 33, 540, 33, 33, 540, 33, 540, 540, 270, 540, 270, 33, 270, 540, 270, 540, 33, 540, 33, 270, 540, 270, 540, 270, 540, 270, 540, 270, 33, 540, 33, 540, 270, 270, 33, 270, 540, 270, 270, 540, 33, 540, 540, 270, 33, 540, 540, 270, 270, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 540, 33, 540, 270, 540, 540, 33, 540, 270, 270, 540, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 540, 270, 33, 33, 33, 33]
Prompts retrieved: 72195 . Total input tokens: 16066339 . Total output tokens: 14169011
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 3.062710478901863,
    "estimated_duration": 3599.8605646779197,
    "input_throughput": 1624.302634766954,
    "output_throughput": 1412.6302695990616,
    "total_throughput": 3036.932904366016,
    "itl": 26.2702710006077,
    "ttft": 136607.3704489024,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4649,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 34.57023580808757,
    "arrivals": 24188,
    "finished_requests": 23679,
    "scheduler_time": 7.1895673608016155
}
#Debug simulation 
Total elapsed time: 3.0627897367812693. Arrivals time: 0.072092164773494 Scheduler time: 2.6188455149531364 Scheduler overhead time: 0.13921676250174642 Adapter cache time: 0.04312964389100671 Engine time: 0.12917356519028544 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-16/adapters_256_slots_16_rate_0.05-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-16/adapters_256_slots_16_rate_0.05-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 540, 33, 540, 540, 33, 540, 270, 540, 33, 270, 33, 540, 270, 270, 270, 270, 540, 33, 33, 33, 270, 540, 33, 540, 540, 270, 270, 270, 33, 540, 33, 270, 270, 33, 270, 33, 33, 270, 270, 540, 270, 33, 270, 540, 270, 270, 540, 270, 540, 33, 540, 540, 270, 33, 33, 540, 270, 33, 270, 270, 540, 270, 33, 33, 540, 540, 540, 540, 540, 540, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 540, 540, 33, 540, 33, 270, 540, 540, 540, 270, 33, 540, 270, 33, 33, 33, 33, 33, 540, 270, 33, 540, 33, 540, 33, 33, 270, 270, 540, 270, 540, 33, 270, 33, 540, 540, 33, 540, 270, 33, 540, 33, 33, 540, 540, 270, 540, 540, 33, 540, 270, 270, 33, 270, 540, 540, 33, 540, 270, 33, 270, 540, 33, 33, 33, 33, 33, 33, 540, 33, 33, 33, 540, 33, 270, 540, 540, 270, 33, 540, 33, 270, 270, 33, 270, 33, 540, 33, 33, 540, 33, 540, 540, 270, 540, 270, 33, 270, 540, 270, 540, 33, 540, 33, 270, 540, 270, 540, 270, 540, 270, 540, 270, 33, 540, 33, 540, 270, 270, 33, 270, 540, 270, 270, 540, 33, 540, 540, 270, 33, 540, 540, 270, 270, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 540, 33, 540, 270, 540, 540, 33, 540, 270, 270, 540, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 540, 270, 33, 33, 33, 33]
Prompts retrieved: 72195 . Total input tokens: 16066339 . Total output tokens: 14169011
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 3.070863428991288,
    "estimated_duration": 3599.8599900079766,
    "input_throughput": 1624.5892940928074,
    "output_throughput": 1413.1196807986769,
    "total_throughput": 3037.7089748914846,
    "itl": 26.215482726251793,
    "ttft": 135748.43391449348,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4662,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 29.76183942494269,
    "arrivals": 24188,
    "finished_requests": 23681,
    "scheduler_time": 7.075391121961483
}
#Debug simulation 
Total elapsed time: 3.0709532010369003. Arrivals time: 0.07344948593527079 Scheduler time: 2.6261398000642657 Scheduler overhead time: 0.13789995340630412 Adapter cache time: 0.04294680804014206 Engine time: 0.13021463993936777 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-32/adapters_256_slots_16_rate_0.05-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-32/adapters_256_slots_16_rate_0.05-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 540, 33, 540, 540, 33, 540, 270, 540, 33, 270, 33, 540, 270, 270, 270, 270, 540, 33, 33, 33, 270, 540, 33, 540, 540, 270, 270, 270, 33, 540, 33, 270, 270, 33, 270, 33, 33, 270, 270, 540, 270, 33, 270, 540, 270, 270, 540, 270, 540, 33, 540, 540, 270, 33, 33, 540, 270, 33, 270, 270, 540, 270, 33, 33, 540, 540, 540, 540, 540, 540, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 540, 540, 33, 540, 33, 270, 540, 540, 540, 270, 33, 540, 270, 33, 33, 33, 33, 33, 540, 270, 33, 540, 33, 540, 33, 33, 270, 270, 540, 270, 540, 33, 270, 33, 540, 540, 33, 540, 270, 33, 540, 33, 33, 540, 540, 270, 540, 540, 33, 540, 270, 270, 33, 270, 540, 540, 33, 540, 270, 33, 270, 540, 33, 33, 33, 33, 33, 33, 540, 33, 33, 33, 540, 33, 270, 540, 540, 270, 33, 540, 33, 270, 270, 33, 270, 33, 540, 33, 33, 540, 33, 540, 540, 270, 540, 270, 33, 270, 540, 270, 540, 33, 540, 33, 270, 540, 270, 540, 270, 540, 270, 540, 270, 33, 540, 33, 540, 270, 270, 33, 270, 540, 270, 270, 540, 33, 540, 540, 270, 33, 540, 540, 270, 270, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 540, 33, 540, 270, 540, 540, 33, 540, 270, 270, 540, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 540, 270, 33, 33, 33, 33]
Prompts retrieved: 72195 . Total input tokens: 16066339 . Total output tokens: 14169011
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 3.089756930246949,
    "estimated_duration": 3599.862710783704,
    "input_throughput": 1625.3858744313552,
    "output_throughput": 1412.7605435521773,
    "total_throughput": 3038.1464179835325,
    "itl": 26.259934784884127,
    "ttft": 136747.56103352128,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4631,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 34.118022928332145,
    "arrivals": 24188,
    "finished_requests": 23678,
    "scheduler_time": 7.187800542929498
}
#Debug simulation 
Total elapsed time: 3.0898360130377114. Arrivals time: 0.07256992487236857 Scheduler time: 2.6473120129667222 Scheduler overhead time: 0.13764607533812523 Adapter cache time: 0.04283258970826864 Engine time: 0.1292635672725737 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-8/adapters_256_slots_16_rate_0.05-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-8/adapters_256_slots_16_rate_0.05-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 540, 66, 540, 540, 66, 540, 135, 540, 66, 135, 66, 540, 135, 135, 135, 135, 540, 66, 66, 66, 135, 540, 66, 540, 540, 135, 135, 135, 66, 540, 66, 135, 135, 66, 135, 66, 66, 135, 135, 540, 135, 66, 135, 540, 135, 135, 540, 135, 540, 66, 540, 540, 135, 66, 66, 540, 135, 66, 135, 135, 540, 135, 66, 66, 540, 540, 540, 540, 540, 540, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 540, 540, 66, 540, 66, 135, 540, 540, 540, 135, 66, 540, 135, 66, 66, 66, 66, 66, 540, 135, 66, 540, 66, 540, 66, 66, 135, 135, 540, 135, 540, 66, 135, 66, 540, 540, 66, 540, 135, 66, 540, 66, 66, 540, 540, 135, 540, 540, 66, 540, 135, 135, 66, 135, 540, 540, 66, 540, 135, 66, 135, 540, 66, 66, 66, 66, 66, 66, 540, 66, 66, 66, 540, 66, 135, 540, 540, 135, 66, 540, 66, 135, 135, 66, 135, 66, 540, 66, 66, 540, 66, 540, 540, 135, 540, 135, 66, 135, 540, 135, 540, 66, 540, 66, 135, 540, 135, 540, 135, 540, 135, 540, 135, 66, 540, 66, 540, 135, 135, 66, 135, 540, 135, 135, 540, 66, 540, 540, 135, 66, 540, 540, 135, 135, 540, 540, 135, 135, 135, 135, 540, 540, 135, 135, 540, 66, 540, 135, 540, 540, 66, 540, 135, 135, 540, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 540, 135, 66, 66, 66, 66]
Prompts retrieved: 63525 . Total input tokens: 14115173 . Total output tokens: 12494728
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 2.7239070241339505,
    "estimated_duration": 3599.9560580607467,
    "input_throughput": 1424.4193310410321,
    "output_throughput": 1247.0588328287438,
    "total_throughput": 2671.478163869776,
    "itl": 25.680623655932674,
    "ttft": 111044.54124238514,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5314,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 35.13834159577958,
    "arrivals": 21245,
    "finished_requests": 20908,
    "scheduler_time": 2.538093693537192
}
#Debug simulation 
Total elapsed time: 2.7240120023489. Arrivals time: 0.06834583589807153 Scheduler time: 2.277924982365221 Scheduler overhead time: 0.1395743819884956 Adapter cache time: 0.04605914419516921 Engine time: 0.13091614609584212 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-16/adapters_256_slots_16_rate_0.05-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-16/adapters_256_slots_16_rate_0.05-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 540, 66, 540, 540, 66, 540, 135, 540, 66, 135, 66, 540, 135, 135, 135, 135, 540, 66, 66, 66, 135, 540, 66, 540, 540, 135, 135, 135, 66, 540, 66, 135, 135, 66, 135, 66, 66, 135, 135, 540, 135, 66, 135, 540, 135, 135, 540, 135, 540, 66, 540, 540, 135, 66, 66, 540, 135, 66, 135, 135, 540, 135, 66, 66, 540, 540, 540, 540, 540, 540, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 540, 540, 66, 540, 66, 135, 540, 540, 540, 135, 66, 540, 135, 66, 66, 66, 66, 66, 540, 135, 66, 540, 66, 540, 66, 66, 135, 135, 540, 135, 540, 66, 135, 66, 540, 540, 66, 540, 135, 66, 540, 66, 66, 540, 540, 135, 540, 540, 66, 540, 135, 135, 66, 135, 540, 540, 66, 540, 135, 66, 135, 540, 66, 66, 66, 66, 66, 66, 540, 66, 66, 66, 540, 66, 135, 540, 540, 135, 66, 540, 66, 135, 135, 66, 135, 66, 540, 66, 66, 540, 66, 540, 540, 135, 540, 135, 66, 135, 540, 135, 540, 66, 540, 66, 135, 540, 135, 540, 135, 540, 135, 540, 135, 66, 540, 66, 540, 135, 135, 66, 135, 540, 135, 135, 540, 66, 540, 540, 135, 66, 540, 540, 135, 135, 540, 540, 135, 135, 135, 135, 540, 540, 135, 135, 540, 66, 540, 135, 540, 540, 66, 540, 135, 135, 540, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 540, 135, 66, 66, 66, 66]
Prompts retrieved: 63525 . Total input tokens: 14115173 . Total output tokens: 12494728
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 2.728476737625897,
    "estimated_duration": 3599.9606160963476,
    "input_throughput": 1424.0414123082721,
    "output_throughput": 1246.7472504926645,
    "total_throughput": 2670.7886628009364,
    "itl": 25.709292089235223,
    "ttft": 112276.70834973999,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5290,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 38.66580892751807,
    "arrivals": 21245,
    "finished_requests": 20901,
    "scheduler_time": 2.564539340618941
}
#Debug simulation 
Total elapsed time: 2.728575306944549. Arrivals time: 0.0661156177520752 Scheduler time: 2.286648822017014 Scheduler overhead time: 0.1388760986737907 Adapter cache time: 0.04602224752306938 Engine time: 0.12988678738474846 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-32/adapters_256_slots_16_rate_0.05-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-32/adapters_256_slots_16_rate_0.05-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 540, 66, 540, 540, 66, 540, 135, 540, 66, 135, 66, 540, 135, 135, 135, 135, 540, 66, 66, 66, 135, 540, 66, 540, 540, 135, 135, 135, 66, 540, 66, 135, 135, 66, 135, 66, 66, 135, 135, 540, 135, 66, 135, 540, 135, 135, 540, 135, 540, 66, 540, 540, 135, 66, 66, 540, 135, 66, 135, 135, 540, 135, 66, 66, 540, 540, 540, 540, 540, 540, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 540, 540, 66, 540, 66, 135, 540, 540, 540, 135, 66, 540, 135, 66, 66, 66, 66, 66, 540, 135, 66, 540, 66, 540, 66, 66, 135, 135, 540, 135, 540, 66, 135, 66, 540, 540, 66, 540, 135, 66, 540, 66, 66, 540, 540, 135, 540, 540, 66, 540, 135, 135, 66, 135, 540, 540, 66, 540, 135, 66, 135, 540, 66, 66, 66, 66, 66, 66, 540, 66, 66, 66, 540, 66, 135, 540, 540, 135, 66, 540, 66, 135, 135, 66, 135, 66, 540, 66, 66, 540, 66, 540, 540, 135, 540, 135, 66, 135, 540, 135, 540, 66, 540, 66, 135, 540, 135, 540, 135, 540, 135, 540, 135, 66, 540, 66, 540, 135, 135, 66, 135, 540, 135, 135, 540, 66, 540, 540, 135, 66, 540, 540, 135, 135, 540, 540, 135, 135, 135, 135, 540, 540, 135, 135, 540, 66, 540, 135, 540, 540, 66, 540, 135, 135, 540, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 540, 135, 66, 66, 66, 66]
Prompts retrieved: 63525 . Total input tokens: 14115173 . Total output tokens: 12494728
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 2.696016169618815,
    "estimated_duration": 3599.943031199847,
    "input_throughput": 1423.7622527853455,
    "output_throughput": 1247.1880696688595,
    "total_throughput": 2670.950322454205,
    "itl": 25.71357664186355,
    "ttft": 111641.2161705934,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5280,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 39.627332932893125,
    "arrivals": 21245,
    "finished_requests": 20905,
    "scheduler_time": 2.57652508934675
}
#Debug simulation 
Total elapsed time: 2.696118057705462. Arrivals time: 0.06822683429345489 Scheduler time: 2.2539347684942186 Scheduler overhead time: 0.13796650432050228 Adapter cache time: 0.045880097430199385 Engine time: 0.1293339068070054 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-16/adapters_256_slots_16_rate_0.05-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-16/adapters_256_slots_16_rate_0.05-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 540, 66, 540, 540, 66, 540, 135, 540, 66, 135, 66, 540, 135, 135, 135, 135, 540, 66, 66, 66, 135, 540, 66, 540, 540, 135, 135, 135, 66, 540, 66, 135, 135, 66, 135, 66, 66, 135, 135, 540, 135, 66, 135, 540, 135, 135, 540, 135, 540, 66, 540, 540, 135, 66, 66, 540, 135, 66, 135, 135, 540, 135, 66, 66, 540, 540, 540, 540, 540, 540, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 540, 540, 66, 540, 66, 135, 540, 540, 540, 135, 66, 540, 135, 66, 66, 66, 66, 66, 540, 135, 66, 540, 66, 540, 66, 66, 135, 135, 540, 135, 540, 66, 135, 66, 540, 540, 66, 540, 135, 66, 540, 66, 66, 540, 540, 135, 540, 540, 66, 540, 135, 135, 66, 135, 540, 540, 66, 540, 135, 66, 135, 540, 66, 66, 66, 66, 66, 66, 540, 66, 66, 66, 540, 66, 135, 540, 540, 135, 66, 540, 66, 135, 135, 66, 135, 66, 540, 66, 66, 540, 66, 540, 540, 135, 540, 135, 66, 135, 540, 135, 540, 66, 540, 66, 135, 540, 135, 540, 135, 540, 135, 540, 135, 66, 540, 66, 540, 135, 135, 66, 135, 540, 135, 135, 540, 66, 540, 540, 135, 66, 540, 540, 135, 135, 540, 540, 135, 135, 135, 135, 540, 540, 135, 135, 540, 66, 540, 135, 540, 540, 66, 540, 135, 135, 540, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 540, 135, 66, 66, 66, 66]
Prompts retrieved: 63525 . Total input tokens: 14115173 . Total output tokens: 12494728
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 2.72936640214175,
    "estimated_duration": 3599.956368733634,
    "input_throughput": 1423.9372578293846,
    "output_throughput": 1246.5828861083198,
    "total_throughput": 2670.5201439377042,
    "itl": 25.68771213994997,
    "ttft": 111938.66609502018,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5305,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 36.30996950275846,
    "arrivals": 21245,
    "finished_requests": 20903,
    "scheduler_time": 2.5396822473954255
}
#Debug simulation 
Total elapsed time: 2.7294603949412704. Arrivals time: 0.06642598379403353 Scheduler time: 2.2843439411371946 Scheduler overhead time: 0.1402551494538784 Adapter cache time: 0.04640039475634694 Engine time: 0.13076668605208397 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-32/adapters_256_slots_16_rate_0.05-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-32/adapters_256_slots_16_rate_0.05-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 540, 66, 540, 540, 66, 540, 135, 540, 66, 135, 66, 540, 135, 135, 135, 135, 540, 66, 66, 66, 135, 540, 66, 540, 540, 135, 135, 135, 66, 540, 66, 135, 135, 66, 135, 66, 66, 135, 135, 540, 135, 66, 135, 540, 135, 135, 540, 135, 540, 66, 540, 540, 135, 66, 66, 540, 135, 66, 135, 135, 540, 135, 66, 66, 540, 540, 540, 540, 540, 540, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 540, 540, 66, 540, 66, 135, 540, 540, 540, 135, 66, 540, 135, 66, 66, 66, 66, 66, 540, 135, 66, 540, 66, 540, 66, 66, 135, 135, 540, 135, 540, 66, 135, 66, 540, 540, 66, 540, 135, 66, 540, 66, 66, 540, 540, 135, 540, 540, 66, 540, 135, 135, 66, 135, 540, 540, 66, 540, 135, 66, 135, 540, 66, 66, 66, 66, 66, 66, 540, 66, 66, 66, 540, 66, 135, 540, 540, 135, 66, 540, 66, 135, 135, 66, 135, 66, 540, 66, 66, 540, 66, 540, 540, 135, 540, 135, 66, 135, 540, 135, 540, 66, 540, 66, 135, 540, 135, 540, 135, 540, 135, 540, 135, 66, 540, 66, 540, 135, 135, 66, 135, 540, 135, 135, 540, 66, 540, 540, 135, 66, 540, 540, 135, 135, 540, 540, 135, 135, 135, 135, 540, 540, 135, 135, 540, 66, 540, 135, 540, 540, 66, 540, 135, 135, 540, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 540, 135, 66, 66, 66, 66]
Prompts retrieved: 63525 . Total input tokens: 14115173 . Total output tokens: 12494728
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 2.693906659260392,
    "estimated_duration": 3599.960350798078,
    "input_throughput": 1423.7331805234328,
    "output_throughput": 1246.7762315784883,
    "total_throughput": 2670.509412101921,
    "itl": 25.718936335202013,
    "ttft": 112203.01234777506,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5289,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 39.336837803437376,
    "arrivals": 21245,
    "finished_requests": 20901,
    "scheduler_time": 2.554535997274816
}
#Debug simulation 
Total elapsed time: 2.6939912270754576. Arrivals time: 0.0654687462374568 Scheduler time: 2.247532126493752 Scheduler overhead time: 0.14311542781069875 Adapter cache time: 0.046334279235452414 Engine time: 0.12913447711616755 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-16/adapters_256_slots_16_rate_0.05-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-16/adapters_256_slots_16_rate_0.05-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 540, 66, 540, 540, 66, 540, 135, 540, 66, 135, 66, 540, 135, 135, 135, 135, 540, 66, 66, 66, 135, 540, 66, 540, 540, 135, 135, 135, 66, 540, 66, 135, 135, 66, 135, 66, 66, 135, 135, 540, 135, 66, 135, 540, 135, 135, 540, 135, 540, 66, 540, 540, 135, 66, 66, 540, 135, 66, 135, 135, 540, 135, 66, 66, 540, 540, 540, 540, 540, 540, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 540, 540, 66, 540, 66, 135, 540, 540, 540, 135, 66, 540, 135, 66, 66, 66, 66, 66, 540, 135, 66, 540, 66, 540, 66, 66, 135, 135, 540, 135, 540, 66, 135, 66, 540, 540, 66, 540, 135, 66, 540, 66, 66, 540, 540, 135, 540, 540, 66, 540, 135, 135, 66, 135, 540, 540, 66, 540, 135, 66, 135, 540, 66, 66, 66, 66, 66, 66, 540, 66, 66, 66, 540, 66, 135, 540, 540, 135, 66, 540, 66, 135, 135, 66, 135, 66, 540, 66, 66, 540, 66, 540, 540, 135, 540, 135, 66, 135, 540, 135, 540, 66, 540, 66, 135, 540, 135, 540, 135, 540, 135, 540, 135, 66, 540, 66, 540, 135, 135, 66, 135, 540, 135, 135, 540, 66, 540, 540, 135, 66, 540, 540, 135, 135, 540, 540, 135, 135, 135, 135, 540, 540, 135, 135, 540, 66, 540, 135, 540, 540, 66, 540, 135, 135, 540, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 540, 135, 66, 66, 66, 66]
Prompts retrieved: 63525 . Total input tokens: 14115173 . Total output tokens: 12494728
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 2.683774162083864,
    "estimated_duration": 3599.954616168102,
    "input_throughput": 1424.5654589553658,
    "output_throughput": 1246.9590532722382,
    "total_throughput": 2671.524512227604,
    "itl": 25.669053156583246,
    "ttft": 110857.14574688989,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5308,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 33.8858523525518,
    "arrivals": 21245,
    "finished_requests": 20909,
    "scheduler_time": 2.529219864100271
}
#Debug simulation 
Total elapsed time: 2.6838675159960985. Arrivals time: 0.06594307348132133 Scheduler time: 2.2427590363658965 Scheduler overhead time: 0.13802749896422029 Adapter cache time: 0.045952762477099895 Engine time: 0.13021606532856822 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-32/adapters_256_slots_16_rate_0.05-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-32/adapters_256_slots_16_rate_0.05-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 540, 66, 540, 540, 66, 540, 135, 540, 66, 135, 66, 540, 135, 135, 135, 135, 540, 66, 66, 66, 135, 540, 66, 540, 540, 135, 135, 135, 66, 540, 66, 135, 135, 66, 135, 66, 66, 135, 135, 540, 135, 66, 135, 540, 135, 135, 540, 135, 540, 66, 540, 540, 135, 66, 66, 540, 135, 66, 135, 135, 540, 135, 66, 66, 540, 540, 540, 540, 540, 540, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 540, 540, 66, 540, 66, 135, 540, 540, 540, 135, 66, 540, 135, 66, 66, 66, 66, 66, 540, 135, 66, 540, 66, 540, 66, 66, 135, 135, 540, 135, 540, 66, 135, 66, 540, 540, 66, 540, 135, 66, 540, 66, 66, 540, 540, 135, 540, 540, 66, 540, 135, 135, 66, 135, 540, 540, 66, 540, 135, 66, 135, 540, 66, 66, 66, 66, 66, 66, 540, 66, 66, 66, 540, 66, 135, 540, 540, 135, 66, 540, 66, 135, 135, 66, 135, 66, 540, 66, 66, 540, 66, 540, 540, 135, 540, 135, 66, 135, 540, 135, 540, 66, 540, 66, 135, 540, 135, 540, 135, 540, 135, 540, 135, 66, 540, 66, 540, 135, 135, 66, 135, 540, 135, 135, 540, 66, 540, 540, 135, 66, 540, 540, 135, 135, 540, 540, 135, 135, 135, 135, 540, 540, 135, 135, 540, 66, 540, 135, 540, 540, 66, 540, 135, 135, 540, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 540, 135, 66, 66, 66, 66]
Prompts retrieved: 63525 . Total input tokens: 14115173 . Total output tokens: 12494728
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 2.696998768951744,
    "estimated_duration": 3599.94814302853,
    "input_throughput": 1424.046346314098,
    "output_throughput": 1246.7515702112796,
    "total_throughput": 2670.797916525378,
    "itl": 25.712503940270633,
    "ttft": 112289.15374489792,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5289,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 38.96992954568945,
    "arrivals": 21245,
    "finished_requests": 20901,
    "scheduler_time": 2.565643327255343
}
#Debug simulation 
Total elapsed time: 2.6970754875801504. Arrivals time: 0.06516784196719527 Scheduler time: 2.254402693361044 Scheduler overhead time: 0.13946355553343892 Adapter cache time: 0.04823620105162263 Engine time: 0.12863450963050127 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-8/adapters_256_slots_16_rate_0.05-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-8/adapters_256_slots_16_rate_0.05-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 540, 33, 540, 540, 33, 540, 135, 540, 33, 135, 33, 540, 135, 135, 135, 135, 540, 33, 33, 33, 135, 540, 33, 540, 540, 135, 135, 135, 33, 540, 33, 135, 135, 33, 135, 33, 33, 135, 135, 540, 135, 33, 135, 540, 135, 135, 540, 135, 540, 33, 540, 540, 135, 33, 33, 540, 135, 33, 135, 135, 540, 135, 33, 33, 540, 540, 540, 540, 540, 540, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 540, 540, 33, 540, 33, 135, 540, 540, 540, 135, 33, 540, 135, 33, 33, 33, 33, 33, 540, 135, 33, 540, 33, 540, 33, 33, 135, 135, 540, 135, 540, 33, 135, 33, 540, 540, 33, 540, 135, 33, 540, 33, 33, 540, 540, 135, 540, 540, 33, 540, 135, 135, 33, 135, 540, 540, 33, 540, 135, 33, 135, 540, 33, 33, 33, 33, 33, 33, 540, 33, 33, 33, 540, 33, 135, 540, 540, 135, 33, 540, 33, 135, 135, 33, 135, 33, 540, 33, 33, 540, 33, 540, 540, 135, 540, 135, 33, 135, 540, 135, 540, 33, 540, 33, 135, 540, 135, 540, 135, 540, 135, 540, 135, 33, 540, 33, 540, 135, 135, 33, 135, 540, 135, 135, 540, 33, 540, 540, 135, 33, 540, 540, 135, 135, 540, 540, 135, 135, 135, 135, 540, 540, 135, 135, 540, 33, 540, 135, 540, 540, 33, 540, 135, 135, 540, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 540, 135, 33, 33, 33, 33]
Prompts retrieved: 60720 . Total input tokens: 13508031 . Total output tokens: 11955602
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 2.519878291990608,
    "estimated_duration": 3600.021214089836,
    "input_throughput": 1387.9626543432116,
    "output_throughput": 1207.8017715513095,
    "total_throughput": 2595.764425894521,
    "itl": 25.549212582553288,
    "ttft": 92650.91800728989,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5304,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 35.07221750546006,
    "arrivals": 20441,
    "finished_requests": 20172,
    "scheduler_time": 1.0209296892251634
}
#Debug simulation 
Total elapsed time: 2.5199531470425427. Arrivals time: 0.06297326786443591 Scheduler time: 2.0858285990543664 Scheduler overhead time: 0.13421939220279455 Adapter cache time: 0.0459060980938375 Engine time: 0.1292647155933082 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-16/adapters_256_slots_16_rate_0.05-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-16/adapters_256_slots_16_rate_0.05-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 540, 33, 540, 540, 33, 540, 135, 540, 33, 135, 33, 540, 135, 135, 135, 135, 540, 33, 33, 33, 135, 540, 33, 540, 540, 135, 135, 135, 33, 540, 33, 135, 135, 33, 135, 33, 33, 135, 135, 540, 135, 33, 135, 540, 135, 135, 540, 135, 540, 33, 540, 540, 135, 33, 33, 540, 135, 33, 135, 135, 540, 135, 33, 33, 540, 540, 540, 540, 540, 540, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 540, 540, 33, 540, 33, 135, 540, 540, 540, 135, 33, 540, 135, 33, 33, 33, 33, 33, 540, 135, 33, 540, 33, 540, 33, 33, 135, 135, 540, 135, 540, 33, 135, 33, 540, 540, 33, 540, 135, 33, 540, 33, 33, 540, 540, 135, 540, 540, 33, 540, 135, 135, 33, 135, 540, 540, 33, 540, 135, 33, 135, 540, 33, 33, 33, 33, 33, 33, 540, 33, 33, 33, 540, 33, 135, 540, 540, 135, 33, 540, 33, 135, 135, 33, 135, 33, 540, 33, 33, 540, 33, 540, 540, 135, 540, 135, 33, 135, 540, 135, 540, 33, 540, 33, 135, 540, 135, 540, 135, 540, 135, 540, 135, 33, 540, 33, 540, 135, 135, 33, 135, 540, 135, 135, 540, 33, 540, 540, 135, 33, 540, 540, 135, 135, 540, 540, 135, 135, 135, 135, 540, 540, 135, 135, 540, 33, 540, 135, 540, 540, 33, 540, 135, 135, 540, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 540, 135, 33, 33, 33, 33]
Prompts retrieved: 60720 . Total input tokens: 13508031 . Total output tokens: 11955602
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 2.519092185422778,
    "estimated_duration": 3600.018623839601,
    "input_throughput": 1387.4889332301832,
    "output_throughput": 1207.996806239234,
    "total_throughput": 2595.4857394694172,
    "itl": 25.585842864761094,
    "ttft": 93021.34301249679,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 38.94339625608052,
    "arrivals": 20441,
    "finished_requests": 20169,
    "scheduler_time": 1.0341133911786018
}
#Debug simulation 
Total elapsed time: 2.5191852441057563. Arrivals time: 0.06331624323502183 Scheduler time: 2.0817658826708794 Scheduler overhead time: 0.13646020973101258 Adapter cache time: 0.04565531387925148 Engine time: 0.1297584897838533 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-32/adapters_256_slots_16_rate_0.05-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-32/adapters_256_slots_16_rate_0.05-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 540, 33, 540, 540, 33, 540, 135, 540, 33, 135, 33, 540, 135, 135, 135, 135, 540, 33, 33, 33, 135, 540, 33, 540, 540, 135, 135, 135, 33, 540, 33, 135, 135, 33, 135, 33, 33, 135, 135, 540, 135, 33, 135, 540, 135, 135, 540, 135, 540, 33, 540, 540, 135, 33, 33, 540, 135, 33, 135, 135, 540, 135, 33, 33, 540, 540, 540, 540, 540, 540, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 540, 540, 33, 540, 33, 135, 540, 540, 540, 135, 33, 540, 135, 33, 33, 33, 33, 33, 540, 135, 33, 540, 33, 540, 33, 33, 135, 135, 540, 135, 540, 33, 135, 33, 540, 540, 33, 540, 135, 33, 540, 33, 33, 540, 540, 135, 540, 540, 33, 540, 135, 135, 33, 135, 540, 540, 33, 540, 135, 33, 135, 540, 33, 33, 33, 33, 33, 33, 540, 33, 33, 33, 540, 33, 135, 540, 540, 135, 33, 540, 33, 135, 135, 33, 135, 33, 540, 33, 33, 540, 33, 540, 540, 135, 540, 135, 33, 135, 540, 135, 540, 33, 540, 33, 135, 540, 135, 540, 135, 540, 135, 540, 135, 33, 540, 33, 540, 135, 135, 33, 135, 540, 135, 135, 540, 33, 540, 540, 135, 33, 540, 540, 135, 135, 540, 540, 135, 135, 135, 135, 540, 540, 135, 135, 540, 33, 540, 135, 540, 540, 33, 540, 135, 135, 540, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 540, 135, 33, 33, 33, 33]
Prompts retrieved: 60720 . Total input tokens: 13508031 . Total output tokens: 11955602
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 2.4933415167033672,
    "estimated_duration": 3599.997914624089,
    "input_throughput": 1388.4608042951986,
    "output_throughput": 1208.1162553823713,
    "total_throughput": 2596.5770596775697,
    "itl": 25.594577866045125,
    "ttft": 91146.49714089619,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5321,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 40.014842552235166,
    "arrivals": 20441,
    "finished_requests": 20180,
    "scheduler_time": 1.0291366526904828
}
#Debug simulation 
Total elapsed time: 2.4934155140072107. Arrivals time: 0.06221687374636531 Scheduler time: 2.063343239016831 Scheduler overhead time: 0.1330795860849321 Adapter cache time: 0.04581955261528492 Engine time: 0.12785285525023937 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-16/adapters_256_slots_16_rate_0.05-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-16/adapters_256_slots_16_rate_0.05-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 540, 33, 540, 540, 33, 540, 135, 540, 33, 135, 33, 540, 135, 135, 135, 135, 540, 33, 33, 33, 135, 540, 33, 540, 540, 135, 135, 135, 33, 540, 33, 135, 135, 33, 135, 33, 33, 135, 135, 540, 135, 33, 135, 540, 135, 135, 540, 135, 540, 33, 540, 540, 135, 33, 33, 540, 135, 33, 135, 135, 540, 135, 33, 33, 540, 540, 540, 540, 540, 540, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 540, 540, 33, 540, 33, 135, 540, 540, 540, 135, 33, 540, 135, 33, 33, 33, 33, 33, 540, 135, 33, 540, 33, 540, 33, 33, 135, 135, 540, 135, 540, 33, 135, 33, 540, 540, 33, 540, 135, 33, 540, 33, 33, 540, 540, 135, 540, 540, 33, 540, 135, 135, 33, 135, 540, 540, 33, 540, 135, 33, 135, 540, 33, 33, 33, 33, 33, 33, 540, 33, 33, 33, 540, 33, 135, 540, 540, 135, 33, 540, 33, 135, 135, 33, 135, 33, 540, 33, 33, 540, 33, 540, 540, 135, 540, 135, 33, 135, 540, 135, 540, 33, 540, 33, 135, 540, 135, 540, 135, 540, 135, 540, 135, 33, 540, 33, 540, 135, 135, 33, 135, 540, 135, 135, 540, 33, 540, 540, 135, 33, 540, 540, 135, 135, 540, 540, 135, 135, 135, 135, 540, 540, 135, 135, 540, 33, 540, 135, 540, 540, 33, 540, 135, 135, 540, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 540, 135, 33, 33, 33, 33]
Prompts retrieved: 60720 . Total input tokens: 13508031 . Total output tokens: 11955602
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 2.5171259129419923,
    "estimated_duration": 3600.006249438175,
    "input_throughput": 1386.8453702765555,
    "output_throughput": 1207.5709592666522,
    "total_throughput": 2594.4163295432077,
    "itl": 25.562214721536613,
    "ttft": 94050.4097110434,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 36.41822230562685,
    "arrivals": 20441,
    "finished_requests": 20164,
    "scheduler_time": 1.041037392089692
}
#Debug simulation 
Total elapsed time: 2.5172197339124978. Arrivals time: 0.062490965239703655 Scheduler time: 2.0847176713868976 Scheduler overhead time: 0.13466174667701125 Adapter cache time: 0.0459885960444808 Engine time: 0.12830056622624397 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-32/adapters_256_slots_16_rate_0.05-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-32/adapters_256_slots_16_rate_0.05-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 540, 33, 540, 540, 33, 540, 135, 540, 33, 135, 33, 540, 135, 135, 135, 135, 540, 33, 33, 33, 135, 540, 33, 540, 540, 135, 135, 135, 33, 540, 33, 135, 135, 33, 135, 33, 33, 135, 135, 540, 135, 33, 135, 540, 135, 135, 540, 135, 540, 33, 540, 540, 135, 33, 33, 540, 135, 33, 135, 135, 540, 135, 33, 33, 540, 540, 540, 540, 540, 540, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 540, 540, 33, 540, 33, 135, 540, 540, 540, 135, 33, 540, 135, 33, 33, 33, 33, 33, 540, 135, 33, 540, 33, 540, 33, 33, 135, 135, 540, 135, 540, 33, 135, 33, 540, 540, 33, 540, 135, 33, 540, 33, 33, 540, 540, 135, 540, 540, 33, 540, 135, 135, 33, 135, 540, 540, 33, 540, 135, 33, 135, 540, 33, 33, 33, 33, 33, 33, 540, 33, 33, 33, 540, 33, 135, 540, 540, 135, 33, 540, 33, 135, 135, 33, 135, 33, 540, 33, 33, 540, 33, 540, 540, 135, 540, 135, 33, 135, 540, 135, 540, 33, 540, 33, 135, 540, 135, 540, 135, 540, 135, 540, 135, 33, 540, 33, 540, 135, 135, 33, 135, 540, 135, 135, 540, 33, 540, 540, 135, 33, 540, 540, 135, 135, 540, 540, 135, 135, 135, 135, 540, 540, 135, 135, 540, 33, 540, 135, 540, 540, 33, 540, 135, 135, 540, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 540, 135, 33, 33, 33, 33]
Prompts retrieved: 60720 . Total input tokens: 13508031 . Total output tokens: 11955602
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 2.521675600204617,
    "estimated_duration": 3600.0248124703394,
    "input_throughput": 1388.2554316536884,
    "output_throughput": 1208.300560855048,
    "total_throughput": 2596.5559925087364,
    "itl": 25.592697912783066,
    "ttft": 91398.79149970492,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5307,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 39.533989647068005,
    "arrivals": 20441,
    "finished_requests": 20179,
    "scheduler_time": 1.0417418807495726
}
#Debug simulation 
Total elapsed time: 2.521771145053208. Arrivals time: 0.06336397537961602 Scheduler time: 2.0888785468414426 Scheduler overhead time: 0.1344102118164301 Adapter cache time: 0.04561803303658962 Engine time: 0.12860094523057342 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-16/adapters_256_slots_16_rate_0.05-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-16/adapters_256_slots_16_rate_0.05-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 540, 33, 540, 540, 33, 540, 135, 540, 33, 135, 33, 540, 135, 135, 135, 135, 540, 33, 33, 33, 135, 540, 33, 540, 540, 135, 135, 135, 33, 540, 33, 135, 135, 33, 135, 33, 33, 135, 135, 540, 135, 33, 135, 540, 135, 135, 540, 135, 540, 33, 540, 540, 135, 33, 33, 540, 135, 33, 135, 135, 540, 135, 33, 33, 540, 540, 540, 540, 540, 540, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 540, 540, 33, 540, 33, 135, 540, 540, 540, 135, 33, 540, 135, 33, 33, 33, 33, 33, 540, 135, 33, 540, 33, 540, 33, 33, 135, 135, 540, 135, 540, 33, 135, 33, 540, 540, 33, 540, 135, 33, 540, 33, 33, 540, 540, 135, 540, 540, 33, 540, 135, 135, 33, 135, 540, 540, 33, 540, 135, 33, 135, 540, 33, 33, 33, 33, 33, 33, 540, 33, 33, 33, 540, 33, 135, 540, 540, 135, 33, 540, 33, 135, 135, 33, 135, 33, 540, 33, 33, 540, 33, 540, 540, 135, 540, 135, 33, 135, 540, 135, 540, 33, 540, 33, 135, 540, 135, 540, 135, 540, 135, 540, 135, 33, 540, 33, 540, 135, 135, 33, 135, 540, 135, 135, 540, 33, 540, 540, 135, 33, 540, 540, 135, 135, 540, 540, 135, 135, 135, 135, 540, 540, 135, 135, 540, 33, 540, 135, 540, 540, 33, 540, 135, 135, 540, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 540, 135, 33, 33, 33, 33]
Prompts retrieved: 60720 . Total input tokens: 13508031 . Total output tokens: 11955602
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 2.523681287188083,
    "estimated_duration": 3600.02185058508,
    "input_throughput": 1387.7387991931387,
    "output_throughput": 1208.148222570687,
    "total_throughput": 2595.887021763826,
    "itl": 25.5462778329007,
    "ttft": 91922.60311689171,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5322,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 33.9752272457198,
    "arrivals": 20441,
    "finished_requests": 20175,
    "scheduler_time": 1.029621593143954
}
#Debug simulation 
Total elapsed time: 2.523779205046594. Arrivals time: 0.06277673598378897 Scheduler time: 2.09052911400795 Scheduler overhead time: 0.1342076137661934 Adapter cache time: 0.045909341890364885 Engine time: 0.12891287170350552 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-32/adapters_256_slots_16_rate_0.05-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-32/adapters_256_slots_16_rate_0.05-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 540, 33, 540, 540, 33, 540, 135, 540, 33, 135, 33, 540, 135, 135, 135, 135, 540, 33, 33, 33, 135, 540, 33, 540, 540, 135, 135, 135, 33, 540, 33, 135, 135, 33, 135, 33, 33, 135, 135, 540, 135, 33, 135, 540, 135, 135, 540, 135, 540, 33, 540, 540, 135, 33, 33, 540, 135, 33, 135, 135, 540, 135, 33, 33, 540, 540, 540, 540, 540, 540, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 540, 540, 33, 540, 33, 135, 540, 540, 540, 135, 33, 540, 135, 33, 33, 33, 33, 33, 540, 135, 33, 540, 33, 540, 33, 33, 135, 135, 540, 135, 540, 33, 135, 33, 540, 540, 33, 540, 135, 33, 540, 33, 33, 540, 540, 135, 540, 540, 33, 540, 135, 135, 33, 135, 540, 540, 33, 540, 135, 33, 135, 540, 33, 33, 33, 33, 33, 33, 540, 33, 33, 33, 540, 33, 135, 540, 540, 135, 33, 540, 33, 135, 135, 33, 135, 33, 540, 33, 33, 540, 33, 540, 540, 135, 540, 135, 33, 135, 540, 135, 540, 33, 540, 33, 135, 540, 135, 540, 135, 540, 135, 540, 135, 33, 540, 33, 540, 135, 135, 33, 135, 540, 135, 135, 540, 33, 540, 540, 135, 33, 540, 540, 135, 135, 540, 540, 135, 135, 135, 135, 540, 540, 135, 135, 540, 33, 540, 135, 540, 540, 33, 540, 135, 135, 540, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 540, 135, 33, 33, 33, 33]
Prompts retrieved: 60720 . Total input tokens: 13508031 . Total output tokens: 11955602
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 2.531690645031631,
    "estimated_duration": 3600.010440360459,
    "input_throughput": 1388.3809735561615,
    "output_throughput": 1208.3226068545648,
    "total_throughput": 2596.7035804107263,
    "itl": 25.584391910005653,
    "ttft": 91289.79866723754,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5317,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 39.23981606340034,
    "arrivals": 20441,
    "finished_requests": 20179,
    "scheduler_time": 1.0245338724940078
}
#Debug simulation 
Total elapsed time: 2.5317855500616133. Arrivals time: 0.06385252205654979 Scheduler time: 2.098972924053669 Scheduler overhead time: 0.13408683892339468 Adapter cache time: 0.04562500771135092 Engine time: 0.12860558042302728 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-8/adapters_256_slots_16_rate_0.05-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-8/adapters_256_slots_16_rate_0.05-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 540, 33, 540, 540, 33, 540, 66, 540, 33, 66, 33, 540, 66, 66, 66, 66, 540, 33, 33, 33, 66, 540, 33, 540, 540, 66, 66, 66, 33, 540, 33, 66, 66, 33, 66, 33, 33, 66, 66, 540, 66, 33, 66, 540, 66, 66, 540, 66, 540, 33, 540, 540, 66, 33, 33, 540, 66, 33, 66, 66, 540, 66, 33, 33, 540, 540, 540, 540, 540, 540, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 540, 540, 33, 540, 33, 66, 540, 540, 540, 66, 33, 540, 66, 33, 33, 33, 33, 33, 540, 66, 33, 540, 33, 540, 33, 33, 66, 66, 540, 66, 540, 33, 66, 33, 540, 540, 33, 540, 66, 33, 540, 33, 33, 540, 540, 66, 540, 540, 33, 540, 66, 66, 33, 66, 540, 540, 33, 540, 66, 33, 66, 540, 33, 33, 33, 33, 33, 33, 540, 33, 33, 33, 540, 33, 66, 540, 540, 66, 33, 540, 33, 66, 66, 33, 66, 33, 540, 33, 33, 540, 33, 540, 540, 66, 540, 66, 33, 66, 540, 66, 540, 33, 540, 33, 66, 540, 66, 540, 66, 540, 66, 540, 66, 33, 540, 33, 540, 66, 66, 33, 66, 540, 66, 66, 540, 33, 540, 540, 66, 33, 540, 540, 66, 66, 540, 540, 66, 66, 66, 66, 540, 540, 66, 66, 540, 33, 540, 66, 540, 540, 33, 540, 66, 66, 540, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 540, 66, 33, 33, 33, 33]
Prompts retrieved: 54855 . Total input tokens: 12187415 . Total output tokens: 10802400
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 2.1616686917841434,
    "estimated_duration": 3599.8605426999,
    "input_throughput": 1261.57831564049,
    "output_throughput": 1097.660576883466,
    "total_throughput": 2359.238892523956,
    "itl": 25.166605647149026,
    "ttft": 75141.564485361,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5759,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 38.08086361499819,
    "arrivals": 18559,
    "finished_requests": 18337,
    "scheduler_time": 0.07425108989082982
}
#Debug simulation 
Total elapsed time: 2.1617431878112257. Arrivals time: 0.05678740190342069 Scheduler time: 1.7434647302143276 Scheduler overhead time: 0.1278022825717926 Adapter cache time: 0.04686085972934961 Engine time: 0.12599362712353468 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-16/adapters_256_slots_16_rate_0.05-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-16/adapters_256_slots_16_rate_0.05-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 540, 33, 540, 540, 33, 540, 66, 540, 33, 66, 33, 540, 66, 66, 66, 66, 540, 33, 33, 33, 66, 540, 33, 540, 540, 66, 66, 66, 33, 540, 33, 66, 66, 33, 66, 33, 33, 66, 66, 540, 66, 33, 66, 540, 66, 66, 540, 66, 540, 33, 540, 540, 66, 33, 33, 540, 66, 33, 66, 66, 540, 66, 33, 33, 540, 540, 540, 540, 540, 540, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 540, 540, 33, 540, 33, 66, 540, 540, 540, 66, 33, 540, 66, 33, 33, 33, 33, 33, 540, 66, 33, 540, 33, 540, 33, 33, 66, 66, 540, 66, 540, 33, 66, 33, 540, 540, 33, 540, 66, 33, 540, 33, 33, 540, 540, 66, 540, 540, 33, 540, 66, 66, 33, 66, 540, 540, 33, 540, 66, 33, 66, 540, 33, 33, 33, 33, 33, 33, 540, 33, 33, 33, 540, 33, 66, 540, 540, 66, 33, 540, 33, 66, 66, 33, 66, 33, 540, 33, 33, 540, 33, 540, 540, 66, 540, 66, 33, 66, 540, 66, 540, 33, 540, 33, 66, 540, 66, 540, 66, 540, 66, 540, 66, 33, 540, 33, 540, 66, 66, 33, 66, 540, 66, 66, 540, 33, 540, 540, 66, 33, 540, 540, 66, 66, 540, 540, 66, 66, 66, 66, 540, 540, 66, 66, 540, 33, 540, 66, 540, 540, 33, 540, 66, 66, 540, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 540, 66, 33, 33, 33, 33]
Prompts retrieved: 54855 . Total input tokens: 12187415 . Total output tokens: 10802400
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 2.1591787501238286,
    "estimated_duration": 3599.8585419171695,
    "input_throughput": 1261.7201334753195,
    "output_throughput": 1097.5734057304835,
    "total_throughput": 2359.293539205803,
    "itl": 25.204500761296956,
    "ttft": 75379.03617224997,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5751,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 42.06968584426078,
    "arrivals": 18559,
    "finished_requests": 18336,
    "scheduler_time": 0.08222891590075357
}
#Debug simulation 
Total elapsed time: 2.159270624164492. Arrivals time: 0.05891624605283141 Scheduler time: 1.739588898140937 Scheduler overhead time: 0.1270345658995211 Adapter cache time: 0.04664368228986859 Engine time: 0.126586539670825 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-32/adapters_256_slots_16_rate_0.05-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-32/adapters_256_slots_16_rate_0.05-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 540, 33, 540, 540, 33, 540, 66, 540, 33, 66, 33, 540, 66, 66, 66, 66, 540, 33, 33, 33, 66, 540, 33, 540, 540, 66, 66, 66, 33, 540, 33, 66, 66, 33, 66, 33, 33, 66, 66, 540, 66, 33, 66, 540, 66, 66, 540, 66, 540, 33, 540, 540, 66, 33, 33, 540, 66, 33, 66, 66, 540, 66, 33, 33, 540, 540, 540, 540, 540, 540, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 540, 540, 33, 540, 33, 66, 540, 540, 540, 66, 33, 540, 66, 33, 33, 33, 33, 33, 540, 66, 33, 540, 33, 540, 33, 33, 66, 66, 540, 66, 540, 33, 66, 33, 540, 540, 33, 540, 66, 33, 540, 33, 33, 540, 540, 66, 540, 540, 33, 540, 66, 66, 33, 66, 540, 540, 33, 540, 66, 33, 66, 540, 33, 33, 33, 33, 33, 33, 540, 33, 33, 33, 540, 33, 66, 540, 540, 66, 33, 540, 33, 66, 66, 33, 66, 33, 540, 33, 33, 540, 33, 540, 540, 66, 540, 66, 33, 66, 540, 66, 540, 33, 540, 33, 66, 540, 66, 540, 66, 540, 66, 540, 66, 33, 540, 33, 540, 66, 66, 33, 66, 540, 66, 66, 540, 33, 540, 540, 66, 33, 540, 540, 66, 66, 540, 540, 66, 66, 66, 66, 540, 540, 66, 66, 540, 33, 540, 66, 540, 540, 33, 540, 66, 66, 540, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 540, 66, 33, 33, 33, 33]
Prompts retrieved: 54855 . Total input tokens: 12187415 . Total output tokens: 10802400
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 2.1605125749483705,
    "estimated_duration": 3599.8781629655505,
    "input_throughput": 1262.3199436995742,
    "output_throughput": 1098.128553535113,
    "total_throughput": 2360.4484972346872,
    "itl": 25.217238985404492,
    "ttft": 73922.84662257627,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5741,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 43.13167553964456,
    "arrivals": 18559,
    "finished_requests": 18344,
    "scheduler_time": 0.08309255951696755
}
#Debug simulation 
Total elapsed time: 2.160607722122222. Arrivals time: 0.057482310105115175 Scheduler time: 1.7425107066519558 Scheduler overhead time: 0.12745134625583887 Adapter cache time: 0.04666126286610961 Engine time: 0.12568908464163542 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-16/adapters_256_slots_16_rate_0.05-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-16/adapters_256_slots_16_rate_0.05-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 540, 33, 540, 540, 33, 540, 66, 540, 33, 66, 33, 540, 66, 66, 66, 66, 540, 33, 33, 33, 66, 540, 33, 540, 540, 66, 66, 66, 33, 540, 33, 66, 66, 33, 66, 33, 33, 66, 66, 540, 66, 33, 66, 540, 66, 66, 540, 66, 540, 33, 540, 540, 66, 33, 33, 540, 66, 33, 66, 66, 540, 66, 33, 33, 540, 540, 540, 540, 540, 540, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 540, 540, 33, 540, 33, 66, 540, 540, 540, 66, 33, 540, 66, 33, 33, 33, 33, 33, 540, 66, 33, 540, 33, 540, 33, 33, 66, 66, 540, 66, 540, 33, 66, 33, 540, 540, 33, 540, 66, 33, 540, 33, 33, 540, 540, 66, 540, 540, 33, 540, 66, 66, 33, 66, 540, 540, 33, 540, 66, 33, 66, 540, 33, 33, 33, 33, 33, 33, 540, 33, 33, 33, 540, 33, 66, 540, 540, 66, 33, 540, 33, 66, 66, 33, 66, 33, 540, 33, 33, 540, 33, 540, 540, 66, 540, 66, 33, 66, 540, 66, 540, 33, 540, 33, 66, 540, 66, 540, 66, 540, 66, 540, 66, 33, 540, 33, 540, 66, 66, 33, 66, 540, 66, 66, 540, 33, 540, 540, 66, 33, 540, 540, 66, 66, 540, 540, 66, 66, 66, 66, 540, 540, 66, 66, 540, 33, 540, 66, 540, 540, 33, 540, 66, 66, 540, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 540, 66, 33, 33, 33, 33]
Prompts retrieved: 54855 . Total input tokens: 12187415 . Total output tokens: 10802400
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 2.1712228693068027,
    "estimated_duration": 3599.853291061867,
    "input_throughput": 1261.820866777633,
    "output_throughput": 1097.5111151917497,
    "total_throughput": 2359.331981969383,
    "itl": 25.18455531427029,
    "ttft": 74552.93209385325,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5771,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 39.37649924530324,
    "arrivals": 18559,
    "finished_requests": 18340,
    "scheduler_time": 0.07826201412759021
}
#Debug simulation 
Total elapsed time: 2.171299420297146. Arrivals time: 0.05720581905916333 Scheduler time: 1.7537230318412185 Scheduler overhead time: 0.12693277560174465 Adapter cache time: 0.04685931606218219 Engine time: 0.12596223130822182 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-32/adapters_256_slots_16_rate_0.05-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-32/adapters_256_slots_16_rate_0.05-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 540, 33, 540, 540, 33, 540, 66, 540, 33, 66, 33, 540, 66, 66, 66, 66, 540, 33, 33, 33, 66, 540, 33, 540, 540, 66, 66, 66, 33, 540, 33, 66, 66, 33, 66, 33, 33, 66, 66, 540, 66, 33, 66, 540, 66, 66, 540, 66, 540, 33, 540, 540, 66, 33, 33, 540, 66, 33, 66, 66, 540, 66, 33, 33, 540, 540, 540, 540, 540, 540, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 540, 540, 33, 540, 33, 66, 540, 540, 540, 66, 33, 540, 66, 33, 33, 33, 33, 33, 540, 66, 33, 540, 33, 540, 33, 33, 66, 66, 540, 66, 540, 33, 66, 33, 540, 540, 33, 540, 66, 33, 540, 33, 33, 540, 540, 66, 540, 540, 33, 540, 66, 66, 33, 66, 540, 540, 33, 540, 66, 33, 66, 540, 33, 33, 33, 33, 33, 33, 540, 33, 33, 33, 540, 33, 66, 540, 540, 66, 33, 540, 33, 66, 66, 33, 66, 33, 540, 33, 33, 540, 33, 540, 540, 66, 540, 66, 33, 66, 540, 66, 540, 33, 540, 33, 66, 540, 66, 540, 66, 540, 66, 540, 66, 33, 540, 33, 540, 66, 66, 33, 66, 540, 66, 66, 540, 33, 540, 540, 66, 33, 540, 540, 66, 66, 540, 540, 66, 66, 66, 66, 540, 540, 66, 66, 540, 33, 540, 66, 540, 540, 33, 540, 66, 66, 540, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 540, 66, 33, 33, 33, 33]
Prompts retrieved: 54855 . Total input tokens: 12187415 . Total output tokens: 10802400
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 2.178387050051242,
    "estimated_duration": 3599.851321687344,
    "input_throughput": 1261.6551613223721,
    "output_throughput": 1097.7111682900793,
    "total_throughput": 2359.3663296124514,
    "itl": 25.203847120423898,
    "ttft": 75131.95637272805,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5733,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 42.654955998923846,
    "arrivals": 18559,
    "finished_requests": 18338,
    "scheduler_time": 0.08146358879981697
}
#Debug simulation 
Total elapsed time: 2.178522193338722. Arrivals time: 0.05838387878611684 Scheduler time: 1.7573647033423185 Scheduler overhead time: 0.12747915601357818 Adapter cache time: 0.0470069139264524 Engine time: 0.12699884921312332 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-16/adapters_256_slots_16_rate_0.05-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-16/adapters_256_slots_16_rate_0.05-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 540, 33, 540, 540, 33, 540, 66, 540, 33, 66, 33, 540, 66, 66, 66, 66, 540, 33, 33, 33, 66, 540, 33, 540, 540, 66, 66, 66, 33, 540, 33, 66, 66, 33, 66, 33, 33, 66, 66, 540, 66, 33, 66, 540, 66, 66, 540, 66, 540, 33, 540, 540, 66, 33, 33, 540, 66, 33, 66, 66, 540, 66, 33, 33, 540, 540, 540, 540, 540, 540, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 540, 540, 33, 540, 33, 66, 540, 540, 540, 66, 33, 540, 66, 33, 33, 33, 33, 33, 540, 66, 33, 540, 33, 540, 33, 33, 66, 66, 540, 66, 540, 33, 66, 33, 540, 540, 33, 540, 66, 33, 540, 33, 33, 540, 540, 66, 540, 540, 33, 540, 66, 66, 33, 66, 540, 540, 33, 540, 66, 33, 66, 540, 33, 33, 33, 33, 33, 33, 540, 33, 33, 33, 540, 33, 66, 540, 540, 66, 33, 540, 33, 66, 66, 33, 66, 33, 540, 33, 33, 540, 33, 540, 540, 66, 540, 66, 33, 66, 540, 66, 540, 33, 540, 33, 66, 540, 66, 540, 66, 540, 66, 540, 66, 33, 540, 33, 540, 66, 66, 33, 66, 540, 66, 66, 540, 33, 540, 540, 66, 33, 540, 540, 66, 66, 540, 540, 66, 66, 66, 66, 540, 540, 66, 66, 540, 33, 540, 66, 540, 540, 33, 540, 66, 66, 540, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 540, 66, 33, 33, 33, 33]
Prompts retrieved: 54855 . Total input tokens: 12187415 . Total output tokens: 10802400
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 2.1756962998770177,
    "estimated_duration": 3599.8546728289803,
    "input_throughput": 1262.1384508362487,
    "output_throughput": 1098.0846059803687,
    "total_throughput": 2360.2230568166174,
    "itl": 25.16319870736956,
    "ttft": 74158.25324548264,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5771,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 36.84160774803635,
    "arrivals": 18559,
    "finished_requests": 18342,
    "scheduler_time": 0.0738073871341511
}
#Debug simulation 
Total elapsed time: 2.175789478700608. Arrivals time: 0.05773483868688345 Scheduler time: 1.7552634002640843 Scheduler overhead time: 0.12722662091255188 Adapter cache time: 0.04789935098960996 Engine time: 0.12687780102714896 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-32/adapters_256_slots_16_rate_0.05-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-32/adapters_256_slots_16_rate_0.05-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 540, 33, 540, 540, 33, 540, 66, 540, 33, 66, 33, 540, 66, 66, 66, 66, 540, 33, 33, 33, 66, 540, 33, 540, 540, 66, 66, 66, 33, 540, 33, 66, 66, 33, 66, 33, 33, 66, 66, 540, 66, 33, 66, 540, 66, 66, 540, 66, 540, 33, 540, 540, 66, 33, 33, 540, 66, 33, 66, 66, 540, 66, 33, 33, 540, 540, 540, 540, 540, 540, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 540, 540, 33, 540, 33, 66, 540, 540, 540, 66, 33, 540, 66, 33, 33, 33, 33, 33, 540, 66, 33, 540, 33, 540, 33, 33, 66, 66, 540, 66, 540, 33, 66, 33, 540, 540, 33, 540, 66, 33, 540, 33, 33, 540, 540, 66, 540, 540, 33, 540, 66, 66, 33, 66, 540, 540, 33, 540, 66, 33, 66, 540, 33, 33, 33, 33, 33, 33, 540, 33, 33, 33, 540, 33, 66, 540, 540, 66, 33, 540, 33, 66, 66, 33, 66, 33, 540, 33, 33, 540, 33, 540, 540, 66, 540, 66, 33, 66, 540, 66, 540, 33, 540, 33, 66, 540, 66, 540, 66, 540, 66, 540, 66, 33, 540, 33, 540, 66, 66, 33, 66, 540, 66, 66, 540, 33, 540, 540, 66, 33, 540, 540, 66, 66, 540, 540, 66, 66, 66, 66, 540, 540, 66, 66, 540, 33, 540, 66, 540, 540, 33, 540, 66, 66, 540, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 540, 66, 33, 33, 33, 33]
Prompts retrieved: 54855 . Total input tokens: 12187415 . Total output tokens: 10802400
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 2.161695836111903,
    "estimated_duration": 3599.854647355308,
    "input_throughput": 1261.3373163096596,
    "output_throughput": 1097.4832005793637,
    "total_throughput": 2358.820516889023,
    "itl": 25.20505047097307,
    "ttft": 75959.33107852546,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5743,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 42.348717750030836,
    "arrivals": 18559,
    "finished_requests": 18333,
    "scheduler_time": 0.08699826098303012
}
#Debug simulation 
Total elapsed time: 2.16179734794423. Arrivals time: 0.05709433741867542 Scheduler time: 1.7428035461343825 Scheduler overhead time: 0.12870828621089458 Adapter cache time: 0.04656476667150855 Engine time: 0.1255479995161295 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-8/adapters_256_slots_16_rate_0.025-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-8/adapters_256_slots_16_rate_0.025-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 270, 66, 270, 270, 66, 270, 135, 270, 66, 135, 66, 270, 135, 135, 135, 135, 270, 66, 66, 66, 135, 270, 66, 270, 270, 135, 135, 135, 66, 270, 66, 135, 135, 66, 135, 66, 66, 135, 135, 270, 135, 66, 135, 270, 135, 135, 270, 135, 270, 66, 270, 270, 135, 66, 66, 270, 135, 66, 135, 135, 270, 135, 66, 66, 270, 270, 270, 270, 270, 270, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 270, 270, 66, 270, 66, 135, 270, 270, 270, 135, 66, 270, 135, 66, 66, 66, 66, 66, 270, 135, 66, 270, 66, 270, 66, 66, 135, 135, 270, 135, 270, 66, 135, 66, 270, 270, 66, 270, 135, 66, 270, 66, 66, 270, 270, 135, 270, 270, 66, 270, 135, 135, 66, 135, 270, 270, 66, 270, 135, 66, 135, 270, 66, 66, 66, 66, 66, 66, 270, 66, 66, 66, 270, 66, 135, 270, 270, 135, 66, 270, 66, 135, 135, 66, 135, 66, 270, 66, 66, 270, 66, 270, 270, 135, 270, 135, 66, 135, 270, 135, 270, 66, 270, 66, 135, 270, 135, 270, 135, 270, 135, 270, 135, 66, 270, 66, 270, 135, 135, 66, 135, 270, 135, 135, 270, 66, 270, 270, 135, 66, 270, 270, 135, 135, 270, 270, 135, 135, 135, 135, 270, 270, 135, 135, 270, 66, 270, 135, 270, 270, 66, 270, 135, 135, 270, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 270, 135, 66, 66, 66, 66]
Prompts retrieved: 40305 . Total input tokens: 8947755 . Total output tokens: 7913671
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 1.707500304095447,
    "estimated_duration": 3599.633642353166,
    "input_throughput": 920.8137075397407,
    "output_throughput": 812.4821275112026,
    "total_throughput": 1733.2958350509434,
    "itl": 24.4048148378436,
    "ttft": 85136.32679418664,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7305,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 48.303647978395865,
    "arrivals": 13666,
    "finished_requests": 13454,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.7075803256593645. Arrivals time: 0.045178362634032965 Scheduler time: 1.2937325495295227 Scheduler overhead time: 0.12855851836502552 Adapter cache time: 0.052177832927554846 Engine time: 0.12571982387453318 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-16/adapters_256_slots_16_rate_0.025-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-16/adapters_256_slots_16_rate_0.025-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 270, 66, 270, 270, 66, 270, 135, 270, 66, 135, 66, 270, 135, 135, 135, 135, 270, 66, 66, 66, 135, 270, 66, 270, 270, 135, 135, 135, 66, 270, 66, 135, 135, 66, 135, 66, 66, 135, 135, 270, 135, 66, 135, 270, 135, 135, 270, 135, 270, 66, 270, 270, 135, 66, 66, 270, 135, 66, 135, 135, 270, 135, 66, 66, 270, 270, 270, 270, 270, 270, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 270, 270, 66, 270, 66, 135, 270, 270, 270, 135, 66, 270, 135, 66, 66, 66, 66, 66, 270, 135, 66, 270, 66, 270, 66, 66, 135, 135, 270, 135, 270, 66, 135, 66, 270, 270, 66, 270, 135, 66, 270, 66, 66, 270, 270, 135, 270, 270, 66, 270, 135, 135, 66, 135, 270, 270, 66, 270, 135, 66, 135, 270, 66, 66, 66, 66, 66, 66, 270, 66, 66, 66, 270, 66, 135, 270, 270, 135, 66, 270, 66, 135, 135, 66, 135, 66, 270, 66, 66, 270, 66, 270, 270, 135, 270, 135, 66, 135, 270, 135, 270, 66, 270, 66, 135, 270, 135, 270, 135, 270, 135, 270, 135, 66, 270, 66, 270, 135, 135, 66, 135, 270, 135, 135, 270, 66, 270, 270, 135, 66, 270, 270, 135, 135, 270, 270, 135, 135, 135, 135, 270, 270, 135, 135, 270, 66, 270, 135, 270, 270, 66, 270, 135, 135, 270, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 270, 135, 66, 66, 66, 66]
Prompts retrieved: 40305 . Total input tokens: 8947755 . Total output tokens: 7913671
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 1.7280217502266169,
    "estimated_duration": 3599.622718154178,
    "input_throughput": 920.4225718685697,
    "output_throughput": 812.3159644629064,
    "total_throughput": 1732.738536331476,
    "itl": 24.439738271069658,
    "ttft": 85648.60956144237,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7276,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 53.25307975379569,
    "arrivals": 13666,
    "finished_requests": 13453,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.728123901411891. Arrivals time: 0.04681428708136082 Scheduler time: 1.3108642562292516 Scheduler overhead time: 0.12859802972525358 Adapter cache time: 0.05272159771993756 Engine time: 0.12767118820920587 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-32/adapters_256_slots_16_rate_0.025-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-32/adapters_256_slots_16_rate_0.025-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 270, 66, 270, 270, 66, 270, 135, 270, 66, 135, 66, 270, 135, 135, 135, 135, 270, 66, 66, 66, 135, 270, 66, 270, 270, 135, 135, 135, 66, 270, 66, 135, 135, 66, 135, 66, 66, 135, 135, 270, 135, 66, 135, 270, 135, 135, 270, 135, 270, 66, 270, 270, 135, 66, 66, 270, 135, 66, 135, 135, 270, 135, 66, 66, 270, 270, 270, 270, 270, 270, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 270, 270, 66, 270, 66, 135, 270, 270, 270, 135, 66, 270, 135, 66, 66, 66, 66, 66, 270, 135, 66, 270, 66, 270, 66, 66, 135, 135, 270, 135, 270, 66, 135, 66, 270, 270, 66, 270, 135, 66, 270, 66, 66, 270, 270, 135, 270, 270, 66, 270, 135, 135, 66, 135, 270, 270, 66, 270, 135, 66, 135, 270, 66, 66, 66, 66, 66, 66, 270, 66, 66, 66, 270, 66, 135, 270, 270, 135, 66, 270, 66, 135, 135, 66, 135, 66, 270, 66, 66, 270, 66, 270, 270, 135, 270, 135, 66, 135, 270, 135, 270, 66, 270, 66, 135, 270, 135, 270, 135, 270, 135, 270, 135, 66, 270, 66, 270, 135, 135, 66, 135, 270, 135, 135, 270, 66, 270, 270, 135, 66, 270, 270, 135, 135, 270, 270, 135, 135, 135, 135, 270, 270, 135, 135, 270, 66, 270, 135, 270, 270, 66, 270, 135, 135, 270, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 270, 135, 66, 66, 66, 66]
Prompts retrieved: 40305 . Total input tokens: 8947755 . Total output tokens: 7913671
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 1.7178054358810186,
    "estimated_duration": 3599.639357178495,
    "input_throughput": 920.4788789166745,
    "output_throughput": 812.3311003833439,
    "total_throughput": 1732.8099793000185,
    "itl": 24.44731912045302,
    "ttft": 85423.37377348298,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7274,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 54.69036014567277,
    "arrivals": 13666,
    "finished_requests": 13454,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.717885413672775. Arrivals time: 0.046012393198907375 Scheduler time: 1.304128230549395 Scheduler overhead time: 0.12751326942816377 Adapter cache time: 0.05219641933217645 Engine time: 0.12695278320461512 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-16/adapters_256_slots_16_rate_0.025-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-16/adapters_256_slots_16_rate_0.025-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 270, 66, 270, 270, 66, 270, 135, 270, 66, 135, 66, 270, 135, 135, 135, 135, 270, 66, 66, 66, 135, 270, 66, 270, 270, 135, 135, 135, 66, 270, 66, 135, 135, 66, 135, 66, 66, 135, 135, 270, 135, 66, 135, 270, 135, 135, 270, 135, 270, 66, 270, 270, 135, 66, 66, 270, 135, 66, 135, 135, 270, 135, 66, 66, 270, 270, 270, 270, 270, 270, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 270, 270, 66, 270, 66, 135, 270, 270, 270, 135, 66, 270, 135, 66, 66, 66, 66, 66, 270, 135, 66, 270, 66, 270, 66, 66, 135, 135, 270, 135, 270, 66, 135, 66, 270, 270, 66, 270, 135, 66, 270, 66, 66, 270, 270, 135, 270, 270, 66, 270, 135, 135, 66, 135, 270, 270, 66, 270, 135, 66, 135, 270, 66, 66, 66, 66, 66, 66, 270, 66, 66, 66, 270, 66, 135, 270, 270, 135, 66, 270, 66, 135, 135, 66, 135, 66, 270, 66, 66, 270, 66, 270, 270, 135, 270, 135, 66, 135, 270, 135, 270, 66, 270, 66, 135, 270, 135, 270, 135, 270, 135, 270, 135, 66, 270, 66, 270, 135, 135, 66, 135, 270, 135, 135, 270, 66, 270, 270, 135, 66, 270, 270, 135, 135, 270, 270, 135, 135, 135, 135, 270, 270, 135, 135, 270, 66, 270, 135, 270, 270, 66, 270, 135, 135, 270, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 270, 135, 66, 66, 66, 66]
Prompts retrieved: 40305 . Total input tokens: 8947755 . Total output tokens: 7913671
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 1.7260689907707274,
    "estimated_duration": 3599.621917375158,
    "input_throughput": 920.594461325098,
    "output_throughput": 812.4055990114751,
    "total_throughput": 1733.0000603365731,
    "itl": 24.41432226957796,
    "ttft": 85797.45482417026,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7293,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 49.93547704765278,
    "arrivals": 13666,
    "finished_requests": 13452,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.726141246035695. Arrivals time: 0.045671595726162195 Scheduler time: 1.3099946067668498 Scheduler overhead time: 0.1299880025908351 Adapter cache time: 0.05233817920088768 Engine time: 0.1265829405747354 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-32/adapters_256_slots_16_rate_0.025-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-32/adapters_256_slots_16_rate_0.025-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 270, 66, 270, 270, 66, 270, 135, 270, 66, 135, 66, 270, 135, 135, 135, 135, 270, 66, 66, 66, 135, 270, 66, 270, 270, 135, 135, 135, 66, 270, 66, 135, 135, 66, 135, 66, 66, 135, 135, 270, 135, 66, 135, 270, 135, 135, 270, 135, 270, 66, 270, 270, 135, 66, 66, 270, 135, 66, 135, 135, 270, 135, 66, 66, 270, 270, 270, 270, 270, 270, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 270, 270, 66, 270, 66, 135, 270, 270, 270, 135, 66, 270, 135, 66, 66, 66, 66, 66, 270, 135, 66, 270, 66, 270, 66, 66, 135, 135, 270, 135, 270, 66, 135, 66, 270, 270, 66, 270, 135, 66, 270, 66, 66, 270, 270, 135, 270, 270, 66, 270, 135, 135, 66, 135, 270, 270, 66, 270, 135, 66, 135, 270, 66, 66, 66, 66, 66, 66, 270, 66, 66, 66, 270, 66, 135, 270, 270, 135, 66, 270, 66, 135, 135, 66, 135, 66, 270, 66, 66, 270, 66, 270, 270, 135, 270, 135, 66, 135, 270, 135, 270, 66, 270, 66, 135, 270, 135, 270, 135, 270, 135, 270, 135, 66, 270, 66, 270, 135, 135, 66, 135, 270, 135, 135, 270, 66, 270, 270, 135, 66, 270, 270, 135, 135, 270, 270, 135, 135, 135, 135, 270, 270, 135, 135, 270, 66, 270, 135, 270, 270, 66, 270, 135, 135, 270, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 270, 135, 66, 66, 66, 66]
Prompts retrieved: 40305 . Total input tokens: 8947755 . Total output tokens: 7913671
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 1.691946311853826,
    "estimated_duration": 3599.6423879250565,
    "input_throughput": 920.5900594781507,
    "output_throughput": 812.4815425584133,
    "total_throughput": 1733.071602036564,
    "itl": 24.439143893394245,
    "ttft": 84849.4199960747,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7280,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 54.223405312534084,
    "arrivals": 13666,
    "finished_requests": 13456,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.6920373919419944. Arrivals time: 0.044776104390621185 Scheduler time: 1.2813996360637248 Scheduler overhead time: 0.1287486581131816 Adapter cache time: 0.05170469405129552 Engine time: 0.12377986637875438 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-16/adapters_256_slots_16_rate_0.025-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-16/adapters_256_slots_16_rate_0.025-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 270, 66, 270, 270, 66, 270, 135, 270, 66, 135, 66, 270, 135, 135, 135, 135, 270, 66, 66, 66, 135, 270, 66, 270, 270, 135, 135, 135, 66, 270, 66, 135, 135, 66, 135, 66, 66, 135, 135, 270, 135, 66, 135, 270, 135, 135, 270, 135, 270, 66, 270, 270, 135, 66, 66, 270, 135, 66, 135, 135, 270, 135, 66, 66, 270, 270, 270, 270, 270, 270, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 270, 270, 66, 270, 66, 135, 270, 270, 270, 135, 66, 270, 135, 66, 66, 66, 66, 66, 270, 135, 66, 270, 66, 270, 66, 66, 135, 135, 270, 135, 270, 66, 135, 66, 270, 270, 66, 270, 135, 66, 270, 66, 66, 270, 270, 135, 270, 270, 66, 270, 135, 135, 66, 135, 270, 270, 66, 270, 135, 66, 135, 270, 66, 66, 66, 66, 66, 66, 270, 66, 66, 66, 270, 66, 135, 270, 270, 135, 66, 270, 66, 135, 135, 66, 135, 66, 270, 66, 66, 270, 66, 270, 270, 135, 270, 135, 66, 135, 270, 135, 270, 66, 270, 66, 135, 270, 135, 270, 135, 270, 135, 270, 135, 66, 270, 66, 270, 135, 135, 66, 135, 270, 135, 135, 270, 66, 270, 270, 135, 66, 270, 270, 135, 135, 270, 270, 135, 135, 135, 135, 270, 270, 135, 135, 270, 66, 270, 135, 270, 270, 66, 270, 135, 135, 270, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 270, 135, 66, 66, 66, 66]
Prompts retrieved: 40305 . Total input tokens: 8947755 . Total output tokens: 7913671
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 1.7389917620457709,
    "estimated_duration": 3599.623275452318,
    "input_throughput": 920.8163594795898,
    "output_throughput": 812.4844674565281,
    "total_throughput": 1733.3008269361178,
    "itl": 24.394054365029316,
    "ttft": 85141.93905063707,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7309,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 46.660078154635144,
    "arrivals": 13666,
    "finished_requests": 13454,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.7390815149992704. Arrivals time: 0.04612457612529397 Scheduler time: 1.3197531327605247 Scheduler overhead time: 0.12868559919297695 Adapter cache time: 0.05337087344378233 Engine time: 0.1289865463040769 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-32/adapters_256_slots_16_rate_0.025-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-32/adapters_256_slots_16_rate_0.025-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 270, 66, 270, 270, 66, 270, 135, 270, 66, 135, 66, 270, 135, 135, 135, 135, 270, 66, 66, 66, 135, 270, 66, 270, 270, 135, 135, 135, 66, 270, 66, 135, 135, 66, 135, 66, 66, 135, 135, 270, 135, 66, 135, 270, 135, 135, 270, 135, 270, 66, 270, 270, 135, 66, 66, 270, 135, 66, 135, 135, 270, 135, 66, 66, 270, 270, 270, 270, 270, 270, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 270, 270, 66, 270, 66, 135, 270, 270, 270, 135, 66, 270, 135, 66, 66, 66, 66, 66, 270, 135, 66, 270, 66, 270, 66, 66, 135, 135, 270, 135, 270, 66, 135, 66, 270, 270, 66, 270, 135, 66, 270, 66, 66, 270, 270, 135, 270, 270, 66, 270, 135, 135, 66, 135, 270, 270, 66, 270, 135, 66, 135, 270, 66, 66, 66, 66, 66, 66, 270, 66, 66, 66, 270, 66, 135, 270, 270, 135, 66, 270, 66, 135, 135, 66, 135, 66, 270, 66, 66, 270, 66, 270, 270, 135, 270, 135, 66, 135, 270, 135, 270, 66, 270, 66, 135, 270, 135, 270, 135, 270, 135, 270, 135, 66, 270, 66, 270, 135, 135, 66, 135, 270, 135, 135, 270, 66, 270, 270, 135, 66, 270, 270, 135, 135, 270, 270, 135, 135, 135, 135, 270, 270, 135, 135, 270, 66, 270, 135, 270, 270, 66, 270, 135, 135, 270, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 270, 135, 66, 66, 66, 66]
Prompts retrieved: 40305 . Total input tokens: 8947755 . Total output tokens: 7913671
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 1.7390776663087308,
    "estimated_duration": 3599.6181146840177,
    "input_throughput": 920.4237489761709,
    "output_throughput": 812.3170033154136,
    "total_throughput": 1732.7407522915846,
    "itl": 24.441586359246784,
    "ttft": 85660.96269391326,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7276,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 53.6880133970424,
    "arrivals": 13666,
    "finished_requests": 13453,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.739151919260621. Arrivals time: 0.04532598052173853 Scheduler time: 1.3256051479838789 Scheduler overhead time: 0.12741909408941865 Adapter cache time: 0.05239766789600253 Engine time: 0.12724111275747418 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-8/adapters_256_slots_16_rate_0.025-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-8/adapters_256_slots_16_rate_0.025-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 270, 33, 270, 270, 33, 270, 135, 270, 33, 135, 33, 270, 135, 135, 135, 135, 270, 33, 33, 33, 135, 270, 33, 270, 270, 135, 135, 135, 33, 270, 33, 135, 135, 33, 135, 33, 33, 135, 135, 270, 135, 33, 135, 270, 135, 135, 270, 135, 270, 33, 270, 270, 135, 33, 33, 270, 135, 33, 135, 135, 270, 135, 33, 33, 270, 270, 270, 270, 270, 270, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 270, 270, 33, 270, 33, 135, 270, 270, 270, 135, 33, 270, 135, 33, 33, 33, 33, 33, 270, 135, 33, 270, 33, 270, 33, 33, 135, 135, 270, 135, 270, 33, 135, 33, 270, 270, 33, 270, 135, 33, 270, 33, 33, 270, 270, 135, 270, 270, 33, 270, 135, 135, 33, 135, 270, 270, 33, 270, 135, 33, 135, 270, 33, 33, 33, 33, 33, 33, 270, 33, 33, 33, 270, 33, 135, 270, 270, 135, 33, 270, 33, 135, 135, 33, 135, 33, 270, 33, 33, 270, 33, 270, 270, 135, 270, 135, 33, 135, 270, 135, 270, 33, 270, 33, 135, 270, 135, 270, 135, 270, 135, 270, 135, 33, 270, 33, 270, 135, 135, 33, 135, 270, 135, 135, 270, 33, 270, 270, 135, 33, 270, 270, 135, 135, 270, 270, 135, 135, 135, 135, 270, 270, 135, 135, 270, 33, 270, 135, 270, 270, 33, 270, 135, 135, 270, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 270, 135, 33, 33, 33, 33]
Prompts retrieved: 37500 . Total input tokens: 8312563 . Total output tokens: 7358299
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 1.5336888981983066,
    "estimated_duration": 3599.978604969524,
    "input_throughput": 861.0331727308254,
    "output_throughput": 752.5125277856848,
    "total_throughput": 1613.5457005165104,
    "itl": 24.201162924601334,
    "ttft": 37816.89772720453,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8086,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 53.46793943235032,
    "arrivals": 12685,
    "finished_requests": 12616,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5337618100456893. Arrivals time: 0.04257682990282774 Scheduler time: 1.1215036208741367 Scheduler overhead time: 0.1281133876182139 Adapter cache time: 0.054669168777763844 Engine time: 0.1250617797486484 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-16/adapters_256_slots_16_rate_0.025-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-16/adapters_256_slots_16_rate_0.025-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 270, 33, 270, 270, 33, 270, 135, 270, 33, 135, 33, 270, 135, 135, 135, 135, 270, 33, 33, 33, 135, 270, 33, 270, 270, 135, 135, 135, 33, 270, 33, 135, 135, 33, 135, 33, 33, 135, 135, 270, 135, 33, 135, 270, 135, 135, 270, 135, 270, 33, 270, 270, 135, 33, 33, 270, 135, 33, 135, 135, 270, 135, 33, 33, 270, 270, 270, 270, 270, 270, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 270, 270, 33, 270, 33, 135, 270, 270, 270, 135, 33, 270, 135, 33, 33, 33, 33, 33, 270, 135, 33, 270, 33, 270, 33, 33, 135, 135, 270, 135, 270, 33, 135, 33, 270, 270, 33, 270, 135, 33, 270, 33, 33, 270, 270, 135, 270, 270, 33, 270, 135, 135, 33, 135, 270, 270, 33, 270, 135, 33, 135, 270, 33, 33, 33, 33, 33, 33, 270, 33, 33, 33, 270, 33, 135, 270, 270, 135, 33, 270, 33, 135, 135, 33, 135, 33, 270, 33, 33, 270, 33, 270, 270, 135, 270, 135, 33, 135, 270, 135, 270, 33, 270, 33, 135, 270, 135, 270, 135, 270, 135, 270, 135, 33, 270, 33, 270, 135, 135, 33, 135, 270, 135, 135, 270, 33, 270, 270, 135, 33, 270, 270, 135, 135, 270, 270, 135, 135, 135, 135, 270, 270, 135, 135, 270, 33, 270, 135, 270, 270, 33, 270, 135, 135, 270, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 270, 135, 33, 33, 33, 33]
Prompts retrieved: 37500 . Total input tokens: 8312563 . Total output tokens: 7358299
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 1.5367307397536933,
    "estimated_duration": 3599.9570425042684,
    "input_throughput": 860.8036049908853,
    "output_throughput": 752.4000892287837,
    "total_throughput": 1613.2036942196692,
    "itl": 24.248215078530286,
    "ttft": 38543.746964645616,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8061,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 59.000214807999136,
    "arrivals": 12685,
    "finished_requests": 12614,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5368193010799587. Arrivals time: 0.043468001298606396 Scheduler time: 1.1189530030824244 Scheduler overhead time: 0.12887925282120705 Adapter cache time: 0.05543684680014849 Engine time: 0.12737716175615788 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-32/adapters_256_slots_16_rate_0.025-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-32/adapters_256_slots_16_rate_0.025-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 270, 33, 270, 270, 33, 270, 135, 270, 33, 135, 33, 270, 135, 135, 135, 135, 270, 33, 33, 33, 135, 270, 33, 270, 270, 135, 135, 135, 33, 270, 33, 135, 135, 33, 135, 33, 33, 135, 135, 270, 135, 33, 135, 270, 135, 135, 270, 135, 270, 33, 270, 270, 135, 33, 33, 270, 135, 33, 135, 135, 270, 135, 33, 33, 270, 270, 270, 270, 270, 270, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 270, 270, 33, 270, 33, 135, 270, 270, 270, 135, 33, 270, 135, 33, 33, 33, 33, 33, 270, 135, 33, 270, 33, 270, 33, 33, 135, 135, 270, 135, 270, 33, 135, 33, 270, 270, 33, 270, 135, 33, 270, 33, 33, 270, 270, 135, 270, 270, 33, 270, 135, 135, 33, 135, 270, 270, 33, 270, 135, 33, 135, 270, 33, 33, 33, 33, 33, 33, 270, 33, 33, 33, 270, 33, 135, 270, 270, 135, 33, 270, 33, 135, 135, 33, 135, 33, 270, 33, 33, 270, 33, 270, 270, 135, 270, 135, 33, 135, 270, 135, 270, 33, 270, 33, 135, 270, 135, 270, 135, 270, 135, 270, 135, 33, 270, 33, 270, 135, 135, 33, 135, 270, 135, 135, 270, 33, 270, 270, 135, 33, 270, 270, 135, 135, 270, 270, 135, 135, 135, 135, 270, 270, 135, 135, 270, 33, 270, 135, 270, 270, 33, 270, 135, 135, 270, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 270, 135, 33, 33, 33, 33]
Prompts retrieved: 37500 . Total input tokens: 8312563 . Total output tokens: 7358299
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 1.539997735992074,
    "estimated_duration": 3599.9697481354087,
    "input_throughput": 860.6694546821669,
    "output_throughput": 752.3968781690214,
    "total_throughput": 1613.0663328511885,
    "itl": 24.25762966989163,
    "ttft": 38895.5151074027,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8050,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 60.52506506580426,
    "arrivals": 12685,
    "finished_requests": 12613,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5400730078108609. Arrivals time: 0.043228404596447945 Scheduler time: 1.1232758560217917 Scheduler overhead time: 0.12841646652668715 Adapter cache time: 0.055386245250701904 Engine time: 0.12751059280708432 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-16/adapters_256_slots_16_rate_0.025-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-16/adapters_256_slots_16_rate_0.025-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 270, 33, 270, 270, 33, 270, 135, 270, 33, 135, 33, 270, 135, 135, 135, 135, 270, 33, 33, 33, 135, 270, 33, 270, 270, 135, 135, 135, 33, 270, 33, 135, 135, 33, 135, 33, 33, 135, 135, 270, 135, 33, 135, 270, 135, 135, 270, 135, 270, 33, 270, 270, 135, 33, 33, 270, 135, 33, 135, 135, 270, 135, 33, 33, 270, 270, 270, 270, 270, 270, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 270, 270, 33, 270, 33, 135, 270, 270, 270, 135, 33, 270, 135, 33, 33, 33, 33, 33, 270, 135, 33, 270, 33, 270, 33, 33, 135, 135, 270, 135, 270, 33, 135, 33, 270, 270, 33, 270, 135, 33, 270, 33, 33, 270, 270, 135, 270, 270, 33, 270, 135, 135, 33, 135, 270, 270, 33, 270, 135, 33, 135, 270, 33, 33, 33, 33, 33, 33, 270, 33, 33, 33, 270, 33, 135, 270, 270, 135, 33, 270, 33, 135, 135, 33, 135, 33, 270, 33, 33, 270, 33, 270, 270, 135, 270, 135, 33, 135, 270, 135, 270, 33, 270, 33, 135, 270, 135, 270, 135, 270, 135, 270, 135, 33, 270, 33, 270, 135, 135, 33, 135, 270, 135, 135, 270, 33, 270, 270, 135, 33, 270, 270, 135, 135, 270, 270, 135, 135, 135, 135, 270, 270, 135, 135, 270, 33, 270, 135, 270, 270, 33, 270, 135, 135, 270, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 270, 135, 33, 33, 33, 33]
Prompts retrieved: 37500 . Total input tokens: 8312563 . Total output tokens: 7358299
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 1.5373534080572426,
    "estimated_duration": 3599.959186138122,
    "input_throughput": 861.0375395186694,
    "output_throughput": 752.516031412602,
    "total_throughput": 1613.5535709312715,
    "itl": 24.21638900713794,
    "ttft": 38137.532084141334,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8077,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 55.30418496006828,
    "arrivals": 12685,
    "finished_requests": 12615,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5374080101028085. Arrivals time: 0.04330415930598974 Scheduler time: 1.1203818754293025 Scheduler overhead time: 0.12931729340925813 Adapter cache time: 0.05538126267492771 Engine time: 0.1274321940727532 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-32/adapters_256_slots_16_rate_0.025-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-32/adapters_256_slots_16_rate_0.025-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 270, 33, 270, 270, 33, 270, 135, 270, 33, 135, 33, 270, 135, 135, 135, 135, 270, 33, 33, 33, 135, 270, 33, 270, 270, 135, 135, 135, 33, 270, 33, 135, 135, 33, 135, 33, 33, 135, 135, 270, 135, 33, 135, 270, 135, 135, 270, 135, 270, 33, 270, 270, 135, 33, 33, 270, 135, 33, 135, 135, 270, 135, 33, 33, 270, 270, 270, 270, 270, 270, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 270, 270, 33, 270, 33, 135, 270, 270, 270, 135, 33, 270, 135, 33, 33, 33, 33, 33, 270, 135, 33, 270, 33, 270, 33, 33, 135, 135, 270, 135, 270, 33, 135, 33, 270, 270, 33, 270, 135, 33, 270, 33, 33, 270, 270, 135, 270, 270, 33, 270, 135, 135, 33, 135, 270, 270, 33, 270, 135, 33, 135, 270, 33, 33, 33, 33, 33, 33, 270, 33, 33, 33, 270, 33, 135, 270, 270, 135, 33, 270, 33, 135, 135, 33, 135, 33, 270, 33, 33, 270, 33, 270, 270, 135, 270, 135, 33, 135, 270, 135, 270, 33, 270, 33, 135, 270, 135, 270, 135, 270, 135, 270, 135, 33, 270, 33, 270, 135, 135, 33, 135, 270, 135, 135, 270, 33, 270, 270, 135, 33, 270, 270, 135, 135, 270, 270, 135, 135, 135, 135, 270, 270, 135, 135, 270, 33, 270, 135, 270, 270, 33, 270, 135, 135, 270, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 270, 135, 33, 33, 33, 33]
Prompts retrieved: 37500 . Total input tokens: 8312563 . Total output tokens: 7358299
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 1.5367332589812577,
    "estimated_duration": 3599.961066834024,
    "input_throughput": 860.8026427144893,
    "output_throughput": 752.3992481346688,
    "total_throughput": 1613.201890849158,
    "itl": 24.25630940246776,
    "ttft": 38587.10316827016,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8053,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 59.98008341560646,
    "arrivals": 12685,
    "finished_requests": 12614,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5367935989052057. Arrivals time: 0.04274011915549636 Scheduler time: 1.1240829159505665 Scheduler overhead time: 0.12865819223225117 Adapter cache time: 0.054643016308546066 Engine time: 0.12499576341360807 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-16/adapters_256_slots_16_rate_0.025-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-16/adapters_256_slots_16_rate_0.025-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 270, 33, 270, 270, 33, 270, 135, 270, 33, 135, 33, 270, 135, 135, 135, 135, 270, 33, 33, 33, 135, 270, 33, 270, 270, 135, 135, 135, 33, 270, 33, 135, 135, 33, 135, 33, 33, 135, 135, 270, 135, 33, 135, 270, 135, 135, 270, 135, 270, 33, 270, 270, 135, 33, 33, 270, 135, 33, 135, 135, 270, 135, 33, 33, 270, 270, 270, 270, 270, 270, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 270, 270, 33, 270, 33, 135, 270, 270, 270, 135, 33, 270, 135, 33, 33, 33, 33, 33, 270, 135, 33, 270, 33, 270, 33, 33, 135, 135, 270, 135, 270, 33, 135, 33, 270, 270, 33, 270, 135, 33, 270, 33, 33, 270, 270, 135, 270, 270, 33, 270, 135, 135, 33, 135, 270, 270, 33, 270, 135, 33, 135, 270, 33, 33, 33, 33, 33, 33, 270, 33, 33, 33, 270, 33, 135, 270, 270, 135, 33, 270, 33, 135, 135, 33, 135, 33, 270, 33, 33, 270, 33, 270, 270, 135, 270, 135, 33, 135, 270, 135, 270, 33, 270, 33, 135, 270, 135, 270, 135, 270, 135, 270, 135, 33, 270, 33, 270, 135, 135, 33, 135, 270, 135, 135, 270, 33, 270, 270, 135, 33, 270, 270, 135, 135, 270, 270, 135, 135, 135, 135, 270, 270, 135, 135, 270, 33, 270, 135, 270, 270, 33, 270, 135, 135, 270, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 270, 135, 33, 33, 33, 33]
Prompts retrieved: 37500 . Total input tokens: 8312563 . Total output tokens: 7358299
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 1.5488752219825983,
    "estimated_duration": 3599.959490771753,
    "input_throughput": 861.0377444373663,
    "output_throughput": 752.516523295445,
    "total_throughput": 1613.5542677328112,
    "itl": 24.189709381651806,
    "ttft": 37788.20515815459,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8090,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 51.6459204092214,
    "arrivals": 12685,
    "finished_requests": 12616,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5489685512147844. Arrivals time: 0.04352741315960884 Scheduler time: 1.1287923054769635 Scheduler overhead time: 0.13070829678326845 Adapter cache time: 0.05568684823811054 Engine time: 0.12729111686348915 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-32/adapters_256_slots_16_rate_0.025-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-32/adapters_256_slots_16_rate_0.025-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 270, 33, 270, 270, 33, 270, 135, 270, 33, 135, 33, 270, 135, 135, 135, 135, 270, 33, 33, 33, 135, 270, 33, 270, 270, 135, 135, 135, 33, 270, 33, 135, 135, 33, 135, 33, 33, 135, 135, 270, 135, 33, 135, 270, 135, 135, 270, 135, 270, 33, 270, 270, 135, 33, 33, 270, 135, 33, 135, 135, 270, 135, 33, 33, 270, 270, 270, 270, 270, 270, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 270, 270, 33, 270, 33, 135, 270, 270, 270, 135, 33, 270, 135, 33, 33, 33, 33, 33, 270, 135, 33, 270, 33, 270, 33, 33, 135, 135, 270, 135, 270, 33, 135, 33, 270, 270, 33, 270, 135, 33, 270, 33, 33, 270, 270, 135, 270, 270, 33, 270, 135, 135, 33, 135, 270, 270, 33, 270, 135, 33, 135, 270, 33, 33, 33, 33, 33, 33, 270, 33, 33, 33, 270, 33, 135, 270, 270, 135, 33, 270, 33, 135, 135, 33, 135, 33, 270, 33, 33, 270, 33, 270, 270, 135, 270, 135, 33, 135, 270, 135, 270, 33, 270, 33, 135, 270, 135, 270, 135, 270, 135, 270, 135, 33, 270, 33, 270, 135, 135, 33, 135, 270, 135, 135, 270, 33, 270, 270, 135, 33, 270, 270, 135, 135, 270, 270, 135, 135, 135, 135, 270, 270, 135, 135, 270, 33, 270, 135, 270, 270, 33, 270, 135, 135, 270, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 270, 135, 33, 33, 33, 33]
Prompts retrieved: 37500 . Total input tokens: 8312563 . Total output tokens: 7358299
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 1.547408030834049,
    "estimated_duration": 3599.98438434643,
    "input_throughput": 860.7970671968876,
    "output_throughput": 752.3943747583068,
    "total_throughput": 1613.1914419551943,
    "itl": 24.251048511495128,
    "ttft": 38547.822999066775,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8059,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 59.464973659529804,
    "arrivals": 12685,
    "finished_requests": 12614,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5474979430437088. Arrivals time: 0.043454661034047604 Scheduler time: 1.13135458342731 Scheduler overhead time: 0.12908168556168675 Adapter cache time: 0.05519259860739112 Engine time: 0.126693666446954 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-8/adapters_256_slots_16_rate_0.025-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-8/adapters_256_slots_16_rate_0.025-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 270, 33, 270, 270, 33, 270, 66, 270, 33, 66, 33, 270, 66, 66, 66, 66, 270, 33, 33, 33, 66, 270, 33, 270, 270, 66, 66, 66, 33, 270, 33, 66, 66, 33, 66, 33, 33, 66, 66, 270, 66, 33, 66, 270, 66, 66, 270, 66, 270, 33, 270, 270, 66, 33, 33, 270, 66, 33, 66, 66, 270, 66, 33, 33, 270, 270, 270, 270, 270, 270, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 270, 270, 33, 270, 33, 66, 270, 270, 270, 66, 33, 270, 66, 33, 33, 33, 33, 33, 270, 66, 33, 270, 33, 270, 33, 33, 66, 66, 270, 66, 270, 33, 66, 33, 270, 270, 33, 270, 66, 33, 270, 33, 33, 270, 270, 66, 270, 270, 33, 270, 66, 66, 33, 66, 270, 270, 33, 270, 66, 33, 66, 270, 33, 33, 33, 33, 33, 33, 270, 33, 33, 33, 270, 33, 66, 270, 270, 66, 33, 270, 33, 66, 66, 33, 66, 33, 270, 33, 33, 270, 33, 270, 270, 66, 270, 66, 33, 66, 270, 66, 270, 33, 270, 33, 66, 270, 66, 270, 66, 270, 66, 270, 66, 33, 270, 33, 270, 66, 66, 33, 66, 270, 66, 66, 270, 33, 270, 270, 66, 33, 270, 270, 66, 66, 270, 270, 66, 66, 66, 66, 270, 270, 66, 66, 270, 33, 270, 66, 270, 270, 33, 270, 66, 66, 270, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 270, 66, 33, 33, 33, 33]
Prompts retrieved: 31635 . Total input tokens: 6994323 . Total output tokens: 6216854
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 1.2668236610479653,
    "estimated_duration": 3599.777950814482,
    "input_throughput": 727.8465604822047,
    "output_throughput": 643.9538859544131,
    "total_throughput": 1371.800446436618,
    "itl": 24.027323800187375,
    "ttft": 10433.6677262744,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8909,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 58.909952065646756,
    "arrivals": 10714,
    "finished_requests": 10694,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2669096272438765. Arrivals time: 0.03911982988938689 Scheduler time: 0.8521999698132277 Scheduler overhead time: 0.12851275689899921 Adapter cache time: 0.05725101847201586 Engine time: 0.1277282373048365 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-16/adapters_256_slots_16_rate_0.025-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-16/adapters_256_slots_16_rate_0.025-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 270, 33, 270, 270, 33, 270, 66, 270, 33, 66, 33, 270, 66, 66, 66, 66, 270, 33, 33, 33, 66, 270, 33, 270, 270, 66, 66, 66, 33, 270, 33, 66, 66, 33, 66, 33, 33, 66, 66, 270, 66, 33, 66, 270, 66, 66, 270, 66, 270, 33, 270, 270, 66, 33, 33, 270, 66, 33, 66, 66, 270, 66, 33, 33, 270, 270, 270, 270, 270, 270, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 270, 270, 33, 270, 33, 66, 270, 270, 270, 66, 33, 270, 66, 33, 33, 33, 33, 33, 270, 66, 33, 270, 33, 270, 33, 33, 66, 66, 270, 66, 270, 33, 66, 33, 270, 270, 33, 270, 66, 33, 270, 33, 33, 270, 270, 66, 270, 270, 33, 270, 66, 66, 33, 66, 270, 270, 33, 270, 66, 33, 66, 270, 33, 33, 33, 33, 33, 33, 270, 33, 33, 33, 270, 33, 66, 270, 270, 66, 33, 270, 33, 66, 66, 33, 66, 33, 270, 33, 33, 270, 33, 270, 270, 66, 270, 66, 33, 66, 270, 66, 270, 33, 270, 33, 66, 270, 66, 270, 66, 270, 66, 270, 66, 33, 270, 33, 270, 66, 66, 33, 66, 270, 66, 66, 270, 33, 270, 270, 66, 33, 270, 270, 66, 66, 270, 270, 66, 66, 66, 66, 270, 270, 66, 66, 270, 33, 270, 66, 270, 270, 33, 270, 66, 66, 270, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 270, 66, 33, 33, 33, 33]
Prompts retrieved: 31635 . Total input tokens: 6994323 . Total output tokens: 6216854
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 1.2551668770611286,
    "estimated_duration": 3599.790158373493,
    "input_throughput": 727.8440922189319,
    "output_throughput": 643.9517021868274,
    "total_throughput": 1371.7957944057594,
    "itl": 24.066067901346987,
    "ttft": 10530.660792252771,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8888,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 65.0432389611731,
    "arrivals": 10714,
    "finished_requests": 10694,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2552293059416115. Arrivals time: 0.03887417446821928 Scheduler time: 0.8400759757496417 Scheduler overhead time: 0.12873877864331007 Adapter cache time: 0.05715016555041075 Engine time: 0.12769395485520363 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-32/adapters_256_slots_16_rate_0.025-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-32/adapters_256_slots_16_rate_0.025-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 270, 33, 270, 270, 33, 270, 66, 270, 33, 66, 33, 270, 66, 66, 66, 66, 270, 33, 33, 33, 66, 270, 33, 270, 270, 66, 66, 66, 33, 270, 33, 66, 66, 33, 66, 33, 33, 66, 66, 270, 66, 33, 66, 270, 66, 66, 270, 66, 270, 33, 270, 270, 66, 33, 33, 270, 66, 33, 66, 66, 270, 66, 33, 33, 270, 270, 270, 270, 270, 270, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 270, 270, 33, 270, 33, 66, 270, 270, 270, 66, 33, 270, 66, 33, 33, 33, 33, 33, 270, 66, 33, 270, 33, 270, 33, 33, 66, 66, 270, 66, 270, 33, 66, 33, 270, 270, 33, 270, 66, 33, 270, 33, 33, 270, 270, 66, 270, 270, 33, 270, 66, 66, 33, 66, 270, 270, 33, 270, 66, 33, 66, 270, 33, 33, 33, 33, 33, 33, 270, 33, 33, 33, 270, 33, 66, 270, 270, 66, 33, 270, 33, 66, 66, 33, 66, 33, 270, 33, 33, 270, 33, 270, 270, 66, 270, 66, 33, 66, 270, 66, 270, 33, 270, 33, 66, 270, 66, 270, 66, 270, 66, 270, 66, 33, 270, 33, 270, 66, 66, 33, 66, 270, 66, 66, 270, 33, 270, 270, 66, 33, 270, 270, 66, 66, 270, 270, 66, 66, 66, 66, 270, 270, 66, 66, 270, 33, 270, 66, 270, 270, 33, 270, 66, 66, 270, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 270, 66, 33, 33, 33, 33]
Prompts retrieved: 31635 . Total input tokens: 6994323 . Total output tokens: 6216854
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 1.254666794091463,
    "estimated_duration": 3599.7896043763726,
    "input_throughput": 727.8394817337944,
    "output_throughput": 643.9512457010902,
    "total_throughput": 1371.7907274348847,
    "itl": 24.07608323733619,
    "ttft": 10889.980630020296,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8887,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 66.81310791465535,
    "arrivals": 10714,
    "finished_requests": 10693,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2547454601153731. Arrivals time: 0.03849464422091842 Scheduler time: 0.8437343100085855 Scheduler overhead time: 0.1287335674278438 Adapter cache time: 0.056960474234074354 Engine time: 0.1249788785353303 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-16/adapters_256_slots_16_rate_0.025-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-16/adapters_256_slots_16_rate_0.025-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 270, 33, 270, 270, 33, 270, 66, 270, 33, 66, 33, 270, 66, 66, 66, 66, 270, 33, 33, 33, 66, 270, 33, 270, 270, 66, 66, 66, 33, 270, 33, 66, 66, 33, 66, 33, 33, 66, 66, 270, 66, 33, 66, 270, 66, 66, 270, 66, 270, 33, 270, 270, 66, 33, 33, 270, 66, 33, 66, 66, 270, 66, 33, 33, 270, 270, 270, 270, 270, 270, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 270, 270, 33, 270, 33, 66, 270, 270, 270, 66, 33, 270, 66, 33, 33, 33, 33, 33, 270, 66, 33, 270, 33, 270, 33, 33, 66, 66, 270, 66, 270, 33, 66, 33, 270, 270, 33, 270, 66, 33, 270, 33, 33, 270, 270, 66, 270, 270, 33, 270, 66, 66, 33, 66, 270, 270, 33, 270, 66, 33, 66, 270, 33, 33, 33, 33, 33, 33, 270, 33, 33, 33, 270, 33, 66, 270, 270, 66, 33, 270, 33, 66, 66, 33, 66, 33, 270, 33, 33, 270, 33, 270, 270, 66, 270, 66, 33, 66, 270, 66, 270, 33, 270, 33, 66, 270, 66, 270, 66, 270, 66, 270, 66, 33, 270, 33, 270, 66, 66, 33, 66, 270, 66, 66, 270, 33, 270, 270, 66, 33, 270, 270, 66, 66, 270, 270, 66, 66, 66, 66, 270, 270, 66, 66, 270, 33, 270, 66, 270, 270, 33, 270, 66, 66, 270, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 270, 66, 33, 33, 33, 33]
Prompts retrieved: 31635 . Total input tokens: 6994323 . Total output tokens: 6216854
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 1.2565594189800322,
    "estimated_duration": 3599.8017632621873,
    "input_throughput": 727.8417458259268,
    "output_throughput": 643.9496262425616,
    "total_throughput": 1371.7913720684885,
    "itl": 24.032852324449962,
    "ttft": 10457.478808770613,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8908,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 60.6883518571618,
    "arrivals": 10714,
    "finished_requests": 10694,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2566950749605894. Arrivals time: 0.038852188270539045 Scheduler time: 0.8445448875427246 Scheduler overhead time: 0.12846317514777184 Adapter cache time: 0.057037392631173134 Engine time: 0.12493736017495394 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-32/adapters_256_slots_16_rate_0.025-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-32/adapters_256_slots_16_rate_0.025-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 270, 33, 270, 270, 33, 270, 66, 270, 33, 66, 33, 270, 66, 66, 66, 66, 270, 33, 33, 33, 66, 270, 33, 270, 270, 66, 66, 66, 33, 270, 33, 66, 66, 33, 66, 33, 33, 66, 66, 270, 66, 33, 66, 270, 66, 66, 270, 66, 270, 33, 270, 270, 66, 33, 33, 270, 66, 33, 66, 66, 270, 66, 33, 33, 270, 270, 270, 270, 270, 270, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 270, 270, 33, 270, 33, 66, 270, 270, 270, 66, 33, 270, 66, 33, 33, 33, 33, 33, 270, 66, 33, 270, 33, 270, 33, 33, 66, 66, 270, 66, 270, 33, 66, 33, 270, 270, 33, 270, 66, 33, 270, 33, 33, 270, 270, 66, 270, 270, 33, 270, 66, 66, 33, 66, 270, 270, 33, 270, 66, 33, 66, 270, 33, 33, 33, 33, 33, 33, 270, 33, 33, 33, 270, 33, 66, 270, 270, 66, 33, 270, 33, 66, 66, 33, 66, 33, 270, 33, 33, 270, 33, 270, 270, 66, 270, 66, 33, 66, 270, 66, 270, 33, 270, 33, 66, 270, 66, 270, 66, 270, 66, 270, 66, 33, 270, 33, 270, 66, 66, 33, 66, 270, 66, 66, 270, 33, 270, 270, 66, 33, 270, 270, 66, 66, 270, 270, 66, 66, 66, 66, 270, 270, 66, 66, 270, 33, 270, 66, 270, 270, 33, 270, 66, 66, 270, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 270, 66, 33, 33, 33, 33]
Prompts retrieved: 31635 . Total input tokens: 6994323 . Total output tokens: 6216854
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 1.2583367470651865,
    "estimated_duration": 3599.799533067747,
    "input_throughput": 727.842196747874,
    "output_throughput": 643.9500251905762,
    "total_throughput": 1371.7922219384502,
    "itl": 24.073845186577046,
    "ttft": 10544.01242898343,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8888,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 66.1467067230079,
    "arrivals": 10714,
    "finished_requests": 10694,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2583981091156602. Arrivals time: 0.03908007265999913 Scheduler time: 0.8468476212583482 Scheduler overhead time: 0.12732943845912814 Adapter cache time: 0.05701510002836585 Engine time: 0.12529015494510531 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-16/adapters_256_slots_16_rate_0.025-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-16/adapters_256_slots_16_rate_0.025-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 270, 33, 270, 270, 33, 270, 66, 270, 33, 66, 33, 270, 66, 66, 66, 66, 270, 33, 33, 33, 66, 270, 33, 270, 270, 66, 66, 66, 33, 270, 33, 66, 66, 33, 66, 33, 33, 66, 66, 270, 66, 33, 66, 270, 66, 66, 270, 66, 270, 33, 270, 270, 66, 33, 33, 270, 66, 33, 66, 66, 270, 66, 33, 33, 270, 270, 270, 270, 270, 270, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 270, 270, 33, 270, 33, 66, 270, 270, 270, 66, 33, 270, 66, 33, 33, 33, 33, 33, 270, 66, 33, 270, 33, 270, 33, 33, 66, 66, 270, 66, 270, 33, 66, 33, 270, 270, 33, 270, 66, 33, 270, 33, 33, 270, 270, 66, 270, 270, 33, 270, 66, 66, 33, 66, 270, 270, 33, 270, 66, 33, 66, 270, 33, 33, 33, 33, 33, 33, 270, 33, 33, 33, 270, 33, 66, 270, 270, 66, 33, 270, 33, 66, 66, 33, 66, 33, 270, 33, 33, 270, 33, 270, 270, 66, 270, 66, 33, 66, 270, 66, 270, 33, 270, 33, 66, 270, 66, 270, 66, 270, 66, 270, 66, 33, 270, 33, 270, 66, 66, 33, 66, 270, 66, 66, 270, 33, 270, 270, 66, 33, 270, 270, 66, 66, 270, 270, 66, 66, 66, 66, 270, 270, 66, 66, 270, 33, 270, 66, 270, 270, 33, 270, 66, 66, 270, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 270, 66, 33, 33, 33, 33]
Prompts retrieved: 31635 . Total input tokens: 6994323 . Total output tokens: 6216854
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 1.2418956262990832,
    "estimated_duration": 3599.787477897995,
    "input_throughput": 727.8446341865529,
    "output_throughput": 643.9521816864564,
    "total_throughput": 1371.7968158730093,
    "itl": 24.007208260013194,
    "ttft": 10420.220462691073,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8912,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 56.893503422371076,
    "arrivals": 10714,
    "finished_requests": 10694,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2419755891896784. Arrivals time: 0.03832900570705533 Scheduler time: 0.829884095583111 Scheduler overhead time: 0.12910835491493344 Adapter cache time: 0.0569475800730288 Engine time: 0.12582349916920066 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-32/adapters_256_slots_16_rate_0.025-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-32/adapters_256_slots_16_rate_0.025-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 270, 33, 270, 270, 33, 270, 66, 270, 33, 66, 33, 270, 66, 66, 66, 66, 270, 33, 33, 33, 66, 270, 33, 270, 270, 66, 66, 66, 33, 270, 33, 66, 66, 33, 66, 33, 33, 66, 66, 270, 66, 33, 66, 270, 66, 66, 270, 66, 270, 33, 270, 270, 66, 33, 33, 270, 66, 33, 66, 66, 270, 66, 33, 33, 270, 270, 270, 270, 270, 270, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 270, 270, 33, 270, 33, 66, 270, 270, 270, 66, 33, 270, 66, 33, 33, 33, 33, 33, 270, 66, 33, 270, 33, 270, 33, 33, 66, 66, 270, 66, 270, 33, 66, 33, 270, 270, 33, 270, 66, 33, 270, 33, 33, 270, 270, 66, 270, 270, 33, 270, 66, 66, 33, 66, 270, 270, 33, 270, 66, 33, 66, 270, 33, 33, 33, 33, 33, 33, 270, 33, 33, 33, 270, 33, 66, 270, 270, 66, 33, 270, 33, 66, 66, 33, 66, 33, 270, 33, 33, 270, 33, 270, 270, 66, 270, 66, 33, 66, 270, 66, 270, 33, 270, 33, 66, 270, 66, 270, 66, 270, 66, 270, 66, 33, 270, 33, 270, 66, 66, 33, 66, 270, 66, 66, 270, 33, 270, 270, 66, 33, 270, 270, 66, 66, 270, 270, 66, 66, 66, 66, 270, 270, 66, 66, 270, 33, 270, 66, 270, 270, 33, 270, 66, 66, 270, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 270, 66, 33, 33, 33, 33]
Prompts retrieved: 31635 . Total input tokens: 6994323 . Total output tokens: 6216854
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 1.2726218728348613,
    "estimated_duration": 3599.793056566629,
    "input_throughput": 727.8435062317046,
    "output_throughput": 643.9511837413575,
    "total_throughput": 1371.794689973062,
    "itl": 24.076687686669263,
    "ttft": 10536.292822788211,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8889,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 65.58324276813794,
    "arrivals": 10714,
    "finished_requests": 10694,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2726965970359743. Arrivals time: 0.03850368969142437 Scheduler time: 0.8610822218470275 Scheduler overhead time: 0.12878363858908415 Adapter cache time: 0.057287135161459446 Engine time: 0.12487580394372344 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-8/adapters_256_slots_16_rate_0.0125-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-8/adapters_256_slots_16_rate_0.0125-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 135, 33, 135, 135, 33, 135, 66, 135, 33, 66, 33, 135, 66, 66, 66, 66, 135, 33, 33, 33, 66, 135, 33, 135, 135, 66, 66, 66, 33, 135, 33, 66, 66, 33, 66, 33, 33, 66, 66, 135, 66, 33, 66, 135, 66, 66, 135, 66, 135, 33, 135, 135, 66, 33, 33, 135, 66, 33, 66, 66, 135, 66, 33, 33, 135, 135, 135, 135, 135, 135, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 135, 135, 33, 135, 33, 66, 135, 135, 135, 66, 33, 135, 66, 33, 33, 33, 33, 33, 135, 66, 33, 135, 33, 135, 33, 33, 66, 66, 135, 66, 135, 33, 66, 33, 135, 135, 33, 135, 66, 33, 135, 33, 33, 135, 135, 66, 135, 135, 33, 135, 66, 66, 33, 66, 135, 135, 33, 135, 66, 33, 66, 135, 33, 33, 33, 33, 33, 33, 135, 33, 33, 33, 135, 33, 66, 135, 135, 66, 33, 135, 33, 66, 66, 33, 66, 33, 135, 33, 33, 135, 33, 135, 135, 66, 135, 66, 33, 66, 135, 66, 135, 33, 135, 33, 66, 135, 66, 135, 66, 135, 66, 135, 66, 33, 135, 33, 135, 66, 66, 33, 66, 135, 66, 66, 135, 33, 135, 135, 66, 33, 135, 135, 66, 66, 135, 135, 66, 66, 66, 66, 135, 135, 66, 66, 135, 33, 135, 66, 135, 135, 33, 135, 66, 66, 135, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 135, 66, 33, 33, 33, 33]
Prompts retrieved: 20025 . Total input tokens: 4440916 . Total output tokens: 3939215
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 0.9482862241566181,
    "estimated_duration": 3599.5031381404374,
    "input_throughput": 455.20254799568744,
    "output_throughput": 407.5926436774671,
    "total_throughput": 862.7951916731546,
    "itl": 22.351419160482013,
    "ttft": 3823.6917510082517,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6224,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 41.15563381485583,
    "arrivals": 6790,
    "finished_requests": 6783,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9483572128228843. Arrivals time: 0.029218008741736412 Scheduler time: 0.5472296429798007 Scheduler overhead time: 0.13243099302053452 Adapter cache time: 0.044615916442126036 Engine time: 0.13012091862037778 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-16/adapters_256_slots_16_rate_0.0125-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-16/adapters_256_slots_16_rate_0.0125-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 135, 33, 135, 135, 33, 135, 66, 135, 33, 66, 33, 135, 66, 66, 66, 66, 135, 33, 33, 33, 66, 135, 33, 135, 135, 66, 66, 66, 33, 135, 33, 66, 66, 33, 66, 33, 33, 66, 66, 135, 66, 33, 66, 135, 66, 66, 135, 66, 135, 33, 135, 135, 66, 33, 33, 135, 66, 33, 66, 66, 135, 66, 33, 33, 135, 135, 135, 135, 135, 135, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 135, 135, 33, 135, 33, 66, 135, 135, 135, 66, 33, 135, 66, 33, 33, 33, 33, 33, 135, 66, 33, 135, 33, 135, 33, 33, 66, 66, 135, 66, 135, 33, 66, 33, 135, 135, 33, 135, 66, 33, 135, 33, 33, 135, 135, 66, 135, 135, 33, 135, 66, 66, 33, 66, 135, 135, 33, 135, 66, 33, 66, 135, 33, 33, 33, 33, 33, 33, 135, 33, 33, 33, 135, 33, 66, 135, 135, 66, 33, 135, 33, 66, 66, 33, 66, 33, 135, 33, 33, 135, 33, 135, 135, 66, 135, 66, 33, 66, 135, 66, 135, 33, 135, 33, 66, 135, 66, 135, 66, 135, 66, 135, 66, 33, 135, 33, 135, 66, 66, 33, 66, 135, 66, 66, 135, 33, 135, 135, 66, 33, 135, 135, 66, 66, 135, 135, 66, 66, 66, 66, 135, 135, 66, 66, 135, 33, 135, 66, 135, 135, 33, 135, 66, 66, 135, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 135, 66, 33, 33, 33, 33]
Prompts retrieved: 20025 . Total input tokens: 4440916 . Total output tokens: 3939215
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 0.9503347501158714,
    "estimated_duration": 3599.5099113617034,
    "input_throughput": 455.20169143808533,
    "output_throughput": 407.59187670773235,
    "total_throughput": 862.7935681458176,
    "itl": 22.38092335513407,
    "ttft": 3825.119283097152,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6225,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 45.548224407391,
    "arrivals": 6790,
    "finished_requests": 6783,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9505675272084773. Arrivals time: 0.029158316552639008 Scheduler time: 0.5486404937691987 Scheduler overhead time: 0.13057235116139054 Adapter cache time: 0.045068558771163225 Engine time: 0.1327030509710312 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-32/adapters_256_slots_16_rate_0.0125-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-32/adapters_256_slots_16_rate_0.0125-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 135, 33, 135, 135, 33, 135, 66, 135, 33, 66, 33, 135, 66, 66, 66, 66, 135, 33, 33, 33, 66, 135, 33, 135, 135, 66, 66, 66, 33, 135, 33, 66, 66, 33, 66, 33, 33, 66, 66, 135, 66, 33, 66, 135, 66, 66, 135, 66, 135, 33, 135, 135, 66, 33, 33, 135, 66, 33, 66, 66, 135, 66, 33, 33, 135, 135, 135, 135, 135, 135, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 135, 135, 33, 135, 33, 66, 135, 135, 135, 66, 33, 135, 66, 33, 33, 33, 33, 33, 135, 66, 33, 135, 33, 135, 33, 33, 66, 66, 135, 66, 135, 33, 66, 33, 135, 135, 33, 135, 66, 33, 135, 33, 33, 135, 135, 66, 135, 135, 33, 135, 66, 66, 33, 66, 135, 135, 33, 135, 66, 33, 66, 135, 33, 33, 33, 33, 33, 33, 135, 33, 33, 33, 135, 33, 66, 135, 135, 66, 33, 135, 33, 66, 66, 33, 66, 33, 135, 33, 33, 135, 33, 135, 135, 66, 135, 66, 33, 66, 135, 66, 135, 33, 135, 33, 66, 135, 66, 135, 66, 135, 66, 135, 66, 33, 135, 33, 135, 66, 66, 33, 66, 135, 66, 66, 135, 33, 135, 135, 66, 33, 135, 135, 66, 66, 135, 135, 66, 66, 66, 66, 135, 135, 66, 66, 135, 33, 135, 66, 135, 135, 33, 135, 66, 66, 135, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 135, 66, 33, 33, 33, 33]
Prompts retrieved: 20025 . Total input tokens: 4440916 . Total output tokens: 3939215
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 0.9465323342010379,
    "estimated_duration": 3599.5160168632874,
    "input_throughput": 455.2009193246581,
    "output_throughput": 407.5911853501062,
    "total_throughput": 862.7921046747642,
    "itl": 22.38838831527198,
    "ttft": 3825.834164403332,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6225,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 46.78417409330919,
    "arrivals": 6790,
    "finished_requests": 6783,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.946590478066355. Arrivals time: 0.02906387997791171 Scheduler time: 0.5428338418714702 Scheduler overhead time: 0.1315432502888143 Adapter cache time: 0.045640811789780855 Engine time: 0.13299531256780028 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-16/adapters_256_slots_16_rate_0.0125-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-16/adapters_256_slots_16_rate_0.0125-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 135, 33, 135, 135, 33, 135, 66, 135, 33, 66, 33, 135, 66, 66, 66, 66, 135, 33, 33, 33, 66, 135, 33, 135, 135, 66, 66, 66, 33, 135, 33, 66, 66, 33, 66, 33, 33, 66, 66, 135, 66, 33, 66, 135, 66, 66, 135, 66, 135, 33, 135, 135, 66, 33, 33, 135, 66, 33, 66, 66, 135, 66, 33, 33, 135, 135, 135, 135, 135, 135, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 135, 135, 33, 135, 33, 66, 135, 135, 135, 66, 33, 135, 66, 33, 33, 33, 33, 33, 135, 66, 33, 135, 33, 135, 33, 33, 66, 66, 135, 66, 135, 33, 66, 33, 135, 135, 33, 135, 66, 33, 135, 33, 33, 135, 135, 66, 135, 135, 33, 135, 66, 66, 33, 66, 135, 135, 33, 135, 66, 33, 66, 135, 33, 33, 33, 33, 33, 33, 135, 33, 33, 33, 135, 33, 66, 135, 135, 66, 33, 135, 33, 66, 66, 33, 66, 33, 135, 33, 33, 135, 33, 135, 135, 66, 135, 66, 33, 66, 135, 66, 135, 33, 135, 33, 66, 135, 66, 135, 66, 135, 66, 135, 66, 33, 135, 33, 135, 66, 66, 33, 66, 135, 66, 66, 135, 33, 135, 135, 66, 33, 135, 135, 66, 66, 135, 135, 66, 66, 66, 66, 135, 135, 66, 66, 135, 33, 135, 66, 135, 135, 33, 135, 66, 66, 135, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 135, 66, 33, 33, 33, 33]
Prompts retrieved: 20025 . Total input tokens: 4440916 . Total output tokens: 3939215
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 0.9467366300523281,
    "estimated_duration": 3599.517299851406,
    "input_throughput": 455.20075707585573,
    "output_throughput": 407.5910400710022,
    "total_throughput": 862.7917971468579,
    "itl": 22.36120611049445,
    "ttft": 3824.1527177815833,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6225,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 42.55105532601157,
    "arrivals": 6790,
    "finished_requests": 6783,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9467954351566732. Arrivals time: 0.028985948767513037 Scheduler time: 0.546479822602123 Scheduler overhead time: 0.13137601176276803 Adapter cache time: 0.0451027937233448 Engine time: 0.13062164187431335 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-32/adapters_256_slots_16_rate_0.0125-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-32/adapters_256_slots_16_rate_0.0125-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 135, 33, 135, 135, 33, 135, 66, 135, 33, 66, 33, 135, 66, 66, 66, 66, 135, 33, 33, 33, 66, 135, 33, 135, 135, 66, 66, 66, 33, 135, 33, 66, 66, 33, 66, 33, 33, 66, 66, 135, 66, 33, 66, 135, 66, 66, 135, 66, 135, 33, 135, 135, 66, 33, 33, 135, 66, 33, 66, 66, 135, 66, 33, 33, 135, 135, 135, 135, 135, 135, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 135, 135, 33, 135, 33, 66, 135, 135, 135, 66, 33, 135, 66, 33, 33, 33, 33, 33, 135, 66, 33, 135, 33, 135, 33, 33, 66, 66, 135, 66, 135, 33, 66, 33, 135, 135, 33, 135, 66, 33, 135, 33, 33, 135, 135, 66, 135, 135, 33, 135, 66, 66, 33, 66, 135, 135, 33, 135, 66, 33, 66, 135, 33, 33, 33, 33, 33, 33, 135, 33, 33, 33, 135, 33, 66, 135, 135, 66, 33, 135, 33, 66, 66, 33, 66, 33, 135, 33, 33, 135, 33, 135, 135, 66, 135, 66, 33, 66, 135, 66, 135, 33, 135, 33, 66, 135, 66, 135, 66, 135, 66, 135, 66, 33, 135, 33, 135, 66, 66, 33, 66, 135, 66, 66, 135, 33, 135, 135, 66, 33, 135, 135, 66, 66, 135, 135, 66, 66, 66, 66, 135, 135, 66, 66, 135, 33, 135, 66, 135, 135, 33, 135, 66, 66, 135, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 135, 66, 33, 33, 33, 33]
Prompts retrieved: 20025 . Total input tokens: 4440916 . Total output tokens: 3939215
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 0.9483017651364207,
    "estimated_duration": 3599.515593679022,
    "input_throughput": 455.20097284126655,
    "output_throughput": 407.5912332693808,
    "total_throughput": 862.7922061106474,
    "itl": 22.3886644538392,
    "ttft": 3825.4732710892217,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6224,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 46.33105507637231,
    "arrivals": 6790,
    "finished_requests": 6783,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9483654680661857. Arrivals time: 0.0296638417057693 Scheduler time: 0.5457748076878488 Scheduler overhead time: 0.1316155707463622 Adapter cache time: 0.045797621831297874 Engine time: 0.13101708935573697 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-16/adapters_256_slots_16_rate_0.0125-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-16/adapters_256_slots_16_rate_0.0125-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 135, 33, 135, 135, 33, 135, 66, 135, 33, 66, 33, 135, 66, 66, 66, 66, 135, 33, 33, 33, 66, 135, 33, 135, 135, 66, 66, 66, 33, 135, 33, 66, 66, 33, 66, 33, 33, 66, 66, 135, 66, 33, 66, 135, 66, 66, 135, 66, 135, 33, 135, 135, 66, 33, 33, 135, 66, 33, 66, 66, 135, 66, 33, 33, 135, 135, 135, 135, 135, 135, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 135, 135, 33, 135, 33, 66, 135, 135, 135, 66, 33, 135, 66, 33, 33, 33, 33, 33, 135, 66, 33, 135, 33, 135, 33, 33, 66, 66, 135, 66, 135, 33, 66, 33, 135, 135, 33, 135, 66, 33, 135, 33, 33, 135, 135, 66, 135, 135, 33, 135, 66, 66, 33, 66, 135, 135, 33, 135, 66, 33, 66, 135, 33, 33, 33, 33, 33, 33, 135, 33, 33, 33, 135, 33, 66, 135, 135, 66, 33, 135, 33, 66, 66, 33, 66, 33, 135, 33, 33, 135, 33, 135, 135, 66, 135, 66, 33, 66, 135, 66, 135, 33, 135, 33, 66, 135, 66, 135, 66, 135, 66, 135, 66, 33, 135, 33, 135, 66, 66, 33, 66, 135, 66, 66, 135, 33, 135, 135, 66, 33, 135, 135, 66, 66, 135, 135, 66, 66, 66, 66, 135, 135, 66, 66, 135, 33, 135, 66, 135, 135, 33, 135, 66, 66, 135, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 135, 66, 33, 33, 33, 33]
Prompts retrieved: 20025 . Total input tokens: 4440916 . Total output tokens: 3939215
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 0.9406322902068496,
    "estimated_duration": 3599.5160888881023,
    "input_throughput": 455.2009102162777,
    "output_throughput": 407.5911771943766,
    "total_throughput": 862.7920874106543,
    "itl": 22.34034675168894,
    "ttft": 3823.0380323311674,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6225,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 39.73990785505576,
    "arrivals": 6790,
    "finished_requests": 6783,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9407073711045086. Arrivals time: 0.029211097862571478 Scheduler time: 0.539368340279907 Scheduler overhead time: 0.13335279887542129 Adapter cache time: 0.04489821894094348 Engine time: 0.12906190240755677 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-32/adapters_256_slots_16_rate_0.0125-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-32/adapters_256_slots_16_rate_0.0125-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 135, 33, 135, 135, 33, 135, 66, 135, 33, 66, 33, 135, 66, 66, 66, 66, 135, 33, 33, 33, 66, 135, 33, 135, 135, 66, 66, 66, 33, 135, 33, 66, 66, 33, 66, 33, 33, 66, 66, 135, 66, 33, 66, 135, 66, 66, 135, 66, 135, 33, 135, 135, 66, 33, 33, 135, 66, 33, 66, 66, 135, 66, 33, 33, 135, 135, 135, 135, 135, 135, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 135, 135, 33, 135, 33, 66, 135, 135, 135, 66, 33, 135, 66, 33, 33, 33, 33, 33, 135, 66, 33, 135, 33, 135, 33, 33, 66, 66, 135, 66, 135, 33, 66, 33, 135, 135, 33, 135, 66, 33, 135, 33, 33, 135, 135, 66, 135, 135, 33, 135, 66, 66, 33, 66, 135, 135, 33, 135, 66, 33, 66, 135, 33, 33, 33, 33, 33, 33, 135, 33, 33, 33, 135, 33, 66, 135, 135, 66, 33, 135, 33, 66, 66, 33, 66, 33, 135, 33, 33, 135, 33, 135, 135, 66, 135, 66, 33, 66, 135, 66, 135, 33, 135, 33, 66, 135, 66, 135, 66, 135, 66, 135, 66, 33, 135, 33, 135, 66, 66, 33, 66, 135, 66, 66, 135, 33, 135, 135, 66, 33, 135, 135, 66, 66, 135, 135, 66, 66, 66, 66, 135, 135, 66, 66, 135, 33, 135, 66, 135, 135, 33, 135, 66, 66, 135, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 135, 66, 33, 33, 33, 33]
Prompts retrieved: 20025 . Total input tokens: 4440916 . Total output tokens: 3939215
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 0.9465950257144868,
    "estimated_duration": 3599.5105857089866,
    "input_throughput": 455.2016061587073,
    "output_throughput": 407.591800347775,
    "total_throughput": 862.7934065064824,
    "itl": 22.384968100542366,
    "ttft": 3825.3572429910855,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6226,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 45.92567189972712,
    "arrivals": 6790,
    "finished_requests": 6783,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9467234956100583. Arrivals time: 0.029189203400164843 Scheduler time: 0.542981565464288 Scheduler overhead time: 0.13198620080947876 Adapter cache time: 0.045037690084427595 Engine time: 0.1325097605586052 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.8_size_8-8-8/adapters_256_slots_32_rate_3.2-1.6-0.8_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.8_size_8-8-8/adapters_256_slots_32_rate_3.2-1.6-0.8_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [85 85 86]
Adapter prompts. [17280, 17280, 34560, 8640, 34560, 34560, 8640, 34560, 17280, 34560, 8640, 17280, 8640, 34560, 17280, 17280, 17280, 17280, 34560, 8640, 8640, 8640, 17280, 34560, 8640, 34560, 34560, 17280, 17280, 17280, 8640, 34560, 8640, 17280, 17280, 8640, 17280, 8640, 8640, 17280, 17280, 34560, 17280, 8640, 17280, 34560, 17280, 17280, 34560, 17280, 34560, 8640, 34560, 34560, 17280, 8640, 8640, 34560, 17280, 8640, 17280, 17280, 34560, 17280, 8640, 8640, 34560, 34560, 34560, 34560, 34560, 34560, 8640, 17280, 8640, 17280, 8640, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 34560, 34560, 8640, 34560, 8640, 17280, 34560, 34560, 34560, 17280, 8640, 34560, 17280, 8640, 8640, 8640, 8640, 8640, 34560, 17280, 8640, 34560, 8640, 34560, 8640, 8640, 17280, 17280, 34560, 17280, 34560, 8640, 17280, 8640, 34560, 34560, 8640, 34560, 17280, 8640, 34560, 8640, 8640, 34560, 34560, 17280, 34560, 34560, 8640, 34560, 17280, 17280, 8640, 17280, 34560, 34560, 8640, 34560, 17280, 8640, 17280, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 8640, 8640, 8640, 34560, 8640, 17280, 34560, 34560, 17280, 8640, 34560, 8640, 17280, 17280, 8640, 17280, 8640, 34560, 8640, 8640, 34560, 8640, 34560, 34560, 17280, 34560, 17280, 8640, 17280, 34560, 17280, 34560, 8640, 34560, 8640, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 8640, 34560, 8640, 34560, 17280, 17280, 8640, 17280, 34560, 17280, 17280, 34560, 8640, 34560, 34560, 17280, 8640, 34560, 34560, 17280, 17280, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 34560, 8640, 34560, 17280, 34560, 34560, 8640, 34560, 17280, 17280, 34560, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 17280, 17280, 17280, 34560, 17280, 8640, 8640, 8640, 8640]
Prompts retrieved: 5175360 . Total input tokens: 1154349377 . Total output tokens: 1016244304
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 75.72947432100773,
    "estimated_duration": 3600.001579002157,
    "input_throughput": 6688.126510953837,
    "output_throughput": 5831.57910886778,
    "total_throughput": 12519.705619821616,
    "itl": 99.66046453904727,
    "ttft": 2080439.7798129807,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 515,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.4053906514542605,
    "arrivals": 1724092,
    "finished_requests": 97558,
    "scheduler_time": 243.54033311497565
}
#Debug simulation 
Total elapsed time: 75.7296447167173. Arrivals time: 0.5144497025758028 Scheduler time: 75.01784659083933 Scheduler overhead time: 0.07618246600031853 Adapter cache time: 0.017843738198280334 Engine time: 0.07415396487340331 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.8_size_8-8-16/adapters_256_slots_32_rate_3.2-1.6-0.8_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.8_size_8-8-16/adapters_256_slots_32_rate_3.2-1.6-0.8_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [85 85 86]
Adapter prompts. [17280, 17280, 34560, 8640, 34560, 34560, 8640, 34560, 17280, 34560, 8640, 17280, 8640, 34560, 17280, 17280, 17280, 17280, 34560, 8640, 8640, 8640, 17280, 34560, 8640, 34560, 34560, 17280, 17280, 17280, 8640, 34560, 8640, 17280, 17280, 8640, 17280, 8640, 8640, 17280, 17280, 34560, 17280, 8640, 17280, 34560, 17280, 17280, 34560, 17280, 34560, 8640, 34560, 34560, 17280, 8640, 8640, 34560, 17280, 8640, 17280, 17280, 34560, 17280, 8640, 8640, 34560, 34560, 34560, 34560, 34560, 34560, 8640, 17280, 8640, 17280, 8640, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 34560, 34560, 8640, 34560, 8640, 17280, 34560, 34560, 34560, 17280, 8640, 34560, 17280, 8640, 8640, 8640, 8640, 8640, 34560, 17280, 8640, 34560, 8640, 34560, 8640, 8640, 17280, 17280, 34560, 17280, 34560, 8640, 17280, 8640, 34560, 34560, 8640, 34560, 17280, 8640, 34560, 8640, 8640, 34560, 34560, 17280, 34560, 34560, 8640, 34560, 17280, 17280, 8640, 17280, 34560, 34560, 8640, 34560, 17280, 8640, 17280, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 8640, 8640, 8640, 34560, 8640, 17280, 34560, 34560, 17280, 8640, 34560, 8640, 17280, 17280, 8640, 17280, 8640, 34560, 8640, 8640, 34560, 8640, 34560, 34560, 17280, 34560, 17280, 8640, 17280, 34560, 17280, 34560, 8640, 34560, 8640, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 8640, 34560, 8640, 34560, 17280, 17280, 8640, 17280, 34560, 17280, 17280, 34560, 8640, 34560, 34560, 17280, 8640, 34560, 34560, 17280, 17280, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 34560, 8640, 34560, 17280, 34560, 34560, 8640, 34560, 17280, 17280, 34560, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 17280, 17280, 17280, 34560, 17280, 8640, 8640, 8640, 8640]
Prompts retrieved: 5175360 . Total input tokens: 1154349377 . Total output tokens: 1016244304
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 74.31015567015857,
    "estimated_duration": 3600.0795959091547,
    "input_throughput": 6623.94048928738,
    "output_throughput": 5776.0025705067,
    "total_throughput": 12399.94305979408,
    "itl": 97.06708522868513,
    "ttft": 2083693.7875676882,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 511,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.724461184744728,
    "arrivals": 1724092,
    "finished_requests": 96684,
    "scheduler_time": 246.16743850411268
}
#Debug simulation 
Total elapsed time: 74.31032645702362. Arrivals time: 0.5157251437194645 Scheduler time: 73.59330790583044 Scheduler overhead time: 0.07741452287882566 Adapter cache time: 0.01824225950986147 Engine time: 0.07556429831311107 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.8_size_8-8-32/adapters_256_slots_32_rate_3.2-1.6-0.8_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.8_size_8-8-32/adapters_256_slots_32_rate_3.2-1.6-0.8_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [85 85 86]
Adapter prompts. [17280, 17280, 34560, 8640, 34560, 34560, 8640, 34560, 17280, 34560, 8640, 17280, 8640, 34560, 17280, 17280, 17280, 17280, 34560, 8640, 8640, 8640, 17280, 34560, 8640, 34560, 34560, 17280, 17280, 17280, 8640, 34560, 8640, 17280, 17280, 8640, 17280, 8640, 8640, 17280, 17280, 34560, 17280, 8640, 17280, 34560, 17280, 17280, 34560, 17280, 34560, 8640, 34560, 34560, 17280, 8640, 8640, 34560, 17280, 8640, 17280, 17280, 34560, 17280, 8640, 8640, 34560, 34560, 34560, 34560, 34560, 34560, 8640, 17280, 8640, 17280, 8640, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 34560, 34560, 8640, 34560, 8640, 17280, 34560, 34560, 34560, 17280, 8640, 34560, 17280, 8640, 8640, 8640, 8640, 8640, 34560, 17280, 8640, 34560, 8640, 34560, 8640, 8640, 17280, 17280, 34560, 17280, 34560, 8640, 17280, 8640, 34560, 34560, 8640, 34560, 17280, 8640, 34560, 8640, 8640, 34560, 34560, 17280, 34560, 34560, 8640, 34560, 17280, 17280, 8640, 17280, 34560, 34560, 8640, 34560, 17280, 8640, 17280, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 8640, 8640, 8640, 34560, 8640, 17280, 34560, 34560, 17280, 8640, 34560, 8640, 17280, 17280, 8640, 17280, 8640, 34560, 8640, 8640, 34560, 8640, 34560, 34560, 17280, 34560, 17280, 8640, 17280, 34560, 17280, 34560, 8640, 34560, 8640, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 8640, 34560, 8640, 34560, 17280, 17280, 8640, 17280, 34560, 17280, 17280, 34560, 8640, 34560, 34560, 17280, 8640, 34560, 34560, 17280, 17280, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 34560, 8640, 34560, 17280, 34560, 34560, 8640, 34560, 17280, 17280, 34560, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 17280, 17280, 17280, 34560, 17280, 8640, 8640, 8640, 8640]
Prompts retrieved: 5175360 . Total input tokens: 1154349377 . Total output tokens: 1016244304
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 72.39024794800207,
    "estimated_duration": 3600.080706265171,
    "input_throughput": 6483.068826591155,
    "output_throughput": 5664.700506438559,
    "total_throughput": 12147.769333029713,
    "itl": 91.79359973100264,
    "ttft": 2092942.4332628609,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 499,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.741172332773018,
    "arrivals": 1724092,
    "finished_requests": 94775,
    "scheduler_time": 251.79613995452175
}
#Debug simulation 
Total elapsed time: 72.39041126705706. Arrivals time: 0.9356544325128198 Scheduler time: 71.25025107478723 Scheduler overhead time: 0.07864351896569133 Adapter cache time: 0.018312568310648203 Engine time: 0.07698994176462293 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.8_size_8-16-16/adapters_256_slots_32_rate_3.2-1.6-0.8_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.8_size_8-16-16/adapters_256_slots_32_rate_3.2-1.6-0.8_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [85 85 86]
Adapter prompts. [17280, 17280, 34560, 8640, 34560, 34560, 8640, 34560, 17280, 34560, 8640, 17280, 8640, 34560, 17280, 17280, 17280, 17280, 34560, 8640, 8640, 8640, 17280, 34560, 8640, 34560, 34560, 17280, 17280, 17280, 8640, 34560, 8640, 17280, 17280, 8640, 17280, 8640, 8640, 17280, 17280, 34560, 17280, 8640, 17280, 34560, 17280, 17280, 34560, 17280, 34560, 8640, 34560, 34560, 17280, 8640, 8640, 34560, 17280, 8640, 17280, 17280, 34560, 17280, 8640, 8640, 34560, 34560, 34560, 34560, 34560, 34560, 8640, 17280, 8640, 17280, 8640, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 34560, 34560, 8640, 34560, 8640, 17280, 34560, 34560, 34560, 17280, 8640, 34560, 17280, 8640, 8640, 8640, 8640, 8640, 34560, 17280, 8640, 34560, 8640, 34560, 8640, 8640, 17280, 17280, 34560, 17280, 34560, 8640, 17280, 8640, 34560, 34560, 8640, 34560, 17280, 8640, 34560, 8640, 8640, 34560, 34560, 17280, 34560, 34560, 8640, 34560, 17280, 17280, 8640, 17280, 34560, 34560, 8640, 34560, 17280, 8640, 17280, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 8640, 8640, 8640, 34560, 8640, 17280, 34560, 34560, 17280, 8640, 34560, 8640, 17280, 17280, 8640, 17280, 8640, 34560, 8640, 8640, 34560, 8640, 34560, 34560, 17280, 34560, 17280, 8640, 17280, 34560, 17280, 34560, 8640, 34560, 8640, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 8640, 34560, 8640, 34560, 17280, 17280, 8640, 17280, 34560, 17280, 17280, 34560, 8640, 34560, 34560, 17280, 8640, 34560, 34560, 17280, 17280, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 34560, 8640, 34560, 17280, 34560, 34560, 8640, 34560, 17280, 17280, 34560, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 17280, 17280, 17280, 34560, 17280, 8640, 8640, 8640, 8640]
Prompts retrieved: 5175360 . Total input tokens: 1154349377 . Total output tokens: 1016244304
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 74.19784713117406,
    "estimated_duration": 3600.0731497581028,
    "input_throughput": 6625.019828167262,
    "output_throughput": 5778.677580870224,
    "total_throughput": 12403.697409037486,
    "itl": 97.13120213038435,
    "ttft": 2084027.8216962507,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 524,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.5881132431887046,
    "arrivals": 1724092,
    "finished_requests": 96769,
    "scheduler_time": 246.0881087507888
}
#Debug simulation 
Total elapsed time: 74.19801818020642. Arrivals time: 0.5023728334344923 Scheduler time: 73.49394888011739 Scheduler overhead time: 0.07766905333846807 Adapter cache time: 0.0180354923941195 Engine time: 0.0762403616681695 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.8_size_8-16-32/adapters_256_slots_32_rate_3.2-1.6-0.8_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.8_size_8-16-32/adapters_256_slots_32_rate_3.2-1.6-0.8_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [85 85 86]
Adapter prompts. [17280, 17280, 34560, 8640, 34560, 34560, 8640, 34560, 17280, 34560, 8640, 17280, 8640, 34560, 17280, 17280, 17280, 17280, 34560, 8640, 8640, 8640, 17280, 34560, 8640, 34560, 34560, 17280, 17280, 17280, 8640, 34560, 8640, 17280, 17280, 8640, 17280, 8640, 8640, 17280, 17280, 34560, 17280, 8640, 17280, 34560, 17280, 17280, 34560, 17280, 34560, 8640, 34560, 34560, 17280, 8640, 8640, 34560, 17280, 8640, 17280, 17280, 34560, 17280, 8640, 8640, 34560, 34560, 34560, 34560, 34560, 34560, 8640, 17280, 8640, 17280, 8640, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 34560, 34560, 8640, 34560, 8640, 17280, 34560, 34560, 34560, 17280, 8640, 34560, 17280, 8640, 8640, 8640, 8640, 8640, 34560, 17280, 8640, 34560, 8640, 34560, 8640, 8640, 17280, 17280, 34560, 17280, 34560, 8640, 17280, 8640, 34560, 34560, 8640, 34560, 17280, 8640, 34560, 8640, 8640, 34560, 34560, 17280, 34560, 34560, 8640, 34560, 17280, 17280, 8640, 17280, 34560, 34560, 8640, 34560, 17280, 8640, 17280, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 8640, 8640, 8640, 34560, 8640, 17280, 34560, 34560, 17280, 8640, 34560, 8640, 17280, 17280, 8640, 17280, 8640, 34560, 8640, 8640, 34560, 8640, 34560, 34560, 17280, 34560, 17280, 8640, 17280, 34560, 17280, 34560, 8640, 34560, 8640, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 8640, 34560, 8640, 34560, 17280, 17280, 8640, 17280, 34560, 17280, 17280, 34560, 8640, 34560, 34560, 17280, 8640, 34560, 34560, 17280, 17280, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 34560, 8640, 34560, 17280, 34560, 34560, 8640, 34560, 17280, 17280, 34560, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 17280, 17280, 17280, 34560, 17280, 8640, 8640, 8640, 8640]
Prompts retrieved: 5175360 . Total input tokens: 1154349377 . Total output tokens: 1016244304
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 71.5912957470864,
    "estimated_duration": 3600.094508820597,
    "input_throughput": 6462.63450667634,
    "output_throughput": 5645.43012696026,
    "total_throughput": 12108.0646336366,
    "itl": 91.57869672020684,
    "ttft": 2093023.476610172,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 494,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.667238983293096,
    "arrivals": 1724092,
    "finished_requests": 94332,
    "scheduler_time": 252.58317327873323
}
#Debug simulation 
Total elapsed time: 71.59146513603628. Arrivals time: 0.6136601446196437 Scheduler time: 70.77240287931636 Scheduler overhead time: 0.07893921714276075 Adapter cache time: 0.017844985704869032 Engine time: 0.07763114338740706 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.8_size_16-16-16/adapters_256_slots_32_rate_3.2-1.6-0.8_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.8_size_16-16-16/adapters_256_slots_32_rate_3.2-1.6-0.8_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [85 85 86]
Adapter prompts. [17280, 17280, 34560, 8640, 34560, 34560, 8640, 34560, 17280, 34560, 8640, 17280, 8640, 34560, 17280, 17280, 17280, 17280, 34560, 8640, 8640, 8640, 17280, 34560, 8640, 34560, 34560, 17280, 17280, 17280, 8640, 34560, 8640, 17280, 17280, 8640, 17280, 8640, 8640, 17280, 17280, 34560, 17280, 8640, 17280, 34560, 17280, 17280, 34560, 17280, 34560, 8640, 34560, 34560, 17280, 8640, 8640, 34560, 17280, 8640, 17280, 17280, 34560, 17280, 8640, 8640, 34560, 34560, 34560, 34560, 34560, 34560, 8640, 17280, 8640, 17280, 8640, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 34560, 34560, 8640, 34560, 8640, 17280, 34560, 34560, 34560, 17280, 8640, 34560, 17280, 8640, 8640, 8640, 8640, 8640, 34560, 17280, 8640, 34560, 8640, 34560, 8640, 8640, 17280, 17280, 34560, 17280, 34560, 8640, 17280, 8640, 34560, 34560, 8640, 34560, 17280, 8640, 34560, 8640, 8640, 34560, 34560, 17280, 34560, 34560, 8640, 34560, 17280, 17280, 8640, 17280, 34560, 34560, 8640, 34560, 17280, 8640, 17280, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 8640, 8640, 8640, 34560, 8640, 17280, 34560, 34560, 17280, 8640, 34560, 8640, 17280, 17280, 8640, 17280, 8640, 34560, 8640, 8640, 34560, 8640, 34560, 34560, 17280, 34560, 17280, 8640, 17280, 34560, 17280, 34560, 8640, 34560, 8640, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 8640, 34560, 8640, 34560, 17280, 17280, 8640, 17280, 34560, 17280, 17280, 34560, 8640, 34560, 34560, 17280, 8640, 34560, 34560, 17280, 17280, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 34560, 8640, 34560, 17280, 34560, 34560, 8640, 34560, 17280, 17280, 34560, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 17280, 17280, 17280, 34560, 17280, 8640, 8640, 8640, 8640]
Prompts retrieved: 5175360 . Total input tokens: 1154349377 . Total output tokens: 1016244304
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 74.94800627883524,
    "estimated_duration": 3600.0920124519575,
    "input_throughput": 6623.558763921513,
    "output_throughput": 5779.834217578259,
    "total_throughput": 12403.392981499772,
    "itl": 97.12315799829268,
    "ttft": 2084266.0249866054,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 493,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.147273023701259,
    "arrivals": 1724092,
    "finished_requests": 96708,
    "scheduler_time": 246.0080390187952
}
#Debug simulation 
Total elapsed time: 74.94817298697308. Arrivals time: 0.5171339558437467 Scheduler time: 74.23132161376998 Scheduler overhead time: 0.07686178758740425 Adapter cache time: 0.018068667966872454 Engine time: 0.07499867817386985 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.8_size_16-16-32/adapters_256_slots_32_rate_3.2-1.6-0.8_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.8_size_16-16-32/adapters_256_slots_32_rate_3.2-1.6-0.8_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [85 85 86]
Adapter prompts. [17280, 17280, 34560, 8640, 34560, 34560, 8640, 34560, 17280, 34560, 8640, 17280, 8640, 34560, 17280, 17280, 17280, 17280, 34560, 8640, 8640, 8640, 17280, 34560, 8640, 34560, 34560, 17280, 17280, 17280, 8640, 34560, 8640, 17280, 17280, 8640, 17280, 8640, 8640, 17280, 17280, 34560, 17280, 8640, 17280, 34560, 17280, 17280, 34560, 17280, 34560, 8640, 34560, 34560, 17280, 8640, 8640, 34560, 17280, 8640, 17280, 17280, 34560, 17280, 8640, 8640, 34560, 34560, 34560, 34560, 34560, 34560, 8640, 17280, 8640, 17280, 8640, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 34560, 34560, 8640, 34560, 8640, 17280, 34560, 34560, 34560, 17280, 8640, 34560, 17280, 8640, 8640, 8640, 8640, 8640, 34560, 17280, 8640, 34560, 8640, 34560, 8640, 8640, 17280, 17280, 34560, 17280, 34560, 8640, 17280, 8640, 34560, 34560, 8640, 34560, 17280, 8640, 34560, 8640, 8640, 34560, 34560, 17280, 34560, 34560, 8640, 34560, 17280, 17280, 8640, 17280, 34560, 34560, 8640, 34560, 17280, 8640, 17280, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 8640, 8640, 8640, 34560, 8640, 17280, 34560, 34560, 17280, 8640, 34560, 8640, 17280, 17280, 8640, 17280, 8640, 34560, 8640, 8640, 34560, 8640, 34560, 34560, 17280, 34560, 17280, 8640, 17280, 34560, 17280, 34560, 8640, 34560, 8640, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 8640, 34560, 8640, 34560, 17280, 17280, 8640, 17280, 34560, 17280, 17280, 34560, 8640, 34560, 34560, 17280, 8640, 34560, 34560, 17280, 17280, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 34560, 8640, 34560, 17280, 34560, 34560, 8640, 34560, 17280, 17280, 34560, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 17280, 17280, 17280, 34560, 17280, 8640, 8640, 8640, 8640]
Prompts retrieved: 5175360 . Total input tokens: 1154349377 . Total output tokens: 1016244304
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 72.73753827996552,
    "estimated_duration": 3600.0236089443033,
    "input_throughput": 6470.9261745178765,
    "output_throughput": 5653.336814079453,
    "total_throughput": 12124.26298859733,
    "itl": 91.63415107700385,
    "ttft": 2091483.4585957797,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 492,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.620744349546762,
    "arrivals": 1724092,
    "finished_requests": 94541,
    "scheduler_time": 252.27642571283377
}
#Debug simulation 
Total elapsed time: 72.73770718602464. Arrivals time: 0.47877728240564466 Scheduler time: 72.0530821760185 Scheduler overhead time: 0.07941457442939281 Adapter cache time: 0.018158755730837584 Engine time: 0.07773613138124347 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.4_size_8-8-8/adapters_256_slots_32_rate_3.2-1.6-0.4_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.4_size_8-8-8/adapters_256_slots_32_rate_3.2-1.6-0.4_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [85 85 86]
Adapter prompts. [17280, 17280, 34560, 4320, 34560, 34560, 4320, 34560, 17280, 34560, 4320, 17280, 4320, 34560, 17280, 17280, 17280, 17280, 34560, 4320, 4320, 4320, 17280, 34560, 4320, 34560, 34560, 17280, 17280, 17280, 4320, 34560, 4320, 17280, 17280, 4320, 17280, 4320, 4320, 17280, 17280, 34560, 17280, 4320, 17280, 34560, 17280, 17280, 34560, 17280, 34560, 4320, 34560, 34560, 17280, 4320, 4320, 34560, 17280, 4320, 17280, 17280, 34560, 17280, 4320, 4320, 34560, 34560, 34560, 34560, 34560, 34560, 4320, 17280, 4320, 17280, 4320, 4320, 4320, 17280, 17280, 17280, 4320, 4320, 34560, 34560, 4320, 34560, 4320, 17280, 34560, 34560, 34560, 17280, 4320, 34560, 17280, 4320, 4320, 4320, 4320, 4320, 34560, 17280, 4320, 34560, 4320, 34560, 4320, 4320, 17280, 17280, 34560, 17280, 34560, 4320, 17280, 4320, 34560, 34560, 4320, 34560, 17280, 4320, 34560, 4320, 4320, 34560, 34560, 17280, 34560, 34560, 4320, 34560, 17280, 17280, 4320, 17280, 34560, 34560, 4320, 34560, 17280, 4320, 17280, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 4320, 4320, 34560, 4320, 17280, 34560, 34560, 17280, 4320, 34560, 4320, 17280, 17280, 4320, 17280, 4320, 34560, 4320, 4320, 34560, 4320, 34560, 34560, 17280, 34560, 17280, 4320, 17280, 34560, 17280, 34560, 4320, 34560, 4320, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 4320, 34560, 4320, 34560, 17280, 17280, 4320, 17280, 34560, 17280, 17280, 34560, 4320, 34560, 34560, 17280, 4320, 34560, 34560, 17280, 17280, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 34560, 4320, 34560, 17280, 34560, 34560, 4320, 34560, 17280, 17280, 34560, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 17280, 17280, 17280, 34560, 17280, 4320, 4320, 4320, 4320]
Prompts retrieved: 4808160 . Total input tokens: 1072438965 . Total output tokens: 944139731
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 78.72345862397924,
    "estimated_duration": 3600.0066088233652,
    "input_throughput": 6727.86014910018,
    "output_throughput": 5858.781744540643,
    "total_throughput": 12586.641893640823,
    "itl": 99.64558695338243,
    "ttft": 2071256.6130818187,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 493,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.259917652751357,
    "arrivals": 1601458,
    "finished_requests": 98146,
    "scheduler_time": 242.21035950347758
}
#Debug simulation 
Total elapsed time: 78.72362509230152. Arrivals time: 0.94519865186885 Scheduler time: 77.58194945892319 Scheduler overhead time: 0.07616378366947174 Adapter cache time: 0.01793288206681609 Engine time: 0.07351427851244807 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.4_size_8-8-16/adapters_256_slots_32_rate_3.2-1.6-0.4_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.4_size_8-8-16/adapters_256_slots_32_rate_3.2-1.6-0.4_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [85 85 86]
Adapter prompts. [17280, 17280, 34560, 4320, 34560, 34560, 4320, 34560, 17280, 34560, 4320, 17280, 4320, 34560, 17280, 17280, 17280, 17280, 34560, 4320, 4320, 4320, 17280, 34560, 4320, 34560, 34560, 17280, 17280, 17280, 4320, 34560, 4320, 17280, 17280, 4320, 17280, 4320, 4320, 17280, 17280, 34560, 17280, 4320, 17280, 34560, 17280, 17280, 34560, 17280, 34560, 4320, 34560, 34560, 17280, 4320, 4320, 34560, 17280, 4320, 17280, 17280, 34560, 17280, 4320, 4320, 34560, 34560, 34560, 34560, 34560, 34560, 4320, 17280, 4320, 17280, 4320, 4320, 4320, 17280, 17280, 17280, 4320, 4320, 34560, 34560, 4320, 34560, 4320, 17280, 34560, 34560, 34560, 17280, 4320, 34560, 17280, 4320, 4320, 4320, 4320, 4320, 34560, 17280, 4320, 34560, 4320, 34560, 4320, 4320, 17280, 17280, 34560, 17280, 34560, 4320, 17280, 4320, 34560, 34560, 4320, 34560, 17280, 4320, 34560, 4320, 4320, 34560, 34560, 17280, 34560, 34560, 4320, 34560, 17280, 17280, 4320, 17280, 34560, 34560, 4320, 34560, 17280, 4320, 17280, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 4320, 4320, 34560, 4320, 17280, 34560, 34560, 17280, 4320, 34560, 4320, 17280, 17280, 4320, 17280, 4320, 34560, 4320, 4320, 34560, 4320, 34560, 34560, 17280, 34560, 17280, 4320, 17280, 34560, 17280, 34560, 4320, 34560, 4320, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 4320, 34560, 4320, 34560, 17280, 17280, 4320, 17280, 34560, 17280, 17280, 34560, 4320, 34560, 34560, 17280, 4320, 34560, 34560, 17280, 17280, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 34560, 4320, 34560, 17280, 34560, 34560, 4320, 34560, 17280, 17280, 34560, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 17280, 17280, 17280, 34560, 17280, 4320, 4320, 4320, 4320]
Prompts retrieved: 4808160 . Total input tokens: 1072438965 . Total output tokens: 944139731
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 74.6836937959306,
    "estimated_duration": 3600.033321887099,
    "input_throughput": 6657.850596626138,
    "output_throughput": 5804.76627062047,
    "total_throughput": 12462.616867246608,
    "itl": 97.1018903209107,
    "ttft": 2076441.171601764,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 491,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.587065219120127,
    "arrivals": 1601458,
    "finished_requests": 97165,
    "scheduler_time": 244.79406570987993
}
#Debug simulation 
Total elapsed time: 74.68396375095472. Arrivals time: 0.6900986954569817 Scheduler time: 73.79350603884086 Scheduler overhead time: 0.07655561761930585 Adapter cache time: 0.018063465133309364 Engine time: 0.07583401910960674 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.4_size_8-8-32/adapters_256_slots_32_rate_3.2-1.6-0.4_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.4_size_8-8-32/adapters_256_slots_32_rate_3.2-1.6-0.4_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [85 85 86]
Adapter prompts. [17280, 17280, 34560, 4320, 34560, 34560, 4320, 34560, 17280, 34560, 4320, 17280, 4320, 34560, 17280, 17280, 17280, 17280, 34560, 4320, 4320, 4320, 17280, 34560, 4320, 34560, 34560, 17280, 17280, 17280, 4320, 34560, 4320, 17280, 17280, 4320, 17280, 4320, 4320, 17280, 17280, 34560, 17280, 4320, 17280, 34560, 17280, 17280, 34560, 17280, 34560, 4320, 34560, 34560, 17280, 4320, 4320, 34560, 17280, 4320, 17280, 17280, 34560, 17280, 4320, 4320, 34560, 34560, 34560, 34560, 34560, 34560, 4320, 17280, 4320, 17280, 4320, 4320, 4320, 17280, 17280, 17280, 4320, 4320, 34560, 34560, 4320, 34560, 4320, 17280, 34560, 34560, 34560, 17280, 4320, 34560, 17280, 4320, 4320, 4320, 4320, 4320, 34560, 17280, 4320, 34560, 4320, 34560, 4320, 4320, 17280, 17280, 34560, 17280, 34560, 4320, 17280, 4320, 34560, 34560, 4320, 34560, 17280, 4320, 34560, 4320, 4320, 34560, 34560, 17280, 34560, 34560, 4320, 34560, 17280, 17280, 4320, 17280, 34560, 34560, 4320, 34560, 17280, 4320, 17280, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 4320, 4320, 34560, 4320, 17280, 34560, 34560, 17280, 4320, 34560, 4320, 17280, 17280, 4320, 17280, 4320, 34560, 4320, 4320, 34560, 4320, 34560, 34560, 17280, 34560, 17280, 4320, 17280, 34560, 17280, 34560, 4320, 34560, 4320, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 4320, 34560, 4320, 34560, 17280, 17280, 4320, 17280, 34560, 17280, 17280, 34560, 4320, 34560, 34560, 17280, 4320, 34560, 34560, 17280, 17280, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 34560, 4320, 34560, 17280, 34560, 34560, 4320, 34560, 17280, 17280, 34560, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 17280, 17280, 17280, 34560, 17280, 4320, 4320, 4320, 4320]
Prompts retrieved: 4808160 . Total input tokens: 1072438965 . Total output tokens: 944139731
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 73.26378765003756,
    "estimated_duration": 3600.093864966907,
    "input_throughput": 6501.680477771421,
    "output_throughput": 5644.1972798914185,
    "total_throughput": 12145.87775766284,
    "itl": 91.2570241282758,
    "ttft": 2088100.4210500596,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 461,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.4735840916494163,
    "arrivals": 1601458,
    "finished_requests": 94711,
    "scheduler_time": 252.61682400380596
}
#Debug simulation 
Total elapsed time: 73.26395623385906. Arrivals time: 0.48847155226394534 Scheduler time: 72.56920016929507 Scheduler overhead time: 0.07931317016482353 Adapter cache time: 0.01815214240923524 Engine time: 0.0777894426137209 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.4_size_8-16-16/adapters_256_slots_32_rate_3.2-1.6-0.4_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.4_size_8-16-16/adapters_256_slots_32_rate_3.2-1.6-0.4_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [85 85 86]
Adapter prompts. [17280, 17280, 34560, 4320, 34560, 34560, 4320, 34560, 17280, 34560, 4320, 17280, 4320, 34560, 17280, 17280, 17280, 17280, 34560, 4320, 4320, 4320, 17280, 34560, 4320, 34560, 34560, 17280, 17280, 17280, 4320, 34560, 4320, 17280, 17280, 4320, 17280, 4320, 4320, 17280, 17280, 34560, 17280, 4320, 17280, 34560, 17280, 17280, 34560, 17280, 34560, 4320, 34560, 34560, 17280, 4320, 4320, 34560, 17280, 4320, 17280, 17280, 34560, 17280, 4320, 4320, 34560, 34560, 34560, 34560, 34560, 34560, 4320, 17280, 4320, 17280, 4320, 4320, 4320, 17280, 17280, 17280, 4320, 4320, 34560, 34560, 4320, 34560, 4320, 17280, 34560, 34560, 34560, 17280, 4320, 34560, 17280, 4320, 4320, 4320, 4320, 4320, 34560, 17280, 4320, 34560, 4320, 34560, 4320, 4320, 17280, 17280, 34560, 17280, 34560, 4320, 17280, 4320, 34560, 34560, 4320, 34560, 17280, 4320, 34560, 4320, 4320, 34560, 34560, 17280, 34560, 34560, 4320, 34560, 17280, 17280, 4320, 17280, 34560, 34560, 4320, 34560, 17280, 4320, 17280, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 4320, 4320, 34560, 4320, 17280, 34560, 34560, 17280, 4320, 34560, 4320, 17280, 17280, 4320, 17280, 4320, 34560, 4320, 4320, 34560, 4320, 34560, 34560, 17280, 34560, 17280, 4320, 17280, 34560, 17280, 34560, 4320, 34560, 4320, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 4320, 34560, 4320, 34560, 17280, 17280, 4320, 17280, 34560, 17280, 17280, 34560, 4320, 34560, 34560, 17280, 4320, 34560, 34560, 17280, 17280, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 34560, 4320, 34560, 17280, 34560, 34560, 4320, 34560, 17280, 17280, 34560, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 17280, 17280, 17280, 34560, 17280, 4320, 4320, 4320, 4320]
Prompts retrieved: 4808160 . Total input tokens: 1072438965 . Total output tokens: 944139731
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 74.46231635287404,
    "estimated_duration": 3600.0681619813354,
    "input_throughput": 6643.399770196906,
    "output_throughput": 5794.075573424697,
    "total_throughput": 12437.475343621603,
    "itl": 97.22493947915147,
    "ttft": 2076248.765423889,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 513,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.5067843450559253,
    "arrivals": 1601458,
    "finished_requests": 97023,
    "scheduler_time": 245.28265808544458
}
#Debug simulation 
Total elapsed time: 74.46249565808102. Arrivals time: 0.5253860680386424 Scheduler time: 73.73530866811052 Scheduler overhead time: 0.07771236216649413 Adapter cache time: 0.018631219398230314 Engine time: 0.07535489182919264 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.4_size_8-16-32/adapters_256_slots_32_rate_3.2-1.6-0.4_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.4_size_8-16-32/adapters_256_slots_32_rate_3.2-1.6-0.4_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [85 85 86]
Adapter prompts. [17280, 17280, 34560, 4320, 34560, 34560, 4320, 34560, 17280, 34560, 4320, 17280, 4320, 34560, 17280, 17280, 17280, 17280, 34560, 4320, 4320, 4320, 17280, 34560, 4320, 34560, 34560, 17280, 17280, 17280, 4320, 34560, 4320, 17280, 17280, 4320, 17280, 4320, 4320, 17280, 17280, 34560, 17280, 4320, 17280, 34560, 17280, 17280, 34560, 17280, 34560, 4320, 34560, 34560, 17280, 4320, 4320, 34560, 17280, 4320, 17280, 17280, 34560, 17280, 4320, 4320, 34560, 34560, 34560, 34560, 34560, 34560, 4320, 17280, 4320, 17280, 4320, 4320, 4320, 17280, 17280, 17280, 4320, 4320, 34560, 34560, 4320, 34560, 4320, 17280, 34560, 34560, 34560, 17280, 4320, 34560, 17280, 4320, 4320, 4320, 4320, 4320, 34560, 17280, 4320, 34560, 4320, 34560, 4320, 4320, 17280, 17280, 34560, 17280, 34560, 4320, 17280, 4320, 34560, 34560, 4320, 34560, 17280, 4320, 34560, 4320, 4320, 34560, 34560, 17280, 34560, 34560, 4320, 34560, 17280, 17280, 4320, 17280, 34560, 34560, 4320, 34560, 17280, 4320, 17280, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 4320, 4320, 34560, 4320, 17280, 34560, 34560, 17280, 4320, 34560, 4320, 17280, 17280, 4320, 17280, 4320, 34560, 4320, 4320, 34560, 4320, 34560, 34560, 17280, 34560, 17280, 4320, 17280, 34560, 17280, 34560, 4320, 34560, 4320, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 4320, 34560, 4320, 34560, 17280, 17280, 4320, 17280, 34560, 17280, 17280, 34560, 4320, 34560, 34560, 17280, 4320, 34560, 34560, 17280, 17280, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 34560, 4320, 34560, 17280, 34560, 34560, 4320, 34560, 17280, 17280, 34560, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 17280, 17280, 17280, 34560, 17280, 4320, 4320, 4320, 4320]
Prompts retrieved: 4808160 . Total input tokens: 1072438965 . Total output tokens: 944139731
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 73.7494788216427,
    "estimated_duration": 3600.039693264994,
    "input_throughput": 6482.246582907952,
    "output_throughput": 5650.749917579474,
    "total_throughput": 12132.996500487427,
    "itl": 91.13657620181321,
    "ttft": 2086399.7681260211,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 472,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.5240004831226805,
    "arrivals": 1601458,
    "finished_requests": 94572,
    "scheduler_time": 252.33412716302547
}
#Debug simulation 
Total elapsed time: 73.74964590091258. Arrivals time: 0.6631794469431043 Scheduler time: 72.87988556595519 Scheduler overhead time: 0.07945604249835014 Adapter cache time: 0.01813392248004675 Engine time: 0.07792582549154758 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.4_size_16-16-16/adapters_256_slots_32_rate_3.2-1.6-0.4_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.4_size_16-16-16/adapters_256_slots_32_rate_3.2-1.6-0.4_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [85 85 86]
Adapter prompts. [17280, 17280, 34560, 4320, 34560, 34560, 4320, 34560, 17280, 34560, 4320, 17280, 4320, 34560, 17280, 17280, 17280, 17280, 34560, 4320, 4320, 4320, 17280, 34560, 4320, 34560, 34560, 17280, 17280, 17280, 4320, 34560, 4320, 17280, 17280, 4320, 17280, 4320, 4320, 17280, 17280, 34560, 17280, 4320, 17280, 34560, 17280, 17280, 34560, 17280, 34560, 4320, 34560, 34560, 17280, 4320, 4320, 34560, 17280, 4320, 17280, 17280, 34560, 17280, 4320, 4320, 34560, 34560, 34560, 34560, 34560, 34560, 4320, 17280, 4320, 17280, 4320, 4320, 4320, 17280, 17280, 17280, 4320, 4320, 34560, 34560, 4320, 34560, 4320, 17280, 34560, 34560, 34560, 17280, 4320, 34560, 17280, 4320, 4320, 4320, 4320, 4320, 34560, 17280, 4320, 34560, 4320, 34560, 4320, 4320, 17280, 17280, 34560, 17280, 34560, 4320, 17280, 4320, 34560, 34560, 4320, 34560, 17280, 4320, 34560, 4320, 4320, 34560, 34560, 17280, 34560, 34560, 4320, 34560, 17280, 17280, 4320, 17280, 34560, 34560, 4320, 34560, 17280, 4320, 17280, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 4320, 4320, 34560, 4320, 17280, 34560, 34560, 17280, 4320, 34560, 4320, 17280, 17280, 4320, 17280, 4320, 34560, 4320, 4320, 34560, 4320, 34560, 34560, 17280, 34560, 17280, 4320, 17280, 34560, 17280, 34560, 4320, 34560, 4320, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 4320, 34560, 4320, 34560, 17280, 17280, 4320, 17280, 34560, 17280, 17280, 34560, 4320, 34560, 34560, 17280, 4320, 34560, 34560, 17280, 17280, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 34560, 4320, 34560, 17280, 34560, 34560, 4320, 34560, 17280, 17280, 34560, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 17280, 17280, 17280, 34560, 17280, 4320, 4320, 4320, 4320]
Prompts retrieved: 4808160 . Total input tokens: 1072438965 . Total output tokens: 944139731
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 79.62861005403101,
    "estimated_duration": 3600.049102372893,
    "input_throughput": 6619.328604238493,
    "output_throughput": 5780.641987989318,
    "total_throughput": 12399.970592227812,
    "itl": 96.72062245527019,
    "ttft": 2072317.3378775546,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 447,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.853612660435016,
    "arrivals": 1601458,
    "finished_requests": 96588,
    "scheduler_time": 246.17209351172093
}
#Debug simulation 
Total elapsed time: 79.62877951329574. Arrivals time: 0.6965059046633542 Scheduler time: 78.7316384264268 Scheduler overhead time: 0.07791646430268884 Adapter cache time: 0.01750214584171772 Engine time: 0.07584398472681642 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.4_size_16-16-32/adapters_256_slots_32_rate_3.2-1.6-0.4_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.4_size_16-16-32/adapters_256_slots_32_rate_3.2-1.6-0.4_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [85 85 86]
Adapter prompts. [17280, 17280, 34560, 4320, 34560, 34560, 4320, 34560, 17280, 34560, 4320, 17280, 4320, 34560, 17280, 17280, 17280, 17280, 34560, 4320, 4320, 4320, 17280, 34560, 4320, 34560, 34560, 17280, 17280, 17280, 4320, 34560, 4320, 17280, 17280, 4320, 17280, 4320, 4320, 17280, 17280, 34560, 17280, 4320, 17280, 34560, 17280, 17280, 34560, 17280, 34560, 4320, 34560, 34560, 17280, 4320, 4320, 34560, 17280, 4320, 17280, 17280, 34560, 17280, 4320, 4320, 34560, 34560, 34560, 34560, 34560, 34560, 4320, 17280, 4320, 17280, 4320, 4320, 4320, 17280, 17280, 17280, 4320, 4320, 34560, 34560, 4320, 34560, 4320, 17280, 34560, 34560, 34560, 17280, 4320, 34560, 17280, 4320, 4320, 4320, 4320, 4320, 34560, 17280, 4320, 34560, 4320, 34560, 4320, 4320, 17280, 17280, 34560, 17280, 34560, 4320, 17280, 4320, 34560, 34560, 4320, 34560, 17280, 4320, 34560, 4320, 4320, 34560, 34560, 17280, 34560, 34560, 4320, 34560, 17280, 17280, 4320, 17280, 34560, 34560, 4320, 34560, 17280, 4320, 17280, 34560, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 4320, 4320, 34560, 4320, 17280, 34560, 34560, 17280, 4320, 34560, 4320, 17280, 17280, 4320, 17280, 4320, 34560, 4320, 4320, 34560, 4320, 34560, 34560, 17280, 34560, 17280, 4320, 17280, 34560, 17280, 34560, 4320, 34560, 4320, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 4320, 34560, 4320, 34560, 17280, 17280, 4320, 17280, 34560, 17280, 17280, 34560, 4320, 34560, 34560, 17280, 4320, 34560, 34560, 17280, 17280, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 34560, 4320, 34560, 17280, 34560, 34560, 4320, 34560, 17280, 17280, 34560, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 17280, 17280, 17280, 34560, 17280, 4320, 4320, 4320, 4320]
Prompts retrieved: 4808160 . Total input tokens: 1072438965 . Total output tokens: 944139731
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 73.81213477812707,
    "estimated_duration": 3600.005581027378,
    "input_throughput": 6494.986319806536,
    "output_throughput": 5660.238169459947,
    "total_throughput": 12155.224489266484,
    "itl": 91.33776655595081,
    "ttft": 2083671.3342502434,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 478,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.521090787313906,
    "arrivals": 1601458,
    "finished_requests": 94710,
    "scheduler_time": 251.82025673393701
}
#Debug simulation 
Total elapsed time: 73.81231398880482. Arrivals time: 0.677717296872288 Scheduler time: 72.92637188499793 Scheduler overhead time: 0.08041884889826179 Adapter cache time: 0.01821493823081255 Engine time: 0.07871354045346379 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.1_size_8-8-8/adapters_256_slots_32_rate_3.2-1.6-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.1_size_8-8-8/adapters_256_slots_32_rate_3.2-1.6-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [85 85 86]
Adapter prompts. [17280, 17280, 34560, 1080, 34560, 34560, 1080, 34560, 17280, 34560, 1080, 17280, 1080, 34560, 17280, 17280, 17280, 17280, 34560, 1080, 1080, 1080, 17280, 34560, 1080, 34560, 34560, 17280, 17280, 17280, 1080, 34560, 1080, 17280, 17280, 1080, 17280, 1080, 1080, 17280, 17280, 34560, 17280, 1080, 17280, 34560, 17280, 17280, 34560, 17280, 34560, 1080, 34560, 34560, 17280, 1080, 1080, 34560, 17280, 1080, 17280, 17280, 34560, 17280, 1080, 1080, 34560, 34560, 34560, 34560, 34560, 34560, 1080, 17280, 1080, 17280, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 34560, 34560, 1080, 34560, 1080, 17280, 34560, 34560, 34560, 17280, 1080, 34560, 17280, 1080, 1080, 1080, 1080, 1080, 34560, 17280, 1080, 34560, 1080, 34560, 1080, 1080, 17280, 17280, 34560, 17280, 34560, 1080, 17280, 1080, 34560, 34560, 1080, 34560, 17280, 1080, 34560, 1080, 1080, 34560, 34560, 17280, 34560, 34560, 1080, 34560, 17280, 17280, 1080, 17280, 34560, 34560, 1080, 34560, 17280, 1080, 17280, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 1080, 1080, 34560, 1080, 17280, 34560, 34560, 17280, 1080, 34560, 1080, 17280, 17280, 1080, 17280, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 34560, 17280, 34560, 17280, 1080, 17280, 34560, 17280, 34560, 1080, 34560, 1080, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 1080, 34560, 1080, 34560, 17280, 17280, 1080, 17280, 34560, 17280, 17280, 34560, 1080, 34560, 34560, 17280, 1080, 34560, 34560, 17280, 17280, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 34560, 1080, 34560, 17280, 34560, 34560, 1080, 34560, 17280, 17280, 34560, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 17280, 17280, 34560, 17280, 1080, 1080, 1080, 1080]
Prompts retrieved: 4532760 . Total input tokens: 1011094124 . Total output tokens: 890027129
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 75.56627999804914,
    "estimated_duration": 3600.0864401408094,
    "input_throughput": 6687.070824626755,
    "output_throughput": 5853.156681197861,
    "total_throughput": 12540.227505824616,
    "itl": 100.22094590582275,
    "ttft": 2073507.415928938,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 514,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.3987782424223103,
    "arrivals": 1509498,
    "finished_requests": 97822,
    "scheduler_time": 242.3072654990858
}
#Debug simulation 
Total elapsed time: 75.5664526578039. Arrivals time: 1.1453555980697274 Scheduler time: 74.22346321353689 Scheduler overhead time: 0.07559322426095605 Adapter cache time: 0.017773848492652178 Engine time: 0.07449451042339206 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.1_size_8-8-16/adapters_256_slots_32_rate_3.2-1.6-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.1_size_8-8-16/adapters_256_slots_32_rate_3.2-1.6-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [85 85 86]
Adapter prompts. [17280, 17280, 34560, 1080, 34560, 34560, 1080, 34560, 17280, 34560, 1080, 17280, 1080, 34560, 17280, 17280, 17280, 17280, 34560, 1080, 1080, 1080, 17280, 34560, 1080, 34560, 34560, 17280, 17280, 17280, 1080, 34560, 1080, 17280, 17280, 1080, 17280, 1080, 1080, 17280, 17280, 34560, 17280, 1080, 17280, 34560, 17280, 17280, 34560, 17280, 34560, 1080, 34560, 34560, 17280, 1080, 1080, 34560, 17280, 1080, 17280, 17280, 34560, 17280, 1080, 1080, 34560, 34560, 34560, 34560, 34560, 34560, 1080, 17280, 1080, 17280, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 34560, 34560, 1080, 34560, 1080, 17280, 34560, 34560, 34560, 17280, 1080, 34560, 17280, 1080, 1080, 1080, 1080, 1080, 34560, 17280, 1080, 34560, 1080, 34560, 1080, 1080, 17280, 17280, 34560, 17280, 34560, 1080, 17280, 1080, 34560, 34560, 1080, 34560, 17280, 1080, 34560, 1080, 1080, 34560, 34560, 17280, 34560, 34560, 1080, 34560, 17280, 17280, 1080, 17280, 34560, 34560, 1080, 34560, 17280, 1080, 17280, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 1080, 1080, 34560, 1080, 17280, 34560, 34560, 17280, 1080, 34560, 1080, 17280, 17280, 1080, 17280, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 34560, 17280, 34560, 17280, 1080, 17280, 34560, 17280, 34560, 1080, 34560, 1080, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 1080, 34560, 1080, 34560, 17280, 17280, 1080, 17280, 34560, 17280, 17280, 34560, 1080, 34560, 34560, 17280, 1080, 34560, 34560, 17280, 17280, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 34560, 1080, 34560, 17280, 34560, 34560, 1080, 34560, 17280, 17280, 34560, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 17280, 17280, 34560, 17280, 1080, 1080, 1080, 1080]
Prompts retrieved: 4532760 . Total input tokens: 1011094124 . Total output tokens: 890027129
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 73.26248988509178,
    "estimated_duration": 3600.018007298515,
    "input_throughput": 6618.402450125386,
    "output_throughput": 5787.550494958491,
    "total_throughput": 12405.952945083876,
    "itl": 97.69284798975214,
    "ttft": 2076166.376616346,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 506,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.7022591268550658,
    "arrivals": 1509498,
    "finished_requests": 96772,
    "scheduler_time": 245.55932789095576
}
#Debug simulation 
Total elapsed time: 73.26266003912315. Arrivals time: 0.6676550516858697 Scheduler time: 72.39686638396233 Scheduler overhead time: 0.07679351745173335 Adapter cache time: 0.01755761308595538 Engine time: 0.07457661721855402 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.1_size_8-8-32/adapters_256_slots_32_rate_3.2-1.6-0.1_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.1_size_8-8-32/adapters_256_slots_32_rate_3.2-1.6-0.1_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [85 85 86]
Adapter prompts. [17280, 17280, 34560, 1080, 34560, 34560, 1080, 34560, 17280, 34560, 1080, 17280, 1080, 34560, 17280, 17280, 17280, 17280, 34560, 1080, 1080, 1080, 17280, 34560, 1080, 34560, 34560, 17280, 17280, 17280, 1080, 34560, 1080, 17280, 17280, 1080, 17280, 1080, 1080, 17280, 17280, 34560, 17280, 1080, 17280, 34560, 17280, 17280, 34560, 17280, 34560, 1080, 34560, 34560, 17280, 1080, 1080, 34560, 17280, 1080, 17280, 17280, 34560, 17280, 1080, 1080, 34560, 34560, 34560, 34560, 34560, 34560, 1080, 17280, 1080, 17280, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 34560, 34560, 1080, 34560, 1080, 17280, 34560, 34560, 34560, 17280, 1080, 34560, 17280, 1080, 1080, 1080, 1080, 1080, 34560, 17280, 1080, 34560, 1080, 34560, 1080, 1080, 17280, 17280, 34560, 17280, 34560, 1080, 17280, 1080, 34560, 34560, 1080, 34560, 17280, 1080, 34560, 1080, 1080, 34560, 34560, 17280, 34560, 34560, 1080, 34560, 17280, 17280, 1080, 17280, 34560, 34560, 1080, 34560, 17280, 1080, 17280, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 1080, 1080, 34560, 1080, 17280, 34560, 34560, 17280, 1080, 34560, 1080, 17280, 17280, 1080, 17280, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 34560, 17280, 34560, 17280, 1080, 17280, 34560, 17280, 34560, 1080, 34560, 1080, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 1080, 34560, 1080, 34560, 17280, 17280, 1080, 17280, 34560, 17280, 17280, 34560, 1080, 34560, 34560, 17280, 1080, 34560, 34560, 17280, 17280, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 34560, 1080, 34560, 17280, 34560, 34560, 1080, 34560, 17280, 17280, 34560, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 17280, 17280, 34560, 17280, 1080, 1080, 1080, 1080]
Prompts retrieved: 4532760 . Total input tokens: 1011094124 . Total output tokens: 890027129
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 73.98966387240216,
    "estimated_duration": 3600.0182938905377,
    "input_throughput": 6410.57909043551,
    "output_throughput": 5635.261919204249,
    "total_throughput": 12045.84100963976,
    "itl": 91.45444778613353,
    "ttft": 2085161.7517793588,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 451,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.3996585834911355,
    "arrivals": 1509498,
    "finished_requests": 93886,
    "scheduler_time": 253.67758176926904
}
#Debug simulation 
Total elapsed time: 73.98983225040138. Arrivals time: 0.7647639205679297 Scheduler time: 73.02001796057448 Scheduler overhead time: 0.07902763225138187 Adapter cache time: 0.017463453579694033 Engine time: 0.07769602164626122 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.1_size_8-16-16/adapters_256_slots_32_rate_3.2-1.6-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.1_size_8-16-16/adapters_256_slots_32_rate_3.2-1.6-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [85 85 86]
Adapter prompts. [17280, 17280, 34560, 1080, 34560, 34560, 1080, 34560, 17280, 34560, 1080, 17280, 1080, 34560, 17280, 17280, 17280, 17280, 34560, 1080, 1080, 1080, 17280, 34560, 1080, 34560, 34560, 17280, 17280, 17280, 1080, 34560, 1080, 17280, 17280, 1080, 17280, 1080, 1080, 17280, 17280, 34560, 17280, 1080, 17280, 34560, 17280, 17280, 34560, 17280, 34560, 1080, 34560, 34560, 17280, 1080, 1080, 34560, 17280, 1080, 17280, 17280, 34560, 17280, 1080, 1080, 34560, 34560, 34560, 34560, 34560, 34560, 1080, 17280, 1080, 17280, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 34560, 34560, 1080, 34560, 1080, 17280, 34560, 34560, 34560, 17280, 1080, 34560, 17280, 1080, 1080, 1080, 1080, 1080, 34560, 17280, 1080, 34560, 1080, 34560, 1080, 1080, 17280, 17280, 34560, 17280, 34560, 1080, 17280, 1080, 34560, 34560, 1080, 34560, 17280, 1080, 34560, 1080, 1080, 34560, 34560, 17280, 34560, 34560, 1080, 34560, 17280, 17280, 1080, 17280, 34560, 34560, 1080, 34560, 17280, 1080, 17280, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 1080, 1080, 34560, 1080, 17280, 34560, 34560, 17280, 1080, 34560, 1080, 17280, 17280, 1080, 17280, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 34560, 17280, 34560, 17280, 1080, 17280, 34560, 17280, 34560, 1080, 34560, 1080, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 1080, 34560, 1080, 34560, 17280, 17280, 1080, 17280, 34560, 17280, 17280, 34560, 1080, 34560, 34560, 17280, 1080, 34560, 34560, 17280, 17280, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 34560, 1080, 34560, 17280, 34560, 34560, 1080, 34560, 17280, 17280, 34560, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 17280, 17280, 34560, 17280, 1080, 1080, 1080, 1080]
Prompts retrieved: 4532760 . Total input tokens: 1011094124 . Total output tokens: 890027129
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 76.6342838020064,
    "estimated_duration": 3600.0503456804577,
    "input_throughput": 6572.638082239819,
    "output_throughput": 5753.130098541786,
    "total_throughput": 12325.768180781604,
    "itl": 96.63481175193976,
    "ttft": 2077749.2869930142,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 448,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.0765590532124008,
    "arrivals": 1509498,
    "finished_requests": 96197,
    "scheduler_time": 247.21387290455414
}
#Debug simulation 
Total elapsed time: 76.63452914590016. Arrivals time: 0.5096435989253223 Scheduler time: 75.9254966583103 Scheduler overhead time: 0.0768163613975048 Adapter cache time: 0.017259190324693918 Engine time: 0.07556970231235027 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.1_size_8-16-32/adapters_256_slots_32_rate_3.2-1.6-0.1_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.1_size_8-16-32/adapters_256_slots_32_rate_3.2-1.6-0.1_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [85 85 86]
Adapter prompts. [17280, 17280, 34560, 1080, 34560, 34560, 1080, 34560, 17280, 34560, 1080, 17280, 1080, 34560, 17280, 17280, 17280, 17280, 34560, 1080, 1080, 1080, 17280, 34560, 1080, 34560, 34560, 17280, 17280, 17280, 1080, 34560, 1080, 17280, 17280, 1080, 17280, 1080, 1080, 17280, 17280, 34560, 17280, 1080, 17280, 34560, 17280, 17280, 34560, 17280, 34560, 1080, 34560, 34560, 17280, 1080, 1080, 34560, 17280, 1080, 17280, 17280, 34560, 17280, 1080, 1080, 34560, 34560, 34560, 34560, 34560, 34560, 1080, 17280, 1080, 17280, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 34560, 34560, 1080, 34560, 1080, 17280, 34560, 34560, 34560, 17280, 1080, 34560, 17280, 1080, 1080, 1080, 1080, 1080, 34560, 17280, 1080, 34560, 1080, 34560, 1080, 1080, 17280, 17280, 34560, 17280, 34560, 1080, 17280, 1080, 34560, 34560, 1080, 34560, 17280, 1080, 34560, 1080, 1080, 34560, 34560, 17280, 34560, 34560, 1080, 34560, 17280, 17280, 1080, 17280, 34560, 34560, 1080, 34560, 17280, 1080, 17280, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 1080, 1080, 34560, 1080, 17280, 34560, 34560, 17280, 1080, 34560, 1080, 17280, 17280, 1080, 17280, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 34560, 17280, 34560, 17280, 1080, 17280, 34560, 17280, 34560, 1080, 34560, 1080, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 1080, 34560, 1080, 34560, 17280, 17280, 1080, 17280, 34560, 17280, 17280, 34560, 1080, 34560, 34560, 17280, 1080, 34560, 34560, 17280, 17280, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 34560, 1080, 34560, 17280, 34560, 34560, 1080, 34560, 17280, 17280, 34560, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 17280, 17280, 34560, 17280, 1080, 1080, 1080, 1080]
Prompts retrieved: 4532760 . Total input tokens: 1011094124 . Total output tokens: 890027129
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 72.11297438619658,
    "estimated_duration": 3600.0122207728423,
    "input_throughput": 6379.61195450319,
    "output_throughput": 5595.922392639888,
    "total_throughput": 11975.534347143077,
    "itl": 90.90511311295133,
    "ttft": 2089573.7915771806,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 448,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.3422397461300974,
    "arrivals": 1509498,
    "finished_requests": 93421,
    "scheduler_time": 254.759140666926
}
#Debug simulation 
Total elapsed time: 72.11314335325733. Arrivals time: 0.6420696265995502 Scheduler time: 71.26872652955353 Scheduler overhead time: 0.07821669522672892 Adapter cache time: 0.017419234849512577 Engine time: 0.07617629831656814 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.1_size_16-16-16/adapters_256_slots_32_rate_3.2-1.6-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.1_size_16-16-16/adapters_256_slots_32_rate_3.2-1.6-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [85 85 86]
Adapter prompts. [17280, 17280, 34560, 1080, 34560, 34560, 1080, 34560, 17280, 34560, 1080, 17280, 1080, 34560, 17280, 17280, 17280, 17280, 34560, 1080, 1080, 1080, 17280, 34560, 1080, 34560, 34560, 17280, 17280, 17280, 1080, 34560, 1080, 17280, 17280, 1080, 17280, 1080, 1080, 17280, 17280, 34560, 17280, 1080, 17280, 34560, 17280, 17280, 34560, 17280, 34560, 1080, 34560, 34560, 17280, 1080, 1080, 34560, 17280, 1080, 17280, 17280, 34560, 17280, 1080, 1080, 34560, 34560, 34560, 34560, 34560, 34560, 1080, 17280, 1080, 17280, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 34560, 34560, 1080, 34560, 1080, 17280, 34560, 34560, 34560, 17280, 1080, 34560, 17280, 1080, 1080, 1080, 1080, 1080, 34560, 17280, 1080, 34560, 1080, 34560, 1080, 1080, 17280, 17280, 34560, 17280, 34560, 1080, 17280, 1080, 34560, 34560, 1080, 34560, 17280, 1080, 34560, 1080, 1080, 34560, 34560, 17280, 34560, 34560, 1080, 34560, 17280, 17280, 1080, 17280, 34560, 34560, 1080, 34560, 17280, 1080, 17280, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 1080, 1080, 34560, 1080, 17280, 34560, 34560, 17280, 1080, 34560, 1080, 17280, 17280, 1080, 17280, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 34560, 17280, 34560, 17280, 1080, 17280, 34560, 17280, 34560, 1080, 34560, 1080, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 1080, 34560, 1080, 34560, 17280, 17280, 1080, 17280, 34560, 17280, 17280, 34560, 1080, 34560, 34560, 17280, 1080, 34560, 34560, 17280, 17280, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 34560, 1080, 34560, 17280, 34560, 34560, 1080, 34560, 17280, 17280, 34560, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 17280, 17280, 34560, 17280, 1080, 1080, 1080, 1080]
Prompts retrieved: 4532760 . Total input tokens: 1011094124 . Total output tokens: 890027129
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 73.42906463192776,
    "estimated_duration": 3600.105676544326,
    "input_throughput": 6598.225478425766,
    "output_throughput": 5778.518707253249,
    "total_throughput": 12376.744185679014,
    "itl": 97.48968053948457,
    "ttft": 2076021.2175565492,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 454,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.8983001070190095,
    "arrivals": 1509498,
    "finished_requests": 96517,
    "scheduler_time": 245.98305249441808
}
#Debug simulation 
Total elapsed time: 73.42923327209428. Arrivals time: 0.4330963329412043 Scheduler time: 72.80704351421446 Scheduler overhead time: 0.07264059921726584 Adapter cache time: 0.01612010318785906 Engine time: 0.07170321559533477 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.1_size_16-16-32/adapters_256_slots_32_rate_3.2-1.6-0.1_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.1_size_16-16-32/adapters_256_slots_32_rate_3.2-1.6-0.1_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [85 85 86]
Adapter prompts. [17280, 17280, 34560, 1080, 34560, 34560, 1080, 34560, 17280, 34560, 1080, 17280, 1080, 34560, 17280, 17280, 17280, 17280, 34560, 1080, 1080, 1080, 17280, 34560, 1080, 34560, 34560, 17280, 17280, 17280, 1080, 34560, 1080, 17280, 17280, 1080, 17280, 1080, 1080, 17280, 17280, 34560, 17280, 1080, 17280, 34560, 17280, 17280, 34560, 17280, 34560, 1080, 34560, 34560, 17280, 1080, 1080, 34560, 17280, 1080, 17280, 17280, 34560, 17280, 1080, 1080, 34560, 34560, 34560, 34560, 34560, 34560, 1080, 17280, 1080, 17280, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 34560, 34560, 1080, 34560, 1080, 17280, 34560, 34560, 34560, 17280, 1080, 34560, 17280, 1080, 1080, 1080, 1080, 1080, 34560, 17280, 1080, 34560, 1080, 34560, 1080, 1080, 17280, 17280, 34560, 17280, 34560, 1080, 17280, 1080, 34560, 34560, 1080, 34560, 17280, 1080, 34560, 1080, 1080, 34560, 34560, 17280, 34560, 34560, 1080, 34560, 17280, 17280, 1080, 17280, 34560, 34560, 1080, 34560, 17280, 1080, 17280, 34560, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 1080, 1080, 34560, 1080, 17280, 34560, 34560, 17280, 1080, 34560, 1080, 17280, 17280, 1080, 17280, 1080, 34560, 1080, 1080, 34560, 1080, 34560, 34560, 17280, 34560, 17280, 1080, 17280, 34560, 17280, 34560, 1080, 34560, 1080, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 1080, 34560, 1080, 34560, 17280, 17280, 1080, 17280, 34560, 17280, 17280, 34560, 1080, 34560, 34560, 17280, 1080, 34560, 34560, 17280, 17280, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 34560, 1080, 34560, 17280, 34560, 34560, 1080, 34560, 17280, 17280, 34560, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 17280, 17280, 34560, 17280, 1080, 1080, 1080, 1080]
Prompts retrieved: 4532760 . Total input tokens: 1011094124 . Total output tokens: 890027129
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 72.61373542202637,
    "estimated_duration": 3600.0920195818817,
    "input_throughput": 6424.375231021498,
    "output_throughput": 5627.860312957531,
    "total_throughput": 12052.235543979028,
    "itl": 91.36670235772984,
    "ttft": 2086669.0071625854,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 489,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.6076493054814938,
    "arrivals": 1509498,
    "finished_requests": 94039,
    "scheduler_time": 253.2714393695403
}
#Debug simulation 
Total elapsed time: 72.61389289610088. Arrivals time: 0.6232632338069379 Scheduler time: 71.790781121701 Scheduler overhead time: 0.07676231395453215 Adapter cache time: 0.017641176469624043 Engine time: 0.07509827148169279 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.05_size_8-8-8/adapters_256_slots_32_rate_3.2-1.6-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.05_size_8-8-8/adapters_256_slots_32_rate_3.2-1.6-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [85 85 86]
Adapter prompts. [17280, 17280, 34560, 540, 34560, 34560, 540, 34560, 17280, 34560, 540, 17280, 540, 34560, 17280, 17280, 17280, 17280, 34560, 540, 540, 540, 17280, 34560, 540, 34560, 34560, 17280, 17280, 17280, 540, 34560, 540, 17280, 17280, 540, 17280, 540, 540, 17280, 17280, 34560, 17280, 540, 17280, 34560, 17280, 17280, 34560, 17280, 34560, 540, 34560, 34560, 17280, 540, 540, 34560, 17280, 540, 17280, 17280, 34560, 17280, 540, 540, 34560, 34560, 34560, 34560, 34560, 34560, 540, 17280, 540, 17280, 540, 540, 540, 17280, 17280, 17280, 540, 540, 34560, 34560, 540, 34560, 540, 17280, 34560, 34560, 34560, 17280, 540, 34560, 17280, 540, 540, 540, 540, 540, 34560, 17280, 540, 34560, 540, 34560, 540, 540, 17280, 17280, 34560, 17280, 34560, 540, 17280, 540, 34560, 34560, 540, 34560, 17280, 540, 34560, 540, 540, 34560, 34560, 17280, 34560, 34560, 540, 34560, 17280, 17280, 540, 17280, 34560, 34560, 540, 34560, 17280, 540, 17280, 34560, 540, 540, 540, 540, 540, 540, 34560, 540, 540, 540, 34560, 540, 17280, 34560, 34560, 17280, 540, 34560, 540, 17280, 17280, 540, 17280, 540, 34560, 540, 540, 34560, 540, 34560, 34560, 17280, 34560, 17280, 540, 17280, 34560, 17280, 34560, 540, 34560, 540, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 540, 34560, 540, 34560, 17280, 17280, 540, 17280, 34560, 17280, 17280, 34560, 540, 34560, 34560, 17280, 540, 34560, 34560, 17280, 17280, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 34560, 540, 34560, 17280, 34560, 34560, 540, 34560, 17280, 17280, 34560, 540, 17280, 540, 540, 540, 540, 17280, 17280, 17280, 17280, 17280, 34560, 17280, 540, 540, 540, 540]
Prompts retrieved: 4486860 . Total input tokens: 1000872100 . Total output tokens: 881050329
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 71.73007489414886,
    "estimated_duration": 3600.0175828035594,
    "input_throughput": 6679.775986336392,
    "output_throughput": 5828.288478430166,
    "total_throughput": 12508.064464766558,
    "itl": 99.80802224142843,
    "ttft": 2073807.0969325767,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 455,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.0086461095372514,
    "arrivals": 1494384,
    "finished_requests": 97054,
    "scheduler_time": 243.48548369656734
}
#Debug simulation 
Total elapsed time: 71.7302401731722. Arrivals time: 0.46188077703118324 Scheduler time: 71.07865444384515 Scheduler overhead time: 0.07308535138145089 Adapter cache time: 0.016709330957382917 Engine time: 0.07164799235761166 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.05_size_8-8-16/adapters_256_slots_32_rate_3.2-1.6-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.05_size_8-8-16/adapters_256_slots_32_rate_3.2-1.6-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [85 85 86]
Adapter prompts. [17280, 17280, 34560, 540, 34560, 34560, 540, 34560, 17280, 34560, 540, 17280, 540, 34560, 17280, 17280, 17280, 17280, 34560, 540, 540, 540, 17280, 34560, 540, 34560, 34560, 17280, 17280, 17280, 540, 34560, 540, 17280, 17280, 540, 17280, 540, 540, 17280, 17280, 34560, 17280, 540, 17280, 34560, 17280, 17280, 34560, 17280, 34560, 540, 34560, 34560, 17280, 540, 540, 34560, 17280, 540, 17280, 17280, 34560, 17280, 540, 540, 34560, 34560, 34560, 34560, 34560, 34560, 540, 17280, 540, 17280, 540, 540, 540, 17280, 17280, 17280, 540, 540, 34560, 34560, 540, 34560, 540, 17280, 34560, 34560, 34560, 17280, 540, 34560, 17280, 540, 540, 540, 540, 540, 34560, 17280, 540, 34560, 540, 34560, 540, 540, 17280, 17280, 34560, 17280, 34560, 540, 17280, 540, 34560, 34560, 540, 34560, 17280, 540, 34560, 540, 540, 34560, 34560, 17280, 34560, 34560, 540, 34560, 17280, 17280, 540, 17280, 34560, 34560, 540, 34560, 17280, 540, 17280, 34560, 540, 540, 540, 540, 540, 540, 34560, 540, 540, 540, 34560, 540, 17280, 34560, 34560, 17280, 540, 34560, 540, 17280, 17280, 540, 17280, 540, 34560, 540, 540, 34560, 540, 34560, 34560, 17280, 34560, 17280, 540, 17280, 34560, 17280, 34560, 540, 34560, 540, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 540, 34560, 540, 34560, 17280, 17280, 540, 17280, 34560, 17280, 17280, 34560, 540, 34560, 34560, 17280, 540, 34560, 34560, 17280, 17280, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 34560, 540, 34560, 17280, 34560, 34560, 540, 34560, 17280, 17280, 34560, 540, 17280, 540, 540, 540, 540, 17280, 17280, 17280, 17280, 17280, 34560, 17280, 540, 540, 540, 540]
Prompts retrieved: 4486860 . Total input tokens: 1000872100 . Total output tokens: 881050329
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 72.98055657697842,
    "estimated_duration": 3600.0004502420666,
    "input_throughput": 6641.321669388224,
    "output_throughput": 5794.609275284207,
    "total_throughput": 12435.930944672431,
    "itl": 97.74684420880399,
    "ttft": 2079028.7166524928,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 476,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.485753521118318,
    "arrivals": 1494384,
    "finished_requests": 96393,
    "scheduler_time": 245.71384914326592
}
#Debug simulation 
Total elapsed time: 72.98071323568001. Arrivals time: 0.46874790731817484 Scheduler time: 72.31693898607045 Scheduler overhead time: 0.07494328171014786 Adapter cache time: 0.017081687226891518 Engine time: 0.07352587999776006 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.05_size_8-8-32/adapters_256_slots_32_rate_3.2-1.6-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.05_size_8-8-32/adapters_256_slots_32_rate_3.2-1.6-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [85 85 86]
Adapter prompts. [17280, 17280, 34560, 540, 34560, 34560, 540, 34560, 17280, 34560, 540, 17280, 540, 34560, 17280, 17280, 17280, 17280, 34560, 540, 540, 540, 17280, 34560, 540, 34560, 34560, 17280, 17280, 17280, 540, 34560, 540, 17280, 17280, 540, 17280, 540, 540, 17280, 17280, 34560, 17280, 540, 17280, 34560, 17280, 17280, 34560, 17280, 34560, 540, 34560, 34560, 17280, 540, 540, 34560, 17280, 540, 17280, 17280, 34560, 17280, 540, 540, 34560, 34560, 34560, 34560, 34560, 34560, 540, 17280, 540, 17280, 540, 540, 540, 17280, 17280, 17280, 540, 540, 34560, 34560, 540, 34560, 540, 17280, 34560, 34560, 34560, 17280, 540, 34560, 17280, 540, 540, 540, 540, 540, 34560, 17280, 540, 34560, 540, 34560, 540, 540, 17280, 17280, 34560, 17280, 34560, 540, 17280, 540, 34560, 34560, 540, 34560, 17280, 540, 34560, 540, 540, 34560, 34560, 17280, 34560, 34560, 540, 34560, 17280, 17280, 540, 17280, 34560, 34560, 540, 34560, 17280, 540, 17280, 34560, 540, 540, 540, 540, 540, 540, 34560, 540, 540, 540, 34560, 540, 17280, 34560, 34560, 17280, 540, 34560, 540, 17280, 17280, 540, 17280, 540, 34560, 540, 540, 34560, 540, 34560, 34560, 17280, 34560, 17280, 540, 17280, 34560, 17280, 34560, 540, 34560, 540, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 540, 34560, 540, 34560, 17280, 17280, 540, 17280, 34560, 17280, 17280, 34560, 540, 34560, 34560, 17280, 540, 34560, 34560, 17280, 17280, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 34560, 540, 34560, 17280, 34560, 34560, 540, 34560, 17280, 17280, 34560, 540, 17280, 540, 540, 540, 540, 17280, 17280, 17280, 17280, 17280, 34560, 17280, 540, 540, 540, 540]
Prompts retrieved: 4486860 . Total input tokens: 1000872100 . Total output tokens: 881050329
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 66.78129357006401,
    "estimated_duration": 3600.051119253821,
    "input_throughput": 6474.281677653225,
    "output_throughput": 5647.799802413436,
    "total_throughput": 12122.081480066661,
    "itl": 91.90308050240745,
    "ttft": 2088504.1601656089,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 555,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.162673926595633,
    "arrivals": 1494384,
    "finished_requests": 94035,
    "scheduler_time": 252.31674459089834
}
#Debug simulation 
Total elapsed time: 66.78145967237651. Arrivals time: 0.4564154641702771 Scheduler time: 66.1258364804089 Scheduler overhead time: 0.07584397029131651 Adapter cache time: 0.018210223875939846 Engine time: 0.07485156832262874 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.05_size_8-16-16/adapters_256_slots_32_rate_3.2-1.6-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.05_size_8-16-16/adapters_256_slots_32_rate_3.2-1.6-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [85 85 86]
Adapter prompts. [17280, 17280, 34560, 540, 34560, 34560, 540, 34560, 17280, 34560, 540, 17280, 540, 34560, 17280, 17280, 17280, 17280, 34560, 540, 540, 540, 17280, 34560, 540, 34560, 34560, 17280, 17280, 17280, 540, 34560, 540, 17280, 17280, 540, 17280, 540, 540, 17280, 17280, 34560, 17280, 540, 17280, 34560, 17280, 17280, 34560, 17280, 34560, 540, 34560, 34560, 17280, 540, 540, 34560, 17280, 540, 17280, 17280, 34560, 17280, 540, 540, 34560, 34560, 34560, 34560, 34560, 34560, 540, 17280, 540, 17280, 540, 540, 540, 17280, 17280, 17280, 540, 540, 34560, 34560, 540, 34560, 540, 17280, 34560, 34560, 34560, 17280, 540, 34560, 17280, 540, 540, 540, 540, 540, 34560, 17280, 540, 34560, 540, 34560, 540, 540, 17280, 17280, 34560, 17280, 34560, 540, 17280, 540, 34560, 34560, 540, 34560, 17280, 540, 34560, 540, 540, 34560, 34560, 17280, 34560, 34560, 540, 34560, 17280, 17280, 540, 17280, 34560, 34560, 540, 34560, 17280, 540, 17280, 34560, 540, 540, 540, 540, 540, 540, 34560, 540, 540, 540, 34560, 540, 17280, 34560, 34560, 17280, 540, 34560, 540, 17280, 17280, 540, 17280, 540, 34560, 540, 540, 34560, 540, 34560, 34560, 17280, 34560, 17280, 540, 17280, 34560, 17280, 34560, 540, 34560, 540, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 540, 34560, 540, 34560, 17280, 17280, 540, 17280, 34560, 17280, 17280, 34560, 540, 34560, 34560, 17280, 540, 34560, 34560, 17280, 17280, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 34560, 540, 34560, 17280, 34560, 34560, 540, 34560, 17280, 17280, 34560, 540, 17280, 540, 540, 540, 540, 17280, 17280, 17280, 17280, 17280, 34560, 17280, 540, 540, 540, 540]
Prompts retrieved: 4486860 . Total input tokens: 1000872100 . Total output tokens: 881050329
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 72.84992234315723,
    "estimated_duration": 3600.08865156541,
    "input_throughput": 6640.29120216393,
    "output_throughput": 5781.891229525409,
    "total_throughput": 12422.18243168934,
    "itl": 97.54161797289343,
    "ttft": 2080096.1442030384,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 482,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.3005534700583623,
    "arrivals": 1494384,
    "finished_requests": 96315,
    "scheduler_time": 245.79711523505728
}
#Debug simulation 
Total elapsed time: 72.85008272808045. Arrivals time: 0.5863429727032781 Scheduler time: 72.0735614830628 Scheduler overhead time: 0.0742886122316122 Adapter cache time: 0.016658270731568336 Engine time: 0.07041464233770967 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.05_size_8-16-32/adapters_256_slots_32_rate_3.2-1.6-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.05_size_8-16-32/adapters_256_slots_32_rate_3.2-1.6-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [85 85 86]
Adapter prompts. [17280, 17280, 34560, 540, 34560, 34560, 540, 34560, 17280, 34560, 540, 17280, 540, 34560, 17280, 17280, 17280, 17280, 34560, 540, 540, 540, 17280, 34560, 540, 34560, 34560, 17280, 17280, 17280, 540, 34560, 540, 17280, 17280, 540, 17280, 540, 540, 17280, 17280, 34560, 17280, 540, 17280, 34560, 17280, 17280, 34560, 17280, 34560, 540, 34560, 34560, 17280, 540, 540, 34560, 17280, 540, 17280, 17280, 34560, 17280, 540, 540, 34560, 34560, 34560, 34560, 34560, 34560, 540, 17280, 540, 17280, 540, 540, 540, 17280, 17280, 17280, 540, 540, 34560, 34560, 540, 34560, 540, 17280, 34560, 34560, 34560, 17280, 540, 34560, 17280, 540, 540, 540, 540, 540, 34560, 17280, 540, 34560, 540, 34560, 540, 540, 17280, 17280, 34560, 17280, 34560, 540, 17280, 540, 34560, 34560, 540, 34560, 17280, 540, 34560, 540, 540, 34560, 34560, 17280, 34560, 34560, 540, 34560, 17280, 17280, 540, 17280, 34560, 34560, 540, 34560, 17280, 540, 17280, 34560, 540, 540, 540, 540, 540, 540, 34560, 540, 540, 540, 34560, 540, 17280, 34560, 34560, 17280, 540, 34560, 540, 17280, 17280, 540, 17280, 540, 34560, 540, 540, 34560, 540, 34560, 34560, 17280, 34560, 17280, 540, 17280, 34560, 17280, 34560, 540, 34560, 540, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 540, 34560, 540, 34560, 17280, 17280, 540, 17280, 34560, 17280, 17280, 34560, 540, 34560, 34560, 17280, 540, 34560, 34560, 17280, 17280, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 34560, 540, 34560, 17280, 34560, 34560, 540, 34560, 17280, 17280, 34560, 540, 17280, 540, 540, 540, 540, 17280, 17280, 17280, 17280, 17280, 34560, 17280, 540, 540, 540, 540]
Prompts retrieved: 4486860 . Total input tokens: 1000872100 . Total output tokens: 881050329
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 68.85839327797294,
    "estimated_duration": 3600.0641347111386,
    "input_throughput": 6484.338924665595,
    "output_throughput": 5650.822940584169,
    "total_throughput": 12135.161865249764,
    "itl": 91.87248271570287,
    "ttft": 2087009.4208688142,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 519,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.8589398482488804,
    "arrivals": 1494384,
    "finished_requests": 94082,
    "scheduler_time": 252.1842561106383
}
#Debug simulation 
Total elapsed time: 68.8585553439334. Arrivals time: 0.46043257880955935 Scheduler time: 68.20318152289838 Scheduler overhead time: 0.07557260990142822 Adapter cache time: 0.017098342068493366 Engine time: 0.07246192544698715 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.05_size_16-16-16/adapters_256_slots_32_rate_3.2-1.6-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.05_size_16-16-16/adapters_256_slots_32_rate_3.2-1.6-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [85 85 86]
Adapter prompts. [17280, 17280, 34560, 540, 34560, 34560, 540, 34560, 17280, 34560, 540, 17280, 540, 34560, 17280, 17280, 17280, 17280, 34560, 540, 540, 540, 17280, 34560, 540, 34560, 34560, 17280, 17280, 17280, 540, 34560, 540, 17280, 17280, 540, 17280, 540, 540, 17280, 17280, 34560, 17280, 540, 17280, 34560, 17280, 17280, 34560, 17280, 34560, 540, 34560, 34560, 17280, 540, 540, 34560, 17280, 540, 17280, 17280, 34560, 17280, 540, 540, 34560, 34560, 34560, 34560, 34560, 34560, 540, 17280, 540, 17280, 540, 540, 540, 17280, 17280, 17280, 540, 540, 34560, 34560, 540, 34560, 540, 17280, 34560, 34560, 34560, 17280, 540, 34560, 17280, 540, 540, 540, 540, 540, 34560, 17280, 540, 34560, 540, 34560, 540, 540, 17280, 17280, 34560, 17280, 34560, 540, 17280, 540, 34560, 34560, 540, 34560, 17280, 540, 34560, 540, 540, 34560, 34560, 17280, 34560, 34560, 540, 34560, 17280, 17280, 540, 17280, 34560, 34560, 540, 34560, 17280, 540, 17280, 34560, 540, 540, 540, 540, 540, 540, 34560, 540, 540, 540, 34560, 540, 17280, 34560, 34560, 17280, 540, 34560, 540, 17280, 17280, 540, 17280, 540, 34560, 540, 540, 34560, 540, 34560, 34560, 17280, 34560, 17280, 540, 17280, 34560, 17280, 34560, 540, 34560, 540, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 540, 34560, 540, 34560, 17280, 17280, 540, 17280, 34560, 17280, 17280, 34560, 540, 34560, 34560, 17280, 540, 34560, 34560, 17280, 17280, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 34560, 540, 34560, 17280, 34560, 34560, 540, 34560, 17280, 17280, 34560, 540, 17280, 540, 540, 540, 540, 17280, 17280, 17280, 17280, 17280, 34560, 17280, 540, 540, 540, 540]
Prompts retrieved: 4486860 . Total input tokens: 1000872100 . Total output tokens: 881050329
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 71.0934443953447,
    "estimated_duration": 3600.090884866754,
    "input_throughput": 6636.311072153463,
    "output_throughput": 5779.7996399110725,
    "total_throughput": 12416.110712064536,
    "itl": 97.48593040846335,
    "ttft": 2080186.024073727,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 492,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.1408891027606884,
    "arrivals": 1494384,
    "finished_requests": 96238,
    "scheduler_time": 245.96738102218404
}
#Debug simulation 
Total elapsed time: 71.09368400136009. Arrivals time: 0.4733863789588213 Scheduler time: 70.42939538275823 Scheduler overhead time: 0.07416146993637085 Adapter cache time: 0.016881983261555433 Engine time: 0.07047421718016267 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.05_size_16-16-32/adapters_256_slots_32_rate_3.2-1.6-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.05_size_16-16-32/adapters_256_slots_32_rate_3.2-1.6-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [85 85 86]
Adapter prompts. [17280, 17280, 34560, 540, 34560, 34560, 540, 34560, 17280, 34560, 540, 17280, 540, 34560, 17280, 17280, 17280, 17280, 34560, 540, 540, 540, 17280, 34560, 540, 34560, 34560, 17280, 17280, 17280, 540, 34560, 540, 17280, 17280, 540, 17280, 540, 540, 17280, 17280, 34560, 17280, 540, 17280, 34560, 17280, 17280, 34560, 17280, 34560, 540, 34560, 34560, 17280, 540, 540, 34560, 17280, 540, 17280, 17280, 34560, 17280, 540, 540, 34560, 34560, 34560, 34560, 34560, 34560, 540, 17280, 540, 17280, 540, 540, 540, 17280, 17280, 17280, 540, 540, 34560, 34560, 540, 34560, 540, 17280, 34560, 34560, 34560, 17280, 540, 34560, 17280, 540, 540, 540, 540, 540, 34560, 17280, 540, 34560, 540, 34560, 540, 540, 17280, 17280, 34560, 17280, 34560, 540, 17280, 540, 34560, 34560, 540, 34560, 17280, 540, 34560, 540, 540, 34560, 34560, 17280, 34560, 34560, 540, 34560, 17280, 17280, 540, 17280, 34560, 34560, 540, 34560, 17280, 540, 17280, 34560, 540, 540, 540, 540, 540, 540, 34560, 540, 540, 540, 34560, 540, 17280, 34560, 34560, 17280, 540, 34560, 540, 17280, 17280, 540, 17280, 540, 34560, 540, 540, 34560, 540, 34560, 34560, 17280, 34560, 17280, 540, 17280, 34560, 17280, 34560, 540, 34560, 540, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 540, 34560, 540, 34560, 17280, 17280, 540, 17280, 34560, 17280, 17280, 34560, 540, 34560, 34560, 17280, 540, 34560, 34560, 17280, 17280, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 34560, 540, 34560, 17280, 34560, 34560, 540, 34560, 17280, 17280, 34560, 540, 17280, 540, 540, 540, 540, 17280, 17280, 17280, 17280, 17280, 34560, 17280, 540, 540, 540, 540]
Prompts retrieved: 4486860 . Total input tokens: 1000872100 . Total output tokens: 881050329
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 67.54613506281748,
    "estimated_duration": 3600.0887399105072,
    "input_throughput": 6477.65365933166,
    "output_throughput": 5652.8673236276645,
    "total_throughput": 12130.520982959324,
    "itl": 91.76948314287465,
    "ttft": 2085962.2597453494,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 525,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.865403011869673,
    "arrivals": 1494384,
    "finished_requests": 94018,
    "scheduler_time": 252.0946814784755
}
#Debug simulation 
Total elapsed time: 67.5462956209667. Arrivals time: 0.4591918531805277 Scheduler time: 66.89062424888834 Scheduler overhead time: 0.07637480553239584 Adapter cache time: 0.017225530929863453 Engine time: 0.0727228419855237 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.025_size_8-8-8/adapters_256_slots_32_rate_3.2-1.6-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.025_size_8-8-8/adapters_256_slots_32_rate_3.2-1.6-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [85 85 86]
Adapter prompts. [17280, 17280, 34560, 270, 34560, 34560, 270, 34560, 17280, 34560, 270, 17280, 270, 34560, 17280, 17280, 17280, 17280, 34560, 270, 270, 270, 17280, 34560, 270, 34560, 34560, 17280, 17280, 17280, 270, 34560, 270, 17280, 17280, 270, 17280, 270, 270, 17280, 17280, 34560, 17280, 270, 17280, 34560, 17280, 17280, 34560, 17280, 34560, 270, 34560, 34560, 17280, 270, 270, 34560, 17280, 270, 17280, 17280, 34560, 17280, 270, 270, 34560, 34560, 34560, 34560, 34560, 34560, 270, 17280, 270, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 270, 34560, 34560, 270, 34560, 270, 17280, 34560, 34560, 34560, 17280, 270, 34560, 17280, 270, 270, 270, 270, 270, 34560, 17280, 270, 34560, 270, 34560, 270, 270, 17280, 17280, 34560, 17280, 34560, 270, 17280, 270, 34560, 34560, 270, 34560, 17280, 270, 34560, 270, 270, 34560, 34560, 17280, 34560, 34560, 270, 34560, 17280, 17280, 270, 17280, 34560, 34560, 270, 34560, 17280, 270, 17280, 34560, 270, 270, 270, 270, 270, 270, 34560, 270, 270, 270, 34560, 270, 17280, 34560, 34560, 17280, 270, 34560, 270, 17280, 17280, 270, 17280, 270, 34560, 270, 270, 34560, 270, 34560, 34560, 17280, 34560, 17280, 270, 17280, 34560, 17280, 34560, 270, 34560, 270, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 270, 34560, 270, 34560, 17280, 17280, 270, 17280, 34560, 17280, 17280, 34560, 270, 34560, 34560, 17280, 270, 34560, 34560, 17280, 17280, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 34560, 270, 34560, 17280, 34560, 34560, 270, 34560, 17280, 17280, 34560, 270, 17280, 270, 270, 270, 270, 17280, 17280, 17280, 17280, 17280, 34560, 17280, 270, 270, 270, 270]
Prompts retrieved: 4463910 . Total input tokens: 995791421 . Total output tokens: 876527782
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 75.436516079586,
    "estimated_duration": 3600.076697152359,
    "input_throughput": 6725.6783776724305,
    "output_throughput": 5875.375104294572,
    "total_throughput": 12601.053481967003,
    "itl": 100.3059584471846,
    "ttft": 2071107.5062690352,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 474,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.1342818811443043,
    "arrivals": 1486681,
    "finished_requests": 98269,
    "scheduler_time": 241.22464043931998
}
#Debug simulation 
Total elapsed time: 75.43669052887708. Arrivals time: 0.47599645983427763 Scheduler time: 74.77327465638518 Scheduler overhead time: 0.07316878577694297 Adapter cache time: 0.016389198135584593 Engine time: 0.06948266364634037 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.025_size_8-8-16/adapters_256_slots_32_rate_3.2-1.6-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.025_size_8-8-16/adapters_256_slots_32_rate_3.2-1.6-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [85 85 86]
Adapter prompts. [17280, 17280, 34560, 270, 34560, 34560, 270, 34560, 17280, 34560, 270, 17280, 270, 34560, 17280, 17280, 17280, 17280, 34560, 270, 270, 270, 17280, 34560, 270, 34560, 34560, 17280, 17280, 17280, 270, 34560, 270, 17280, 17280, 270, 17280, 270, 270, 17280, 17280, 34560, 17280, 270, 17280, 34560, 17280, 17280, 34560, 17280, 34560, 270, 34560, 34560, 17280, 270, 270, 34560, 17280, 270, 17280, 17280, 34560, 17280, 270, 270, 34560, 34560, 34560, 34560, 34560, 34560, 270, 17280, 270, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 270, 34560, 34560, 270, 34560, 270, 17280, 34560, 34560, 34560, 17280, 270, 34560, 17280, 270, 270, 270, 270, 270, 34560, 17280, 270, 34560, 270, 34560, 270, 270, 17280, 17280, 34560, 17280, 34560, 270, 17280, 270, 34560, 34560, 270, 34560, 17280, 270, 34560, 270, 270, 34560, 34560, 17280, 34560, 34560, 270, 34560, 17280, 17280, 270, 17280, 34560, 34560, 270, 34560, 17280, 270, 17280, 34560, 270, 270, 270, 270, 270, 270, 34560, 270, 270, 270, 34560, 270, 17280, 34560, 34560, 17280, 270, 34560, 270, 17280, 17280, 270, 17280, 270, 34560, 270, 270, 34560, 270, 34560, 34560, 17280, 34560, 17280, 270, 17280, 34560, 17280, 34560, 270, 34560, 270, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 270, 34560, 270, 34560, 17280, 17280, 270, 17280, 34560, 17280, 17280, 34560, 270, 34560, 34560, 17280, 270, 34560, 34560, 17280, 17280, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 34560, 270, 34560, 17280, 34560, 34560, 270, 34560, 17280, 17280, 34560, 270, 17280, 270, 270, 270, 270, 17280, 17280, 17280, 17280, 17280, 34560, 17280, 270, 270, 270, 270]
Prompts retrieved: 4463910 . Total input tokens: 995791421 . Total output tokens: 876527782
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 71.63651812588796,
    "estimated_duration": 3600.007842401656,
    "input_throughput": 6627.92833920106,
    "output_throughput": 5800.043753813128,
    "total_throughput": 12427.972093014188,
    "itl": 97.67668712306694,
    "ttft": 2076587.680312834,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 475,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.4752049372578084,
    "arrivals": 1486681,
    "finished_requests": 96941,
    "scheduler_time": 244.7755987199511
}
#Debug simulation 
Total elapsed time: 71.6366688250564. Arrivals time: 0.47483911691233516 Scheduler time: 70.97019787179306 Scheduler overhead time: 0.0740737458691001 Adapter cache time: 0.01663505658507347 Engine time: 0.07112883124500513 
