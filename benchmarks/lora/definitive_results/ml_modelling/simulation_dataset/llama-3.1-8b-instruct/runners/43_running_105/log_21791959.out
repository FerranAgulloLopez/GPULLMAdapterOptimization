INFO 05-31 19:30:51 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 05-31 19:30:52 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_8-8-8/adapters_64_slots_64_rate_1.6-0.4-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_8-8-8/adapters_64_slots_64_rate_1.6-0.4-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [21 21 22]
Adapter prompts. [270, 4320, 17280, 17280, 270, 17280, 270, 4320, 270, 17280, 4320, 17280, 270, 4320, 17280, 17280, 17280, 270, 17280, 4320, 4320, 270, 270, 270, 17280, 270, 270, 270, 17280, 4320, 270, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 270, 4320, 4320, 17280, 17280, 4320, 17280, 270, 17280, 4320, 4320, 4320, 17280, 4320, 270, 270, 4320, 4320, 270, 4320, 270, 270, 270, 17280, 4320]
Prompts retrieved: 476550 . Total input tokens: 106303446 . Total output tokens: 93582864
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 6.347205887082964,
    "estimated_duration": 3600.0915284129455,
    "input_throughput": 6255.6765077381515,
    "output_throughput": 5502.363160397911,
    "total_throughput": 11758.039668136062,
    "itl": 105.357724069381,
    "ttft": 1378342.928184097,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.42319417804479564,
    "arrivals": 158690,
    "finished_requests": 91561,
    "scheduler_time": 48.64672362690106
}
#Debug simulation 
Total elapsed time: 6.347310544922948. Arrivals time: 0.2695582560263574 Scheduler time: 5.938021073117852 Scheduler overhead time: 0.04916625516489148 Adapter cache time: 0.015739213209599257 Engine time: 0.051314896903932095 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_8-8-16/adapters_64_slots_64_rate_1.6-0.4-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_8-8-16/adapters_64_slots_64_rate_1.6-0.4-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [21 21 22]
Adapter prompts. [270, 4320, 17280, 17280, 270, 17280, 270, 4320, 270, 17280, 4320, 17280, 270, 4320, 17280, 17280, 17280, 270, 17280, 4320, 4320, 270, 270, 270, 17280, 270, 270, 270, 17280, 4320, 270, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 270, 4320, 4320, 17280, 17280, 4320, 17280, 270, 17280, 4320, 4320, 4320, 17280, 4320, 270, 270, 4320, 4320, 270, 4320, 270, 270, 270, 17280, 4320]
Prompts retrieved: 476550 . Total input tokens: 106303446 . Total output tokens: 93582864
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 6.240093341097236,
    "estimated_duration": 3600.0374425168116,
    "input_throughput": 6107.980083848062,
    "output_throughput": 5376.387415145507,
    "total_throughput": 11484.36749899357,
    "itl": 97.57981136133336,
    "ttft": 1408192.5030872773,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.46826444204896667,
    "arrivals": 158690,
    "finished_requests": 89411,
    "scheduler_time": 43.99964112683692
}
#Debug simulation 
Total elapsed time: 6.240198257379234. Arrivals time: 0.25396102061495185 Scheduler time: 5.837034053634852 Scheduler overhead time: 0.05252100946381688 Adapter cache time: 0.017027398105710745 Engine time: 0.05433617765083909 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_8-8-32/adapters_64_slots_64_rate_1.6-0.4-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_8-8-32/adapters_64_slots_64_rate_1.6-0.4-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [21 21 22]
Adapter prompts. [270, 4320, 17280, 17280, 270, 17280, 270, 4320, 270, 17280, 4320, 17280, 270, 4320, 17280, 17280, 17280, 270, 17280, 4320, 4320, 270, 270, 270, 17280, 270, 270, 270, 17280, 4320, 270, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 270, 4320, 4320, 17280, 17280, 4320, 17280, 270, 17280, 4320, 4320, 4320, 17280, 4320, 270, 270, 4320, 4320, 270, 4320, 270, 270, 270, 17280, 4320]
Prompts retrieved: 476550 . Total input tokens: 106303446 . Total output tokens: 93582864
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 6.087926572188735,
    "estimated_duration": 3600.0160877620156,
    "input_throughput": 5830.906442712449,
    "output_throughput": 5142.673407192806,
    "total_throughput": 10973.579849905254,
    "itl": 85.93257639932516,
    "ttft": 1464364.4042956668,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4809837616281585,
    "arrivals": 158690,
    "finished_requests": 85447,
    "scheduler_time": 35.36338994101231
}
#Debug simulation 
Total elapsed time: 6.088020530063659. Arrivals time: 0.24659515917301178 Scheduler time: 5.6739634638652205 Scheduler overhead time: 0.05858841072767973 Adapter cache time: 0.01984566356986761 Engine time: 0.060799720231443644 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_8-16-16/adapters_64_slots_64_rate_1.6-0.4-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_8-16-16/adapters_64_slots_64_rate_1.6-0.4-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [21 21 22]
Adapter prompts. [270, 4320, 17280, 17280, 270, 17280, 270, 4320, 270, 17280, 4320, 17280, 270, 4320, 17280, 17280, 17280, 270, 17280, 4320, 4320, 270, 270, 270, 17280, 270, 270, 270, 17280, 4320, 270, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 270, 4320, 4320, 17280, 17280, 4320, 17280, 270, 17280, 4320, 4320, 4320, 17280, 4320, 270, 270, 4320, 4320, 270, 4320, 270, 270, 270, 17280, 4320]
Prompts retrieved: 476550 . Total input tokens: 106303446 . Total output tokens: 93582864
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 6.2803038652054965,
    "estimated_duration": 3600.0886746060582,
    "input_throughput": 6115.829078129383,
    "output_throughput": 5382.168816194579,
    "total_throughput": 11497.997894323962,
    "itl": 97.92401962534319,
    "ttft": 1407060.0861474557,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4391118016093969,
    "arrivals": 158690,
    "finished_requests": 89523,
    "scheduler_time": 44.23873603857924
}
#Debug simulation 
Total elapsed time: 6.280396411195397. Arrivals time: 0.2583164661191404 Scheduler time: 5.872403325047344 Scheduler overhead time: 0.05248368578031659 Adapter cache time: 0.017168530728667974 Engine time: 0.054675990249961615 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_8-16-32/adapters_64_slots_64_rate_1.6-0.4-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_8-16-32/adapters_64_slots_64_rate_1.6-0.4-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [21 21 22]
Adapter prompts. [270, 4320, 17280, 17280, 270, 17280, 270, 4320, 270, 17280, 4320, 17280, 270, 4320, 17280, 17280, 17280, 270, 17280, 4320, 4320, 270, 270, 270, 17280, 270, 270, 270, 17280, 4320, 270, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 270, 4320, 4320, 17280, 17280, 4320, 17280, 270, 17280, 4320, 4320, 4320, 17280, 4320, 270, 270, 4320, 4320, 270, 4320, 270, 270, 270, 17280, 4320]
Prompts retrieved: 476550 . Total input tokens: 106303446 . Total output tokens: 93582864
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 6.064397704321891,
    "estimated_duration": 3600.060578503103,
    "input_throughput": 5832.5651866477065,
    "output_throughput": 5143.521503657397,
    "total_throughput": 10976.086690305103,
    "itl": 86.01320423785441,
    "ttft": 1463722.3359153222,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.47663430091924974,
    "arrivals": 158690,
    "finished_requests": 85471,
    "scheduler_time": 35.43386383065367
}
#Debug simulation 
Total elapsed time: 6.064524027984589. Arrivals time: 0.24913921114057302 Scheduler time: 5.648477551527321 Scheduler overhead time: 0.058363656513392925 Adapter cache time: 0.019596360623836517 Engine time: 0.060793743934482336 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_16-16-16/adapters_64_slots_64_rate_1.6-0.4-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_16-16-16/adapters_64_slots_64_rate_1.6-0.4-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [21 21 22]
Adapter prompts. [270, 4320, 17280, 17280, 270, 17280, 270, 4320, 270, 17280, 4320, 17280, 270, 4320, 17280, 17280, 17280, 270, 17280, 4320, 4320, 270, 270, 270, 17280, 270, 270, 270, 17280, 4320, 270, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 270, 4320, 4320, 17280, 17280, 4320, 17280, 270, 17280, 4320, 4320, 4320, 17280, 4320, 270, 270, 4320, 4320, 270, 4320, 270, 270, 270, 17280, 4320]
Prompts retrieved: 476550 . Total input tokens: 106303446 . Total output tokens: 93582864
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 6.607419806998223,
    "estimated_duration": 3600.0582398060124,
    "input_throughput": 6115.875781272473,
    "output_throughput": 5382.239872053872,
    "total_throughput": 11498.115653326346,
    "itl": 97.92207579834673,
    "ttft": 1407060.3884830317,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4085709401965145,
    "arrivals": 158690,
    "finished_requests": 89523,
    "scheduler_time": 44.237127120758714
}
#Debug simulation 
Total elapsed time: 6.607513131108135. Arrivals time: 0.2603263510391116 Scheduler time: 6.196223694365472 Scheduler overhead time: 0.05289573408663273 Adapter cache time: 0.017498706933110952 Engine time: 0.05500148609280586 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_16-16-32/adapters_64_slots_64_rate_1.6-0.4-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_16-16-32/adapters_64_slots_64_rate_1.6-0.4-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [21 21 22]
Adapter prompts. [270, 4320, 17280, 17280, 270, 17280, 270, 4320, 270, 17280, 4320, 17280, 270, 4320, 17280, 17280, 17280, 270, 17280, 4320, 4320, 270, 270, 270, 17280, 270, 270, 270, 17280, 4320, 270, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 270, 4320, 4320, 17280, 17280, 4320, 17280, 270, 17280, 4320, 4320, 4320, 17280, 4320, 270, 270, 4320, 4320, 270, 4320, 270, 270, 270, 17280, 4320]
Prompts retrieved: 476550 . Total input tokens: 106303446 . Total output tokens: 93582864
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 6.1016601389274,
    "estimated_duration": 3600.049279739585,
    "input_throughput": 5830.491854133271,
    "output_throughput": 5142.081555433339,
    "total_throughput": 10972.57340956661,
    "itl": 85.92171771587984,
    "ttft": 1464492.630900684,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.47207772303372625,
    "arrivals": 158690,
    "finished_requests": 85441,
    "scheduler_time": 35.35102328861147
}
#Debug simulation 
Total elapsed time: 6.101753163151443. Arrivals time: 0.2733621275983751 Scheduler time: 5.659732690081 Scheduler overhead time: 0.059452120680361986 Adapter cache time: 0.019648517947643995 Engine time: 0.061263663694262505 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-8/adapters_64_slots_64_rate_1.6-0.4-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-8/adapters_64_slots_64_rate_1.6-0.4-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [21 21 22]
Adapter prompts. [135, 4320, 17280, 17280, 135, 17280, 135, 4320, 135, 17280, 4320, 17280, 135, 4320, 17280, 17280, 17280, 135, 17280, 4320, 4320, 135, 135, 135, 17280, 135, 135, 135, 17280, 4320, 135, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 135, 4320, 4320, 17280, 17280, 4320, 17280, 135, 17280, 4320, 4320, 4320, 17280, 4320, 135, 135, 4320, 4320, 135, 4320, 135, 135, 135, 17280, 4320]
Prompts retrieved: 473715 . Total input tokens: 105660551 . Total output tokens: 93034366
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 6.605957345105708,
    "estimated_duration": 3600.1026197115575,
    "input_throughput": 6468.765049221254,
    "output_throughput": 5610.849504511737,
    "total_throughput": 12079.614553732992,
    "itl": 102.44457765380564,
    "ttft": 1335575.2411277597,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.42319417804479564,
    "arrivals": 157801,
    "finished_requests": 93959,
    "scheduler_time": 49.787220889838444
}
#Debug simulation 
Total elapsed time: 6.606052590999752. Arrivals time: 0.2662916276603937 Scheduler time: 6.197371908929199 Scheduler overhead time: 0.05105720367282629 Adapter cache time: 0.01378622092306614 Engine time: 0.053158840630203485 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-16/adapters_64_slots_64_rate_1.6-0.4-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-16/adapters_64_slots_64_rate_1.6-0.4-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [21 21 22]
Adapter prompts. [135, 4320, 17280, 17280, 135, 17280, 135, 4320, 135, 17280, 4320, 17280, 135, 4320, 17280, 17280, 17280, 135, 17280, 4320, 4320, 135, 135, 135, 17280, 135, 135, 135, 17280, 4320, 135, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 135, 4320, 4320, 17280, 17280, 4320, 17280, 135, 17280, 4320, 4320, 4320, 17280, 4320, 135, 135, 4320, 4320, 135, 4320, 135, 135, 135, 17280, 4320]
Prompts retrieved: 473715 . Total input tokens: 105660551 . Total output tokens: 93034366
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 6.652056589722633,
    "estimated_duration": 3600.0767703931133,
    "input_throughput": 6323.887642405469,
    "output_throughput": 5484.459987736313,
    "total_throughput": 11808.347630141781,
    "itl": 95.28286078753214,
    "ttft": 1367766.846713877,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4682644420489668,
    "arrivals": 157801,
    "finished_requests": 91813,
    "scheduler_time": 45.161774174600296
}
#Debug simulation 
Total elapsed time: 6.652123276609927. Arrivals time: 0.26936994958668947 Scheduler time: 6.232237409800291 Scheduler overhead time: 0.05400701053440571 Adapter cache time: 0.014502327423542738 Engine time: 0.056086975149810314 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-32/adapters_64_slots_64_rate_1.6-0.4-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-32/adapters_64_slots_64_rate_1.6-0.4-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [21 21 22]
Adapter prompts. [135, 4320, 17280, 17280, 135, 17280, 135, 4320, 135, 17280, 4320, 17280, 135, 4320, 17280, 17280, 17280, 135, 17280, 4320, 4320, 135, 135, 135, 17280, 135, 135, 135, 17280, 4320, 135, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 135, 4320, 4320, 17280, 17280, 4320, 17280, 135, 17280, 4320, 4320, 4320, 17280, 4320, 135, 135, 4320, 4320, 135, 4320, 135, 135, 135, 17280, 4320]
Prompts retrieved: 473715 . Total input tokens: 105660551 . Total output tokens: 93034366
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 6.201278719119728,
    "estimated_duration": 3600.019072578609,
    "input_throughput": 6034.239142083226,
    "output_throughput": 5227.4606385683455,
    "total_throughput": 11261.699780651572,
    "itl": 83.82830498865302,
    "ttft": 1428876.1163520818,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4809837616281585,
    "arrivals": 157801,
    "finished_requests": 87538,
    "scheduler_time": 36.02814523310433
}
#Debug simulation 
Total elapsed time: 6.201436969451606. Arrivals time: 0.2578245741315186 Scheduler time: 5.7752116727642715 Scheduler overhead time: 0.06008028192445636 Adapter cache time: 0.016637118067592382 Engine time: 0.06289309868589044 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_8-16-16/adapters_64_slots_64_rate_1.6-0.4-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_8-16-16/adapters_64_slots_64_rate_1.6-0.4-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [21 21 22]
Adapter prompts. [135, 4320, 17280, 17280, 135, 17280, 135, 4320, 135, 17280, 4320, 17280, 135, 4320, 17280, 17280, 17280, 135, 17280, 4320, 4320, 135, 135, 135, 17280, 135, 135, 135, 17280, 4320, 135, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 135, 4320, 4320, 17280, 17280, 4320, 17280, 135, 17280, 4320, 4320, 4320, 17280, 4320, 135, 135, 4320, 4320, 135, 4320, 135, 135, 135, 17280, 4320]
Prompts retrieved: 473715 . Total input tokens: 105660551 . Total output tokens: 93034366
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 6.53246263274923,
    "estimated_duration": 3600.096330355501,
    "input_throughput": 6324.011890468444,
    "output_throughput": 5484.2640830253395,
    "total_throughput": 11808.275973493784,
    "itl": 95.27950264235733,
    "ttft": 1367871.8719674486,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.43911180160939695,
    "arrivals": 157801,
    "finished_requests": 91812,
    "scheduler_time": 45.16109413429501
}
#Debug simulation 
Total elapsed time: 6.532555217854679. Arrivals time: 0.26521053072065115 Scheduler time: 6.114374234806746 Scheduler overhead time: 0.05412851786240935 Adapter cache time: 0.014747143257409334 Engine time: 0.057790429797023535 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_8-16-32/adapters_64_slots_64_rate_1.6-0.4-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_8-16-32/adapters_64_slots_64_rate_1.6-0.4-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [21 21 22]
Adapter prompts. [135, 4320, 17280, 17280, 135, 17280, 135, 4320, 135, 17280, 4320, 17280, 135, 4320, 17280, 17280, 17280, 135, 17280, 4320, 4320, 135, 135, 135, 17280, 135, 135, 135, 17280, 4320, 135, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 135, 4320, 4320, 17280, 17280, 4320, 17280, 135, 17280, 4320, 4320, 4320, 17280, 4320, 135, 135, 4320, 4320, 135, 4320, 135, 135, 135, 17280, 4320]
Prompts retrieved: 473715 . Total input tokens: 105660551 . Total output tokens: 93034366
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 6.219341380055994,
    "estimated_duration": 3600.08571285121,
    "input_throughput": 6034.458547042341,
    "output_throughput": 5227.638590053153,
    "total_throughput": 11262.097137095494,
    "itl": 83.828060679229,
    "ttft": 1428817.1237508005,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.47663430091924974,
    "arrivals": 157801,
    "finished_requests": 87542,
    "scheduler_time": 36.02951723356259
}
#Debug simulation 
Total elapsed time: 6.219435330945998. Arrivals time: 0.2582655190490186 Scheduler time: 5.792271127924323 Scheduler overhead time: 0.06054318882524967 Adapter cache time: 0.016608377918601036 Engine time: 0.06269961362704635 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_16-16-16/adapters_64_slots_64_rate_1.6-0.4-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_16-16-16/adapters_64_slots_64_rate_1.6-0.4-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [21 21 22]
Adapter prompts. [135, 4320, 17280, 17280, 135, 17280, 135, 4320, 135, 17280, 4320, 17280, 135, 4320, 17280, 17280, 17280, 135, 17280, 4320, 4320, 135, 135, 135, 17280, 135, 135, 135, 17280, 4320, 135, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 135, 4320, 4320, 17280, 17280, 4320, 17280, 135, 17280, 4320, 4320, 4320, 17280, 4320, 135, 135, 4320, 4320, 135, 4320, 135, 135, 135, 17280, 4320]
Prompts retrieved: 473715 . Total input tokens: 105660551 . Total output tokens: 93034366
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 6.436259466223419,
    "estimated_duration": 3600.050306650112,
    "input_throughput": 6323.926629009928,
    "output_throughput": 5484.289195495092,
    "total_throughput": 11808.21582450502,
    "itl": 95.28021508248503,
    "ttft": 1367817.2398906036,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4085709401965145,
    "arrivals": 157801,
    "finished_requests": 91810,
    "scheduler_time": 45.16248017520291
}
#Debug simulation 
Total elapsed time: 6.4363743788562715. Arrivals time: 0.2615374862216413 Scheduler time: 6.0238931607455015 Scheduler overhead time: 0.05410347366705537 Adapter cache time: 0.014666405972093344 Engine time: 0.056032742373645306 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_16-16-32/adapters_64_slots_64_rate_1.6-0.4-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_16-16-32/adapters_64_slots_64_rate_1.6-0.4-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [21 21 22]
Adapter prompts. [135, 4320, 17280, 17280, 135, 17280, 135, 4320, 135, 17280, 4320, 17280, 135, 4320, 17280, 17280, 17280, 135, 17280, 4320, 4320, 135, 135, 135, 17280, 135, 135, 135, 17280, 4320, 135, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 135, 4320, 4320, 17280, 17280, 4320, 17280, 135, 17280, 4320, 4320, 4320, 17280, 4320, 135, 135, 4320, 4320, 135, 4320, 135, 135, 135, 17280, 4320]
Prompts retrieved: 473715 . Total input tokens: 105660551 . Total output tokens: 93034366
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 6.267159774899483,
    "estimated_duration": 3600.0618029531884,
    "input_throughput": 6034.317794816612,
    "output_throughput": 5227.487757171903,
    "total_throughput": 11261.805551988515,
    "itl": 83.83041525070522,
    "ttft": 1428784.49652079,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4720777230337263,
    "arrivals": 157801,
    "finished_requests": 87540,
    "scheduler_time": 36.03088875494566
}
#Debug simulation 
Total elapsed time: 6.2672772337682545. Arrivals time: 0.25523071689531207 Scheduler time: 5.842544254846871 Scheduler overhead time: 0.060332330875098705 Adapter cache time: 0.01641510333865881 Engine time: 0.06358838686719537 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-8/adapters_64_slots_64_rate_1.6-0.4-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-8/adapters_64_slots_64_rate_1.6-0.4-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [21 21 22]
Adapter prompts. [66, 4320, 17280, 17280, 66, 17280, 66, 4320, 66, 17280, 4320, 17280, 66, 4320, 17280, 17280, 17280, 66, 17280, 4320, 4320, 66, 66, 66, 17280, 66, 66, 66, 17280, 4320, 66, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 66, 4320, 4320, 17280, 17280, 4320, 17280, 66, 17280, 4320, 4320, 4320, 17280, 4320, 66, 66, 4320, 4320, 66, 4320, 66, 66, 66, 17280, 4320]
Prompts retrieved: 472266 . Total input tokens: 105339642 . Total output tokens: 92744421
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 6.598128828220069,
    "estimated_duration": 3600.074722826789,
    "input_throughput": 6549.785439310309,
    "output_throughput": 5665.895174526741,
    "total_throughput": 12215.68061383705,
    "itl": 101.16902108812776,
    "ttft": 1327419.224697073,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.42319417804479564,
    "arrivals": 157261,
    "finished_requests": 94611,
    "scheduler_time": 50.270642165603185
}
#Debug simulation 
Total elapsed time: 6.598258183337748. Arrivals time: 0.28196811815723777 Scheduler time: 6.174359139055014 Scheduler overhead time: 0.051508461590856314 Adapter cache time: 0.012149674352258444 Engine time: 0.05340623715892434 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-16/adapters_64_slots_64_rate_1.6-0.4-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-16/adapters_64_slots_64_rate_1.6-0.4-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [21 21 22]
Adapter prompts. [66, 4320, 17280, 17280, 66, 17280, 66, 4320, 66, 17280, 4320, 17280, 66, 4320, 17280, 17280, 17280, 66, 17280, 4320, 4320, 66, 66, 66, 17280, 66, 66, 66, 17280, 4320, 66, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 66, 4320, 4320, 17280, 17280, 4320, 17280, 66, 17280, 4320, 4320, 4320, 17280, 4320, 66, 66, 4320, 4320, 66, 4320, 66, 66, 66, 17280, 4320]
Prompts retrieved: 472266 . Total input tokens: 105339642 . Total output tokens: 92744421
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 6.572422154713422,
    "estimated_duration": 3600.031994408664,
    "input_throughput": 6397.345366866102,
    "output_throughput": 5532.288054920868,
    "total_throughput": 11929.63342178697,
    "itl": 94.19048235060663,
    "ttft": 1360370.9771039633,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.46826444204896667,
    "arrivals": 157261,
    "finished_requests": 92408,
    "scheduler_time": 45.55278147361794
}
#Debug simulation 
Total elapsed time: 6.572550348006189. Arrivals time: 0.26373794162645936 Scheduler time: 6.156402192544192 Scheduler overhead time: 0.05514887720346451 Adapter cache time: 0.013028785586357117 Engine time: 0.05763543490320444 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-32/adapters_64_slots_64_rate_1.6-0.4-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-32/adapters_64_slots_64_rate_1.6-0.4-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [21 21 22]
Adapter prompts. [66, 4320, 17280, 17280, 66, 17280, 66, 4320, 66, 17280, 4320, 17280, 66, 4320, 17280, 17280, 17280, 66, 17280, 4320, 4320, 66, 66, 66, 17280, 66, 66, 66, 17280, 4320, 66, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 66, 4320, 4320, 17280, 17280, 4320, 17280, 66, 17280, 4320, 4320, 4320, 17280, 4320, 66, 66, 4320, 4320, 66, 4320, 66, 66, 66, 17280, 4320]
Prompts retrieved: 472266 . Total input tokens: 105339642 . Total output tokens: 92744421
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 6.2850713562220335,
    "estimated_duration": 3600.0437247045647,
    "input_throughput": 6076.681749690489,
    "output_throughput": 5256.434767761865,
    "total_throughput": 11333.116517452354,
    "itl": 82.6967895764344,
    "ttft": 1426472.18888658,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4809837616281584,
    "arrivals": 157261,
    "finished_requests": 87746,
    "scheduler_time": 35.9003924473313
}
#Debug simulation 
Total elapsed time: 6.285164651926607. Arrivals time: 0.2564330166205764 Scheduler time: 5.856826287694275 Scheduler overhead time: 0.06109255272895098 Adapter cache time: 0.015335334930568933 Engine time: 0.06588055938482285 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_8-16-16/adapters_64_slots_64_rate_1.6-0.4-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_8-16-16/adapters_64_slots_64_rate_1.6-0.4-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [21 21 22]
Adapter prompts. [66, 4320, 17280, 17280, 66, 17280, 66, 4320, 66, 17280, 4320, 17280, 66, 4320, 17280, 17280, 17280, 66, 17280, 4320, 4320, 66, 66, 66, 17280, 66, 66, 66, 17280, 4320, 66, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 66, 4320, 4320, 17280, 17280, 4320, 17280, 66, 17280, 4320, 4320, 4320, 17280, 4320, 66, 66, 4320, 4320, 66, 4320, 66, 66, 66, 17280, 4320]
Prompts retrieved: 472266 . Total input tokens: 105339642 . Total output tokens: 92744421
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 6.581471738871187,
    "estimated_duration": 3600.063108304764,
    "input_throughput": 6397.392853161702,
    "output_throughput": 5532.27246323982,
    "total_throughput": 11929.665316401522,
    "itl": 94.1904406260808,
    "ttft": 1360361.183117701,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4391118016093971,
    "arrivals": 157261,
    "finished_requests": 92409,
    "scheduler_time": 45.5530903657752
}
#Debug simulation 
Total elapsed time: 6.581575138960034. Arrivals time: 0.2714002216234803 Scheduler time: 6.1579171204939485 Scheduler overhead time: 0.05526200821623206 Adapter cache time: 0.013169935438781977 Engine time: 0.05737601174041629 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_8-16-32/adapters_64_slots_64_rate_1.6-0.4-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_8-16-32/adapters_64_slots_64_rate_1.6-0.4-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [21 21 22]
Adapter prompts. [66, 4320, 17280, 17280, 66, 17280, 66, 4320, 66, 17280, 4320, 17280, 66, 4320, 17280, 17280, 17280, 66, 17280, 4320, 4320, 66, 66, 66, 17280, 66, 66, 66, 17280, 4320, 66, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 66, 4320, 4320, 17280, 17280, 4320, 17280, 66, 17280, 4320, 4320, 4320, 17280, 4320, 66, 66, 4320, 4320, 66, 4320, 66, 66, 66, 17280, 4320]
Prompts retrieved: 472266 . Total input tokens: 105339642 . Total output tokens: 92744421
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 6.29578400682658,
    "estimated_duration": 3600.0117354425984,
    "input_throughput": 6072.8249257532425,
    "output_throughput": 5253.823984458391,
    "total_throughput": 11326.648910211634,
    "itl": 82.60160202861854,
    "ttft": 1427093.2387045117,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4766343009192497,
    "arrivals": 157261,
    "finished_requests": 87700,
    "scheduler_time": 35.800550988559024
}
#Debug simulation 
Total elapsed time: 6.2958721299655735. Arrivals time: 0.2645972054451704 Scheduler time: 5.861637291498482 Scheduler overhead time: 0.06102828215807676 Adapter cache time: 0.015420862939208746 Engine time: 0.06371986912563443 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_16-16-16/adapters_64_slots_64_rate_1.6-0.4-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_16-16-16/adapters_64_slots_64_rate_1.6-0.4-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [21 21 22]
Adapter prompts. [66, 4320, 17280, 17280, 66, 17280, 66, 4320, 66, 17280, 4320, 17280, 66, 4320, 17280, 17280, 17280, 66, 17280, 4320, 4320, 66, 66, 66, 17280, 66, 66, 66, 17280, 4320, 66, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 66, 4320, 4320, 17280, 17280, 4320, 17280, 66, 17280, 4320, 4320, 4320, 17280, 4320, 66, 66, 4320, 4320, 66, 4320, 66, 66, 66, 17280, 4320]
Prompts retrieved: 472266 . Total input tokens: 105339642 . Total output tokens: 92744421
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 6.568138142116368,
    "estimated_duration": 3600.0598377390947,
    "input_throughput": 6397.541162666961,
    "output_throughput": 5532.30859976706,
    "total_throughput": 11929.849762434022,
    "itl": 94.19016700491647,
    "ttft": 1360369.997997747,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4085709401965145,
    "arrivals": 157261,
    "finished_requests": 92410,
    "scheduler_time": 45.55335629575942
}
#Debug simulation 
Total elapsed time: 6.5682299779728055. Arrivals time: 0.2692802078090608 Scheduler time: 6.147684857714921 Scheduler overhead time: 0.05469575338065624 Adapter cache time: 0.013172872364521027 Engine time: 0.057098053861409426 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_16-16-32/adapters_64_slots_64_rate_1.6-0.4-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_16-16-32/adapters_64_slots_64_rate_1.6-0.4-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [21 21 22]
Adapter prompts. [66, 4320, 17280, 17280, 66, 17280, 66, 4320, 66, 17280, 4320, 17280, 66, 4320, 17280, 17280, 17280, 66, 17280, 4320, 4320, 66, 66, 66, 17280, 66, 66, 66, 17280, 4320, 66, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 66, 4320, 4320, 17280, 17280, 4320, 17280, 66, 17280, 4320, 4320, 4320, 17280, 4320, 66, 66, 4320, 4320, 66, 4320, 66, 66, 66, 17280, 4320]
Prompts retrieved: 472266 . Total input tokens: 105339642 . Total output tokens: 92744421
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 6.194943769369274,
    "estimated_duration": 3600.054537700186,
    "input_throughput": 6077.355154174077,
    "output_throughput": 5257.222300885095,
    "total_throughput": 11334.577455059172,
    "itl": 82.72097154383827,
    "ttft": 1426355.770508143,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.47207772303372625,
    "arrivals": 157261,
    "finished_requests": 87756,
    "scheduler_time": 35.9236855929252
}
#Debug simulation 
Total elapsed time: 6.195038326084614. Arrivals time: 0.2577956821769476 Scheduler time: 5.769340607337654 Scheduler overhead time: 0.06048570992425084 Adapter cache time: 0.015176346525549889 Engine time: 0.06289808917790651 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-8/adapters_64_slots_64_rate_1.6-0.4-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-8/adapters_64_slots_64_rate_1.6-0.4-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [21 21 22]
Adapter prompts. [33, 4320, 17280, 17280, 33, 17280, 33, 4320, 33, 17280, 4320, 17280, 33, 4320, 17280, 17280, 17280, 33, 17280, 4320, 4320, 33, 33, 33, 17280, 33, 33, 33, 17280, 4320, 33, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 33, 4320, 4320, 17280, 17280, 4320, 17280, 33, 17280, 4320, 4320, 4320, 17280, 4320, 33, 33, 4320, 4320, 33, 4320, 33, 33, 33, 17280, 4320]
Prompts retrieved: 471573 . Total input tokens: 105185848 . Total output tokens: 92612733
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 6.621705064084381,
    "estimated_duration": 3600.0559517759857,
    "input_throughput": 6465.217016562719,
    "output_throughput": 5697.984774342315,
    "total_throughput": 12163.201790905036,
    "itl": 101.20852885207641,
    "ttft": 1325021.313393324,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.42319417804479564,
    "arrivals": 157020,
    "finished_requests": 94295,
    "scheduler_time": 50.76235813383196
}
#Debug simulation 
Total elapsed time: 6.621801852248609. Arrivals time: 0.2792311585508287 Scheduler time: 6.202550905756652 Scheduler overhead time: 0.05123260337859392 Adapter cache time: 0.01080670952796936 Engine time: 0.05332069331780076 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-16/adapters_64_slots_64_rate_1.6-0.4-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-16/adapters_64_slots_64_rate_1.6-0.4-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [21 21 22]
Adapter prompts. [33, 4320, 17280, 17280, 33, 17280, 33, 4320, 33, 17280, 4320, 17280, 33, 4320, 17280, 17280, 17280, 33, 17280, 4320, 4320, 33, 33, 33, 17280, 33, 33, 33, 17280, 4320, 33, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 33, 4320, 4320, 17280, 17280, 4320, 17280, 33, 17280, 4320, 4320, 4320, 17280, 4320, 33, 33, 4320, 4320, 33, 4320, 33, 33, 33, 17280, 4320]
Prompts retrieved: 471573 . Total input tokens: 105185848 . Total output tokens: 92612733
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 6.492606739047915,
    "estimated_duration": 3600.060881463518,
    "input_throughput": 6305.665306074365,
    "output_throughput": 5559.679032945495,
    "total_throughput": 11865.34433901986,
    "itl": 94.27401131856871,
    "ttft": 1356931.3425046273,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4682644420489666,
    "arrivals": 157020,
    "finished_requests": 92013,
    "scheduler_time": 46.001216691654214
}
#Debug simulation 
Total elapsed time: 6.492773557081819. Arrivals time: 0.2776210093870759 Scheduler time: 6.066166241653264 Scheduler overhead time: 0.054470885545015335 Adapter cache time: 0.011632473673671484 Engine time: 0.05650045396760106 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-32/adapters_64_slots_64_rate_1.6-0.4-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-32/adapters_64_slots_64_rate_1.6-0.4-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [21 21 22]
Adapter prompts. [33, 4320, 17280, 17280, 33, 17280, 33, 4320, 33, 17280, 4320, 17280, 33, 4320, 17280, 17280, 17280, 33, 17280, 4320, 4320, 33, 33, 33, 17280, 33, 33, 33, 17280, 4320, 33, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 33, 4320, 4320, 17280, 17280, 4320, 17280, 33, 17280, 4320, 4320, 4320, 17280, 4320, 33, 33, 4320, 4320, 33, 4320, 33, 33, 33, 17280, 4320]
Prompts retrieved: 471573 . Total input tokens: 105185848 . Total output tokens: 92612733
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 6.2541943630203605,
    "estimated_duration": 3600.0763084869695,
    "input_throughput": 6001.438622027531,
    "output_throughput": 5289.504546086464,
    "total_throughput": 11290.943168113996,
    "itl": 83.18909078720517,
    "ttft": 1422086.0925648585,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4809837616281585,
    "arrivals": 157020,
    "finished_requests": 87590,
    "scheduler_time": 36.6921088063917
}
#Debug simulation 
Total elapsed time: 6.254288796335459. Arrivals time: 0.27000963874161243 Scheduler time: 5.817679125349969 Scheduler overhead time: 0.06045670621097088 Adapter cache time: 0.013682018965482712 Engine time: 0.06314394529908895 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_8-16-16/adapters_64_slots_64_rate_1.6-0.4-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_8-16-16/adapters_64_slots_64_rate_1.6-0.4-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [21 21 22]
Adapter prompts. [33, 4320, 17280, 17280, 33, 17280, 33, 4320, 33, 17280, 4320, 17280, 33, 4320, 17280, 17280, 17280, 33, 17280, 4320, 4320, 33, 33, 33, 17280, 33, 33, 33, 17280, 4320, 33, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 33, 4320, 4320, 17280, 17280, 4320, 17280, 33, 17280, 4320, 4320, 4320, 17280, 4320, 33, 33, 4320, 4320, 33, 4320, 33, 33, 33, 17280, 4320]
Prompts retrieved: 471573 . Total input tokens: 105185848 . Total output tokens: 92612733
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 6.585900868289173,
    "estimated_duration": 3600.0649791385636,
    "input_throughput": 6305.806459480087,
    "output_throughput": 5559.9165892804285,
    "total_throughput": 11865.723048760516,
    "itl": 94.26932095191995,
    "ttft": 1356973.5778701412,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.439111801609397,
    "arrivals": 157020,
    "finished_requests": 92018,
    "scheduler_time": 45.9999644249208
}
#Debug simulation 
Total elapsed time: 6.5860184440389276. Arrivals time: 0.26524909399449825 Scheduler time: 6.170215544756502 Scheduler overhead time: 0.054773091338574886 Adapter cache time: 0.011718704365193844 Engine time: 0.057508344762027264 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_8-16-32/adapters_64_slots_64_rate_1.6-0.4-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_8-16-32/adapters_64_slots_64_rate_1.6-0.4-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [21 21 22]
Adapter prompts. [33, 4320, 17280, 17280, 33, 17280, 33, 4320, 33, 17280, 4320, 17280, 33, 4320, 17280, 17280, 17280, 33, 17280, 4320, 4320, 33, 33, 33, 17280, 33, 33, 33, 17280, 4320, 33, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 33, 4320, 4320, 17280, 17280, 4320, 17280, 33, 17280, 4320, 4320, 4320, 17280, 4320, 33, 33, 4320, 4320, 33, 4320, 33, 33, 33, 17280, 4320]
Prompts retrieved: 471573 . Total input tokens: 105185848 . Total output tokens: 92612733
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 6.533785971812904,
    "estimated_duration": 3600.046837716536,
    "input_throughput": 6001.501917598443,
    "output_throughput": 5289.615624023005,
    "total_throughput": 11291.117541621446,
    "itl": 83.18825921532654,
    "ttft": 1422033.0244037758,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.47663430091924974,
    "arrivals": 157020,
    "finished_requests": 87591,
    "scheduler_time": 36.692753177842526
}
#Debug simulation 
Total elapsed time: 6.533850621897727. Arrivals time: 0.27710919780656695 Scheduler time: 6.089634372852743 Scheduler overhead time: 0.060751309152692556 Adapter cache time: 0.013619349338114262 Engine time: 0.06322324462234974 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_16-16-16/adapters_64_slots_64_rate_1.6-0.4-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_16-16-16/adapters_64_slots_64_rate_1.6-0.4-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [21 21 22]
Adapter prompts. [33, 4320, 17280, 17280, 33, 17280, 33, 4320, 33, 17280, 4320, 17280, 33, 4320, 17280, 17280, 17280, 33, 17280, 4320, 4320, 33, 33, 33, 17280, 33, 33, 33, 17280, 4320, 33, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 33, 4320, 4320, 17280, 17280, 4320, 17280, 33, 17280, 4320, 4320, 4320, 17280, 4320, 33, 33, 4320, 4320, 33, 4320, 33, 33, 33, 17280, 4320]
Prompts retrieved: 471573 . Total input tokens: 105185848 . Total output tokens: 92612733
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 6.5233379933051765,
    "estimated_duration": 3600.0064882611423,
    "input_throughput": 6305.808357296852,
    "output_throughput": 5559.763590778315,
    "total_throughput": 11865.571948075167,
    "itl": 94.2693870952635,
    "ttft": 1356887.072926886,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4085709401965145,
    "arrivals": 157020,
    "finished_requests": 92014,
    "scheduler_time": 45.99937647665417
}
#Debug simulation 
Total elapsed time: 6.523461114149541. Arrivals time: 0.27366249868646264 Scheduler time: 6.100643862038851 Scheduler overhead time: 0.05475775012746453 Adapter cache time: 0.011724628042429686 Engine time: 0.05654062703251839 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_16-16-32/adapters_64_slots_64_rate_1.6-0.4-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_16-16-32/adapters_64_slots_64_rate_1.6-0.4-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [21 21 22]
Adapter prompts. [33, 4320, 17280, 17280, 33, 17280, 33, 4320, 33, 17280, 4320, 17280, 33, 4320, 17280, 17280, 17280, 33, 17280, 4320, 4320, 33, 33, 33, 17280, 33, 33, 33, 17280, 4320, 33, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 17280, 33, 4320, 4320, 17280, 17280, 4320, 17280, 33, 17280, 4320, 4320, 4320, 17280, 4320, 33, 33, 4320, 4320, 33, 4320, 33, 33, 33, 17280, 4320]
Prompts retrieved: 471573 . Total input tokens: 105185848 . Total output tokens: 92612733
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 6.311760332901031,
    "estimated_duration": 3600.0250369771784,
    "input_throughput": 6001.52492776593,
    "output_throughput": 5289.726544788116,
    "total_throughput": 11291.251472554046,
    "itl": 83.1880878958449,
    "ttft": 1421961.600386032,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4720777230337263,
    "arrivals": 157020,
    "finished_requests": 87592,
    "scheduler_time": 36.692673540495726
}
#Debug simulation 
Total elapsed time: 6.311883867718279. Arrivals time: 0.27251768112182617 Scheduler time: 5.871658007614315 Scheduler overhead time: 0.060927812941372395 Adapter cache time: 0.013627505861222744 Engine time: 0.06373036932200193 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_8-8-8/adapters_64_slots_64_rate_1.6-0.1-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_8-8-8/adapters_64_slots_64_rate_1.6-0.1-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [21 21 22]
Adapter prompts. [540, 1080, 17280, 17280, 540, 17280, 540, 1080, 540, 17280, 1080, 17280, 540, 1080, 17280, 17280, 17280, 540, 17280, 1080, 1080, 540, 540, 540, 17280, 540, 540, 540, 17280, 1080, 540, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 540, 1080, 1080, 17280, 17280, 1080, 17280, 540, 17280, 1080, 1080, 1080, 17280, 1080, 540, 540, 1080, 1080, 540, 1080, 540, 540, 540, 17280, 1080]
Prompts retrieved: 414180 . Total input tokens: 92398094 . Total output tokens: 81346516
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 6.450490559916943,
    "estimated_duration": 3600.0491499406985,
    "input_throughput": 6277.769846662311,
    "output_throughput": 5445.373711168059,
    "total_throughput": 11723.14355783037,
    "itl": 105.64501971483696,
    "ttft": 1261450.7482006578,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.42319417804479564,
    "arrivals": 137849,
    "finished_requests": 91114,
    "scheduler_time": 50.67715553189894
}
#Debug simulation 
Total elapsed time: 6.45059655373916. Arrivals time: 0.2616094476543367 Scheduler time: 6.03644380485639 Scheduler overhead time: 0.04987526498734951 Adapter cache time: 0.026231487281620502 Engine time: 0.05240605538710952 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_8-8-16/adapters_64_slots_64_rate_1.6-0.1-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_8-8-16/adapters_64_slots_64_rate_1.6-0.1-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [21 21 22]
Adapter prompts. [540, 1080, 17280, 17280, 540, 17280, 540, 1080, 540, 17280, 1080, 17280, 540, 1080, 17280, 17280, 17280, 540, 17280, 1080, 1080, 540, 540, 540, 17280, 540, 540, 540, 17280, 1080, 540, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 540, 1080, 1080, 17280, 17280, 1080, 17280, 540, 17280, 1080, 1080, 1080, 17280, 1080, 540, 540, 1080, 1080, 540, 1080, 540, 540, 540, 17280, 1080]
Prompts retrieved: 414180 . Total input tokens: 92398094 . Total output tokens: 81346516
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 6.360594755969942,
    "estimated_duration": 3600.0354352161216,
    "input_throughput": 6172.769796268944,
    "output_throughput": 5357.817817935467,
    "total_throughput": 11530.58761420441,
    "itl": 97.65988886397024,
    "ttft": 1286061.3240812987,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4682644420489667,
    "arrivals": 137849,
    "finished_requests": 89623,
    "scheduler_time": 46.61262427876295
}
#Debug simulation 
Total elapsed time: 6.360693573020399. Arrivals time: 0.2559787849895656 Scheduler time: 5.941307728178799 Scheduler overhead time: 0.053163979202508926 Adapter cache time: 0.029086980037391186 Engine time: 0.05554213235154748 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_8-8-32/adapters_64_slots_64_rate_1.6-0.1-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_8-8-32/adapters_64_slots_64_rate_1.6-0.1-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [21 21 22]
Adapter prompts. [540, 1080, 17280, 17280, 540, 17280, 540, 1080, 540, 17280, 1080, 17280, 540, 1080, 17280, 17280, 17280, 540, 17280, 1080, 1080, 540, 540, 540, 17280, 540, 540, 540, 17280, 1080, 540, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 540, 1080, 1080, 17280, 17280, 1080, 17280, 540, 17280, 1080, 1080, 1080, 17280, 1080, 540, 540, 1080, 1080, 540, 1080, 540, 540, 540, 17280, 1080]
Prompts retrieved: 414180 . Total input tokens: 92398094 . Total output tokens: 81346516
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 6.1881330269388855,
    "estimated_duration": 3600.029824886657,
    "input_throughput": 5955.083997304097,
    "output_throughput": 5171.444100629402,
    "total_throughput": 11126.528097933498,
    "itl": 84.9620099105641,
    "ttft": 1336269.2986586762,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4809837616281585,
    "arrivals": 137849,
    "finished_requests": 86441,
    "scheduler_time": 38.316620210768875
}
#Debug simulation 
Total elapsed time: 6.188226264901459. Arrivals time: 0.24956580810248852 Scheduler time: 5.755037667229772 Scheduler overhead time: 0.05955321900546551 Adapter cache time: 0.03287805523723364 Engine time: 0.06235589133575559 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_8-16-16/adapters_64_slots_64_rate_1.6-0.1-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_8-16-16/adapters_64_slots_64_rate_1.6-0.1-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [21 21 22]
Adapter prompts. [540, 1080, 17280, 17280, 540, 17280, 540, 1080, 540, 17280, 1080, 17280, 540, 1080, 17280, 17280, 17280, 540, 17280, 1080, 1080, 540, 540, 540, 17280, 540, 540, 540, 17280, 1080, 540, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 540, 1080, 1080, 17280, 17280, 1080, 17280, 540, 17280, 1080, 1080, 1080, 17280, 1080, 540, 540, 1080, 1080, 540, 1080, 540, 540, 540, 17280, 1080]
Prompts retrieved: 414180 . Total input tokens: 92398094 . Total output tokens: 81346516
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 6.389117131009698,
    "estimated_duration": 3600.0020010433204,
    "input_throughput": 6172.808513317433,
    "output_throughput": 5357.7117441629725,
    "total_throughput": 11530.520257480404,
    "itl": 97.6611597745267,
    "ttft": 1286221.1038870593,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.43911180160939706,
    "arrivals": 137849,
    "finished_requests": 89621,
    "scheduler_time": 46.61205450819794
}
#Debug simulation 
Total elapsed time: 6.389213904272765. Arrivals time: 0.25723057705909014 Scheduler time: 5.967604312580079 Scheduler overhead time: 0.05336100747808814 Adapter cache time: 0.02918083081021905 Engine time: 0.05609211837872863 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_8-16-32/adapters_64_slots_64_rate_1.6-0.1-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_8-16-32/adapters_64_slots_64_rate_1.6-0.1-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [21 21 22]
Adapter prompts. [540, 1080, 17280, 17280, 540, 17280, 540, 1080, 540, 17280, 1080, 17280, 540, 1080, 17280, 17280, 17280, 540, 17280, 1080, 1080, 540, 540, 540, 17280, 540, 540, 540, 17280, 1080, 540, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 540, 1080, 1080, 17280, 17280, 1080, 17280, 540, 17280, 1080, 1080, 1080, 17280, 1080, 540, 540, 1080, 1080, 540, 1080, 540, 540, 540, 17280, 1080]
Prompts retrieved: 414180 . Total input tokens: 92398094 . Total output tokens: 81346516
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 6.181672046426684,
    "estimated_duration": 3600.0755776010324,
    "input_throughput": 5955.164423044209,
    "output_throughput": 5171.476986715431,
    "total_throughput": 11126.641409759639,
    "itl": 84.95976390460035,
    "ttft": 1336234.8575089618,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.47663430091924974,
    "arrivals": 137849,
    "finished_requests": 86445,
    "scheduler_time": 38.31922151146107
}
#Debug simulation 
Total elapsed time: 6.181789654307067. Arrivals time: 0.251257780008018 Scheduler time: 5.746069923043251 Scheduler overhead time: 0.05970684438943863 Adapter cache time: 0.03335592756047845 Engine time: 0.062491183169186115 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_16-16-16/adapters_64_slots_64_rate_1.6-0.1-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_16-16-16/adapters_64_slots_64_rate_1.6-0.1-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [21 21 22]
Adapter prompts. [540, 1080, 17280, 17280, 540, 17280, 540, 1080, 540, 17280, 1080, 17280, 540, 1080, 17280, 17280, 17280, 540, 17280, 1080, 1080, 540, 540, 540, 17280, 540, 540, 540, 17280, 1080, 540, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 540, 1080, 1080, 17280, 17280, 1080, 17280, 540, 17280, 1080, 1080, 1080, 17280, 1080, 540, 540, 1080, 1080, 540, 1080, 540, 540, 540, 17280, 1080]
Prompts retrieved: 414180 . Total input tokens: 92398094 . Total output tokens: 81346516
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 6.373894864693284,
    "estimated_duration": 3600.104323708916,
    "input_throughput": 6172.651679467486,
    "output_throughput": 5357.71529535252,
    "total_throughput": 11530.366974820006,
    "itl": 97.65774716066028,
    "ttft": 1286103.3867678011,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4085709401965145,
    "arrivals": 137849,
    "finished_requests": 89623,
    "scheduler_time": 46.61225768706215
}
#Debug simulation 
Total elapsed time: 6.374014898668975. Arrivals time: 0.2548639322631061 Scheduler time: 5.954870987217873 Scheduler overhead time: 0.05354649340733886 Adapter cache time: 0.0292687825858593 Engine time: 0.05554302083328366 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_16-16-32/adapters_64_slots_64_rate_1.6-0.1-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_16-16-32/adapters_64_slots_64_rate_1.6-0.1-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [21 21 22]
Adapter prompts. [540, 1080, 17280, 17280, 540, 17280, 540, 1080, 540, 17280, 1080, 17280, 540, 1080, 17280, 17280, 17280, 540, 17280, 1080, 1080, 540, 540, 540, 17280, 540, 540, 540, 17280, 1080, 540, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 540, 1080, 1080, 17280, 17280, 1080, 17280, 540, 17280, 1080, 1080, 1080, 17280, 1080, 540, 540, 1080, 1080, 540, 1080, 540, 540, 540, 17280, 1080]
Prompts retrieved: 414180 . Total input tokens: 92398094 . Total output tokens: 81346516
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 6.196180964820087,
    "estimated_duration": 3600.081446626561,
    "input_throughput": 5955.4055423079935,
    "output_throughput": 5171.716050326158,
    "total_throughput": 11127.121592634152,
    "itl": 84.95819648913013,
    "ttft": 1336208.2151882425,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4720777230337263,
    "arrivals": 137849,
    "finished_requests": 86448,
    "scheduler_time": 38.31837255480696
}
#Debug simulation 
Total elapsed time: 6.1962742689065635. Arrivals time: 0.24966686638072133 Scheduler time: 5.761616320349276 Scheduler overhead time: 0.0599221782758832 Adapter cache time: 0.03351293224841356 Engine time: 0.06257907999679446 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_8-8-8/adapters_64_slots_64_rate_1.6-0.1-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_8-8-8/adapters_64_slots_64_rate_1.6-0.1-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [21 21 22]
Adapter prompts. [270, 1080, 17280, 17280, 270, 17280, 270, 1080, 270, 17280, 1080, 17280, 270, 1080, 17280, 17280, 17280, 270, 17280, 1080, 1080, 270, 270, 270, 17280, 270, 270, 270, 17280, 1080, 270, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 270, 1080, 1080, 17280, 17280, 1080, 17280, 270, 17280, 1080, 1080, 1080, 17280, 1080, 270, 270, 1080, 1080, 270, 1080, 270, 270, 270, 17280, 1080]
Prompts retrieved: 408510 . Total input tokens: 91140276 . Total output tokens: 80211485
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 6.531364695169032,
    "estimated_duration": 3600.1115441889865,
    "input_throughput": 6438.5246722186575,
    "output_throughput": 5585.346663065628,
    "total_throughput": 12023.871335284286,
    "itl": 102.70307061661728,
    "ttft": 1211348.7328129548,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.42319417804479564,
    "arrivals": 135943,
    "finished_requests": 93470,
    "scheduler_time": 52.86905045365235
}
#Debug simulation 
Total elapsed time: 6.531551603227854. Arrivals time: 0.256504331715405 Scheduler time: 6.1222987794317305 Scheduler overhead time: 0.0509903053753078 Adapter cache time: 0.02396155148744583 Engine time: 0.053212793078273535 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_8-8-16/adapters_64_slots_64_rate_1.6-0.1-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_8-8-16/adapters_64_slots_64_rate_1.6-0.1-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [21 21 22]
Adapter prompts. [270, 1080, 17280, 17280, 270, 17280, 270, 1080, 270, 17280, 1080, 17280, 270, 1080, 17280, 17280, 17280, 270, 17280, 1080, 1080, 270, 270, 270, 17280, 270, 270, 270, 17280, 1080, 270, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 270, 1080, 1080, 17280, 17280, 1080, 17280, 270, 17280, 1080, 1080, 1080, 17280, 1080, 270, 270, 1080, 1080, 270, 1080, 270, 270, 270, 17280, 1080]
Prompts retrieved: 408510 . Total input tokens: 91140276 . Total output tokens: 80211485
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 6.438850237056613,
    "estimated_duration": 3600.0373230544196,
    "input_throughput": 6331.163528233083,
    "output_throughput": 5490.265857363507,
    "total_throughput": 11821.42938559659,
    "itl": 95.01234197997321,
    "ttft": 1237779.2672987967,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4682644420489667,
    "arrivals": 135943,
    "finished_requests": 91856,
    "scheduler_time": 48.63713545212122
}
#Debug simulation 
Total elapsed time: 6.4389417371712625. Arrivals time: 0.25405311957001686 Scheduler time: 6.022039226721972 Scheduler overhead time: 0.05422408552840352 Adapter cache time: 0.025540377013385296 Engine time: 0.0569517407566309 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_8-8-32/adapters_64_slots_64_rate_1.6-0.1-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_8-8-32/adapters_64_slots_64_rate_1.6-0.1-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [21 21 22]
Adapter prompts. [270, 1080, 17280, 17280, 270, 17280, 270, 1080, 270, 17280, 1080, 17280, 270, 1080, 17280, 17280, 17280, 270, 17280, 1080, 1080, 270, 270, 270, 17280, 270, 270, 270, 17280, 1080, 270, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 270, 1080, 1080, 17280, 17280, 1080, 17280, 270, 17280, 1080, 1080, 1080, 17280, 1080, 270, 270, 1080, 1080, 270, 1080, 270, 270, 270, 17280, 1080]
Prompts retrieved: 408510 . Total input tokens: 91140276 . Total output tokens: 80211485
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 6.302262225188315,
    "estimated_duration": 3600.089037077131,
    "input_throughput": 6100.073574244074,
    "output_throughput": 5291.2288567911555,
    "total_throughput": 11391.30243103523,
    "itl": 82.7267148320047,
    "ttft": 1292706.4196980535,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4809837616281584,
    "arrivals": 135943,
    "finished_requests": 88460,
    "scheduler_time": 39.979107867887535
}
#Debug simulation 
Total elapsed time: 6.302356088068336. Arrivals time: 0.2530023823492229 Scheduler time: 5.865132707171142 Scheduler overhead time: 0.06126558221876621 Adapter cache time: 0.02912455750629306 Engine time: 0.06432934105396271 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_8-16-16/adapters_64_slots_64_rate_1.6-0.1-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_8-16-16/adapters_64_slots_64_rate_1.6-0.1-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [21 21 22]
Adapter prompts. [270, 1080, 17280, 17280, 270, 17280, 270, 1080, 270, 17280, 1080, 17280, 270, 1080, 17280, 17280, 17280, 270, 17280, 1080, 1080, 270, 270, 270, 17280, 270, 270, 270, 17280, 1080, 270, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 270, 1080, 1080, 17280, 17280, 1080, 17280, 270, 17280, 1080, 1080, 1080, 17280, 1080, 270, 270, 1080, 1080, 270, 1080, 270, 270, 270, 17280, 1080]
Prompts retrieved: 408510 . Total input tokens: 91140276 . Total output tokens: 80211485
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 6.475389823783189,
    "estimated_duration": 3600.084633747235,
    "input_throughput": 6331.055883060184,
    "output_throughput": 5490.12787497365,
    "total_throughput": 11821.183758033834,
    "itl": 95.0098434980467,
    "ttft": 1237809.991040445,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.43911180160939706,
    "arrivals": 135943,
    "finished_requests": 91855,
    "scheduler_time": 48.63689228615078
}
#Debug simulation 
Total elapsed time: 6.475485323928297. Arrivals time: 0.2567264367826283 Scheduler time: 6.055075390264392 Scheduler overhead time: 0.054319684859365225 Adapter cache time: 0.025899576488882303 Engine time: 0.057303506415337324 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_8-16-32/adapters_64_slots_64_rate_1.6-0.1-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_8-16-32/adapters_64_slots_64_rate_1.6-0.1-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [21 21 22]
Adapter prompts. [270, 1080, 17280, 17280, 270, 17280, 270, 1080, 270, 17280, 1080, 17280, 270, 1080, 17280, 17280, 17280, 270, 17280, 1080, 1080, 270, 270, 270, 17280, 270, 270, 270, 17280, 1080, 270, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 270, 1080, 1080, 17280, 17280, 1080, 17280, 270, 17280, 1080, 1080, 1080, 17280, 1080, 270, 270, 1080, 1080, 270, 1080, 270, 270, 270, 17280, 1080]
Prompts retrieved: 408510 . Total input tokens: 91140276 . Total output tokens: 80211485
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 6.299093707930297,
    "estimated_duration": 3600.0424526358115,
    "input_throughput": 6099.980844370766,
    "output_throughput": 5291.108716246842,
    "total_throughput": 11391.089560617607,
    "itl": 82.72809658571097,
    "ttft": 1292692.6362152272,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4766343009192497,
    "arrivals": 135943,
    "finished_requests": 88456,
    "scheduler_time": 39.98083446002791
}
#Debug simulation 
Total elapsed time: 6.2991974162869155. Arrivals time: 0.2646206319332123 Scheduler time: 5.8509727087803185 Scheduler overhead time: 0.06122748227789998 Adapter cache time: 0.02895253011956811 Engine time: 0.06392507068812847 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_16-16-16/adapters_64_slots_64_rate_1.6-0.1-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_16-16-16/adapters_64_slots_64_rate_1.6-0.1-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [21 21 22]
Adapter prompts. [270, 1080, 17280, 17280, 270, 17280, 270, 1080, 270, 17280, 1080, 17280, 270, 1080, 17280, 17280, 17280, 270, 17280, 1080, 1080, 270, 270, 270, 17280, 270, 270, 270, 17280, 1080, 270, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 270, 1080, 1080, 17280, 17280, 1080, 17280, 270, 17280, 1080, 1080, 1080, 17280, 1080, 270, 270, 1080, 1080, 270, 1080, 270, 270, 270, 17280, 1080]
Prompts retrieved: 408510 . Total input tokens: 91140276 . Total output tokens: 80211485
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 6.501193586271256,
    "estimated_duration": 3600.1023074256273,
    "input_throughput": 6331.197853179585,
    "output_throughput": 5490.167309754521,
    "total_throughput": 11821.365162934106,
    "itl": 95.0086272626887,
    "ttft": 1237720.0158587606,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4085709401965145,
    "arrivals": 135943,
    "finished_requests": 91857,
    "scheduler_time": 48.637968787449836
}
#Debug simulation 
Total elapsed time: 6.501325035002083. Arrivals time: 0.2559923534281552 Scheduler time: 6.081119475886226 Scheduler overhead time: 0.054673122707754374 Adapter cache time: 0.02614495623856783 Engine time: 0.05708163511008024 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_16-16-32/adapters_64_slots_64_rate_1.6-0.1-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_16-16-32/adapters_64_slots_64_rate_1.6-0.1-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [21 21 22]
Adapter prompts. [270, 1080, 17280, 17280, 270, 17280, 270, 1080, 270, 17280, 1080, 17280, 270, 1080, 17280, 17280, 17280, 270, 17280, 1080, 1080, 270, 270, 270, 17280, 270, 270, 270, 17280, 1080, 270, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 270, 1080, 1080, 17280, 17280, 1080, 17280, 270, 17280, 1080, 1080, 1080, 17280, 1080, 270, 270, 1080, 1080, 270, 1080, 270, 270, 270, 17280, 1080]
Prompts retrieved: 408510 . Total input tokens: 91140276 . Total output tokens: 80211485
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 6.299002008046955,
    "estimated_duration": 3600.0448868347057,
    "input_throughput": 6100.062274309166,
    "output_throughput": 5291.281525311331,
    "total_throughput": 11391.343799620498,
    "itl": 82.7258999238061,
    "ttft": 1292758.283341436,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.47207772303372625,
    "arrivals": 135943,
    "finished_requests": 88458,
    "scheduler_time": 39.98049214688571
}
#Debug simulation 
Total elapsed time: 6.299093815032393. Arrivals time: 0.256520573515445 Scheduler time: 5.8578946348279715 Scheduler overhead time: 0.06121007399633527 Adapter cache time: 0.030000865925103426 Engine time: 0.06386553216725588 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-8/adapters_64_slots_64_rate_1.6-0.1-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-8/adapters_64_slots_64_rate_1.6-0.1-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [21 21 22]
Adapter prompts. [135, 1080, 17280, 17280, 135, 17280, 135, 1080, 135, 17280, 1080, 17280, 135, 1080, 17280, 17280, 17280, 135, 17280, 1080, 1080, 135, 135, 135, 17280, 135, 135, 135, 17280, 1080, 135, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 135, 1080, 1080, 17280, 17280, 1080, 17280, 135, 17280, 1080, 1080, 1080, 17280, 1080, 135, 135, 1080, 1080, 135, 1080, 135, 135, 135, 17280, 1080]
Prompts retrieved: 405675 . Total input tokens: 90522113 . Total output tokens: 79647408
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 6.662101417314261,
    "estimated_duration": 3600.0102865844524,
    "input_throughput": 6478.361766606827,
    "output_throughput": 5688.179302239785,
    "total_throughput": 12166.54106884661,
    "itl": 101.55582355426607,
    "ttft": 1186920.7712644944,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.42319417804479564,
    "arrivals": 135044,
    "finished_requests": 94697,
    "scheduler_time": 54.50804310042586
}
#Debug simulation 
Total elapsed time: 6.662192803341895. Arrivals time: 0.2613102123141289 Scheduler time: 6.249064969830215 Scheduler overhead time: 0.05150750558823347 Adapter cache time: 0.021706026513129473 Engine time: 0.053899502381682396 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-16/adapters_64_slots_64_rate_1.6-0.1-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-16/adapters_64_slots_64_rate_1.6-0.1-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [21 21 22]
Adapter prompts. [135, 1080, 17280, 17280, 135, 17280, 135, 1080, 135, 17280, 1080, 17280, 135, 1080, 17280, 17280, 17280, 135, 17280, 1080, 1080, 135, 135, 135, 17280, 135, 135, 135, 17280, 1080, 135, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 135, 1080, 1080, 17280, 17280, 1080, 17280, 135, 17280, 1080, 1080, 1080, 17280, 1080, 135, 135, 1080, 1080, 135, 1080, 135, 135, 135, 17280, 1080]
Prompts retrieved: 405675 . Total input tokens: 90522113 . Total output tokens: 79647408
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 6.510775075759739,
    "estimated_duration": 3600.006283804323,
    "input_throughput": 6350.611415000149,
    "output_throughput": 5582.780810804946,
    "total_throughput": 11933.392225805095,
    "itl": 94.09486354865784,
    "ttft": 1215653.5495545797,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.46826444204896667,
    "arrivals": 135044,
    "finished_requests": 92878,
    "scheduler_time": 50.08403138109815
}
#Debug simulation 
Total elapsed time: 6.510904582682997. Arrivals time: 0.26077054534107447 Scheduler time: 6.088050407823175 Scheduler overhead time: 0.0547901657409966 Adapter cache time: 0.02349265245720744 Engine time: 0.0573083208873868 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-32/adapters_64_slots_64_rate_1.6-0.1-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-32/adapters_64_slots_64_rate_1.6-0.1-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [21 21 22]
Adapter prompts. [135, 1080, 17280, 17280, 135, 17280, 135, 1080, 135, 17280, 1080, 17280, 135, 1080, 17280, 17280, 17280, 135, 17280, 1080, 1080, 135, 135, 135, 17280, 135, 135, 135, 17280, 1080, 135, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 135, 1080, 1080, 17280, 17280, 1080, 17280, 135, 17280, 1080, 1080, 1080, 17280, 1080, 135, 135, 1080, 1080, 135, 1080, 135, 135, 135, 17280, 1080]
Prompts retrieved: 405675 . Total input tokens: 90522113 . Total output tokens: 79647408
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 6.382110225968063,
    "estimated_duration": 3600.0534157680704,
    "input_throughput": 6110.121006442621,
    "output_throughput": 5371.088083112408,
    "total_throughput": 11481.209089555028,
    "itl": 82.12587274456968,
    "ttft": 1273182.9618760743,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4809837616281584,
    "arrivals": 135044,
    "finished_requests": 89344,
    "scheduler_time": 41.24043542763431
}
#Debug simulation 
Total elapsed time: 6.382241141982377. Arrivals time: 0.2582230232656002 Scheduler time: 5.940648217685521 Scheduler overhead time: 0.06163230957463384 Adapter cache time: 0.027244781143963337 Engine time: 0.06473612738773227 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-16-16/adapters_64_slots_64_rate_1.6-0.1-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-16-16/adapters_64_slots_64_rate_1.6-0.1-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [21 21 22]
Adapter prompts. [135, 1080, 17280, 17280, 135, 17280, 135, 1080, 135, 17280, 1080, 17280, 135, 1080, 17280, 17280, 17280, 135, 17280, 1080, 1080, 135, 135, 135, 17280, 135, 135, 135, 17280, 1080, 135, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 135, 1080, 1080, 17280, 17280, 1080, 17280, 135, 17280, 1080, 1080, 1080, 17280, 1080, 135, 135, 1080, 1080, 135, 1080, 135, 135, 135, 17280, 1080]
Prompts retrieved: 405675 . Total input tokens: 90522113 . Total output tokens: 79647408
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 6.550575754605234,
    "estimated_duration": 3600.0352374147565,
    "input_throughput": 6350.658949776836,
    "output_throughput": 5582.6036898551,
    "total_throughput": 11933.262639631936,
    "itl": 94.09361692114496,
    "ttft": 1215696.0206163244,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.43911180160939695,
    "arrivals": 135044,
    "finished_requests": 92879,
    "scheduler_time": 50.0871341884822
}
#Debug simulation 
Total elapsed time: 6.550667660776526. Arrivals time: 0.26138740312308073 Scheduler time: 6.1244983952492476 Scheduler overhead time: 0.05501757329329848 Adapter cache time: 0.023559050634503365 Engine time: 0.05960516119375825 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-16-32/adapters_64_slots_64_rate_1.6-0.1-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-16-32/adapters_64_slots_64_rate_1.6-0.1-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [21 21 22]
Adapter prompts. [135, 1080, 17280, 17280, 135, 17280, 135, 1080, 135, 17280, 1080, 17280, 135, 1080, 17280, 17280, 17280, 135, 17280, 1080, 1080, 135, 135, 135, 17280, 135, 135, 135, 17280, 1080, 135, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 135, 1080, 1080, 17280, 17280, 1080, 17280, 135, 17280, 1080, 1080, 1080, 17280, 1080, 135, 135, 1080, 1080, 135, 1080, 135, 135, 135, 17280, 1080]
Prompts retrieved: 405675 . Total input tokens: 90522113 . Total output tokens: 79647408
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 6.395893756765872,
    "estimated_duration": 3600.0592946361467,
    "input_throughput": 6110.063529446164,
    "output_throughput": 5371.050979301794,
    "total_throughput": 11481.114508747956,
    "itl": 82.12405127808506,
    "ttft": 1273294.5561674132,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4766343009192497,
    "arrivals": 135044,
    "finished_requests": 89343,
    "scheduler_time": 41.23817184149314
}
#Debug simulation 
Total elapsed time: 6.396013038698584. Arrivals time: 0.25751186860725284 Scheduler time: 5.954897385556251 Scheduler overhead time: 0.06186812091618776 Adapter cache time: 0.02723380457609892 Engine time: 0.06455594347789884 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_16-16-16/adapters_64_slots_64_rate_1.6-0.1-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_16-16-16/adapters_64_slots_64_rate_1.6-0.1-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [21 21 22]
Adapter prompts. [135, 1080, 17280, 17280, 135, 17280, 135, 1080, 135, 17280, 1080, 17280, 135, 1080, 17280, 17280, 17280, 135, 17280, 1080, 1080, 135, 135, 135, 17280, 135, 135, 135, 17280, 1080, 135, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 135, 1080, 1080, 17280, 17280, 1080, 17280, 135, 17280, 1080, 1080, 1080, 17280, 1080, 135, 135, 1080, 1080, 135, 1080, 135, 135, 135, 17280, 1080]
Prompts retrieved: 405675 . Total input tokens: 90522113 . Total output tokens: 79647408
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 6.634176212362945,
    "estimated_duration": 3600.081664749031,
    "input_throughput": 6350.671770551022,
    "output_throughput": 5582.66447030753,
    "total_throughput": 11933.336240858553,
    "itl": 94.09487257188324,
    "ttft": 1215628.9173954653,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4085709401965145,
    "arrivals": 135044,
    "finished_requests": 92879,
    "scheduler_time": 50.08830964697713
}
#Debug simulation 
Total elapsed time: 6.634293721057475. Arrivals time: 0.2662235270254314 Scheduler time: 6.2040084935724735 Scheduler overhead time: 0.05547690624371171 Adapter cache time: 0.02359220338985324 Engine time: 0.05833894666284323 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_16-16-32/adapters_64_slots_64_rate_1.6-0.1-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_16-16-32/adapters_64_slots_64_rate_1.6-0.1-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [21 21 22]
Adapter prompts. [135, 1080, 17280, 17280, 135, 17280, 135, 1080, 135, 17280, 1080, 17280, 135, 1080, 17280, 17280, 17280, 135, 17280, 1080, 1080, 135, 135, 135, 17280, 135, 135, 135, 17280, 1080, 135, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 135, 1080, 1080, 17280, 17280, 1080, 17280, 135, 17280, 1080, 1080, 1080, 17280, 1080, 135, 135, 1080, 1080, 135, 1080, 135, 135, 135, 17280, 1080]
Prompts retrieved: 405675 . Total input tokens: 90522113 . Total output tokens: 79647408
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 6.308341007679701,
    "estimated_duration": 3600.0207110167935,
    "input_throughput": 6110.052904053248,
    "output_throughput": 5370.895212027519,
    "total_throughput": 11480.948116080768,
    "itl": 82.12292097717244,
    "ttft": 1273182.8627565494,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.47207772303372625,
    "arrivals": 135044,
    "finished_requests": 89341,
    "scheduler_time": 41.236918878789034
}
#Debug simulation 
Total elapsed time: 6.3085229326970875. Arrivals time: 0.2572827567346394 Scheduler time: 5.867806538939476 Scheduler overhead time: 0.06108639808371663 Adapter cache time: 0.026683147065341473 Engine time: 0.06621722131967545 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-8/adapters_64_slots_64_rate_1.6-0.1-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-8/adapters_64_slots_64_rate_1.6-0.1-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [21 21 22]
Adapter prompts. [66, 1080, 17280, 17280, 66, 17280, 66, 1080, 66, 17280, 1080, 17280, 66, 1080, 17280, 17280, 17280, 66, 17280, 1080, 1080, 66, 66, 66, 17280, 66, 66, 66, 17280, 1080, 66, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 66, 1080, 1080, 17280, 17280, 1080, 17280, 66, 17280, 1080, 1080, 1080, 17280, 1080, 66, 66, 1080, 1080, 66, 1080, 66, 66, 66, 17280, 1080]
Prompts retrieved: 404226 . Total input tokens: 90195380 . Total output tokens: 79368359
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 6.695208910852671,
    "estimated_duration": 3600.011900677097,
    "input_throughput": 6563.148859467968,
    "output_throughput": 5776.1611832696935,
    "total_throughput": 12339.310042737661,
    "itl": 99.6623881460944,
    "ttft": 1176738.9349856407,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.42319417804479564,
    "arrivals": 134574,
    "finished_requests": 95685,
    "scheduler_time": 55.35274163007381
}
#Debug simulation 
Total elapsed time: 6.695327565073967. Arrivals time: 0.26868431735783815 Scheduler time: 6.274192520882934 Scheduler overhead time: 0.05251056654378772 Adapter cache time: 0.01997875701636076 Engine time: 0.054945345502346754 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-16/adapters_64_slots_64_rate_1.6-0.1-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-16/adapters_64_slots_64_rate_1.6-0.1-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [21 21 22]
Adapter prompts. [66, 1080, 17280, 17280, 66, 17280, 66, 1080, 66, 17280, 1080, 17280, 66, 1080, 17280, 17280, 17280, 66, 17280, 1080, 1080, 66, 66, 66, 17280, 66, 66, 66, 17280, 1080, 66, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 66, 1080, 1080, 17280, 17280, 1080, 17280, 66, 17280, 1080, 1080, 1080, 17280, 1080, 66, 66, 1080, 1080, 66, 1080, 66, 66, 66, 17280, 1080]
Prompts retrieved: 404226 . Total input tokens: 90195380 . Total output tokens: 79368359
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 6.661994511261582,
    "estimated_duration": 3600.022718660824,
    "input_throughput": 6431.588023036985,
    "output_throughput": 5664.895361434355,
    "total_throughput": 12096.48338447134,
    "itl": 92.4166519565436,
    "ttft": 1207498.0347023509,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.46826444204896667,
    "arrivals": 134574,
    "finished_requests": 93779,
    "scheduler_time": 50.76832127348418
}
#Debug simulation 
Total elapsed time: 6.662085921969265. Arrivals time: 0.2665136344730854 Scheduler time: 6.232692590449005 Scheduler overhead time: 0.055918311700224876 Adapter cache time: 0.021774896420538425 Engine time: 0.058291779831051826 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-32/adapters_64_slots_64_rate_1.6-0.1-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-32/adapters_64_slots_64_rate_1.6-0.1-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [21 21 22]
Adapter prompts. [66, 1080, 17280, 17280, 66, 17280, 66, 1080, 66, 17280, 1080, 17280, 66, 1080, 17280, 17280, 17280, 66, 17280, 1080, 1080, 66, 66, 66, 17280, 66, 66, 66, 17280, 1080, 66, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 66, 1080, 1080, 17280, 17280, 1080, 17280, 66, 17280, 1080, 1080, 1080, 17280, 1080, 66, 66, 1080, 1080, 66, 1080, 66, 66, 66, 17280, 1080]
Prompts retrieved: 404226 . Total input tokens: 90195380 . Total output tokens: 79368359
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 6.41084209503606,
    "estimated_duration": 3600.047478056486,
    "input_throughput": 6171.07861366139,
    "output_throughput": 5440.212697020632,
    "total_throughput": 11611.291310682022,
    "itl": 80.80334175145671,
    "ttft": 1268536.3321956706,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4809837616281584,
    "arrivals": 134574,
    "finished_requests": 89972,
    "scheduler_time": 41.58509651849542
}
#Debug simulation 
Total elapsed time: 6.410939445253462. Arrivals time: 0.2642969056032598 Scheduler time: 5.964272204786539 Scheduler overhead time: 0.062314657494425774 Adapter cache time: 0.024747338611632586 Engine time: 0.06532756052911282 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-16-16/adapters_64_slots_64_rate_1.6-0.1-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-16-16/adapters_64_slots_64_rate_1.6-0.1-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [21 21 22]
Adapter prompts. [66, 1080, 17280, 17280, 66, 17280, 66, 1080, 66, 17280, 1080, 17280, 66, 1080, 17280, 17280, 17280, 66, 17280, 1080, 1080, 66, 66, 66, 17280, 66, 66, 66, 17280, 1080, 66, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 66, 1080, 1080, 17280, 17280, 1080, 17280, 66, 17280, 1080, 1080, 1080, 17280, 1080, 66, 66, 1080, 1080, 66, 1080, 66, 66, 66, 17280, 1080]
Prompts retrieved: 404226 . Total input tokens: 90195380 . Total output tokens: 79368359
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 6.637888713274151,
    "estimated_duration": 3600.0035683426067,
    "input_throughput": 6431.700569302451,
    "output_throughput": 5665.2407734666585,
    "total_throughput": 12096.94134276911,
    "itl": 92.41025141923578,
    "ttft": 1207543.913051757,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4391118016093969,
    "arrivals": 134574,
    "finished_requests": 93782,
    "scheduler_time": 50.76877559948584
}
#Debug simulation 
Total elapsed time: 6.63798320107162. Arrivals time: 0.2700499058701098 Scheduler time: 6.204692070372403 Scheduler overhead time: 0.056172231677919626 Adapter cache time: 0.02175453817471862 Engine time: 0.058395407162606716 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-16-32/adapters_64_slots_64_rate_1.6-0.1-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-16-32/adapters_64_slots_64_rate_1.6-0.1-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [21 21 22]
Adapter prompts. [66, 1080, 17280, 17280, 66, 17280, 66, 1080, 66, 17280, 1080, 17280, 66, 1080, 17280, 17280, 17280, 66, 17280, 1080, 1080, 66, 66, 66, 17280, 66, 66, 66, 17280, 1080, 66, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 66, 1080, 1080, 17280, 17280, 1080, 17280, 66, 17280, 1080, 1080, 1080, 17280, 1080, 66, 66, 1080, 1080, 66, 1080, 66, 66, 66, 17280, 1080]
Prompts retrieved: 404226 . Total input tokens: 90195380 . Total output tokens: 79368359
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 6.420622861012816,
    "estimated_duration": 3600.0675492416967,
    "input_throughput": 6171.227816177967,
    "output_throughput": 5440.298753317948,
    "total_throughput": 11611.526569495914,
    "itl": 80.80380708611202,
    "ttft": 1268497.6433998176,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4766343009192497,
    "arrivals": 134574,
    "finished_requests": 89974,
    "scheduler_time": 41.58569543741449
}
#Debug simulation 
Total elapsed time: 6.420711839105934. Arrivals time: 0.26242833817377687 Scheduler time: 5.973759192507714 Scheduler overhead time: 0.06244399817660451 Adapter cache time: 0.025000324938446283 Engine time: 0.06721725594252348 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_16-16-16/adapters_64_slots_64_rate_1.6-0.1-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_16-16-16/adapters_64_slots_64_rate_1.6-0.1-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [21 21 22]
Adapter prompts. [66, 1080, 17280, 17280, 66, 17280, 66, 1080, 66, 17280, 1080, 17280, 66, 1080, 17280, 17280, 17280, 66, 17280, 1080, 1080, 66, 66, 66, 17280, 66, 66, 66, 17280, 1080, 66, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 66, 1080, 1080, 17280, 17280, 1080, 17280, 66, 17280, 1080, 1080, 1080, 17280, 1080, 66, 66, 1080, 1080, 66, 1080, 66, 66, 66, 17280, 1080]
Prompts retrieved: 404226 . Total input tokens: 90195380 . Total output tokens: 79368359
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 6.579559030011296,
    "estimated_duration": 3600.0224752073987,
    "input_throughput": 6431.7937344727425,
    "output_throughput": 5665.392130315799,
    "total_throughput": 12097.185864788542,
    "itl": 92.41255323317243,
    "ttft": 1207481.4100734417,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4085709401965145,
    "arrivals": 134574,
    "finished_requests": 93784,
    "scheduler_time": 50.77081405178696
}
#Debug simulation 
Total elapsed time: 6.579652355983853. Arrivals time: 0.26529429433867335 Scheduler time: 6.152410549111664 Scheduler overhead time: 0.0556869488209486 Adapter cache time: 0.021640736144036055 Engine time: 0.05771014979109168 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_16-16-32/adapters_64_slots_64_rate_1.6-0.1-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_16-16-32/adapters_64_slots_64_rate_1.6-0.1-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [21 21 22]
Adapter prompts. [66, 1080, 17280, 17280, 66, 17280, 66, 1080, 66, 17280, 1080, 17280, 66, 1080, 17280, 17280, 17280, 66, 17280, 1080, 1080, 66, 66, 66, 17280, 66, 66, 66, 17280, 1080, 66, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 66, 1080, 1080, 17280, 17280, 1080, 17280, 66, 17280, 1080, 1080, 1080, 17280, 1080, 66, 66, 1080, 1080, 66, 1080, 66, 66, 66, 17280, 1080]
Prompts retrieved: 404226 . Total input tokens: 90195380 . Total output tokens: 79368359
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 6.43710754532367,
    "estimated_duration": 3600.0861744433955,
    "input_throughput": 6171.274776064203,
    "output_throughput": 5440.392271451154,
    "total_throughput": 11611.667047515357,
    "itl": 80.80053809135907,
    "ttft": 1268431.1988438673,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.47207772303372625,
    "arrivals": 134574,
    "finished_requests": 89976,
    "scheduler_time": 41.5858458905139
}
#Debug simulation 
Total elapsed time: 6.437198277097195. Arrivals time: 0.2586485263891518 Scheduler time: 5.995908319950104 Scheduler overhead time: 0.06257344922050834 Adapter cache time: 0.02493346994742751 Engine time: 0.06517867278307676 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-8/adapters_64_slots_64_rate_1.6-0.1-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-8/adapters_64_slots_64_rate_1.6-0.1-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [21 21 22]
Adapter prompts. [33, 1080, 17280, 17280, 33, 17280, 33, 1080, 33, 17280, 1080, 17280, 33, 1080, 17280, 17280, 17280, 33, 17280, 1080, 1080, 33, 33, 33, 17280, 33, 33, 33, 17280, 1080, 33, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 33, 1080, 1080, 17280, 17280, 1080, 17280, 33, 17280, 1080, 1080, 1080, 17280, 1080, 33, 33, 1080, 1080, 33, 1080, 33, 33, 33, 17280, 1080]
Prompts retrieved: 403533 . Total input tokens: 90037262 . Total output tokens: 79231279
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 6.782932014670223,
    "estimated_duration": 3600.028378448458,
    "input_throughput": 6695.679440835027,
    "output_throughput": 5836.435936389888,
    "total_throughput": 12532.115377224916,
    "itl": 98.88724637463466,
    "ttft": 1145191.700756062,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.42319417804479564,
    "arrivals": 134344,
    "finished_requests": 97330,
    "scheduler_time": 56.7136858020096
}
#Debug simulation 
Total elapsed time: 6.783022345043719. Arrivals time: 0.2661430644802749 Scheduler time: 6.366358024533838 Scheduler overhead time: 0.05244317650794983 Adapter cache time: 0.018097431398928165 Engine time: 0.054841955192387104 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-16/adapters_64_slots_64_rate_1.6-0.1-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-16/adapters_64_slots_64_rate_1.6-0.1-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [21 21 22]
Adapter prompts. [33, 1080, 17280, 17280, 33, 17280, 33, 1080, 33, 17280, 1080, 17280, 33, 1080, 17280, 17280, 17280, 33, 17280, 1080, 1080, 33, 33, 33, 17280, 33, 33, 33, 17280, 1080, 33, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 33, 1080, 1080, 17280, 17280, 1080, 17280, 33, 17280, 1080, 1080, 1080, 17280, 1080, 33, 33, 1080, 1080, 33, 1080, 33, 33, 33, 17280, 1080]
Prompts retrieved: 403533 . Total input tokens: 90037262 . Total output tokens: 79231279
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 6.647306613624096,
    "estimated_duration": 3600.0942447676844,
    "input_throughput": 6560.564083656127,
    "output_throughput": 5720.231082819583,
    "total_throughput": 12280.79516647571,
    "itl": 91.76176678128537,
    "ttft": 1177631.136106134,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4682644420489666,
    "arrivals": 134344,
    "finished_requests": 95377,
    "scheduler_time": 52.03786517180104
}
#Debug simulation 
Total elapsed time: 6.647407855838537. Arrivals time: 0.26287754299119115 Scheduler time: 6.223974570631981 Scheduler overhead time: 0.05591224320232868 Adapter cache time: 0.01984165422618389 Engine time: 0.05804160237312317 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-32/adapters_64_slots_64_rate_1.6-0.1-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-32/adapters_64_slots_64_rate_1.6-0.1-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [21 21 22]
Adapter prompts. [33, 1080, 17280, 17280, 33, 17280, 33, 1080, 33, 17280, 1080, 17280, 33, 1080, 17280, 17280, 17280, 33, 17280, 1080, 1080, 33, 33, 33, 17280, 33, 33, 33, 17280, 1080, 33, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 33, 1080, 1080, 17280, 17280, 1080, 17280, 33, 17280, 1080, 1080, 1080, 17280, 1080, 33, 33, 1080, 1080, 33, 1080, 33, 33, 33, 17280, 1080]
Prompts retrieved: 403533 . Total input tokens: 90037262 . Total output tokens: 79231279
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 6.42860308336094,
    "estimated_duration": 3600.0166850476044,
    "input_throughput": 6281.252276946318,
    "output_throughput": 5486.4342940507295,
    "total_throughput": 11767.686570997048,
    "itl": 80.33678203515971,
    "ttft": 1241611.9798636837,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.48098376162815853,
    "arrivals": 134344,
    "finished_requests": 91352,
    "scheduler_time": 42.652973623166815
}
#Debug simulation 
Total elapsed time: 6.428695206064731. Arrivals time: 0.2589086829684675 Scheduler time: 5.988808559719473 Scheduler overhead time: 0.06258821627125144 Adapter cache time: 0.022882369346916676 Engine time: 0.06567347701638937 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-16-16/adapters_64_slots_64_rate_1.6-0.1-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-16-16/adapters_64_slots_64_rate_1.6-0.1-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [21 21 22]
Adapter prompts. [33, 1080, 17280, 17280, 33, 17280, 33, 1080, 33, 17280, 1080, 17280, 33, 1080, 17280, 17280, 17280, 33, 17280, 1080, 1080, 33, 33, 33, 17280, 33, 33, 33, 17280, 1080, 33, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 33, 1080, 1080, 17280, 17280, 1080, 17280, 33, 17280, 1080, 1080, 1080, 17280, 1080, 33, 33, 1080, 1080, 33, 1080, 33, 33, 33, 17280, 1080]
Prompts retrieved: 403533 . Total input tokens: 90037262 . Total output tokens: 79231279
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 6.637161321938038,
    "estimated_duration": 3600.0359098589734,
    "input_throughput": 6560.73594580484,
    "output_throughput": 5720.378217229151,
    "total_throughput": 12281.114163033992,
    "itl": 91.7625231946221,
    "ttft": 1177540.7376120514,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.43911180160939695,
    "arrivals": 134344,
    "finished_requests": 95378,
    "scheduler_time": 52.03703597224131
}
#Debug simulation 
Total elapsed time: 6.637252603657544. Arrivals time: 0.260903827380389 Scheduler time: 6.216145430225879 Scheduler overhead time: 0.055747912265360355 Adapter cache time: 0.01951704639941454 Engine time: 0.05820024712011218 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-16-32/adapters_64_slots_64_rate_1.6-0.1-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-16-32/adapters_64_slots_64_rate_1.6-0.1-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [21 21 22]
Adapter prompts. [33, 1080, 17280, 17280, 33, 17280, 33, 1080, 33, 17280, 1080, 17280, 33, 1080, 17280, 17280, 17280, 33, 17280, 1080, 1080, 33, 33, 33, 17280, 33, 33, 33, 17280, 1080, 33, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 33, 1080, 1080, 17280, 17280, 1080, 17280, 33, 17280, 1080, 1080, 1080, 17280, 1080, 33, 33, 1080, 1080, 33, 1080, 33, 33, 33, 17280, 1080]
Prompts retrieved: 403533 . Total input tokens: 90037262 . Total output tokens: 79231279
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 6.457063870038837,
    "estimated_duration": 3600.0684423397706,
    "input_throughput": 6281.02947545737,
    "output_throughput": 5486.480970112583,
    "total_throughput": 11767.510445569953,
    "itl": 80.33877177758637,
    "ttft": 1241551.0719506862,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.47663430091924974,
    "arrivals": 134344,
    "finished_requests": 91350,
    "scheduler_time": 42.65311982130233
}
#Debug simulation 
Total elapsed time: 6.457157793920487. Arrivals time: 0.26015472412109375 Scheduler time: 6.014483334496617 Scheduler overhead time: 0.0628051022067666 Adapter cache time: 0.024229543283581734 Engine time: 0.06523238448426127 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_16-16-16/adapters_64_slots_64_rate_1.6-0.1-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_16-16-16/adapters_64_slots_64_rate_1.6-0.1-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [21 21 22]
Adapter prompts. [33, 1080, 17280, 17280, 33, 17280, 33, 1080, 33, 17280, 1080, 17280, 33, 1080, 17280, 17280, 17280, 33, 17280, 1080, 1080, 33, 33, 33, 17280, 33, 33, 33, 17280, 1080, 33, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 33, 1080, 1080, 17280, 17280, 1080, 17280, 33, 17280, 1080, 1080, 1080, 17280, 1080, 33, 33, 1080, 1080, 33, 1080, 33, 33, 33, 17280, 1080]
Prompts retrieved: 403533 . Total input tokens: 90037262 . Total output tokens: 79231279
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 6.647440881934017,
    "estimated_duration": 3600.042905965795,
    "input_throughput": 6560.762917814072,
    "output_throughput": 5720.474321534563,
    "total_throughput": 12281.237239348637,
    "itl": 91.75902071035574,
    "ttft": 1177508.4091658778,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4085709401965145,
    "arrivals": 134344,
    "finished_requests": 95381,
    "scheduler_time": 52.03753124107986
}
#Debug simulation 
Total elapsed time: 6.647602476645261. Arrivals time: 0.27913499157875776 Scheduler time: 6.207379769999534 Scheduler overhead time: 0.05593376653268933 Adapter cache time: 0.019671001937240362 Engine time: 0.05865654954686761 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_16-16-32/adapters_64_slots_64_rate_1.6-0.1-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_16-16-32/adapters_64_slots_64_rate_1.6-0.1-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [21 21 22]
Adapter prompts. [33, 1080, 17280, 17280, 33, 17280, 33, 1080, 33, 17280, 1080, 17280, 33, 1080, 17280, 17280, 17280, 33, 17280, 1080, 1080, 33, 33, 33, 17280, 33, 33, 33, 17280, 1080, 33, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 33, 1080, 1080, 17280, 17280, 1080, 17280, 33, 17280, 1080, 1080, 1080, 17280, 1080, 33, 33, 1080, 1080, 33, 1080, 33, 33, 33, 17280, 1080]
Prompts retrieved: 403533 . Total input tokens: 90037262 . Total output tokens: 79231279
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 6.431331280153245,
    "estimated_duration": 3600.07336743393,
    "input_throughput": 6281.153935514898,
    "output_throughput": 5486.640127581373,
    "total_throughput": 11767.794063096271,
    "itl": 80.33793064040663,
    "ttft": 1241615.39816343,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4720777230337263,
    "arrivals": 134344,
    "finished_requests": 91354,
    "scheduler_time": 42.653522069268796
}
#Debug simulation 
Total elapsed time: 6.431416689883918. Arrivals time: 0.2571089486591518 Scheduler time: 5.994135326240212 Scheduler overhead time: 0.06248541222885251 Adapter cache time: 0.022787086199969053 Engine time: 0.06496516615152359 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-8-8/adapters_64_slots_64_rate_1.6-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-8-8/adapters_64_slots_64_rate_1.6-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [21 21 22]
Adapter prompts. [270, 540, 17280, 17280, 270, 17280, 270, 540, 270, 17280, 540, 17280, 270, 540, 17280, 17280, 17280, 270, 17280, 540, 540, 270, 270, 270, 17280, 270, 270, 270, 17280, 540, 270, 17280, 17280, 17280, 17280, 540, 540, 540, 17280, 270, 540, 540, 17280, 17280, 540, 17280, 270, 17280, 540, 540, 540, 17280, 540, 270, 270, 540, 540, 270, 540, 270, 270, 270, 17280, 540]
Prompts retrieved: 397170 . Total input tokens: 88626587 . Total output tokens: 77965993
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 6.7457378432154655,
    "estimated_duration": 3600.044963362862,
    "input_throughput": 6561.868043429476,
    "output_throughput": 5785.703848694011,
    "total_throughput": 12347.571892123487,
    "itl": 99.8562720310995,
    "ttft": 1145410.236943571,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.42319417804479564,
    "arrivals": 132130,
    "finished_requests": 95957,
    "scheduler_time": 56.75428072673887
}
#Debug simulation 
Total elapsed time: 6.7458314201794565. Arrivals time: 0.2660119133070111 Scheduler time: 6.321773884352297 Scheduler overhead time: 0.052541959565132856 Adapter cache time: 0.02528307493776083 Engine time: 0.05487635964527726 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-8-16/adapters_64_slots_64_rate_1.6-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-8-16/adapters_64_slots_64_rate_1.6-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [21 21 22]
Adapter prompts. [270, 540, 17280, 17280, 270, 17280, 270, 540, 270, 17280, 540, 17280, 270, 540, 17280, 17280, 17280, 270, 17280, 540, 540, 270, 270, 270, 17280, 270, 270, 270, 17280, 540, 270, 17280, 17280, 17280, 17280, 540, 540, 540, 17280, 270, 540, 540, 17280, 17280, 540, 17280, 270, 17280, 540, 540, 540, 17280, 540, 270, 270, 540, 540, 270, 540, 270, 270, 270, 17280, 540]
Prompts retrieved: 397170 . Total input tokens: 88626587 . Total output tokens: 77965993
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 6.6002355120144784,
    "estimated_duration": 3600.0244073981826,
    "input_throughput": 6452.984583176614,
    "output_throughput": 5692.482517031266,
    "total_throughput": 12145.467100207881,
    "itl": 92.30341081642146,
    "ttft": 1172432.9184171255,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.46826444204896667,
    "arrivals": 132130,
    "finished_requests": 94357,
    "scheduler_time": 52.42060431356175
}
#Debug simulation 
Total elapsed time: 6.600337972398847. Arrivals time: 0.2628444884903729 Scheduler time: 6.170785867609084 Scheduler overhead time: 0.05554259708151221 Adapter cache time: 0.026462177745997906 Engine time: 0.05803579557687044 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-8-32/adapters_64_slots_64_rate_1.6-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-8-32/adapters_64_slots_64_rate_1.6-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [21 21 22]
Adapter prompts. [270, 540, 17280, 17280, 270, 17280, 270, 540, 270, 17280, 540, 17280, 270, 540, 17280, 17280, 17280, 270, 17280, 540, 540, 270, 270, 270, 17280, 270, 270, 270, 17280, 540, 270, 17280, 17280, 17280, 17280, 540, 540, 540, 17280, 270, 540, 540, 17280, 17280, 540, 17280, 270, 17280, 540, 540, 540, 17280, 540, 270, 270, 540, 540, 270, 540, 270, 270, 270, 17280, 540]
Prompts retrieved: 397170 . Total input tokens: 88626587 . Total output tokens: 77965993
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 6.442186413798481,
    "estimated_duration": 3600.0235699526493,
    "input_throughput": 6216.905407731643,
    "output_throughput": 5489.878501062133,
    "total_throughput": 11706.783908793775,
    "itl": 80.37981271469181,
    "ttft": 1227878.5979594553,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4809837616281585,
    "arrivals": 132130,
    "finished_requests": 90877,
    "scheduler_time": 43.503609865585936
}
#Debug simulation 
Total elapsed time: 6.442275975830853. Arrivals time: 0.2585573880933225 Scheduler time: 5.997052215505391 Scheduler overhead time: 0.06281345197930932 Adapter cache time: 0.02873208187520504 Engine time: 0.06515335850417614 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-16-16/adapters_64_slots_64_rate_1.6-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-16-16/adapters_64_slots_64_rate_1.6-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [21 21 22]
Adapter prompts. [270, 540, 17280, 17280, 270, 17280, 270, 540, 270, 17280, 540, 17280, 270, 540, 17280, 17280, 17280, 270, 17280, 540, 540, 270, 270, 270, 17280, 270, 270, 270, 17280, 540, 270, 17280, 17280, 17280, 17280, 540, 540, 540, 17280, 270, 540, 540, 17280, 17280, 540, 17280, 270, 17280, 540, 540, 540, 17280, 540, 270, 270, 540, 540, 270, 540, 270, 270, 270, 17280, 540]
Prompts retrieved: 397170 . Total input tokens: 88626587 . Total output tokens: 77965993
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 6.617283370811492,
    "estimated_duration": 3600.0180485167903,
    "input_throughput": 6453.040425608759,
    "output_throughput": 5692.546460549896,
    "total_throughput": 12145.586886158655,
    "itl": 92.29954807013992,
    "ttft": 1172426.3878540718,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.43911180160939717,
    "arrivals": 132130,
    "finished_requests": 94358,
    "scheduler_time": 52.421746886704355
}
#Debug simulation 
Total elapsed time: 6.617373485118151. Arrivals time: 0.259325351100415 Scheduler time: 6.190477049909532 Scheduler overhead time: 0.055964584928005934 Adapter cache time: 0.026950085535645485 Engine time: 0.05803970666602254 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-16-32/adapters_64_slots_64_rate_1.6-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-16-32/adapters_64_slots_64_rate_1.6-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [21 21 22]
Adapter prompts. [270, 540, 17280, 17280, 270, 17280, 270, 540, 270, 17280, 540, 17280, 270, 540, 17280, 17280, 17280, 270, 17280, 540, 540, 270, 270, 270, 17280, 270, 270, 270, 17280, 540, 270, 17280, 17280, 17280, 17280, 540, 540, 540, 17280, 270, 540, 540, 17280, 17280, 540, 17280, 270, 17280, 540, 540, 540, 17280, 540, 270, 270, 540, 540, 270, 540, 270, 270, 270, 17280, 540]
Prompts retrieved: 397170 . Total input tokens: 88626587 . Total output tokens: 77965993
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 6.447999330703169,
    "estimated_duration": 3600.07475817589,
    "input_throughput": 6216.850344335688,
    "output_throughput": 5489.8687742846,
    "total_throughput": 11706.719118620287,
    "itl": 80.37900422273754,
    "ttft": 1227904.438080306,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.47663430091924974,
    "arrivals": 132130,
    "finished_requests": 90878,
    "scheduler_time": 43.50206688178849
}
#Debug simulation 
Total elapsed time: 6.448092648759484. Arrivals time: 0.26204277109354734 Scheduler time: 5.995126927271485 Scheduler overhead time: 0.06414491916075349 Adapter cache time: 0.028997677378356457 Engine time: 0.06762399058789015 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_16-16-16/adapters_64_slots_64_rate_1.6-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_16-16-16/adapters_64_slots_64_rate_1.6-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [21 21 22]
Adapter prompts. [270, 540, 17280, 17280, 270, 17280, 270, 540, 270, 17280, 540, 17280, 270, 540, 17280, 17280, 17280, 270, 17280, 540, 540, 270, 270, 270, 17280, 270, 270, 270, 17280, 540, 270, 17280, 17280, 17280, 17280, 540, 540, 540, 17280, 270, 540, 540, 17280, 17280, 540, 17280, 270, 17280, 540, 540, 540, 17280, 540, 270, 270, 540, 540, 270, 540, 270, 270, 270, 17280, 540]
Prompts retrieved: 397170 . Total input tokens: 88626587 . Total output tokens: 77965993
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 6.639952447731048,
    "estimated_duration": 3600.0274098775903,
    "input_throughput": 6452.81448031805,
    "output_throughput": 5692.302492968183,
    "total_throughput": 12145.116973286234,
    "itl": 92.30208420529911,
    "ttft": 1172384.586230882,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4085709401965145,
    "arrivals": 132130,
    "finished_requests": 94352,
    "scheduler_time": 52.41972181027907
}
#Debug simulation 
Total elapsed time: 6.640046269167215. Arrivals time: 0.26439244858920574 Scheduler time: 6.208184109535068 Scheduler overhead time: 0.055878409184515476 Adapter cache time: 0.026657954789698124 Engine time: 0.058209864888340235 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_16-16-32/adapters_64_slots_64_rate_1.6-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_16-16-32/adapters_64_slots_64_rate_1.6-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [21 21 22]
Adapter prompts. [270, 540, 17280, 17280, 270, 17280, 270, 540, 270, 17280, 540, 17280, 270, 540, 17280, 17280, 17280, 270, 17280, 540, 540, 270, 270, 270, 17280, 270, 270, 270, 17280, 540, 270, 17280, 17280, 17280, 17280, 540, 540, 540, 17280, 270, 540, 540, 17280, 17280, 540, 17280, 270, 17280, 540, 540, 540, 17280, 540, 270, 270, 540, 540, 270, 540, 270, 270, 270, 17280, 540]
Prompts retrieved: 397170 . Total input tokens: 88626587 . Total output tokens: 77965993
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 6.439468766096979,
    "estimated_duration": 3600.006570499145,
    "input_throughput": 6217.008653097211,
    "output_throughput": 5489.930813448413,
    "total_throughput": 11706.939466545624,
    "itl": 80.37922926432461,
    "ttft": 1227824.176472844,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4720777230337263,
    "arrivals": 132130,
    "finished_requests": 90877,
    "scheduler_time": 43.50350368249932
}
#Debug simulation 
Total elapsed time: 6.439561706967652. Arrivals time: 0.25895569240674376 Scheduler time: 5.993641905486584 Scheduler overhead time: 0.06252540508285165 Adapter cache time: 0.028922180645167828 Engine time: 0.0653722402639687 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-8/adapters_64_slots_64_rate_1.6-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-8/adapters_64_slots_64_rate_1.6-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [21 21 22]
Adapter prompts. [135, 540, 17280, 17280, 135, 17280, 135, 540, 135, 17280, 540, 17280, 135, 540, 17280, 17280, 17280, 135, 17280, 540, 540, 135, 135, 135, 17280, 135, 135, 135, 17280, 540, 135, 17280, 17280, 17280, 17280, 540, 540, 540, 17280, 135, 540, 540, 17280, 17280, 540, 17280, 135, 17280, 540, 540, 540, 17280, 540, 135, 135, 540, 540, 135, 540, 135, 135, 135, 17280, 540]
Prompts retrieved: 394335 . Total input tokens: 88002976 . Total output tokens: 77408960
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 6.821297029964626,
    "estimated_duration": 3600.012501697875,
    "input_throughput": 6878.280002728196,
    "output_throughput": 5923.411652026983,
    "total_throughput": 12801.69165475518,
    "itl": 97.06008910319237,
    "ttft": 1079136.4418733623,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.42319417804479564,
    "arrivals": 131205,
    "finished_requests": 99590,
    "scheduler_time": 59.86197555031448
}
#Debug simulation 
Total elapsed time: 6.821415043901652. Arrivals time: 0.2702568843960762 Scheduler time: 6.393748786300421 Scheduler overhead time: 0.053568449802696705 Adapter cache time: 0.022394399158656597 Engine time: 0.05598517134785652 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-16/adapters_64_slots_64_rate_1.6-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-16/adapters_64_slots_64_rate_1.6-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [21 21 22]
Adapter prompts. [135, 540, 17280, 17280, 135, 17280, 135, 540, 135, 17280, 540, 17280, 135, 540, 17280, 17280, 17280, 135, 17280, 540, 540, 135, 135, 135, 17280, 135, 135, 135, 17280, 540, 135, 17280, 17280, 17280, 17280, 540, 540, 540, 17280, 135, 540, 540, 17280, 17280, 540, 17280, 135, 17280, 540, 540, 540, 17280, 540, 135, 135, 540, 540, 135, 540, 135, 135, 135, 17280, 540]
Prompts retrieved: 394335 . Total input tokens: 88002976 . Total output tokens: 77408960
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 6.7552745919674635,
    "estimated_duration": 3600.064300113812,
    "input_throughput": 6760.689801910081,
    "output_throughput": 5818.4607978634685,
    "total_throughput": 12579.15059977355,
    "itl": 89.82797085369879,
    "ttft": 1107939.6014756644,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.46826444204896656,
    "arrivals": 131205,
    "finished_requests": 97860,
    "scheduler_time": 55.20852259130876
}
#Debug simulation 
Total elapsed time: 6.755391375161707. Arrivals time: 0.2680626162327826 Scheduler time: 6.317169557325542 Scheduler overhead time: 0.05723001481965184 Adapter cache time: 0.02389769535511732 Engine time: 0.06147936685010791 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-32/adapters_64_slots_64_rate_1.6-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-32/adapters_64_slots_64_rate_1.6-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [21 21 22]
Adapter prompts. [135, 540, 17280, 17280, 135, 17280, 135, 540, 135, 17280, 540, 17280, 135, 540, 17280, 17280, 17280, 135, 17280, 540, 540, 135, 135, 135, 17280, 135, 135, 135, 17280, 540, 135, 17280, 17280, 17280, 17280, 540, 540, 540, 17280, 135, 540, 540, 17280, 17280, 540, 17280, 135, 17280, 540, 540, 540, 17280, 540, 135, 135, 540, 540, 135, 540, 135, 135, 135, 17280, 540]
Prompts retrieved: 394335 . Total input tokens: 88002976 . Total output tokens: 77408960
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 6.569759581703693,
    "estimated_duration": 3600.0713541786536,
    "input_throughput": 6497.394273268957,
    "output_throughput": 5594.300506467283,
    "total_throughput": 12091.694779736239,
    "itl": 78.48396307194551,
    "ttft": 1169294.9712605856,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4809837616281584,
    "arrivals": 131205,
    "finished_requests": 93997,
    "scheduler_time": 45.68439600740639
}
#Debug simulation 
Total elapsed time: 6.569853818975389. Arrivals time: 0.2653317665681243 Scheduler time: 6.116657384671271 Scheduler overhead time: 0.06433019880205393 Adapter cache time: 0.02587032923474908 Engine time: 0.06688080448657274 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-16-16/adapters_64_slots_64_rate_1.6-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-16-16/adapters_64_slots_64_rate_1.6-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [21 21 22]
Adapter prompts. [135, 540, 17280, 17280, 135, 17280, 135, 540, 135, 17280, 540, 17280, 135, 540, 17280, 17280, 17280, 135, 17280, 540, 540, 135, 135, 135, 17280, 135, 135, 135, 17280, 540, 135, 17280, 17280, 17280, 17280, 540, 540, 540, 17280, 135, 540, 540, 17280, 17280, 540, 17280, 135, 17280, 540, 540, 540, 17280, 540, 135, 135, 540, 540, 135, 540, 135, 135, 135, 17280, 540]
Prompts retrieved: 394335 . Total input tokens: 88002976 . Total output tokens: 77408960
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 6.837944517843425,
    "estimated_duration": 3600.0666564046087,
    "input_throughput": 6760.565101399227,
    "output_throughput": 5818.405601667233,
    "total_throughput": 12578.97070306646,
    "itl": 89.82970190013768,
    "ttft": 1108002.1220226549,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.43911180160939695,
    "arrivals": 131205,
    "finished_requests": 97859,
    "scheduler_time": 55.20985646810341
}
#Debug simulation 
Total elapsed time: 6.838064165785909. Arrivals time: 0.2718295739032328 Scheduler time: 6.396247486118227 Scheduler overhead time: 0.0577571433968842 Adapter cache time: 0.024287840351462364 Engine time: 0.060328752268105745 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-16-32/adapters_64_slots_64_rate_1.6-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-16-32/adapters_64_slots_64_rate_1.6-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [21 21 22]
Adapter prompts. [135, 540, 17280, 17280, 135, 17280, 135, 540, 135, 17280, 540, 17280, 135, 540, 17280, 17280, 17280, 135, 17280, 540, 540, 135, 135, 135, 17280, 135, 135, 135, 17280, 540, 135, 17280, 17280, 17280, 17280, 540, 540, 540, 17280, 135, 540, 540, 17280, 17280, 540, 17280, 135, 17280, 540, 540, 540, 17280, 540, 135, 135, 540, 540, 135, 540, 135, 135, 135, 17280, 540]
Prompts retrieved: 394335 . Total input tokens: 88002976 . Total output tokens: 77408960
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 6.591669870074838,
    "estimated_duration": 3600.0257409064343,
    "input_throughput": 6497.559096372013,
    "output_throughput": 5594.385832066038,
    "total_throughput": 12091.944928438052,
    "itl": 78.48293170356732,
    "ttft": 1169269.3601653718,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4766343009192497,
    "arrivals": 131205,
    "finished_requests": 93998,
    "scheduler_time": 45.68274196739387
}
#Debug simulation 
Total elapsed time: 6.591841568239033. Arrivals time: 0.2699015843681991 Scheduler time: 6.132835165597498 Scheduler overhead time: 0.06479769991710782 Adapter cache time: 0.0257963789626956 Engine time: 0.06739134481176734 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_16-16-16/adapters_64_slots_64_rate_1.6-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_16-16-16/adapters_64_slots_64_rate_1.6-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [21 21 22]
Adapter prompts. [135, 540, 17280, 17280, 135, 17280, 135, 540, 135, 17280, 540, 17280, 135, 540, 17280, 17280, 17280, 135, 17280, 540, 540, 135, 135, 135, 17280, 135, 135, 135, 17280, 540, 135, 17280, 17280, 17280, 17280, 540, 540, 540, 17280, 135, 540, 540, 17280, 17280, 540, 17280, 135, 17280, 540, 540, 540, 17280, 540, 135, 135, 540, 540, 135, 540, 135, 135, 135, 17280, 540]
Prompts retrieved: 394335 . Total input tokens: 88002976 . Total output tokens: 77408960
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 6.794250037986785,
    "estimated_duration": 3600.0909260382914,
    "input_throughput": 6760.63980050184,
    "output_throughput": 5818.41776508986,
    "total_throughput": 12579.0575655917,
    "itl": 89.82866349056863,
    "ttft": 1107940.3297349075,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4085709401965145,
    "arrivals": 131205,
    "finished_requests": 97860,
    "scheduler_time": 55.21195081500547
}
#Debug simulation 
Total elapsed time: 6.794363275170326. Arrivals time: 0.27630968298763037 Scheduler time: 6.349653607234359 Scheduler overhead time: 0.057284553069621325 Adapter cache time: 0.023761091753840446 Engine time: 0.059816084802150726 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_16-16-32/adapters_64_slots_64_rate_1.6-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_16-16-32/adapters_64_slots_64_rate_1.6-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [21 21 22]
Adapter prompts. [135, 540, 17280, 17280, 135, 17280, 135, 540, 135, 17280, 540, 17280, 135, 540, 17280, 17280, 17280, 135, 17280, 540, 540, 135, 135, 135, 17280, 135, 135, 135, 17280, 540, 135, 17280, 17280, 17280, 17280, 540, 540, 540, 17280, 135, 540, 540, 17280, 17280, 540, 17280, 135, 17280, 540, 540, 540, 17280, 540, 135, 135, 540, 540, 135, 540, 135, 135, 135, 17280, 540]
Prompts retrieved: 394335 . Total input tokens: 88002976 . Total output tokens: 77408960
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 6.636859267018735,
    "estimated_duration": 3600.0550063294436,
    "input_throughput": 6497.50599890124,
    "output_throughput": 5594.339798861668,
    "total_throughput": 12091.845797762908,
    "itl": 78.4845190974823,
    "ttft": 1169198.367994879,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.47207772303372625,
    "arrivals": 131205,
    "finished_requests": 93997,
    "scheduler_time": 45.68405729705003
}
#Debug simulation 
Total elapsed time: 6.636969764716923. Arrivals time: 0.26944461232051253 Scheduler time: 6.178009898867458 Scheduler overhead time: 0.06454693991690874 Adapter cache time: 0.02608924964442849 Engine time: 0.06770042330026627 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-8/adapters_64_slots_64_rate_1.6-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-8/adapters_64_slots_64_rate_1.6-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [21 21 22]
Adapter prompts. [66, 540, 17280, 17280, 66, 17280, 66, 540, 66, 17280, 540, 17280, 66, 540, 17280, 17280, 17280, 66, 17280, 540, 540, 66, 66, 66, 17280, 66, 66, 66, 17280, 540, 66, 17280, 17280, 17280, 17280, 540, 540, 540, 17280, 66, 540, 540, 17280, 17280, 540, 17280, 66, 17280, 540, 540, 540, 17280, 540, 66, 66, 540, 540, 66, 540, 66, 66, 66, 17280, 540]
Prompts retrieved: 392886 . Total input tokens: 87691996 . Total output tokens: 77111729
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 6.957992507144809,
    "estimated_duration": 3600.095731973405,
    "input_throughput": 6964.307303644007,
    "output_throughput": 5981.842318452849,
    "total_throughput": 12946.149622096857,
    "itl": 95.92983127868855,
    "ttft": 1059730.4149368291,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.42319417804479564,
    "arrivals": 130771,
    "finished_requests": 100604,
    "scheduler_time": 61.12782669448361
}
#Debug simulation 
Total elapsed time: 6.958084993995726. Arrivals time: 0.27289090771228075 Scheduler time: 6.526524641085416 Scheduler overhead time: 0.05459967581555247 Adapter cache time: 0.020979495719075203 Engine time: 0.05688016675412655 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-16/adapters_64_slots_64_rate_1.6-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-16/adapters_64_slots_64_rate_1.6-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [21 21 22]
Adapter prompts. [66, 540, 17280, 17280, 66, 17280, 66, 540, 66, 17280, 540, 17280, 66, 540, 17280, 17280, 17280, 66, 17280, 540, 540, 66, 66, 66, 17280, 66, 66, 66, 17280, 540, 66, 17280, 17280, 17280, 17280, 540, 540, 540, 17280, 66, 540, 540, 17280, 17280, 540, 17280, 66, 17280, 540, 540, 540, 17280, 540, 66, 66, 540, 540, 66, 540, 66, 66, 66, 17280, 540]
Prompts retrieved: 392886 . Total input tokens: 87691996 . Total output tokens: 77111729
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 6.90684854472056,
    "estimated_duration": 3600.0338697059756,
    "input_throughput": 6830.2993499359145,
    "output_throughput": 5869.113393015289,
    "total_throughput": 12699.412742951205,
    "itl": 88.86345992623026,
    "ttft": 1089779.005542261,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4682644420489668,
    "arrivals": 130771,
    "finished_requests": 98656,
    "scheduler_time": 56.27238005517725
}
#Debug simulation 
Total elapsed time: 6.906937894877046. Arrivals time: 0.27099561551585793 Scheduler time: 6.4664395772852 Scheduler overhead time: 0.05842133378610015 Adapter cache time: 0.02236904250457883 Engine time: 0.06087171658873558 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-32/adapters_64_slots_64_rate_1.6-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-32/adapters_64_slots_64_rate_1.6-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [21 21 22]
Adapter prompts. [66, 540, 17280, 17280, 66, 17280, 66, 540, 66, 17280, 540, 17280, 66, 540, 17280, 17280, 17280, 66, 17280, 540, 540, 66, 66, 66, 17280, 66, 66, 66, 17280, 540, 66, 17280, 17280, 17280, 17280, 540, 540, 540, 17280, 66, 540, 540, 17280, 17280, 540, 17280, 66, 17280, 540, 540, 540, 17280, 540, 66, 66, 540, 540, 66, 540, 66, 66, 66, 17280, 540]
Prompts retrieved: 392886 . Total input tokens: 87691996 . Total output tokens: 77111729
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 6.635435713920742,
    "estimated_duration": 3600.0322015496176,
    "input_throughput": 6564.900722228794,
    "output_throughput": 5641.483426525423,
    "total_throughput": 12206.384148754218,
    "itl": 77.64994360987774,
    "ttft": 1152903.4012550032,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4809837616281584,
    "arrivals": 130771,
    "finished_requests": 94830,
    "scheduler_time": 46.53674744120898
}
#Debug simulation 
Total elapsed time: 6.635526028927416. Arrivals time: 0.26694565638899803 Scheduler time: 6.180988613516092 Scheduler overhead time: 0.06490553123876452 Adapter cache time: 0.024152416735887527 Engine time: 0.06753374729305506 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_8-16-16/adapters_64_slots_64_rate_1.6-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_8-16-16/adapters_64_slots_64_rate_1.6-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [21 21 22]
Adapter prompts. [66, 540, 17280, 17280, 66, 17280, 66, 540, 66, 17280, 540, 17280, 66, 540, 17280, 17280, 17280, 66, 17280, 540, 540, 66, 66, 66, 17280, 66, 66, 66, 17280, 540, 66, 17280, 17280, 17280, 17280, 540, 540, 540, 17280, 66, 540, 540, 17280, 17280, 540, 17280, 66, 17280, 540, 540, 540, 17280, 540, 66, 66, 540, 540, 66, 540, 66, 66, 66, 17280, 540]
Prompts retrieved: 392886 . Total input tokens: 87691996 . Total output tokens: 77111729
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 6.848046710714698,
    "estimated_duration": 3600.024399738237,
    "input_throughput": 6830.258984296858,
    "output_throughput": 5868.922722172734,
    "total_throughput": 12699.181706469593,
    "itl": 88.86425306404827,
    "ttft": 1089768.1314282103,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.43911180160939717,
    "arrivals": 130771,
    "finished_requests": 98655,
    "scheduler_time": 56.27565699398868
}
#Debug simulation 
Total elapsed time: 6.848141269758344. Arrivals time: 0.2682483606040478 Scheduler time: 6.411100580822676 Scheduler overhead time: 0.057990665547549725 Adapter cache time: 0.02234588423743844 Engine time: 0.06069957558065653 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_8-16-32/adapters_64_slots_64_rate_1.6-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_8-16-32/adapters_64_slots_64_rate_1.6-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [21 21 22]
Adapter prompts. [66, 540, 17280, 17280, 66, 17280, 66, 540, 66, 17280, 540, 17280, 66, 540, 17280, 17280, 17280, 66, 17280, 540, 540, 66, 66, 66, 17280, 66, 66, 66, 17280, 540, 66, 17280, 17280, 17280, 17280, 540, 540, 540, 17280, 66, 540, 540, 17280, 17280, 540, 17280, 66, 17280, 540, 540, 540, 17280, 540, 66, 66, 540, 540, 66, 540, 66, 66, 66, 17280, 540]
Prompts retrieved: 392886 . Total input tokens: 87691996 . Total output tokens: 77111729
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 6.715030170045793,
    "estimated_duration": 3600.0822877819633,
    "input_throughput": 6564.809387887905,
    "output_throughput": 5641.404939250109,
    "total_throughput": 12206.214327138014,
    "itl": 77.64952388734012,
    "ttft": 1152916.981664388,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4766343009192497,
    "arrivals": 130771,
    "finished_requests": 94830,
    "scheduler_time": 46.53766165882387
}
#Debug simulation 
Total elapsed time: 6.715122578199953. Arrivals time: 0.26554066874086857 Scheduler time: 6.259198650252074 Scheduler overhead time: 0.06572126829996705 Adapter cache time: 0.024570916313678026 Engine time: 0.06874568667262793 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_16-16-16/adapters_64_slots_64_rate_1.6-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_16-16-16/adapters_64_slots_64_rate_1.6-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [21 21 22]
Adapter prompts. [66, 540, 17280, 17280, 66, 17280, 66, 540, 66, 17280, 540, 17280, 66, 540, 17280, 17280, 17280, 66, 17280, 540, 540, 66, 66, 66, 17280, 66, 66, 66, 17280, 540, 66, 17280, 17280, 17280, 17280, 540, 540, 540, 17280, 66, 540, 540, 17280, 17280, 540, 17280, 66, 17280, 540, 540, 540, 17280, 540, 66, 66, 540, 540, 66, 540, 66, 66, 66, 17280, 540]
Prompts retrieved: 392886 . Total input tokens: 87691996 . Total output tokens: 77111729
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 6.928272032178938,
    "estimated_duration": 3600.0096068291687,
    "input_throughput": 6830.1748287992295,
    "output_throughput": 5869.2665597107825,
    "total_throughput": 12699.441388510011,
    "itl": 88.86374502896315,
    "ttft": 1089700.169971499,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4085709401965145,
    "arrivals": 130771,
    "finished_requests": 98656,
    "scheduler_time": 56.27517159963441
}
#Debug simulation 
Total elapsed time: 6.92836572509259. Arrivals time: 0.2707468941807747 Scheduler time: 6.4867801163345575 Scheduler overhead time: 0.05888745281845331 Adapter cache time: 0.022501079831272364 Engine time: 0.06140719307586551 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_16-16-32/adapters_64_slots_64_rate_1.6-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_16-16-32/adapters_64_slots_64_rate_1.6-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [21 21 22]
Adapter prompts. [66, 540, 17280, 17280, 66, 17280, 66, 540, 66, 17280, 540, 17280, 66, 540, 17280, 17280, 17280, 66, 17280, 540, 540, 66, 66, 66, 17280, 66, 66, 66, 17280, 540, 66, 17280, 17280, 17280, 17280, 540, 540, 540, 17280, 66, 540, 540, 17280, 17280, 540, 17280, 66, 17280, 540, 540, 540, 17280, 540, 66, 66, 540, 540, 66, 540, 66, 66, 66, 17280, 540]
Prompts retrieved: 392886 . Total input tokens: 87691996 . Total output tokens: 77111729
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 6.723646502010524,
    "estimated_duration": 3600.032997422818,
    "input_throughput": 6564.668161908056,
    "output_throughput": 5641.117738236896,
    "total_throughput": 12205.785900144952,
    "itl": 77.65064253509286,
    "ttft": 1153007.1722030896,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.47207772303372625,
    "arrivals": 130771,
    "finished_requests": 94826,
    "scheduler_time": 46.53777921290404
}
#Debug simulation 
Total elapsed time: 6.723744824063033. Arrivals time: 0.2679100325331092 Scheduler time: 6.266341557260603 Scheduler overhead time: 0.06535098841413856 Adapter cache time: 0.024484198540449142 Engine time: 0.06832297192886472 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-8/adapters_64_slots_64_rate_1.6-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-8/adapters_64_slots_64_rate_1.6-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [21 21 22]
Adapter prompts. [33, 540, 17280, 17280, 33, 17280, 33, 540, 33, 17280, 540, 17280, 33, 540, 17280, 17280, 17280, 33, 17280, 540, 540, 33, 33, 33, 17280, 33, 33, 33, 17280, 540, 33, 17280, 17280, 17280, 17280, 540, 540, 540, 17280, 33, 540, 540, 17280, 17280, 540, 17280, 33, 17280, 540, 540, 540, 17280, 540, 33, 33, 540, 540, 33, 540, 33, 33, 33, 17280, 540]
Prompts retrieved: 392193 . Total input tokens: 87528464 . Total output tokens: 76979800
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 7.059422660153359,
    "estimated_duration": 3600.0295483263126,
    "input_throughput": 6909.612731252312,
    "output_throughput": 6019.751701781221,
    "total_throughput": 12929.364433033534,
    "itl": 95.72858854133734,
    "ttft": 1055691.3654468425,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.42319417804479564,
    "arrivals": 130530,
    "finished_requests": 100575,
    "scheduler_time": 61.79941743221599
}
#Debug simulation 
Total elapsed time: 7.05954019818455. Arrivals time: 0.2726059462875128 Scheduler time: 6.627977934200317 Scheduler overhead time: 0.05501185264438391 Adapter cache time: 0.02005870034918189 Engine time: 0.05759529350325465 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-16/adapters_64_slots_64_rate_1.6-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-16/adapters_64_slots_64_rate_1.6-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [21 21 22]
Adapter prompts. [33, 540, 17280, 17280, 33, 17280, 33, 540, 33, 17280, 540, 17280, 33, 540, 17280, 17280, 17280, 33, 17280, 540, 540, 33, 33, 33, 17280, 33, 33, 33, 17280, 540, 33, 17280, 17280, 17280, 17280, 540, 540, 540, 17280, 33, 540, 540, 17280, 17280, 540, 17280, 33, 17280, 540, 540, 540, 17280, 540, 33, 33, 540, 540, 33, 540, 33, 33, 33, 17280, 540]
Prompts retrieved: 392193 . Total input tokens: 87528464 . Total output tokens: 76979800
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 7.0098373158834875,
    "estimated_duration": 3600.057518931961,
    "input_throughput": 6784.325214683216,
    "output_throughput": 5907.361448577436,
    "total_throughput": 12691.68666326065,
    "itl": 88.69800348201909,
    "ttft": 1086973.9574503438,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.46826444204896667,
    "arrivals": 130530,
    "finished_requests": 98713,
    "scheduler_time": 56.86746510603771
}
#Debug simulation 
Total elapsed time: 7.009958161972463. Arrivals time: 0.2716537304222584 Scheduler time: 6.5682160635478795 Scheduler overhead time: 0.05888812942430377 Adapter cache time: 0.021462746430188417 Engine time: 0.06143322540447116 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-32/adapters_64_slots_64_rate_1.6-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-32/adapters_64_slots_64_rate_1.6-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [21 21 22]
Adapter prompts. [33, 540, 17280, 17280, 33, 17280, 33, 540, 33, 17280, 540, 17280, 33, 540, 17280, 17280, 17280, 33, 17280, 540, 540, 33, 33, 33, 17280, 33, 33, 33, 17280, 540, 33, 17280, 17280, 17280, 17280, 540, 540, 540, 17280, 33, 540, 540, 17280, 17280, 540, 17280, 33, 17280, 540, 540, 540, 17280, 540, 33, 33, 540, 540, 33, 540, 33, 33, 33, 17280, 540]
Prompts retrieved: 392193 . Total input tokens: 87528464 . Total output tokens: 76979800
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 6.691684539895505,
    "estimated_duration": 3600.0457037870333,
    "input_throughput": 6514.809513481509,
    "output_throughput": 5675.766832211514,
    "total_throughput": 12190.576345693024,
    "itl": 77.50227922126587,
    "ttft": 1151823.1300812697,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4809837616281584,
    "arrivals": 130530,
    "finished_requests": 94807,
    "scheduler_time": 46.99312220642811
}
#Debug simulation 
Total elapsed time: 6.691776710096747. Arrivals time: 0.2682199366390705 Scheduler time: 6.234948834404349 Scheduler overhead time: 0.06548095820471644 Adapter cache time: 0.023223507218062878 Engine time: 0.06838432420045137 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_8-16-16/adapters_64_slots_64_rate_1.6-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_8-16-16/adapters_64_slots_64_rate_1.6-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [21 21 22]
Adapter prompts. [33, 540, 17280, 17280, 33, 17280, 33, 540, 33, 17280, 540, 17280, 33, 540, 17280, 17280, 17280, 33, 17280, 540, 540, 33, 33, 33, 17280, 33, 33, 33, 17280, 540, 33, 17280, 17280, 17280, 17280, 540, 540, 540, 17280, 33, 540, 540, 17280, 17280, 540, 17280, 33, 17280, 540, 540, 540, 17280, 540, 33, 33, 540, 540, 33, 540, 33, 33, 33, 17280, 540]
Prompts retrieved: 392193 . Total input tokens: 87528464 . Total output tokens: 76979800
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 6.94017669884488,
    "estimated_duration": 3600.011099244814,
    "input_throughput": 6784.144083645545,
    "output_throughput": 5907.136232013559,
    "total_throughput": 12691.280315659104,
    "itl": 88.6999840568706,
    "ttft": 1087061.5372943678,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.43911180160939695,
    "arrivals": 130530,
    "finished_requests": 98710,
    "scheduler_time": 56.865980304915965
}
#Debug simulation 
Total elapsed time: 6.940353089943528. Arrivals time: 0.26928385719656944 Scheduler time: 6.500929081812501 Scheduler overhead time: 0.05858640279620886 Adapter cache time: 0.021809526719152927 Engine time: 0.06160919647663832 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_8-16-32/adapters_64_slots_64_rate_1.6-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_8-16-32/adapters_64_slots_64_rate_1.6-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [21 21 22]
Adapter prompts. [33, 540, 17280, 17280, 33, 17280, 33, 540, 33, 17280, 540, 17280, 33, 540, 17280, 17280, 17280, 33, 17280, 540, 540, 33, 33, 33, 17280, 33, 33, 33, 17280, 540, 33, 17280, 17280, 17280, 17280, 540, 540, 540, 17280, 33, 540, 540, 17280, 17280, 540, 17280, 33, 17280, 540, 540, 540, 17280, 540, 33, 33, 540, 540, 33, 540, 33, 33, 33, 17280, 540]
Prompts retrieved: 392193 . Total input tokens: 87528464 . Total output tokens: 76979800
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 6.676302375271916,
    "estimated_duration": 3600.0054041468716,
    "input_throughput": 6514.766887011919,
    "output_throughput": 5675.797868654085,
    "total_throughput": 12190.564755666004,
    "itl": 77.50176192203168,
    "ttft": 1151792.875098127,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4766343009192497,
    "arrivals": 130530,
    "finished_requests": 94807,
    "scheduler_time": 46.9931657046179
}
#Debug simulation 
Total elapsed time: 6.6763932392932475. Arrivals time: 0.265340827871114 Scheduler time: 6.223619971424341 Scheduler overhead time: 0.06510398257523775 Adapter cache time: 0.023400045465677977 Engine time: 0.06790871359407902 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_16-16-16/adapters_64_slots_64_rate_1.6-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_16-16-16/adapters_64_slots_64_rate_1.6-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [21 21 22]
Adapter prompts. [33, 540, 17280, 17280, 33, 17280, 33, 540, 33, 17280, 540, 17280, 33, 540, 17280, 17280, 17280, 33, 17280, 540, 540, 33, 33, 33, 17280, 33, 33, 33, 17280, 540, 33, 17280, 17280, 17280, 17280, 540, 540, 540, 17280, 33, 540, 540, 17280, 17280, 540, 17280, 33, 17280, 540, 540, 540, 17280, 540, 33, 33, 540, 540, 33, 540, 33, 33, 33, 17280, 540]
Prompts retrieved: 392193 . Total input tokens: 87528464 . Total output tokens: 76979800
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 6.922731462866068,
    "estimated_duration": 3600.0403779636877,
    "input_throughput": 6784.530015137058,
    "output_throughput": 5907.411519653381,
    "total_throughput": 12691.94153479044,
    "itl": 88.6976033267173,
    "ttft": 1086951.9436879836,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4085709401965145,
    "arrivals": 130530,
    "finished_requests": 98714,
    "scheduler_time": 56.87008338566467
}
#Debug simulation 
Total elapsed time: 6.92282425891608. Arrivals time: 0.27207657089456916 Scheduler time: 6.481445459648967 Scheduler overhead time: 0.05885525140911341 Adapter cache time: 0.021362690720707178 Engine time: 0.06099116429686546 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_16-16-32/adapters_64_slots_64_rate_1.6-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_16-16-32/adapters_64_slots_64_rate_1.6-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [21 21 22]
Adapter prompts. [33, 540, 17280, 17280, 33, 17280, 33, 540, 33, 17280, 540, 17280, 33, 540, 17280, 17280, 17280, 33, 17280, 540, 540, 33, 33, 33, 17280, 33, 33, 33, 17280, 540, 33, 17280, 17280, 17280, 17280, 540, 540, 540, 17280, 33, 540, 540, 17280, 17280, 540, 17280, 33, 17280, 540, 540, 540, 17280, 540, 33, 33, 540, 540, 33, 540, 33, 33, 33, 17280, 540]
Prompts retrieved: 392193 . Total input tokens: 87528464 . Total output tokens: 76979800
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 6.677593193948269,
    "estimated_duration": 3600.0831028488656,
    "input_throughput": 6514.844888286074,
    "output_throughput": 5675.745091503739,
    "total_throughput": 12190.589979789813,
    "itl": 77.50167605309365,
    "ttft": 1151772.978905989,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.47207772303372625,
    "arrivals": 130530,
    "finished_requests": 94808,
    "scheduler_time": 46.99527729029986
}
#Debug simulation 
Total elapsed time: 6.677684308029711. Arrivals time: 0.2762392368167639 Scheduler time: 6.213873476721346 Scheduler overhead time: 0.06552545865997672 Adapter cache time: 0.02329872502014041 Engine time: 0.06752768717706203 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-8/adapters_64_slots_64_rate_1.6-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-8/adapters_64_slots_64_rate_1.6-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [21 21 22]
Adapter prompts. [135, 270, 17280, 17280, 135, 17280, 135, 270, 135, 17280, 270, 17280, 135, 270, 17280, 17280, 17280, 135, 17280, 270, 270, 135, 135, 135, 17280, 135, 135, 135, 17280, 270, 135, 17280, 17280, 17280, 17280, 270, 270, 270, 17280, 135, 270, 270, 17280, 17280, 270, 17280, 135, 17280, 270, 270, 270, 17280, 270, 135, 135, 270, 270, 135, 270, 135, 135, 135, 17280, 270]
Prompts retrieved: 388665 . Total input tokens: 86768647 . Total output tokens: 76278364
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 7.102504912763834,
    "estimated_duration": 3600.0167641556186,
    "input_throughput": 7049.204396122365,
    "output_throughput": 6109.606827111217,
    "total_throughput": 13158.811223233582,
    "itl": 93.79536706455126,
    "ttft": 1022580.1400587229,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.42319417804479564,
    "arrivals": 129375,
    "finished_requests": 102000,
    "scheduler_time": 64.19769352392959
}
#Debug simulation 
Total elapsed time: 7.10262345103547. Arrivals time: 0.27593324333429337 Scheduler time: 6.664565266110003 Scheduler overhead time: 0.05588311096653342 Adapter cache time: 0.021627090871334076 Engine time: 0.05800887243822217 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-16/adapters_64_slots_64_rate_1.6-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-16/adapters_64_slots_64_rate_1.6-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [21 21 22]
Adapter prompts. [135, 270, 17280, 17280, 135, 17280, 135, 270, 135, 17280, 270, 17280, 135, 270, 17280, 17280, 17280, 135, 17280, 270, 270, 135, 135, 135, 17280, 135, 135, 135, 17280, 270, 135, 17280, 17280, 17280, 17280, 270, 270, 270, 17280, 135, 270, 270, 17280, 17280, 270, 17280, 135, 17280, 270, 270, 270, 17280, 270, 135, 135, 270, 270, 135, 270, 135, 135, 135, 17280, 270]
Prompts retrieved: 388665 . Total input tokens: 86768647 . Total output tokens: 76278364
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 6.991170763969421,
    "estimated_duration": 3600.025979077285,
    "input_throughput": 6917.474802885411,
    "output_throughput": 5996.228395421972,
    "total_throughput": 12913.703198307383,
    "itl": 86.88862610516985,
    "ttft": 1054554.086577527,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4682644420489666,
    "arrivals": 129375,
    "finished_requests": 100099,
    "scheduler_time": 59.10178090597676
}
#Debug simulation 
Total elapsed time: 6.9912884728983045. Arrivals time: 0.27135001542046666 Scheduler time: 6.548254480119795 Scheduler overhead time: 0.05935697304084897 Adapter cache time: 0.022409502416849136 Engine time: 0.061579212080687284 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-32/adapters_64_slots_64_rate_1.6-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-32/adapters_64_slots_64_rate_1.6-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [21 21 22]
Adapter prompts. [135, 270, 17280, 17280, 135, 17280, 135, 270, 135, 17280, 270, 17280, 135, 270, 17280, 17280, 17280, 135, 17280, 270, 270, 135, 135, 135, 17280, 135, 135, 135, 17280, 270, 135, 17280, 17280, 17280, 17280, 270, 270, 270, 17280, 135, 270, 270, 17280, 17280, 270, 17280, 135, 17280, 270, 270, 270, 17280, 270, 135, 135, 270, 270, 135, 270, 135, 135, 135, 17280, 270]
Prompts retrieved: 388665 . Total input tokens: 86768647 . Total output tokens: 76278364
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 6.755989971105009,
    "estimated_duration": 3600.055560408503,
    "input_throughput": 6645.642157057497,
    "output_throughput": 5756.28366070232,
    "total_throughput": 12401.925817759817,
    "itl": 75.96648580618685,
    "ttft": 1121237.5566666725,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4809837616281585,
    "arrivals": 129375,
    "finished_requests": 96094,
    "scheduler_time": 48.793905520695404
}
#Debug simulation 
Total elapsed time: 6.756087759975344. Arrivals time: 0.26678075501695275 Scheduler time: 6.298227542545646 Scheduler overhead time: 0.06646979553624988 Adapter cache time: 0.023629646748304367 Engine time: 0.06924423016607761 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-16-16/adapters_64_slots_64_rate_1.6-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-16-16/adapters_64_slots_64_rate_1.6-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [21 21 22]
Adapter prompts. [135, 270, 17280, 17280, 135, 17280, 135, 270, 135, 17280, 270, 17280, 135, 270, 17280, 17280, 17280, 135, 17280, 270, 270, 135, 135, 135, 17280, 135, 135, 135, 17280, 270, 135, 17280, 17280, 17280, 17280, 270, 270, 270, 17280, 135, 270, 270, 17280, 17280, 270, 17280, 135, 17280, 270, 270, 270, 17280, 270, 135, 135, 270, 270, 135, 270, 135, 135, 135, 17280, 270]
Prompts retrieved: 388665 . Total input tokens: 86768647 . Total output tokens: 76278364
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 7.005793387070298,
    "estimated_duration": 3600.0108889781923,
    "input_throughput": 6917.164910872815,
    "output_throughput": 5996.169085512664,
    "total_throughput": 12913.33399638548,
    "itl": 86.88746611752727,
    "ttft": 1054521.7469303403,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.43911180160939706,
    "arrivals": 129375,
    "finished_requests": 100097,
    "scheduler_time": 59.10212084803533
}
#Debug simulation 
Total elapsed time: 7.005899215117097. Arrivals time: 0.27408581180498004 Scheduler time: 6.5598792638629675 Scheduler overhead time: 0.059459093026816845 Adapter cache time: 0.022424971219152212 Engine time: 0.06161828292533755 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-16-32/adapters_64_slots_64_rate_1.6-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-16-32/adapters_64_slots_64_rate_1.6-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [21 21 22]
Adapter prompts. [135, 270, 17280, 17280, 135, 17280, 135, 270, 135, 17280, 270, 17280, 135, 270, 17280, 17280, 17280, 135, 17280, 270, 270, 135, 135, 135, 17280, 135, 135, 135, 17280, 270, 135, 17280, 17280, 17280, 17280, 270, 270, 270, 17280, 135, 270, 270, 17280, 17280, 270, 17280, 135, 17280, 270, 270, 270, 17280, 270, 135, 135, 270, 270, 135, 270, 135, 135, 135, 17280, 270]
Prompts retrieved: 388665 . Total input tokens: 86768647 . Total output tokens: 76278364
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 6.792062376160175,
    "estimated_duration": 3600.0377416547526,
    "input_throughput": 6645.8400486109285,
    "output_throughput": 5756.424928610482,
    "total_throughput": 12402.264977221412,
    "itl": 75.96529769134045,
    "ttft": 1121228.9922902863,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.47663430091924974,
    "arrivals": 129375,
    "finished_requests": 96095,
    "scheduler_time": 48.79401903887069
}
#Debug simulation 
Total elapsed time: 6.7921521118842065. Arrivals time: 0.2659065583720803 Scheduler time: 6.335300679784268 Scheduler overhead time: 0.06636743946000934 Adapter cache time: 0.023762624245136976 Engine time: 0.0690128868445754 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_16-16-16/adapters_64_slots_64_rate_1.6-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_16-16-16/adapters_64_slots_64_rate_1.6-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [21 21 22]
Adapter prompts. [135, 270, 17280, 17280, 135, 17280, 135, 270, 135, 17280, 270, 17280, 135, 270, 17280, 17280, 17280, 135, 17280, 270, 270, 135, 135, 135, 17280, 135, 135, 135, 17280, 270, 135, 17280, 17280, 17280, 17280, 270, 270, 270, 17280, 135, 270, 270, 17280, 17280, 270, 17280, 135, 17280, 270, 270, 270, 17280, 270, 135, 135, 270, 270, 135, 270, 135, 135, 135, 17280, 270]
Prompts retrieved: 388665 . Total input tokens: 86768647 . Total output tokens: 76278364
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 6.954589439090341,
    "estimated_duration": 3600.002046620803,
    "input_throughput": 6917.181900875451,
    "output_throughput": 5996.1838133570745,
    "total_throughput": 12913.365714232526,
    "itl": 86.88858080923723,
    "ttft": 1054521.2066731849,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4085709401965145,
    "arrivals": 129375,
    "finished_requests": 100097,
    "scheduler_time": 59.10152958298015
}
#Debug simulation 
Total elapsed time: 6.9546902370639145. Arrivals time: 0.27556924242526293 Scheduler time: 6.508220640476793 Scheduler overhead time: 0.0591687923297286 Adapter cache time: 0.02197188511490822 Engine time: 0.061376459896564484 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_16-16-32/adapters_64_slots_64_rate_1.6-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_16-16-32/adapters_64_slots_64_rate_1.6-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [21 21 22]
Adapter prompts. [135, 270, 17280, 17280, 135, 17280, 135, 270, 135, 17280, 270, 17280, 135, 270, 17280, 17280, 17280, 135, 17280, 270, 270, 135, 135, 135, 17280, 135, 135, 135, 17280, 270, 135, 17280, 17280, 17280, 17280, 270, 270, 270, 17280, 135, 270, 270, 17280, 17280, 270, 17280, 135, 17280, 270, 270, 270, 17280, 270, 135, 135, 270, 270, 135, 270, 135, 135, 135, 17280, 270]
Prompts retrieved: 388665 . Total input tokens: 86768647 . Total output tokens: 76278364
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 6.766277094837278,
    "estimated_duration": 3600.0747018998827,
    "input_throughput": 6645.938204386008,
    "output_throughput": 5756.425551131888,
    "total_throughput": 12402.363755517896,
    "itl": 75.96798803482132,
    "ttft": 1121189.1490676126,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.47207772303372625,
    "arrivals": 129375,
    "finished_requests": 96097,
    "scheduler_time": 48.79419008560437
}
#Debug simulation 
Total elapsed time: 6.766370690893382. Arrivals time: 0.2689890884794295 Scheduler time: 6.306512522511184 Scheduler overhead time: 0.06641034642234445 Adapter cache time: 0.023737586103379726 Engine time: 0.06908722128719091 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-8/adapters_64_slots_64_rate_1.6-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-8/adapters_64_slots_64_rate_1.6-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [21 21 22]
Adapter prompts. [66, 270, 17280, 17280, 66, 17280, 66, 270, 66, 17280, 270, 17280, 66, 270, 17280, 17280, 17280, 66, 17280, 270, 270, 66, 66, 66, 17280, 66, 66, 66, 17280, 270, 66, 17280, 17280, 17280, 17280, 270, 270, 270, 17280, 66, 270, 270, 17280, 17280, 270, 17280, 66, 17280, 270, 270, 270, 17280, 270, 66, 66, 270, 270, 66, 270, 66, 66, 66, 17280, 270]
Prompts retrieved: 387216 . Total input tokens: 86455484 . Total output tokens: 75990362
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 7.160685530863702,
    "estimated_duration": 3600.102332330961,
    "input_throughput": 7054.832517373322,
    "output_throughput": 6192.5164737096475,
    "total_throughput": 13247.348991082968,
    "itl": 92.85593565781099,
    "ttft": 1007262.8035129051,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.42319417804479564,
    "arrivals": 128882,
    "finished_requests": 102861,
    "scheduler_time": 65.69015337518017
}
#Debug simulation 
Total elapsed time: 7.160774366930127. Arrivals time: 0.2763755959458649 Scheduler time: 6.723685929086059 Scheduler overhead time: 0.05610848916694522 Adapter cache time: 0.019452138338238 Engine time: 0.05853747809305787 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-16/adapters_64_slots_64_rate_1.6-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-16/adapters_64_slots_64_rate_1.6-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [21 21 22]
Adapter prompts. [66, 270, 17280, 17280, 66, 17280, 66, 270, 66, 17280, 270, 17280, 66, 270, 17280, 17280, 17280, 66, 17280, 270, 270, 66, 66, 66, 17280, 66, 66, 66, 17280, 270, 66, 17280, 17280, 17280, 17280, 270, 270, 270, 17280, 66, 270, 270, 17280, 17280, 270, 17280, 66, 17280, 270, 270, 270, 17280, 270, 66, 66, 270, 270, 66, 270, 66, 66, 66, 17280, 270]
Prompts retrieved: 387216 . Total input tokens: 86455484 . Total output tokens: 75990362
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 7.074931115843356,
    "estimated_duration": 3600.0824448746384,
    "input_throughput": 6917.804072919565,
    "output_throughput": 6070.596808446429,
    "total_throughput": 12988.400881365995,
    "itl": 86.12143287277404,
    "ttft": 1043669.2198801045,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4682644420489666,
    "arrivals": 128882,
    "finished_requests": 100829,
    "scheduler_time": 60.34400744455385
}
#Debug simulation 
Total elapsed time: 7.075026501901448. Arrivals time: 0.28859273018315434 Scheduler time: 6.614264109637588 Scheduler overhead time: 0.060346654150635004 Adapter cache time: 0.020373306702822447 Engine time: 0.0627772300504148 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-32/adapters_64_slots_64_rate_1.6-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-32/adapters_64_slots_64_rate_1.6-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [21 21 22]
Adapter prompts. [66, 270, 17280, 17280, 66, 17280, 66, 270, 66, 17280, 270, 17280, 66, 270, 17280, 17280, 17280, 66, 17280, 270, 270, 66, 66, 66, 17280, 66, 66, 66, 17280, 270, 66, 17280, 17280, 17280, 17280, 270, 270, 270, 17280, 66, 270, 270, 17280, 17280, 270, 17280, 66, 17280, 270, 270, 270, 17280, 270, 66, 66, 270, 270, 66, 270, 66, 66, 66, 17280, 270]
Prompts retrieved: 387216 . Total input tokens: 86455484 . Total output tokens: 75990362
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 6.845540111884475,
    "estimated_duration": 3600.053715367731,
    "input_throughput": 6632.40964935465,
    "output_throughput": 5820.32121091829,
    "total_throughput": 12452.73086027294,
    "itl": 75.37593460635813,
    "ttft": 1112356.3646442762,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4809837616281585,
    "arrivals": 128882,
    "finished_requests": 96639,
    "scheduler_time": 49.66289433605989
}
#Debug simulation 
Total elapsed time: 6.845689022913575. Arrivals time: 0.27058585500344634 Scheduler time: 6.384985134471208 Scheduler overhead time: 0.0667808623984456 Adapter cache time: 0.021708006970584393 Engine time: 0.06960838055238128 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-16-16/adapters_64_slots_64_rate_1.6-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-16-16/adapters_64_slots_64_rate_1.6-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [21 21 22]
Adapter prompts. [66, 270, 17280, 17280, 66, 17280, 66, 270, 66, 17280, 270, 17280, 66, 270, 17280, 17280, 17280, 66, 17280, 270, 270, 66, 66, 66, 17280, 66, 66, 66, 17280, 270, 66, 17280, 17280, 17280, 17280, 270, 270, 270, 17280, 66, 270, 270, 17280, 17280, 270, 17280, 66, 17280, 270, 270, 270, 17280, 270, 66, 66, 270, 270, 66, 270, 66, 66, 66, 17280, 270]
Prompts retrieved: 387216 . Total input tokens: 86455484 . Total output tokens: 75990362
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 7.0711838118731976,
    "estimated_duration": 3600.0541187792683,
    "input_throughput": 6918.241831443722,
    "output_throughput": 6070.926791348063,
    "total_throughput": 12989.168622791785,
    "itl": 86.11973007348345,
    "ttft": 1043535.4239712681,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.439111801609397,
    "arrivals": 128882,
    "finished_requests": 100835,
    "scheduler_time": 60.34842218434212
}
#Debug simulation 
Total elapsed time: 7.071294179651886. Arrivals time: 0.2751107322983444 Scheduler time: 6.624657312873751 Scheduler overhead time: 0.06002567010000348 Adapter cache time: 0.020146939903497696 Engine time: 0.06274173595011234 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-16-32/adapters_64_slots_64_rate_1.6-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-16-32/adapters_64_slots_64_rate_1.6-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [21 21 22]
Adapter prompts. [66, 270, 17280, 17280, 66, 17280, 66, 270, 66, 17280, 270, 17280, 66, 270, 17280, 17280, 17280, 66, 17280, 270, 270, 66, 66, 66, 17280, 66, 66, 66, 17280, 270, 66, 17280, 17280, 17280, 17280, 270, 270, 270, 17280, 66, 270, 270, 17280, 17280, 270, 17280, 66, 17280, 270, 270, 270, 17280, 270, 66, 66, 270, 270, 66, 270, 66, 66, 66, 17280, 270]
Prompts retrieved: 387216 . Total input tokens: 86455484 . Total output tokens: 75990362
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 6.830977893434465,
    "estimated_duration": 3600.0766663426125,
    "input_throughput": 6632.248758262335,
    "output_throughput": 5820.258828345159,
    "total_throughput": 12452.507586607495,
    "itl": 75.37569954422626,
    "ttft": 1112387.5343233186,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.47663430091924974,
    "arrivals": 128882,
    "finished_requests": 96638,
    "scheduler_time": 49.66232101488705
}
#Debug simulation 
Total elapsed time: 6.831087093334645. Arrivals time: 0.2716903630644083 Scheduler time: 6.368818538729101 Scheduler overhead time: 0.06702465936541557 Adapter cache time: 0.021786301396787167 Engine time: 0.06962370499968529 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_16-16-16/adapters_64_slots_64_rate_1.6-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_16-16-16/adapters_64_slots_64_rate_1.6-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [21 21 22]
Adapter prompts. [66, 270, 17280, 17280, 66, 17280, 66, 270, 66, 17280, 270, 17280, 66, 270, 17280, 17280, 17280, 66, 17280, 270, 270, 66, 66, 66, 17280, 66, 66, 66, 17280, 270, 66, 17280, 17280, 17280, 17280, 270, 270, 270, 17280, 66, 270, 270, 17280, 17280, 270, 17280, 66, 17280, 270, 270, 270, 17280, 270, 66, 66, 270, 270, 66, 270, 66, 66, 66, 17280, 270]
Prompts retrieved: 387216 . Total input tokens: 86455484 . Total output tokens: 75990362
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 7.0719028557650745,
    "estimated_duration": 3600.0698540196,
    "input_throughput": 6918.071595803098,
    "output_throughput": 6070.884701194748,
    "total_throughput": 12988.956296997847,
    "itl": 86.11918000913562,
    "ttft": 1043591.7835022861,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4085709401965145,
    "arrivals": 128882,
    "finished_requests": 100833,
    "scheduler_time": 60.34735652282748
}
#Debug simulation 
Total elapsed time: 7.071995184756815. Arrivals time: 0.2760685351677239 Scheduler time: 6.62457815464586 Scheduler overhead time: 0.06004975037649274 Adapter cache time: 0.020372174214571714 Engine time: 0.06231179367750883 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_16-16-32/adapters_64_slots_64_rate_1.6-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_16-16-32/adapters_64_slots_64_rate_1.6-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [21 21 22]
Adapter prompts. [66, 270, 17280, 17280, 66, 17280, 66, 270, 66, 17280, 270, 17280, 66, 270, 17280, 17280, 17280, 66, 17280, 270, 270, 66, 66, 66, 17280, 66, 66, 66, 17280, 270, 66, 17280, 17280, 17280, 17280, 270, 270, 270, 17280, 66, 270, 270, 17280, 17280, 270, 17280, 66, 17280, 270, 270, 270, 17280, 270, 66, 66, 270, 270, 66, 270, 66, 66, 66, 17280, 270]
Prompts retrieved: 387216 . Total input tokens: 86455484 . Total output tokens: 75990362
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 6.845373869873583,
    "estimated_duration": 3600.048363059067,
    "input_throughput": 6632.276178565397,
    "output_throughput": 5820.274587143432,
    "total_throughput": 12452.55076570883,
    "itl": 75.37533980536492,
    "ttft": 1112322.8420283375,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4720777230337263,
    "arrivals": 128882,
    "finished_requests": 96637,
    "scheduler_time": 49.661436463809686
}
#Debug simulation 
Total elapsed time: 6.845463609788567. Arrivals time: 0.2817062698304653 Scheduler time: 6.3730102479457855 Scheduler overhead time: 0.0669430154375732 Adapter cache time: 0.02171774674206972 Engine time: 0.07023316342383623 
