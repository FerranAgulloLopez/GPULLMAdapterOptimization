INFO 05-31 19:30:51 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 05-31 19:30:52 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-16-16/adapters_160_slots_64_rate_1.6-0.1-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-16-16/adapters_160_slots_64_rate_1.6-0.1-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [53 53 54]
Adapter prompts. [135, 17280, 135, 135, 1080, 135, 135, 135, 17280, 135, 1080, 17280, 1080, 135, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 135, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 135, 1080, 1080, 1080, 17280, 135, 135, 17280, 135, 17280, 135, 135, 1080, 135, 1080, 17280, 135, 135, 1080, 135, 135, 135, 135, 135, 17280, 1080, 1080, 17280, 1080, 135, 17280, 17280, 17280, 1080, 1080, 135, 135, 135, 17280, 135, 1080, 1080, 135, 17280, 17280, 17280, 135, 135, 17280, 1080, 17280, 17280, 135, 17280, 135, 1080, 135, 135, 1080, 1080, 17280, 17280, 17280, 135, 17280, 1080, 1080, 135, 135, 135, 135, 17280, 1080, 17280, 1080, 17280, 17280, 17280, 135, 1080, 1080, 17280, 1080, 17280, 135, 135, 135, 1080, 1080, 1080, 17280, 17280, 1080, 17280, 135, 1080, 1080, 135, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 17280, 135, 17280, 135, 17280, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 17280, 1080, 135, 135]
Prompts retrieved: 997515 . Total input tokens: 222433513 . Total output tokens: 196181963
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 7.241993135306984,
    "estimated_duration": 3600.084374893826,
    "input_throughput": 5443.217424752143,
    "output_throughput": 4749.2117460453255,
    "total_throughput": 10192.429170797468,
    "itl": 110.69114295502723,
    "ttft": 1910274.717459134,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 645,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.4258140627434415,
    "arrivals": 332795,
    "finished_requests": 79039,
    "scheduler_time": 149.18925596882718
}
#Debug simulation 
Total elapsed time: 7.242099351249635. Arrivals time: 0.23344790562987328 Scheduler time: 6.8696900573559105 Scheduler overhead time: 0.051629068329930305 Adapter cache time: 0.015098412986844778 Engine time: 0.04953163955360651 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-16-32/adapters_160_slots_64_rate_1.6-0.1-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-16-32/adapters_160_slots_64_rate_1.6-0.1-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [53 53 54]
Adapter prompts. [135, 17280, 135, 135, 1080, 135, 135, 135, 17280, 135, 1080, 17280, 1080, 135, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 135, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 135, 1080, 1080, 1080, 17280, 135, 135, 17280, 135, 17280, 135, 135, 1080, 135, 1080, 17280, 135, 135, 1080, 135, 135, 135, 135, 135, 17280, 1080, 1080, 17280, 1080, 135, 17280, 17280, 17280, 1080, 1080, 135, 135, 135, 17280, 135, 1080, 1080, 135, 17280, 17280, 17280, 135, 135, 17280, 1080, 17280, 17280, 135, 17280, 135, 1080, 135, 135, 1080, 1080, 17280, 17280, 17280, 135, 17280, 1080, 1080, 135, 135, 135, 135, 17280, 1080, 17280, 1080, 17280, 17280, 17280, 135, 1080, 1080, 17280, 1080, 17280, 135, 135, 135, 1080, 1080, 1080, 17280, 17280, 1080, 17280, 135, 1080, 1080, 135, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 17280, 135, 17280, 135, 17280, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 17280, 1080, 135, 135]
Prompts retrieved: 997515 . Total input tokens: 222433513 . Total output tokens: 196181963
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 6.5782890929840505,
    "estimated_duration": 3600.0550458358584,
    "input_throughput": 5131.9176414732965,
    "output_throughput": 4491.918816270597,
    "total_throughput": 9623.836457743893,
    "itl": 98.39378079842503,
    "ttft": 1952745.2740233287,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 845,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.284094932880275,
    "arrivals": 332795,
    "finished_requests": 74633,
    "scheduler_time": 155.46702343643346
}
#Debug simulation 
Total elapsed time: 6.5783994900994. Arrivals time: 0.23507025837898254 Scheduler time: 6.188510928303003 Scheduler overhead time: 0.05823307251557708 Adapter cache time: 0.018098681699484587 Engine time: 0.05347392940893769 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_16-16-16/adapters_160_slots_64_rate_1.6-0.1-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_16-16-16/adapters_160_slots_64_rate_1.6-0.1-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [53 53 54]
Adapter prompts. [135, 17280, 135, 135, 1080, 135, 135, 135, 17280, 135, 1080, 17280, 1080, 135, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 135, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 135, 1080, 1080, 1080, 17280, 135, 135, 17280, 135, 17280, 135, 135, 1080, 135, 1080, 17280, 135, 135, 1080, 135, 135, 135, 135, 135, 17280, 1080, 1080, 17280, 1080, 135, 17280, 17280, 17280, 1080, 1080, 135, 135, 135, 17280, 135, 1080, 1080, 135, 17280, 17280, 17280, 135, 135, 17280, 1080, 17280, 17280, 135, 17280, 135, 1080, 135, 135, 1080, 1080, 17280, 17280, 17280, 135, 17280, 1080, 1080, 135, 135, 135, 135, 17280, 1080, 17280, 1080, 17280, 17280, 17280, 135, 1080, 1080, 17280, 1080, 17280, 135, 135, 135, 1080, 1080, 1080, 17280, 17280, 1080, 17280, 135, 1080, 1080, 135, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 17280, 135, 17280, 135, 17280, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 17280, 1080, 135, 135]
Prompts retrieved: 997515 . Total input tokens: 222433513 . Total output tokens: 196181963
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 7.312541905790567,
    "estimated_duration": 3600.0833782185227,
    "input_throughput": 5445.958868236505,
    "output_throughput": 4749.976376508806,
    "total_throughput": 10195.935244745311,
    "itl": 110.67770656025397,
    "ttft": 1910528.641710851,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 624,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.983566666915994,
    "arrivals": 332795,
    "finished_requests": 79069,
    "scheduler_time": 149.19947648727143
}
#Debug simulation 
Total elapsed time: 7.312630998902023. Arrivals time: 0.24888154305517673 Scheduler time: 6.9257983532734215 Scheduler overhead time: 0.051233535166829824 Adapter cache time: 0.015033788979053497 Engine time: 0.04898732667788863 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_16-16-32/adapters_160_slots_64_rate_1.6-0.1-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_16-16-32/adapters_160_slots_64_rate_1.6-0.1-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [53 53 54]
Adapter prompts. [135, 17280, 135, 135, 1080, 135, 135, 135, 17280, 135, 1080, 17280, 1080, 135, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 135, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 135, 1080, 1080, 1080, 17280, 135, 135, 17280, 135, 17280, 135, 135, 1080, 135, 1080, 17280, 135, 135, 1080, 135, 135, 135, 135, 135, 17280, 1080, 1080, 17280, 1080, 135, 17280, 17280, 17280, 1080, 1080, 135, 135, 135, 17280, 135, 1080, 1080, 135, 17280, 17280, 17280, 135, 135, 17280, 1080, 17280, 17280, 135, 17280, 135, 1080, 135, 135, 1080, 1080, 17280, 17280, 17280, 135, 17280, 1080, 1080, 135, 135, 135, 135, 17280, 1080, 17280, 1080, 17280, 17280, 17280, 135, 1080, 1080, 17280, 1080, 17280, 135, 135, 135, 1080, 1080, 1080, 17280, 17280, 1080, 17280, 135, 1080, 1080, 135, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 17280, 135, 17280, 135, 17280, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 17280, 1080, 135, 135]
Prompts retrieved: 997515 . Total input tokens: 222433513 . Total output tokens: 196181963
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 6.5790546289645135,
    "estimated_duration": 3600.0981839015963,
    "input_throughput": 5131.523657496159,
    "output_throughput": 4491.343339552087,
    "total_throughput": 9622.866997048246,
    "itl": 98.37769835641184,
    "ttft": 1952759.7378844048,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 864,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.3662916594743955,
    "arrivals": 332795,
    "finished_requests": 74623,
    "scheduler_time": 155.47351860741557
}
#Debug simulation 
Total elapsed time: 6.579141927883029. Arrivals time: 0.2372648953460157 Scheduler time: 6.188204086851329 Scheduler overhead time: 0.05629404913634062 Adapter cache time: 0.018179606646299362 Engine time: 0.054191586561501026 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-8/adapters_160_slots_64_rate_1.6-0.1-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-8/adapters_160_slots_64_rate_1.6-0.1-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 1080, 66, 66, 66, 17280, 66, 1080, 17280, 1080, 66, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 66, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 66, 1080, 1080, 1080, 17280, 66, 66, 17280, 66, 17280, 66, 66, 1080, 66, 1080, 17280, 66, 66, 1080, 66, 66, 66, 66, 66, 17280, 1080, 1080, 17280, 1080, 66, 17280, 17280, 17280, 1080, 1080, 66, 66, 66, 17280, 66, 1080, 1080, 66, 17280, 17280, 17280, 66, 66, 17280, 1080, 17280, 17280, 66, 17280, 66, 1080, 66, 66, 1080, 1080, 17280, 17280, 17280, 66, 17280, 1080, 1080, 66, 66, 66, 66, 17280, 1080, 17280, 1080, 17280, 17280, 17280, 66, 1080, 1080, 17280, 1080, 17280, 66, 66, 66, 1080, 1080, 1080, 17280, 17280, 1080, 17280, 66, 1080, 1080, 66, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 17280, 66, 17280, 66, 17280, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 17280, 1080, 66, 66]
Prompts retrieved: 993858 . Total input tokens: 221622877 . Total output tokens: 195469147
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 7.393886911217123,
    "estimated_duration": 3600.067523197691,
    "input_throughput": 5614.021923135511,
    "output_throughput": 4887.796100104905,
    "total_throughput": 10501.818023240417,
    "itl": 118.48972184656488,
    "ttft": 1878464.6120676226,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 572,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.782297966275419,
    "arrivals": 331579,
    "finished_requests": 81662,
    "scheduler_time": 145.6955459361427
}
#Debug simulation 
Total elapsed time: 7.393982196226716. Arrivals time: 0.2818450788035989 Scheduler time: 6.9807884893380105 Scheduler overhead time: 0.04850344732403755 Adapter cache time: 0.014348503667861223 Engine time: 0.04704669304192066 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-16/adapters_160_slots_64_rate_1.6-0.1-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-16/adapters_160_slots_64_rate_1.6-0.1-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 1080, 66, 66, 66, 17280, 66, 1080, 17280, 1080, 66, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 66, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 66, 1080, 1080, 1080, 17280, 66, 66, 17280, 66, 17280, 66, 66, 1080, 66, 1080, 17280, 66, 66, 1080, 66, 66, 66, 66, 66, 17280, 1080, 1080, 17280, 1080, 66, 17280, 17280, 17280, 1080, 1080, 66, 66, 66, 17280, 66, 1080, 1080, 66, 17280, 17280, 17280, 66, 66, 17280, 1080, 17280, 17280, 66, 17280, 66, 1080, 66, 66, 1080, 1080, 17280, 17280, 17280, 66, 17280, 1080, 1080, 66, 66, 66, 66, 17280, 1080, 17280, 1080, 17280, 17280, 17280, 66, 1080, 1080, 17280, 1080, 17280, 66, 66, 66, 1080, 1080, 1080, 17280, 17280, 1080, 17280, 66, 1080, 1080, 66, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 17280, 66, 17280, 66, 17280, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 17280, 1080, 66, 66]
Prompts retrieved: 993858 . Total input tokens: 221622877 . Total output tokens: 195469147
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 7.245626981835812,
    "estimated_duration": 3600.0167231282903,
    "input_throughput": 5459.35908401046,
    "output_throughput": 4749.481548280765,
    "total_throughput": 10208.840632291225,
    "itl": 110.70950055520615,
    "ttft": 1898737.6530301326,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 656,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.794504702351994,
    "arrivals": 331579,
    "finished_requests": 79369,
    "scheduler_time": 148.97539516228747
}
#Debug simulation 
Total elapsed time: 7.245723566040397. Arrivals time: 0.5063237524591386 Scheduler time: 6.5999607178382576 Scheduler overhead time: 0.05151586700230837 Adapter cache time: 0.01562244538217783 Engine time: 0.04950274946168065 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-32/adapters_160_slots_64_rate_1.6-0.1-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-32/adapters_160_slots_64_rate_1.6-0.1-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 1080, 66, 66, 66, 17280, 66, 1080, 17280, 1080, 66, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 66, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 66, 1080, 1080, 1080, 17280, 66, 66, 17280, 66, 17280, 66, 66, 1080, 66, 1080, 17280, 66, 66, 1080, 66, 66, 66, 66, 66, 17280, 1080, 1080, 17280, 1080, 66, 17280, 17280, 17280, 1080, 1080, 66, 66, 66, 17280, 66, 1080, 1080, 66, 17280, 17280, 17280, 66, 66, 17280, 1080, 17280, 17280, 66, 17280, 66, 1080, 66, 66, 1080, 1080, 17280, 17280, 17280, 66, 17280, 1080, 1080, 66, 66, 66, 66, 17280, 1080, 17280, 1080, 17280, 17280, 17280, 66, 1080, 1080, 17280, 1080, 17280, 66, 66, 66, 1080, 1080, 1080, 17280, 17280, 1080, 17280, 66, 1080, 1080, 66, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 17280, 66, 17280, 66, 17280, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 17280, 1080, 66, 66]
Prompts retrieved: 993858 . Total input tokens: 221622877 . Total output tokens: 195469147
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 6.409404001198709,
    "estimated_duration": 3600.058252025712,
    "input_throughput": 5154.497150027634,
    "output_throughput": 4491.914538021899,
    "total_throughput": 9646.411688049533,
    "itl": 98.30905625507587,
    "ttft": 1940212.5215875786,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 795,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.965935831102566,
    "arrivals": 331579,
    "finished_requests": 74949,
    "scheduler_time": 155.32510988385016
}
#Debug simulation 
Total elapsed time: 6.409498051274568. Arrivals time: 0.23804368218407035 Scheduler time: 6.017974142916501 Scheduler overhead time: 0.0564634227193892 Adapter cache time: 0.017751645296812057 Engine time: 0.05424886476248503 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-16-16/adapters_160_slots_64_rate_1.6-0.1-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-16-16/adapters_160_slots_64_rate_1.6-0.1-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 1080, 66, 66, 66, 17280, 66, 1080, 17280, 1080, 66, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 66, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 66, 1080, 1080, 1080, 17280, 66, 66, 17280, 66, 17280, 66, 66, 1080, 66, 1080, 17280, 66, 66, 1080, 66, 66, 66, 66, 66, 17280, 1080, 1080, 17280, 1080, 66, 17280, 17280, 17280, 1080, 1080, 66, 66, 66, 17280, 66, 1080, 1080, 66, 17280, 17280, 17280, 66, 66, 17280, 1080, 17280, 17280, 66, 17280, 66, 1080, 66, 66, 1080, 1080, 17280, 17280, 17280, 66, 17280, 1080, 1080, 66, 66, 66, 66, 17280, 1080, 17280, 1080, 17280, 17280, 17280, 66, 1080, 1080, 17280, 1080, 17280, 66, 66, 66, 1080, 1080, 1080, 17280, 17280, 1080, 17280, 66, 1080, 1080, 66, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 17280, 66, 17280, 66, 17280, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 17280, 1080, 66, 66]
Prompts retrieved: 993858 . Total input tokens: 221622877 . Total output tokens: 195469147
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 7.0187401180155575,
    "estimated_duration": 3600.05546696276,
    "input_throughput": 5459.776156333128,
    "output_throughput": 4750.051258078823,
    "total_throughput": 10209.82741441195,
    "itl": 110.70217244737464,
    "ttft": 1898650.789998702,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 650,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.457733667446294,
    "arrivals": 331579,
    "finished_requests": 79377,
    "scheduler_time": 148.99042685624326
}
#Debug simulation 
Total elapsed time: 7.018861135933548. Arrivals time: 0.24864191189408302 Scheduler time: 6.630547641776502 Scheduler overhead time: 0.05133348936215043 Adapter cache time: 0.015646676998585463 Engine time: 0.049937432166188955 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-16-32/adapters_160_slots_64_rate_1.6-0.1-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-16-32/adapters_160_slots_64_rate_1.6-0.1-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 1080, 66, 66, 66, 17280, 66, 1080, 17280, 1080, 66, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 66, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 66, 1080, 1080, 1080, 17280, 66, 66, 17280, 66, 17280, 66, 66, 1080, 66, 1080, 17280, 66, 66, 1080, 66, 66, 66, 66, 66, 17280, 1080, 1080, 17280, 1080, 66, 17280, 17280, 17280, 1080, 1080, 66, 66, 66, 17280, 66, 1080, 1080, 66, 17280, 17280, 17280, 66, 66, 17280, 1080, 17280, 17280, 66, 17280, 66, 1080, 66, 66, 1080, 1080, 17280, 17280, 17280, 66, 17280, 1080, 1080, 66, 66, 66, 66, 17280, 1080, 17280, 1080, 17280, 17280, 17280, 66, 1080, 1080, 17280, 1080, 17280, 66, 66, 66, 1080, 1080, 1080, 17280, 17280, 1080, 17280, 66, 1080, 1080, 66, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 17280, 66, 17280, 66, 17280, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 17280, 1080, 66, 66]
Prompts retrieved: 993858 . Total input tokens: 221622877 . Total output tokens: 195469147
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 6.373112302273512,
    "estimated_duration": 3600.0095814573856,
    "input_throughput": 5154.053226849624,
    "output_throughput": 4492.220543883414,
    "total_throughput": 9646.273770733038,
    "itl": 98.31080948958983,
    "ttft": 1940280.5660554778,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 807,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.999573876005621,
    "arrivals": 331579,
    "finished_requests": 74944,
    "scheduler_time": 155.32294965366447
}
#Debug simulation 
Total elapsed time: 6.373232344165444. Arrivals time: 0.26778061827644706 Scheduler time: 5.953269531019032 Scheduler overhead time: 0.055744463577866554 Adapter cache time: 0.017949345521628857 Engine time: 0.05361679708585143 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_16-16-16/adapters_160_slots_64_rate_1.6-0.1-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_16-16-16/adapters_160_slots_64_rate_1.6-0.1-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 1080, 66, 66, 66, 17280, 66, 1080, 17280, 1080, 66, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 66, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 66, 1080, 1080, 1080, 17280, 66, 66, 17280, 66, 17280, 66, 66, 1080, 66, 1080, 17280, 66, 66, 1080, 66, 66, 66, 66, 66, 17280, 1080, 1080, 17280, 1080, 66, 17280, 17280, 17280, 1080, 1080, 66, 66, 66, 17280, 66, 1080, 1080, 66, 17280, 17280, 17280, 66, 66, 17280, 1080, 17280, 17280, 66, 17280, 66, 1080, 66, 66, 1080, 1080, 17280, 17280, 17280, 66, 17280, 1080, 1080, 66, 66, 66, 66, 17280, 1080, 17280, 1080, 17280, 17280, 17280, 66, 1080, 1080, 17280, 1080, 17280, 66, 66, 66, 1080, 1080, 1080, 17280, 17280, 1080, 17280, 66, 1080, 1080, 66, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 17280, 66, 17280, 66, 17280, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 17280, 1080, 66, 66]
Prompts retrieved: 993858 . Total input tokens: 221622877 . Total output tokens: 195469147
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 6.964818210806698,
    "estimated_duration": 3600.047427667173,
    "input_throughput": 5461.766378100568,
    "output_throughput": 4751.510179710174,
    "total_throughput": 10213.276557810741,
    "itl": 110.69111271346812,
    "ttft": 1898746.865172302,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 644,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.111245085727404,
    "arrivals": 331579,
    "finished_requests": 79397,
    "scheduler_time": 149.001960360121
}
#Debug simulation 
Total elapsed time: 6.964937760028988. Arrivals time: 0.28366601886227727 Scheduler time: 6.54190188460052 Scheduler overhead time: 0.051500811241567135 Adapter cache time: 0.015452117659151554 Engine time: 0.04965407447889447 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_16-16-32/adapters_160_slots_64_rate_1.6-0.1-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_16-16-32/adapters_160_slots_64_rate_1.6-0.1-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 1080, 66, 66, 66, 17280, 66, 1080, 17280, 1080, 66, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 66, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 66, 1080, 1080, 1080, 17280, 66, 66, 17280, 66, 17280, 66, 66, 1080, 66, 1080, 17280, 66, 66, 1080, 66, 66, 66, 66, 66, 17280, 1080, 1080, 17280, 1080, 66, 17280, 17280, 17280, 1080, 1080, 66, 66, 66, 17280, 66, 1080, 1080, 66, 17280, 17280, 17280, 66, 66, 17280, 1080, 17280, 17280, 66, 17280, 66, 1080, 66, 66, 1080, 1080, 17280, 17280, 17280, 66, 17280, 1080, 1080, 66, 66, 66, 66, 17280, 1080, 17280, 1080, 17280, 17280, 17280, 66, 1080, 1080, 17280, 1080, 17280, 66, 66, 66, 1080, 1080, 1080, 17280, 17280, 1080, 17280, 66, 1080, 1080, 66, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 17280, 66, 17280, 66, 17280, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 17280, 1080, 66, 66]
Prompts retrieved: 993858 . Total input tokens: 221622877 . Total output tokens: 195469147
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 6.370349373202771,
    "estimated_duration": 3600.0914785083546,
    "input_throughput": 5154.108197186173,
    "output_throughput": 4491.822804097246,
    "total_throughput": 9645.93100128342,
    "itl": 98.30833601677436,
    "ttft": 1940083.449104278,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 805,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.926050271336013,
    "arrivals": 331579,
    "finished_requests": 74938,
    "scheduler_time": 155.33005361262693
}
#Debug simulation 
Total elapsed time: 6.370441149920225. Arrivals time: 0.2396997669711709 Scheduler time: 5.977476321160793 Scheduler overhead time: 0.05645988043397665 Adapter cache time: 0.01793665438890457 Engine time: 0.053896005265414715 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-8/adapters_160_slots_64_rate_1.6-0.1-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-8/adapters_160_slots_64_rate_1.6-0.1-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 1080, 33, 33, 33, 17280, 33, 1080, 17280, 1080, 33, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 33, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 33, 1080, 1080, 1080, 17280, 33, 33, 17280, 33, 17280, 33, 33, 1080, 33, 1080, 17280, 33, 33, 1080, 33, 33, 33, 33, 33, 17280, 1080, 1080, 17280, 1080, 33, 17280, 17280, 17280, 1080, 1080, 33, 33, 33, 17280, 33, 1080, 1080, 33, 17280, 17280, 17280, 33, 33, 17280, 1080, 17280, 17280, 33, 17280, 33, 1080, 33, 33, 1080, 1080, 17280, 17280, 17280, 33, 17280, 1080, 1080, 33, 33, 33, 33, 17280, 1080, 17280, 1080, 17280, 17280, 17280, 33, 1080, 1080, 17280, 1080, 17280, 33, 33, 33, 1080, 1080, 1080, 17280, 17280, 1080, 17280, 33, 1080, 1080, 33, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 17280, 33, 17280, 33, 17280, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 17280, 1080, 33, 33]
Prompts retrieved: 992109 . Total input tokens: 221209647 . Total output tokens: 195121829
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 7.142014427110553,
    "estimated_duration": 3600.104884742367,
    "input_throughput": 5617.539390507858,
    "output_throughput": 4876.139602042804,
    "total_throughput": 10493.678992550662,
    "itl": 117.87995867871479,
    "ttft": 1880208.7925587075,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 556,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.6764994217642166,
    "arrivals": 330904,
    "finished_requests": 81315,
    "scheduler_time": 145.92207425050822
}
#Debug simulation 
Total elapsed time: 7.142141430173069. Arrivals time: 0.271949436981231 Scheduler time: 6.738522185944021 Scheduler overhead time: 0.049153296276926994 Adapter cache time: 0.01391346100717783 Engine time: 0.04702069563791156 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-16/adapters_160_slots_64_rate_1.6-0.1-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-16/adapters_160_slots_64_rate_1.6-0.1-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 1080, 33, 33, 33, 17280, 33, 1080, 17280, 1080, 33, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 33, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 33, 1080, 1080, 1080, 17280, 33, 33, 17280, 33, 17280, 33, 33, 1080, 33, 1080, 17280, 33, 33, 1080, 33, 33, 33, 33, 33, 17280, 1080, 1080, 17280, 1080, 33, 17280, 17280, 17280, 1080, 1080, 33, 33, 33, 17280, 33, 1080, 1080, 33, 17280, 17280, 17280, 33, 33, 17280, 1080, 17280, 17280, 33, 17280, 33, 1080, 33, 33, 1080, 1080, 17280, 17280, 17280, 33, 17280, 1080, 1080, 33, 33, 33, 33, 17280, 1080, 17280, 1080, 17280, 17280, 17280, 33, 1080, 1080, 17280, 1080, 17280, 33, 33, 33, 1080, 1080, 1080, 17280, 17280, 1080, 17280, 33, 1080, 1080, 33, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 17280, 33, 17280, 33, 17280, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 17280, 1080, 33, 33]
Prompts retrieved: 992109 . Total input tokens: 221209647 . Total output tokens: 195121829
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 6.7357244859449565,
    "estimated_duration": 3600.0003931707056,
    "input_throughput": 5459.706903723107,
    "output_throughput": 4743.674481923932,
    "total_throughput": 10203.381385647039,
    "itl": 110.2398279165319,
    "ttft": 1901992.5894434773,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 599,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.373704148833646,
    "arrivals": 330904,
    "finished_requests": 79088,
    "scheduler_time": 149.177202220056
}
#Debug simulation 
Total elapsed time: 6.735838007647544. Arrivals time: 0.25970432069152594 Scheduler time: 6.338189353700727 Scheduler overhead time: 0.05126779526472092 Adapter cache time: 0.014746583998203278 Engine time: 0.04912921693176031 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-32/adapters_160_slots_64_rate_1.6-0.1-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-32/adapters_160_slots_64_rate_1.6-0.1-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 1080, 33, 33, 33, 17280, 33, 1080, 17280, 1080, 33, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 33, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 33, 1080, 1080, 1080, 17280, 33, 33, 17280, 33, 17280, 33, 33, 1080, 33, 1080, 17280, 33, 33, 1080, 33, 33, 33, 33, 33, 17280, 1080, 1080, 17280, 1080, 33, 17280, 17280, 17280, 1080, 1080, 33, 33, 33, 17280, 33, 1080, 1080, 33, 17280, 17280, 17280, 33, 33, 17280, 1080, 17280, 17280, 33, 17280, 33, 1080, 33, 33, 1080, 1080, 17280, 17280, 17280, 33, 17280, 1080, 1080, 33, 33, 33, 33, 17280, 1080, 17280, 1080, 17280, 17280, 17280, 33, 1080, 1080, 17280, 1080, 17280, 33, 33, 33, 1080, 1080, 1080, 17280, 17280, 1080, 17280, 33, 1080, 1080, 33, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 17280, 33, 17280, 33, 17280, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 17280, 1080, 33, 33]
Prompts retrieved: 992109 . Total input tokens: 221209647 . Total output tokens: 195121829
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 6.248430300038308,
    "estimated_duration": 3600.0380078760277,
    "input_throughput": 5153.806976317604,
    "output_throughput": 4484.605430464657,
    "total_throughput": 9638.412406782261,
    "itl": 97.9699629409561,
    "ttft": 1944430.0264207039,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 772,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.785312562692006,
    "arrivals": 330904,
    "finished_requests": 74782,
    "scheduler_time": 155.48461293144692
}
#Debug simulation 
Total elapsed time: 6.248548218049109. Arrivals time: 0.23643419006839395 Scheduler time: 5.858609523624182 Scheduler overhead time: 0.05676245130598545 Adapter cache time: 0.017508758697658777 Engine time: 0.05409448314458132 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-16-16/adapters_160_slots_64_rate_1.6-0.1-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-16-16/adapters_160_slots_64_rate_1.6-0.1-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 1080, 33, 33, 33, 17280, 33, 1080, 17280, 1080, 33, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 33, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 33, 1080, 1080, 1080, 17280, 33, 33, 17280, 33, 17280, 33, 33, 1080, 33, 1080, 17280, 33, 33, 1080, 33, 33, 33, 33, 33, 17280, 1080, 1080, 17280, 1080, 33, 17280, 17280, 17280, 1080, 1080, 33, 33, 33, 17280, 33, 1080, 1080, 33, 17280, 17280, 17280, 33, 33, 17280, 1080, 17280, 17280, 33, 17280, 33, 1080, 33, 33, 1080, 1080, 17280, 17280, 17280, 33, 17280, 1080, 1080, 33, 33, 33, 33, 17280, 1080, 17280, 1080, 17280, 17280, 17280, 33, 1080, 1080, 17280, 1080, 17280, 33, 33, 33, 1080, 1080, 1080, 17280, 17280, 1080, 17280, 33, 1080, 1080, 33, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 17280, 33, 17280, 33, 17280, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 17280, 1080, 33, 33]
Prompts retrieved: 992109 . Total input tokens: 221209647 . Total output tokens: 195121829
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 6.8830969161354005,
    "estimated_duration": 3600.0894818266484,
    "input_throughput": 5459.493742924252,
    "output_throughput": 4743.433763578402,
    "total_throughput": 10202.927506502654,
    "itl": 110.22997179576998,
    "ttft": 1901789.5163039356,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 602,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.134646810619155,
    "arrivals": 330904,
    "finished_requests": 79087,
    "scheduler_time": 149.19299016277196
}
#Debug simulation 
Total elapsed time: 6.8831883310340345. Arrivals time: 0.277278371155262 Scheduler time: 6.466030907817185 Scheduler overhead time: 0.05175805417820811 Adapter cache time: 0.015045793261379004 Engine time: 0.05000164406374097 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-16-32/adapters_160_slots_64_rate_1.6-0.1-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-16-32/adapters_160_slots_64_rate_1.6-0.1-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 1080, 33, 33, 33, 17280, 33, 1080, 17280, 1080, 33, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 33, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 33, 1080, 1080, 1080, 17280, 33, 33, 17280, 33, 17280, 33, 33, 1080, 33, 1080, 17280, 33, 33, 1080, 33, 33, 33, 33, 33, 17280, 1080, 1080, 17280, 1080, 33, 17280, 17280, 17280, 1080, 1080, 33, 33, 33, 17280, 33, 1080, 1080, 33, 17280, 17280, 17280, 33, 33, 17280, 1080, 17280, 17280, 33, 17280, 33, 1080, 33, 33, 1080, 1080, 17280, 17280, 17280, 33, 17280, 1080, 1080, 33, 33, 33, 33, 17280, 1080, 17280, 1080, 17280, 17280, 17280, 33, 1080, 1080, 17280, 1080, 17280, 33, 33, 33, 1080, 1080, 1080, 17280, 17280, 1080, 17280, 33, 1080, 1080, 33, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 17280, 33, 17280, 33, 17280, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 17280, 1080, 33, 33]
Prompts retrieved: 992109 . Total input tokens: 221209647 . Total output tokens: 195121829
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 6.246544701047242,
    "estimated_duration": 3600.028068098259,
    "input_throughput": 5152.705103713013,
    "output_throughput": 4484.407814222454,
    "total_throughput": 9637.112917935468,
    "itl": 97.96254581557818,
    "ttft": 1944496.7084926195,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 774,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.756313523687451,
    "arrivals": 330904,
    "finished_requests": 74769,
    "scheduler_time": 155.4881028667553
}
#Debug simulation 
Total elapsed time: 6.246662714984268. Arrivals time: 0.2380962986499071 Scheduler time: 5.854879582300782 Scheduler overhead time: 0.05660056509077549 Adapter cache time: 0.017479950096458197 Engine time: 0.05449799820780754 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_16-16-16/adapters_160_slots_64_rate_1.6-0.1-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_16-16-16/adapters_160_slots_64_rate_1.6-0.1-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 1080, 33, 33, 33, 17280, 33, 1080, 17280, 1080, 33, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 33, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 33, 1080, 1080, 1080, 17280, 33, 33, 17280, 33, 17280, 33, 33, 1080, 33, 1080, 17280, 33, 33, 1080, 33, 33, 33, 33, 33, 17280, 1080, 1080, 17280, 1080, 33, 17280, 17280, 17280, 1080, 1080, 33, 33, 33, 17280, 33, 1080, 1080, 33, 17280, 17280, 17280, 33, 33, 17280, 1080, 17280, 17280, 33, 17280, 33, 1080, 33, 33, 1080, 1080, 17280, 17280, 17280, 33, 17280, 1080, 1080, 33, 33, 33, 33, 17280, 1080, 17280, 1080, 17280, 17280, 17280, 33, 1080, 1080, 17280, 1080, 17280, 33, 33, 33, 1080, 1080, 1080, 17280, 17280, 1080, 17280, 33, 1080, 1080, 33, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 17280, 33, 17280, 33, 17280, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 17280, 1080, 33, 33]
Prompts retrieved: 992109 . Total input tokens: 221209647 . Total output tokens: 195121829
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 6.808585101738572,
    "estimated_duration": 3600.051629138522,
    "input_throughput": 5460.250581101774,
    "output_throughput": 4743.7014129951785,
    "total_throughput": 10203.951994096951,
    "itl": 110.21523307275697,
    "ttft": 1901721.4928622146,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 599,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.8239686434017317,
    "arrivals": 330904,
    "finished_requests": 79092,
    "scheduler_time": 149.20452645181376
}
#Debug simulation 
Total elapsed time: 6.808705357834697. Arrivals time: 0.27728364476934075 Scheduler time: 6.392367199994624 Scheduler overhead time: 0.051430475898087025 Adapter cache time: 0.015009277034550905 Engine time: 0.049696840811520815 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_16-16-32/adapters_160_slots_64_rate_1.6-0.1-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_16-16-32/adapters_160_slots_64_rate_1.6-0.1-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 1080, 33, 33, 33, 17280, 33, 1080, 17280, 1080, 33, 1080, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 33, 17280, 1080, 17280, 17280, 17280, 1080, 17280, 33, 1080, 1080, 1080, 17280, 33, 33, 17280, 33, 17280, 33, 33, 1080, 33, 1080, 17280, 33, 33, 1080, 33, 33, 33, 33, 33, 17280, 1080, 1080, 17280, 1080, 33, 17280, 17280, 17280, 1080, 1080, 33, 33, 33, 17280, 33, 1080, 1080, 33, 17280, 17280, 17280, 33, 33, 17280, 1080, 17280, 17280, 33, 17280, 33, 1080, 33, 33, 1080, 1080, 17280, 17280, 17280, 33, 17280, 1080, 1080, 33, 33, 33, 33, 17280, 1080, 17280, 1080, 17280, 17280, 17280, 33, 1080, 1080, 17280, 1080, 17280, 33, 33, 33, 1080, 1080, 1080, 17280, 17280, 1080, 17280, 33, 1080, 1080, 33, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 17280, 33, 17280, 33, 17280, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 17280, 1080, 33, 33]
Prompts retrieved: 992109 . Total input tokens: 221209647 . Total output tokens: 195121829
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 6.292185702826828,
    "estimated_duration": 3600.08690390437,
    "input_throughput": 5153.69086781713,
    "output_throughput": 4484.832014052093,
    "total_throughput": 9638.522881869223,
    "itl": 97.96449670739005,
    "ttft": 1944698.627058843,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 757,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.578374158237158,
    "arrivals": 330904,
    "finished_requests": 74777,
    "scheduler_time": 155.49570960807642
}
#Debug simulation 
Total elapsed time: 6.292281757108867. Arrivals time: 0.25067737558856606 Scheduler time: 5.888371500652283 Scheduler overhead time: 0.05674663186073303 Adapter cache time: 0.01716382149606943 Engine time: 0.05414807656779885 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-8-8/adapters_160_slots_64_rate_1.6-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-8-8/adapters_160_slots_64_rate_1.6-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [53 53 54]
Adapter prompts. [270, 17280, 270, 270, 540, 270, 270, 270, 17280, 270, 540, 17280, 540, 270, 540, 540, 540, 540, 17280, 17280, 17280, 540, 540, 540, 17280, 17280, 270, 17280, 540, 17280, 17280, 17280, 540, 17280, 270, 540, 540, 540, 17280, 270, 270, 17280, 270, 17280, 270, 270, 540, 270, 540, 17280, 270, 270, 540, 270, 270, 270, 270, 270, 17280, 540, 540, 17280, 540, 270, 17280, 17280, 17280, 540, 540, 270, 270, 270, 17280, 270, 540, 540, 270, 17280, 17280, 17280, 270, 270, 17280, 540, 17280, 17280, 270, 17280, 270, 540, 270, 270, 540, 540, 17280, 17280, 17280, 270, 17280, 540, 540, 270, 270, 270, 270, 17280, 540, 17280, 540, 17280, 17280, 17280, 270, 540, 540, 17280, 540, 17280, 270, 270, 270, 540, 540, 540, 17280, 17280, 540, 17280, 270, 540, 540, 270, 17280, 17280, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 540, 17280, 270, 17280, 270, 17280, 540, 270, 540, 270, 270, 540, 540, 540, 17280, 540, 270, 270]
Prompts retrieved: 976050 . Total input tokens: 217623164 . Total output tokens: 191983283
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 7.212526134680957,
    "estimated_duration": 3600.124183699016,
    "input_throughput": 5627.835309609389,
    "output_throughput": 4878.052007071602,
    "total_throughput": 10505.887316680992,
    "itl": 118.01091647265258,
    "ttft": 1875334.1124330712,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 702,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.641911140428938,
    "arrivals": 325545,
    "finished_requests": 81565,
    "scheduler_time": 145.73994393901276
}
#Debug simulation 
Total elapsed time: 7.2126579796895385. Arrivals time: 0.25527607230469584 Scheduler time: 6.823811286594719 Scheduler overhead time: 0.04919686447829008 Adapter cache time: 0.015466573648154736 Engine time: 0.04723344324156642 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-8-16/adapters_160_slots_64_rate_1.6-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-8-16/adapters_160_slots_64_rate_1.6-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [53 53 54]
Adapter prompts. [270, 17280, 270, 270, 540, 270, 270, 270, 17280, 270, 540, 17280, 540, 270, 540, 540, 540, 540, 17280, 17280, 17280, 540, 540, 540, 17280, 17280, 270, 17280, 540, 17280, 17280, 17280, 540, 17280, 270, 540, 540, 540, 17280, 270, 270, 17280, 270, 17280, 270, 270, 540, 270, 540, 17280, 270, 270, 540, 270, 270, 270, 270, 270, 17280, 540, 540, 17280, 540, 270, 17280, 17280, 17280, 540, 540, 270, 270, 270, 17280, 270, 540, 540, 270, 17280, 17280, 17280, 270, 270, 17280, 540, 17280, 17280, 270, 17280, 270, 540, 270, 270, 540, 540, 17280, 17280, 17280, 270, 17280, 540, 540, 270, 270, 270, 270, 17280, 540, 17280, 540, 17280, 17280, 17280, 270, 540, 540, 17280, 540, 17280, 270, 270, 270, 540, 540, 540, 17280, 17280, 540, 17280, 270, 540, 540, 270, 17280, 17280, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 540, 17280, 270, 17280, 270, 17280, 540, 270, 540, 270, 270, 540, 540, 540, 17280, 540, 270, 270]
Prompts retrieved: 976050 . Total input tokens: 217623164 . Total output tokens: 191983283
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 6.89463927783072,
    "estimated_duration": 3600.0541114251846,
    "input_throughput": 5466.0278404009605,
    "output_throughput": 4743.785918606437,
    "total_throughput": 10209.813759007397,
    "itl": 110.31931188713588,
    "ttft": 1895966.5112681706,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 756,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.51202539188788,
    "arrivals": 325545,
    "finished_requests": 79268,
    "scheduler_time": 149.00812549311448
}
#Debug simulation 
Total elapsed time: 6.89476290717721. Arrivals time: 0.2506024115718901 Scheduler time: 6.502334213349968 Scheduler overhead time: 0.052158554550260305 Adapter cache time: 0.01653878204524517 Engine time: 0.05008187051862478 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-8-32/adapters_160_slots_64_rate_1.6-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-8-32/adapters_160_slots_64_rate_1.6-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [53 53 54]
Adapter prompts. [270, 17280, 270, 270, 540, 270, 270, 270, 17280, 270, 540, 17280, 540, 270, 540, 540, 540, 540, 17280, 17280, 17280, 540, 540, 540, 17280, 17280, 270, 17280, 540, 17280, 17280, 17280, 540, 17280, 270, 540, 540, 540, 17280, 270, 270, 17280, 270, 17280, 270, 270, 540, 270, 540, 17280, 270, 270, 540, 270, 270, 270, 270, 270, 17280, 540, 540, 17280, 540, 270, 17280, 17280, 17280, 540, 540, 270, 270, 270, 17280, 270, 540, 540, 270, 17280, 17280, 17280, 270, 270, 17280, 540, 17280, 17280, 270, 17280, 270, 540, 270, 270, 540, 540, 17280, 17280, 17280, 270, 17280, 540, 540, 270, 270, 270, 270, 17280, 540, 17280, 540, 17280, 17280, 17280, 270, 540, 540, 17280, 540, 17280, 270, 270, 270, 540, 540, 540, 17280, 17280, 540, 17280, 270, 540, 540, 270, 17280, 17280, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 540, 17280, 270, 17280, 270, 17280, 540, 270, 540, 270, 270, 540, 540, 540, 17280, 540, 270, 270]
Prompts retrieved: 976050 . Total input tokens: 217623164 . Total output tokens: 191983283
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 6.225708546116948,
    "estimated_duration": 3600.061680822775,
    "input_throughput": 5156.329153715361,
    "output_throughput": 4482.0295957574535,
    "total_throughput": 9638.358749472814,
    "itl": 98.01145993304141,
    "ttft": 1938018.8348454498,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1023,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.66032321036329,
    "arrivals": 325545,
    "finished_requests": 74766,
    "scheduler_time": 155.31012870406053
}
#Debug simulation 
Total elapsed time: 6.225833389908075. Arrivals time: 0.23498434340581298 Scheduler time: 5.834803779609501 Scheduler overhead time: 0.05620475858449936 Adapter cache time: 0.020237524062395096 Engine time: 0.054424220230430365 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-16-16/adapters_160_slots_64_rate_1.6-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-16-16/adapters_160_slots_64_rate_1.6-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [53 53 54]
Adapter prompts. [270, 17280, 270, 270, 540, 270, 270, 270, 17280, 270, 540, 17280, 540, 270, 540, 540, 540, 540, 17280, 17280, 17280, 540, 540, 540, 17280, 17280, 270, 17280, 540, 17280, 17280, 17280, 540, 17280, 270, 540, 540, 540, 17280, 270, 270, 17280, 270, 17280, 270, 270, 540, 270, 540, 17280, 270, 270, 540, 270, 270, 270, 270, 270, 17280, 540, 540, 17280, 540, 270, 17280, 17280, 17280, 540, 540, 270, 270, 270, 17280, 270, 540, 540, 270, 17280, 17280, 17280, 270, 270, 17280, 540, 17280, 17280, 270, 17280, 270, 540, 270, 270, 540, 540, 17280, 17280, 17280, 270, 17280, 540, 540, 270, 270, 270, 270, 17280, 540, 17280, 540, 17280, 17280, 17280, 270, 540, 540, 17280, 540, 17280, 270, 270, 270, 540, 540, 540, 17280, 17280, 540, 17280, 270, 540, 540, 270, 17280, 17280, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 540, 17280, 270, 17280, 270, 17280, 540, 270, 540, 270, 270, 540, 540, 540, 17280, 540, 270, 270]
Prompts retrieved: 976050 . Total input tokens: 217623164 . Total output tokens: 191983283
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 6.885698528960347,
    "estimated_duration": 3600.0552745836876,
    "input_throughput": 5464.587763107325,
    "output_throughput": 4743.496612555422,
    "total_throughput": 10208.084375662747,
    "itl": 110.31430301506417,
    "ttft": 1895862.26327923,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 768,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.258235851526252,
    "arrivals": 325545,
    "finished_requests": 79248,
    "scheduler_time": 149.0146079206533
}
#Debug simulation 
Total elapsed time: 6.885784790851176. Arrivals time: 0.2521085198968649 Scheduler time: 6.4932269006967545 Scheduler overhead time: 0.0516047403216362 Adapter cache time: 0.01656087301671505 Engine time: 0.049394268076866865 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-16-32/adapters_160_slots_64_rate_1.6-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-16-32/adapters_160_slots_64_rate_1.6-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [53 53 54]
Adapter prompts. [270, 17280, 270, 270, 540, 270, 270, 270, 17280, 270, 540, 17280, 540, 270, 540, 540, 540, 540, 17280, 17280, 17280, 540, 540, 540, 17280, 17280, 270, 17280, 540, 17280, 17280, 17280, 540, 17280, 270, 540, 540, 540, 17280, 270, 270, 17280, 270, 17280, 270, 270, 540, 270, 540, 17280, 270, 270, 540, 270, 270, 270, 270, 270, 17280, 540, 540, 17280, 540, 270, 17280, 17280, 17280, 540, 540, 270, 270, 270, 17280, 270, 540, 540, 270, 17280, 17280, 17280, 270, 270, 17280, 540, 17280, 17280, 270, 17280, 270, 540, 270, 270, 540, 540, 17280, 17280, 17280, 270, 17280, 540, 540, 270, 270, 270, 270, 17280, 540, 17280, 540, 17280, 17280, 17280, 270, 540, 540, 17280, 540, 17280, 270, 270, 270, 540, 540, 540, 17280, 17280, 540, 17280, 270, 540, 540, 270, 17280, 17280, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 540, 17280, 270, 17280, 270, 17280, 540, 270, 540, 270, 270, 540, 540, 540, 17280, 540, 270, 270]
Prompts retrieved: 976050 . Total input tokens: 217623164 . Total output tokens: 191983283
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 6.220221776980907,
    "estimated_duration": 3600.0639073358298,
    "input_throughput": 5156.676236266668,
    "output_throughput": 4482.4790379741025,
    "total_throughput": 9639.155274240771,
    "itl": 98.01370275308176,
    "ttft": 1938293.7339451392,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1028,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.636393873267822,
    "arrivals": 325545,
    "finished_requests": 74772,
    "scheduler_time": 155.30683674869292
}
#Debug simulation 
Total elapsed time: 6.220346056856215. Arrivals time: 0.2364473775960505 Scheduler time: 5.827547038439661 Scheduler overhead time: 0.056697053369134665 Adapter cache time: 0.0203963965177536 Engine time: 0.054182803723961115 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_16-16-16/adapters_160_slots_64_rate_1.6-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_16-16-16/adapters_160_slots_64_rate_1.6-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [53 53 54]
Adapter prompts. [270, 17280, 270, 270, 540, 270, 270, 270, 17280, 270, 540, 17280, 540, 270, 540, 540, 540, 540, 17280, 17280, 17280, 540, 540, 540, 17280, 17280, 270, 17280, 540, 17280, 17280, 17280, 540, 17280, 270, 540, 540, 540, 17280, 270, 270, 17280, 270, 17280, 270, 270, 540, 270, 540, 17280, 270, 270, 540, 270, 270, 270, 270, 270, 17280, 540, 540, 17280, 540, 270, 17280, 17280, 17280, 540, 540, 270, 270, 270, 17280, 270, 540, 540, 270, 17280, 17280, 17280, 270, 270, 17280, 540, 17280, 17280, 270, 17280, 270, 540, 270, 270, 540, 540, 17280, 17280, 17280, 270, 17280, 540, 540, 270, 270, 270, 270, 17280, 540, 17280, 540, 17280, 17280, 17280, 270, 540, 540, 17280, 540, 17280, 270, 270, 270, 540, 540, 540, 17280, 17280, 540, 17280, 270, 540, 540, 270, 17280, 17280, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 540, 17280, 270, 17280, 270, 17280, 540, 270, 540, 270, 270, 540, 540, 540, 17280, 540, 270, 270]
Prompts retrieved: 976050 . Total input tokens: 217623164 . Total output tokens: 191983283
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 6.864601856097579,
    "estimated_duration": 3600.091803281656,
    "input_throughput": 5466.065332573534,
    "output_throughput": 4743.570423518987,
    "total_throughput": 10209.63575609252,
    "itl": 110.29392931551293,
    "ttft": 1895710.3824538703,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 756,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.8262442310713,
    "arrivals": 325545,
    "finished_requests": 79264,
    "scheduler_time": 149.0356472781461
}
#Debug simulation 
Total elapsed time: 6.8647219319827855. Arrivals time: 0.24978667683899403 Scheduler time: 6.473862993065268 Scheduler overhead time: 0.05204444471746683 Adapter cache time: 0.016632819082587957 Engine time: 0.04953293828293681 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_16-16-32/adapters_160_slots_64_rate_1.6-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_16-16-32/adapters_160_slots_64_rate_1.6-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [53 53 54]
Adapter prompts. [270, 17280, 270, 270, 540, 270, 270, 270, 17280, 270, 540, 17280, 540, 270, 540, 540, 540, 540, 17280, 17280, 17280, 540, 540, 540, 17280, 17280, 270, 17280, 540, 17280, 17280, 17280, 540, 17280, 270, 540, 540, 540, 17280, 270, 270, 17280, 270, 17280, 270, 270, 540, 270, 540, 17280, 270, 270, 540, 270, 270, 270, 270, 270, 17280, 540, 540, 17280, 540, 270, 17280, 17280, 17280, 540, 540, 270, 270, 270, 17280, 270, 540, 540, 270, 17280, 17280, 17280, 270, 270, 17280, 540, 17280, 17280, 270, 17280, 270, 540, 270, 270, 540, 540, 17280, 17280, 17280, 270, 17280, 540, 540, 270, 270, 270, 270, 17280, 540, 17280, 540, 17280, 17280, 17280, 270, 540, 540, 17280, 540, 17280, 270, 270, 270, 540, 540, 540, 17280, 17280, 540, 17280, 270, 540, 540, 270, 17280, 17280, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 540, 17280, 270, 17280, 270, 17280, 540, 270, 540, 270, 270, 540, 540, 540, 17280, 540, 270, 270]
Prompts retrieved: 976050 . Total input tokens: 217623164 . Total output tokens: 191983283
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 6.199958271812648,
    "estimated_duration": 3600.0640976648506,
    "input_throughput": 5156.7431846676745,
    "output_throughput": 4482.246305132932,
    "total_throughput": 9638.989489800606,
    "itl": 98.00891431870143,
    "ttft": 1937986.1635603916,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1025,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.537085497248933,
    "arrivals": 325545,
    "finished_requests": 74772,
    "scheduler_time": 155.3118622528099
}
#Debug simulation 
Total elapsed time: 6.200051023624837. Arrivals time: 0.2375217997469008 Scheduler time: 5.806793796364218 Scheduler overhead time: 0.05649922415614128 Adapter cache time: 0.019977138377726078 Engine time: 0.054151033982634544 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-8/adapters_160_slots_64_rate_1.6-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-8/adapters_160_slots_64_rate_1.6-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [53 53 54]
Adapter prompts. [135, 17280, 135, 135, 540, 135, 135, 135, 17280, 135, 540, 17280, 540, 135, 540, 540, 540, 540, 17280, 17280, 17280, 540, 540, 540, 17280, 17280, 135, 17280, 540, 17280, 17280, 17280, 540, 17280, 135, 540, 540, 540, 17280, 135, 135, 17280, 135, 17280, 135, 135, 540, 135, 540, 17280, 135, 135, 540, 135, 135, 135, 135, 135, 17280, 540, 540, 17280, 540, 135, 17280, 17280, 17280, 540, 540, 135, 135, 135, 17280, 135, 540, 540, 135, 17280, 17280, 17280, 135, 135, 17280, 540, 17280, 17280, 135, 17280, 135, 540, 135, 135, 540, 540, 17280, 17280, 17280, 135, 17280, 540, 540, 135, 135, 135, 135, 17280, 540, 17280, 540, 17280, 17280, 17280, 135, 540, 540, 17280, 540, 17280, 135, 135, 135, 540, 540, 540, 17280, 17280, 540, 17280, 135, 540, 540, 135, 17280, 17280, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 540, 17280, 135, 17280, 135, 17280, 540, 135, 540, 135, 135, 540, 540, 540, 17280, 540, 135, 135]
Prompts retrieved: 968895 . Total input tokens: 216027269 . Total output tokens: 190582552
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 6.701911523006856,
    "estimated_duration": 3600.076386488469,
    "input_throughput": 5574.607548695768,
    "output_throughput": 4884.226086422325,
    "total_throughput": 10458.833635118093,
    "itl": 118.40547505783408,
    "ttft": 1872489.8387891927,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 721,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.767546912035991,
    "arrivals": 323217,
    "finished_requests": 81365,
    "scheduler_time": 145.61184877722266
}
#Debug simulation 
Total elapsed time: 6.702038950286806. Arrivals time: 0.2516323388554156 Scheduler time: 6.318022686988115 Scheduler overhead time: 0.048555116169154644 Adapter cache time: 0.01557145407423377 Engine time: 0.04670700477436185 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-16/adapters_160_slots_64_rate_1.6-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-16/adapters_160_slots_64_rate_1.6-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [53 53 54]
Adapter prompts. [135, 17280, 135, 135, 540, 135, 135, 135, 17280, 135, 540, 17280, 540, 135, 540, 540, 540, 540, 17280, 17280, 17280, 540, 540, 540, 17280, 17280, 135, 17280, 540, 17280, 17280, 17280, 540, 17280, 135, 540, 540, 540, 17280, 135, 135, 17280, 135, 17280, 135, 135, 540, 135, 540, 17280, 135, 135, 540, 135, 135, 135, 135, 135, 17280, 540, 540, 17280, 540, 135, 17280, 17280, 17280, 540, 540, 135, 135, 135, 17280, 135, 540, 540, 135, 17280, 17280, 17280, 135, 135, 17280, 540, 17280, 17280, 135, 17280, 135, 540, 135, 135, 540, 540, 17280, 17280, 17280, 135, 17280, 540, 540, 135, 135, 135, 135, 17280, 540, 17280, 540, 17280, 17280, 17280, 135, 540, 540, 17280, 540, 17280, 135, 135, 135, 540, 540, 540, 17280, 17280, 540, 17280, 135, 540, 540, 135, 17280, 17280, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 540, 17280, 135, 17280, 135, 17280, 540, 135, 540, 135, 135, 540, 540, 540, 17280, 540, 135, 135]
Prompts retrieved: 968895 . Total input tokens: 216027269 . Total output tokens: 190582552
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 6.709351575002074,
    "estimated_duration": 3600.097618035462,
    "input_throughput": 5423.377661257539,
    "output_throughput": 4750.053974739624,
    "total_throughput": 10173.431635997164,
    "itl": 110.72384598089393,
    "ttft": 1894279.424069753,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 847,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.187361223665075,
    "arrivals": 323217,
    "finished_requests": 79140,
    "scheduler_time": 148.84816275613366
}
#Debug simulation 
Total elapsed time: 6.7094563147984445. Arrivals time: 0.5336859244853258 Scheduler time: 6.035303394310176 Scheduler overhead time: 0.0512241437099874 Adapter cache time: 0.017263395711779594 Engine time: 0.049260292667895555 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-32/adapters_160_slots_64_rate_1.6-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-32/adapters_160_slots_64_rate_1.6-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [53 53 54]
Adapter prompts. [135, 17280, 135, 135, 540, 135, 135, 135, 17280, 135, 540, 17280, 540, 135, 540, 540, 540, 540, 17280, 17280, 17280, 540, 540, 540, 17280, 17280, 135, 17280, 540, 17280, 17280, 17280, 540, 17280, 135, 540, 540, 540, 17280, 135, 135, 17280, 135, 17280, 135, 135, 540, 135, 540, 17280, 135, 135, 540, 135, 135, 135, 135, 135, 17280, 540, 540, 17280, 540, 135, 17280, 17280, 17280, 540, 540, 135, 135, 135, 17280, 135, 540, 540, 135, 17280, 17280, 17280, 135, 135, 17280, 540, 17280, 17280, 135, 17280, 135, 540, 135, 135, 540, 540, 17280, 17280, 17280, 135, 17280, 540, 540, 135, 135, 135, 135, 17280, 540, 17280, 540, 17280, 17280, 17280, 135, 540, 540, 17280, 540, 17280, 135, 135, 135, 540, 540, 540, 17280, 17280, 540, 17280, 135, 540, 540, 135, 17280, 17280, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 540, 17280, 135, 17280, 135, 17280, 540, 135, 540, 135, 135, 540, 540, 540, 17280, 540, 135, 135]
Prompts retrieved: 968895 . Total input tokens: 216027269 . Total output tokens: 190582552
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.939007923938334,
    "estimated_duration": 3600.0004773349997,
    "input_throughput": 5119.803210038538,
    "output_throughput": 4491.539682230808,
    "total_throughput": 9611.342892269346,
    "itl": 98.37504095162562,
    "ttft": 1936741.0067096492,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1079,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.0937864489481,
    "arrivals": 323217,
    "finished_requests": 74798,
    "scheduler_time": 155.11484588860722
}
#Debug simulation 
Total elapsed time: 5.939131622202694. Arrivals time: 0.26384866749867797 Scheduler time: 5.517711868043989 Scheduler overhead time: 0.05628850590437651 Adapter cache time: 0.021046361420303583 Engine time: 0.05512018594890833 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-16-16/adapters_160_slots_64_rate_1.6-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-16-16/adapters_160_slots_64_rate_1.6-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [53 53 54]
Adapter prompts. [135, 17280, 135, 135, 540, 135, 135, 135, 17280, 135, 540, 17280, 540, 135, 540, 540, 540, 540, 17280, 17280, 17280, 540, 540, 540, 17280, 17280, 135, 17280, 540, 17280, 17280, 17280, 540, 17280, 135, 540, 540, 540, 17280, 135, 135, 17280, 135, 17280, 135, 135, 540, 135, 540, 17280, 135, 135, 540, 135, 135, 135, 135, 135, 17280, 540, 540, 17280, 540, 135, 17280, 17280, 17280, 540, 540, 135, 135, 135, 17280, 135, 540, 540, 135, 17280, 17280, 17280, 135, 135, 17280, 540, 17280, 17280, 135, 17280, 135, 540, 135, 135, 540, 540, 17280, 17280, 17280, 135, 17280, 540, 540, 135, 135, 135, 135, 17280, 540, 17280, 540, 17280, 17280, 17280, 135, 540, 540, 17280, 540, 17280, 135, 135, 135, 540, 540, 540, 17280, 17280, 540, 17280, 135, 540, 540, 135, 17280, 17280, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 540, 17280, 135, 17280, 135, 17280, 540, 135, 540, 135, 135, 540, 540, 540, 17280, 540, 135, 135]
Prompts retrieved: 968895 . Total input tokens: 216027269 . Total output tokens: 190582552
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 6.521249260287732,
    "estimated_duration": 3600.0533807066954,
    "input_throughput": 5423.33069410414,
    "output_throughput": 4750.563447657212,
    "total_throughput": 10173.894141761353,
    "itl": 110.71200124539114,
    "ttft": 1894073.7291937051,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 850,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.824752218825734,
    "arrivals": 323217,
    "finished_requests": 79141,
    "scheduler_time": 148.8587353897931
}
#Debug simulation 
Total elapsed time: 6.521343729924411. Arrivals time: 0.2761050737462938 Scheduler time: 6.103209136985242 Scheduler overhead time: 0.05171489715576172 Adapter cache time: 0.017509411554783583 Engine time: 0.04981211107224226 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-16-32/adapters_160_slots_64_rate_1.6-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-16-32/adapters_160_slots_64_rate_1.6-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [53 53 54]
Adapter prompts. [135, 17280, 135, 135, 540, 135, 135, 135, 17280, 135, 540, 17280, 540, 135, 540, 540, 540, 540, 17280, 17280, 17280, 540, 540, 540, 17280, 17280, 135, 17280, 540, 17280, 17280, 17280, 540, 17280, 135, 540, 540, 540, 17280, 135, 135, 17280, 135, 17280, 135, 135, 540, 135, 540, 17280, 135, 135, 540, 135, 135, 135, 135, 135, 17280, 540, 540, 17280, 540, 135, 17280, 17280, 17280, 540, 540, 135, 135, 135, 17280, 135, 540, 540, 135, 17280, 17280, 17280, 135, 135, 17280, 540, 17280, 17280, 135, 17280, 135, 540, 135, 135, 540, 540, 17280, 17280, 17280, 135, 17280, 540, 540, 135, 135, 135, 135, 17280, 540, 17280, 540, 17280, 17280, 17280, 135, 540, 540, 17280, 540, 17280, 135, 135, 135, 540, 540, 540, 17280, 17280, 540, 17280, 135, 540, 540, 135, 17280, 17280, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 540, 17280, 135, 17280, 135, 17280, 540, 135, 540, 135, 135, 540, 540, 540, 17280, 540, 135, 135]
Prompts retrieved: 968895 . Total input tokens: 216027269 . Total output tokens: 190582552
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 5.937762720044702,
    "estimated_duration": 3600.0704525921524,
    "input_throughput": 5119.954523870026,
    "output_throughput": 4491.674041644628,
    "total_throughput": 9611.628565514653,
    "itl": 98.37443154851663,
    "ttft": 1936945.3680984322,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1089,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.095220945291235,
    "arrivals": 323217,
    "finished_requests": 74804,
    "scheduler_time": 155.11997393080898
}
#Debug simulation 
Total elapsed time: 5.93787764525041. Arrivals time: 0.26675650058314204 Scheduler time: 5.5149358147755265 Scheduler overhead time: 0.05605961522087455 Adapter cache time: 0.0208827992901206 Engine time: 0.054130999837070704 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_16-16-16/adapters_160_slots_64_rate_1.6-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_16-16-16/adapters_160_slots_64_rate_1.6-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [53 53 54]
Adapter prompts. [135, 17280, 135, 135, 540, 135, 135, 135, 17280, 135, 540, 17280, 540, 135, 540, 540, 540, 540, 17280, 17280, 17280, 540, 540, 540, 17280, 17280, 135, 17280, 540, 17280, 17280, 17280, 540, 17280, 135, 540, 540, 540, 17280, 135, 135, 17280, 135, 17280, 135, 135, 540, 135, 540, 17280, 135, 135, 540, 135, 135, 135, 135, 135, 17280, 540, 540, 17280, 540, 135, 17280, 17280, 17280, 540, 540, 135, 135, 135, 17280, 135, 540, 540, 135, 17280, 17280, 17280, 135, 135, 17280, 540, 17280, 17280, 135, 17280, 135, 540, 135, 135, 540, 540, 17280, 17280, 17280, 135, 17280, 540, 540, 135, 135, 135, 135, 17280, 540, 17280, 540, 17280, 17280, 17280, 135, 540, 540, 17280, 540, 17280, 135, 135, 135, 540, 540, 540, 17280, 17280, 540, 17280, 135, 540, 540, 135, 17280, 17280, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 540, 17280, 135, 17280, 135, 17280, 540, 135, 540, 135, 135, 540, 540, 540, 17280, 540, 135, 135]
Prompts retrieved: 968895 . Total input tokens: 216027269 . Total output tokens: 190582552
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 6.459283938631415,
    "estimated_duration": 3600.042342551112,
    "input_throughput": 5424.0039816206045,
    "output_throughput": 4751.078840889261,
    "total_throughput": 10175.082822509867,
    "itl": 110.68993714586897,
    "ttft": 1893933.0012735557,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 827,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.279502617851805,
    "arrivals": 323217,
    "finished_requests": 79150,
    "scheduler_time": 148.881730995065
}
#Debug simulation 
Total elapsed time: 6.459377129562199. Arrivals time: 0.2767070750705898 Scheduler time: 6.042676972225308 Scheduler overhead time: 0.051248172763735056 Adapter cache time: 0.017015140037983656 Engine time: 0.04911789111793041 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_16-16-32/adapters_160_slots_64_rate_1.6-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_16-16-32/adapters_160_slots_64_rate_1.6-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [53 53 54]
Adapter prompts. [135, 17280, 135, 135, 540, 135, 135, 135, 17280, 135, 540, 17280, 540, 135, 540, 540, 540, 540, 17280, 17280, 17280, 540, 540, 540, 17280, 17280, 135, 17280, 540, 17280, 17280, 17280, 540, 17280, 135, 540, 540, 540, 17280, 135, 135, 17280, 135, 17280, 135, 135, 540, 135, 540, 17280, 135, 135, 540, 135, 135, 135, 135, 135, 17280, 540, 540, 17280, 540, 135, 17280, 17280, 17280, 540, 540, 135, 135, 135, 17280, 135, 540, 540, 135, 17280, 17280, 17280, 135, 135, 17280, 540, 17280, 17280, 135, 17280, 135, 540, 135, 135, 540, 540, 17280, 17280, 17280, 135, 17280, 540, 540, 135, 135, 135, 135, 17280, 540, 17280, 540, 17280, 17280, 17280, 135, 540, 540, 17280, 540, 17280, 135, 135, 135, 540, 540, 540, 17280, 17280, 540, 17280, 135, 540, 540, 135, 17280, 17280, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 540, 17280, 135, 17280, 135, 17280, 540, 135, 540, 135, 135, 540, 540, 540, 17280, 540, 135, 135]
Prompts retrieved: 968895 . Total input tokens: 216027269 . Total output tokens: 190582552
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.939472166821361,
    "estimated_duration": 3600.0663862189967,
    "input_throughput": 5120.49474158742,
    "output_throughput": 4492.08799646181,
    "total_throughput": 9612.58273804923,
    "itl": 98.3613160892866,
    "ttft": 1936683.1985062,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1060,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.807993896491842,
    "arrivals": 323217,
    "finished_requests": 74808,
    "scheduler_time": 155.12980948495928
}
#Debug simulation 
Total elapsed time: 5.939596965909004. Arrivals time: 0.23379094386473298 Scheduler time: 5.549765972420573 Scheduler overhead time: 0.05621333187445998 Adapter cache time: 0.020611812360584736 Engine time: 0.05409763054922223 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-8/adapters_160_slots_64_rate_1.6-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-8/adapters_160_slots_64_rate_1.6-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 540, 66, 66, 66, 17280, 66, 540, 17280, 540, 66, 540, 540, 540, 540, 17280, 17280, 17280, 540, 540, 540, 17280, 17280, 66, 17280, 540, 17280, 17280, 17280, 540, 17280, 66, 540, 540, 540, 17280, 66, 66, 17280, 66, 17280, 66, 66, 540, 66, 540, 17280, 66, 66, 540, 66, 66, 66, 66, 66, 17280, 540, 540, 17280, 540, 66, 17280, 17280, 17280, 540, 540, 66, 66, 66, 17280, 66, 540, 540, 66, 17280, 17280, 17280, 66, 66, 17280, 540, 17280, 17280, 66, 17280, 66, 540, 66, 66, 540, 540, 17280, 17280, 17280, 66, 17280, 540, 540, 66, 66, 66, 66, 17280, 540, 17280, 540, 17280, 17280, 17280, 66, 540, 540, 17280, 540, 17280, 66, 66, 66, 540, 540, 540, 17280, 17280, 540, 17280, 66, 540, 540, 66, 17280, 17280, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 540, 17280, 66, 17280, 66, 17280, 540, 66, 540, 66, 66, 540, 540, 540, 17280, 540, 66, 66]
Prompts retrieved: 965238 . Total input tokens: 215208942 . Total output tokens: 189862100
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 6.354424120858312,
    "estimated_duration": 3600.07918864769,
    "input_throughput": 5587.371262118225,
    "output_throughput": 4878.152140480213,
    "total_throughput": 10465.52340259844,
    "itl": 118.23404685132407,
    "ttft": 1876797.3103171948,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 787,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.203965908144701,
    "arrivals": 321998,
    "finished_requests": 81186,
    "scheduler_time": 145.64839090036836
}
#Debug simulation 
Total elapsed time: 6.354547707829624. Arrivals time: 0.24858277710154653 Scheduler time: 5.972816611640155 Scheduler overhead time: 0.0483279125764966 Adapter cache time: 0.01632006000727415 Engine time: 0.04685323731973767 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-16/adapters_160_slots_64_rate_1.6-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-16/adapters_160_slots_64_rate_1.6-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 540, 66, 66, 66, 17280, 66, 540, 17280, 540, 66, 540, 540, 540, 540, 17280, 17280, 17280, 540, 540, 540, 17280, 17280, 66, 17280, 540, 17280, 17280, 17280, 540, 17280, 66, 540, 540, 540, 17280, 66, 66, 17280, 66, 17280, 66, 66, 540, 66, 540, 17280, 66, 66, 540, 66, 66, 66, 66, 66, 17280, 540, 540, 17280, 540, 66, 17280, 17280, 17280, 540, 540, 66, 66, 66, 17280, 66, 540, 540, 66, 17280, 17280, 17280, 66, 66, 17280, 540, 17280, 17280, 66, 17280, 66, 540, 66, 66, 540, 540, 17280, 17280, 17280, 66, 17280, 540, 540, 66, 66, 66, 66, 17280, 540, 17280, 540, 17280, 17280, 17280, 66, 540, 540, 17280, 540, 17280, 66, 66, 66, 540, 540, 540, 17280, 17280, 540, 17280, 66, 540, 540, 66, 17280, 17280, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 540, 17280, 66, 17280, 66, 17280, 540, 66, 540, 66, 66, 540, 540, 540, 17280, 540, 66, 66]
Prompts retrieved: 965238 . Total input tokens: 215208942 . Total output tokens: 189862100
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 6.089223119895905,
    "estimated_duration": 3600.0928146480574,
    "input_throughput": 5430.871370995849,
    "output_throughput": 4742.581060835543,
    "total_throughput": 10173.452431831392,
    "itl": 110.50574989648594,
    "ttft": 1898414.3428166248,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 868,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.331141110230246,
    "arrivals": 321998,
    "finished_requests": 78914,
    "scheduler_time": 148.91639586282625
}
#Debug simulation 
Total elapsed time: 6.089317064732313. Arrivals time: 0.24431438744068146 Scheduler time: 5.704086318612099 Scheduler overhead time: 0.05119380122050643 Adapter cache time: 0.017835641279816628 Engine time: 0.04915444366633892 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-32/adapters_160_slots_64_rate_1.6-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-32/adapters_160_slots_64_rate_1.6-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 540, 66, 66, 66, 17280, 66, 540, 17280, 540, 66, 540, 540, 540, 540, 17280, 17280, 17280, 540, 540, 540, 17280, 17280, 66, 17280, 540, 17280, 17280, 17280, 540, 17280, 66, 540, 540, 540, 17280, 66, 66, 17280, 66, 17280, 66, 66, 540, 66, 540, 17280, 66, 66, 540, 66, 66, 66, 66, 66, 17280, 540, 540, 17280, 540, 66, 17280, 17280, 17280, 540, 540, 66, 66, 66, 17280, 66, 540, 540, 66, 17280, 17280, 17280, 66, 66, 17280, 540, 17280, 17280, 66, 17280, 66, 540, 66, 66, 540, 540, 17280, 17280, 17280, 66, 17280, 540, 540, 66, 66, 66, 66, 17280, 540, 17280, 540, 17280, 17280, 17280, 66, 540, 540, 17280, 540, 17280, 66, 66, 66, 540, 540, 540, 17280, 17280, 540, 17280, 66, 540, 540, 66, 17280, 17280, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 540, 17280, 66, 17280, 66, 17280, 540, 66, 540, 66, 66, 540, 540, 540, 17280, 540, 66, 66]
Prompts retrieved: 965238 . Total input tokens: 215208942 . Total output tokens: 189862100
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.6774485390633345,
    "estimated_duration": 3600.0479763575463,
    "input_throughput": 5132.8010408061255,
    "output_throughput": 4481.282501219015,
    "total_throughput": 9614.08354202514,
    "itl": 98.12834468291838,
    "ttft": 1941246.5140849527,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1127,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.445553036597557,
    "arrivals": 321998,
    "finished_requests": 74495,
    "scheduler_time": 155.22707035560902
}
#Debug simulation 
Total elapsed time: 5.6775674829259515. Arrivals time: 0.23236203333362937 Scheduler time: 5.2883506920188665 Scheduler overhead time: 0.05627150321379304 Adapter cache time: 0.02119653346017003 Engine time: 0.05418048845604062 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_8-16-16/adapters_160_slots_64_rate_1.6-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_8-16-16/adapters_160_slots_64_rate_1.6-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 540, 66, 66, 66, 17280, 66, 540, 17280, 540, 66, 540, 540, 540, 540, 17280, 17280, 17280, 540, 540, 540, 17280, 17280, 66, 17280, 540, 17280, 17280, 17280, 540, 17280, 66, 540, 540, 540, 17280, 66, 66, 17280, 66, 17280, 66, 66, 540, 66, 540, 17280, 66, 66, 540, 66, 66, 66, 66, 66, 17280, 540, 540, 17280, 540, 66, 17280, 17280, 17280, 540, 540, 66, 66, 66, 17280, 66, 540, 540, 66, 17280, 17280, 17280, 66, 66, 17280, 540, 17280, 17280, 66, 17280, 66, 540, 66, 66, 540, 540, 17280, 17280, 17280, 66, 17280, 540, 540, 66, 66, 66, 66, 17280, 540, 17280, 540, 17280, 17280, 17280, 66, 540, 540, 17280, 540, 17280, 66, 66, 66, 540, 540, 540, 17280, 17280, 540, 17280, 66, 540, 540, 66, 17280, 17280, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 540, 17280, 66, 17280, 66, 17280, 540, 66, 540, 66, 66, 540, 540, 540, 17280, 540, 66, 66]
Prompts retrieved: 965238 . Total input tokens: 215208942 . Total output tokens: 189862100
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 6.326255721971393,
    "estimated_duration": 3600.066537233481,
    "input_throughput": 5431.710719165466,
    "output_throughput": 4743.578715387633,
    "total_throughput": 10175.289434553099,
    "itl": 110.49440417112876,
    "ttft": 1898335.470420785,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 868,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.950768563542507,
    "arrivals": 321998,
    "finished_requests": 78923,
    "scheduler_time": 148.93037506232386
}
#Debug simulation 
Total elapsed time: 6.326319430954754. Arrivals time: 0.24782719695940614 Scheduler time: 5.9383373549208045 Scheduler overhead time: 0.05100435018539429 Adapter cache time: 0.017596663907170296 Engine time: 0.04884964972734451 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_8-16-32/adapters_160_slots_64_rate_1.6-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_8-16-32/adapters_160_slots_64_rate_1.6-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 540, 66, 66, 66, 17280, 66, 540, 17280, 540, 66, 540, 540, 540, 540, 17280, 17280, 17280, 540, 540, 540, 17280, 17280, 66, 17280, 540, 17280, 17280, 17280, 540, 17280, 66, 540, 540, 540, 17280, 66, 66, 17280, 66, 17280, 66, 66, 540, 66, 540, 17280, 66, 66, 540, 66, 66, 66, 66, 66, 17280, 540, 540, 17280, 540, 66, 17280, 17280, 17280, 540, 540, 66, 66, 66, 17280, 66, 540, 540, 66, 17280, 17280, 17280, 66, 66, 17280, 540, 17280, 17280, 66, 17280, 66, 540, 66, 66, 540, 540, 17280, 17280, 17280, 66, 17280, 540, 540, 66, 66, 66, 66, 17280, 540, 17280, 540, 17280, 17280, 17280, 66, 540, 540, 17280, 540, 17280, 66, 66, 66, 540, 540, 540, 17280, 17280, 540, 17280, 66, 540, 540, 66, 17280, 17280, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 540, 17280, 66, 17280, 66, 17280, 540, 66, 540, 66, 66, 540, 540, 540, 17280, 540, 66, 66]
Prompts retrieved: 965238 . Total input tokens: 215208942 . Total output tokens: 189862100
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 5.661249827127904,
    "estimated_duration": 3600.098699062607,
    "input_throughput": 5132.32512342259,
    "output_throughput": 4481.353248509767,
    "total_throughput": 9613.678371932358,
    "itl": 98.12732914445343,
    "ttft": 1941001.2576073343,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1135,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.431560475686567,
    "arrivals": 321998,
    "finished_requests": 74492,
    "scheduler_time": 155.2298699017578
}
#Debug simulation 
Total elapsed time: 5.66137518780306. Arrivals time: 0.23797522112727165 Scheduler time: 5.266446915920824 Scheduler overhead time: 0.056463994551450014 Adapter cache time: 0.021348875015974045 Engine time: 0.054100737906992435 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_16-16-16/adapters_160_slots_64_rate_1.6-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_16-16-16/adapters_160_slots_64_rate_1.6-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 540, 66, 66, 66, 17280, 66, 540, 17280, 540, 66, 540, 540, 540, 540, 17280, 17280, 17280, 540, 540, 540, 17280, 17280, 66, 17280, 540, 17280, 17280, 17280, 540, 17280, 66, 540, 540, 540, 17280, 66, 66, 17280, 66, 17280, 66, 66, 540, 66, 540, 17280, 66, 66, 540, 66, 66, 66, 66, 66, 17280, 540, 540, 17280, 540, 66, 17280, 17280, 17280, 540, 540, 66, 66, 66, 17280, 66, 540, 540, 66, 17280, 17280, 17280, 66, 66, 17280, 540, 17280, 17280, 66, 17280, 66, 540, 66, 66, 540, 540, 17280, 17280, 17280, 66, 17280, 540, 540, 66, 66, 66, 66, 17280, 540, 17280, 540, 17280, 17280, 17280, 66, 540, 540, 17280, 540, 17280, 66, 66, 66, 540, 540, 540, 17280, 17280, 540, 17280, 66, 540, 540, 66, 17280, 17280, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 540, 17280, 66, 17280, 66, 17280, 540, 66, 540, 66, 66, 540, 540, 540, 17280, 540, 66, 66]
Prompts retrieved: 965238 . Total input tokens: 215208942 . Total output tokens: 189862100
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 6.107474510092288,
    "estimated_duration": 3600.052621587429,
    "input_throughput": 5431.901434645487,
    "output_throughput": 4743.873158295513,
    "total_throughput": 10175.774592941001,
    "itl": 110.48487660560644,
    "ttft": 1898346.4695501246,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 866,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.528475534534055,
    "arrivals": 321998,
    "finished_requests": 78928,
    "scheduler_time": 148.94308910711865
}
#Debug simulation 
Total elapsed time: 6.107599603012204. Arrivals time: 0.2590848309919238 Scheduler time: 5.706426694057882 Scheduler overhead time: 0.05183473648503423 Adapter cache time: 0.017617006320506334 Engine time: 0.04974419670179486 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_16-16-32/adapters_160_slots_64_rate_1.6-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_16-16-32/adapters_160_slots_64_rate_1.6-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 540, 66, 66, 66, 17280, 66, 540, 17280, 540, 66, 540, 540, 540, 540, 17280, 17280, 17280, 540, 540, 540, 17280, 17280, 66, 17280, 540, 17280, 17280, 17280, 540, 17280, 66, 540, 540, 540, 17280, 66, 66, 17280, 66, 17280, 66, 66, 540, 66, 540, 17280, 66, 66, 540, 66, 66, 66, 66, 66, 17280, 540, 540, 17280, 540, 66, 17280, 17280, 17280, 540, 540, 66, 66, 66, 17280, 66, 540, 540, 66, 17280, 17280, 17280, 66, 66, 17280, 540, 17280, 17280, 66, 17280, 66, 540, 66, 66, 540, 540, 17280, 17280, 17280, 66, 17280, 540, 540, 66, 66, 66, 66, 17280, 540, 17280, 540, 17280, 17280, 17280, 66, 540, 540, 17280, 540, 17280, 66, 66, 66, 540, 540, 540, 17280, 17280, 540, 17280, 66, 540, 540, 66, 17280, 17280, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 540, 17280, 66, 17280, 66, 17280, 540, 66, 540, 66, 66, 540, 540, 540, 17280, 540, 66, 66]
Prompts retrieved: 965238 . Total input tokens: 215208942 . Total output tokens: 189862100
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.653183543123305,
    "estimated_duration": 3600.06335757367,
    "input_throughput": 5133.194381460781,
    "output_throughput": 4481.2100226127395,
    "total_throughput": 9614.40440407352,
    "itl": 98.12669663647122,
    "ttft": 1941200.0651733477,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.295028862915942,
    "arrivals": 321998,
    "finished_requests": 74492,
    "scheduler_time": 155.2324251119142
}
#Debug simulation 
Total elapsed time: 5.653303419239819. Arrivals time: 0.23241601884365082 Scheduler time: 5.264888637699187 Scheduler overhead time: 0.055896425154060125 Adapter cache time: 0.021224725991487503 Engine time: 0.05377615336328745 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-8/adapters_160_slots_64_rate_1.6-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-8/adapters_160_slots_64_rate_1.6-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 540, 33, 33, 33, 17280, 33, 540, 17280, 540, 33, 540, 540, 540, 540, 17280, 17280, 17280, 540, 540, 540, 17280, 17280, 33, 17280, 540, 17280, 17280, 17280, 540, 17280, 33, 540, 540, 540, 17280, 33, 33, 17280, 33, 17280, 33, 33, 540, 33, 540, 17280, 33, 33, 540, 33, 33, 33, 33, 33, 17280, 540, 540, 17280, 540, 33, 17280, 17280, 17280, 540, 540, 33, 33, 33, 17280, 33, 540, 540, 33, 17280, 17280, 17280, 33, 33, 17280, 540, 17280, 17280, 33, 17280, 33, 540, 33, 33, 540, 540, 17280, 17280, 17280, 33, 17280, 540, 540, 33, 33, 33, 33, 17280, 540, 17280, 540, 17280, 17280, 17280, 33, 540, 540, 17280, 540, 17280, 33, 33, 33, 540, 540, 540, 17280, 17280, 540, 17280, 33, 540, 540, 33, 17280, 17280, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 540, 17280, 33, 17280, 33, 17280, 540, 33, 540, 33, 33, 540, 540, 540, 17280, 540, 33, 33]
Prompts retrieved: 963489 . Total input tokens: 214807685 . Total output tokens: 189517768
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 6.240788250695914,
    "estimated_duration": 3600.0272230420705,
    "input_throughput": 5605.475667194469,
    "output_throughput": 4876.708400322792,
    "total_throughput": 10482.18406751726,
    "itl": 118.26288257479712,
    "ttft": 1874213.5115884515,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 775,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.124616999761299,
    "arrivals": 321377,
    "finished_requests": 81234,
    "scheduler_time": 145.72022150883632
}
#Debug simulation 
Total elapsed time: 6.240879859775305. Arrivals time: 0.2499958979897201 Scheduler time: 5.857541653793305 Scheduler overhead time: 0.0484786331653595 Adapter cache time: 0.016243445221334696 Engine time: 0.04705094639211893 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-16/adapters_160_slots_64_rate_1.6-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-16/adapters_160_slots_64_rate_1.6-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 540, 33, 33, 33, 17280, 33, 540, 17280, 540, 33, 540, 540, 540, 540, 17280, 17280, 17280, 540, 540, 540, 17280, 17280, 33, 17280, 540, 17280, 17280, 17280, 540, 17280, 33, 540, 540, 540, 17280, 33, 33, 17280, 33, 17280, 33, 33, 540, 33, 540, 17280, 33, 33, 540, 33, 33, 33, 33, 33, 17280, 540, 540, 17280, 540, 33, 17280, 17280, 17280, 540, 540, 33, 33, 33, 17280, 33, 540, 540, 33, 17280, 17280, 17280, 33, 33, 17280, 540, 17280, 17280, 33, 17280, 33, 540, 33, 33, 540, 540, 17280, 17280, 17280, 33, 17280, 540, 540, 33, 33, 33, 33, 17280, 540, 17280, 540, 17280, 17280, 17280, 33, 540, 540, 17280, 540, 17280, 33, 33, 33, 540, 540, 540, 17280, 17280, 540, 17280, 33, 540, 540, 33, 17280, 17280, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 540, 17280, 33, 17280, 33, 17280, 540, 33, 540, 33, 33, 540, 540, 540, 17280, 540, 33, 33]
Prompts retrieved: 963489 . Total input tokens: 214807685 . Total output tokens: 189517768
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.990725057199597,
    "estimated_duration": 3600.102460805294,
    "input_throughput": 5452.592867484404,
    "output_throughput": 4746.444076532676,
    "total_throughput": 10199.036944017082,
    "itl": 110.6172404889227,
    "ttft": 1896791.8888617756,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 901,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.570963141708644,
    "arrivals": 321377,
    "finished_requests": 79069,
    "scheduler_time": 148.93922175543375
}
#Debug simulation 
Total elapsed time: 5.990842162165791. Arrivals time: 0.24459278769791126 Scheduler time: 5.605836412869394 Scheduler overhead time: 0.050889046397060156 Adapter cache time: 0.017589895520359278 Engine time: 0.049140970688313246 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-32/adapters_160_slots_64_rate_1.6-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-32/adapters_160_slots_64_rate_1.6-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 540, 33, 33, 33, 17280, 33, 540, 17280, 540, 33, 540, 540, 540, 540, 17280, 17280, 17280, 540, 540, 540, 17280, 17280, 33, 17280, 540, 17280, 17280, 17280, 540, 17280, 33, 540, 540, 540, 17280, 33, 33, 17280, 33, 17280, 33, 33, 540, 33, 540, 17280, 33, 33, 540, 33, 33, 33, 33, 33, 17280, 540, 540, 17280, 540, 33, 17280, 17280, 17280, 540, 540, 33, 33, 33, 17280, 33, 540, 540, 33, 17280, 17280, 17280, 33, 33, 17280, 540, 17280, 17280, 33, 17280, 33, 540, 33, 33, 540, 540, 17280, 17280, 17280, 33, 17280, 540, 540, 33, 33, 33, 33, 17280, 540, 17280, 540, 17280, 17280, 17280, 33, 540, 540, 17280, 540, 17280, 33, 33, 33, 540, 540, 540, 17280, 17280, 540, 17280, 33, 540, 540, 33, 17280, 17280, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 540, 17280, 33, 17280, 33, 17280, 540, 33, 540, 33, 33, 540, 540, 540, 17280, 540, 33, 33]
Prompts retrieved: 963489 . Total input tokens: 214807685 . Total output tokens: 189517768
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.566578325815499,
    "estimated_duration": 3600.0182180203064,
    "input_throughput": 5147.472562011205,
    "output_throughput": 4483.846753663553,
    "total_throughput": 9631.319315674758,
    "itl": 98.27252050461826,
    "ttft": 1939889.9309319737,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1157,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.665620754677784,
    "arrivals": 321377,
    "finished_requests": 74670,
    "scheduler_time": 155.21360283704502
}
#Debug simulation 
Total elapsed time: 5.56667268788442. Arrivals time: 0.23579248506575823 Scheduler time: 5.174836023245007 Scheduler overhead time: 0.055707196705043316 Adapter cache time: 0.021263211499899626 Engine time: 0.053964797873049974 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_8-16-16/adapters_160_slots_64_rate_1.6-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_8-16-16/adapters_160_slots_64_rate_1.6-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 540, 33, 33, 33, 17280, 33, 540, 17280, 540, 33, 540, 540, 540, 540, 17280, 17280, 17280, 540, 540, 540, 17280, 17280, 33, 17280, 540, 17280, 17280, 17280, 540, 17280, 33, 540, 540, 540, 17280, 33, 33, 17280, 33, 17280, 33, 33, 540, 33, 540, 17280, 33, 33, 540, 33, 33, 33, 33, 33, 17280, 540, 540, 17280, 540, 33, 17280, 17280, 17280, 540, 540, 33, 33, 33, 17280, 33, 540, 540, 33, 17280, 17280, 17280, 33, 33, 17280, 540, 17280, 17280, 33, 17280, 33, 540, 33, 33, 540, 540, 17280, 17280, 17280, 33, 17280, 540, 540, 33, 33, 33, 33, 17280, 540, 17280, 540, 17280, 17280, 17280, 33, 540, 540, 17280, 540, 17280, 33, 33, 33, 540, 540, 540, 17280, 17280, 540, 17280, 33, 540, 540, 33, 17280, 17280, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 540, 17280, 33, 17280, 33, 17280, 540, 33, 540, 33, 33, 540, 540, 540, 17280, 540, 33, 33]
Prompts retrieved: 963489 . Total input tokens: 214807685 . Total output tokens: 189517768
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 5.960039394907653,
    "estimated_duration": 3600.0267439151135,
    "input_throughput": 5452.641159729911,
    "output_throughput": 4746.519183192744,
    "total_throughput": 10199.160342922656,
    "itl": 110.60557380706642,
    "ttft": 1896605.9493089856,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 899,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.144505449780253,
    "arrivals": 321377,
    "finished_requests": 79067,
    "scheduler_time": 148.95001925742633
}
#Debug simulation 
Total elapsed time: 5.960154948756099. Arrivals time: 0.24373455625027418 Scheduler time: 5.576407596934587 Scheduler overhead time: 0.050698925741016865 Adapter cache time: 0.017747435718774796 Engine time: 0.04889282491058111 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_8-16-32/adapters_160_slots_64_rate_1.6-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_8-16-32/adapters_160_slots_64_rate_1.6-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 540, 33, 33, 33, 17280, 33, 540, 17280, 540, 33, 540, 540, 540, 540, 17280, 17280, 17280, 540, 540, 540, 17280, 17280, 33, 17280, 540, 17280, 17280, 17280, 540, 17280, 33, 540, 540, 540, 17280, 33, 33, 17280, 33, 17280, 33, 33, 540, 33, 540, 17280, 33, 33, 540, 33, 33, 33, 33, 33, 17280, 540, 540, 17280, 540, 33, 17280, 17280, 17280, 540, 540, 33, 33, 33, 17280, 33, 540, 540, 33, 17280, 17280, 17280, 33, 33, 17280, 540, 17280, 17280, 33, 17280, 33, 540, 33, 33, 540, 540, 17280, 17280, 17280, 33, 17280, 540, 540, 33, 33, 33, 33, 17280, 540, 17280, 540, 17280, 17280, 17280, 33, 540, 540, 17280, 540, 17280, 33, 33, 33, 540, 540, 540, 17280, 17280, 540, 17280, 33, 540, 540, 33, 17280, 17280, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 540, 17280, 33, 17280, 33, 17280, 540, 33, 540, 33, 33, 540, 540, 540, 17280, 540, 33, 33]
Prompts retrieved: 963489 . Total input tokens: 214807685 . Total output tokens: 189517768
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 5.605336890090257,
    "estimated_duration": 3600.0520208200523,
    "input_throughput": 5147.868667680663,
    "output_throughput": 4483.965205681365,
    "total_throughput": 9631.833873362028,
    "itl": 98.26388764322635,
    "ttft": 1940042.992930084,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1136,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.424982381002037,
    "arrivals": 321377,
    "finished_requests": 74677,
    "scheduler_time": 155.22894945588934
}
#Debug simulation 
Total elapsed time: 5.605429909192026. Arrivals time: 0.2767170197330415 Scheduler time: 5.172374590765685 Scheduler overhead time: 0.05602473672479391 Adapter cache time: 0.02118427911773324 Engine time: 0.05409410409629345 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_16-16-16/adapters_160_slots_64_rate_1.6-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_16-16-16/adapters_160_slots_64_rate_1.6-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 540, 33, 33, 33, 17280, 33, 540, 17280, 540, 33, 540, 540, 540, 540, 17280, 17280, 17280, 540, 540, 540, 17280, 17280, 33, 17280, 540, 17280, 17280, 17280, 540, 17280, 33, 540, 540, 540, 17280, 33, 33, 17280, 33, 17280, 33, 33, 540, 33, 540, 17280, 33, 33, 540, 33, 33, 33, 33, 33, 17280, 540, 540, 17280, 540, 33, 17280, 17280, 17280, 540, 540, 33, 33, 33, 17280, 33, 540, 540, 33, 17280, 17280, 17280, 33, 33, 17280, 540, 17280, 17280, 33, 17280, 33, 540, 33, 33, 540, 540, 17280, 17280, 17280, 33, 17280, 540, 540, 33, 33, 33, 33, 17280, 540, 17280, 540, 17280, 17280, 17280, 33, 540, 540, 17280, 540, 17280, 33, 33, 33, 540, 540, 540, 17280, 17280, 540, 17280, 33, 540, 540, 33, 17280, 17280, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 540, 17280, 33, 17280, 33, 17280, 540, 33, 540, 33, 33, 540, 540, 540, 17280, 540, 33, 33]
Prompts retrieved: 963489 . Total input tokens: 214807685 . Total output tokens: 189517768
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.951575136277825,
    "estimated_duration": 3600.0661633433674,
    "input_throughput": 5453.296997677294,
    "output_throughput": 4747.63274465126,
    "total_throughput": 10200.929742328553,
    "itl": 110.59074205518067,
    "ttft": 1896817.3542723635,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 894,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.7072253208700285,
    "arrivals": 321377,
    "finished_requests": 79083,
    "scheduler_time": 148.9697101573654
}
#Debug simulation 
Total elapsed time: 5.951667570043355. Arrivals time: 0.25415008794516325 Scheduler time: 5.558153522200882 Scheduler overhead time: 0.05062456289306283 Adapter cache time: 0.017387063708156347 Engine time: 0.04876993456855416 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_16-16-32/adapters_160_slots_64_rate_1.6-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_16-16-32/adapters_160_slots_64_rate_1.6-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 540, 33, 33, 33, 17280, 33, 540, 17280, 540, 33, 540, 540, 540, 540, 17280, 17280, 17280, 540, 540, 540, 17280, 17280, 33, 17280, 540, 17280, 17280, 17280, 540, 17280, 33, 540, 540, 540, 17280, 33, 33, 17280, 33, 17280, 33, 33, 540, 33, 540, 17280, 33, 33, 540, 33, 33, 33, 33, 33, 17280, 540, 540, 17280, 540, 33, 17280, 17280, 17280, 540, 540, 33, 33, 33, 17280, 33, 540, 540, 33, 17280, 17280, 17280, 33, 33, 17280, 540, 17280, 17280, 33, 17280, 33, 540, 33, 33, 540, 540, 17280, 17280, 17280, 33, 17280, 540, 540, 33, 33, 33, 33, 17280, 540, 17280, 540, 17280, 17280, 17280, 33, 540, 540, 17280, 540, 17280, 33, 33, 33, 540, 540, 540, 17280, 17280, 540, 17280, 33, 540, 540, 33, 17280, 17280, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 540, 17280, 33, 17280, 33, 17280, 540, 33, 540, 33, 33, 540, 540, 540, 17280, 540, 33, 33]
Prompts retrieved: 963489 . Total input tokens: 214807685 . Total output tokens: 189517768
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.619409314822406,
    "estimated_duration": 3600.004442436209,
    "input_throughput": 5147.938647391931,
    "output_throughput": 4484.500021637424,
    "total_throughput": 9632.438669029354,
    "itl": 98.26017500315376,
    "ttft": 1939998.4280460668,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1138,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.361704911142587,
    "arrivals": 321377,
    "finished_requests": 74679,
    "scheduler_time": 155.23054527105154
}
#Debug simulation 
Total elapsed time: 5.619517241604626. Arrivals time: 0.2443490019068122 Scheduler time: 5.217620593961328 Scheduler overhead time: 0.05731132160872221 Adapter cache time: 0.021174372173845768 Engine time: 0.05398625181987882 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-8/adapters_160_slots_64_rate_1.6-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-8/adapters_160_slots_64_rate_1.6-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [53 53 54]
Adapter prompts. [135, 17280, 135, 135, 270, 135, 135, 135, 17280, 135, 270, 17280, 270, 135, 270, 270, 270, 270, 17280, 17280, 17280, 270, 270, 270, 17280, 17280, 135, 17280, 270, 17280, 17280, 17280, 270, 17280, 135, 270, 270, 270, 17280, 135, 135, 17280, 135, 17280, 135, 135, 270, 135, 270, 17280, 135, 135, 270, 135, 135, 135, 135, 135, 17280, 270, 270, 17280, 270, 135, 17280, 17280, 17280, 270, 270, 135, 135, 135, 17280, 135, 270, 270, 135, 17280, 17280, 17280, 135, 135, 17280, 270, 17280, 17280, 135, 17280, 135, 270, 135, 135, 270, 270, 17280, 17280, 17280, 135, 17280, 270, 270, 135, 135, 135, 135, 17280, 270, 17280, 270, 17280, 17280, 17280, 135, 270, 270, 17280, 270, 17280, 135, 135, 135, 270, 270, 270, 17280, 17280, 270, 17280, 135, 270, 270, 135, 17280, 17280, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 270, 17280, 135, 17280, 135, 17280, 270, 135, 270, 135, 135, 270, 270, 270, 17280, 270, 135, 135]
Prompts retrieved: 954585 . Total input tokens: 212848812 . Total output tokens: 187739450
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 6.109703009948134,
    "estimated_duration": 3600.037514184748,
    "input_throughput": 5572.02999162152,
    "output_throughput": 4880.443031710683,
    "total_throughput": 10452.473023332203,
    "itl": 118.41692058587417,
    "ttft": 1874188.9063759823,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 963,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.367749897767927,
    "arrivals": 318402,
    "finished_requests": 81038,
    "scheduler_time": 145.47999907353702
}
#Debug simulation 
Total elapsed time: 6.1098120007663965. Arrivals time: 0.2536004255525768 Scheduler time: 5.7212743908166885 Scheduler overhead time: 0.048661858309060335 Adapter cache time: 0.017987307626754045 Engine time: 0.04668290913105011 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-16/adapters_160_slots_64_rate_1.6-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-16/adapters_160_slots_64_rate_1.6-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [53 53 54]
Adapter prompts. [135, 17280, 135, 135, 270, 135, 135, 135, 17280, 135, 270, 17280, 270, 135, 270, 270, 270, 270, 17280, 17280, 17280, 270, 270, 270, 17280, 17280, 135, 17280, 270, 17280, 17280, 17280, 270, 17280, 135, 270, 270, 270, 17280, 135, 135, 17280, 135, 17280, 135, 135, 270, 135, 270, 17280, 135, 135, 270, 135, 135, 135, 135, 135, 17280, 270, 270, 17280, 270, 135, 17280, 17280, 17280, 270, 270, 135, 135, 135, 17280, 135, 270, 270, 135, 17280, 17280, 17280, 135, 135, 17280, 270, 17280, 17280, 135, 17280, 135, 270, 135, 135, 270, 270, 17280, 17280, 17280, 135, 17280, 270, 270, 135, 135, 135, 135, 17280, 270, 17280, 270, 17280, 17280, 17280, 135, 270, 270, 17280, 270, 17280, 135, 135, 135, 270, 270, 270, 17280, 17280, 270, 17280, 135, 270, 270, 135, 17280, 17280, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 270, 17280, 135, 17280, 135, 17280, 270, 135, 270, 135, 135, 270, 270, 270, 17280, 270, 135, 135]
Prompts retrieved: 954585 . Total input tokens: 212848812 . Total output tokens: 187739450
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.858972928021103,
    "estimated_duration": 3600.0549365028414,
    "input_throughput": 5413.765718512284,
    "output_throughput": 4744.549264182186,
    "total_throughput": 10158.31498269447,
    "itl": 110.72754714076929,
    "ttft": 1895791.9961003242,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1080,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.899706600494695,
    "arrivals": 318402,
    "finished_requests": 78737,
    "scheduler_time": 148.71646518666574
}
#Debug simulation 
Total elapsed time: 5.859071268234402. Arrivals time: 0.2386659043841064 Scheduler time: 5.477838934864849 Scheduler overhead time: 0.05083451932296157 Adapter cache time: 0.019672274589538574 Engine time: 0.04930554423481226 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-32/adapters_160_slots_64_rate_1.6-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-32/adapters_160_slots_64_rate_1.6-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [53 53 54]
Adapter prompts. [135, 17280, 135, 135, 270, 135, 135, 135, 17280, 135, 270, 17280, 270, 135, 270, 270, 270, 270, 17280, 17280, 17280, 270, 270, 270, 17280, 17280, 135, 17280, 270, 17280, 17280, 17280, 270, 17280, 135, 270, 270, 270, 17280, 135, 135, 17280, 135, 17280, 135, 135, 270, 135, 270, 17280, 135, 135, 270, 135, 135, 135, 135, 135, 17280, 270, 270, 17280, 270, 135, 17280, 17280, 17280, 270, 270, 135, 135, 135, 17280, 135, 270, 270, 135, 17280, 17280, 17280, 135, 135, 17280, 270, 17280, 17280, 135, 17280, 135, 270, 135, 135, 270, 270, 17280, 17280, 17280, 135, 17280, 270, 270, 135, 135, 135, 135, 17280, 270, 17280, 270, 17280, 17280, 17280, 135, 270, 270, 17280, 270, 17280, 135, 135, 135, 270, 270, 270, 17280, 17280, 270, 17280, 135, 270, 270, 135, 17280, 17280, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 270, 17280, 135, 17280, 135, 17280, 270, 135, 270, 135, 135, 270, 270, 270, 17280, 270, 135, 135]
Prompts retrieved: 954585 . Total input tokens: 212848812 . Total output tokens: 187739450
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.4397071450948715,
    "estimated_duration": 3600.102242001755,
    "input_throughput": 5118.247972244955,
    "output_throughput": 4485.103731671221,
    "total_throughput": 9603.351703916176,
    "itl": 98.35107537723758,
    "ttft": 1939280.8379937096,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1389,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.44186781287649,
    "arrivals": 318402,
    "finished_requests": 74402,
    "scheduler_time": 155.02568452923782
}
#Debug simulation 
Total elapsed time: 5.439788562245667. Arrivals time: 0.22486207354813814 Scheduler time: 5.056078499183059 Scheduler overhead time: 0.05611997516825795 Adapter cache time: 0.02390438597649336 Engine time: 0.05385571578517556 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-16-16/adapters_160_slots_64_rate_1.6-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-16-16/adapters_160_slots_64_rate_1.6-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [53 53 54]
Adapter prompts. [135, 17280, 135, 135, 270, 135, 135, 135, 17280, 135, 270, 17280, 270, 135, 270, 270, 270, 270, 17280, 17280, 17280, 270, 270, 270, 17280, 17280, 135, 17280, 270, 17280, 17280, 17280, 270, 17280, 135, 270, 270, 270, 17280, 135, 135, 17280, 135, 17280, 135, 135, 270, 135, 270, 17280, 135, 135, 270, 135, 135, 135, 135, 135, 17280, 270, 270, 17280, 270, 135, 17280, 17280, 17280, 270, 270, 135, 135, 135, 17280, 135, 270, 270, 135, 17280, 17280, 17280, 135, 135, 17280, 270, 17280, 17280, 135, 17280, 135, 270, 135, 135, 270, 270, 17280, 17280, 17280, 135, 17280, 270, 270, 135, 135, 135, 135, 17280, 270, 17280, 270, 17280, 17280, 17280, 135, 270, 270, 17280, 270, 17280, 135, 135, 135, 270, 270, 270, 17280, 17280, 270, 17280, 135, 270, 270, 135, 17280, 17280, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 270, 17280, 135, 17280, 135, 17280, 270, 135, 270, 135, 135, 270, 270, 270, 17280, 270, 135, 135]
Prompts retrieved: 954585 . Total input tokens: 212848812 . Total output tokens: 187739450
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 5.837418524548411,
    "estimated_duration": 3600.008959402506,
    "input_throughput": 5414.053748142578,
    "output_throughput": 4744.714302831884,
    "total_throughput": 10158.768050974462,
    "itl": 110.7087557746636,
    "ttft": 1895843.2139116994,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1079,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.412998222787854,
    "arrivals": 318402,
    "finished_requests": 78741,
    "scheduler_time": 148.73451568259867
}
#Debug simulation 
Total elapsed time: 5.837503638584167. Arrivals time: 0.23072431096807122 Scheduler time: 5.46447647921741 Scheduler overhead time: 0.050818685442209244 Adapter cache time: 0.019712648820132017 Engine time: 0.049027100671082735 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-16-32/adapters_160_slots_64_rate_1.6-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-16-32/adapters_160_slots_64_rate_1.6-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [53 53 54]
Adapter prompts. [135, 17280, 135, 135, 270, 135, 135, 135, 17280, 135, 270, 17280, 270, 135, 270, 270, 270, 270, 17280, 17280, 17280, 270, 270, 270, 17280, 17280, 135, 17280, 270, 17280, 17280, 17280, 270, 17280, 135, 270, 270, 270, 17280, 135, 135, 17280, 135, 17280, 135, 135, 270, 135, 270, 17280, 135, 135, 270, 135, 135, 135, 135, 135, 17280, 270, 270, 17280, 270, 135, 17280, 17280, 17280, 270, 270, 135, 135, 135, 17280, 135, 270, 270, 135, 17280, 17280, 17280, 135, 135, 17280, 270, 17280, 17280, 135, 17280, 135, 270, 135, 135, 270, 270, 17280, 17280, 17280, 135, 17280, 270, 270, 135, 135, 135, 135, 17280, 270, 17280, 270, 17280, 17280, 17280, 135, 270, 270, 17280, 270, 17280, 135, 135, 135, 270, 270, 270, 17280, 17280, 270, 17280, 135, 270, 270, 135, 17280, 17280, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 270, 17280, 135, 17280, 135, 17280, 270, 135, 270, 135, 135, 270, 270, 270, 17280, 270, 135, 135]
Prompts retrieved: 954585 . Total input tokens: 212848812 . Total output tokens: 187739450
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 5.461314569227397,
    "estimated_duration": 3600.0885937342928,
    "input_throughput": 5118.433205246839,
    "output_throughput": 4485.1868445967875,
    "total_throughput": 9603.620049843626,
    "itl": 98.34994904963229,
    "ttft": 1939317.2991739393,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1393,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.3779141294769,
    "arrivals": 318402,
    "finished_requests": 74405,
    "scheduler_time": 155.030084500257
}
#Debug simulation 
Total elapsed time: 5.461403165943921. Arrivals time: 0.2337997336871922 Scheduler time: 5.069198664277792 Scheduler overhead time: 0.05586569244042039 Adapter cache time: 0.023943393025547266 Engine time: 0.05356197524815798 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_16-16-16/adapters_160_slots_64_rate_1.6-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_16-16-16/adapters_160_slots_64_rate_1.6-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [53 53 54]
Adapter prompts. [135, 17280, 135, 135, 270, 135, 135, 135, 17280, 135, 270, 17280, 270, 135, 270, 270, 270, 270, 17280, 17280, 17280, 270, 270, 270, 17280, 17280, 135, 17280, 270, 17280, 17280, 17280, 270, 17280, 135, 270, 270, 270, 17280, 135, 135, 17280, 135, 17280, 135, 135, 270, 135, 270, 17280, 135, 135, 270, 135, 135, 135, 135, 135, 17280, 270, 270, 17280, 270, 135, 17280, 17280, 17280, 270, 270, 135, 135, 135, 17280, 135, 270, 270, 135, 17280, 17280, 17280, 135, 135, 17280, 270, 17280, 17280, 135, 17280, 135, 270, 135, 135, 270, 270, 17280, 17280, 17280, 135, 17280, 270, 270, 135, 135, 135, 135, 17280, 270, 17280, 270, 17280, 17280, 17280, 135, 270, 270, 17280, 270, 17280, 135, 135, 135, 270, 270, 270, 17280, 17280, 270, 17280, 135, 270, 270, 135, 17280, 17280, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 270, 17280, 135, 17280, 135, 17280, 270, 135, 270, 135, 135, 270, 270, 270, 17280, 270, 135, 135]
Prompts retrieved: 954585 . Total input tokens: 212848812 . Total output tokens: 187739450
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.888644798193127,
    "estimated_duration": 3600.104589432385,
    "input_throughput": 5414.174648485189,
    "output_throughput": 4744.8899262933,
    "total_throughput": 10159.06457477849,
    "itl": 110.69535096190175,
    "ttft": 1895592.7609529796,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1079,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.888250694875571,
    "arrivals": 318402,
    "finished_requests": 78748,
    "scheduler_time": 148.75991255614596
}
#Debug simulation 
Total elapsed time: 5.8887407700531185. Arrivals time: 0.24200305482372642 Scheduler time: 5.503093491308391 Scheduler overhead time: 0.05145135149359703 Adapter cache time: 0.01995991449803114 Engine time: 0.04938908899202943 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_16-16-32/adapters_160_slots_64_rate_1.6-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_16-16-32/adapters_160_slots_64_rate_1.6-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [53 53 54]
Adapter prompts. [135, 17280, 135, 135, 270, 135, 135, 135, 17280, 135, 270, 17280, 270, 135, 270, 270, 270, 270, 17280, 17280, 17280, 270, 270, 270, 17280, 17280, 135, 17280, 270, 17280, 17280, 17280, 270, 17280, 135, 270, 270, 270, 17280, 135, 135, 17280, 135, 17280, 135, 135, 270, 135, 270, 17280, 135, 135, 270, 135, 135, 135, 135, 135, 17280, 270, 270, 17280, 270, 135, 17280, 17280, 17280, 270, 270, 135, 135, 135, 17280, 135, 270, 270, 135, 17280, 17280, 17280, 135, 135, 17280, 270, 17280, 17280, 135, 17280, 135, 270, 135, 135, 270, 270, 17280, 17280, 17280, 135, 17280, 270, 270, 135, 135, 135, 135, 17280, 270, 17280, 270, 17280, 17280, 17280, 135, 270, 270, 17280, 270, 17280, 135, 135, 135, 270, 270, 270, 17280, 17280, 270, 17280, 135, 270, 270, 135, 17280, 17280, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 270, 17280, 135, 17280, 135, 17280, 270, 135, 270, 135, 135, 270, 270, 270, 17280, 270, 135, 135]
Prompts retrieved: 954585 . Total input tokens: 212848812 . Total output tokens: 187739450
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.430815086234361,
    "estimated_duration": 3600.0855285133957,
    "input_throughput": 5118.33673229673,
    "output_throughput": 4485.164552928737,
    "total_throughput": 9603.501285225468,
    "itl": 98.34897954835576,
    "ttft": 1939350.4577508643,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1390,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.254580519720822,
    "arrivals": 318402,
    "finished_requests": 74405,
    "scheduler_time": 155.0310780878741
}
#Debug simulation 
Total elapsed time: 5.430906686000526. Arrivals time: 0.23131372267380357 Scheduler time: 5.040714363567531 Scheduler overhead time: 0.05601757951080799 Adapter cache time: 0.023837719578295946 Engine time: 0.053939645644277334 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-8/adapters_160_slots_64_rate_1.6-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-8/adapters_160_slots_64_rate_1.6-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 270, 66, 66, 66, 17280, 66, 270, 17280, 270, 66, 270, 270, 270, 270, 17280, 17280, 17280, 270, 270, 270, 17280, 17280, 66, 17280, 270, 17280, 17280, 17280, 270, 17280, 66, 270, 270, 270, 17280, 66, 66, 17280, 66, 17280, 66, 66, 270, 66, 270, 17280, 66, 66, 270, 66, 66, 66, 66, 66, 17280, 270, 270, 17280, 270, 66, 17280, 17280, 17280, 270, 270, 66, 66, 66, 17280, 66, 270, 270, 66, 17280, 17280, 17280, 66, 66, 17280, 270, 17280, 17280, 66, 17280, 66, 270, 66, 66, 270, 270, 17280, 17280, 17280, 66, 17280, 270, 270, 66, 66, 66, 66, 17280, 270, 17280, 270, 17280, 17280, 17280, 66, 270, 270, 17280, 270, 17280, 66, 66, 66, 270, 270, 270, 17280, 17280, 270, 17280, 66, 270, 270, 66, 17280, 17280, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 270, 17280, 66, 17280, 66, 17280, 270, 66, 270, 66, 66, 270, 270, 270, 17280, 270, 66, 66]
Prompts retrieved: 950928 . Total input tokens: 212056530 . Total output tokens: 187021572
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.877052146941423,
    "estimated_duration": 3600.1143302849823,
    "input_throughput": 5594.310389138592,
    "output_throughput": 4882.506606007863,
    "total_throughput": 10476.816995146455,
    "itl": 118.45673422187078,
    "ttft": 1863985.0035223854,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1083,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.1612389816019455,
    "arrivals": 317160,
    "finished_requests": 81545,
    "scheduler_time": 145.42150092093064
}
#Debug simulation 
Total elapsed time: 5.87714563915506. Arrivals time: 0.2495930870063603 Scheduler time: 5.49271438177675 Scheduler overhead time: 0.0482322066091001 Adapter cache time: 0.018904573749750853 Engine time: 0.04626963147893548 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-16/adapters_160_slots_64_rate_1.6-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-16/adapters_160_slots_64_rate_1.6-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 270, 66, 66, 66, 17280, 66, 270, 17280, 270, 66, 270, 270, 270, 270, 17280, 17280, 17280, 270, 270, 270, 17280, 17280, 66, 17280, 270, 17280, 17280, 17280, 270, 17280, 66, 270, 270, 270, 17280, 66, 66, 17280, 66, 17280, 66, 66, 270, 66, 270, 17280, 66, 66, 270, 66, 66, 66, 66, 66, 17280, 270, 270, 17280, 270, 66, 17280, 17280, 17280, 270, 270, 66, 66, 66, 17280, 66, 270, 270, 66, 17280, 17280, 17280, 66, 66, 17280, 270, 17280, 17280, 66, 17280, 66, 270, 66, 66, 270, 270, 17280, 17280, 17280, 66, 17280, 270, 270, 66, 66, 66, 66, 17280, 270, 17280, 270, 17280, 17280, 17280, 66, 270, 270, 17280, 270, 17280, 66, 66, 66, 270, 270, 270, 17280, 17280, 270, 17280, 66, 270, 270, 66, 17280, 17280, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 270, 17280, 66, 17280, 66, 17280, 270, 66, 270, 66, 66, 270, 270, 270, 17280, 270, 66, 66]
Prompts retrieved: 950928 . Total input tokens: 212056530 . Total output tokens: 187021572
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.69634824199602,
    "estimated_duration": 3600.0849021146278,
    "input_throughput": 5437.3500992996105,
    "output_throughput": 4747.649976243752,
    "total_throughput": 10185.000075543361,
    "itl": 110.55003297401262,
    "ttft": 1884990.982010141,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1196,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.77073420109225,
    "arrivals": 317160,
    "finished_requests": 79247,
    "scheduler_time": 148.83799762382907
}
#Debug simulation 
Total elapsed time: 5.696467504836619. Arrivals time: 0.26823726389557123 Scheduler time: 5.286337205208838 Scheduler overhead time: 0.05031259264796972 Adapter cache time: 0.020397302228957415 Engine time: 0.04866307321935892 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-32/adapters_160_slots_64_rate_1.6-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-32/adapters_160_slots_64_rate_1.6-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 270, 66, 66, 66, 17280, 66, 270, 17280, 270, 66, 270, 270, 270, 270, 17280, 17280, 17280, 270, 270, 270, 17280, 17280, 66, 17280, 270, 17280, 17280, 17280, 270, 17280, 66, 270, 270, 270, 17280, 66, 66, 17280, 66, 17280, 66, 66, 270, 66, 270, 17280, 66, 66, 270, 66, 66, 66, 66, 66, 17280, 270, 270, 17280, 270, 66, 17280, 17280, 17280, 270, 270, 66, 66, 66, 17280, 66, 270, 270, 66, 17280, 17280, 17280, 66, 66, 17280, 270, 17280, 17280, 66, 17280, 66, 270, 66, 66, 270, 270, 17280, 17280, 17280, 66, 17280, 270, 270, 66, 66, 66, 66, 17280, 270, 17280, 270, 17280, 17280, 17280, 66, 270, 270, 17280, 270, 17280, 66, 66, 66, 270, 270, 270, 17280, 17280, 270, 17280, 66, 270, 270, 66, 17280, 17280, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 270, 17280, 66, 17280, 66, 17280, 270, 66, 270, 66, 66, 270, 270, 270, 17280, 270, 66, 66]
Prompts retrieved: 950928 . Total input tokens: 212056530 . Total output tokens: 187021572
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.394921944011003,
    "estimated_duration": 3600.0940550150826,
    "input_throughput": 5168.319137129335,
    "output_throughput": 4513.389025868639,
    "total_throughput": 9681.708162997973,
    "itl": 97.51807442332355,
    "ttft": 1924059.1431600442,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1263,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.518266919497355,
    "arrivals": 317160,
    "finished_requests": 75271,
    "scheduler_time": 156.14217214612768
}
#Debug simulation 
Total elapsed time: 5.395036564208567. Arrivals time: 0.27080746926367283 Scheduler time: 4.967785512562841 Scheduler overhead time: 0.05503744538873434 Adapter cache time: 0.02285737544298172 Engine time: 0.05370875960215926 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-16-16/adapters_160_slots_64_rate_1.6-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-16-16/adapters_160_slots_64_rate_1.6-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 270, 66, 66, 66, 17280, 66, 270, 17280, 270, 66, 270, 270, 270, 270, 17280, 17280, 17280, 270, 270, 270, 17280, 17280, 66, 17280, 270, 17280, 17280, 17280, 270, 17280, 66, 270, 270, 270, 17280, 66, 66, 17280, 66, 17280, 66, 66, 270, 66, 270, 17280, 66, 66, 270, 66, 66, 66, 66, 66, 17280, 270, 270, 17280, 270, 66, 17280, 17280, 17280, 270, 270, 66, 66, 66, 17280, 66, 270, 270, 66, 17280, 17280, 17280, 66, 66, 17280, 270, 17280, 17280, 66, 17280, 66, 270, 66, 66, 270, 270, 17280, 17280, 17280, 66, 17280, 270, 270, 66, 66, 66, 66, 17280, 270, 17280, 270, 17280, 17280, 17280, 66, 270, 270, 17280, 270, 17280, 66, 66, 66, 270, 270, 270, 17280, 17280, 270, 17280, 66, 270, 270, 66, 17280, 17280, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 270, 17280, 66, 17280, 66, 17280, 270, 66, 270, 66, 66, 270, 270, 270, 17280, 270, 66, 66]
Prompts retrieved: 950928 . Total input tokens: 212056530 . Total output tokens: 187021572
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 5.691465959884226,
    "estimated_duration": 3600.0483774676836,
    "input_throughput": 5437.897202306619,
    "output_throughput": 4748.380912598847,
    "total_throughput": 10186.278114905466,
    "itl": 110.53497877686469,
    "ttft": 1884839.9012655467,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1195,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.206285448879932,
    "arrivals": 317160,
    "finished_requests": 79256,
    "scheduler_time": 148.8583644462148
}
#Debug simulation 
Total elapsed time: 5.691565136890858. Arrivals time: 0.2701896922662854 Scheduler time: 5.278303810860962 Scheduler overhead time: 0.0507667507044971 Adapter cache time: 0.02066943934187293 Engine time: 0.04897021781653166 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-16-32/adapters_160_slots_64_rate_1.6-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-16-32/adapters_160_slots_64_rate_1.6-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 270, 66, 66, 66, 17280, 66, 270, 17280, 270, 66, 270, 270, 270, 270, 17280, 17280, 17280, 270, 270, 270, 17280, 17280, 66, 17280, 270, 17280, 17280, 17280, 270, 17280, 66, 270, 270, 270, 17280, 66, 66, 17280, 66, 17280, 66, 66, 270, 66, 270, 17280, 66, 66, 270, 66, 66, 66, 66, 66, 17280, 270, 270, 17280, 270, 66, 17280, 17280, 17280, 270, 270, 66, 66, 66, 17280, 66, 270, 270, 66, 17280, 17280, 17280, 66, 66, 17280, 270, 17280, 17280, 66, 17280, 66, 270, 66, 66, 270, 270, 17280, 17280, 17280, 66, 17280, 270, 270, 66, 66, 66, 66, 17280, 270, 17280, 270, 17280, 17280, 17280, 66, 270, 270, 17280, 270, 17280, 66, 66, 66, 270, 270, 270, 17280, 17280, 270, 17280, 66, 270, 270, 66, 17280, 17280, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 270, 17280, 66, 17280, 66, 17280, 270, 66, 270, 66, 66, 270, 270, 270, 17280, 270, 66, 66]
Prompts retrieved: 950928 . Total input tokens: 212056530 . Total output tokens: 187021572
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 5.409055988769978,
    "estimated_duration": 3600.024008128937,
    "input_throughput": 5168.450531992562,
    "output_throughput": 4513.549066147793,
    "total_throughput": 9681.999598140355,
    "itl": 97.51206767161759,
    "ttft": 1924105.6242255692,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1262,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.4215446945326,
    "arrivals": 317160,
    "finished_requests": 75272,
    "scheduler_time": 156.14370676562626
}
#Debug simulation 
Total elapsed time: 5.409178455825895. Arrivals time: 0.2659210739657283 Scheduler time: 4.987084365915507 Scheduler overhead time: 0.05489152390509844 Adapter cache time: 0.02269836375489831 Engine time: 0.05376296769827604 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_16-16-16/adapters_160_slots_64_rate_1.6-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_16-16-16/adapters_160_slots_64_rate_1.6-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 270, 66, 66, 66, 17280, 66, 270, 17280, 270, 66, 270, 270, 270, 270, 17280, 17280, 17280, 270, 270, 270, 17280, 17280, 66, 17280, 270, 17280, 17280, 17280, 270, 17280, 66, 270, 270, 270, 17280, 66, 66, 17280, 66, 17280, 66, 66, 270, 66, 270, 17280, 66, 66, 270, 66, 66, 66, 66, 66, 17280, 270, 270, 17280, 270, 66, 17280, 17280, 17280, 270, 270, 66, 66, 66, 17280, 66, 270, 270, 66, 17280, 17280, 17280, 66, 66, 17280, 270, 17280, 17280, 66, 17280, 66, 270, 66, 66, 270, 270, 17280, 17280, 17280, 66, 17280, 270, 270, 66, 66, 66, 66, 17280, 270, 17280, 270, 17280, 17280, 17280, 66, 270, 270, 17280, 270, 17280, 66, 66, 66, 270, 270, 270, 17280, 17280, 270, 17280, 66, 270, 270, 66, 17280, 17280, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 270, 17280, 66, 17280, 66, 17280, 270, 66, 270, 66, 66, 270, 270, 270, 17280, 270, 66, 66]
Prompts retrieved: 950928 . Total input tokens: 212056530 . Total output tokens: 187021572
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.711610005237162,
    "estimated_duration": 3600.084222752753,
    "input_throughput": 5441.16270286083,
    "output_throughput": 4750.786909902418,
    "total_throughput": 10191.949612763248,
    "itl": 110.62935924600285,
    "ttft": 1884482.1977742394,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1198,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.64793728680346,
    "arrivals": 317160,
    "finished_requests": 79304,
    "scheduler_time": 148.8255785521862
}
#Debug simulation 
Total elapsed time: 5.7117356993258. Arrivals time: 0.27184772165492177 Scheduler time: 5.296600994654 Scheduler overhead time: 0.05030491854995489 Adapter cache time: 0.02085419511422515 Engine time: 0.04904241440817714 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_16-16-32/adapters_160_slots_64_rate_1.6-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_16-16-32/adapters_160_slots_64_rate_1.6-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 270, 66, 66, 66, 17280, 66, 270, 17280, 270, 66, 270, 270, 270, 270, 17280, 17280, 17280, 270, 270, 270, 17280, 17280, 66, 17280, 270, 17280, 17280, 17280, 270, 17280, 66, 270, 270, 270, 17280, 66, 66, 17280, 66, 17280, 66, 66, 270, 66, 270, 17280, 66, 66, 270, 66, 66, 66, 66, 66, 17280, 270, 270, 17280, 270, 66, 17280, 17280, 17280, 270, 270, 66, 66, 66, 17280, 66, 270, 270, 66, 17280, 17280, 17280, 66, 66, 17280, 270, 17280, 17280, 66, 17280, 66, 270, 66, 66, 270, 270, 17280, 17280, 17280, 66, 17280, 270, 270, 66, 66, 66, 66, 17280, 270, 17280, 270, 17280, 17280, 17280, 66, 270, 270, 17280, 270, 17280, 66, 66, 66, 270, 270, 270, 17280, 17280, 270, 17280, 66, 270, 270, 66, 17280, 17280, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 270, 17280, 66, 17280, 66, 17280, 270, 66, 270, 66, 66, 270, 270, 270, 17280, 270, 66, 66]
Prompts retrieved: 950928 . Total input tokens: 212056530 . Total output tokens: 187021572
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.417592845857143,
    "estimated_duration": 3600.0381763955065,
    "input_throughput": 5168.806020449185,
    "output_throughput": 4513.648245883163,
    "total_throughput": 9682.454266332348,
    "itl": 97.51117322260332,
    "ttft": 1924103.7572952665,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1264,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.34568494588133,
    "arrivals": 317160,
    "finished_requests": 75276,
    "scheduler_time": 156.14723064395855
}
#Debug simulation 
Total elapsed time: 5.417686091270298. Arrivals time: 0.27299644239246845 Scheduler time: 4.987931891810149 Scheduler overhead time: 0.055232380982488394 Adapter cache time: 0.02283103484660387 Engine time: 0.05390751315280795 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-8/adapters_160_slots_64_rate_1.6-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-8/adapters_160_slots_64_rate_1.6-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 270, 33, 33, 33, 17280, 33, 270, 17280, 270, 33, 270, 270, 270, 270, 17280, 17280, 17280, 270, 270, 270, 17280, 17280, 33, 17280, 270, 17280, 17280, 17280, 270, 17280, 33, 270, 270, 270, 17280, 33, 33, 17280, 33, 17280, 33, 33, 270, 33, 270, 17280, 33, 33, 270, 33, 33, 33, 33, 33, 17280, 270, 270, 17280, 270, 33, 17280, 17280, 17280, 270, 270, 33, 33, 33, 17280, 33, 270, 270, 33, 17280, 17280, 17280, 33, 33, 17280, 270, 17280, 17280, 33, 17280, 33, 270, 33, 33, 270, 270, 17280, 17280, 17280, 33, 17280, 270, 270, 33, 33, 33, 33, 17280, 270, 17280, 270, 17280, 17280, 17280, 33, 270, 270, 17280, 270, 17280, 33, 33, 33, 270, 270, 270, 17280, 17280, 270, 17280, 33, 270, 270, 33, 17280, 17280, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 270, 17280, 33, 17280, 33, 17280, 270, 33, 270, 33, 33, 270, 270, 270, 17280, 270, 33, 33]
Prompts retrieved: 949179 . Total input tokens: 211679878 . Total output tokens: 186680714
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 6.0793218137696385,
    "estimated_duration": 3600.0846378199535,
    "input_throughput": 5607.437332980169,
    "output_throughput": 4893.602171161254,
    "total_throughput": 10501.039504141423,
    "itl": 118.5116808160135,
    "ttft": 1863466.014941091,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1089,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.200913435793646,
    "arrivals": 316555,
    "finished_requests": 81809,
    "scheduler_time": 145.50239766324762
}
#Debug simulation 
Total elapsed time: 6.079392277635634. Arrivals time: 0.5318461139686406 Scheduler time: 5.413045609369874 Scheduler overhead time: 0.04793763626366854 Adapter cache time: 0.019006917718797922 Engine time: 0.04619823442772031 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-16/adapters_160_slots_64_rate_1.6-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-16/adapters_160_slots_64_rate_1.6-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 270, 33, 33, 33, 17280, 33, 270, 17280, 270, 33, 270, 270, 270, 270, 17280, 17280, 17280, 270, 270, 270, 17280, 17280, 33, 17280, 270, 17280, 17280, 17280, 270, 17280, 33, 270, 270, 270, 17280, 33, 33, 17280, 33, 17280, 33, 33, 270, 33, 270, 17280, 33, 33, 270, 33, 33, 33, 33, 33, 17280, 270, 270, 17280, 270, 33, 17280, 17280, 17280, 270, 270, 33, 33, 33, 17280, 33, 270, 270, 33, 17280, 17280, 17280, 33, 33, 17280, 270, 17280, 17280, 33, 17280, 33, 270, 33, 33, 270, 270, 17280, 17280, 17280, 33, 17280, 270, 270, 33, 33, 33, 33, 17280, 270, 17280, 270, 17280, 17280, 17280, 33, 270, 270, 17280, 270, 17280, 33, 33, 33, 270, 270, 270, 17280, 17280, 270, 17280, 33, 270, 270, 33, 17280, 17280, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 270, 17280, 33, 17280, 33, 17280, 270, 33, 270, 33, 33, 270, 270, 270, 17280, 270, 33, 33]
Prompts retrieved: 949179 . Total input tokens: 211679878 . Total output tokens: 186680714
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.68462220299989,
    "estimated_duration": 3600.088663155801,
    "input_throughput": 5474.4123948113665,
    "output_throughput": 4774.938510800799,
    "total_throughput": 10249.350905612166,
    "itl": 110.4642251418864,
    "ttft": 1884372.411396521,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.268604749441149,
    "arrivals": 316555,
    "finished_requests": 79822,
    "scheduler_time": 149.19693178150726
}
#Debug simulation 
Total elapsed time: 5.684715396724641. Arrivals time: 0.24589819507673383 Scheduler time: 5.29660108871758 Scheduler overhead time: 0.05045731598511338 Adapter cache time: 0.020240986719727516 Engine time: 0.048900782596319914 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-32/adapters_160_slots_64_rate_1.6-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-32/adapters_160_slots_64_rate_1.6-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 270, 33, 33, 33, 17280, 33, 270, 17280, 270, 33, 270, 270, 270, 270, 17280, 17280, 17280, 270, 270, 270, 17280, 17280, 33, 17280, 270, 17280, 17280, 17280, 270, 17280, 33, 270, 270, 270, 17280, 33, 33, 17280, 33, 17280, 33, 33, 270, 33, 270, 17280, 33, 33, 270, 33, 33, 33, 33, 33, 17280, 270, 270, 17280, 270, 33, 17280, 17280, 17280, 270, 270, 33, 33, 33, 17280, 33, 270, 270, 33, 17280, 17280, 17280, 33, 33, 17280, 270, 17280, 17280, 33, 17280, 33, 270, 33, 33, 270, 270, 17280, 17280, 17280, 33, 17280, 270, 270, 33, 33, 33, 33, 17280, 270, 17280, 270, 17280, 17280, 17280, 33, 270, 270, 17280, 270, 17280, 33, 33, 33, 270, 270, 270, 17280, 17280, 270, 17280, 33, 270, 270, 33, 17280, 17280, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 270, 17280, 33, 17280, 33, 17280, 270, 33, 270, 33, 33, 270, 270, 270, 17280, 270, 33, 33]
Prompts retrieved: 949179 . Total input tokens: 211679878 . Total output tokens: 186680714
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.445008603390306,
    "estimated_duration": 3600.001077644944,
    "input_throughput": 5202.608998176311,
    "output_throughput": 4545.203917189994,
    "total_throughput": 9747.812915366305,
    "itl": 97.40094380850886,
    "ttft": 1921624.849952371,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1125,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.482373888082797,
    "arrivals": 316555,
    "finished_requests": 75883,
    "scheduler_time": 156.64087221915426
}
#Debug simulation 
Total elapsed time: 5.445100899320096. Arrivals time: 0.2356709628365934 Scheduler time: 5.052564735058695 Scheduler overhead time: 0.055308496579527855 Adapter cache time: 0.022120671812444925 Engine time: 0.054541675839573145 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_8-16-16/adapters_160_slots_64_rate_1.6-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_8-16-16/adapters_160_slots_64_rate_1.6-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 270, 33, 33, 33, 17280, 33, 270, 17280, 270, 33, 270, 270, 270, 270, 17280, 17280, 17280, 270, 270, 270, 17280, 17280, 33, 17280, 270, 17280, 17280, 17280, 270, 17280, 33, 270, 270, 270, 17280, 33, 33, 17280, 33, 17280, 33, 33, 270, 33, 270, 17280, 33, 33, 270, 33, 33, 33, 33, 33, 17280, 270, 270, 17280, 270, 33, 17280, 17280, 17280, 270, 270, 33, 33, 33, 17280, 33, 270, 270, 33, 17280, 17280, 17280, 33, 33, 17280, 270, 17280, 17280, 33, 17280, 33, 270, 33, 33, 270, 270, 17280, 17280, 17280, 33, 17280, 270, 270, 33, 33, 33, 33, 17280, 270, 17280, 270, 17280, 17280, 17280, 33, 270, 270, 17280, 270, 17280, 33, 33, 33, 270, 270, 270, 17280, 17280, 270, 17280, 33, 270, 270, 33, 17280, 17280, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 270, 17280, 33, 17280, 33, 17280, 270, 33, 270, 33, 33, 270, 270, 270, 17280, 270, 33, 33]
Prompts retrieved: 949179 . Total input tokens: 211679878 . Total output tokens: 186680714
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 5.668510274961591,
    "estimated_duration": 3600.0651895141305,
    "input_throughput": 5475.024190509213,
    "output_throughput": 4775.583245013491,
    "total_throughput": 10250.607435522705,
    "itl": 110.44776798494463,
    "ttft": 1884114.8895435904,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.7230339069291825,
    "arrivals": 316555,
    "finished_requests": 79829,
    "scheduler_time": 149.2195590119302
}
#Debug simulation 
Total elapsed time: 5.668634145986289. Arrivals time: 0.24610707676038146 Scheduler time: 5.28058469761163 Scheduler overhead time: 0.050330592319369316 Adapter cache time: 0.01997610554099083 Engine time: 0.04906898504123092 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_8-16-32/adapters_160_slots_64_rate_1.6-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_8-16-32/adapters_160_slots_64_rate_1.6-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 270, 33, 33, 33, 17280, 33, 270, 17280, 270, 33, 270, 270, 270, 270, 17280, 17280, 17280, 270, 270, 270, 17280, 17280, 33, 17280, 270, 17280, 17280, 17280, 270, 17280, 33, 270, 270, 270, 17280, 33, 33, 17280, 33, 17280, 33, 33, 270, 33, 270, 17280, 33, 33, 270, 33, 33, 33, 33, 33, 17280, 270, 270, 17280, 270, 33, 17280, 17280, 17280, 270, 270, 33, 33, 33, 17280, 33, 270, 270, 33, 17280, 17280, 17280, 33, 33, 17280, 270, 17280, 17280, 33, 17280, 33, 270, 33, 33, 270, 270, 17280, 17280, 17280, 33, 17280, 270, 270, 33, 33, 33, 33, 17280, 270, 17280, 270, 17280, 17280, 17280, 33, 270, 270, 17280, 270, 17280, 33, 33, 33, 270, 270, 270, 17280, 17280, 270, 17280, 33, 270, 270, 33, 17280, 17280, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 270, 17280, 33, 17280, 33, 17280, 270, 33, 270, 33, 33, 270, 270, 270, 17280, 270, 33, 33]
Prompts retrieved: 949179 . Total input tokens: 211679878 . Total output tokens: 186680714
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 5.426739783957601,
    "estimated_duration": 3600.084896400214,
    "input_throughput": 5202.957302126273,
    "output_throughput": 4545.6147482419765,
    "total_throughput": 9748.57205036825,
    "itl": 97.40038251199896,
    "ttft": 1921752.6539745873,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1124,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.392900764299554,
    "arrivals": 316555,
    "finished_requests": 75888,
    "scheduler_time": 156.6502965261003
}
#Debug simulation 
Total elapsed time: 5.426857484970242. Arrivals time: 0.23755499674007297 Scheduler time: 5.034016300458461 Scheduler overhead time: 0.05517491931095719 Adapter cache time: 0.021593037527054548 Engine time: 0.05366148008033633 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_16-16-16/adapters_160_slots_64_rate_1.6-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_16-16-16/adapters_160_slots_64_rate_1.6-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 270, 33, 33, 33, 17280, 33, 270, 17280, 270, 33, 270, 270, 270, 270, 17280, 17280, 17280, 270, 270, 270, 17280, 17280, 33, 17280, 270, 17280, 17280, 17280, 270, 17280, 33, 270, 270, 270, 17280, 33, 33, 17280, 33, 17280, 33, 33, 270, 33, 270, 17280, 33, 33, 270, 33, 33, 33, 33, 33, 17280, 270, 270, 17280, 270, 33, 17280, 17280, 17280, 270, 270, 33, 33, 33, 17280, 33, 270, 270, 33, 17280, 17280, 17280, 33, 33, 17280, 270, 17280, 17280, 33, 17280, 33, 270, 33, 33, 270, 270, 17280, 17280, 17280, 33, 17280, 270, 270, 33, 33, 33, 33, 17280, 270, 17280, 270, 17280, 17280, 17280, 33, 270, 270, 17280, 270, 17280, 33, 33, 33, 270, 270, 270, 17280, 17280, 270, 17280, 33, 270, 270, 33, 17280, 17280, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 270, 17280, 33, 17280, 33, 17280, 270, 33, 270, 33, 33, 270, 270, 270, 17280, 270, 33, 33]
Prompts retrieved: 949179 . Total input tokens: 211679878 . Total output tokens: 186680714
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.67719090403989,
    "estimated_duration": 3600.0039714479526,
    "input_throughput": 5475.552015036155,
    "output_throughput": 4776.248619826999,
    "total_throughput": 10251.800634863155,
    "itl": 110.4312289352487,
    "ttft": 1883977.8699270969,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1129,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.2074467419040955,
    "arrivals": 316555,
    "finished_requests": 79838,
    "scheduler_time": 149.23561321181342
}
#Debug simulation 
Total elapsed time: 5.677289911080152. Arrivals time: 0.24028068641200662 Scheduler time: 5.295380268245935 Scheduler overhead time: 0.050362927839159966 Adapter cache time: 0.01993728382512927 Engine time: 0.048794872127473354 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_16-16-32/adapters_160_slots_64_rate_1.6-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.003125_size_16-16-32/adapters_160_slots_64_rate_1.6-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 270, 33, 33, 33, 17280, 33, 270, 17280, 270, 33, 270, 270, 270, 270, 17280, 17280, 17280, 270, 270, 270, 17280, 17280, 33, 17280, 270, 17280, 17280, 17280, 270, 17280, 33, 270, 270, 270, 17280, 33, 33, 17280, 33, 17280, 33, 33, 270, 33, 270, 17280, 33, 33, 270, 33, 33, 33, 33, 33, 17280, 270, 270, 17280, 270, 33, 17280, 17280, 17280, 270, 270, 33, 33, 33, 17280, 33, 270, 270, 33, 17280, 17280, 17280, 33, 33, 17280, 270, 17280, 17280, 33, 17280, 33, 270, 33, 33, 270, 270, 17280, 17280, 17280, 33, 17280, 270, 270, 33, 33, 33, 33, 17280, 270, 17280, 270, 17280, 17280, 17280, 33, 270, 270, 17280, 270, 17280, 33, 33, 33, 270, 270, 270, 17280, 17280, 270, 17280, 33, 270, 270, 33, 17280, 17280, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 270, 17280, 33, 17280, 33, 17280, 270, 33, 270, 33, 33, 270, 270, 270, 17280, 270, 33, 33]
Prompts retrieved: 949179 . Total input tokens: 211679878 . Total output tokens: 186680714
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.425242152996361,
    "estimated_duration": 3600.0588237920897,
    "input_throughput": 5202.766653760019,
    "output_throughput": 4545.379617648445,
    "total_throughput": 9748.146271408465,
    "itl": 97.39764689610885,
    "ttft": 1921768.8987533909,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1124,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.3146104715392,
    "arrivals": 316555,
    "finished_requests": 75886,
    "scheduler_time": 156.65312705894968
}
#Debug simulation 
Total elapsed time: 5.425338971894234. Arrivals time: 0.23356100590899587 Scheduler time: 5.036591598764062 Scheduler overhead time: 0.05519015062600374 Adapter cache time: 0.021366136148571968 Engine time: 0.053841542452573776 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-8/adapters_160_slots_64_rate_1.6-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-8/adapters_160_slots_64_rate_1.6-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 135, 66, 66, 66, 17280, 66, 135, 17280, 135, 66, 135, 135, 135, 135, 17280, 17280, 17280, 135, 135, 135, 17280, 17280, 66, 17280, 135, 17280, 17280, 17280, 135, 17280, 66, 135, 135, 135, 17280, 66, 66, 17280, 66, 17280, 66, 66, 135, 66, 135, 17280, 66, 66, 135, 66, 66, 66, 66, 66, 17280, 135, 135, 17280, 135, 66, 17280, 17280, 17280, 135, 135, 66, 66, 66, 17280, 66, 135, 135, 66, 17280, 17280, 17280, 66, 66, 17280, 135, 17280, 17280, 66, 17280, 66, 135, 66, 66, 135, 135, 17280, 17280, 17280, 66, 17280, 135, 135, 66, 66, 66, 66, 17280, 135, 17280, 135, 17280, 17280, 17280, 66, 135, 135, 17280, 135, 17280, 66, 66, 66, 135, 135, 135, 17280, 17280, 135, 17280, 66, 135, 135, 66, 17280, 17280, 17280, 17280, 17280, 17280, 135, 135, 135, 135, 135, 17280, 66, 17280, 66, 17280, 135, 66, 135, 66, 66, 135, 135, 135, 17280, 135, 66, 66]
Prompts retrieved: 943773 . Total input tokens: 210485266 . Total output tokens: 185624437
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.885734390001744,
    "estimated_duration": 3600.1067971835223,
    "input_throughput": 5716.0776497239485,
    "output_throughput": 4976.509034125384,
    "total_throughput": 10692.586683849333,
    "itl": 116.04374894651188,
    "ttft": 1849039.6181643028,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 880,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.818919948116065,
    "arrivals": 314729,
    "finished_requests": 82948,
    "scheduler_time": 148.33678441669514
}
#Debug simulation 
Total elapsed time: 5.885837509762496. Arrivals time: 0.25713968789204955 Scheduler time: 5.494667690712959 Scheduler overhead time: 0.04815762909129262 Adapter cache time: 0.01738046295940876 Engine time: 0.046935591381043196 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-16/adapters_160_slots_64_rate_1.6-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-16/adapters_160_slots_64_rate_1.6-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 135, 66, 66, 66, 17280, 66, 135, 17280, 135, 66, 135, 135, 135, 135, 17280, 17280, 17280, 135, 135, 135, 17280, 17280, 66, 17280, 135, 17280, 17280, 17280, 135, 17280, 66, 135, 135, 135, 17280, 66, 66, 17280, 66, 17280, 66, 66, 135, 66, 135, 17280, 66, 66, 135, 66, 66, 66, 66, 66, 17280, 135, 135, 17280, 135, 66, 17280, 17280, 17280, 135, 135, 66, 66, 66, 17280, 66, 135, 135, 66, 17280, 17280, 17280, 66, 66, 17280, 135, 17280, 17280, 66, 17280, 66, 135, 66, 66, 135, 135, 17280, 17280, 17280, 66, 17280, 135, 135, 66, 66, 66, 66, 17280, 135, 17280, 135, 17280, 17280, 17280, 66, 135, 135, 17280, 135, 17280, 66, 66, 66, 135, 135, 135, 17280, 17280, 135, 17280, 66, 135, 135, 66, 17280, 17280, 17280, 17280, 17280, 17280, 135, 135, 135, 135, 135, 17280, 66, 17280, 66, 17280, 135, 66, 135, 66, 66, 135, 135, 135, 17280, 135, 66, 66]
Prompts retrieved: 943773 . Total input tokens: 210485266 . Total output tokens: 185624437
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.720152743160725,
    "estimated_duration": 3600.040802541252,
    "input_throughput": 5575.528751182813,
    "output_throughput": 4858.149381988731,
    "total_throughput": 10433.678133171545,
    "itl": 108.0880009634387,
    "ttft": 1868462.5084538523,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 856,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.258698721863338,
    "arrivals": 314729,
    "finished_requests": 80906,
    "scheduler_time": 152.2101623555131
}
#Debug simulation 
Total elapsed time: 5.720244844909757. Arrivals time: 0.2581262239255011 Scheduler time: 5.322061292361468 Scheduler overhead time: 0.05060572735965252 Adapter cache time: 0.017663005273789167 Engine time: 0.04915072303265333 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-32/adapters_160_slots_64_rate_1.6-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-32/adapters_160_slots_64_rate_1.6-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 135, 66, 66, 66, 17280, 66, 135, 17280, 135, 66, 135, 135, 135, 135, 17280, 17280, 17280, 135, 135, 135, 17280, 17280, 66, 17280, 135, 17280, 17280, 17280, 135, 17280, 66, 135, 135, 135, 17280, 66, 66, 17280, 66, 17280, 66, 66, 135, 66, 135, 17280, 66, 66, 135, 66, 66, 66, 66, 66, 17280, 135, 135, 17280, 135, 66, 17280, 17280, 17280, 135, 135, 66, 66, 66, 17280, 66, 135, 135, 66, 17280, 17280, 17280, 66, 66, 17280, 135, 17280, 17280, 66, 17280, 66, 135, 66, 66, 135, 135, 17280, 17280, 17280, 66, 17280, 135, 135, 66, 66, 66, 66, 17280, 135, 17280, 135, 17280, 17280, 17280, 66, 135, 135, 17280, 135, 17280, 66, 66, 66, 135, 135, 135, 17280, 17280, 135, 17280, 66, 135, 135, 66, 17280, 17280, 17280, 17280, 17280, 17280, 135, 135, 135, 135, 135, 17280, 66, 17280, 66, 17280, 135, 66, 135, 66, 66, 135, 135, 135, 17280, 135, 66, 66]
Prompts retrieved: 943773 . Total input tokens: 210485266 . Total output tokens: 185624437
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.535395167768002,
    "estimated_duration": 3600.018609361954,
    "input_throughput": 5312.027262933876,
    "output_throughput": 4621.966663374839,
    "total_throughput": 9933.993926308716,
    "itl": 95.42402354121488,
    "ttft": 1909449.1135434338,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 812,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.096393852876525,
    "arrivals": 314729,
    "finished_requests": 77076,
    "scheduler_time": 159.65984364067214
}
#Debug simulation 
Total elapsed time: 5.535488800611347. Arrivals time: 0.23805368319153786 Scheduler time: 5.141488198656589 Scheduler overhead time: 0.05658991541713476 Adapter cache time: 0.018345600925385952 Engine time: 0.05572408251464367 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_8-16-16/adapters_160_slots_64_rate_1.6-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_8-16-16/adapters_160_slots_64_rate_1.6-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 135, 66, 66, 66, 17280, 66, 135, 17280, 135, 66, 135, 135, 135, 135, 17280, 17280, 17280, 135, 135, 135, 17280, 17280, 66, 17280, 135, 17280, 17280, 17280, 135, 17280, 66, 135, 135, 135, 17280, 66, 66, 17280, 66, 17280, 66, 66, 135, 66, 135, 17280, 66, 66, 135, 66, 66, 66, 66, 66, 17280, 135, 135, 17280, 135, 66, 17280, 17280, 17280, 135, 135, 66, 66, 66, 17280, 66, 135, 135, 66, 17280, 17280, 17280, 66, 66, 17280, 135, 17280, 17280, 66, 17280, 66, 135, 66, 66, 135, 135, 17280, 17280, 17280, 66, 17280, 135, 135, 66, 66, 66, 66, 17280, 135, 17280, 135, 17280, 17280, 17280, 66, 135, 135, 17280, 135, 17280, 66, 66, 66, 135, 135, 135, 17280, 17280, 135, 17280, 66, 135, 135, 66, 17280, 17280, 17280, 17280, 17280, 17280, 135, 135, 135, 135, 135, 17280, 66, 17280, 66, 17280, 135, 66, 135, 66, 66, 135, 135, 135, 17280, 135, 66, 66]
Prompts retrieved: 943773 . Total input tokens: 210485266 . Total output tokens: 185624437
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 5.797668871935457,
    "estimated_duration": 3600.015080058745,
    "input_throughput": 5576.594417952384,
    "output_throughput": 4858.786035894764,
    "total_throughput": 10435.380453847147,
    "itl": 108.07344614269469,
    "ttft": 1868403.8414501734,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 855,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.859448265475213,
    "arrivals": 314729,
    "finished_requests": 80917,
    "scheduler_time": 152.2245758221309
}
#Debug simulation 
Total elapsed time: 5.797760661691427. Arrivals time: 0.27164426539093256 Scheduler time: 5.385181718040258 Scheduler overhead time: 0.05100831389427185 Adapter cache time: 0.017673401162028313 Engine time: 0.0493807946331799 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_8-16-32/adapters_160_slots_64_rate_1.6-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_8-16-32/adapters_160_slots_64_rate_1.6-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 135, 66, 66, 66, 17280, 66, 135, 17280, 135, 66, 135, 135, 135, 135, 17280, 17280, 17280, 135, 135, 135, 17280, 17280, 66, 17280, 135, 17280, 17280, 17280, 135, 17280, 66, 135, 135, 135, 17280, 66, 66, 17280, 66, 17280, 66, 66, 135, 66, 135, 17280, 66, 66, 135, 66, 66, 66, 66, 66, 17280, 135, 135, 17280, 135, 66, 17280, 17280, 17280, 135, 135, 66, 66, 66, 17280, 66, 135, 135, 66, 17280, 17280, 17280, 66, 66, 17280, 135, 17280, 17280, 66, 17280, 66, 135, 66, 66, 135, 135, 17280, 17280, 17280, 66, 17280, 135, 135, 66, 66, 66, 66, 17280, 135, 17280, 135, 17280, 17280, 17280, 66, 135, 135, 17280, 135, 17280, 66, 66, 66, 135, 135, 135, 17280, 17280, 135, 17280, 66, 135, 135, 66, 17280, 17280, 17280, 17280, 17280, 17280, 135, 135, 135, 135, 135, 17280, 66, 17280, 66, 17280, 135, 66, 135, 66, 66, 135, 135, 135, 17280, 135, 66, 66]
Prompts retrieved: 943773 . Total input tokens: 210485266 . Total output tokens: 185624437
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 5.5358110456727445,
    "estimated_duration": 3600.074177732865,
    "input_throughput": 5312.028601600395,
    "output_throughput": 4622.010597147952,
    "total_throughput": 9934.039198748345,
    "itl": 95.42371121400662,
    "ttft": 1909510.2645158798,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 812,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.041507801073629,
    "arrivals": 314729,
    "finished_requests": 77077,
    "scheduler_time": 159.66442624735765
}
#Debug simulation 
Total elapsed time: 5.535906303673983. Arrivals time: 0.2745131361298263 Scheduler time: 5.106803112663329 Scheduler overhead time: 0.056281321216374636 Adapter cache time: 0.018373440019786358 Engine time: 0.054660739842802286 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_16-16-16/adapters_160_slots_64_rate_1.6-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_16-16-16/adapters_160_slots_64_rate_1.6-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 135, 66, 66, 66, 17280, 66, 135, 17280, 135, 66, 135, 135, 135, 135, 17280, 17280, 17280, 135, 135, 135, 17280, 17280, 66, 17280, 135, 17280, 17280, 17280, 135, 17280, 66, 135, 135, 135, 17280, 66, 66, 17280, 66, 17280, 66, 66, 135, 66, 135, 17280, 66, 66, 135, 66, 66, 66, 66, 66, 17280, 135, 135, 17280, 135, 66, 17280, 17280, 17280, 135, 135, 66, 66, 66, 17280, 66, 135, 135, 66, 17280, 17280, 17280, 66, 66, 17280, 135, 17280, 17280, 66, 17280, 66, 135, 66, 66, 135, 135, 17280, 17280, 17280, 66, 17280, 135, 135, 66, 66, 66, 66, 17280, 135, 17280, 135, 17280, 17280, 17280, 66, 135, 135, 17280, 135, 17280, 66, 66, 66, 135, 135, 135, 17280, 17280, 135, 17280, 66, 135, 135, 66, 17280, 17280, 17280, 17280, 17280, 17280, 135, 135, 135, 135, 135, 17280, 66, 17280, 66, 17280, 135, 66, 135, 66, 66, 135, 135, 135, 17280, 135, 66, 66]
Prompts retrieved: 943773 . Total input tokens: 210485266 . Total output tokens: 185624437
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.74345037015155,
    "estimated_duration": 3600.0972888816846,
    "input_throughput": 5577.4237163011,
    "output_throughput": 4859.251458016618,
    "total_throughput": 10436.675174317717,
    "itl": 108.06261964821446,
    "ttft": 1868515.964021987,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 855,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.458252404187779,
    "arrivals": 314729,
    "finished_requests": 80931,
    "scheduler_time": 152.24142299317938
}
#Debug simulation 
Total elapsed time: 5.743540963158011. Arrivals time: 0.27068816125392914 Scheduler time: 5.3317234930582345 Scheduler overhead time: 0.051127251237630844 Adapter cache time: 0.01780125591903925 Engine time: 0.04942900454625487 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_16-16-32/adapters_160_slots_64_rate_1.6-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.00625_size_16-16-32/adapters_160_slots_64_rate_1.6-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [53 53 54]
Adapter prompts. [66, 17280, 66, 66, 135, 66, 66, 66, 17280, 66, 135, 17280, 135, 66, 135, 135, 135, 135, 17280, 17280, 17280, 135, 135, 135, 17280, 17280, 66, 17280, 135, 17280, 17280, 17280, 135, 17280, 66, 135, 135, 135, 17280, 66, 66, 17280, 66, 17280, 66, 66, 135, 66, 135, 17280, 66, 66, 135, 66, 66, 66, 66, 66, 17280, 135, 135, 17280, 135, 66, 17280, 17280, 17280, 135, 135, 66, 66, 66, 17280, 66, 135, 135, 66, 17280, 17280, 17280, 66, 66, 17280, 135, 17280, 17280, 66, 17280, 66, 135, 66, 66, 135, 135, 17280, 17280, 17280, 66, 17280, 135, 135, 66, 66, 66, 66, 17280, 135, 17280, 135, 17280, 17280, 17280, 66, 135, 135, 17280, 135, 17280, 66, 66, 66, 135, 135, 135, 17280, 17280, 135, 17280, 66, 135, 135, 66, 17280, 17280, 17280, 17280, 17280, 17280, 135, 135, 135, 135, 135, 17280, 66, 17280, 66, 17280, 135, 66, 135, 66, 66, 135, 135, 135, 17280, 135, 66, 66]
Prompts retrieved: 943773 . Total input tokens: 210485266 . Total output tokens: 185624437
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.555515837389976,
    "estimated_duration": 3600.080860719751,
    "input_throughput": 5311.854022127933,
    "output_throughput": 4621.981739786068,
    "total_throughput": 9933.835761914,
    "itl": 95.42172497687865,
    "ttft": 1909443.998623957,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 812,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.984136343151358,
    "arrivals": 314729,
    "finished_requests": 77077,
    "scheduler_time": 159.66527578628333
}
#Debug simulation 
Total elapsed time: 5.555604824330658. Arrivals time: 0.2621613903902471 Scheduler time: 5.138520206790417 Scheduler overhead time: 0.056268337182700634 Adapter cache time: 0.01850921707227826 Engine time: 0.05480680335313082 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-8/adapters_160_slots_64_rate_1.6-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-8/adapters_160_slots_64_rate_1.6-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 135, 33, 33, 33, 17280, 33, 135, 17280, 135, 33, 135, 135, 135, 135, 17280, 17280, 17280, 135, 135, 135, 17280, 17280, 33, 17280, 135, 17280, 17280, 17280, 135, 17280, 33, 135, 135, 135, 17280, 33, 33, 17280, 33, 17280, 33, 33, 135, 33, 135, 17280, 33, 33, 135, 33, 33, 33, 33, 33, 17280, 135, 135, 17280, 135, 33, 17280, 17280, 17280, 135, 135, 33, 33, 33, 17280, 33, 135, 135, 33, 17280, 17280, 17280, 33, 33, 17280, 135, 17280, 17280, 33, 17280, 33, 135, 33, 33, 135, 135, 17280, 17280, 17280, 33, 17280, 135, 135, 33, 33, 33, 33, 17280, 135, 17280, 135, 17280, 17280, 17280, 33, 135, 135, 17280, 135, 17280, 33, 33, 33, 135, 135, 135, 17280, 17280, 135, 17280, 33, 135, 135, 33, 17280, 17280, 17280, 17280, 17280, 17280, 135, 135, 135, 135, 135, 17280, 33, 17280, 33, 17280, 135, 33, 135, 33, 33, 135, 135, 135, 17280, 135, 33, 33]
Prompts retrieved: 942024 . Total input tokens: 210077244 . Total output tokens: 185294656
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.8672707779332995,
    "estimated_duration": 3600.057270938334,
    "input_throughput": 5673.153636991082,
    "output_throughput": 4999.283246210414,
    "total_throughput": 10672.436883201497,
    "itl": 115.81473018438635,
    "ttft": 1843427.0119825583,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 771,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.0981673636334985,
    "arrivals": 314142,
    "finished_requests": 83145,
    "scheduler_time": 148.76559231385409
}
#Debug simulation 
Total elapsed time: 5.867364375852048. Arrivals time: 0.2743790065869689 Scheduler time: 5.460496956948191 Scheduler overhead time: 0.04807400517165661 Adapter cache time: 0.01633878517895937 Engine time: 0.04658245574682951 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-16/adapters_160_slots_64_rate_1.6-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-16/adapters_160_slots_64_rate_1.6-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 135, 33, 33, 33, 17280, 33, 135, 17280, 135, 33, 135, 135, 135, 135, 17280, 17280, 17280, 135, 135, 135, 17280, 17280, 33, 17280, 135, 17280, 17280, 17280, 135, 17280, 33, 135, 135, 135, 17280, 33, 33, 17280, 33, 17280, 33, 33, 135, 33, 135, 17280, 33, 33, 135, 33, 33, 33, 33, 33, 17280, 135, 135, 17280, 135, 33, 17280, 17280, 17280, 135, 135, 33, 33, 33, 17280, 33, 135, 135, 33, 17280, 17280, 17280, 33, 33, 17280, 135, 17280, 17280, 33, 17280, 33, 135, 33, 33, 135, 135, 17280, 17280, 17280, 33, 17280, 135, 135, 33, 33, 33, 33, 17280, 135, 17280, 135, 17280, 17280, 17280, 33, 135, 135, 17280, 135, 17280, 33, 33, 33, 135, 135, 135, 17280, 17280, 135, 17280, 33, 135, 135, 33, 17280, 17280, 17280, 17280, 17280, 17280, 135, 135, 135, 135, 135, 17280, 33, 17280, 33, 17280, 135, 33, 135, 33, 33, 135, 135, 135, 17280, 135, 33, 33]
Prompts retrieved: 942024 . Total input tokens: 210077244 . Total output tokens: 185294656
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.719544216990471,
    "estimated_duration": 3600.0429682359045,
    "input_throughput": 5535.911703233331,
    "output_throughput": 4879.03593234252,
    "total_throughput": 10414.94763557585,
    "itl": 107.92365312434734,
    "ttft": 1863593.8164977657,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 750,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.50842739057728,
    "arrivals": 314142,
    "finished_requests": 81121,
    "scheduler_time": 152.61436410718434
}
#Debug simulation 
Total elapsed time: 5.719637559726834. Arrivals time: 0.24592051468789577 Scheduler time: 5.334072281140834 Scheduler overhead time: 0.0507094319909811 Adapter cache time: 0.016936009284108877 Engine time: 0.049369939137250185 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-32/adapters_160_slots_64_rate_1.6-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-32/adapters_160_slots_64_rate_1.6-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 135, 33, 33, 33, 17280, 33, 135, 17280, 135, 33, 135, 135, 135, 135, 17280, 17280, 17280, 135, 135, 135, 17280, 17280, 33, 17280, 135, 17280, 17280, 17280, 135, 17280, 33, 135, 135, 135, 17280, 33, 33, 17280, 33, 17280, 33, 33, 135, 33, 135, 17280, 33, 33, 135, 33, 33, 33, 33, 33, 17280, 135, 135, 17280, 135, 33, 17280, 17280, 17280, 135, 135, 33, 33, 33, 17280, 33, 135, 135, 33, 17280, 17280, 17280, 33, 33, 17280, 135, 17280, 17280, 33, 17280, 33, 135, 33, 33, 135, 135, 17280, 17280, 17280, 33, 17280, 135, 135, 33, 33, 33, 33, 17280, 135, 17280, 135, 17280, 17280, 17280, 33, 135, 135, 17280, 135, 17280, 33, 33, 33, 135, 135, 135, 17280, 17280, 135, 17280, 33, 135, 135, 33, 17280, 17280, 17280, 17280, 17280, 17280, 135, 135, 135, 135, 135, 17280, 33, 17280, 33, 17280, 135, 33, 135, 33, 33, 135, 135, 135, 17280, 135, 33, 33]
Prompts retrieved: 942024 . Total input tokens: 210077244 . Total output tokens: 185294656
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.52930524898693,
    "estimated_duration": 3600.0762032126145,
    "input_throughput": 5258.859793885838,
    "output_throughput": 4638.080989813392,
    "total_throughput": 9896.94078369923,
    "itl": 95.34325272023986,
    "ttft": 1902909.4624336418,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 708,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.3436313481396365,
    "arrivals": 314142,
    "finished_requests": 77083,
    "scheduler_time": 159.9641922235365
}
#Debug simulation 
Total elapsed time: 5.529419852420688. Arrivals time: 0.2388923275284469 Scheduler time: 5.136240804567933 Scheduler overhead time: 0.0563466758467257 Adapter cache time: 0.017555699218064547 Engine time: 0.05502324411645532 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_8-16-16/adapters_160_slots_64_rate_1.6-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_8-16-16/adapters_160_slots_64_rate_1.6-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 135, 33, 33, 33, 17280, 33, 135, 17280, 135, 33, 135, 135, 135, 135, 17280, 17280, 17280, 135, 135, 135, 17280, 17280, 33, 17280, 135, 17280, 17280, 17280, 135, 17280, 33, 135, 135, 135, 17280, 33, 33, 17280, 33, 17280, 33, 33, 135, 33, 135, 17280, 33, 33, 135, 33, 33, 33, 33, 33, 17280, 135, 135, 17280, 135, 33, 17280, 17280, 17280, 135, 135, 33, 33, 33, 17280, 33, 135, 135, 33, 17280, 17280, 17280, 33, 33, 17280, 135, 17280, 17280, 33, 17280, 33, 135, 33, 33, 135, 135, 17280, 17280, 17280, 33, 17280, 135, 135, 33, 33, 33, 33, 17280, 135, 17280, 135, 17280, 17280, 17280, 33, 135, 135, 17280, 135, 17280, 33, 33, 33, 135, 135, 135, 17280, 17280, 135, 17280, 33, 135, 135, 33, 17280, 17280, 17280, 17280, 17280, 17280, 135, 135, 135, 135, 135, 17280, 33, 17280, 33, 17280, 135, 33, 135, 33, 33, 135, 135, 135, 17280, 135, 33, 33]
Prompts retrieved: 942024 . Total input tokens: 210077244 . Total output tokens: 185294656
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 5.707194836810231,
    "estimated_duration": 3600.002371678721,
    "input_throughput": 5536.476074793752,
    "output_throughput": 4879.760396326696,
    "total_throughput": 10416.236471120446,
    "itl": 107.90924006369714,
    "ttft": 1863512.2746913063,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 750,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.159983926275738,
    "arrivals": 314142,
    "finished_requests": 81131,
    "scheduler_time": 152.62783824351135
}
#Debug simulation 
Total elapsed time: 5.707288263831288. Arrivals time: 0.24410380329936743 Scheduler time: 5.323924938682467 Scheduler overhead time: 0.05051244189962745 Adapter cache time: 0.016615918837487698 Engine time: 0.04935959680005908 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_8-16-32/adapters_160_slots_64_rate_1.6-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_8-16-32/adapters_160_slots_64_rate_1.6-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 135, 33, 33, 33, 17280, 33, 135, 17280, 135, 33, 135, 135, 135, 135, 17280, 17280, 17280, 135, 135, 135, 17280, 17280, 33, 17280, 135, 17280, 17280, 17280, 135, 17280, 33, 135, 135, 135, 17280, 33, 33, 17280, 33, 17280, 33, 33, 135, 33, 135, 17280, 33, 33, 135, 33, 33, 33, 33, 33, 17280, 135, 135, 17280, 135, 33, 17280, 17280, 17280, 135, 135, 33, 33, 33, 17280, 33, 135, 135, 33, 17280, 17280, 17280, 33, 33, 17280, 135, 17280, 17280, 33, 17280, 33, 135, 33, 33, 135, 135, 17280, 17280, 17280, 33, 17280, 135, 135, 33, 33, 33, 33, 17280, 135, 17280, 135, 17280, 17280, 17280, 33, 135, 135, 17280, 135, 17280, 33, 33, 33, 135, 135, 135, 17280, 17280, 135, 17280, 33, 135, 135, 33, 17280, 17280, 17280, 17280, 17280, 17280, 135, 135, 135, 135, 135, 17280, 33, 17280, 33, 17280, 135, 33, 135, 33, 33, 135, 135, 135, 17280, 135, 33, 33]
Prompts retrieved: 942024 . Total input tokens: 210077244 . Total output tokens: 185294656
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 5.513006873894483,
    "estimated_duration": 3600.0752196815206,
    "input_throughput": 5258.861230592521,
    "output_throughput": 4638.082256924936,
    "total_throughput": 9896.943487517456,
    "itl": 95.3434610122735,
    "ttft": 1902905.679498623,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 707,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.285847152378441,
    "arrivals": 314142,
    "finished_requests": 77083,
    "scheduler_time": 159.96505976041024
}
#Debug simulation 
Total elapsed time: 5.513101771939546. Arrivals time: 0.23740599444136024 Scheduler time: 5.122470667120069 Scheduler overhead time: 0.056195559445768595 Adapter cache time: 0.017439949791878462 Engine time: 0.054461630526930094 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_16-16-16/adapters_160_slots_64_rate_1.6-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_16-16-16/adapters_160_slots_64_rate_1.6-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 135, 33, 33, 33, 17280, 33, 135, 17280, 135, 33, 135, 135, 135, 135, 17280, 17280, 17280, 135, 135, 135, 17280, 17280, 33, 17280, 135, 17280, 17280, 17280, 135, 17280, 33, 135, 135, 135, 17280, 33, 33, 17280, 33, 17280, 33, 33, 135, 33, 135, 17280, 33, 33, 135, 33, 33, 33, 33, 33, 17280, 135, 135, 17280, 135, 33, 17280, 17280, 17280, 135, 135, 33, 33, 33, 17280, 33, 135, 135, 33, 17280, 17280, 17280, 33, 33, 17280, 135, 17280, 17280, 33, 17280, 33, 135, 33, 33, 135, 135, 17280, 17280, 17280, 33, 17280, 135, 135, 33, 33, 33, 33, 17280, 135, 17280, 135, 17280, 17280, 17280, 33, 135, 135, 17280, 135, 17280, 33, 33, 33, 135, 135, 135, 17280, 17280, 135, 17280, 33, 135, 135, 33, 17280, 17280, 17280, 17280, 17280, 17280, 135, 135, 135, 135, 135, 17280, 33, 17280, 33, 17280, 135, 33, 135, 33, 33, 135, 135, 135, 17280, 135, 33, 33]
Prompts retrieved: 942024 . Total input tokens: 210077244 . Total output tokens: 185294656
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.7689731190912426,
    "estimated_duration": 3600.090702434538,
    "input_throughput": 5536.394120992963,
    "output_throughput": 4879.755665078119,
    "total_throughput": 10416.14978607108,
    "itl": 107.89666627937038,
    "ttft": 1863585.1848802543,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 749,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.781556784487306,
    "arrivals": 314142,
    "finished_requests": 81133,
    "scheduler_time": 152.6461265914535
}
#Debug simulation 
Total elapsed time: 5.769088982138783. Arrivals time: 0.24848790746182203 Scheduler time: 5.379644935019314 Scheduler overhead time: 0.05128116486594081 Adapter cache time: 0.016963421367108822 Engine time: 0.04985715076327324 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_16-16-32/adapters_160_slots_64_rate_1.6-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.0125-0.003125_size_16-16-32/adapters_160_slots_64_rate_1.6-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 135, 33, 33, 33, 17280, 33, 135, 17280, 135, 33, 135, 135, 135, 135, 17280, 17280, 17280, 135, 135, 135, 17280, 17280, 33, 17280, 135, 17280, 17280, 17280, 135, 17280, 33, 135, 135, 135, 17280, 33, 33, 17280, 33, 17280, 33, 33, 135, 33, 135, 17280, 33, 33, 135, 33, 33, 33, 33, 33, 17280, 135, 135, 17280, 135, 33, 17280, 17280, 17280, 135, 135, 33, 33, 33, 17280, 33, 135, 135, 33, 17280, 17280, 17280, 33, 33, 17280, 135, 17280, 17280, 33, 17280, 33, 135, 33, 33, 135, 135, 17280, 17280, 17280, 33, 17280, 135, 135, 33, 33, 33, 33, 17280, 135, 17280, 135, 17280, 17280, 17280, 33, 135, 135, 17280, 135, 17280, 33, 33, 33, 135, 135, 135, 17280, 17280, 135, 17280, 33, 135, 135, 33, 17280, 17280, 17280, 17280, 17280, 17280, 135, 135, 135, 135, 135, 17280, 33, 17280, 33, 17280, 135, 33, 135, 33, 33, 135, 135, 135, 17280, 135, 33, 33]
Prompts retrieved: 942024 . Total input tokens: 210077244 . Total output tokens: 185294656
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.528134937863797,
    "estimated_duration": 3600.094537172927,
    "input_throughput": 5258.794124575127,
    "output_throughput": 4638.016815278415,
    "total_throughput": 9896.810939853542,
    "itl": 95.34163035027134,
    "ttft": 1902916.9711626119,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 706,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.226613136380942,
    "arrivals": 314142,
    "finished_requests": 77082,
    "scheduler_time": 159.96875975902935
}
#Debug simulation 
Total elapsed time: 5.5282523250207305. Arrivals time: 0.2611140548251569 Scheduler time: 5.112807578872889 Scheduler overhead time: 0.056267212610691786 Adapter cache time: 0.017480161506682634 Engine time: 0.05536297895014286 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-8/adapters_160_slots_64_rate_1.6-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-8/adapters_160_slots_64_rate_1.6-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 66, 33, 33, 33, 17280, 33, 66, 17280, 66, 33, 66, 66, 66, 66, 17280, 17280, 17280, 66, 66, 66, 17280, 17280, 33, 17280, 66, 17280, 17280, 17280, 66, 17280, 33, 66, 66, 66, 17280, 33, 33, 17280, 33, 17280, 33, 33, 66, 33, 66, 17280, 33, 33, 66, 33, 33, 33, 33, 33, 17280, 66, 66, 17280, 66, 33, 17280, 17280, 17280, 66, 66, 33, 33, 33, 17280, 33, 66, 66, 33, 17280, 17280, 17280, 33, 33, 17280, 66, 17280, 17280, 33, 17280, 33, 66, 33, 33, 66, 66, 17280, 17280, 17280, 33, 17280, 66, 66, 33, 33, 33, 33, 17280, 66, 17280, 66, 17280, 17280, 17280, 33, 66, 66, 17280, 66, 17280, 33, 33, 33, 66, 66, 66, 17280, 17280, 66, 17280, 33, 66, 66, 33, 17280, 17280, 17280, 17280, 17280, 17280, 66, 66, 66, 66, 66, 17280, 33, 17280, 33, 17280, 66, 33, 66, 33, 33, 66, 66, 66, 17280, 66, 33, 33]
Prompts retrieved: 938367 . Total input tokens: 209260215 . Total output tokens: 184571794
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.919477003626525,
    "estimated_duration": 3600.0886917468197,
    "input_throughput": 5817.898611224819,
    "output_throughput": 5079.242364756153,
    "total_throughput": 10897.140975980972,
    "itl": 113.96523797635298,
    "ttft": 1830752.302168903,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 497,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.2863672888791577,
    "arrivals": 312976,
    "finished_requests": 84919,
    "scheduler_time": 150.96974264057172
}
#Debug simulation 
Total elapsed time: 5.919573490042239. Arrivals time: 0.27802799409255385 Scheduler time: 5.5111368373036385 Scheduler overhead time: 0.048305110074579716 Adapter cache time: 0.01350249582901597 Engine time: 0.04695446416735649 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-16/adapters_160_slots_64_rate_1.6-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-16/adapters_160_slots_64_rate_1.6-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 66, 33, 33, 33, 17280, 33, 66, 17280, 66, 33, 66, 66, 66, 66, 17280, 17280, 17280, 66, 66, 66, 17280, 17280, 33, 17280, 66, 17280, 17280, 17280, 66, 17280, 33, 66, 66, 66, 17280, 33, 33, 17280, 33, 17280, 33, 33, 66, 33, 66, 17280, 33, 33, 66, 33, 33, 33, 33, 33, 17280, 66, 66, 17280, 66, 33, 17280, 17280, 17280, 66, 66, 33, 33, 33, 17280, 33, 66, 66, 33, 17280, 17280, 17280, 33, 33, 17280, 66, 17280, 17280, 33, 17280, 33, 66, 33, 33, 66, 66, 17280, 17280, 17280, 33, 17280, 66, 66, 33, 33, 33, 33, 17280, 66, 17280, 66, 17280, 17280, 17280, 33, 66, 66, 17280, 66, 17280, 33, 33, 33, 66, 66, 66, 17280, 17280, 66, 17280, 33, 66, 66, 33, 17280, 17280, 17280, 17280, 17280, 17280, 66, 66, 66, 66, 66, 17280, 33, 17280, 33, 17280, 66, 33, 66, 33, 33, 66, 66, 66, 17280, 66, 33, 33]
Prompts retrieved: 938367 . Total input tokens: 209260215 . Total output tokens: 184571794
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.781885982956737,
    "estimated_duration": 3600.026366959523,
    "input_throughput": 5665.956001657624,
    "output_throughput": 4947.05848919696,
    "total_throughput": 10613.014490854584,
    "itl": 106.19836494577176,
    "ttft": 1851353.138147854,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 474,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.474373900210489,
    "arrivals": 312976,
    "finished_requests": 82684,
    "scheduler_time": 154.72214747415234
}
#Debug simulation 
Total elapsed time: 5.7819799752905965. Arrivals time: 0.27160974871367216 Scheduler time: 5.372758232988417 Scheduler overhead time: 0.051110560074448586 Adapter cache time: 0.013808180578052998 Engine time: 0.049655059818178415 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-32/adapters_160_slots_64_rate_1.6-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-32/adapters_160_slots_64_rate_1.6-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 66, 33, 33, 33, 17280, 33, 66, 17280, 66, 33, 66, 66, 66, 66, 17280, 17280, 17280, 66, 66, 66, 17280, 17280, 33, 17280, 66, 17280, 17280, 17280, 66, 17280, 33, 66, 66, 66, 17280, 33, 33, 17280, 33, 17280, 33, 33, 66, 33, 66, 17280, 33, 33, 66, 33, 33, 33, 33, 33, 17280, 66, 66, 17280, 66, 33, 17280, 17280, 17280, 66, 66, 33, 33, 33, 17280, 33, 66, 66, 33, 17280, 17280, 17280, 33, 33, 17280, 66, 17280, 17280, 33, 17280, 33, 66, 33, 33, 66, 66, 17280, 17280, 17280, 33, 17280, 66, 66, 33, 33, 33, 33, 17280, 66, 17280, 66, 17280, 17280, 17280, 33, 66, 66, 17280, 66, 17280, 33, 33, 33, 66, 66, 66, 17280, 17280, 66, 17280, 33, 66, 66, 33, 17280, 17280, 17280, 17280, 17280, 17280, 66, 66, 66, 66, 66, 17280, 33, 17280, 33, 17280, 66, 33, 66, 33, 33, 66, 66, 66, 17280, 66, 33, 33]
Prompts retrieved: 938367 . Total input tokens: 209260215 . Total output tokens: 184571794
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.558809095993638,
    "estimated_duration": 3600.071841956466,
    "input_throughput": 5372.337233550652,
    "output_throughput": 4689.852519949842,
    "total_throughput": 10062.189753500494,
    "itl": 93.97735704734029,
    "ttft": 1893099.098569827,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 455,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.4251276514074096,
    "arrivals": 312976,
    "finished_requests": 78333,
    "scheduler_time": 161.79568439511456
}
#Debug simulation 
Total elapsed time: 5.558904103003442. Arrivals time: 0.23741555865854025 Scheduler time: 5.169296690262854 Scheduler overhead time: 0.05680925818160176 Adapter cache time: 0.014536964241415262 Engine time: 0.05532804876565933 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_8-16-16/adapters_160_slots_64_rate_1.6-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_8-16-16/adapters_160_slots_64_rate_1.6-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 66, 33, 33, 33, 17280, 33, 66, 17280, 66, 33, 66, 66, 66, 66, 17280, 17280, 17280, 66, 66, 66, 17280, 17280, 33, 17280, 66, 17280, 17280, 17280, 66, 17280, 33, 66, 66, 66, 17280, 33, 33, 17280, 33, 17280, 33, 33, 66, 33, 66, 17280, 33, 33, 66, 33, 33, 33, 33, 33, 17280, 66, 66, 17280, 66, 33, 17280, 17280, 17280, 66, 66, 33, 33, 33, 17280, 33, 66, 66, 33, 17280, 17280, 17280, 33, 33, 17280, 66, 17280, 17280, 33, 17280, 33, 66, 33, 33, 66, 66, 17280, 17280, 17280, 33, 17280, 66, 66, 33, 33, 33, 33, 17280, 66, 17280, 66, 17280, 17280, 17280, 33, 66, 66, 17280, 66, 17280, 33, 33, 33, 66, 66, 66, 17280, 17280, 66, 17280, 33, 66, 66, 33, 17280, 17280, 17280, 17280, 17280, 17280, 66, 66, 66, 66, 66, 17280, 33, 17280, 33, 17280, 66, 33, 66, 33, 33, 66, 66, 66, 17280, 66, 33, 33]
Prompts retrieved: 938367 . Total input tokens: 209260215 . Total output tokens: 184571794
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 5.855090487282723,
    "estimated_duration": 3600.11144172347,
    "input_throughput": 5669.021176252703,
    "output_throughput": 4949.512338281857,
    "total_throughput": 10618.53351453456,
    "itl": 106.26743761897069,
    "ttft": 1851296.0200119114,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 474,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.2550349864270496,
    "arrivals": 312976,
    "finished_requests": 82718,
    "scheduler_time": 154.69701375465985
}
#Debug simulation 
Total elapsed time: 5.855183040257543. Arrivals time: 0.2612056122161448 Scheduler time: 5.455235234927386 Scheduler overhead time: 0.05190977081656456 Adapter cache time: 0.013745647389441729 Engine time: 0.04992373287677765 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_8-16-32/adapters_160_slots_64_rate_1.6-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_8-16-32/adapters_160_slots_64_rate_1.6-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 66, 33, 33, 33, 17280, 33, 66, 17280, 66, 33, 66, 66, 66, 66, 17280, 17280, 17280, 66, 66, 66, 17280, 17280, 33, 17280, 66, 17280, 17280, 17280, 66, 17280, 33, 66, 66, 66, 17280, 33, 33, 17280, 33, 17280, 33, 33, 66, 33, 66, 17280, 33, 33, 66, 33, 33, 33, 33, 33, 17280, 66, 66, 17280, 66, 33, 17280, 17280, 17280, 66, 66, 33, 33, 33, 17280, 33, 66, 66, 33, 17280, 17280, 17280, 33, 33, 17280, 66, 17280, 17280, 33, 17280, 33, 66, 33, 33, 66, 66, 17280, 17280, 17280, 33, 17280, 66, 66, 33, 33, 33, 33, 17280, 66, 17280, 66, 17280, 17280, 17280, 33, 66, 66, 17280, 66, 17280, 33, 33, 33, 66, 66, 66, 17280, 17280, 66, 17280, 33, 66, 66, 33, 17280, 17280, 17280, 17280, 17280, 17280, 66, 66, 66, 66, 66, 17280, 33, 17280, 33, 17280, 66, 33, 66, 33, 33, 66, 66, 66, 17280, 66, 33, 33]
Prompts retrieved: 938367 . Total input tokens: 209260215 . Total output tokens: 184571794
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 5.559691842179745,
    "estimated_duration": 3600.0496829598933,
    "input_throughput": 5372.349190497399,
    "output_throughput": 4689.79638806504,
    "total_throughput": 10062.145578562438,
    "itl": 93.97655854961387,
    "ttft": 1893181.802774757,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 455,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.39343872338536,
    "arrivals": 312976,
    "finished_requests": 78331,
    "scheduler_time": 161.7951314911331
}
#Debug simulation 
Total elapsed time: 5.559782584197819. Arrivals time: 0.23943976731970906 Scheduler time: 5.167787009384483 Scheduler overhead time: 0.057067524176090956 Adapter cache time: 0.014774650800973177 Engine time: 0.05519226845353842 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_16-16-16/adapters_160_slots_64_rate_1.6-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_16-16-16/adapters_160_slots_64_rate_1.6-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 66, 33, 33, 33, 17280, 33, 66, 17280, 66, 33, 66, 66, 66, 66, 17280, 17280, 17280, 66, 66, 66, 17280, 17280, 33, 17280, 66, 17280, 17280, 17280, 66, 17280, 33, 66, 66, 66, 17280, 33, 33, 17280, 33, 17280, 33, 33, 66, 33, 66, 17280, 33, 33, 66, 33, 33, 33, 33, 33, 17280, 66, 66, 17280, 66, 33, 17280, 17280, 17280, 66, 66, 33, 33, 33, 17280, 33, 66, 66, 33, 17280, 17280, 17280, 33, 33, 17280, 66, 17280, 17280, 33, 17280, 33, 66, 33, 33, 66, 66, 17280, 17280, 17280, 33, 17280, 66, 66, 33, 33, 33, 33, 17280, 66, 17280, 66, 17280, 17280, 17280, 33, 66, 66, 17280, 66, 17280, 33, 33, 33, 66, 66, 66, 17280, 17280, 66, 17280, 33, 66, 66, 33, 17280, 17280, 17280, 17280, 17280, 17280, 66, 66, 66, 66, 66, 17280, 33, 17280, 33, 17280, 66, 33, 66, 33, 33, 66, 66, 66, 17280, 66, 33, 33]
Prompts retrieved: 938367 . Total input tokens: 209260215 . Total output tokens: 184571794
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.878448379226029,
    "estimated_duration": 3600.066624884955,
    "input_throughput": 5669.323967206365,
    "output_throughput": 4949.57617640463,
    "total_throughput": 10618.900143610994,
    "itl": 106.25783660880305,
    "ttft": 1851278.1681212685,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 474,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.0259785258304195,
    "arrivals": 312976,
    "finished_requests": 82720,
    "scheduler_time": 154.70405605799073
}
#Debug simulation 
Total elapsed time: 5.878555639181286. Arrivals time: 0.25706181256100535 Scheduler time: 5.482782093808055 Scheduler overhead time: 0.05147398076951504 Adapter cache time: 0.013969570398330688 Engine time: 0.050101475324481726 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_16-16-32/adapters_160_slots_64_rate_1.6-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.00625-0.003125_size_16-16-32/adapters_160_slots_64_rate_1.6-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [53 53 54]
Adapter prompts. [33, 17280, 33, 33, 66, 33, 33, 33, 17280, 33, 66, 17280, 66, 33, 66, 66, 66, 66, 17280, 17280, 17280, 66, 66, 66, 17280, 17280, 33, 17280, 66, 17280, 17280, 17280, 66, 17280, 33, 66, 66, 66, 17280, 33, 33, 17280, 33, 17280, 33, 33, 66, 33, 66, 17280, 33, 33, 66, 33, 33, 33, 33, 33, 17280, 66, 66, 17280, 66, 33, 17280, 17280, 17280, 66, 66, 33, 33, 33, 17280, 33, 66, 66, 33, 17280, 17280, 17280, 33, 33, 17280, 66, 17280, 17280, 33, 17280, 33, 66, 33, 33, 66, 66, 17280, 17280, 17280, 33, 17280, 66, 66, 33, 33, 33, 33, 17280, 66, 17280, 66, 17280, 17280, 17280, 33, 66, 66, 17280, 66, 17280, 33, 33, 33, 66, 66, 66, 17280, 17280, 66, 17280, 33, 66, 66, 33, 17280, 17280, 17280, 17280, 17280, 17280, 66, 66, 66, 66, 66, 17280, 33, 17280, 33, 17280, 66, 33, 66, 33, 33, 66, 66, 66, 17280, 66, 33, 33]
Prompts retrieved: 938367 . Total input tokens: 209260215 . Total output tokens: 184571794
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.599287415388972,
    "estimated_duration": 3600.0128514590006,
    "input_throughput": 5371.90137867491,
    "output_throughput": 4689.792702589267,
    "total_throughput": 10061.694081264177,
    "itl": 93.98187267633429,
    "ttft": 1893056.738750035,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 455,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.3611284438334663,
    "arrivals": 312976,
    "finished_requests": 78326,
    "scheduler_time": 161.79355451237203
}
#Debug simulation 
Total elapsed time: 5.59938495233655. Arrivals time: 0.2419214118272066 Scheduler time: 5.204815053381026 Scheduler overhead time: 0.05690924171358347 Adapter cache time: 0.014769280329346657 Engine time: 0.05531712155789137 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_8-8-8/adapters_160_slots_64_rate_0.8-0.4-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_8-8-8/adapters_160_slots_64_rate_0.8-0.4-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [53 53 54]
Adapter prompts. [1080, 8640, 1080, 1080, 4320, 1080, 1080, 1080, 8640, 1080, 4320, 8640, 4320, 1080, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 1080, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 1080, 4320, 4320, 4320, 8640, 1080, 1080, 8640, 1080, 8640, 1080, 1080, 4320, 1080, 4320, 8640, 1080, 1080, 4320, 1080, 1080, 1080, 1080, 1080, 8640, 4320, 4320, 8640, 4320, 1080, 8640, 8640, 8640, 4320, 4320, 1080, 1080, 1080, 8640, 1080, 4320, 4320, 1080, 8640, 8640, 8640, 1080, 1080, 8640, 4320, 8640, 8640, 1080, 8640, 1080, 4320, 1080, 1080, 4320, 4320, 8640, 8640, 8640, 1080, 8640, 4320, 4320, 1080, 1080, 1080, 1080, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 1080, 4320, 4320, 8640, 4320, 8640, 1080, 1080, 1080, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 1080, 4320, 4320, 1080, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 1080, 8640, 1080, 8640, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 8640, 4320, 1080, 1080]
Prompts retrieved: 752760 . Total input tokens: 167863645 . Total output tokens: 147998204
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 27.51955792028457,
    "estimated_duration": 3600.1230335984087,
    "input_throughput": 5604.341243813907,
    "output_throughput": 4876.739721434325,
    "total_throughput": 10481.080965248231,
    "itl": 117.84623332076957,
    "ttft": 1764162.01196794,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 596,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.9409957830422226,
    "arrivals": 250580,
    "finished_requests": 81744,
    "scheduler_time": 143.76338115923016
}
#Debug simulation 
Total elapsed time: 27.51967672817409. Arrivals time: 0.3411053563468158 Scheduler time: 27.024893852416426 Scheduler overhead time: 0.05770392715930939 Adapter cache time: 0.016176456585526466 Engine time: 0.056573281064629555 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_8-8-16/adapters_160_slots_64_rate_0.8-0.4-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_8-8-16/adapters_160_slots_64_rate_0.8-0.4-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [53 53 54]
Adapter prompts. [1080, 8640, 1080, 1080, 4320, 1080, 1080, 1080, 8640, 1080, 4320, 8640, 4320, 1080, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 1080, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 1080, 4320, 4320, 4320, 8640, 1080, 1080, 8640, 1080, 8640, 1080, 1080, 4320, 1080, 4320, 8640, 1080, 1080, 4320, 1080, 1080, 1080, 1080, 1080, 8640, 4320, 4320, 8640, 4320, 1080, 8640, 8640, 8640, 4320, 4320, 1080, 1080, 1080, 8640, 1080, 4320, 4320, 1080, 8640, 8640, 8640, 1080, 1080, 8640, 4320, 8640, 8640, 1080, 8640, 1080, 4320, 1080, 1080, 4320, 4320, 8640, 8640, 8640, 1080, 8640, 4320, 4320, 1080, 1080, 1080, 1080, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 1080, 4320, 4320, 8640, 4320, 8640, 1080, 1080, 1080, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 1080, 4320, 4320, 1080, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 1080, 8640, 1080, 8640, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 8640, 4320, 1080, 1080]
Prompts retrieved: 752760 . Total input tokens: 167863645 . Total output tokens: 147998204
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 20.21052139485255,
    "estimated_duration": 3600.1077664428126,
    "input_throughput": 5436.529201274092,
    "output_throughput": 4739.595064083214,
    "total_throughput": 10176.124265357306,
    "itl": 109.98777702123874,
    "ttft": 1799400.2884342517,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 648,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.73371578801424,
    "arrivals": 250580,
    "finished_requests": 79381,
    "scheduler_time": 147.04758777338353
}
#Debug simulation 
Total elapsed time: 20.210675838869065. Arrivals time: 0.3124087196774781 Scheduler time: 19.742416718509048 Scheduler overhead time: 0.05806811386719346 Adapter cache time: 0.017352540511637926 Engine time: 0.05620906734839082 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_8-8-32/adapters_160_slots_64_rate_0.8-0.4-0.1_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_8-8-32/adapters_160_slots_64_rate_0.8-0.4-0.1_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [53 53 54]
Adapter prompts. [1080, 8640, 1080, 1080, 4320, 1080, 1080, 1080, 8640, 1080, 4320, 8640, 4320, 1080, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 1080, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 1080, 4320, 4320, 4320, 8640, 1080, 1080, 8640, 1080, 8640, 1080, 1080, 4320, 1080, 4320, 8640, 1080, 1080, 4320, 1080, 1080, 1080, 1080, 1080, 8640, 4320, 4320, 8640, 4320, 1080, 8640, 8640, 8640, 4320, 4320, 1080, 1080, 1080, 8640, 1080, 4320, 4320, 1080, 8640, 8640, 8640, 1080, 1080, 8640, 4320, 8640, 8640, 1080, 8640, 1080, 4320, 1080, 1080, 4320, 4320, 8640, 8640, 8640, 1080, 8640, 4320, 4320, 1080, 1080, 1080, 1080, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 1080, 4320, 4320, 8640, 4320, 8640, 1080, 1080, 1080, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 1080, 4320, 4320, 1080, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 1080, 8640, 1080, 8640, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 8640, 4320, 1080, 1080]
Prompts retrieved: 752760 . Total input tokens: 167863645 . Total output tokens: 147998204
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 14.271533891092986,
    "estimated_duration": 3600.090153863801,
    "input_throughput": 5132.4145258332965,
    "output_throughput": 4484.776855566162,
    "total_throughput": 9617.19138139946,
    "itl": 97.93147877605202,
    "ttft": 1844326.6542452888,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 895,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.718861363842172,
    "arrivals": 250580,
    "finished_requests": 74999,
    "scheduler_time": 153.0822199203032
}
#Debug simulation 
Total elapsed time: 14.271655501332134. Arrivals time: 0.31232512136921287 Scheduler time: 13.794893132057041 Scheduler overhead time: 0.06059061083942652 Adapter cache time: 0.020360951777547598 Engine time: 0.05755819985643029 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_8-16-16/adapters_160_slots_64_rate_0.8-0.4-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_8-16-16/adapters_160_slots_64_rate_0.8-0.4-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [53 53 54]
Adapter prompts. [1080, 8640, 1080, 1080, 4320, 1080, 1080, 1080, 8640, 1080, 4320, 8640, 4320, 1080, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 1080, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 1080, 4320, 4320, 4320, 8640, 1080, 1080, 8640, 1080, 8640, 1080, 1080, 4320, 1080, 4320, 8640, 1080, 1080, 4320, 1080, 1080, 1080, 1080, 1080, 8640, 4320, 4320, 8640, 4320, 1080, 8640, 8640, 8640, 4320, 4320, 1080, 1080, 1080, 8640, 1080, 4320, 4320, 1080, 8640, 8640, 8640, 1080, 1080, 8640, 4320, 8640, 8640, 1080, 8640, 1080, 4320, 1080, 1080, 4320, 4320, 8640, 8640, 8640, 1080, 8640, 4320, 4320, 1080, 1080, 1080, 1080, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 1080, 4320, 4320, 8640, 4320, 8640, 1080, 1080, 1080, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 1080, 4320, 4320, 1080, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 1080, 8640, 1080, 8640, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 8640, 4320, 1080, 1080]
Prompts retrieved: 752760 . Total input tokens: 167863645 . Total output tokens: 147998204
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 21.57713359873742,
    "estimated_duration": 3600.046850829174,
    "input_throughput": 5446.020513728676,
    "output_throughput": 4750.589008601633,
    "total_throughput": 10196.60952233031,
    "itl": 110.33982034289247,
    "ttft": 1797421.1011198813,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 595,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.073300712355407,
    "arrivals": 250580,
    "finished_requests": 79599,
    "scheduler_time": 146.88901877609985
}
#Debug simulation 
Total elapsed time: 21.57725409278646. Arrivals time: 0.3173213293775916 Scheduler time: 21.103899721521884 Scheduler overhead time: 0.058312402572482824 Adapter cache time: 0.016755447257310152 Engine time: 0.05689859390258789 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_8-16-32/adapters_160_slots_64_rate_0.8-0.4-0.1_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_8-16-32/adapters_160_slots_64_rate_0.8-0.4-0.1_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [53 53 54]
Adapter prompts. [1080, 8640, 1080, 1080, 4320, 1080, 1080, 1080, 8640, 1080, 4320, 8640, 4320, 1080, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 1080, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 1080, 4320, 4320, 4320, 8640, 1080, 1080, 8640, 1080, 8640, 1080, 1080, 4320, 1080, 4320, 8640, 1080, 1080, 4320, 1080, 1080, 1080, 1080, 1080, 8640, 4320, 4320, 8640, 4320, 1080, 8640, 8640, 8640, 4320, 4320, 1080, 1080, 1080, 8640, 1080, 4320, 4320, 1080, 8640, 8640, 8640, 1080, 1080, 8640, 4320, 8640, 8640, 1080, 8640, 1080, 4320, 1080, 1080, 4320, 4320, 8640, 8640, 8640, 1080, 8640, 4320, 4320, 1080, 1080, 1080, 1080, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 1080, 4320, 4320, 8640, 4320, 8640, 1080, 1080, 1080, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 1080, 4320, 4320, 1080, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 1080, 8640, 1080, 8640, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 8640, 4320, 1080, 1080]
Prompts retrieved: 752760 . Total input tokens: 167863645 . Total output tokens: 147998204
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 13.916738910134882,
    "estimated_duration": 3600.0032899921202,
    "input_throughput": 5130.016422857331,
    "output_throughput": 4485.740900541051,
    "total_throughput": 9615.757323398382,
    "itl": 97.93892261772515,
    "ttft": 1844472.5691047604,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 869,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.4491299712984045,
    "arrivals": 250580,
    "finished_requests": 74923,
    "scheduler_time": 153.09943811344735
}
#Debug simulation 
Total elapsed time: 13.916833364404738. Arrivals time: 0.304818956181407 Scheduler time: 13.449089648202062 Scheduler overhead time: 0.059981928672641516 Adapter cache time: 0.01975875534117222 Engine time: 0.05757160717621446 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_16-16-16/adapters_160_slots_64_rate_0.8-0.4-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_16-16-16/adapters_160_slots_64_rate_0.8-0.4-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [53 53 54]
Adapter prompts. [1080, 8640, 1080, 1080, 4320, 1080, 1080, 1080, 8640, 1080, 4320, 8640, 4320, 1080, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 1080, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 1080, 4320, 4320, 4320, 8640, 1080, 1080, 8640, 1080, 8640, 1080, 1080, 4320, 1080, 4320, 8640, 1080, 1080, 4320, 1080, 1080, 1080, 1080, 1080, 8640, 4320, 4320, 8640, 4320, 1080, 8640, 8640, 8640, 4320, 4320, 1080, 1080, 1080, 8640, 1080, 4320, 4320, 1080, 8640, 8640, 8640, 1080, 1080, 8640, 4320, 8640, 8640, 1080, 8640, 1080, 4320, 1080, 1080, 4320, 4320, 8640, 8640, 8640, 1080, 8640, 4320, 4320, 1080, 1080, 1080, 1080, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 1080, 4320, 4320, 8640, 4320, 8640, 1080, 1080, 1080, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 1080, 4320, 4320, 1080, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 1080, 8640, 1080, 8640, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 8640, 4320, 1080, 1080]
Prompts retrieved: 752760 . Total input tokens: 167863645 . Total output tokens: 147998204
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 23.748474901076406,
    "estimated_duration": 3600.008060493139,
    "input_throughput": 5446.297805598307,
    "output_throughput": 4737.140504530962,
    "total_throughput": 10183.43831012927,
    "itl": 109.76313155446559,
    "ttft": 1789292.6380911085,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 552,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.5239243591949183,
    "arrivals": 250580,
    "finished_requests": 79389,
    "scheduler_time": 147.20467594583837
}
#Debug simulation 
Total elapsed time: 23.748587524984032. Arrivals time: 0.3213661499321461 Scheduler time: 23.26772706070915 Scheduler overhead time: 0.05907055363059044 Adapter cache time: 0.016178433783352375 Engine time: 0.06004478270187974 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_16-16-32/adapters_160_slots_64_rate_0.8-0.4-0.1_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_16-16-32/adapters_160_slots_64_rate_0.8-0.4-0.1_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [53 53 54]
Adapter prompts. [1080, 8640, 1080, 1080, 4320, 1080, 1080, 1080, 8640, 1080, 4320, 8640, 4320, 1080, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 1080, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 1080, 4320, 4320, 4320, 8640, 1080, 1080, 8640, 1080, 8640, 1080, 1080, 4320, 1080, 4320, 8640, 1080, 1080, 4320, 1080, 1080, 1080, 1080, 1080, 8640, 4320, 4320, 8640, 4320, 1080, 8640, 8640, 8640, 4320, 4320, 1080, 1080, 1080, 8640, 1080, 4320, 4320, 1080, 8640, 8640, 8640, 1080, 1080, 8640, 4320, 8640, 8640, 1080, 8640, 1080, 4320, 1080, 1080, 4320, 4320, 8640, 8640, 8640, 1080, 8640, 4320, 4320, 1080, 1080, 1080, 1080, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 1080, 4320, 4320, 8640, 4320, 8640, 1080, 1080, 1080, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 1080, 4320, 4320, 1080, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 1080, 8640, 1080, 8640, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 8640, 4320, 1080, 1080]
Prompts retrieved: 752760 . Total input tokens: 167863645 . Total output tokens: 147998204
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 13.380577115342021,
    "estimated_duration": 3600.0899790998606,
    "input_throughput": 5131.349801601051,
    "output_throughput": 4486.789245206237,
    "total_throughput": 9618.139046807288,
    "itl": 98.01695561425907,
    "ttft": 1845117.6319709055,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 976,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.178537049517053,
    "arrivals": 250580,
    "finished_requests": 74882,
    "scheduler_time": 153.0622796887737
}
#Debug simulation 
Total elapsed time: 13.380687783937901. Arrivals time: 0.2909027892164886 Scheduler time: 12.925463740713894 Scheduler overhead time: 0.06016903929412365 Adapter cache time: 0.02116603311151266 Engine time: 0.057385876309126616 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_8-8-8/adapters_160_slots_64_rate_0.8-0.4-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_8-8-8/adapters_160_slots_64_rate_0.8-0.4-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [53 53 54]
Adapter prompts. [540, 8640, 540, 540, 4320, 540, 540, 540, 8640, 540, 4320, 8640, 4320, 540, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 540, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 540, 4320, 4320, 4320, 8640, 540, 540, 8640, 540, 8640, 540, 540, 4320, 540, 4320, 8640, 540, 540, 4320, 540, 540, 540, 540, 540, 8640, 4320, 4320, 8640, 4320, 540, 8640, 8640, 8640, 4320, 4320, 540, 540, 540, 8640, 540, 4320, 4320, 540, 8640, 8640, 8640, 540, 540, 8640, 4320, 8640, 8640, 540, 8640, 540, 4320, 540, 540, 4320, 4320, 8640, 8640, 8640, 540, 8640, 4320, 4320, 540, 540, 540, 540, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 540, 4320, 4320, 8640, 4320, 8640, 540, 540, 540, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 540, 4320, 4320, 540, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 540, 8640, 540, 8640, 4320, 540, 4320, 540, 540, 4320, 4320, 4320, 8640, 4320, 540, 540]
Prompts retrieved: 724140 . Total input tokens: 161466883 . Total output tokens: 142426645
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 25.228103963658214,
    "estimated_duration": 3600.0925687001923,
    "input_throughput": 5609.297709611675,
    "output_throughput": 4879.861465990826,
    "total_throughput": 10489.1591756025,
    "itl": 118.03572279021627,
    "ttft": 1747454.1831656655,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 635,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.198879735288278,
    "arrivals": 240851,
    "finished_requests": 81774,
    "scheduler_time": 143.31261645984267
}
#Debug simulation 
Total elapsed time: 25.228256502654403. Arrivals time: 0.33920827228575945 Scheduler time: 24.735637404955924 Scheduler overhead time: 0.05724624264985323 Adapter cache time: 0.016853302251547575 Engine time: 0.05601404467597604 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_8-8-16/adapters_160_slots_64_rate_0.8-0.4-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_8-8-16/adapters_160_slots_64_rate_0.8-0.4-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [53 53 54]
Adapter prompts. [540, 8640, 540, 540, 4320, 540, 540, 540, 8640, 540, 4320, 8640, 4320, 540, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 540, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 540, 4320, 4320, 4320, 8640, 540, 540, 8640, 540, 8640, 540, 540, 4320, 540, 4320, 8640, 540, 540, 4320, 540, 540, 540, 540, 540, 8640, 4320, 4320, 8640, 4320, 540, 8640, 8640, 8640, 4320, 4320, 540, 540, 540, 8640, 540, 4320, 4320, 540, 8640, 8640, 8640, 540, 540, 8640, 4320, 8640, 8640, 540, 8640, 540, 4320, 540, 540, 4320, 4320, 8640, 8640, 8640, 540, 8640, 4320, 4320, 540, 540, 540, 540, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 540, 4320, 4320, 8640, 4320, 8640, 540, 540, 540, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 540, 4320, 4320, 540, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 540, 8640, 540, 8640, 4320, 540, 4320, 540, 540, 4320, 4320, 4320, 8640, 4320, 540, 540]
Prompts retrieved: 724140 . Total input tokens: 161466883 . Total output tokens: 142426645
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 19.119255629833788,
    "estimated_duration": 3600.1004570295613,
    "input_throughput": 5459.467655026775,
    "output_throughput": 4745.151198946038,
    "total_throughput": 10204.618853972812,
    "itl": 110.28928343220795,
    "ttft": 1777844.4882620287,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 912,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.663397807627925,
    "arrivals": 240851,
    "finished_requests": 79471,
    "scheduler_time": 146.45518063030633
}
#Debug simulation 
Total elapsed time: 19.119401962962. Arrivals time: 0.31436510337516665 Scheduler time: 18.647377003449947 Scheduler overhead time: 0.05781815480440855 Adapter cache time: 0.020054656080901623 Engine time: 0.05585374170914292 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_8-8-32/adapters_160_slots_64_rate_0.8-0.4-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_8-8-32/adapters_160_slots_64_rate_0.8-0.4-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [53 53 54]
Adapter prompts. [540, 8640, 540, 540, 4320, 540, 540, 540, 8640, 540, 4320, 8640, 4320, 540, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 540, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 540, 4320, 4320, 4320, 8640, 540, 540, 8640, 540, 8640, 540, 540, 4320, 540, 4320, 8640, 540, 540, 4320, 540, 540, 540, 540, 540, 8640, 4320, 4320, 8640, 4320, 540, 8640, 8640, 8640, 4320, 4320, 540, 540, 540, 8640, 540, 4320, 4320, 540, 8640, 8640, 8640, 540, 540, 8640, 4320, 8640, 8640, 540, 8640, 540, 4320, 540, 540, 4320, 4320, 8640, 8640, 8640, 540, 8640, 4320, 4320, 540, 540, 540, 540, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 540, 4320, 4320, 8640, 4320, 8640, 540, 540, 540, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 540, 4320, 4320, 540, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 540, 8640, 540, 8640, 4320, 540, 4320, 540, 540, 4320, 4320, 4320, 8640, 4320, 540, 540]
Prompts retrieved: 724140 . Total input tokens: 161466883 . Total output tokens: 142426645
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 12.168797458987683,
    "estimated_duration": 3600.0778241009275,
    "input_throughput": 5157.132125230275,
    "output_throughput": 4489.125177185871,
    "total_throughput": 9646.257302416145,
    "itl": 98.20661143380734,
    "ttft": 1827182.937746491,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1293,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.697323284107204,
    "arrivals": 240851,
    "finished_requests": 75103,
    "scheduler_time": 152.41536576867225
}
#Debug simulation 
Total elapsed time: 12.168929198291153. Arrivals time: 0.29504070011898875 Scheduler time: 11.70711566042155 Scheduler overhead time: 0.059330420568585396 Adapter cache time: 0.024974833708256483 Engine time: 0.05676878755912185 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_8-16-16/adapters_160_slots_64_rate_0.8-0.4-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_8-16-16/adapters_160_slots_64_rate_0.8-0.4-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [53 53 54]
Adapter prompts. [540, 8640, 540, 540, 4320, 540, 540, 540, 8640, 540, 4320, 8640, 4320, 540, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 540, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 540, 4320, 4320, 4320, 8640, 540, 540, 8640, 540, 8640, 540, 540, 4320, 540, 4320, 8640, 540, 540, 4320, 540, 540, 540, 540, 540, 8640, 4320, 4320, 8640, 4320, 540, 8640, 8640, 8640, 4320, 4320, 540, 540, 540, 8640, 540, 4320, 4320, 540, 8640, 8640, 8640, 540, 540, 8640, 4320, 8640, 8640, 540, 8640, 540, 4320, 540, 540, 4320, 4320, 8640, 8640, 8640, 540, 8640, 4320, 4320, 540, 540, 540, 540, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 540, 4320, 4320, 8640, 4320, 8640, 540, 540, 540, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 540, 4320, 4320, 540, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 540, 8640, 540, 8640, 4320, 540, 4320, 540, 540, 4320, 4320, 4320, 8640, 4320, 540, 540]
Prompts retrieved: 724140 . Total input tokens: 161466883 . Total output tokens: 142426645
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 17.143301118165255,
    "estimated_duration": 3600.065658661007,
    "input_throughput": 5468.092492324637,
    "output_throughput": 4750.077532297097,
    "total_throughput": 10218.170024621733,
    "itl": 110.54554887845221,
    "ttft": 1777985.4766541175,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 922,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.319100050879634,
    "arrivals": 240851,
    "finished_requests": 79612,
    "scheduler_time": 146.32480648003943
}
#Debug simulation 
Total elapsed time: 17.143448657356203. Arrivals time: 0.3064555781893432 Scheduler time: 16.681820400059223 Scheduler overhead time: 0.05682971468195319 Adapter cache time: 0.019893974531441927 Engine time: 0.05482296133413911 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_8-16-32/adapters_160_slots_64_rate_0.8-0.4-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_8-16-32/adapters_160_slots_64_rate_0.8-0.4-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [53 53 54]
Adapter prompts. [540, 8640, 540, 540, 4320, 540, 540, 540, 8640, 540, 4320, 8640, 4320, 540, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 540, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 540, 4320, 4320, 4320, 8640, 540, 540, 8640, 540, 8640, 540, 540, 4320, 540, 4320, 8640, 540, 540, 4320, 540, 540, 540, 540, 540, 8640, 4320, 4320, 8640, 4320, 540, 8640, 8640, 8640, 4320, 4320, 540, 540, 540, 8640, 540, 4320, 4320, 540, 8640, 8640, 8640, 540, 540, 8640, 4320, 8640, 8640, 540, 8640, 540, 4320, 540, 540, 4320, 4320, 8640, 8640, 8640, 540, 8640, 4320, 4320, 540, 540, 540, 540, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 540, 4320, 4320, 8640, 4320, 8640, 540, 540, 540, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 540, 4320, 4320, 540, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 540, 8640, 540, 8640, 4320, 540, 4320, 540, 540, 4320, 4320, 4320, 8640, 4320, 540, 540]
Prompts retrieved: 724140 . Total input tokens: 161466883 . Total output tokens: 142426645
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 13.829293912276626,
    "estimated_duration": 3600.0861253346325,
    "input_throughput": 5152.467011681788,
    "output_throughput": 4482.799143728794,
    "total_throughput": 9635.266155410582,
    "itl": 97.97699303460317,
    "ttft": 1827987.0228115784,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1195,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.851708207428423,
    "arrivals": 240851,
    "finished_requests": 75071,
    "scheduler_time": 152.55547118725755
}
#Debug simulation 
Total elapsed time: 13.829408401157707. Arrivals time: 0.29088213155046105 Scheduler time: 13.37210887344554 Scheduler overhead time: 0.05958701390773058 Adapter cache time: 0.02345612971112132 Engine time: 0.05779035063460469 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_16-16-16/adapters_160_slots_64_rate_0.8-0.4-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_16-16-16/adapters_160_slots_64_rate_0.8-0.4-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [53 53 54]
Adapter prompts. [540, 8640, 540, 540, 4320, 540, 540, 540, 8640, 540, 4320, 8640, 4320, 540, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 540, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 540, 4320, 4320, 4320, 8640, 540, 540, 8640, 540, 8640, 540, 540, 4320, 540, 4320, 8640, 540, 540, 4320, 540, 540, 540, 540, 540, 8640, 4320, 4320, 8640, 4320, 540, 8640, 8640, 8640, 4320, 4320, 540, 540, 540, 8640, 540, 4320, 4320, 540, 8640, 8640, 8640, 540, 540, 8640, 4320, 8640, 8640, 540, 8640, 540, 4320, 540, 540, 4320, 4320, 8640, 8640, 8640, 540, 8640, 4320, 4320, 540, 540, 540, 540, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 540, 4320, 4320, 8640, 4320, 8640, 540, 540, 540, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 540, 4320, 4320, 540, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 540, 8640, 540, 8640, 4320, 540, 4320, 540, 540, 4320, 4320, 4320, 8640, 4320, 540, 540]
Prompts retrieved: 724140 . Total input tokens: 161466883 . Total output tokens: 142426645
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 18.37521721003577,
    "estimated_duration": 3600.029551962243,
    "input_throughput": 5456.194377430491,
    "output_throughput": 4742.351348392224,
    "total_throughput": 10198.545725822716,
    "itl": 110.11935566774528,
    "ttft": 1778067.4635280163,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 885,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.649770032404894,
    "arrivals": 240851,
    "finished_requests": 79451,
    "scheduler_time": 146.57029141541645
}
#Debug simulation 
Total elapsed time: 18.37531486991793. Arrivals time: 0.30443775933235884 Scheduler time: 17.914066373370588 Scheduler overhead time: 0.05736727686598897 Adapter cache time: 0.019562663044780493 Engine time: 0.05580564634874463 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_16-16-32/adapters_160_slots_64_rate_0.8-0.4-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_16-16-32/adapters_160_slots_64_rate_0.8-0.4-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [53 53 54]
Adapter prompts. [540, 8640, 540, 540, 4320, 540, 540, 540, 8640, 540, 4320, 8640, 4320, 540, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 540, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 540, 4320, 4320, 4320, 8640, 540, 540, 8640, 540, 8640, 540, 540, 4320, 540, 4320, 8640, 540, 540, 4320, 540, 540, 540, 540, 540, 8640, 4320, 4320, 8640, 4320, 540, 8640, 8640, 8640, 4320, 4320, 540, 540, 540, 8640, 540, 4320, 4320, 540, 8640, 8640, 8640, 540, 540, 8640, 4320, 8640, 8640, 540, 8640, 540, 4320, 540, 540, 4320, 4320, 8640, 8640, 8640, 540, 8640, 4320, 4320, 540, 540, 540, 540, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 540, 4320, 4320, 8640, 4320, 8640, 540, 540, 540, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 540, 4320, 4320, 540, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 540, 8640, 540, 8640, 4320, 540, 4320, 540, 540, 4320, 4320, 4320, 8640, 4320, 540, 540]
Prompts retrieved: 724140 . Total input tokens: 161466883 . Total output tokens: 142426645
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 14.446623642928898,
    "estimated_duration": 3600.0802936671694,
    "input_throughput": 5158.689663858084,
    "output_throughput": 4486.260494914718,
    "total_throughput": 9644.950158772801,
    "itl": 97.98847984897336,
    "ttft": 1828031.4059524238,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1144,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.420932162068784,
    "arrivals": 240851,
    "finished_requests": 75147,
    "scheduler_time": 152.5475456267809
}
#Debug simulation 
Total elapsed time: 14.446716553997248. Arrivals time: 0.28786060120910406 Scheduler time: 13.992454482708126 Scheduler overhead time: 0.05986176757141948 Adapter cache time: 0.022768236231058836 Engine time: 0.05806615995243192 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_8-8-8/adapters_160_slots_64_rate_0.8-0.4-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_8-8-8/adapters_160_slots_64_rate_0.8-0.4-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [53 53 54]
Adapter prompts. [270, 8640, 270, 270, 4320, 270, 270, 270, 8640, 270, 4320, 8640, 4320, 270, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 270, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 270, 4320, 4320, 4320, 8640, 270, 270, 8640, 270, 8640, 270, 270, 4320, 270, 4320, 8640, 270, 270, 4320, 270, 270, 270, 270, 270, 8640, 4320, 4320, 8640, 4320, 270, 8640, 8640, 8640, 4320, 4320, 270, 270, 270, 8640, 270, 4320, 4320, 270, 8640, 8640, 8640, 270, 270, 8640, 4320, 8640, 8640, 270, 8640, 270, 4320, 270, 270, 4320, 4320, 8640, 8640, 8640, 270, 8640, 4320, 4320, 270, 270, 270, 270, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 270, 4320, 4320, 8640, 4320, 8640, 270, 270, 270, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 270, 4320, 4320, 270, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 270, 8640, 270, 8640, 4320, 270, 4320, 270, 270, 4320, 4320, 4320, 8640, 4320, 270, 270]
Prompts retrieved: 709830 . Total input tokens: 158244851 . Total output tokens: 139627461
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 25.857181704137474,
    "estimated_duration": 3600.0635500339863,
    "input_throughput": 5588.3871827235025,
    "output_throughput": 4870.341802670254,
    "total_throughput": 10458.728985393756,
    "itl": 117.48203261349809,
    "ttft": 1745848.6011468426,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 863,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.706508994572912,
    "arrivals": 236027,
    "finished_requests": 81527,
    "scheduler_time": 143.24304542481448
}
#Debug simulation 
Total elapsed time: 25.857332090847194. Arrivals time: 0.33589171478524804 Scheduler time: 25.366156097967178 Scheduler overhead time: 0.05743432603776455 Adapter cache time: 0.018602493684738874 Engine time: 0.05608915397897363 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_8-8-16/adapters_160_slots_64_rate_0.8-0.4-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_8-8-16/adapters_160_slots_64_rate_0.8-0.4-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [53 53 54]
Adapter prompts. [270, 8640, 270, 270, 4320, 270, 270, 270, 8640, 270, 4320, 8640, 4320, 270, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 270, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 270, 4320, 4320, 4320, 8640, 270, 270, 8640, 270, 8640, 270, 270, 4320, 270, 4320, 8640, 270, 270, 4320, 270, 270, 270, 270, 270, 8640, 4320, 4320, 8640, 4320, 270, 8640, 8640, 8640, 4320, 4320, 270, 270, 270, 8640, 270, 4320, 4320, 270, 8640, 8640, 8640, 270, 270, 8640, 4320, 8640, 8640, 270, 8640, 270, 4320, 270, 270, 4320, 4320, 8640, 8640, 8640, 270, 8640, 4320, 4320, 270, 270, 270, 270, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 270, 4320, 4320, 8640, 4320, 8640, 270, 270, 270, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 270, 4320, 4320, 270, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 270, 8640, 270, 8640, 4320, 270, 4320, 270, 270, 4320, 4320, 4320, 8640, 4320, 270, 270]
Prompts retrieved: 709830 . Total input tokens: 158244851 . Total output tokens: 139627461
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 18.887127137277275,
    "estimated_duration": 3600.0275573169383,
    "input_throughput": 5442.011953542171,
    "output_throughput": 4740.06510458989,
    "total_throughput": 10182.077058132061,
    "itl": 110.06397779694987,
    "ttft": 1774021.5142139785,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.457619788832966,
    "arrivals": 236027,
    "finished_requests": 79335,
    "scheduler_time": 146.2829409645435
}
#Debug simulation 
Total elapsed time: 18.88727834634483. Arrivals time: 0.3036867561750114 Scheduler time: 18.425335452426225 Scheduler overhead time: 0.05729445582255721 Adapter cache time: 0.021925711538642645 Engine time: 0.05508775217458606 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_8-8-32/adapters_160_slots_64_rate_0.8-0.4-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_8-8-32/adapters_160_slots_64_rate_0.8-0.4-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [53 53 54]
Adapter prompts. [270, 8640, 270, 270, 4320, 270, 270, 270, 8640, 270, 4320, 8640, 4320, 270, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 4320, 8640, 8640, 270, 8640, 4320, 8640, 8640, 8640, 4320, 8640, 270, 4320, 4320, 4320, 8640, 270, 270, 8640, 270, 8640, 270, 270, 4320, 270, 4320, 8640, 270, 270, 4320, 270, 270, 270, 270, 270, 8640, 4320, 4320, 8640, 4320, 270, 8640, 8640, 8640, 4320, 4320, 270, 270, 270, 8640, 270, 4320, 4320, 270, 8640, 8640, 8640, 270, 270, 8640, 4320, 8640, 8640, 270, 8640, 270, 4320, 270, 270, 4320, 4320, 8640, 8640, 8640, 270, 8640, 4320, 4320, 270, 270, 270, 270, 8640, 4320, 8640, 4320, 8640, 8640, 8640, 270, 4320, 4320, 8640, 4320, 8640, 270, 270, 270, 4320, 4320, 4320, 8640, 8640, 4320, 8640, 270, 4320, 4320, 270, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 8640, 270, 8640, 270, 8640, 4320, 270, 4320, 270, 270, 4320, 4320, 4320, 8640, 4320, 270, 270]
Prompts retrieved: 709830 . Total input tokens: 158244851 . Total output tokens: 139627461
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 11.631077107042074,
    "estimated_duration": 3600.027104086593,
    "input_throughput": 5147.747909720804,
    "output_throughput": 4480.834041968365,
    "total_throughput": 9628.58195168917,
    "itl": 97.76182095688549,
    "ttft": 1825001.414061895,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1404,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.518579947221921,
    "arrivals": 236027,
    "finished_requests": 75003,
    "scheduler_time": 152.42872032594255
}
#Debug simulation 
Total elapsed time: 11.631205427926034. Arrivals time: 0.2787234019488096 Scheduler time: 11.18646307149902 Scheduler overhead time: 0.058620522264391184 Adapter cache time: 0.025407006964087486 Engine time: 0.05646901344880462 
