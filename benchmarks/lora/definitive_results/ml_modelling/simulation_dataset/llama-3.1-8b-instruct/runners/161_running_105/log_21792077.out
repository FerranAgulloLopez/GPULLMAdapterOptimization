INFO 05-31 19:30:53 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 05-31 19:30:54 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-32/adapters_192_slots_16_rate_0.025-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-32/adapters_192_slots_16_rate_0.025-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [64 64 64]
Adapter prompts. [270, 33, 270, 33, 270, 33, 270, 33, 33, 33, 135, 135, 135, 135, 270, 135, 33, 270, 33, 135, 135, 33, 270, 270, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 270, 135, 33, 135, 270, 270, 135, 270, 33, 135, 135, 270, 135, 33, 33, 135, 270, 33, 135, 33, 270, 270, 135, 270, 270, 270, 33, 135, 270, 33, 135, 33, 135, 33, 33, 135, 270, 270, 33, 33, 33, 270, 270, 270, 135, 33, 33, 33, 33, 33, 270, 33, 135, 33, 270, 270, 33, 270, 33, 135, 135, 270, 33, 33, 33, 270, 270, 135, 270, 135, 270, 270, 135, 135, 33, 270, 135, 135, 135, 270, 135, 33, 135, 270, 270, 135, 270, 135, 33, 270, 135, 33, 135, 135, 33, 135, 270, 33, 135, 270, 33, 135, 270, 270, 135, 33, 270, 135, 33, 33, 135, 270, 270, 270, 33, 270, 33, 270, 33, 135, 33, 270, 270, 135, 270, 33, 270, 270, 270, 33, 270, 270, 270, 135, 135, 135, 135, 135, 135, 33, 270, 135, 270, 33, 270, 135, 33, 135, 33, 33, 135, 135, 135, 270, 135, 33, 33]
Prompts retrieved: 28032 . Total input tokens: 6164867 . Total output tokens: 5513241
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 1.1443481468595564,
    "estimated_duration": 3599.784349392353,
    "input_throughput": 640.67587837291,
    "output_throughput": 568.308210003005,
    "total_throughput": 1208.984088375915,
    "itl": 23.560587614382932,
    "ttft": 8440.279606094527,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8170,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 59.93447339776511,
    "arrivals": 9452,
    "finished_requests": 9432,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1444817958399653. Arrivals time: 0.0382828451693058 Scheduler time: 0.7219234923832119 Scheduler overhead time: 0.1336618773639202 Adapter cache time: 0.05571306822821498 Engine time: 0.1307137506082654 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-8/adapters_192_slots_16_rate_0.025-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-8/adapters_192_slots_16_rate_0.025-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [64 64 64]
Adapter prompts. [270, 33, 270, 33, 270, 33, 270, 33, 33, 33, 66, 66, 66, 66, 270, 66, 33, 270, 33, 66, 66, 33, 270, 270, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 270, 66, 33, 66, 270, 270, 66, 270, 33, 66, 66, 270, 66, 33, 33, 66, 270, 33, 66, 33, 270, 270, 66, 270, 270, 270, 33, 66, 270, 33, 66, 33, 66, 33, 33, 66, 270, 270, 33, 33, 33, 270, 270, 270, 66, 33, 33, 33, 33, 33, 270, 33, 66, 33, 270, 270, 33, 270, 33, 66, 66, 270, 33, 33, 33, 270, 270, 66, 270, 66, 270, 270, 66, 66, 33, 270, 66, 66, 66, 270, 66, 33, 66, 270, 270, 66, 270, 66, 33, 270, 66, 33, 66, 66, 33, 66, 270, 33, 66, 270, 33, 66, 270, 270, 66, 33, 270, 66, 33, 33, 66, 270, 270, 270, 33, 270, 33, 270, 33, 66, 33, 270, 270, 66, 270, 33, 270, 270, 270, 33, 270, 270, 270, 66, 66, 66, 66, 66, 66, 33, 270, 66, 270, 33, 270, 66, 33, 66, 33, 33, 66, 66, 66, 270, 66, 33, 33]
Prompts retrieved: 23616 . Total input tokens: 5209427 . Total output tokens: 4648377
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 1.0247479318641126,
    "estimated_duration": 3598.8009576519753,
    "input_throughput": 545.0051345100468,
    "output_throughput": 485.12574619828024,
    "total_throughput": 1030.130880708327,
    "itl": 22.690058122741565,
    "ttft": 7372.727573896353,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6882,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 45.5065989578802,
    "arrivals": 8047,
    "finished_requests": 8031,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0248757489025593. Arrivals time: 0.033287511207163334 Scheduler time: 0.6183831389062107 Scheduler overhead time: 0.13417871249839664 Adapter cache time: 0.048136497382074594 Engine time: 0.1271580122411251 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-16/adapters_192_slots_16_rate_0.025-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-16/adapters_192_slots_16_rate_0.025-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [64 64 64]
Adapter prompts. [270, 33, 270, 33, 270, 33, 270, 33, 33, 33, 66, 66, 66, 66, 270, 66, 33, 270, 33, 66, 66, 33, 270, 270, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 270, 66, 33, 66, 270, 270, 66, 270, 33, 66, 66, 270, 66, 33, 33, 66, 270, 33, 66, 33, 270, 270, 66, 270, 270, 270, 33, 66, 270, 33, 66, 33, 66, 33, 33, 66, 270, 270, 33, 33, 33, 270, 270, 270, 66, 33, 33, 33, 33, 33, 270, 33, 66, 33, 270, 270, 33, 270, 33, 66, 66, 270, 33, 33, 33, 270, 270, 66, 270, 66, 270, 270, 66, 66, 33, 270, 66, 66, 66, 270, 66, 33, 66, 270, 270, 66, 270, 66, 33, 270, 66, 33, 66, 66, 33, 66, 270, 33, 66, 270, 33, 66, 270, 270, 66, 33, 270, 66, 33, 33, 66, 270, 270, 270, 33, 270, 33, 270, 33, 66, 33, 270, 270, 66, 270, 33, 270, 270, 270, 33, 270, 270, 270, 66, 66, 66, 66, 66, 66, 33, 270, 66, 270, 33, 270, 66, 33, 66, 33, 33, 66, 66, 66, 270, 66, 33, 33]
Prompts retrieved: 23616 . Total input tokens: 5209427 . Total output tokens: 4648377
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 1.0185909201391041,
    "estimated_duration": 3598.810330935982,
    "input_throughput": 545.0037150165361,
    "output_throughput": 485.12448266367295,
    "total_throughput": 1030.128197680209,
    "itl": 22.730603951211148,
    "ttft": 7376.235829204706,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6875,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 50.101745321995956,
    "arrivals": 8047,
    "finished_requests": 8031,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0186728797852993. Arrivals time: 0.03342329850420356 Scheduler time: 0.6187270567752421 Scheduler overhead time: 0.12812239304184914 Adapter cache time: 0.048459519166499376 Engine time: 0.1262574358843267 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-32/adapters_192_slots_16_rate_0.025-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-32/adapters_192_slots_16_rate_0.025-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [64 64 64]
Adapter prompts. [270, 33, 270, 33, 270, 33, 270, 33, 33, 33, 66, 66, 66, 66, 270, 66, 33, 270, 33, 66, 66, 33, 270, 270, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 270, 66, 33, 66, 270, 270, 66, 270, 33, 66, 66, 270, 66, 33, 33, 66, 270, 33, 66, 33, 270, 270, 66, 270, 270, 270, 33, 66, 270, 33, 66, 33, 66, 33, 33, 66, 270, 270, 33, 33, 33, 270, 270, 270, 66, 33, 33, 33, 33, 33, 270, 33, 66, 33, 270, 270, 33, 270, 33, 66, 66, 270, 33, 33, 33, 270, 270, 66, 270, 66, 270, 270, 66, 66, 33, 270, 66, 66, 66, 270, 66, 33, 66, 270, 270, 66, 270, 66, 33, 270, 66, 33, 66, 66, 33, 66, 270, 33, 66, 270, 33, 66, 270, 270, 66, 33, 270, 66, 33, 33, 66, 270, 270, 270, 33, 270, 33, 270, 33, 66, 33, 270, 270, 66, 270, 33, 270, 270, 270, 33, 270, 270, 270, 66, 66, 66, 66, 66, 66, 33, 270, 66, 270, 33, 270, 66, 33, 66, 33, 33, 66, 66, 66, 270, 66, 33, 33]
Prompts retrieved: 23616 . Total input tokens: 5209427 . Total output tokens: 4648377
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 1.0171875981613994,
    "estimated_duration": 3598.824793259986,
    "input_throughput": 545.0015248514787,
    "output_throughput": 485.1225331307411,
    "total_throughput": 1030.1240579822197,
    "itl": 22.731446628670298,
    "ttft": 7377.294651546301,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6879,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 51.45075577763139,
    "arrivals": 8047,
    "finished_requests": 8031,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0176942460238934. Arrivals time: 0.03334618080407381 Scheduler time: 0.61686907755211 Scheduler overhead time: 0.12738477298989892 Adapter cache time: 0.048183299135416746 Engine time: 0.12799768010154366 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-16/adapters_192_slots_16_rate_0.025-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-16/adapters_192_slots_16_rate_0.025-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [64 64 64]
Adapter prompts. [270, 33, 270, 33, 270, 33, 270, 33, 33, 33, 66, 66, 66, 66, 270, 66, 33, 270, 33, 66, 66, 33, 270, 270, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 270, 66, 33, 66, 270, 270, 66, 270, 33, 66, 66, 270, 66, 33, 33, 66, 270, 33, 66, 33, 270, 270, 66, 270, 270, 270, 33, 66, 270, 33, 66, 33, 66, 33, 33, 66, 270, 270, 33, 33, 33, 270, 270, 270, 66, 33, 33, 33, 33, 33, 270, 33, 66, 33, 270, 270, 33, 270, 33, 66, 66, 270, 33, 33, 33, 270, 270, 66, 270, 66, 270, 270, 66, 66, 33, 270, 66, 66, 66, 270, 66, 33, 66, 270, 270, 66, 270, 66, 33, 270, 66, 33, 66, 66, 33, 66, 270, 33, 66, 270, 33, 66, 270, 270, 66, 33, 270, 66, 33, 33, 66, 270, 270, 270, 33, 270, 33, 270, 33, 66, 33, 270, 270, 66, 270, 33, 270, 270, 270, 33, 270, 270, 270, 66, 66, 66, 66, 66, 66, 33, 270, 66, 270, 33, 270, 66, 33, 66, 33, 33, 66, 66, 66, 270, 66, 33, 33]
Prompts retrieved: 23616 . Total input tokens: 5209427 . Total output tokens: 4648377
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 1.013832566794008,
    "estimated_duration": 3598.821316191784,
    "input_throughput": 545.0020514148465,
    "output_throughput": 485.1230018409064,
    "total_throughput": 1030.1250532557528,
    "itl": 22.703346583588726,
    "ttft": 7374.048113561071,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6875,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 47.130952439109464,
    "arrivals": 8047,
    "finished_requests": 8031,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0139315277338028. Arrivals time: 0.03321214858442545 Scheduler time: 0.6165389120578766 Scheduler overhead time: 0.12729756673797965 Adapter cache time: 0.04819754511117935 Engine time: 0.12533852411434054 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-32/adapters_192_slots_16_rate_0.025-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-32/adapters_192_slots_16_rate_0.025-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [64 64 64]
Adapter prompts. [270, 33, 270, 33, 270, 33, 270, 33, 33, 33, 66, 66, 66, 66, 270, 66, 33, 270, 33, 66, 66, 33, 270, 270, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 270, 66, 33, 66, 270, 270, 66, 270, 33, 66, 66, 270, 66, 33, 33, 66, 270, 33, 66, 33, 270, 270, 66, 270, 270, 270, 33, 66, 270, 33, 66, 33, 66, 33, 33, 66, 270, 270, 33, 33, 33, 270, 270, 270, 66, 33, 33, 33, 33, 33, 270, 33, 66, 33, 270, 270, 33, 270, 33, 66, 66, 270, 33, 33, 33, 270, 270, 66, 270, 66, 270, 270, 66, 66, 33, 270, 66, 66, 66, 270, 66, 33, 66, 270, 270, 66, 270, 66, 33, 270, 66, 33, 66, 66, 33, 66, 270, 33, 66, 270, 33, 66, 270, 270, 66, 33, 270, 66, 33, 33, 66, 270, 270, 270, 33, 270, 33, 270, 33, 66, 33, 270, 270, 66, 270, 33, 270, 270, 270, 33, 270, 270, 270, 66, 66, 66, 66, 66, 66, 33, 270, 66, 270, 33, 270, 66, 33, 66, 33, 33, 66, 66, 66, 270, 66, 33, 33]
Prompts retrieved: 23616 . Total input tokens: 5209427 . Total output tokens: 4648377
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 1.0162401562556624,
    "estimated_duration": 3598.8210380019414,
    "input_throughput": 545.0020935436529,
    "output_throughput": 485.1230393410461,
    "total_throughput": 1030.125132884699,
    "itl": 22.73483622537693,
    "ttft": 7376.764985349062,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6873,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 50.963107543753054,
    "arrivals": 8047,
    "finished_requests": 8031,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0163201922550797. Arrivals time: 0.03311833832412958 Scheduler time: 0.6189042045734823 Scheduler overhead time: 0.12663691770285368 Adapter cache time: 0.048100961837917566 Engine time: 0.1261653983965516 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-16/adapters_192_slots_16_rate_0.025-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-16/adapters_192_slots_16_rate_0.025-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [64 64 64]
Adapter prompts. [270, 33, 270, 33, 270, 33, 270, 33, 33, 33, 66, 66, 66, 66, 270, 66, 33, 270, 33, 66, 66, 33, 270, 270, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 270, 66, 33, 66, 270, 270, 66, 270, 33, 66, 66, 270, 66, 33, 33, 66, 270, 33, 66, 33, 270, 270, 66, 270, 270, 270, 33, 66, 270, 33, 66, 33, 66, 33, 33, 66, 270, 270, 33, 33, 33, 270, 270, 270, 66, 33, 33, 33, 33, 33, 270, 33, 66, 33, 270, 270, 33, 270, 33, 66, 66, 270, 33, 33, 33, 270, 270, 66, 270, 66, 270, 270, 66, 66, 33, 270, 66, 66, 66, 270, 66, 33, 66, 270, 270, 66, 270, 66, 33, 270, 66, 33, 66, 66, 33, 66, 270, 33, 66, 270, 33, 66, 270, 270, 66, 33, 270, 66, 33, 33, 66, 270, 270, 270, 33, 270, 33, 270, 33, 66, 33, 270, 270, 66, 270, 33, 270, 270, 270, 33, 270, 270, 270, 66, 66, 66, 66, 66, 66, 33, 270, 66, 270, 33, 270, 66, 33, 66, 33, 33, 66, 66, 66, 270, 66, 33, 33]
Prompts retrieved: 23616 . Total input tokens: 5209427 . Total output tokens: 4648377
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 1.0362220359966159,
    "estimated_duration": 3598.8013639284013,
    "input_throughput": 545.005072983245,
    "output_throughput": 485.1256914313914,
    "total_throughput": 1030.1307644146364,
    "itl": 22.679112809385263,
    "ttft": 7371.803325828983,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6877,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 43.902224308308305,
    "arrivals": 8047,
    "finished_requests": 8031,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.036565248388797. Arrivals time: 0.03365654265508056 Scheduler time: 0.6333073149435222 Scheduler overhead time: 0.12744045769795775 Adapter cache time: 0.04890350624918938 Engine time: 0.12940349662676454 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-32/adapters_192_slots_16_rate_0.025-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-32/adapters_192_slots_16_rate_0.025-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [64 64 64]
Adapter prompts. [270, 33, 270, 33, 270, 33, 270, 33, 33, 33, 66, 66, 66, 66, 270, 66, 33, 270, 33, 66, 66, 33, 270, 270, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 270, 66, 33, 66, 270, 270, 66, 270, 33, 66, 66, 270, 66, 33, 33, 66, 270, 33, 66, 33, 270, 270, 66, 270, 270, 270, 33, 66, 270, 33, 66, 33, 66, 33, 33, 66, 270, 270, 33, 33, 33, 270, 270, 270, 66, 33, 33, 33, 33, 33, 270, 33, 66, 33, 270, 270, 33, 270, 33, 66, 66, 270, 33, 33, 33, 270, 270, 66, 270, 66, 270, 270, 66, 66, 33, 270, 66, 66, 66, 270, 66, 33, 66, 270, 270, 66, 270, 66, 33, 270, 66, 33, 66, 66, 33, 66, 270, 33, 66, 270, 33, 66, 270, 270, 66, 33, 270, 66, 33, 33, 66, 270, 270, 270, 33, 270, 33, 270, 33, 66, 33, 270, 270, 66, 270, 33, 270, 270, 270, 33, 270, 270, 270, 66, 66, 66, 66, 66, 66, 33, 270, 66, 270, 33, 270, 66, 33, 66, 33, 33, 66, 66, 66, 270, 66, 33, 33]
Prompts retrieved: 23616 . Total input tokens: 5209427 . Total output tokens: 4648377
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 1.0464084041304886,
    "estimated_duration": 3598.804159915826,
    "input_throughput": 545.0046495572227,
    "output_throughput": 485.12531452693304,
    "total_throughput": 1030.1299640841557,
    "itl": 22.726031637971786,
    "ttft": 7376.527795548186,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6873,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 50.479281819181175,
    "arrivals": 8047,
    "finished_requests": 8031,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0467460961081088. Arrivals time: 0.03364776540547609 Scheduler time: 0.6441105576232076 Scheduler overhead time: 0.12670736573636532 Adapter cache time: 0.049284717068076134 Engine time: 0.1290083690546453 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-8/adapters_192_slots_16_rate_0.0125-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 301520,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-8/adapters_192_slots_16_rate_0.0125-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [64 64 64]
Adapter prompts. [135, 33, 135, 33, 135, 33, 135, 33, 33, 33, 66, 66, 66, 66, 135, 66, 33, 135, 33, 66, 66, 33, 135, 135, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 135, 66, 33, 66, 135, 135, 66, 135, 33, 66, 66, 135, 66, 33, 33, 66, 135, 33, 66, 33, 135, 135, 66, 135, 135, 135, 33, 66, 135, 33, 66, 33, 66, 33, 33, 66, 135, 135, 33, 33, 33, 135, 135, 135, 66, 33, 33, 33, 33, 33, 135, 33, 66, 33, 135, 135, 33, 135, 33, 66, 66, 135, 33, 33, 33, 135, 135, 66, 135, 66, 135, 135, 66, 66, 33, 135, 66, 66, 66, 135, 66, 33, 66, 135, 135, 66, 135, 66, 33, 135, 66, 33, 66, 66, 33, 66, 135, 33, 66, 135, 33, 66, 135, 135, 66, 33, 135, 66, 33, 33, 66, 135, 135, 135, 33, 135, 33, 135, 33, 66, 33, 135, 135, 66, 135, 33, 135, 135, 135, 33, 135, 135, 135, 66, 66, 66, 66, 66, 66, 33, 135, 66, 135, 33, 135, 66, 33, 66, 33, 33, 66, 66, 66, 135, 66, 33, 33]
Prompts retrieved: 14976 . Total input tokens: 3292385 . Total output tokens: 2986592
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 0.8203354212455451,
    "estimated_duration": 3599.9587178596744,
    "input_throughput": 347.07898004532177,
    "output_throughput": 303.4468130371992,
    "total_throughput": 650.525793082521,
    "itl": 21.41000892855924,
    "ttft": 7838.612429084018,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4531,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 29.960825323762315,
    "arrivals": 5084,
    "finished_requests": 5073,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8204007712192833. Arrivals time: 0.025107397697865963 Scheduler time: 0.42695164447650313 Scheduler overhead time: 0.13086243579164147 Adapter cache time: 0.038615223951637745 Engine time: 0.13269018847495317 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-16/adapters_192_slots_16_rate_0.0125-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-16/adapters_192_slots_16_rate_0.0125-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [64 64 64]
Adapter prompts. [135, 33, 135, 33, 135, 33, 135, 33, 33, 33, 66, 66, 66, 66, 135, 66, 33, 135, 33, 66, 66, 33, 135, 135, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 135, 66, 33, 66, 135, 135, 66, 135, 33, 66, 66, 135, 66, 33, 33, 66, 135, 33, 66, 33, 135, 135, 66, 135, 135, 135, 33, 66, 135, 33, 66, 33, 66, 33, 33, 66, 135, 135, 33, 33, 33, 135, 135, 135, 66, 33, 33, 33, 33, 33, 135, 33, 66, 33, 135, 135, 33, 135, 33, 66, 66, 135, 33, 33, 33, 135, 135, 66, 135, 66, 135, 135, 66, 66, 33, 135, 66, 66, 66, 135, 66, 33, 66, 135, 135, 66, 135, 66, 33, 135, 66, 33, 66, 66, 33, 66, 135, 33, 66, 135, 33, 66, 135, 135, 66, 33, 135, 66, 33, 33, 66, 135, 135, 135, 33, 135, 33, 135, 33, 66, 33, 135, 135, 66, 135, 33, 135, 135, 135, 33, 135, 135, 135, 66, 66, 66, 66, 66, 66, 33, 135, 66, 135, 33, 135, 66, 33, 66, 33, 33, 66, 66, 66, 135, 66, 33, 33]
Prompts retrieved: 14976 . Total input tokens: 3292385 . Total output tokens: 2986592
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 0.8247126410715282,
    "estimated_duration": 3599.954082516874,
    "input_throughput": 347.0794269482584,
    "output_throughput": 303.44720375884947,
    "total_throughput": 650.5266307071079,
    "itl": 21.42872275587078,
    "ttft": 7839.184963900777,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4531,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 32.99580967547752,
    "arrivals": 5084,
    "finished_requests": 5073,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.824794489890337. Arrivals time: 0.025390708819031715 Scheduler time: 0.4308612160384655 Scheduler overhead time: 0.13075031246989965 Adapter cache time: 0.03920555720105767 Engine time: 0.1322806221432984 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-32/adapters_192_slots_16_rate_0.0125-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-32/adapters_192_slots_16_rate_0.0125-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [64 64 64]
Adapter prompts. [135, 33, 135, 33, 135, 33, 135, 33, 33, 33, 66, 66, 66, 66, 135, 66, 33, 135, 33, 66, 66, 33, 135, 135, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 135, 66, 33, 66, 135, 135, 66, 135, 33, 66, 66, 135, 66, 33, 33, 66, 135, 33, 66, 33, 135, 135, 66, 135, 135, 135, 33, 66, 135, 33, 66, 33, 66, 33, 33, 66, 135, 135, 33, 33, 33, 135, 135, 135, 66, 33, 33, 33, 33, 33, 135, 33, 66, 33, 135, 135, 33, 135, 33, 66, 66, 135, 33, 33, 33, 135, 135, 66, 135, 66, 135, 135, 66, 66, 33, 135, 66, 66, 66, 135, 66, 33, 66, 135, 135, 66, 135, 66, 33, 135, 66, 33, 66, 66, 33, 66, 135, 33, 66, 135, 33, 66, 135, 135, 66, 33, 135, 66, 33, 33, 66, 135, 135, 135, 33, 135, 33, 135, 33, 66, 33, 135, 135, 66, 135, 33, 135, 135, 135, 33, 135, 135, 135, 66, 66, 66, 66, 66, 66, 33, 135, 66, 135, 33, 135, 66, 33, 66, 33, 33, 66, 66, 66, 135, 66, 33, 33]
Prompts retrieved: 14976 . Total input tokens: 3292385 . Total output tokens: 2986592
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 0.8259104341268539,
    "estimated_duration": 3599.947224539332,
    "input_throughput": 347.08008814209455,
    "output_throughput": 303.4477818323541,
    "total_throughput": 650.5278699744487,
    "itl": 21.43438575052005,
    "ttft": 7839.434244602731,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4531,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 33.86030703112595,
    "arrivals": 5084,
    "finished_requests": 5073,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8260030969977379. Arrivals time: 0.025368416216224432 Scheduler time: 0.4308426370844245 Scheduler overhead time: 0.13078099256381392 Adapter cache time: 0.03858852805569768 Engine time: 0.1339500853791833 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-16/adapters_192_slots_16_rate_0.0125-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-16/adapters_192_slots_16_rate_0.0125-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [64 64 64]
Adapter prompts. [135, 33, 135, 33, 135, 33, 135, 33, 33, 33, 66, 66, 66, 66, 135, 66, 33, 135, 33, 66, 66, 33, 135, 135, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 135, 66, 33, 66, 135, 135, 66, 135, 33, 66, 66, 135, 66, 33, 33, 66, 135, 33, 66, 33, 135, 135, 66, 135, 135, 135, 33, 66, 135, 33, 66, 33, 66, 33, 33, 66, 135, 135, 33, 33, 33, 135, 135, 135, 66, 33, 33, 33, 33, 33, 135, 33, 66, 33, 135, 135, 33, 135, 33, 66, 66, 135, 33, 33, 33, 135, 135, 66, 135, 66, 135, 135, 66, 66, 33, 135, 66, 66, 66, 135, 66, 33, 66, 135, 135, 66, 135, 66, 33, 135, 66, 33, 66, 66, 33, 66, 135, 33, 66, 135, 33, 66, 135, 135, 66, 33, 135, 66, 33, 33, 66, 135, 135, 135, 33, 135, 33, 135, 33, 66, 33, 135, 135, 66, 135, 33, 135, 135, 135, 33, 135, 135, 135, 66, 66, 66, 66, 66, 66, 33, 135, 66, 135, 33, 135, 66, 33, 66, 33, 33, 66, 66, 66, 135, 66, 33, 33]
Prompts retrieved: 14976 . Total input tokens: 3292385 . Total output tokens: 2986592
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 0.8185069430619478,
    "estimated_duration": 3599.940965945197,
    "input_throughput": 347.0806915501572,
    "output_throughput": 303.44830938447944,
    "total_throughput": 650.5290009346367,
    "itl": 21.41808738743619,
    "ttft": 7838.6225978125785,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4532,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 31.003155394849422,
    "arrivals": 5084,
    "finished_requests": 5073,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8185940939001739. Arrivals time: 0.02520388411357999 Scheduler time: 0.42582048336043954 Scheduler overhead time: 0.13119967374950647 Adapter cache time: 0.03868511971086264 Engine time: 0.13112861849367619 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-32/adapters_192_slots_16_rate_0.0125-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-32/adapters_192_slots_16_rate_0.0125-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [64 64 64]
Adapter prompts. [135, 33, 135, 33, 135, 33, 135, 33, 33, 33, 66, 66, 66, 66, 135, 66, 33, 135, 33, 66, 66, 33, 135, 135, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 135, 66, 33, 66, 135, 135, 66, 135, 33, 66, 66, 135, 66, 33, 33, 66, 135, 33, 66, 33, 135, 135, 66, 135, 135, 135, 33, 66, 135, 33, 66, 33, 66, 33, 33, 66, 135, 135, 33, 33, 33, 135, 135, 135, 66, 33, 33, 33, 33, 33, 135, 33, 66, 33, 135, 135, 33, 135, 33, 66, 66, 135, 33, 33, 33, 135, 135, 66, 135, 66, 135, 135, 66, 66, 33, 135, 66, 66, 66, 135, 66, 33, 66, 135, 135, 66, 135, 66, 33, 135, 66, 33, 66, 66, 33, 66, 135, 33, 66, 135, 33, 66, 135, 135, 66, 33, 135, 66, 33, 33, 66, 135, 135, 135, 33, 135, 33, 135, 33, 66, 33, 135, 135, 66, 135, 33, 135, 135, 135, 33, 135, 135, 135, 66, 66, 66, 66, 66, 66, 33, 135, 66, 135, 33, 135, 66, 33, 66, 33, 33, 66, 66, 66, 135, 66, 33, 33]
Prompts retrieved: 14976 . Total input tokens: 3292385 . Total output tokens: 2986592
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 0.8294671499170363,
    "estimated_duration": 3599.9539028780405,
    "input_throughput": 347.0794442676311,
    "output_throughput": 303.44721890096054,
    "total_throughput": 650.5266631685917,
    "itl": 21.431163104120753,
    "ttft": 7839.387561743026,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4531,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 33.56205829680085,
    "arrivals": 5084,
    "finished_requests": 5073,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8295343979261816. Arrivals time: 0.025898993015289307 Scheduler time: 0.43204933404922485 Scheduler overhead time: 0.1307235606946051 Adapter cache time: 0.039129351265728474 Engine time: 0.13565237494185567 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-16/adapters_192_slots_16_rate_0.0125-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 296000,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-16/adapters_192_slots_16_rate_0.0125-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [64 64 64]
Adapter prompts. [135, 33, 135, 33, 135, 33, 135, 33, 33, 33, 66, 66, 66, 66, 135, 66, 33, 135, 33, 66, 66, 33, 135, 135, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 135, 66, 33, 66, 135, 135, 66, 135, 33, 66, 66, 135, 66, 33, 33, 66, 135, 33, 66, 33, 135, 135, 66, 135, 135, 135, 33, 66, 135, 33, 66, 33, 66, 33, 33, 66, 135, 135, 33, 33, 33, 135, 135, 135, 66, 33, 33, 33, 33, 33, 135, 33, 66, 33, 135, 135, 33, 135, 33, 66, 66, 135, 33, 33, 33, 135, 135, 66, 135, 66, 135, 135, 66, 66, 33, 135, 66, 66, 66, 135, 66, 33, 66, 135, 135, 66, 135, 66, 33, 135, 66, 33, 66, 66, 33, 66, 135, 33, 66, 135, 33, 66, 135, 135, 66, 33, 135, 66, 33, 33, 66, 135, 135, 135, 33, 135, 33, 135, 33, 66, 33, 135, 135, 66, 135, 33, 135, 135, 135, 33, 135, 135, 135, 66, 66, 66, 66, 66, 66, 33, 135, 66, 135, 33, 135, 66, 33, 66, 33, 33, 66, 66, 66, 135, 66, 33, 33]
Prompts retrieved: 14976 . Total input tokens: 3292385 . Total output tokens: 2986592
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 0.828131312970072,
    "estimated_duration": 3599.9571501452624,
    "input_throughput": 347.079131191765,
    "output_throughput": 303.4469451826449,
    "total_throughput": 650.5260763744099,
    "itl": 21.404461676562427,
    "ttft": 7838.092226690233,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4531,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 28.925545781727838,
    "arrivals": 5084,
    "finished_requests": 5073,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8282151720486581. Arrivals time: 0.025839447043836117 Scheduler time: 0.4314348855987191 Scheduler overhead time: 0.13079117331653833 Adapter cache time: 0.03905570274218917 Engine time: 0.1344507564790547 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-32/adapters_192_slots_16_rate_0.0125-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 284944,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-32/adapters_192_slots_16_rate_0.0125-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [64 64 64]
Adapter prompts. [135, 33, 135, 33, 135, 33, 135, 33, 33, 33, 66, 66, 66, 66, 135, 66, 33, 135, 33, 66, 66, 33, 135, 135, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 135, 66, 33, 66, 135, 135, 66, 135, 33, 66, 66, 135, 66, 33, 33, 66, 135, 33, 66, 33, 135, 135, 66, 135, 135, 135, 33, 66, 135, 33, 66, 33, 66, 33, 33, 66, 135, 135, 33, 33, 33, 135, 135, 135, 66, 33, 33, 33, 33, 33, 135, 33, 66, 33, 135, 135, 33, 135, 33, 66, 66, 135, 33, 33, 33, 135, 135, 66, 135, 66, 135, 135, 66, 66, 33, 135, 66, 66, 66, 135, 66, 33, 66, 135, 135, 66, 135, 66, 33, 135, 66, 33, 66, 66, 33, 66, 135, 33, 66, 135, 33, 66, 135, 135, 66, 33, 135, 66, 33, 33, 66, 135, 135, 135, 33, 135, 33, 135, 33, 66, 33, 135, 135, 66, 135, 33, 135, 135, 135, 33, 135, 135, 135, 66, 66, 66, 66, 66, 66, 33, 135, 66, 135, 33, 135, 66, 33, 66, 33, 33, 66, 66, 66, 135, 66, 33, 33]
Prompts retrieved: 14976 . Total input tokens: 3292385 . Total output tokens: 2986592
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 0.8182039777748287,
    "estimated_duration": 3599.942740002493,
    "input_throughput": 347.08052050826086,
    "output_throughput": 303.44815984468784,
    "total_throughput": 650.5286803529488,
    "itl": 21.432630350065732,
    "ttft": 7839.227161207686,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4531,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 33.25303946929179,
    "arrivals": 5084,
    "finished_requests": 5073,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8185508446767926. Arrivals time: 0.025216799695044756 Scheduler time: 0.42773045133799314 Scheduler overhead time: 0.13030383177101612 Adapter cache time: 0.038580406457185745 Engine time: 0.1301902229897678 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.8_size_8-8-8/adapters_192_slots_32_rate_3.2-1.6-0.8_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.8_size_8-8-8/adapters_192_slots_32_rate_3.2-1.6-0.8_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 8640, 8640, 17280, 17280, 17280, 17280, 34560, 17280, 8640, 34560, 8640, 17280, 17280, 8640, 34560, 34560, 8640, 17280, 8640, 17280, 8640, 8640, 17280, 8640, 8640, 17280, 17280, 34560, 17280, 8640, 17280, 34560, 34560, 17280, 34560, 8640, 17280, 17280, 34560, 17280, 8640, 8640, 17280, 34560, 8640, 17280, 8640, 34560, 34560, 17280, 34560, 34560, 34560, 8640, 17280, 34560, 8640, 17280, 8640, 17280, 8640, 8640, 17280, 34560, 34560, 8640, 8640, 8640, 34560, 34560, 34560, 17280, 8640, 8640, 8640, 8640, 8640, 34560, 8640, 17280, 8640, 34560, 34560, 8640, 34560, 8640, 17280, 17280, 34560, 8640, 8640, 8640, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 8640, 34560, 17280, 17280, 17280, 34560, 17280, 8640, 17280, 34560, 34560, 17280, 34560, 17280, 8640, 34560, 17280, 8640, 17280, 17280, 8640, 17280, 34560, 8640, 17280, 34560, 8640, 17280, 34560, 34560, 17280, 8640, 34560, 17280, 8640, 8640, 17280, 34560, 34560, 34560, 8640, 34560, 8640, 34560, 8640, 17280, 8640, 34560, 34560, 17280, 34560, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 8640, 34560, 17280, 34560, 8640, 34560, 17280, 8640, 17280, 8640, 8640, 17280, 17280, 17280, 34560, 17280, 8640, 8640]
Prompts retrieved: 3870720 . Total input tokens: 863190198 . Total output tokens: 760505632
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 106.05064174206927,
    "estimated_duration": 3600.0579797348414,
    "input_throughput": 6790.182307508413,
    "output_throughput": 5908.713170660309,
    "total_throughput": 12698.89547816872,
    "itl": 99.98811298654674,
    "ttft": 2046650.2814202623,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 361,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3870796605339373,
    "arrivals": 1289329,
    "finished_requests": 98957,
    "scheduler_time": 231.96980493267904
}
#Debug simulation 
Total elapsed time: 106.05091208498925. Arrivals time: 0.8346954616717994 Scheduler time: 104.94229318760335 Scheduler overhead time: 0.10739392414689064 Adapter cache time: 0.023939858190715313 Engine time: 0.10728492913767695 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.8_size_8-8-16/adapters_192_slots_32_rate_3.2-1.6-0.8_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.8_size_8-8-16/adapters_192_slots_32_rate_3.2-1.6-0.8_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 8640, 8640, 17280, 17280, 17280, 17280, 34560, 17280, 8640, 34560, 8640, 17280, 17280, 8640, 34560, 34560, 8640, 17280, 8640, 17280, 8640, 8640, 17280, 8640, 8640, 17280, 17280, 34560, 17280, 8640, 17280, 34560, 34560, 17280, 34560, 8640, 17280, 17280, 34560, 17280, 8640, 8640, 17280, 34560, 8640, 17280, 8640, 34560, 34560, 17280, 34560, 34560, 34560, 8640, 17280, 34560, 8640, 17280, 8640, 17280, 8640, 8640, 17280, 34560, 34560, 8640, 8640, 8640, 34560, 34560, 34560, 17280, 8640, 8640, 8640, 8640, 8640, 34560, 8640, 17280, 8640, 34560, 34560, 8640, 34560, 8640, 17280, 17280, 34560, 8640, 8640, 8640, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 8640, 34560, 17280, 17280, 17280, 34560, 17280, 8640, 17280, 34560, 34560, 17280, 34560, 17280, 8640, 34560, 17280, 8640, 17280, 17280, 8640, 17280, 34560, 8640, 17280, 34560, 8640, 17280, 34560, 34560, 17280, 8640, 34560, 17280, 8640, 8640, 17280, 34560, 34560, 34560, 8640, 34560, 8640, 34560, 8640, 17280, 8640, 34560, 34560, 17280, 34560, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 8640, 34560, 17280, 34560, 8640, 34560, 17280, 8640, 17280, 8640, 8640, 17280, 17280, 17280, 34560, 17280, 8640, 8640]
Prompts retrieved: 3870720 . Total input tokens: 863190198 . Total output tokens: 760505632
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 99.36785648716614,
    "estimated_duration": 3600.022966236666,
    "input_throughput": 6712.637732214775,
    "output_throughput": 5848.357134790537,
    "total_throughput": 12560.994867005313,
    "itl": 97.48264349621321,
    "ttft": 2053044.2038263727,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 376,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.7501859589293636,
    "arrivals": 1289329,
    "finished_requests": 97903,
    "scheduler_time": 234.7117674163528
}
#Debug simulation 
Total elapsed time: 99.36807146715. Arrivals time: 0.8317188816145062 Scheduler time: 98.26579871075228 Scheduler overhead time: 0.10688765626400709 Adapter cache time: 0.022998266387730837 Engine time: 0.10523881996050477 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.8_size_8-8-32/adapters_192_slots_32_rate_3.2-1.6-0.8_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.8_size_8-8-32/adapters_192_slots_32_rate_3.2-1.6-0.8_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 8640, 8640, 17280, 17280, 17280, 17280, 34560, 17280, 8640, 34560, 8640, 17280, 17280, 8640, 34560, 34560, 8640, 17280, 8640, 17280, 8640, 8640, 17280, 8640, 8640, 17280, 17280, 34560, 17280, 8640, 17280, 34560, 34560, 17280, 34560, 8640, 17280, 17280, 34560, 17280, 8640, 8640, 17280, 34560, 8640, 17280, 8640, 34560, 34560, 17280, 34560, 34560, 34560, 8640, 17280, 34560, 8640, 17280, 8640, 17280, 8640, 8640, 17280, 34560, 34560, 8640, 8640, 8640, 34560, 34560, 34560, 17280, 8640, 8640, 8640, 8640, 8640, 34560, 8640, 17280, 8640, 34560, 34560, 8640, 34560, 8640, 17280, 17280, 34560, 8640, 8640, 8640, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 8640, 34560, 17280, 17280, 17280, 34560, 17280, 8640, 17280, 34560, 34560, 17280, 34560, 17280, 8640, 34560, 17280, 8640, 17280, 17280, 8640, 17280, 34560, 8640, 17280, 34560, 8640, 17280, 34560, 34560, 17280, 8640, 34560, 17280, 8640, 8640, 17280, 34560, 34560, 34560, 8640, 34560, 8640, 34560, 8640, 17280, 8640, 34560, 34560, 17280, 34560, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 8640, 34560, 17280, 34560, 8640, 34560, 17280, 8640, 17280, 8640, 8640, 17280, 17280, 17280, 34560, 17280, 8640, 8640]
Prompts retrieved: 3870720 . Total input tokens: 863190198 . Total output tokens: 760505632
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 99.2860586810857,
    "estimated_duration": 3600.00670041562,
    "input_throughput": 6530.049234987808,
    "output_throughput": 5682.652756629085,
    "total_throughput": 12212.701991616892,
    "itl": 91.40620570398619,
    "ttft": 2065152.810268646,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 380,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.851889469879697,
    "arrivals": 1289329,
    "finished_requests": 95122,
    "scheduler_time": 242.08889129444438
}
#Debug simulation 
Total elapsed time: 99.28622931987047. Arrivals time: 0.8622892028652132 Scheduler time: 98.14067980274558 Scheduler overhead time: 0.1103305472061038 Adapter cache time: 0.024605298414826393 Engine time: 0.11156598897650838 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.8_size_8-16-16/adapters_192_slots_32_rate_3.2-1.6-0.8_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.8_size_8-16-16/adapters_192_slots_32_rate_3.2-1.6-0.8_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 8640, 8640, 17280, 17280, 17280, 17280, 34560, 17280, 8640, 34560, 8640, 17280, 17280, 8640, 34560, 34560, 8640, 17280, 8640, 17280, 8640, 8640, 17280, 8640, 8640, 17280, 17280, 34560, 17280, 8640, 17280, 34560, 34560, 17280, 34560, 8640, 17280, 17280, 34560, 17280, 8640, 8640, 17280, 34560, 8640, 17280, 8640, 34560, 34560, 17280, 34560, 34560, 34560, 8640, 17280, 34560, 8640, 17280, 8640, 17280, 8640, 8640, 17280, 34560, 34560, 8640, 8640, 8640, 34560, 34560, 34560, 17280, 8640, 8640, 8640, 8640, 8640, 34560, 8640, 17280, 8640, 34560, 34560, 8640, 34560, 8640, 17280, 17280, 34560, 8640, 8640, 8640, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 8640, 34560, 17280, 17280, 17280, 34560, 17280, 8640, 17280, 34560, 34560, 17280, 34560, 17280, 8640, 34560, 17280, 8640, 17280, 17280, 8640, 17280, 34560, 8640, 17280, 34560, 8640, 17280, 34560, 34560, 17280, 8640, 34560, 17280, 8640, 8640, 17280, 34560, 34560, 34560, 8640, 34560, 8640, 34560, 8640, 17280, 8640, 34560, 34560, 17280, 34560, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 8640, 34560, 17280, 34560, 8640, 34560, 17280, 8640, 17280, 8640, 8640, 17280, 17280, 17280, 34560, 17280, 8640, 8640]
Prompts retrieved: 3870720 . Total input tokens: 863190198 . Total output tokens: 760505632
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 103.5249609798193,
    "estimated_duration": 3600.029363847353,
    "input_throughput": 6684.952140023833,
    "output_throughput": 5830.1410568411,
    "total_throughput": 12515.093196864933,
    "itl": 97.29318181654122,
    "ttft": 2052871.818241586,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 374,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.5569493905175444,
    "arrivals": 1289329,
    "finished_requests": 97597,
    "scheduler_time": 235.29014419064734
}
#Debug simulation 
Total elapsed time: 103.52513433201239. Arrivals time: 0.8603916219435632 Scheduler time: 102.38748562848195 Scheduler overhead time: 0.10870102420449257 Adapter cache time: 0.02496777754276991 Engine time: 0.10782266547903419 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.8_size_8-16-32/adapters_192_slots_32_rate_3.2-1.6-0.8_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.8_size_8-16-32/adapters_192_slots_32_rate_3.2-1.6-0.8_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 8640, 8640, 17280, 17280, 17280, 17280, 34560, 17280, 8640, 34560, 8640, 17280, 17280, 8640, 34560, 34560, 8640, 17280, 8640, 17280, 8640, 8640, 17280, 8640, 8640, 17280, 17280, 34560, 17280, 8640, 17280, 34560, 34560, 17280, 34560, 8640, 17280, 17280, 34560, 17280, 8640, 8640, 17280, 34560, 8640, 17280, 8640, 34560, 34560, 17280, 34560, 34560, 34560, 8640, 17280, 34560, 8640, 17280, 8640, 17280, 8640, 8640, 17280, 34560, 34560, 8640, 8640, 8640, 34560, 34560, 34560, 17280, 8640, 8640, 8640, 8640, 8640, 34560, 8640, 17280, 8640, 34560, 34560, 8640, 34560, 8640, 17280, 17280, 34560, 8640, 8640, 8640, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 8640, 34560, 17280, 17280, 17280, 34560, 17280, 8640, 17280, 34560, 34560, 17280, 34560, 17280, 8640, 34560, 17280, 8640, 17280, 17280, 8640, 17280, 34560, 8640, 17280, 34560, 8640, 17280, 34560, 34560, 17280, 8640, 34560, 17280, 8640, 8640, 17280, 34560, 34560, 34560, 8640, 34560, 8640, 34560, 8640, 17280, 8640, 34560, 34560, 17280, 34560, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 8640, 34560, 17280, 34560, 8640, 34560, 17280, 8640, 17280, 8640, 8640, 17280, 17280, 17280, 34560, 17280, 8640, 8640]
Prompts retrieved: 3870720 . Total input tokens: 863190198 . Total output tokens: 760505632
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 96.31180423637852,
    "estimated_duration": 3600.045212981082,
    "input_throughput": 6547.089718487893,
    "output_throughput": 5689.6599315314315,
    "total_throughput": 12236.749650019325,
    "itl": 91.42926882960343,
    "ttft": 2066579.2854608262,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 386,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.871297636413965,
    "arrivals": 1289329,
    "finished_requests": 95340,
    "scheduler_time": 241.9721852130965
}
#Debug simulation 
Total elapsed time: 96.31197265116498. Arrivals time: 0.8844176228158176 Scheduler time: 95.15637911576778 Scheduler overhead time: 0.10534214647486806 Adapter cache time: 0.023650876712054014 Engine time: 0.10605421382933855 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.8_size_16-16-16/adapters_192_slots_32_rate_3.2-1.6-0.8_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.8_size_16-16-16/adapters_192_slots_32_rate_3.2-1.6-0.8_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 8640, 8640, 17280, 17280, 17280, 17280, 34560, 17280, 8640, 34560, 8640, 17280, 17280, 8640, 34560, 34560, 8640, 17280, 8640, 17280, 8640, 8640, 17280, 8640, 8640, 17280, 17280, 34560, 17280, 8640, 17280, 34560, 34560, 17280, 34560, 8640, 17280, 17280, 34560, 17280, 8640, 8640, 17280, 34560, 8640, 17280, 8640, 34560, 34560, 17280, 34560, 34560, 34560, 8640, 17280, 34560, 8640, 17280, 8640, 17280, 8640, 8640, 17280, 34560, 34560, 8640, 8640, 8640, 34560, 34560, 34560, 17280, 8640, 8640, 8640, 8640, 8640, 34560, 8640, 17280, 8640, 34560, 34560, 8640, 34560, 8640, 17280, 17280, 34560, 8640, 8640, 8640, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 8640, 34560, 17280, 17280, 17280, 34560, 17280, 8640, 17280, 34560, 34560, 17280, 34560, 17280, 8640, 34560, 17280, 8640, 17280, 17280, 8640, 17280, 34560, 8640, 17280, 34560, 8640, 17280, 34560, 34560, 17280, 8640, 34560, 17280, 8640, 8640, 17280, 34560, 34560, 34560, 8640, 34560, 8640, 34560, 8640, 17280, 8640, 34560, 34560, 17280, 34560, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 8640, 34560, 17280, 34560, 8640, 34560, 17280, 8640, 17280, 8640, 8640, 17280, 17280, 17280, 34560, 17280, 8640, 8640]
Prompts retrieved: 3870720 . Total input tokens: 863190198 . Total output tokens: 760505632
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 103.02695894986391,
    "estimated_duration": 3600.090021733063,
    "input_throughput": 6710.833021994739,
    "output_throughput": 5840.858109952879,
    "total_throughput": 12551.691131947618,
    "itl": 97.32919856154003,
    "ttft": 2051967.1278031897,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 372,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3748185898922287,
    "arrivals": 1289329,
    "finished_requests": 97721,
    "scheduler_time": 234.81803523627696
}
#Debug simulation 
Total elapsed time: 103.02713375911117. Arrivals time: 1.2307336586527526 Scheduler time: 101.52855940768495 Scheduler overhead time: 0.10419018100947142 Adapter cache time: 0.023319325875490904 Engine time: 0.10509031126275659 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.8_size_16-16-32/adapters_192_slots_32_rate_3.2-1.6-0.8_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.8_size_16-16-32/adapters_192_slots_32_rate_3.2-1.6-0.8_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 8640, 8640, 17280, 17280, 17280, 17280, 34560, 17280, 8640, 34560, 8640, 17280, 17280, 8640, 34560, 34560, 8640, 17280, 8640, 17280, 8640, 8640, 17280, 8640, 8640, 17280, 17280, 34560, 17280, 8640, 17280, 34560, 34560, 17280, 34560, 8640, 17280, 17280, 34560, 17280, 8640, 8640, 17280, 34560, 8640, 17280, 8640, 34560, 34560, 17280, 34560, 34560, 34560, 8640, 17280, 34560, 8640, 17280, 8640, 17280, 8640, 8640, 17280, 34560, 34560, 8640, 8640, 8640, 34560, 34560, 34560, 17280, 8640, 8640, 8640, 8640, 8640, 34560, 8640, 17280, 8640, 34560, 34560, 8640, 34560, 8640, 17280, 17280, 34560, 8640, 8640, 8640, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 8640, 34560, 17280, 17280, 17280, 34560, 17280, 8640, 17280, 34560, 34560, 17280, 34560, 17280, 8640, 34560, 17280, 8640, 17280, 17280, 8640, 17280, 34560, 8640, 17280, 34560, 8640, 17280, 34560, 34560, 17280, 8640, 34560, 17280, 8640, 8640, 17280, 34560, 34560, 34560, 8640, 34560, 8640, 34560, 8640, 17280, 8640, 34560, 34560, 17280, 34560, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 8640, 34560, 17280, 34560, 8640, 34560, 17280, 8640, 17280, 8640, 8640, 17280, 17280, 17280, 34560, 17280, 8640, 8640]
Prompts retrieved: 3870720 . Total input tokens: 863190198 . Total output tokens: 760505632
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 97.18307843897492,
    "estimated_duration": 3600.0402363446206,
    "input_throughput": 6531.3517228559,
    "output_throughput": 5680.640397720915,
    "total_throughput": 12211.992120576815,
    "itl": 91.34633816474836,
    "ttft": 2065725.9485815044,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 386,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.842197493724542,
    "arrivals": 1289329,
    "finished_requests": 95134,
    "scheduler_time": 242.31502930817774
}
#Debug simulation 
Total elapsed time: 97.1832746239379. Arrivals time: 0.8377530151046813 Scheduler time: 96.07152762683108 Scheduler overhead time: 0.1069838535040617 Adapter cache time: 0.02416996844112873 Engine time: 0.10681459633633494 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.4_size_8-8-8/adapters_192_slots_32_rate_3.2-1.6-0.4_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.4_size_8-8-8/adapters_192_slots_32_rate_3.2-1.6-0.4_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 4320, 4320, 17280, 17280, 17280, 17280, 34560, 17280, 4320, 34560, 4320, 17280, 17280, 4320, 34560, 34560, 4320, 17280, 4320, 17280, 4320, 4320, 17280, 4320, 4320, 17280, 17280, 34560, 17280, 4320, 17280, 34560, 34560, 17280, 34560, 4320, 17280, 17280, 34560, 17280, 4320, 4320, 17280, 34560, 4320, 17280, 4320, 34560, 34560, 17280, 34560, 34560, 34560, 4320, 17280, 34560, 4320, 17280, 4320, 17280, 4320, 4320, 17280, 34560, 34560, 4320, 4320, 4320, 34560, 34560, 34560, 17280, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 17280, 4320, 34560, 34560, 4320, 34560, 4320, 17280, 17280, 34560, 4320, 4320, 4320, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 4320, 34560, 17280, 17280, 17280, 34560, 17280, 4320, 17280, 34560, 34560, 17280, 34560, 17280, 4320, 34560, 17280, 4320, 17280, 17280, 4320, 17280, 34560, 4320, 17280, 34560, 4320, 17280, 34560, 34560, 17280, 4320, 34560, 17280, 4320, 4320, 17280, 34560, 34560, 34560, 4320, 34560, 4320, 34560, 4320, 17280, 4320, 34560, 34560, 17280, 34560, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 34560, 17280, 34560, 4320, 34560, 17280, 4320, 17280, 4320, 4320, 17280, 17280, 17280, 34560, 17280, 4320, 4320]
Prompts retrieved: 3594240 . Total input tokens: 801481657 . Total output tokens: 706278274
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 105.2783460658975,
    "estimated_duration": 3600.0882509957855,
    "input_throughput": 6818.970338632606,
    "output_throughput": 5915.174716650281,
    "total_throughput": 12734.145055282886,
    "itl": 99.9630746643043,
    "ttft": 2040236.6229808317,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 372,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.459816159885389,
    "arrivals": 1197398,
    "finished_requests": 98940,
    "scheduler_time": 231.24582191414484
}
#Debug simulation 
Total elapsed time: 105.27851723507047. Arrivals time: 0.8797629810869694 Scheduler time: 104.11786208022386 Scheduler overhead time: 0.10932483756914735 Adapter cache time: 0.024145607370883226 Engine time: 0.11035642260685563 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.4_size_8-8-16/adapters_192_slots_32_rate_3.2-1.6-0.4_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.4_size_8-8-16/adapters_192_slots_32_rate_3.2-1.6-0.4_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 4320, 4320, 17280, 17280, 17280, 17280, 34560, 17280, 4320, 34560, 4320, 17280, 17280, 4320, 34560, 34560, 4320, 17280, 4320, 17280, 4320, 4320, 17280, 4320, 4320, 17280, 17280, 34560, 17280, 4320, 17280, 34560, 34560, 17280, 34560, 4320, 17280, 17280, 34560, 17280, 4320, 4320, 17280, 34560, 4320, 17280, 4320, 34560, 34560, 17280, 34560, 34560, 34560, 4320, 17280, 34560, 4320, 17280, 4320, 17280, 4320, 4320, 17280, 34560, 34560, 4320, 4320, 4320, 34560, 34560, 34560, 17280, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 17280, 4320, 34560, 34560, 4320, 34560, 4320, 17280, 17280, 34560, 4320, 4320, 4320, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 4320, 34560, 17280, 17280, 17280, 34560, 17280, 4320, 17280, 34560, 34560, 17280, 34560, 17280, 4320, 34560, 17280, 4320, 17280, 17280, 4320, 17280, 34560, 4320, 17280, 34560, 4320, 17280, 34560, 34560, 17280, 4320, 34560, 17280, 4320, 4320, 17280, 34560, 34560, 34560, 4320, 34560, 4320, 34560, 4320, 17280, 4320, 34560, 34560, 17280, 34560, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 34560, 17280, 34560, 4320, 34560, 17280, 4320, 17280, 4320, 4320, 17280, 17280, 17280, 34560, 17280, 4320, 4320]
Prompts retrieved: 3594240 . Total input tokens: 801481657 . Total output tokens: 706278274
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 83.03385551134124,
    "estimated_duration": 3600.0939235489777,
    "input_throughput": 6742.011601761976,
    "output_throughput": 5844.133916167192,
    "total_throughput": 12586.145517929168,
    "itl": 97.18967064300949,
    "ttft": 2044276.375311009,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 330,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.4107143035437946,
    "arrivals": 1197398,
    "finished_requests": 97730,
    "scheduler_time": 234.54045940446414
}
#Debug simulation 
Total elapsed time: 83.0340125951916. Arrivals time: 0.6387850437313318 Scheduler time: 82.18680176511407 Scheduler overhead time: 0.08113585878163576 Adapter cache time: 0.01708798622712493 Engine time: 0.07944012572988868 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.4_size_8-8-32/adapters_192_slots_32_rate_3.2-1.6-0.4_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.4_size_8-8-32/adapters_192_slots_32_rate_3.2-1.6-0.4_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 4320, 4320, 17280, 17280, 17280, 17280, 34560, 17280, 4320, 34560, 4320, 17280, 17280, 4320, 34560, 34560, 4320, 17280, 4320, 17280, 4320, 4320, 17280, 4320, 4320, 17280, 17280, 34560, 17280, 4320, 17280, 34560, 34560, 17280, 34560, 4320, 17280, 17280, 34560, 17280, 4320, 4320, 17280, 34560, 4320, 17280, 4320, 34560, 34560, 17280, 34560, 34560, 34560, 4320, 17280, 34560, 4320, 17280, 4320, 17280, 4320, 4320, 17280, 34560, 34560, 4320, 4320, 4320, 34560, 34560, 34560, 17280, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 17280, 4320, 34560, 34560, 4320, 34560, 4320, 17280, 17280, 34560, 4320, 4320, 4320, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 4320, 34560, 17280, 17280, 17280, 34560, 17280, 4320, 17280, 34560, 34560, 17280, 34560, 17280, 4320, 34560, 17280, 4320, 17280, 17280, 4320, 17280, 34560, 4320, 17280, 34560, 4320, 17280, 34560, 34560, 17280, 4320, 34560, 17280, 4320, 4320, 17280, 34560, 34560, 34560, 4320, 34560, 4320, 34560, 4320, 17280, 4320, 34560, 34560, 17280, 34560, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 34560, 17280, 34560, 4320, 34560, 17280, 4320, 17280, 4320, 4320, 17280, 17280, 17280, 34560, 17280, 4320, 4320]
Prompts retrieved: 3594240 . Total input tokens: 801481657 . Total output tokens: 706278274
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 103.95213694125414,
    "estimated_duration": 3600.0882638779076,
    "input_throughput": 6553.6043204078915,
    "output_throughput": 5679.061040013815,
    "total_throughput": 12232.665360421706,
    "itl": 90.80921189730775,
    "ttft": 2061770.582905209,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 373,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.7953569562640213,
    "arrivals": 1197398,
    "finished_requests": 95012,
    "scheduler_time": 242.08812494817315
}
#Debug simulation 
Total elapsed time: 103.95232257293537. Arrivals time: 0.9409382422454655 Scheduler time: 102.69641771959141 Scheduler overhead time: 0.12444533500820398 Adapter cache time: 0.027847049292176962 Engine time: 0.12397863250225782 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.4_size_8-16-16/adapters_192_slots_32_rate_3.2-1.6-0.4_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.4_size_8-16-16/adapters_192_slots_32_rate_3.2-1.6-0.4_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 4320, 4320, 17280, 17280, 17280, 17280, 34560, 17280, 4320, 34560, 4320, 17280, 17280, 4320, 34560, 34560, 4320, 17280, 4320, 17280, 4320, 4320, 17280, 4320, 4320, 17280, 17280, 34560, 17280, 4320, 17280, 34560, 34560, 17280, 34560, 4320, 17280, 17280, 34560, 17280, 4320, 4320, 17280, 34560, 4320, 17280, 4320, 34560, 34560, 17280, 34560, 34560, 34560, 4320, 17280, 34560, 4320, 17280, 4320, 17280, 4320, 4320, 17280, 34560, 34560, 4320, 4320, 4320, 34560, 34560, 34560, 17280, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 17280, 4320, 34560, 34560, 4320, 34560, 4320, 17280, 17280, 34560, 4320, 4320, 4320, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 4320, 34560, 17280, 17280, 17280, 34560, 17280, 4320, 17280, 34560, 34560, 17280, 34560, 17280, 4320, 34560, 17280, 4320, 17280, 17280, 4320, 17280, 34560, 4320, 17280, 34560, 4320, 17280, 34560, 34560, 17280, 4320, 34560, 17280, 4320, 4320, 17280, 34560, 34560, 34560, 4320, 34560, 4320, 34560, 4320, 17280, 4320, 34560, 34560, 17280, 34560, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 34560, 17280, 34560, 4320, 34560, 17280, 4320, 17280, 4320, 4320, 17280, 17280, 17280, 34560, 17280, 4320, 4320]
Prompts retrieved: 3594240 . Total input tokens: 801481657 . Total output tokens: 706278274
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 106.16573263006285,
    "estimated_duration": 3600.03823730843,
    "input_throughput": 6753.490212419936,
    "output_throughput": 5852.691724672605,
    "total_throughput": 12606.18193709254,
    "itl": 97.45669263378412,
    "ttft": 2042307.0144282593,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 399,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.7290414027916228,
    "arrivals": 1197398,
    "finished_requests": 97840,
    "scheduler_time": 234.37831200713467
}
#Debug simulation 
Total elapsed time: 106.16591147100553. Arrivals time: 0.8918016413226724 Scheduler time: 104.99648979865015 Scheduler overhead time: 0.10731933591887355 Adapter cache time: 0.025460228323936462 Engine time: 0.10929859569296241 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.4_size_8-16-32/adapters_192_slots_32_rate_3.2-1.6-0.4_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.4_size_8-16-32/adapters_192_slots_32_rate_3.2-1.6-0.4_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 4320, 4320, 17280, 17280, 17280, 17280, 34560, 17280, 4320, 34560, 4320, 17280, 17280, 4320, 34560, 34560, 4320, 17280, 4320, 17280, 4320, 4320, 17280, 4320, 4320, 17280, 17280, 34560, 17280, 4320, 17280, 34560, 34560, 17280, 34560, 4320, 17280, 17280, 34560, 17280, 4320, 4320, 17280, 34560, 4320, 17280, 4320, 34560, 34560, 17280, 34560, 34560, 34560, 4320, 17280, 34560, 4320, 17280, 4320, 17280, 4320, 4320, 17280, 34560, 34560, 4320, 4320, 4320, 34560, 34560, 34560, 17280, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 17280, 4320, 34560, 34560, 4320, 34560, 4320, 17280, 17280, 34560, 4320, 4320, 4320, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 4320, 34560, 17280, 17280, 17280, 34560, 17280, 4320, 17280, 34560, 34560, 17280, 34560, 17280, 4320, 34560, 17280, 4320, 17280, 17280, 4320, 17280, 34560, 4320, 17280, 34560, 4320, 17280, 34560, 34560, 17280, 4320, 34560, 17280, 4320, 4320, 17280, 34560, 34560, 34560, 4320, 34560, 4320, 34560, 4320, 17280, 4320, 34560, 34560, 17280, 34560, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 34560, 17280, 34560, 4320, 34560, 17280, 4320, 17280, 4320, 4320, 17280, 17280, 17280, 34560, 17280, 4320, 4320]
Prompts retrieved: 3594240 . Total input tokens: 801481657 . Total output tokens: 706278274
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 98.55792111903429,
    "estimated_duration": 3600.0159367116516,
    "input_throughput": 6561.780118556202,
    "output_throughput": 5686.460937919921,
    "total_throughput": 12248.241056476123,
    "itl": 91.16288677839832,
    "ttft": 2061002.7822931998,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 382,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.8383201224077683,
    "arrivals": 1197398,
    "finished_requests": 95157,
    "scheduler_time": 241.84160465972414
}
#Debug simulation 
Total elapsed time: 98.55810767691582. Arrivals time: 0.951014363206923 Scheduler time: 97.32825000723824 Scheduler overhead time: 0.10929047595709562 Adapter cache time: 0.023984920233488083 Engine time: 0.10918923933058977 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.4_size_16-16-16/adapters_192_slots_32_rate_3.2-1.6-0.4_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.4_size_16-16-16/adapters_192_slots_32_rate_3.2-1.6-0.4_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 4320, 4320, 17280, 17280, 17280, 17280, 34560, 17280, 4320, 34560, 4320, 17280, 17280, 4320, 34560, 34560, 4320, 17280, 4320, 17280, 4320, 4320, 17280, 4320, 4320, 17280, 17280, 34560, 17280, 4320, 17280, 34560, 34560, 17280, 34560, 4320, 17280, 17280, 34560, 17280, 4320, 4320, 17280, 34560, 4320, 17280, 4320, 34560, 34560, 17280, 34560, 34560, 34560, 4320, 17280, 34560, 4320, 17280, 4320, 17280, 4320, 4320, 17280, 34560, 34560, 4320, 4320, 4320, 34560, 34560, 34560, 17280, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 17280, 4320, 34560, 34560, 4320, 34560, 4320, 17280, 17280, 34560, 4320, 4320, 4320, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 4320, 34560, 17280, 17280, 17280, 34560, 17280, 4320, 17280, 34560, 34560, 17280, 34560, 17280, 4320, 34560, 17280, 4320, 17280, 17280, 4320, 17280, 34560, 4320, 17280, 34560, 4320, 17280, 34560, 34560, 17280, 4320, 34560, 17280, 4320, 4320, 17280, 34560, 34560, 34560, 4320, 34560, 4320, 34560, 4320, 17280, 4320, 34560, 34560, 17280, 34560, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 34560, 17280, 34560, 4320, 34560, 17280, 4320, 17280, 4320, 4320, 17280, 17280, 17280, 34560, 17280, 4320, 4320]
Prompts retrieved: 3594240 . Total input tokens: 801481657 . Total output tokens: 706278274
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 108.60147542599589,
    "estimated_duration": 3600.000042714782,
    "input_throughput": 6743.151864435483,
    "output_throughput": 5844.682708429348,
    "total_throughput": 12587.834572864831,
    "itl": 97.32296428897315,
    "ttft": 2047020.270712988,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 344,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.196068803556255,
    "arrivals": 1197398,
    "finished_requests": 97903,
    "scheduler_time": 234.45734531709562
}
#Debug simulation 
Total elapsed time: 108.60166075034067. Arrivals time: 0.8651051102206111 Scheduler time: 107.45615934068337 Scheduler overhead time: 0.11003300501033664 Adapter cache time: 0.024703969713300467 Engine time: 0.10917912097647786 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.4_size_16-16-32/adapters_192_slots_32_rate_3.2-1.6-0.4_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.4_size_16-16-32/adapters_192_slots_32_rate_3.2-1.6-0.4_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 4320, 4320, 17280, 17280, 17280, 17280, 34560, 17280, 4320, 34560, 4320, 17280, 17280, 4320, 34560, 34560, 4320, 17280, 4320, 17280, 4320, 4320, 17280, 4320, 4320, 17280, 17280, 34560, 17280, 4320, 17280, 34560, 34560, 17280, 34560, 4320, 17280, 17280, 34560, 17280, 4320, 4320, 17280, 34560, 4320, 17280, 4320, 34560, 34560, 17280, 34560, 34560, 34560, 4320, 17280, 34560, 4320, 17280, 4320, 17280, 4320, 4320, 17280, 34560, 34560, 4320, 4320, 4320, 34560, 34560, 34560, 17280, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 17280, 4320, 34560, 34560, 4320, 34560, 4320, 17280, 17280, 34560, 4320, 4320, 4320, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 4320, 34560, 17280, 17280, 17280, 34560, 17280, 4320, 17280, 34560, 34560, 17280, 34560, 17280, 4320, 34560, 17280, 4320, 17280, 17280, 4320, 17280, 34560, 4320, 17280, 34560, 4320, 17280, 34560, 34560, 17280, 4320, 34560, 17280, 4320, 4320, 17280, 34560, 34560, 34560, 4320, 34560, 4320, 34560, 4320, 17280, 4320, 34560, 34560, 17280, 34560, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 34560, 17280, 34560, 4320, 34560, 17280, 4320, 17280, 4320, 4320, 17280, 17280, 17280, 34560, 17280, 4320, 4320]
Prompts retrieved: 3594240 . Total input tokens: 801481657 . Total output tokens: 706278274
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 99.4213427589275,
    "estimated_duration": 3600.098084681518,
    "input_throughput": 6549.804045710048,
    "output_throughput": 5675.813691561586,
    "total_throughput": 12225.617737271634,
    "itl": 91.12332164007012,
    "ttft": 2056138.5229144725,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 362,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.666857747957126,
    "arrivals": 1197398,
    "finished_requests": 94862,
    "scheduler_time": 242.01984776444974
}
#Debug simulation 
Total elapsed time: 99.42154222819954. Arrivals time: 0.8200101871043444 Scheduler time: 98.31449830112979 Scheduler overhead time: 0.11214404413476586 Adapter cache time: 0.024671060498803854 Engine time: 0.11332804337143898 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.1_size_8-8-8/adapters_192_slots_32_rate_3.2-1.6-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.1_size_8-8-8/adapters_192_slots_32_rate_3.2-1.6-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 17280, 17280, 17280, 17280, 34560, 17280, 1080, 34560, 1080, 17280, 17280, 1080, 34560, 34560, 1080, 17280, 1080, 17280, 1080, 1080, 17280, 1080, 1080, 17280, 17280, 34560, 17280, 1080, 17280, 34560, 34560, 17280, 34560, 1080, 17280, 17280, 34560, 17280, 1080, 1080, 17280, 34560, 1080, 17280, 1080, 34560, 34560, 17280, 34560, 34560, 34560, 1080, 17280, 34560, 1080, 17280, 1080, 17280, 1080, 1080, 17280, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 17280, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 17280, 1080, 34560, 34560, 1080, 34560, 1080, 17280, 17280, 34560, 1080, 1080, 1080, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 1080, 34560, 17280, 17280, 17280, 34560, 17280, 1080, 17280, 34560, 34560, 17280, 34560, 17280, 1080, 34560, 17280, 1080, 17280, 17280, 1080, 17280, 34560, 1080, 17280, 34560, 1080, 17280, 34560, 34560, 17280, 1080, 34560, 17280, 1080, 1080, 17280, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 1080, 17280, 1080, 34560, 34560, 17280, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 34560, 17280, 34560, 1080, 34560, 17280, 1080, 17280, 1080, 1080, 17280, 17280, 17280, 34560, 17280, 1080, 1080]
Prompts retrieved: 3386880 . Total input tokens: 755269785 . Total output tokens: 665596261
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 108.39235567301512,
    "estimated_duration": 3600.0289986842968,
    "input_throughput": 6733.5849263601485,
    "output_throughput": 5886.180641251631,
    "total_throughput": 12619.76556761178,
    "itl": 99.95622089018401,
    "ttft": 2032796.921845609,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 384,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.5391650682687907,
    "arrivals": 1127741,
    "finished_requests": 98679,
    "scheduler_time": 232.51694866975419
}
#Debug simulation 
Total elapsed time: 108.39253729628399. Arrivals time: 1.075410985853523 Scheduler time: 107.04411137802526 Scheduler overhead time: 0.10658992268145084 Adapter cache time: 0.024201473221182823 Engine time: 0.10666284104809165 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.1_size_8-8-16/adapters_192_slots_32_rate_3.2-1.6-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.1_size_8-8-16/adapters_192_slots_32_rate_3.2-1.6-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 17280, 17280, 17280, 17280, 34560, 17280, 1080, 34560, 1080, 17280, 17280, 1080, 34560, 34560, 1080, 17280, 1080, 17280, 1080, 1080, 17280, 1080, 1080, 17280, 17280, 34560, 17280, 1080, 17280, 34560, 34560, 17280, 34560, 1080, 17280, 17280, 34560, 17280, 1080, 1080, 17280, 34560, 1080, 17280, 1080, 34560, 34560, 17280, 34560, 34560, 34560, 1080, 17280, 34560, 1080, 17280, 1080, 17280, 1080, 1080, 17280, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 17280, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 17280, 1080, 34560, 34560, 1080, 34560, 1080, 17280, 17280, 34560, 1080, 1080, 1080, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 1080, 34560, 17280, 17280, 17280, 34560, 17280, 1080, 17280, 34560, 34560, 17280, 34560, 17280, 1080, 34560, 17280, 1080, 17280, 17280, 1080, 17280, 34560, 1080, 17280, 34560, 1080, 17280, 34560, 34560, 17280, 1080, 34560, 17280, 1080, 1080, 17280, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 1080, 17280, 1080, 34560, 34560, 17280, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 34560, 17280, 34560, 1080, 34560, 17280, 1080, 17280, 1080, 1080, 17280, 17280, 17280, 34560, 17280, 1080, 1080]
Prompts retrieved: 3386880 . Total input tokens: 755269785 . Total output tokens: 665596261
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 95.69322925293818,
    "estimated_duration": 3600.0710194308936,
    "input_throughput": 6664.219641920467,
    "output_throughput": 5836.180977152337,
    "total_throughput": 12500.400619072803,
    "itl": 97.72549874493052,
    "ttft": 2037718.5610211473,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 445,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.247593563734558,
    "arrivals": 1127741,
    "finished_requests": 97692,
    "scheduler_time": 234.5506310222596
}
#Debug simulation 
Total elapsed time: 95.69339605234563. Arrivals time: 0.9791730893775821 Scheduler time: 94.4484078232199 Scheduler overhead time: 0.10377341276034713 Adapter cache time: 0.02389850653707981 Engine time: 0.10367296962067485 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.1_size_8-8-32/adapters_192_slots_32_rate_3.2-1.6-0.1_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.1_size_8-8-32/adapters_192_slots_32_rate_3.2-1.6-0.1_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 17280, 17280, 17280, 17280, 34560, 17280, 1080, 34560, 1080, 17280, 17280, 1080, 34560, 34560, 1080, 17280, 1080, 17280, 1080, 1080, 17280, 1080, 1080, 17280, 17280, 34560, 17280, 1080, 17280, 34560, 34560, 17280, 34560, 1080, 17280, 17280, 34560, 17280, 1080, 1080, 17280, 34560, 1080, 17280, 1080, 34560, 34560, 17280, 34560, 34560, 34560, 1080, 17280, 34560, 1080, 17280, 1080, 17280, 1080, 1080, 17280, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 17280, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 17280, 1080, 34560, 34560, 1080, 34560, 1080, 17280, 17280, 34560, 1080, 1080, 1080, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 1080, 34560, 17280, 17280, 17280, 34560, 17280, 1080, 17280, 34560, 34560, 17280, 34560, 17280, 1080, 34560, 17280, 1080, 17280, 17280, 1080, 17280, 34560, 1080, 17280, 34560, 1080, 17280, 34560, 34560, 17280, 1080, 34560, 17280, 1080, 1080, 17280, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 1080, 17280, 1080, 34560, 34560, 17280, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 34560, 17280, 34560, 1080, 34560, 17280, 1080, 17280, 1080, 1080, 17280, 17280, 17280, 34560, 17280, 1080, 1080]
Prompts retrieved: 3386880 . Total input tokens: 755269785 . Total output tokens: 665596261
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 97.53343914914876,
    "estimated_duration": 3600.020724265849,
    "input_throughput": 6488.959866964065,
    "output_throughput": 5674.400667281122,
    "total_throughput": 12163.360534245186,
    "itl": 91.46085748881377,
    "ttft": 2050722.76160336,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 367,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.750318128811213,
    "arrivals": 1127741,
    "finished_requests": 94997,
    "scheduler_time": 242.0437359458587
}
#Debug simulation 
Total elapsed time: 97.5336278011091. Arrivals time: 0.9635223476216197 Scheduler time: 96.29437652975321 Scheduler overhead time: 0.10731214005500078 Adapter cache time: 0.024574873503297567 Engine time: 0.10688992496579885 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.1_size_8-16-16/adapters_192_slots_32_rate_3.2-1.6-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.1_size_8-16-16/adapters_192_slots_32_rate_3.2-1.6-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 17280, 17280, 17280, 17280, 34560, 17280, 1080, 34560, 1080, 17280, 17280, 1080, 34560, 34560, 1080, 17280, 1080, 17280, 1080, 1080, 17280, 1080, 1080, 17280, 17280, 34560, 17280, 1080, 17280, 34560, 34560, 17280, 34560, 1080, 17280, 17280, 34560, 17280, 1080, 1080, 17280, 34560, 1080, 17280, 1080, 34560, 34560, 17280, 34560, 34560, 34560, 1080, 17280, 34560, 1080, 17280, 1080, 17280, 1080, 1080, 17280, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 17280, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 17280, 1080, 34560, 34560, 1080, 34560, 1080, 17280, 17280, 34560, 1080, 1080, 1080, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 1080, 34560, 17280, 17280, 17280, 34560, 17280, 1080, 17280, 34560, 34560, 17280, 34560, 17280, 1080, 34560, 17280, 1080, 17280, 17280, 1080, 17280, 34560, 1080, 17280, 34560, 1080, 17280, 34560, 34560, 17280, 1080, 34560, 17280, 1080, 1080, 17280, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 1080, 17280, 1080, 34560, 34560, 17280, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 34560, 17280, 34560, 1080, 34560, 17280, 1080, 17280, 1080, 1080, 17280, 17280, 17280, 34560, 17280, 1080, 1080]
Prompts retrieved: 3386880 . Total input tokens: 755269785 . Total output tokens: 665596261
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 103.15317316679284,
    "estimated_duration": 3600.078853600894,
    "input_throughput": 6666.177041093365,
    "output_throughput": 5837.943515869988,
    "total_throughput": 12504.120556963353,
    "itl": 97.82514110536916,
    "ttft": 2034581.2153901588,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 419,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.860884484522972,
    "arrivals": 1127741,
    "finished_requests": 97733,
    "scheduler_time": 234.6619204308895
}
#Debug simulation 
Total elapsed time: 103.15333649376407. Arrivals time: 1.0152203906327486 Scheduler time: 101.85705997841433 Scheduler overhead time: 0.10994150396436453 Adapter cache time: 0.02500926936045289 Engine time: 0.10928610991686583 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.1_size_8-16-32/adapters_192_slots_32_rate_3.2-1.6-0.1_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.1_size_8-16-32/adapters_192_slots_32_rate_3.2-1.6-0.1_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 17280, 17280, 17280, 17280, 34560, 17280, 1080, 34560, 1080, 17280, 17280, 1080, 34560, 34560, 1080, 17280, 1080, 17280, 1080, 1080, 17280, 1080, 1080, 17280, 17280, 34560, 17280, 1080, 17280, 34560, 34560, 17280, 34560, 1080, 17280, 17280, 34560, 17280, 1080, 1080, 17280, 34560, 1080, 17280, 1080, 34560, 34560, 17280, 34560, 34560, 34560, 1080, 17280, 34560, 1080, 17280, 1080, 17280, 1080, 1080, 17280, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 17280, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 17280, 1080, 34560, 34560, 1080, 34560, 1080, 17280, 17280, 34560, 1080, 1080, 1080, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 1080, 34560, 17280, 17280, 17280, 34560, 17280, 1080, 17280, 34560, 34560, 17280, 34560, 17280, 1080, 34560, 17280, 1080, 17280, 17280, 1080, 17280, 34560, 1080, 17280, 34560, 1080, 17280, 34560, 34560, 17280, 1080, 34560, 17280, 1080, 1080, 17280, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 1080, 17280, 1080, 34560, 34560, 17280, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 34560, 17280, 34560, 1080, 34560, 17280, 1080, 17280, 1080, 1080, 17280, 17280, 17280, 34560, 17280, 1080, 1080]
Prompts retrieved: 3386880 . Total input tokens: 755269785 . Total output tokens: 665596261
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 96.09715823223814,
    "estimated_duration": 3600.096679902512,
    "input_throughput": 6498.967411240071,
    "output_throughput": 5680.900769740945,
    "total_throughput": 12179.868180981015,
    "itl": 91.57651701936909,
    "ttft": 2051438.8479634367,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 398,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.962048511831111,
    "arrivals": 1127741,
    "finished_requests": 95084,
    "scheduler_time": 241.65756065821705
}
#Debug simulation 
Total elapsed time: 96.09733968600631. Arrivals time: 0.9550147806294262 Scheduler time: 94.8707146588713 Scheduler overhead time: 0.10558923939242959 Adapter cache time: 0.02398928999900818 Engine time: 0.10574884572997689 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.1_size_16-16-16/adapters_192_slots_32_rate_3.2-1.6-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.1_size_16-16-16/adapters_192_slots_32_rate_3.2-1.6-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 17280, 17280, 17280, 17280, 34560, 17280, 1080, 34560, 1080, 17280, 17280, 1080, 34560, 34560, 1080, 17280, 1080, 17280, 1080, 1080, 17280, 1080, 1080, 17280, 17280, 34560, 17280, 1080, 17280, 34560, 34560, 17280, 34560, 1080, 17280, 17280, 34560, 17280, 1080, 1080, 17280, 34560, 1080, 17280, 1080, 34560, 34560, 17280, 34560, 34560, 34560, 1080, 17280, 34560, 1080, 17280, 1080, 17280, 1080, 1080, 17280, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 17280, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 17280, 1080, 34560, 34560, 1080, 34560, 1080, 17280, 17280, 34560, 1080, 1080, 1080, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 1080, 34560, 17280, 17280, 17280, 34560, 17280, 1080, 17280, 34560, 34560, 17280, 34560, 17280, 1080, 34560, 17280, 1080, 17280, 17280, 1080, 17280, 34560, 1080, 17280, 34560, 1080, 17280, 34560, 34560, 17280, 1080, 34560, 17280, 1080, 1080, 17280, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 1080, 17280, 1080, 34560, 34560, 17280, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 34560, 17280, 34560, 1080, 34560, 17280, 1080, 17280, 1080, 1080, 17280, 17280, 17280, 34560, 17280, 1080, 1080]
Prompts retrieved: 3386880 . Total input tokens: 755269785 . Total output tokens: 665596261
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 104.19044559681788,
    "estimated_duration": 3600.086462631953,
    "input_throughput": 6666.844324192475,
    "output_throughput": 5832.3635329162325,
    "total_throughput": 12499.207857108708,
    "itl": 97.62135543869216,
    "ttft": 2033972.5190961552,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 407,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.598255822812196,
    "arrivals": 1127741,
    "finished_requests": 97703,
    "scheduler_time": 234.80250428121192
}
#Debug simulation 
Total elapsed time: 104.19060646509752. Arrivals time: 0.8521012561395764 Scheduler time: 103.06058941828087 Scheduler overhead time: 0.10731575405225158 Adapter cache time: 0.025466847699135542 Engine time: 0.10867835627868772 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.1_size_16-16-32/adapters_192_slots_32_rate_3.2-1.6-0.1_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.1_size_16-16-32/adapters_192_slots_32_rate_3.2-1.6-0.1_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 17280, 17280, 17280, 17280, 34560, 17280, 1080, 34560, 1080, 17280, 17280, 1080, 34560, 34560, 1080, 17280, 1080, 17280, 1080, 1080, 17280, 1080, 1080, 17280, 17280, 34560, 17280, 1080, 17280, 34560, 34560, 17280, 34560, 1080, 17280, 17280, 34560, 17280, 1080, 1080, 17280, 34560, 1080, 17280, 1080, 34560, 34560, 17280, 34560, 34560, 34560, 1080, 17280, 34560, 1080, 17280, 1080, 17280, 1080, 1080, 17280, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 17280, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 17280, 1080, 34560, 34560, 1080, 34560, 1080, 17280, 17280, 34560, 1080, 1080, 1080, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 1080, 34560, 17280, 17280, 17280, 34560, 17280, 1080, 17280, 34560, 34560, 17280, 34560, 17280, 1080, 34560, 17280, 1080, 17280, 17280, 1080, 17280, 34560, 1080, 17280, 34560, 1080, 17280, 34560, 34560, 17280, 1080, 34560, 17280, 1080, 1080, 17280, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 1080, 17280, 1080, 34560, 34560, 17280, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 34560, 17280, 34560, 1080, 34560, 17280, 1080, 17280, 1080, 1080, 17280, 17280, 17280, 34560, 17280, 1080, 1080]
Prompts retrieved: 3386880 . Total input tokens: 755269785 . Total output tokens: 665596261
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 93.66867815889418,
    "estimated_duration": 3600.006899841378,
    "input_throughput": 6509.159191065021,
    "output_throughput": 5697.026580950073,
    "total_throughput": 12206.185772015095,
    "itl": 91.66258167361255,
    "ttft": 2048092.9296535943,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 407,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.9954320601187856,
    "arrivals": 1127741,
    "finished_requests": 95380,
    "scheduler_time": 241.31632750295861
}
#Debug simulation 
Total elapsed time: 93.66885496396571. Arrivals time: 0.8978800708428025 Scheduler time: 92.49916527140886 Scheduler overhead time: 0.10560117661952972 Adapter cache time: 0.023849327582865953 Engine time: 0.1049628765322268 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.05_size_8-8-8/adapters_192_slots_32_rate_3.2-1.6-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.05_size_8-8-8/adapters_192_slots_32_rate_3.2-1.6-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [64 64 64]
Adapter prompts. [34560, 540, 34560, 540, 34560, 540, 34560, 540, 540, 540, 17280, 17280, 17280, 17280, 34560, 17280, 540, 34560, 540, 17280, 17280, 540, 34560, 34560, 540, 17280, 540, 17280, 540, 540, 17280, 540, 540, 17280, 17280, 34560, 17280, 540, 17280, 34560, 34560, 17280, 34560, 540, 17280, 17280, 34560, 17280, 540, 540, 17280, 34560, 540, 17280, 540, 34560, 34560, 17280, 34560, 34560, 34560, 540, 17280, 34560, 540, 17280, 540, 17280, 540, 540, 17280, 34560, 34560, 540, 540, 540, 34560, 34560, 34560, 17280, 540, 540, 540, 540, 540, 34560, 540, 17280, 540, 34560, 34560, 540, 34560, 540, 17280, 17280, 34560, 540, 540, 540, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 540, 34560, 17280, 17280, 17280, 34560, 17280, 540, 17280, 34560, 34560, 17280, 34560, 17280, 540, 34560, 17280, 540, 17280, 17280, 540, 17280, 34560, 540, 17280, 34560, 540, 17280, 34560, 34560, 17280, 540, 34560, 17280, 540, 540, 17280, 34560, 34560, 34560, 540, 34560, 540, 34560, 540, 17280, 540, 34560, 34560, 17280, 34560, 540, 34560, 34560, 34560, 540, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 540, 34560, 17280, 34560, 540, 34560, 17280, 540, 17280, 540, 540, 17280, 17280, 17280, 34560, 17280, 540, 540]
Prompts retrieved: 3352320 . Total input tokens: 747459949 . Total output tokens: 658822510
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 103.13433038210496,
    "estimated_duration": 3600.0220778489133,
    "input_throughput": 6796.435263702528,
    "output_throughput": 5897.683831063177,
    "total_throughput": 12694.119094765705,
    "itl": 100.12079057418921,
    "ttft": 2028371.3326714686,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 453,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.995421291473351,
    "arrivals": 1116016,
    "finished_requests": 98872,
    "scheduler_time": 231.77952481403696
}
#Debug simulation 
Total elapsed time: 103.13451828528196. Arrivals time: 0.8444657362997532 Scheduler time: 102.02140221418813 Scheduler overhead time: 0.1043579657562077 Adapter cache time: 0.024916306603699923 Engine time: 0.1044884747825563 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.05_size_8-8-16/adapters_192_slots_32_rate_3.2-1.6-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.05_size_8-8-16/adapters_192_slots_32_rate_3.2-1.6-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [64 64 64]
Adapter prompts. [34560, 540, 34560, 540, 34560, 540, 34560, 540, 540, 540, 17280, 17280, 17280, 17280, 34560, 17280, 540, 34560, 540, 17280, 17280, 540, 34560, 34560, 540, 17280, 540, 17280, 540, 540, 17280, 540, 540, 17280, 17280, 34560, 17280, 540, 17280, 34560, 34560, 17280, 34560, 540, 17280, 17280, 34560, 17280, 540, 540, 17280, 34560, 540, 17280, 540, 34560, 34560, 17280, 34560, 34560, 34560, 540, 17280, 34560, 540, 17280, 540, 17280, 540, 540, 17280, 34560, 34560, 540, 540, 540, 34560, 34560, 34560, 17280, 540, 540, 540, 540, 540, 34560, 540, 17280, 540, 34560, 34560, 540, 34560, 540, 17280, 17280, 34560, 540, 540, 540, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 540, 34560, 17280, 17280, 17280, 34560, 17280, 540, 17280, 34560, 34560, 17280, 34560, 17280, 540, 34560, 17280, 540, 17280, 17280, 540, 17280, 34560, 540, 17280, 34560, 540, 17280, 34560, 34560, 17280, 540, 34560, 17280, 540, 540, 17280, 34560, 34560, 34560, 540, 34560, 540, 34560, 540, 17280, 540, 34560, 34560, 17280, 34560, 540, 34560, 34560, 34560, 540, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 540, 34560, 17280, 34560, 540, 34560, 17280, 540, 17280, 540, 540, 17280, 17280, 17280, 34560, 17280, 540, 540]
Prompts retrieved: 3352320 . Total input tokens: 747459949 . Total output tokens: 658822510
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 97.73167018499225,
    "estimated_duration": 3600.0683775160405,
    "input_throughput": 6716.782978628928,
    "output_throughput": 5822.774681425228,
    "total_throughput": 12539.557660054155,
    "itl": 97.46853465729158,
    "ttft": 2034289.5344836095,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 478,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.4915802581328945,
    "arrivals": 1116016,
    "finished_requests": 97759,
    "scheduler_time": 235.21591491448095
}
#Debug simulation 
Total elapsed time: 97.73193247010931. Arrivals time: 0.8651050012558699 Scheduler time: 96.592738494277 Scheduler overhead time: 0.10578413959592581 Adapter cache time: 0.025555466301739216 Engine time: 0.10690646478906274 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.05_size_8-8-32/adapters_192_slots_32_rate_3.2-1.6-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.05_size_8-8-32/adapters_192_slots_32_rate_3.2-1.6-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [64 64 64]
Adapter prompts. [34560, 540, 34560, 540, 34560, 540, 34560, 540, 540, 540, 17280, 17280, 17280, 17280, 34560, 17280, 540, 34560, 540, 17280, 17280, 540, 34560, 34560, 540, 17280, 540, 17280, 540, 540, 17280, 540, 540, 17280, 17280, 34560, 17280, 540, 17280, 34560, 34560, 17280, 34560, 540, 17280, 17280, 34560, 17280, 540, 540, 17280, 34560, 540, 17280, 540, 34560, 34560, 17280, 34560, 34560, 34560, 540, 17280, 34560, 540, 17280, 540, 17280, 540, 540, 17280, 34560, 34560, 540, 540, 540, 34560, 34560, 34560, 17280, 540, 540, 540, 540, 540, 34560, 540, 17280, 540, 34560, 34560, 540, 34560, 540, 17280, 17280, 34560, 540, 540, 540, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 540, 34560, 17280, 17280, 17280, 34560, 17280, 540, 17280, 34560, 34560, 17280, 34560, 17280, 540, 34560, 17280, 540, 17280, 17280, 540, 17280, 34560, 540, 17280, 34560, 540, 17280, 34560, 34560, 17280, 540, 34560, 17280, 540, 540, 17280, 34560, 34560, 34560, 540, 34560, 540, 34560, 540, 17280, 540, 34560, 34560, 17280, 34560, 540, 34560, 34560, 34560, 540, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 540, 34560, 17280, 34560, 540, 34560, 17280, 540, 17280, 540, 540, 17280, 17280, 17280, 34560, 17280, 540, 540]
Prompts retrieved: 3352320 . Total input tokens: 747459949 . Total output tokens: 658822510
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 89.19280612282455,
    "estimated_duration": 3600.065237699658,
    "input_throughput": 6576.806373411417,
    "output_throughput": 5703.49914356552,
    "total_throughput": 12280.305516976938,
    "itl": 91.78689240463012,
    "ttft": 2049337.1837257496,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 489,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.6689556310093345,
    "arrivals": 1116016,
    "finished_requests": 95763,
    "scheduler_time": 240.49165056839732
}
#Debug simulation 
Total elapsed time: 89.19297950575128. Arrivals time: 0.7960467408411205 Scheduler time: 88.12566583650187 Scheduler overhead time: 0.10493377782404423 Adapter cache time: 0.024641502648591995 Engine time: 0.10594013566151261 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.05_size_8-16-16/adapters_192_slots_32_rate_3.2-1.6-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.05_size_8-16-16/adapters_192_slots_32_rate_3.2-1.6-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [64 64 64]
Adapter prompts. [34560, 540, 34560, 540, 34560, 540, 34560, 540, 540, 540, 17280, 17280, 17280, 17280, 34560, 17280, 540, 34560, 540, 17280, 17280, 540, 34560, 34560, 540, 17280, 540, 17280, 540, 540, 17280, 540, 540, 17280, 17280, 34560, 17280, 540, 17280, 34560, 34560, 17280, 34560, 540, 17280, 17280, 34560, 17280, 540, 540, 17280, 34560, 540, 17280, 540, 34560, 34560, 17280, 34560, 34560, 34560, 540, 17280, 34560, 540, 17280, 540, 17280, 540, 540, 17280, 34560, 34560, 540, 540, 540, 34560, 34560, 34560, 17280, 540, 540, 540, 540, 540, 34560, 540, 17280, 540, 34560, 34560, 540, 34560, 540, 17280, 17280, 34560, 540, 540, 540, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 540, 34560, 17280, 17280, 17280, 34560, 17280, 540, 17280, 34560, 34560, 17280, 34560, 17280, 540, 34560, 17280, 540, 17280, 17280, 540, 17280, 34560, 540, 17280, 34560, 540, 17280, 34560, 34560, 17280, 540, 34560, 17280, 540, 540, 17280, 34560, 34560, 34560, 540, 34560, 540, 34560, 540, 17280, 540, 34560, 34560, 17280, 34560, 540, 34560, 34560, 34560, 540, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 540, 34560, 17280, 34560, 540, 34560, 17280, 540, 17280, 540, 540, 17280, 17280, 17280, 34560, 17280, 540, 540]
Prompts retrieved: 3352320 . Total input tokens: 747459949 . Total output tokens: 658822510
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 100.57047239225358,
    "estimated_duration": 3600.0269366465905,
    "input_throughput": 6703.470119720682,
    "output_throughput": 5815.015656382874,
    "total_throughput": 12518.485776103556,
    "itl": 97.26942088464251,
    "ttft": 2031160.5266272132,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 441,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.0249305017618426,
    "arrivals": 1116016,
    "finished_requests": 97505,
    "scheduler_time": 235.51505041751892
}
#Debug simulation 
Total elapsed time: 100.57065818784758. Arrivals time: 0.8378453608602285 Scheduler time: 99.45542471902445 Scheduler overhead time: 0.10766644636169076 Adapter cache time: 0.02493062475696206 Engine time: 0.10822222288697958 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.05_size_8-16-32/adapters_192_slots_32_rate_3.2-1.6-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.05_size_8-16-32/adapters_192_slots_32_rate_3.2-1.6-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [64 64 64]
Adapter prompts. [34560, 540, 34560, 540, 34560, 540, 34560, 540, 540, 540, 17280, 17280, 17280, 17280, 34560, 17280, 540, 34560, 540, 17280, 17280, 540, 34560, 34560, 540, 17280, 540, 17280, 540, 540, 17280, 540, 540, 17280, 17280, 34560, 17280, 540, 17280, 34560, 34560, 17280, 34560, 540, 17280, 17280, 34560, 17280, 540, 540, 17280, 34560, 540, 17280, 540, 34560, 34560, 17280, 34560, 34560, 34560, 540, 17280, 34560, 540, 17280, 540, 17280, 540, 540, 17280, 34560, 34560, 540, 540, 540, 34560, 34560, 34560, 17280, 540, 540, 540, 540, 540, 34560, 540, 17280, 540, 34560, 34560, 540, 34560, 540, 17280, 17280, 34560, 540, 540, 540, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 540, 34560, 17280, 17280, 17280, 34560, 17280, 540, 17280, 34560, 34560, 17280, 34560, 17280, 540, 34560, 17280, 540, 17280, 17280, 540, 17280, 34560, 540, 17280, 34560, 540, 17280, 34560, 34560, 17280, 540, 34560, 17280, 540, 540, 17280, 34560, 34560, 34560, 540, 34560, 540, 34560, 540, 17280, 540, 34560, 34560, 17280, 34560, 540, 34560, 34560, 34560, 540, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 540, 34560, 17280, 34560, 540, 34560, 17280, 540, 17280, 540, 540, 17280, 17280, 17280, 34560, 17280, 540, 540]
Prompts retrieved: 3352320 . Total input tokens: 747459949 . Total output tokens: 658822510
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 97.06637677177787,
    "estimated_duration": 3600.0578047667764,
    "input_throughput": 6572.000307515269,
    "output_throughput": 5692.754981007224,
    "total_throughput": 12264.755288522494,
    "itl": 91.52864888842807,
    "ttft": 2048333.8581829048,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 460,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.4209771078033633,
    "arrivals": 1116016,
    "finished_requests": 95491,
    "scheduler_time": 241.10674598678114
}
#Debug simulation 
Total elapsed time: 97.06654752790928. Arrivals time: 0.8125835815444589 Scheduler time: 95.9763975883834 Scheduler overhead time: 0.10667210584506392 Adapter cache time: 0.02492384146898985 Engine time: 0.1088978131301701 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.05_size_16-16-16/adapters_192_slots_32_rate_3.2-1.6-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.05_size_16-16-16/adapters_192_slots_32_rate_3.2-1.6-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [64 64 64]
Adapter prompts. [34560, 540, 34560, 540, 34560, 540, 34560, 540, 540, 540, 17280, 17280, 17280, 17280, 34560, 17280, 540, 34560, 540, 17280, 17280, 540, 34560, 34560, 540, 17280, 540, 17280, 540, 540, 17280, 540, 540, 17280, 17280, 34560, 17280, 540, 17280, 34560, 34560, 17280, 34560, 540, 17280, 17280, 34560, 17280, 540, 540, 17280, 34560, 540, 17280, 540, 34560, 34560, 17280, 34560, 34560, 34560, 540, 17280, 34560, 540, 17280, 540, 17280, 540, 540, 17280, 34560, 34560, 540, 540, 540, 34560, 34560, 34560, 17280, 540, 540, 540, 540, 540, 34560, 540, 17280, 540, 34560, 34560, 540, 34560, 540, 17280, 17280, 34560, 540, 540, 540, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 540, 34560, 17280, 17280, 17280, 34560, 17280, 540, 17280, 34560, 34560, 17280, 34560, 17280, 540, 34560, 17280, 540, 17280, 17280, 540, 17280, 34560, 540, 17280, 34560, 540, 17280, 34560, 34560, 17280, 540, 34560, 17280, 540, 540, 17280, 34560, 34560, 34560, 540, 34560, 540, 34560, 540, 17280, 540, 34560, 34560, 17280, 34560, 540, 34560, 34560, 34560, 540, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 540, 34560, 17280, 34560, 540, 34560, 17280, 540, 17280, 540, 540, 17280, 17280, 17280, 34560, 17280, 540, 540]
Prompts retrieved: 3352320 . Total input tokens: 747459949 . Total output tokens: 658822510
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 101.09185654297471,
    "estimated_duration": 3600.0151334522106,
    "input_throughput": 6736.973346204395,
    "output_throughput": 5829.289106314413,
    "total_throughput": 12566.262452518808,
    "itl": 97.11879948415141,
    "ttft": 2034140.8767441362,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 381,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.432273878357363,
    "arrivals": 1116016,
    "finished_requests": 98006,
    "scheduler_time": 234.96673792319004
}
#Debug simulation 
Total elapsed time: 101.09205744508654. Arrivals time: 0.8186031659133732 Scheduler time: 99.99776095850393 Scheduler overhead time: 0.10766817536205053 Adapter cache time: 0.024274035822600126 Engine time: 0.10740779899060726 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.05_size_16-16-32/adapters_192_slots_32_rate_3.2-1.6-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.05_size_16-16-32/adapters_192_slots_32_rate_3.2-1.6-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [64 64 64]
Adapter prompts. [34560, 540, 34560, 540, 34560, 540, 34560, 540, 540, 540, 17280, 17280, 17280, 17280, 34560, 17280, 540, 34560, 540, 17280, 17280, 540, 34560, 34560, 540, 17280, 540, 17280, 540, 540, 17280, 540, 540, 17280, 17280, 34560, 17280, 540, 17280, 34560, 34560, 17280, 34560, 540, 17280, 17280, 34560, 17280, 540, 540, 17280, 34560, 540, 17280, 540, 34560, 34560, 17280, 34560, 34560, 34560, 540, 17280, 34560, 540, 17280, 540, 17280, 540, 540, 17280, 34560, 34560, 540, 540, 540, 34560, 34560, 34560, 17280, 540, 540, 540, 540, 540, 34560, 540, 17280, 540, 34560, 34560, 540, 34560, 540, 17280, 17280, 34560, 540, 540, 540, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 540, 34560, 17280, 17280, 17280, 34560, 17280, 540, 17280, 34560, 34560, 17280, 34560, 17280, 540, 34560, 17280, 540, 17280, 17280, 540, 17280, 34560, 540, 17280, 34560, 540, 17280, 34560, 34560, 17280, 540, 34560, 17280, 540, 540, 17280, 34560, 34560, 34560, 540, 34560, 540, 34560, 540, 17280, 540, 34560, 34560, 17280, 34560, 540, 34560, 34560, 34560, 540, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 540, 34560, 17280, 34560, 540, 34560, 17280, 540, 17280, 540, 540, 17280, 17280, 17280, 34560, 17280, 540, 540]
Prompts retrieved: 3352320 . Total input tokens: 747459949 . Total output tokens: 658822510
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 101.29373298306018,
    "estimated_duration": 3600.07285130341,
    "input_throughput": 6564.456880766683,
    "output_throughput": 5693.716723698731,
    "total_throughput": 12258.173604465414,
    "itl": 91.5490833480808,
    "ttft": 2048075.1718465963,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 400,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.9403493667394116,
    "arrivals": 1116016,
    "finished_requests": 95510,
    "scheduler_time": 241.08177138494221
}
#Debug simulation 
Total elapsed time: 101.29392264597118. Arrivals time: 0.8334404886700213 Scheduler time: 100.17642268212512 Scheduler overhead time: 0.1100323679856956 Adapter cache time: 0.025286072865128517 Engine time: 0.11106057185679674 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.025_size_8-8-8/adapters_192_slots_32_rate_3.2-1.6-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.025_size_8-8-8/adapters_192_slots_32_rate_3.2-1.6-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [64 64 64]
Adapter prompts. [34560, 270, 34560, 270, 34560, 270, 34560, 270, 270, 270, 17280, 17280, 17280, 17280, 34560, 17280, 270, 34560, 270, 17280, 17280, 270, 34560, 34560, 270, 17280, 270, 17280, 270, 270, 17280, 270, 270, 17280, 17280, 34560, 17280, 270, 17280, 34560, 34560, 17280, 34560, 270, 17280, 17280, 34560, 17280, 270, 270, 17280, 34560, 270, 17280, 270, 34560, 34560, 17280, 34560, 34560, 34560, 270, 17280, 34560, 270, 17280, 270, 17280, 270, 270, 17280, 34560, 34560, 270, 270, 270, 34560, 34560, 34560, 17280, 270, 270, 270, 270, 270, 34560, 270, 17280, 270, 34560, 34560, 270, 34560, 270, 17280, 17280, 34560, 270, 270, 270, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 270, 34560, 17280, 17280, 17280, 34560, 17280, 270, 17280, 34560, 34560, 17280, 34560, 17280, 270, 34560, 17280, 270, 17280, 17280, 270, 17280, 34560, 270, 17280, 34560, 270, 17280, 34560, 34560, 17280, 270, 34560, 17280, 270, 270, 17280, 34560, 34560, 34560, 270, 34560, 270, 34560, 270, 17280, 270, 34560, 34560, 17280, 34560, 270, 34560, 34560, 34560, 270, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 270, 34560, 17280, 34560, 270, 34560, 17280, 270, 17280, 270, 270, 17280, 17280, 17280, 34560, 17280, 270, 270]
Prompts retrieved: 3335040 . Total input tokens: 743590138 . Total output tokens: 655449743
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 103.04004652705044,
    "estimated_duration": 3600.068691094807,
    "input_throughput": 6766.856438117462,
    "output_throughput": 5884.562995257054,
    "total_throughput": 12651.419433374516,
    "itl": 100.28634460899973,
    "ttft": 2030949.2584921191,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 325,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.149032935383732,
    "arrivals": 1110264,
    "finished_requests": 98653,
    "scheduler_time": 232.5611419819174
}
#Debug simulation 
Total elapsed time: 103.04022898897529. Arrivals time: 0.8402866213582456 Scheduler time: 101.92615979071707 Scheduler overhead time: 0.10703947860747576 Adapter cache time: 0.024168818723410368 Engine time: 0.10689561674371362 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.025_size_8-8-16/adapters_192_slots_32_rate_3.2-1.6-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.025_size_8-8-16/adapters_192_slots_32_rate_3.2-1.6-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [64 64 64]
Adapter prompts. [34560, 270, 34560, 270, 34560, 270, 34560, 270, 270, 270, 17280, 17280, 17280, 17280, 34560, 17280, 270, 34560, 270, 17280, 17280, 270, 34560, 34560, 270, 17280, 270, 17280, 270, 270, 17280, 270, 270, 17280, 17280, 34560, 17280, 270, 17280, 34560, 34560, 17280, 34560, 270, 17280, 17280, 34560, 17280, 270, 270, 17280, 34560, 270, 17280, 270, 34560, 34560, 17280, 34560, 34560, 34560, 270, 17280, 34560, 270, 17280, 270, 17280, 270, 270, 17280, 34560, 34560, 270, 270, 270, 34560, 34560, 34560, 17280, 270, 270, 270, 270, 270, 34560, 270, 17280, 270, 34560, 34560, 270, 34560, 270, 17280, 17280, 34560, 270, 270, 270, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 270, 34560, 17280, 17280, 17280, 34560, 17280, 270, 17280, 34560, 34560, 17280, 34560, 17280, 270, 34560, 17280, 270, 17280, 17280, 270, 17280, 34560, 270, 17280, 34560, 270, 17280, 34560, 34560, 17280, 270, 34560, 17280, 270, 270, 17280, 34560, 34560, 34560, 270, 34560, 270, 34560, 270, 17280, 270, 34560, 34560, 17280, 34560, 270, 34560, 34560, 34560, 270, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 270, 34560, 17280, 34560, 270, 34560, 17280, 270, 17280, 270, 270, 17280, 17280, 17280, 34560, 17280, 270, 270]
Prompts retrieved: 3335040 . Total input tokens: 743590138 . Total output tokens: 655449743
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 96.51621600892395,
    "estimated_duration": 3600.0911493108633,
    "input_throughput": 6748.5024662918995,
    "output_throughput": 5860.2805109638775,
    "total_throughput": 12608.782977255778,
    "itl": 98.37525869483243,
    "ttft": 2034666.6387416164,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 371,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.716878133253198,
    "arrivals": 1110264,
    "finished_requests": 98329,
    "scheduler_time": 233.5033621663823
}
#Debug simulation 
Total elapsed time: 96.51639135600999. Arrivals time: 0.987876848783344 Scheduler time: 95.26285385712981 Scheduler overhead time: 0.1043300568126142 Adapter cache time: 0.023528017103672028 Engine time: 0.10372089315205812 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.025_size_8-8-32/adapters_192_slots_32_rate_3.2-1.6-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.025_size_8-8-32/adapters_192_slots_32_rate_3.2-1.6-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [64 64 64]
Adapter prompts. [34560, 270, 34560, 270, 34560, 270, 34560, 270, 270, 270, 17280, 17280, 17280, 17280, 34560, 17280, 270, 34560, 270, 17280, 17280, 270, 34560, 34560, 270, 17280, 270, 17280, 270, 270, 17280, 270, 270, 17280, 17280, 34560, 17280, 270, 17280, 34560, 34560, 17280, 34560, 270, 17280, 17280, 34560, 17280, 270, 270, 17280, 34560, 270, 17280, 270, 34560, 34560, 17280, 34560, 34560, 34560, 270, 17280, 34560, 270, 17280, 270, 17280, 270, 270, 17280, 34560, 34560, 270, 270, 270, 34560, 34560, 34560, 17280, 270, 270, 270, 270, 270, 34560, 270, 17280, 270, 34560, 34560, 270, 34560, 270, 17280, 17280, 34560, 270, 270, 270, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 270, 34560, 17280, 17280, 17280, 34560, 17280, 270, 17280, 34560, 34560, 17280, 34560, 17280, 270, 34560, 17280, 270, 17280, 17280, 270, 17280, 34560, 270, 17280, 34560, 270, 17280, 34560, 34560, 17280, 270, 34560, 17280, 270, 270, 17280, 34560, 34560, 34560, 270, 34560, 270, 34560, 270, 17280, 270, 34560, 34560, 17280, 34560, 270, 34560, 34560, 34560, 270, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 270, 34560, 17280, 34560, 270, 34560, 17280, 270, 17280, 270, 270, 17280, 17280, 17280, 34560, 17280, 270, 270]
Prompts retrieved: 3335040 . Total input tokens: 743590138 . Total output tokens: 655449743
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 90.37393201794475,
    "estimated_duration": 3600.099981561613,
    "input_throughput": 6555.897925302126,
    "output_throughput": 5698.862560783821,
    "total_throughput": 12254.760486085946,
    "itl": 92.15614493866522,
    "ttft": 2046811.027298639,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 406,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.039652894465275,
    "arrivals": 1110264,
    "finished_requests": 95552,
    "scheduler_time": 240.81635095501554
}
#Debug simulation 
Total elapsed time: 90.37417450593784. Arrivals time: 0.986368587706238 Scheduler time: 89.11778325168416 Scheduler overhead time: 0.10508684813976288 Adapter cache time: 0.023662397172302008 Engine time: 0.10538135701790452 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.025_size_8-16-16/adapters_192_slots_32_rate_3.2-1.6-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.025_size_8-16-16/adapters_192_slots_32_rate_3.2-1.6-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [64 64 64]
Adapter prompts. [34560, 270, 34560, 270, 34560, 270, 34560, 270, 270, 270, 17280, 17280, 17280, 17280, 34560, 17280, 270, 34560, 270, 17280, 17280, 270, 34560, 34560, 270, 17280, 270, 17280, 270, 270, 17280, 270, 270, 17280, 17280, 34560, 17280, 270, 17280, 34560, 34560, 17280, 34560, 270, 17280, 17280, 34560, 17280, 270, 270, 17280, 34560, 270, 17280, 270, 34560, 34560, 17280, 34560, 34560, 34560, 270, 17280, 34560, 270, 17280, 270, 17280, 270, 270, 17280, 34560, 34560, 270, 270, 270, 34560, 34560, 34560, 17280, 270, 270, 270, 270, 270, 34560, 270, 17280, 270, 34560, 34560, 270, 34560, 270, 17280, 17280, 34560, 270, 270, 270, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 270, 34560, 17280, 17280, 17280, 34560, 17280, 270, 17280, 34560, 34560, 17280, 34560, 17280, 270, 34560, 17280, 270, 17280, 17280, 270, 17280, 34560, 270, 17280, 34560, 270, 17280, 34560, 34560, 17280, 270, 34560, 17280, 270, 270, 17280, 34560, 34560, 34560, 270, 34560, 270, 34560, 270, 17280, 270, 34560, 34560, 17280, 34560, 270, 34560, 34560, 34560, 270, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 270, 34560, 17280, 34560, 270, 34560, 17280, 270, 17280, 270, 270, 17280, 17280, 17280, 34560, 17280, 270, 270]
Prompts retrieved: 3335040 . Total input tokens: 743590138 . Total output tokens: 655449743
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 101.65254999091849,
    "estimated_duration": 3600.0132850061254,
    "input_throughput": 6684.9272751945,
    "output_throughput": 5809.301617609007,
    "total_throughput": 12494.228892803507,
    "itl": 97.56580594001481,
    "ttft": 2037411.3539713854,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 316,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.16030577747151,
    "arrivals": 1110264,
    "finished_requests": 97434,
    "scheduler_time": 235.96969090087364
}
#Debug simulation 
Total elapsed time: 101.65273798722774. Arrivals time: 1.0594532694667578 Scheduler time: 100.3191422089003 Scheduler overhead time: 0.10698034474626184 Adapter cache time: 0.02414388721808791 Engine time: 0.10741965798661113 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.025_size_8-16-32/adapters_192_slots_32_rate_3.2-1.6-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.025_size_8-16-32/adapters_192_slots_32_rate_3.2-1.6-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [64 64 64]
Adapter prompts. [34560, 270, 34560, 270, 34560, 270, 34560, 270, 270, 270, 17280, 17280, 17280, 17280, 34560, 17280, 270, 34560, 270, 17280, 17280, 270, 34560, 34560, 270, 17280, 270, 17280, 270, 270, 17280, 270, 270, 17280, 17280, 34560, 17280, 270, 17280, 34560, 34560, 17280, 34560, 270, 17280, 17280, 34560, 17280, 270, 270, 17280, 34560, 270, 17280, 270, 34560, 34560, 17280, 34560, 34560, 34560, 270, 17280, 34560, 270, 17280, 270, 17280, 270, 270, 17280, 34560, 34560, 270, 270, 270, 34560, 34560, 34560, 17280, 270, 270, 270, 270, 270, 34560, 270, 17280, 270, 34560, 34560, 270, 34560, 270, 17280, 17280, 34560, 270, 270, 270, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 270, 34560, 17280, 17280, 17280, 34560, 17280, 270, 17280, 34560, 34560, 17280, 34560, 17280, 270, 34560, 17280, 270, 17280, 17280, 270, 17280, 34560, 270, 17280, 34560, 270, 17280, 34560, 34560, 17280, 270, 34560, 17280, 270, 270, 17280, 34560, 34560, 34560, 270, 34560, 270, 34560, 270, 17280, 270, 34560, 34560, 17280, 34560, 270, 34560, 34560, 34560, 270, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 270, 34560, 17280, 34560, 270, 34560, 17280, 270, 17280, 270, 270, 17280, 17280, 17280, 34560, 17280, 270, 270]
Prompts retrieved: 3335040 . Total input tokens: 743590138 . Total output tokens: 655449743
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 95.8113550641574,
    "estimated_duration": 3600.1019761740436,
    "input_throughput": 6534.745447683583,
    "output_throughput": 5678.410815941762,
    "total_throughput": 12213.156263625344,
    "itl": 91.8877712479086,
    "ttft": 2046653.7294778707,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 425,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.1550917485310013,
    "arrivals": 1110264,
    "finished_requests": 95234,
    "scheduler_time": 241.67366321430907
}
#Debug simulation 
Total elapsed time: 95.81151269609109. Arrivals time: 0.9434040365740657 Scheduler time: 94.59447975410149 Scheduler overhead time: 0.10624505905434489 Adapter cache time: 0.02423536404967308 Engine time: 0.10688208322972059 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.025_size_16-16-16/adapters_192_slots_32_rate_3.2-1.6-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.025_size_16-16-16/adapters_192_slots_32_rate_3.2-1.6-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [64 64 64]
Adapter prompts. [34560, 270, 34560, 270, 34560, 270, 34560, 270, 270, 270, 17280, 17280, 17280, 17280, 34560, 17280, 270, 34560, 270, 17280, 17280, 270, 34560, 34560, 270, 17280, 270, 17280, 270, 270, 17280, 270, 270, 17280, 17280, 34560, 17280, 270, 17280, 34560, 34560, 17280, 34560, 270, 17280, 17280, 34560, 17280, 270, 270, 17280, 34560, 270, 17280, 270, 34560, 34560, 17280, 34560, 34560, 34560, 270, 17280, 34560, 270, 17280, 270, 17280, 270, 270, 17280, 34560, 34560, 270, 270, 270, 34560, 34560, 34560, 17280, 270, 270, 270, 270, 270, 34560, 270, 17280, 270, 34560, 34560, 270, 34560, 270, 17280, 17280, 34560, 270, 270, 270, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 270, 34560, 17280, 17280, 17280, 34560, 17280, 270, 17280, 34560, 34560, 17280, 34560, 17280, 270, 34560, 17280, 270, 17280, 17280, 270, 17280, 34560, 270, 17280, 34560, 270, 17280, 34560, 34560, 17280, 270, 34560, 17280, 270, 270, 17280, 34560, 34560, 34560, 270, 34560, 270, 34560, 270, 17280, 270, 34560, 34560, 17280, 34560, 270, 34560, 34560, 34560, 270, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 270, 34560, 17280, 34560, 270, 34560, 17280, 270, 17280, 270, 270, 17280, 17280, 17280, 34560, 17280, 270, 270]
Prompts retrieved: 3335040 . Total input tokens: 743590138 . Total output tokens: 655449743
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 106.25720728980377,
    "estimated_duration": 3600.0078530164715,
    "input_throughput": 6644.573283349045,
    "output_throughput": 5768.08658420029,
    "total_throughput": 12412.659867549335,
    "itl": 95.43649677438623,
    "ttft": 2038181.7651420217,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 326,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.081158226625986,
    "arrivals": 1110264,
    "finished_requests": 96778,
    "scheduler_time": 237.96908018590653
}
#Debug simulation 
Total elapsed time: 106.25738779408857. Arrivals time: 0.9818642772734165 Scheduler time: 104.99397447844967 Scheduler overhead time: 0.11108258459717035 Adapter cache time: 0.02354998094961047 Engine time: 0.11065733898431063 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.025_size_16-16-32/adapters_192_slots_32_rate_3.2-1.6-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.025_size_16-16-32/adapters_192_slots_32_rate_3.2-1.6-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [64 64 64]
Adapter prompts. [34560, 270, 34560, 270, 34560, 270, 34560, 270, 270, 270, 17280, 17280, 17280, 17280, 34560, 17280, 270, 34560, 270, 17280, 17280, 270, 34560, 34560, 270, 17280, 270, 17280, 270, 270, 17280, 270, 270, 17280, 17280, 34560, 17280, 270, 17280, 34560, 34560, 17280, 34560, 270, 17280, 17280, 34560, 17280, 270, 270, 17280, 34560, 270, 17280, 270, 34560, 34560, 17280, 34560, 34560, 34560, 270, 17280, 34560, 270, 17280, 270, 17280, 270, 270, 17280, 34560, 34560, 270, 270, 270, 34560, 34560, 34560, 17280, 270, 270, 270, 270, 270, 34560, 270, 17280, 270, 34560, 34560, 270, 34560, 270, 17280, 17280, 34560, 270, 270, 270, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 270, 34560, 17280, 17280, 17280, 34560, 17280, 270, 17280, 34560, 34560, 17280, 34560, 17280, 270, 34560, 17280, 270, 17280, 17280, 270, 17280, 34560, 270, 17280, 34560, 270, 17280, 34560, 34560, 17280, 270, 34560, 17280, 270, 270, 17280, 34560, 34560, 34560, 270, 34560, 270, 34560, 270, 17280, 270, 34560, 34560, 17280, 34560, 270, 34560, 34560, 34560, 270, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 270, 34560, 17280, 34560, 270, 34560, 17280, 270, 17280, 270, 270, 17280, 17280, 17280, 34560, 17280, 270, 270]
Prompts retrieved: 3335040 . Total input tokens: 743590138 . Total output tokens: 655449743
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 95.20771470107138,
    "estimated_duration": 3600.027613180186,
    "input_throughput": 6532.960167831594,
    "output_throughput": 5682.19252683164,
    "total_throughput": 12215.152694663233,
    "itl": 91.94050373847284,
    "ttft": 2046496.9182904565,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 398,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.926113143563292,
    "arrivals": 1110264,
    "finished_requests": 95228,
    "scheduler_time": 241.55833729022385
}
#Debug simulation 
Total elapsed time: 95.20789762493223. Arrivals time: 0.9204333950765431 Scheduler time: 94.0102130509913 Scheduler overhead time: 0.10757925873622298 Adapter cache time: 0.024804766289889812 Engine time: 0.10857024928554893 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-8/adapters_192_slots_32_rate_3.2-1.6-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-8/adapters_192_slots_32_rate_3.2-1.6-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 17280, 17280, 17280, 17280, 34560, 17280, 135, 34560, 135, 17280, 17280, 135, 34560, 34560, 135, 17280, 135, 17280, 135, 135, 17280, 135, 135, 17280, 17280, 34560, 17280, 135, 17280, 34560, 34560, 17280, 34560, 135, 17280, 17280, 34560, 17280, 135, 135, 17280, 34560, 135, 17280, 135, 34560, 34560, 17280, 34560, 34560, 34560, 135, 17280, 34560, 135, 17280, 135, 17280, 135, 135, 17280, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 17280, 135, 135, 135, 135, 135, 34560, 135, 17280, 135, 34560, 34560, 135, 34560, 135, 17280, 17280, 34560, 135, 135, 135, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 135, 34560, 17280, 17280, 17280, 34560, 17280, 135, 17280, 34560, 34560, 17280, 34560, 17280, 135, 34560, 17280, 135, 17280, 17280, 135, 17280, 34560, 135, 17280, 34560, 135, 17280, 34560, 34560, 17280, 135, 34560, 17280, 135, 135, 17280, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 17280, 135, 34560, 34560, 17280, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 135, 34560, 17280, 34560, 135, 34560, 17280, 135, 17280, 135, 135, 17280, 17280, 17280, 34560, 17280, 135, 135]
Prompts retrieved: 3326400 . Total input tokens: 741693916 . Total output tokens: 653727687
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 76.32346701901406,
    "estimated_duration": 3600.0633282327203,
    "input_throughput": 6745.78550036832,
    "output_throughput": 5902.806718245123,
    "total_throughput": 12648.592218613443,
    "itl": 100.4568264495202,
    "ttft": 2028611.092479316,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 321,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1225832992559313,
    "arrivals": 1107343,
    "finished_requests": 98744,
    "scheduler_time": 231.69637851077076
}
#Debug simulation 
Total elapsed time: 76.32362006604671. Arrivals time: 0.47082218155264854 Scheduler time: 75.65961578208953 Scheduler overhead time: 0.07477690977975726 Adapter cache time: 0.015543404035270214 Engine time: 0.07334143435582519 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-16/adapters_192_slots_32_rate_3.2-1.6-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-16/adapters_192_slots_32_rate_3.2-1.6-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 17280, 17280, 17280, 17280, 34560, 17280, 135, 34560, 135, 17280, 17280, 135, 34560, 34560, 135, 17280, 135, 17280, 135, 135, 17280, 135, 135, 17280, 17280, 34560, 17280, 135, 17280, 34560, 34560, 17280, 34560, 135, 17280, 17280, 34560, 17280, 135, 135, 17280, 34560, 135, 17280, 135, 34560, 34560, 17280, 34560, 34560, 34560, 135, 17280, 34560, 135, 17280, 135, 17280, 135, 135, 17280, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 17280, 135, 135, 135, 135, 135, 34560, 135, 17280, 135, 34560, 34560, 135, 34560, 135, 17280, 17280, 34560, 135, 135, 135, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 135, 34560, 17280, 17280, 17280, 34560, 17280, 135, 17280, 34560, 34560, 17280, 34560, 17280, 135, 34560, 17280, 135, 17280, 17280, 135, 17280, 34560, 135, 17280, 34560, 135, 17280, 34560, 34560, 17280, 135, 34560, 17280, 135, 135, 17280, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 17280, 135, 34560, 34560, 17280, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 135, 34560, 17280, 34560, 135, 34560, 17280, 135, 17280, 135, 135, 17280, 17280, 17280, 34560, 17280, 135, 135]
Prompts retrieved: 3326400 . Total input tokens: 741693916 . Total output tokens: 653727687
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 71.16231440799311,
    "estimated_duration": 3600.031850092634,
    "input_throughput": 6685.1836323005655,
    "output_throughput": 5848.909086584385,
    "total_throughput": 12534.09271888495,
    "itl": 98.3209455799284,
    "ttft": 2031281.7294135368,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 354,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.581975278770554,
    "arrivals": 1107343,
    "finished_requests": 97925,
    "scheduler_time": 234.07819155710712
}
#Debug simulation 
Total elapsed time: 71.16249510506168. Arrivals time: 0.4737693276256323 Scheduler time: 70.49523815326393 Scheduler overhead time: 0.07396264933049679 Adapter cache time: 0.016104152891784906 Engine time: 0.0732198366895318 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-32/adapters_192_slots_32_rate_3.2-1.6-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-32/adapters_192_slots_32_rate_3.2-1.6-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 17280, 17280, 17280, 17280, 34560, 17280, 135, 34560, 135, 17280, 17280, 135, 34560, 34560, 135, 17280, 135, 17280, 135, 135, 17280, 135, 135, 17280, 17280, 34560, 17280, 135, 17280, 34560, 34560, 17280, 34560, 135, 17280, 17280, 34560, 17280, 135, 135, 17280, 34560, 135, 17280, 135, 34560, 34560, 17280, 34560, 34560, 34560, 135, 17280, 34560, 135, 17280, 135, 17280, 135, 135, 17280, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 17280, 135, 135, 135, 135, 135, 34560, 135, 17280, 135, 34560, 34560, 135, 34560, 135, 17280, 17280, 34560, 135, 135, 135, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 135, 34560, 17280, 17280, 17280, 34560, 17280, 135, 17280, 34560, 34560, 17280, 34560, 17280, 135, 34560, 17280, 135, 17280, 17280, 135, 17280, 34560, 135, 17280, 34560, 135, 17280, 34560, 34560, 17280, 135, 34560, 17280, 135, 135, 17280, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 17280, 135, 34560, 34560, 17280, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 135, 34560, 17280, 34560, 135, 34560, 17280, 135, 17280, 135, 135, 17280, 17280, 17280, 34560, 17280, 135, 135]
Prompts retrieved: 3326400 . Total input tokens: 741693916 . Total output tokens: 653727687
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 96.12041373038664,
    "estimated_duration": 3600.0977890836098,
    "input_throughput": 6502.101157079531,
    "output_throughput": 5681.500392023093,
    "total_throughput": 12183.601549102625,
    "itl": 92.05431946512222,
    "ttft": 2043725.9465186521,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 372,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.7821544637065547,
    "arrivals": 1107343,
    "finished_requests": 95162,
    "scheduler_time": 241.62380597805924
}
#Debug simulation 
Total elapsed time: 96.12066127406433. Arrivals time: 0.8293833425268531 Scheduler time: 95.0181463197805 Scheduler overhead time: 0.10576970921829343 Adapter cache time: 0.0240140943787992 Engine time: 0.10632043611258268 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.0125_size_8-16-16/adapters_192_slots_32_rate_3.2-1.6-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.0125_size_8-16-16/adapters_192_slots_32_rate_3.2-1.6-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 17280, 17280, 17280, 17280, 34560, 17280, 135, 34560, 135, 17280, 17280, 135, 34560, 34560, 135, 17280, 135, 17280, 135, 135, 17280, 135, 135, 17280, 17280, 34560, 17280, 135, 17280, 34560, 34560, 17280, 34560, 135, 17280, 17280, 34560, 17280, 135, 135, 17280, 34560, 135, 17280, 135, 34560, 34560, 17280, 34560, 34560, 34560, 135, 17280, 34560, 135, 17280, 135, 17280, 135, 135, 17280, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 17280, 135, 135, 135, 135, 135, 34560, 135, 17280, 135, 34560, 34560, 135, 34560, 135, 17280, 17280, 34560, 135, 135, 135, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 135, 34560, 17280, 17280, 17280, 34560, 17280, 135, 17280, 34560, 34560, 17280, 34560, 17280, 135, 34560, 17280, 135, 17280, 17280, 135, 17280, 34560, 135, 17280, 34560, 135, 17280, 34560, 34560, 17280, 135, 34560, 17280, 135, 135, 17280, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 17280, 135, 34560, 34560, 17280, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 135, 34560, 17280, 34560, 135, 34560, 17280, 135, 17280, 135, 135, 17280, 17280, 17280, 34560, 17280, 135, 135]
Prompts retrieved: 3326400 . Total input tokens: 741693916 . Total output tokens: 653727687
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 97.12918155826628,
    "estimated_duration": 3600.0713135376996,
    "input_throughput": 6686.961702529036,
    "output_throughput": 5852.794337925093,
    "total_throughput": 12539.75604045413,
    "itl": 98.24801922970514,
    "ttft": 2031633.6754111657,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 393,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.6824085513083227,
    "arrivals": 1107343,
    "finished_requests": 97878,
    "scheduler_time": 233.7993723615341
}
#Debug simulation 
Total elapsed time: 97.12935644993559. Arrivals time: 0.8050359860062599 Scheduler time: 96.06160338316113 Scheduler overhead time: 0.10234640911221504 Adapter cache time: 0.023471581283956766 Engine time: 0.10206937836483121 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.0125_size_8-16-32/adapters_192_slots_32_rate_3.2-1.6-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.0125_size_8-16-32/adapters_192_slots_32_rate_3.2-1.6-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 17280, 17280, 17280, 17280, 34560, 17280, 135, 34560, 135, 17280, 17280, 135, 34560, 34560, 135, 17280, 135, 17280, 135, 135, 17280, 135, 135, 17280, 17280, 34560, 17280, 135, 17280, 34560, 34560, 17280, 34560, 135, 17280, 17280, 34560, 17280, 135, 135, 17280, 34560, 135, 17280, 135, 34560, 34560, 17280, 34560, 34560, 34560, 135, 17280, 34560, 135, 17280, 135, 17280, 135, 135, 17280, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 17280, 135, 135, 135, 135, 135, 34560, 135, 17280, 135, 34560, 34560, 135, 34560, 135, 17280, 17280, 34560, 135, 135, 135, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 135, 34560, 17280, 17280, 17280, 34560, 17280, 135, 17280, 34560, 34560, 17280, 34560, 17280, 135, 34560, 17280, 135, 17280, 17280, 135, 17280, 34560, 135, 17280, 34560, 135, 17280, 34560, 34560, 17280, 135, 34560, 17280, 135, 135, 17280, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 17280, 135, 34560, 34560, 17280, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 135, 34560, 17280, 34560, 135, 34560, 17280, 135, 17280, 135, 135, 17280, 17280, 17280, 34560, 17280, 135, 135]
Prompts retrieved: 3326400 . Total input tokens: 741693916 . Total output tokens: 653727687
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 101.99049366405234,
    "estimated_duration": 3600.0704237907175,
    "input_throughput": 6516.885848943012,
    "output_throughput": 5698.934349844454,
    "total_throughput": 12215.820198787465,
    "itl": 92.06908554958042,
    "ttft": 2041472.063615012,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 378,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.8073104009544645,
    "arrivals": 1107343,
    "finished_requests": 95389,
    "scheduler_time": 240.80091606601297
}
#Debug simulation 
Total elapsed time: 101.9906927132979. Arrivals time: 1.1639933460392058 Scheduler time: 100.55142251821235 Scheduler overhead time: 0.10701557900756598 Adapter cache time: 0.024304228834807873 Engine time: 0.10742980754002929 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.0125_size_16-16-16/adapters_192_slots_32_rate_3.2-1.6-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.0125_size_16-16-16/adapters_192_slots_32_rate_3.2-1.6-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 17280, 17280, 17280, 17280, 34560, 17280, 135, 34560, 135, 17280, 17280, 135, 34560, 34560, 135, 17280, 135, 17280, 135, 135, 17280, 135, 135, 17280, 17280, 34560, 17280, 135, 17280, 34560, 34560, 17280, 34560, 135, 17280, 17280, 34560, 17280, 135, 135, 17280, 34560, 135, 17280, 135, 34560, 34560, 17280, 34560, 34560, 34560, 135, 17280, 34560, 135, 17280, 135, 17280, 135, 135, 17280, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 17280, 135, 135, 135, 135, 135, 34560, 135, 17280, 135, 34560, 34560, 135, 34560, 135, 17280, 17280, 34560, 135, 135, 135, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 135, 34560, 17280, 17280, 17280, 34560, 17280, 135, 17280, 34560, 34560, 17280, 34560, 17280, 135, 34560, 17280, 135, 17280, 17280, 135, 17280, 34560, 135, 17280, 34560, 135, 17280, 34560, 34560, 17280, 135, 34560, 17280, 135, 135, 17280, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 17280, 135, 34560, 34560, 17280, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 135, 34560, 17280, 34560, 135, 34560, 17280, 135, 17280, 135, 135, 17280, 17280, 17280, 34560, 17280, 135, 135]
Prompts retrieved: 3326400 . Total input tokens: 741693916 . Total output tokens: 653727687
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 99.24116780143231,
    "estimated_duration": 3600.1017336897958,
    "input_throughput": 6689.585956593731,
    "output_throughput": 5844.133181879931,
    "total_throughput": 12533.719138473662,
    "itl": 98.13068824419172,
    "ttft": 2032839.585682175,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 329,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1003099894476973,
    "arrivals": 1107343,
    "finished_requests": 97832,
    "scheduler_time": 234.41693067513313
}
#Debug simulation 
Total elapsed time: 99.24134386517107. Arrivals time: 0.9531031837686896 Scheduler time: 98.01720887701958 Scheduler overhead time: 0.10543048707768321 Adapter cache time: 0.023738224059343338 Engine time: 0.10583034949377179 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.0125_size_16-16-32/adapters_192_slots_32_rate_3.2-1.6-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.0125_size_16-16-32/adapters_192_slots_32_rate_3.2-1.6-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 17280, 17280, 17280, 17280, 34560, 17280, 135, 34560, 135, 17280, 17280, 135, 34560, 34560, 135, 17280, 135, 17280, 135, 135, 17280, 135, 135, 17280, 17280, 34560, 17280, 135, 17280, 34560, 34560, 17280, 34560, 135, 17280, 17280, 34560, 17280, 135, 135, 17280, 34560, 135, 17280, 135, 34560, 34560, 17280, 34560, 34560, 34560, 135, 17280, 34560, 135, 17280, 135, 17280, 135, 135, 17280, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 17280, 135, 135, 135, 135, 135, 34560, 135, 17280, 135, 34560, 34560, 135, 34560, 135, 17280, 17280, 34560, 135, 135, 135, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 135, 34560, 17280, 17280, 17280, 34560, 17280, 135, 17280, 34560, 34560, 17280, 34560, 17280, 135, 34560, 17280, 135, 17280, 17280, 135, 17280, 34560, 135, 17280, 34560, 135, 17280, 34560, 34560, 17280, 135, 34560, 17280, 135, 135, 17280, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 17280, 135, 34560, 34560, 17280, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 135, 34560, 17280, 34560, 135, 34560, 17280, 135, 17280, 135, 135, 17280, 17280, 17280, 34560, 17280, 135, 135]
Prompts retrieved: 3326400 . Total input tokens: 741693916 . Total output tokens: 653727687
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 98.40664955880493,
    "estimated_duration": 3600.0743212424923,
    "input_throughput": 6502.887415924295,
    "output_throughput": 5685.399848338669,
    "total_throughput": 12188.287264262963,
    "itl": 91.97173227293331,
    "ttft": 2040744.0992333728,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 356,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.6256507676467455,
    "arrivals": 1107343,
    "finished_requests": 95140,
    "scheduler_time": 241.41560653676825
}
#Debug simulation 
Total elapsed time: 98.40684919292107. Arrivals time: 0.8587588765658438 Scheduler time: 97.27794861467555 Scheduler overhead time: 0.10460603795945644 Adapter cache time: 0.023437003139406443 Engine time: 0.10556809138506651 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-8/adapters_192_slots_32_rate_3.2-1.6-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-8/adapters_192_slots_32_rate_3.2-1.6-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 17280, 17280, 17280, 17280, 34560, 17280, 66, 34560, 66, 17280, 17280, 66, 34560, 34560, 66, 17280, 66, 17280, 66, 66, 17280, 66, 66, 17280, 17280, 34560, 17280, 66, 17280, 34560, 34560, 17280, 34560, 66, 17280, 17280, 34560, 17280, 66, 66, 17280, 34560, 66, 17280, 66, 34560, 34560, 17280, 34560, 34560, 34560, 66, 17280, 34560, 66, 17280, 66, 17280, 66, 66, 17280, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 17280, 66, 66, 66, 66, 66, 34560, 66, 17280, 66, 34560, 34560, 66, 34560, 66, 17280, 17280, 34560, 66, 66, 66, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 66, 34560, 17280, 17280, 17280, 34560, 17280, 66, 17280, 34560, 34560, 17280, 34560, 17280, 66, 34560, 17280, 66, 17280, 17280, 66, 17280, 34560, 66, 17280, 34560, 66, 17280, 34560, 34560, 17280, 66, 34560, 17280, 66, 66, 17280, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 17280, 66, 34560, 34560, 17280, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 66, 34560, 17280, 34560, 66, 34560, 17280, 66, 17280, 66, 66, 17280, 17280, 17280, 34560, 17280, 66, 66]
Prompts retrieved: 3321984 . Total input tokens: 740725179 . Total output tokens: 652862987
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 101.9884542869404,
    "estimated_duration": 3600.1096463319273,
    "input_throughput": 6803.531393816254,
    "output_throughput": 5910.013607968402,
    "total_throughput": 12713.545001784656,
    "itl": 100.28642093297933,
    "ttft": 2032552.6693405388,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 303,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0035599366808285,
    "arrivals": 1105914,
    "finished_requests": 99319,
    "scheduler_time": 231.36996356205785
}
#Debug simulation 
Total elapsed time: 101.98864394286647. Arrivals time: 0.8252033619210124 Scheduler time: 100.88999021332711 Scheduler overhead time: 0.10701105976477265 Adapter cache time: 0.02307844255119562 Engine time: 0.1078259483911097 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-16/adapters_192_slots_32_rate_3.2-1.6-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-16/adapters_192_slots_32_rate_3.2-1.6-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 17280, 17280, 17280, 17280, 34560, 17280, 66, 34560, 66, 17280, 17280, 66, 34560, 34560, 66, 17280, 66, 17280, 66, 66, 17280, 66, 66, 17280, 17280, 34560, 17280, 66, 17280, 34560, 34560, 17280, 34560, 66, 17280, 17280, 34560, 17280, 66, 66, 17280, 34560, 66, 17280, 66, 34560, 34560, 17280, 34560, 34560, 34560, 66, 17280, 34560, 66, 17280, 66, 17280, 66, 66, 17280, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 17280, 66, 66, 66, 66, 66, 34560, 66, 17280, 66, 34560, 34560, 66, 34560, 66, 17280, 17280, 34560, 66, 66, 66, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 66, 34560, 17280, 17280, 17280, 34560, 17280, 66, 17280, 34560, 34560, 17280, 34560, 17280, 66, 34560, 17280, 66, 17280, 17280, 66, 17280, 34560, 66, 17280, 34560, 66, 17280, 34560, 34560, 17280, 66, 34560, 17280, 66, 66, 17280, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 17280, 66, 34560, 34560, 17280, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 66, 34560, 17280, 34560, 66, 34560, 17280, 66, 17280, 66, 66, 17280, 17280, 17280, 34560, 17280, 66, 66]
Prompts retrieved: 3321984 . Total input tokens: 740725179 . Total output tokens: 652862987
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 100.91123749688268,
    "estimated_duration": 3600.0777374775876,
    "input_throughput": 6728.453040842372,
    "output_throughput": 5845.415997806911,
    "total_throughput": 12573.869038649284,
    "itl": 97.5313083200477,
    "ttft": 2037815.8938555021,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 307,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.231955039524476,
    "arrivals": 1105914,
    "finished_requests": 98188,
    "scheduler_time": 234.16724467652347
}
#Debug simulation 
Total elapsed time: 100.91143057402223. Arrivals time: 0.8157561374828219 Scheduler time: 99.82984586944804 Scheduler overhead time: 0.10453562950715423 Adapter cache time: 0.02163064805790782 Engine time: 0.10371537180617452 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-32/adapters_192_slots_32_rate_3.2-1.6-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-32/adapters_192_slots_32_rate_3.2-1.6-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 17280, 17280, 17280, 17280, 34560, 17280, 66, 34560, 66, 17280, 17280, 66, 34560, 34560, 66, 17280, 66, 17280, 66, 66, 17280, 66, 66, 17280, 17280, 34560, 17280, 66, 17280, 34560, 34560, 17280, 34560, 66, 17280, 17280, 34560, 17280, 66, 66, 17280, 34560, 66, 17280, 66, 34560, 34560, 17280, 34560, 34560, 34560, 66, 17280, 34560, 66, 17280, 66, 17280, 66, 66, 17280, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 17280, 66, 66, 66, 66, 66, 34560, 66, 17280, 66, 34560, 34560, 66, 34560, 66, 17280, 17280, 34560, 66, 66, 66, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 66, 34560, 17280, 17280, 17280, 34560, 17280, 66, 17280, 34560, 34560, 17280, 34560, 17280, 66, 34560, 17280, 66, 17280, 17280, 66, 17280, 34560, 66, 17280, 34560, 66, 17280, 34560, 34560, 17280, 66, 34560, 17280, 66, 66, 17280, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 17280, 66, 34560, 34560, 17280, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 66, 34560, 17280, 34560, 66, 34560, 17280, 66, 17280, 66, 66, 17280, 17280, 17280, 34560, 17280, 66, 66]
Prompts retrieved: 3321984 . Total input tokens: 740725179 . Total output tokens: 652862987
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 101.93663016706705,
    "estimated_duration": 3600.093097820225,
    "input_throughput": 6511.131896614786,
    "output_throughput": 5668.229805600156,
    "total_throughput": 12179.361702214943,
    "itl": 91.00433507460566,
    "ttft": 2049121.7737304186,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 300,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2399797278782434,
    "arrivals": 1105914,
    "finished_requests": 95113,
    "scheduler_time": 242.1784118482205
}
#Debug simulation 
Total elapsed time: 101.93679242720827. Arrivals time: 0.7894428949803114 Scheduler time: 100.86011960962787 Scheduler overhead time: 0.1125473715364933 Adapter cache time: 0.023403297178447247 Engine time: 0.11431588931009173 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.00625_size_8-16-16/adapters_192_slots_32_rate_3.2-1.6-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.00625_size_8-16-16/adapters_192_slots_32_rate_3.2-1.6-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 17280, 17280, 17280, 17280, 34560, 17280, 66, 34560, 66, 17280, 17280, 66, 34560, 34560, 66, 17280, 66, 17280, 66, 66, 17280, 66, 66, 17280, 17280, 34560, 17280, 66, 17280, 34560, 34560, 17280, 34560, 66, 17280, 17280, 34560, 17280, 66, 66, 17280, 34560, 66, 17280, 66, 34560, 34560, 17280, 34560, 34560, 34560, 66, 17280, 34560, 66, 17280, 66, 17280, 66, 66, 17280, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 17280, 66, 66, 66, 66, 66, 34560, 66, 17280, 66, 34560, 34560, 66, 34560, 66, 17280, 17280, 34560, 66, 66, 66, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 66, 34560, 17280, 17280, 17280, 34560, 17280, 66, 17280, 34560, 34560, 17280, 34560, 17280, 66, 34560, 17280, 66, 17280, 17280, 66, 17280, 34560, 66, 17280, 34560, 66, 17280, 34560, 34560, 17280, 66, 34560, 17280, 66, 66, 17280, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 17280, 66, 34560, 34560, 17280, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 66, 34560, 17280, 34560, 66, 34560, 17280, 66, 17280, 66, 66, 17280, 17280, 17280, 34560, 17280, 66, 66]
Prompts retrieved: 3321984 . Total input tokens: 740725179 . Total output tokens: 652862987
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 101.23913808399811,
    "estimated_duration": 3600.0434107953956,
    "input_throughput": 6712.318503587448,
    "output_throughput": 5841.877610957306,
    "total_throughput": 12554.196114544755,
    "itl": 97.57380080682263,
    "ttft": 2036665.9432450843,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 313,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.149483340489676,
    "arrivals": 1105914,
    "finished_requests": 98077,
    "scheduler_time": 234.40020840157138
}
#Debug simulation 
Total elapsed time: 101.23931847978383. Arrivals time: 0.8047182848677039 Scheduler time: 100.16052407585084 Scheduler overhead time: 0.10731469374150038 Adapter cache time: 0.022922268602997065 Engine time: 0.10847937455400825 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.00625_size_8-16-32/adapters_192_slots_32_rate_3.2-1.6-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.00625_size_8-16-32/adapters_192_slots_32_rate_3.2-1.6-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 17280, 17280, 17280, 17280, 34560, 17280, 66, 34560, 66, 17280, 17280, 66, 34560, 34560, 66, 17280, 66, 17280, 66, 66, 17280, 66, 66, 17280, 17280, 34560, 17280, 66, 17280, 34560, 34560, 17280, 34560, 66, 17280, 17280, 34560, 17280, 66, 66, 17280, 34560, 66, 17280, 66, 34560, 34560, 17280, 34560, 34560, 34560, 66, 17280, 34560, 66, 17280, 66, 17280, 66, 66, 17280, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 17280, 66, 66, 66, 66, 66, 34560, 66, 17280, 66, 34560, 34560, 66, 34560, 66, 17280, 17280, 34560, 66, 66, 66, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 66, 34560, 17280, 17280, 17280, 34560, 17280, 66, 17280, 34560, 34560, 17280, 34560, 17280, 66, 34560, 17280, 66, 17280, 17280, 66, 17280, 34560, 66, 17280, 34560, 66, 17280, 34560, 34560, 17280, 66, 34560, 17280, 66, 66, 17280, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 17280, 66, 34560, 34560, 17280, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 66, 34560, 17280, 34560, 66, 34560, 17280, 66, 17280, 66, 66, 17280, 17280, 17280, 34560, 17280, 66, 66]
Prompts retrieved: 3321984 . Total input tokens: 740725179 . Total output tokens: 652862987
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 101.02446025796235,
    "estimated_duration": 3600.021951177132,
    "input_throughput": 6501.877854479868,
    "output_throughput": 5660.291597204592,
    "total_throughput": 12162.16945168446,
    "itl": 90.96472019426191,
    "ttft": 2047491.69994501,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 300,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.222426636847675,
    "arrivals": 1105914,
    "finished_requests": 94961,
    "scheduler_time": 242.67560074441818
}
#Debug simulation 
Total elapsed time: 101.02463835384697. Arrivals time: 0.8226235844194889 Scheduler time: 99.92099799681455 Scheduler overhead time: 0.11014339094981551 Adapter cache time: 0.02319245506078005 Engine time: 0.11070873588323593 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.00625_size_16-16-16/adapters_192_slots_32_rate_3.2-1.6-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.00625_size_16-16-16/adapters_192_slots_32_rate_3.2-1.6-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 17280, 17280, 17280, 17280, 34560, 17280, 66, 34560, 66, 17280, 17280, 66, 34560, 34560, 66, 17280, 66, 17280, 66, 66, 17280, 66, 66, 17280, 17280, 34560, 17280, 66, 17280, 34560, 34560, 17280, 34560, 66, 17280, 17280, 34560, 17280, 66, 66, 17280, 34560, 66, 17280, 66, 34560, 34560, 17280, 34560, 34560, 34560, 66, 17280, 34560, 66, 17280, 66, 17280, 66, 66, 17280, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 17280, 66, 66, 66, 66, 66, 34560, 66, 17280, 66, 34560, 34560, 66, 34560, 66, 17280, 17280, 34560, 66, 66, 66, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 66, 34560, 17280, 17280, 17280, 34560, 17280, 66, 17280, 34560, 34560, 17280, 34560, 17280, 66, 34560, 17280, 66, 17280, 17280, 66, 17280, 34560, 66, 17280, 34560, 66, 17280, 34560, 34560, 17280, 66, 34560, 17280, 66, 66, 17280, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 17280, 66, 34560, 34560, 17280, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 66, 34560, 17280, 34560, 66, 34560, 17280, 66, 17280, 66, 66, 17280, 17280, 17280, 34560, 17280, 66, 66]
Prompts retrieved: 3321984 . Total input tokens: 740725179 . Total output tokens: 652862987
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 100.85340332426131,
    "estimated_duration": 3600.03523960576,
    "input_throughput": 6715.147044684868,
    "output_throughput": 5844.9127854382605,
    "total_throughput": 12560.05983012313,
    "itl": 97.6229183787474,
    "ttft": 2036207.9716000475,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 301,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9215602031117234,
    "arrivals": 1105914,
    "finished_requests": 98122,
    "scheduler_time": 234.23863227410538
}
#Debug simulation 
Total elapsed time: 100.85358691215515. Arrivals time: 0.8257826268672943 Scheduler time: 99.75349982827902 Scheduler overhead time: 0.10766420606523752 Adapter cache time: 0.022591528948396444 Engine time: 0.1085247304290533 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.00625_size_16-16-32/adapters_192_slots_32_rate_3.2-1.6-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.00625_size_16-16-32/adapters_192_slots_32_rate_3.2-1.6-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 17280, 17280, 17280, 17280, 34560, 17280, 66, 34560, 66, 17280, 17280, 66, 34560, 34560, 66, 17280, 66, 17280, 66, 66, 17280, 66, 66, 17280, 17280, 34560, 17280, 66, 17280, 34560, 34560, 17280, 34560, 66, 17280, 17280, 34560, 17280, 66, 66, 17280, 34560, 66, 17280, 66, 34560, 34560, 17280, 34560, 34560, 34560, 66, 17280, 34560, 66, 17280, 66, 17280, 66, 66, 17280, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 17280, 66, 66, 66, 66, 66, 34560, 66, 17280, 66, 34560, 34560, 66, 34560, 66, 17280, 17280, 34560, 66, 66, 66, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 66, 34560, 17280, 17280, 17280, 34560, 17280, 66, 17280, 34560, 34560, 17280, 34560, 17280, 66, 34560, 17280, 66, 17280, 17280, 66, 17280, 34560, 66, 17280, 34560, 66, 17280, 34560, 34560, 17280, 66, 34560, 17280, 66, 66, 17280, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 17280, 66, 34560, 34560, 17280, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 66, 34560, 17280, 34560, 66, 34560, 17280, 66, 17280, 66, 66, 17280, 17280, 17280, 34560, 17280, 66, 66]
Prompts retrieved: 3321984 . Total input tokens: 740725179 . Total output tokens: 652862987
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 100.15291805705056,
    "estimated_duration": 3600.0795129322187,
    "input_throughput": 6528.518860645096,
    "output_throughput": 5675.672141851581,
    "total_throughput": 12204.191002496676,
    "itl": 91.3921986879645,
    "ttft": 2048638.5461542995,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 298,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1857698896154836,
    "arrivals": 1105914,
    "finished_requests": 95304,
    "scheduler_time": 241.88855858822222
}
#Debug simulation 
Total elapsed time: 100.15320076001808. Arrivals time: 0.795065198559314 Scheduler time: 99.0840072077699 Scheduler overhead time: 0.10726524982601404 Adapter cache time: 0.022531735245138407 Engine time: 0.10806765081360936 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.003125_size_8-8-8/adapters_192_slots_32_rate_3.2-1.6-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.003125_size_8-8-8/adapters_192_slots_32_rate_3.2-1.6-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 17280, 17280, 17280, 17280, 34560, 17280, 33, 34560, 33, 17280, 17280, 33, 34560, 34560, 33, 17280, 33, 17280, 33, 33, 17280, 33, 33, 17280, 17280, 34560, 17280, 33, 17280, 34560, 34560, 17280, 34560, 33, 17280, 17280, 34560, 17280, 33, 33, 17280, 34560, 33, 17280, 33, 34560, 34560, 17280, 34560, 34560, 34560, 33, 17280, 34560, 33, 17280, 33, 17280, 33, 33, 17280, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 17280, 33, 33, 33, 33, 33, 34560, 33, 17280, 33, 34560, 34560, 33, 34560, 33, 17280, 17280, 34560, 33, 33, 33, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 33, 34560, 17280, 17280, 17280, 34560, 17280, 33, 17280, 34560, 34560, 17280, 34560, 17280, 33, 34560, 17280, 33, 17280, 17280, 33, 17280, 34560, 33, 17280, 34560, 33, 17280, 34560, 34560, 17280, 33, 34560, 17280, 33, 33, 17280, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 17280, 33, 34560, 34560, 17280, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 33, 34560, 17280, 34560, 33, 34560, 17280, 33, 17280, 33, 33, 17280, 17280, 17280, 34560, 17280, 33, 33]
Prompts retrieved: 3319872 . Total input tokens: 740232898 . Total output tokens: 652452478
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 103.5083476640284,
    "estimated_duration": 3600.056637587326,
    "input_throughput": 6721.069815228171,
    "output_throughput": 5919.644090455802,
    "total_throughput": 12640.713905683973,
    "itl": 100.51690011994421,
    "ttft": 2035011.281654333,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 289,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9109862102335295,
    "arrivals": 1105156,
    "finished_requests": 98510,
    "scheduler_time": 230.95990836706792
}
#Debug simulation 
Total elapsed time: 103.50852070795372. Arrivals time: 0.8190184701234102 Scheduler time: 102.41455780202523 Scheduler overhead time: 0.10848663421347737 Adapter cache time: 0.02259953459724784 Engine time: 0.10865024570375681 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.003125_size_8-8-16/adapters_192_slots_32_rate_3.2-1.6-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.003125_size_8-8-16/adapters_192_slots_32_rate_3.2-1.6-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 17280, 17280, 17280, 17280, 34560, 17280, 33, 34560, 33, 17280, 17280, 33, 34560, 34560, 33, 17280, 33, 17280, 33, 33, 17280, 33, 33, 17280, 17280, 34560, 17280, 33, 17280, 34560, 34560, 17280, 34560, 33, 17280, 17280, 34560, 17280, 33, 33, 17280, 34560, 33, 17280, 33, 34560, 34560, 17280, 34560, 34560, 34560, 33, 17280, 34560, 33, 17280, 33, 17280, 33, 33, 17280, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 17280, 33, 33, 33, 33, 33, 34560, 33, 17280, 33, 34560, 34560, 33, 34560, 33, 17280, 17280, 34560, 33, 33, 33, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 33, 34560, 17280, 17280, 17280, 34560, 17280, 33, 17280, 34560, 34560, 17280, 34560, 17280, 33, 34560, 17280, 33, 17280, 17280, 33, 17280, 34560, 33, 17280, 34560, 33, 17280, 34560, 34560, 17280, 33, 34560, 17280, 33, 33, 17280, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 17280, 33, 34560, 34560, 17280, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 33, 34560, 17280, 34560, 33, 34560, 17280, 33, 17280, 33, 33, 17280, 17280, 17280, 34560, 17280, 33, 33]
Prompts retrieved: 3319872 . Total input tokens: 740232898 . Total output tokens: 652452478
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 108.36582545097917,
    "estimated_duration": 3600.0986763525034,
    "input_throughput": 6640.866028767449,
    "output_throughput": 5847.704436071036,
    "total_throughput": 12488.570464838485,
    "itl": 97.28887418733837,
    "ttft": 2037915.605447846,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 270,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9596562194172311,
    "arrivals": 1105156,
    "finished_requests": 97294,
    "scheduler_time": 234.35193742420668
}
#Debug simulation 
Total elapsed time: 108.3660232629627. Arrivals time: 0.8350444794632494 Scheduler time: 107.25361626408994 Scheduler overhead time: 0.10929513443261385 Adapter cache time: 0.022557846270501614 Engine time: 0.10969041241332889 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.003125_size_8-8-32/adapters_192_slots_32_rate_3.2-1.6-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.003125_size_8-8-32/adapters_192_slots_32_rate_3.2-1.6-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 17280, 17280, 17280, 17280, 34560, 17280, 33, 34560, 33, 17280, 17280, 33, 34560, 34560, 33, 17280, 33, 17280, 33, 33, 17280, 33, 33, 17280, 17280, 34560, 17280, 33, 17280, 34560, 34560, 17280, 34560, 33, 17280, 17280, 34560, 17280, 33, 33, 17280, 34560, 33, 17280, 33, 34560, 34560, 17280, 34560, 34560, 34560, 33, 17280, 34560, 33, 17280, 33, 17280, 33, 33, 17280, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 17280, 33, 33, 33, 33, 33, 34560, 33, 17280, 33, 34560, 34560, 33, 34560, 33, 17280, 17280, 34560, 33, 33, 33, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 33, 34560, 17280, 17280, 17280, 34560, 17280, 33, 17280, 34560, 34560, 17280, 34560, 17280, 33, 34560, 17280, 33, 17280, 17280, 33, 17280, 34560, 33, 17280, 34560, 33, 17280, 34560, 34560, 17280, 33, 34560, 17280, 33, 33, 17280, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 17280, 33, 34560, 34560, 17280, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 33, 34560, 17280, 34560, 33, 34560, 17280, 33, 17280, 33, 33, 17280, 17280, 17280, 34560, 17280, 33, 33]
Prompts retrieved: 3319872 . Total input tokens: 740232898 . Total output tokens: 652452478
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 96.37438753340393,
    "estimated_duration": 3600.072596398805,
    "input_throughput": 6456.947013583205,
    "output_throughput": 5678.256883055222,
    "total_throughput": 12135.203896638426,
    "itl": 91.2378611049822,
    "ttft": 2051143.4509061768,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 310,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3139052360365255,
    "arrivals": 1105156,
    "finished_requests": 94528,
    "scheduler_time": 241.8403058741358
}
#Debug simulation 
Total elapsed time: 96.37454534834251. Arrivals time: 0.767625043168664 Scheduler time: 95.33619614411145 Scheduler overhead time: 0.1044361381791532 Adapter cache time: 0.021975622978061438 Engine time: 0.10858924593776464 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.003125_size_8-16-16/adapters_192_slots_32_rate_3.2-1.6-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.003125_size_8-16-16/adapters_192_slots_32_rate_3.2-1.6-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 17280, 17280, 17280, 17280, 34560, 17280, 33, 34560, 33, 17280, 17280, 33, 34560, 34560, 33, 17280, 33, 17280, 33, 33, 17280, 33, 33, 17280, 17280, 34560, 17280, 33, 17280, 34560, 34560, 17280, 34560, 33, 17280, 17280, 34560, 17280, 33, 33, 17280, 34560, 33, 17280, 33, 34560, 34560, 17280, 34560, 34560, 34560, 33, 17280, 34560, 33, 17280, 33, 17280, 33, 33, 17280, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 17280, 33, 33, 33, 33, 33, 34560, 33, 17280, 33, 34560, 34560, 33, 34560, 33, 17280, 17280, 34560, 33, 33, 33, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 33, 34560, 17280, 17280, 17280, 34560, 17280, 33, 17280, 34560, 34560, 17280, 34560, 17280, 33, 34560, 17280, 33, 17280, 17280, 33, 17280, 34560, 33, 17280, 34560, 33, 17280, 34560, 34560, 17280, 33, 34560, 17280, 33, 33, 17280, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 17280, 33, 34560, 34560, 17280, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 33, 34560, 17280, 34560, 33, 34560, 17280, 33, 17280, 33, 33, 17280, 17280, 17280, 34560, 17280, 33, 33]
Prompts retrieved: 3319872 . Total input tokens: 740232898 . Total output tokens: 652452478
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 98.87645798921585,
    "estimated_duration": 3600.019745377279,
    "input_throughput": 6650.5743560833935,
    "output_throughput": 5849.20236258127,
    "total_throughput": 12499.776718664663,
    "itl": 97.67613758350609,
    "ttft": 2039258.7426300824,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 294,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.001812644125891,
    "arrivals": 1105156,
    "finished_requests": 97441,
    "scheduler_time": 234.16009490295758
}
#Debug simulation 
Total elapsed time: 98.8766552140005. Arrivals time: 0.8257298399694264 Scheduler time: 97.7833413197659 Scheduler overhead time: 0.1045020162127912 Adapter cache time: 0.021826185286045074 Engine time: 0.1065500183030963 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.003125_size_8-16-32/adapters_192_slots_32_rate_3.2-1.6-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.003125_size_8-16-32/adapters_192_slots_32_rate_3.2-1.6-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 17280, 17280, 17280, 17280, 34560, 17280, 33, 34560, 33, 17280, 17280, 33, 34560, 34560, 33, 17280, 33, 17280, 33, 33, 17280, 33, 33, 17280, 17280, 34560, 17280, 33, 17280, 34560, 34560, 17280, 34560, 33, 17280, 17280, 34560, 17280, 33, 33, 17280, 34560, 33, 17280, 33, 34560, 34560, 17280, 34560, 34560, 34560, 33, 17280, 34560, 33, 17280, 33, 17280, 33, 33, 17280, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 17280, 33, 33, 33, 33, 33, 34560, 33, 17280, 33, 34560, 34560, 33, 34560, 33, 17280, 17280, 34560, 33, 33, 33, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 33, 34560, 17280, 17280, 17280, 34560, 17280, 33, 17280, 34560, 34560, 17280, 34560, 17280, 33, 34560, 17280, 33, 17280, 17280, 33, 17280, 34560, 33, 17280, 34560, 33, 17280, 34560, 34560, 17280, 33, 34560, 17280, 33, 33, 17280, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 17280, 33, 34560, 34560, 17280, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 33, 34560, 17280, 34560, 33, 34560, 17280, 33, 17280, 33, 33, 17280, 17280, 17280, 34560, 17280, 33, 33]
Prompts retrieved: 3319872 . Total input tokens: 740232898 . Total output tokens: 652452478
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 94.84892245102674,
    "estimated_duration": 3600.005019540326,
    "input_throughput": 6455.448499059982,
    "output_throughput": 5678.95235951934,
    "total_throughput": 12134.400858579322,
    "itl": 91.4376676298456,
    "ttft": 2053787.7693981968,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 289,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.130586451301357,
    "arrivals": 1105156,
    "finished_requests": 94575,
    "scheduler_time": 241.7229364515508
}
#Debug simulation 
Total elapsed time: 94.84909328026697. Arrivals time: 0.7900071209296584 Scheduler time: 93.78868214506656 Scheduler overhead time: 0.10594020923599601 Adapter cache time: 0.02230763202533126 Engine time: 0.10677485074847937 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.003125_size_16-16-16/adapters_192_slots_32_rate_3.2-1.6-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.003125_size_16-16-16/adapters_192_slots_32_rate_3.2-1.6-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 17280, 17280, 17280, 17280, 34560, 17280, 33, 34560, 33, 17280, 17280, 33, 34560, 34560, 33, 17280, 33, 17280, 33, 33, 17280, 33, 33, 17280, 17280, 34560, 17280, 33, 17280, 34560, 34560, 17280, 34560, 33, 17280, 17280, 34560, 17280, 33, 33, 17280, 34560, 33, 17280, 33, 34560, 34560, 17280, 34560, 34560, 34560, 33, 17280, 34560, 33, 17280, 33, 17280, 33, 33, 17280, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 17280, 33, 33, 33, 33, 33, 34560, 33, 17280, 33, 34560, 34560, 33, 34560, 33, 17280, 17280, 34560, 33, 33, 33, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 33, 34560, 17280, 17280, 17280, 34560, 17280, 33, 17280, 34560, 34560, 17280, 34560, 17280, 33, 34560, 17280, 33, 17280, 17280, 33, 17280, 34560, 33, 17280, 34560, 33, 17280, 34560, 34560, 17280, 33, 34560, 17280, 33, 33, 17280, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 17280, 33, 34560, 34560, 17280, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 33, 34560, 17280, 34560, 33, 34560, 17280, 33, 17280, 33, 33, 17280, 17280, 17280, 34560, 17280, 33, 33]
Prompts retrieved: 3319872 . Total input tokens: 740232898 . Total output tokens: 652452478
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 73.25726251024753,
    "estimated_duration": 3600.0844396051843,
    "input_throughput": 6643.835276992306,
    "output_throughput": 5845.941769718065,
    "total_throughput": 12489.777046710371,
    "itl": 97.587829932048,
    "ttft": 2040133.1895088612,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 286,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.825801389003166,
    "arrivals": 1105156,
    "finished_requests": 97312,
    "scheduler_time": 234.29377715266804
}
#Debug simulation 
Total elapsed time: 73.25741857290268. Arrivals time: 0.47032953007146716 Scheduler time: 72.59392021642998 Scheduler overhead time: 0.07526870118454099 Adapter cache time: 0.01504527311772108 Engine time: 0.07388664409518242 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.003125_size_16-16-32/adapters_192_slots_32_rate_3.2-1.6-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-1.6-0.003125_size_16-16-32/adapters_192_slots_32_rate_3.2-1.6-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 17280, 17280, 17280, 17280, 34560, 17280, 33, 34560, 33, 17280, 17280, 33, 34560, 34560, 33, 17280, 33, 17280, 33, 33, 17280, 33, 33, 17280, 17280, 34560, 17280, 33, 17280, 34560, 34560, 17280, 34560, 33, 17280, 17280, 34560, 17280, 33, 33, 17280, 34560, 33, 17280, 33, 34560, 34560, 17280, 34560, 34560, 34560, 33, 17280, 34560, 33, 17280, 33, 17280, 33, 33, 17280, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 17280, 33, 33, 33, 33, 33, 34560, 33, 17280, 33, 34560, 34560, 33, 34560, 33, 17280, 17280, 34560, 33, 33, 33, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 33, 34560, 17280, 17280, 17280, 34560, 17280, 33, 17280, 34560, 34560, 17280, 34560, 17280, 33, 34560, 17280, 33, 17280, 17280, 33, 17280, 34560, 33, 17280, 34560, 33, 17280, 34560, 34560, 17280, 33, 34560, 17280, 33, 33, 17280, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 17280, 33, 34560, 34560, 17280, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 33, 34560, 17280, 34560, 33, 34560, 17280, 33, 17280, 33, 33, 17280, 17280, 17280, 34560, 17280, 33, 33]
Prompts retrieved: 3319872 . Total input tokens: 740232898 . Total output tokens: 652452478
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 100.38880321895704,
    "estimated_duration": 3600.0094224140926,
    "input_throughput": 6439.951200031405,
    "output_throughput": 5669.562660842468,
    "total_throughput": 12109.513860873873,
    "itl": 91.20880784560242,
    "ttft": 2054138.3968190835,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 295,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1576579533703684,
    "arrivals": 1105156,
    "finished_requests": 94330,
    "scheduler_time": 242.19993537166073
}
#Debug simulation 
Total elapsed time: 100.38897921796888. Arrivals time: 0.9445171146653593 Scheduler time: 99.15420068055391 Scheduler overhead time: 0.11484682932496071 Adapter cache time: 0.023588713724166155 Engine time: 0.11319706402719021 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.4_size_8-8-8/adapters_192_slots_32_rate_3.2-0.8-0.4_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.4_size_8-8-8/adapters_192_slots_32_rate_3.2-0.8-0.4_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 4320, 4320, 8640, 8640, 8640, 8640, 34560, 8640, 4320, 34560, 4320, 8640, 8640, 4320, 34560, 34560, 4320, 8640, 4320, 8640, 4320, 4320, 8640, 4320, 4320, 8640, 8640, 34560, 8640, 4320, 8640, 34560, 34560, 8640, 34560, 4320, 8640, 8640, 34560, 8640, 4320, 4320, 8640, 34560, 4320, 8640, 4320, 34560, 34560, 8640, 34560, 34560, 34560, 4320, 8640, 34560, 4320, 8640, 4320, 8640, 4320, 4320, 8640, 34560, 34560, 4320, 4320, 4320, 34560, 34560, 34560, 8640, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 8640, 4320, 34560, 34560, 4320, 34560, 4320, 8640, 8640, 34560, 4320, 4320, 4320, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 4320, 34560, 8640, 8640, 8640, 34560, 8640, 4320, 8640, 34560, 34560, 8640, 34560, 8640, 4320, 34560, 8640, 4320, 8640, 8640, 4320, 8640, 34560, 4320, 8640, 34560, 4320, 8640, 34560, 34560, 8640, 4320, 34560, 8640, 4320, 4320, 8640, 34560, 34560, 34560, 4320, 34560, 4320, 34560, 4320, 8640, 4320, 34560, 34560, 8640, 34560, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 34560, 8640, 34560, 4320, 34560, 8640, 4320, 8640, 4320, 4320, 8640, 8640, 8640, 34560, 8640, 4320, 4320]
Prompts retrieved: 3041280 . Total input tokens: 678087627 . Total output tokens: 597685331
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 107.18759656790644,
    "estimated_duration": 3600.005685612297,
    "input_throughput": 6821.161449311274,
    "output_throughput": 5903.852064718361,
    "total_throughput": 12725.013514029635,
    "itl": 100.06318577857989,
    "ttft": 2018584.8095719826,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 345,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.281281116022735,
    "arrivals": 1012546,
    "finished_requests": 98934,
    "scheduler_time": 231.34358564751284
}
#Debug simulation 
Total elapsed time: 107.18777344794944. Arrivals time: 0.8200587490573525 Scheduler time: 106.09203165769577 Scheduler overhead time: 0.10877683432772756 Adapter cache time: 0.02366396551951766 Engine time: 0.10818419279530644 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.4_size_8-8-16/adapters_192_slots_32_rate_3.2-0.8-0.4_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.4_size_8-8-16/adapters_192_slots_32_rate_3.2-0.8-0.4_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 4320, 4320, 8640, 8640, 8640, 8640, 34560, 8640, 4320, 34560, 4320, 8640, 8640, 4320, 34560, 34560, 4320, 8640, 4320, 8640, 4320, 4320, 8640, 4320, 4320, 8640, 8640, 34560, 8640, 4320, 8640, 34560, 34560, 8640, 34560, 4320, 8640, 8640, 34560, 8640, 4320, 4320, 8640, 34560, 4320, 8640, 4320, 34560, 34560, 8640, 34560, 34560, 34560, 4320, 8640, 34560, 4320, 8640, 4320, 8640, 4320, 4320, 8640, 34560, 34560, 4320, 4320, 4320, 34560, 34560, 34560, 8640, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 8640, 4320, 34560, 34560, 4320, 34560, 4320, 8640, 8640, 34560, 4320, 4320, 4320, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 4320, 34560, 8640, 8640, 8640, 34560, 8640, 4320, 8640, 34560, 34560, 8640, 34560, 8640, 4320, 34560, 8640, 4320, 8640, 8640, 4320, 8640, 34560, 4320, 8640, 34560, 4320, 8640, 34560, 34560, 8640, 4320, 34560, 8640, 4320, 4320, 8640, 34560, 34560, 34560, 4320, 34560, 4320, 34560, 4320, 8640, 4320, 34560, 34560, 8640, 34560, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 34560, 8640, 34560, 4320, 34560, 8640, 4320, 8640, 4320, 4320, 8640, 8640, 8640, 34560, 8640, 4320, 4320]
Prompts retrieved: 3041280 . Total input tokens: 678087627 . Total output tokens: 597685331
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 106.4355030558072,
    "estimated_duration": 3600.0670534247683,
    "input_throughput": 6751.638966523471,
    "output_throughput": 5843.566435793783,
    "total_throughput": 12595.205402317253,
    "itl": 97.42959669106409,
    "ttft": 2022126.9647406107,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 350,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.5522749320883333,
    "arrivals": 1012546,
    "finished_requests": 97867,
    "scheduler_time": 234.09437825897476
}
#Debug simulation 
Total elapsed time: 106.43567663384601. Arrivals time: 0.8346165199764073 Scheduler time: 105.32429480319843 Scheduler overhead time: 0.10997809655964375 Adapter cache time: 0.023354425095021725 Engine time: 0.10883356351405382 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.4_size_8-8-32/adapters_192_slots_32_rate_3.2-0.8-0.4_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.4_size_8-8-32/adapters_192_slots_32_rate_3.2-0.8-0.4_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 4320, 4320, 8640, 8640, 8640, 8640, 34560, 8640, 4320, 34560, 4320, 8640, 8640, 4320, 34560, 34560, 4320, 8640, 4320, 8640, 4320, 4320, 8640, 4320, 4320, 8640, 8640, 34560, 8640, 4320, 8640, 34560, 34560, 8640, 34560, 4320, 8640, 8640, 34560, 8640, 4320, 4320, 8640, 34560, 4320, 8640, 4320, 34560, 34560, 8640, 34560, 34560, 34560, 4320, 8640, 34560, 4320, 8640, 4320, 8640, 4320, 4320, 8640, 34560, 34560, 4320, 4320, 4320, 34560, 34560, 34560, 8640, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 8640, 4320, 34560, 34560, 4320, 34560, 4320, 8640, 8640, 34560, 4320, 4320, 4320, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 4320, 34560, 8640, 8640, 8640, 34560, 8640, 4320, 8640, 34560, 34560, 8640, 34560, 8640, 4320, 34560, 8640, 4320, 8640, 8640, 4320, 8640, 34560, 4320, 8640, 34560, 4320, 8640, 34560, 34560, 8640, 4320, 34560, 8640, 4320, 4320, 8640, 34560, 34560, 34560, 4320, 34560, 4320, 34560, 4320, 8640, 4320, 34560, 34560, 8640, 34560, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 34560, 8640, 34560, 4320, 34560, 8640, 4320, 8640, 4320, 4320, 8640, 8640, 8640, 34560, 8640, 4320, 4320]
Prompts retrieved: 3041280 . Total input tokens: 678087627 . Total output tokens: 597685331
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 96.06824477901682,
    "estimated_duration": 3600.05403457148,
    "input_throughput": 6568.595852427192,
    "output_throughput": 5690.285146633473,
    "total_throughput": 12258.880999060664,
    "itl": 91.24930797367813,
    "ttft": 2030878.6016944828,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 408,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.0609314603964086,
    "arrivals": 1012546,
    "finished_requests": 95167,
    "scheduler_time": 241.2240737478281
}
#Debug simulation 
Total elapsed time: 96.06841069087386. Arrivals time: 0.8111096173524857 Scheduler time: 94.97401958052069 Scheduler overhead time: 0.11105934670194983 Adapter cache time: 0.024252566043287516 Engine time: 0.11141075287014246 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.4_size_8-16-16/adapters_192_slots_32_rate_3.2-0.8-0.4_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.4_size_8-16-16/adapters_192_slots_32_rate_3.2-0.8-0.4_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 4320, 4320, 8640, 8640, 8640, 8640, 34560, 8640, 4320, 34560, 4320, 8640, 8640, 4320, 34560, 34560, 4320, 8640, 4320, 8640, 4320, 4320, 8640, 4320, 4320, 8640, 8640, 34560, 8640, 4320, 8640, 34560, 34560, 8640, 34560, 4320, 8640, 8640, 34560, 8640, 4320, 4320, 8640, 34560, 4320, 8640, 4320, 34560, 34560, 8640, 34560, 34560, 34560, 4320, 8640, 34560, 4320, 8640, 4320, 8640, 4320, 4320, 8640, 34560, 34560, 4320, 4320, 4320, 34560, 34560, 34560, 8640, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 8640, 4320, 34560, 34560, 4320, 34560, 4320, 8640, 8640, 34560, 4320, 4320, 4320, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 4320, 34560, 8640, 8640, 8640, 34560, 8640, 4320, 8640, 34560, 34560, 8640, 34560, 8640, 4320, 34560, 8640, 4320, 8640, 8640, 4320, 8640, 34560, 4320, 8640, 34560, 4320, 8640, 34560, 34560, 8640, 4320, 34560, 8640, 4320, 4320, 8640, 34560, 34560, 34560, 4320, 34560, 4320, 34560, 4320, 8640, 4320, 34560, 34560, 8640, 34560, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 34560, 8640, 34560, 4320, 34560, 8640, 4320, 8640, 4320, 4320, 8640, 8640, 8640, 34560, 8640, 4320, 4320]
Prompts retrieved: 3041280 . Total input tokens: 678087627 . Total output tokens: 597685331
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 107.6385210189037,
    "estimated_duration": 3600.0161733209125,
    "input_throughput": 6748.702458630387,
    "output_throughput": 5842.125698173964,
    "total_throughput": 12590.828156804351,
    "itl": 97.26049650510842,
    "ttft": 2023561.493887408,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 333,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.277161759301086,
    "arrivals": 1012546,
    "finished_requests": 97918,
    "scheduler_time": 234.28019350732427
}
#Debug simulation 
Total elapsed time: 107.63873781310394. Arrivals time: 0.8308778409846127 Scheduler time: 106.52174412738532 Scheduler overhead time: 0.11245490377768874 Adapter cache time: 0.024605783633887768 Engine time: 0.11308681964874268 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.4_size_8-16-32/adapters_192_slots_32_rate_3.2-0.8-0.4_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.4_size_8-16-32/adapters_192_slots_32_rate_3.2-0.8-0.4_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 4320, 4320, 8640, 8640, 8640, 8640, 34560, 8640, 4320, 34560, 4320, 8640, 8640, 4320, 34560, 34560, 4320, 8640, 4320, 8640, 4320, 4320, 8640, 4320, 4320, 8640, 8640, 34560, 8640, 4320, 8640, 34560, 34560, 8640, 34560, 4320, 8640, 8640, 34560, 8640, 4320, 4320, 8640, 34560, 4320, 8640, 4320, 34560, 34560, 8640, 34560, 34560, 34560, 4320, 8640, 34560, 4320, 8640, 4320, 8640, 4320, 4320, 8640, 34560, 34560, 4320, 4320, 4320, 34560, 34560, 34560, 8640, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 8640, 4320, 34560, 34560, 4320, 34560, 4320, 8640, 8640, 34560, 4320, 4320, 4320, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 4320, 34560, 8640, 8640, 8640, 34560, 8640, 4320, 8640, 34560, 34560, 8640, 34560, 8640, 4320, 34560, 8640, 4320, 8640, 8640, 4320, 8640, 34560, 4320, 8640, 34560, 4320, 8640, 34560, 34560, 8640, 4320, 34560, 8640, 4320, 4320, 8640, 34560, 34560, 34560, 4320, 34560, 4320, 34560, 4320, 8640, 4320, 34560, 34560, 8640, 34560, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 34560, 8640, 34560, 4320, 34560, 8640, 4320, 8640, 4320, 4320, 8640, 8640, 8640, 34560, 8640, 4320, 4320]
Prompts retrieved: 3041280 . Total input tokens: 678087627 . Total output tokens: 597685331
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 92.82930125296116,
    "estimated_duration": 3600.0721554768884,
    "input_throughput": 6576.999287077763,
    "output_throughput": 5701.514612359489,
    "total_throughput": 12278.513899437252,
    "itl": 91.40378669496816,
    "ttft": 2033892.1678356926,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 408,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.0314689523354392,
    "arrivals": 1012546,
    "finished_requests": 95388,
    "scheduler_time": 240.71550532879806
}
#Debug simulation 
Total elapsed time: 92.8294891207479. Arrivals time: 0.7972194910980761 Scheduler time: 91.75348235666752 Scheduler overhead time: 0.10934428963810205 Adapter cache time: 0.024100962560623884 Engine time: 0.10938878264278173 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.4_size_16-16-16/adapters_192_slots_32_rate_3.2-0.8-0.4_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.4_size_16-16-16/adapters_192_slots_32_rate_3.2-0.8-0.4_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 4320, 4320, 8640, 8640, 8640, 8640, 34560, 8640, 4320, 34560, 4320, 8640, 8640, 4320, 34560, 34560, 4320, 8640, 4320, 8640, 4320, 4320, 8640, 4320, 4320, 8640, 8640, 34560, 8640, 4320, 8640, 34560, 34560, 8640, 34560, 4320, 8640, 8640, 34560, 8640, 4320, 4320, 8640, 34560, 4320, 8640, 4320, 34560, 34560, 8640, 34560, 34560, 34560, 4320, 8640, 34560, 4320, 8640, 4320, 8640, 4320, 4320, 8640, 34560, 34560, 4320, 4320, 4320, 34560, 34560, 34560, 8640, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 8640, 4320, 34560, 34560, 4320, 34560, 4320, 8640, 8640, 34560, 4320, 4320, 4320, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 4320, 34560, 8640, 8640, 8640, 34560, 8640, 4320, 8640, 34560, 34560, 8640, 34560, 8640, 4320, 34560, 8640, 4320, 8640, 8640, 4320, 8640, 34560, 4320, 8640, 34560, 4320, 8640, 34560, 34560, 8640, 4320, 34560, 8640, 4320, 4320, 8640, 34560, 34560, 34560, 4320, 34560, 4320, 34560, 4320, 8640, 4320, 34560, 34560, 8640, 34560, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 34560, 8640, 34560, 4320, 34560, 8640, 4320, 8640, 4320, 4320, 8640, 8640, 8640, 34560, 8640, 4320, 4320]
Prompts retrieved: 3041280 . Total input tokens: 678087627 . Total output tokens: 597685331
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 107.67859574221075,
    "estimated_duration": 3600.102077811674,
    "input_throughput": 6748.427537579089,
    "output_throughput": 5842.080181455403,
    "total_throughput": 12590.507719034493,
    "itl": 97.27324653852081,
    "ttft": 2020979.0442023342,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 344,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.196068803556255,
    "arrivals": 1012546,
    "finished_requests": 97910,
    "scheduler_time": 234.38073639678157
}
#Debug simulation 
Total elapsed time: 107.67876496817917. Arrivals time: 0.8398020910099149 Scheduler time: 106.55741791659966 Scheduler overhead time: 0.11077907355502248 Adapter cache time: 0.023914155084639788 Engine time: 0.11118536535650492 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.4_size_16-16-32/adapters_192_slots_32_rate_3.2-0.8-0.4_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.4_size_16-16-32/adapters_192_slots_32_rate_3.2-0.8-0.4_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 4320, 4320, 8640, 8640, 8640, 8640, 34560, 8640, 4320, 34560, 4320, 8640, 8640, 4320, 34560, 34560, 4320, 8640, 4320, 8640, 4320, 4320, 8640, 4320, 4320, 8640, 8640, 34560, 8640, 4320, 8640, 34560, 34560, 8640, 34560, 4320, 8640, 8640, 34560, 8640, 4320, 4320, 8640, 34560, 4320, 8640, 4320, 34560, 34560, 8640, 34560, 34560, 34560, 4320, 8640, 34560, 4320, 8640, 4320, 8640, 4320, 4320, 8640, 34560, 34560, 4320, 4320, 4320, 34560, 34560, 34560, 8640, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 8640, 4320, 34560, 34560, 4320, 34560, 4320, 8640, 8640, 34560, 4320, 4320, 4320, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 4320, 34560, 8640, 8640, 8640, 34560, 8640, 4320, 8640, 34560, 34560, 8640, 34560, 8640, 4320, 34560, 8640, 4320, 8640, 8640, 4320, 8640, 34560, 4320, 8640, 34560, 4320, 8640, 34560, 34560, 8640, 4320, 34560, 8640, 4320, 4320, 8640, 34560, 34560, 34560, 4320, 34560, 4320, 34560, 4320, 8640, 4320, 34560, 34560, 8640, 34560, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 34560, 8640, 34560, 4320, 34560, 8640, 4320, 8640, 4320, 4320, 8640, 8640, 8640, 34560, 8640, 4320, 4320]
Prompts retrieved: 3041280 . Total input tokens: 678087627 . Total output tokens: 597685331
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 92.08988672681153,
    "estimated_duration": 3600.0052460058123,
    "input_throughput": 6570.366814393751,
    "output_throughput": 5695.35225615249,
    "total_throughput": 12265.71907054624,
    "itl": 91.43108538314688,
    "ttft": 2035115.7446707417,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 403,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.9654579245485566,
    "arrivals": 1012546,
    "finished_requests": 95285,
    "scheduler_time": 240.9157545303915
}
#Debug simulation 
Total elapsed time: 92.09004681091756. Arrivals time: 0.792878944426775 Scheduler time: 91.02080255420879 Scheduler overhead time: 0.10967338318005204 Adapter cache time: 0.023676260840147734 Engine time: 0.10724339680746198 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.1_size_8-8-8/adapters_192_slots_32_rate_3.2-0.8-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.1_size_8-8-8/adapters_192_slots_32_rate_3.2-0.8-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 8640, 8640, 8640, 8640, 34560, 8640, 1080, 34560, 1080, 8640, 8640, 1080, 34560, 34560, 1080, 8640, 1080, 8640, 1080, 1080, 8640, 1080, 1080, 8640, 8640, 34560, 8640, 1080, 8640, 34560, 34560, 8640, 34560, 1080, 8640, 8640, 34560, 8640, 1080, 1080, 8640, 34560, 1080, 8640, 1080, 34560, 34560, 8640, 34560, 34560, 34560, 1080, 8640, 34560, 1080, 8640, 1080, 8640, 1080, 1080, 8640, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 8640, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 8640, 1080, 34560, 34560, 1080, 34560, 1080, 8640, 8640, 34560, 1080, 1080, 1080, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 1080, 34560, 8640, 8640, 8640, 34560, 8640, 1080, 8640, 34560, 34560, 8640, 34560, 8640, 1080, 34560, 8640, 1080, 8640, 8640, 1080, 8640, 34560, 1080, 8640, 34560, 1080, 8640, 34560, 34560, 8640, 1080, 34560, 8640, 1080, 1080, 8640, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 1080, 8640, 1080, 34560, 34560, 8640, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 34560, 8640, 34560, 1080, 34560, 8640, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 34560, 8640, 1080, 1080]
Prompts retrieved: 2833920 . Total input tokens: 631986954 . Total output tokens: 556995452
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 107.6548616620712,
    "estimated_duration": 3600.0336722025595,
    "input_throughput": 6782.61017071568,
    "output_throughput": 5918.28631062904,
    "total_throughput": 12700.89648134472,
    "itl": 99.82865408371072,
    "ttft": 2011218.147170593,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 331,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1887073895754328,
    "arrivals": 943308,
    "finished_requests": 98716,
    "scheduler_time": 231.24595982476004
}
#Debug simulation 
Total elapsed time: 107.65502851689234. Arrivals time: 0.8387201777659357 Scheduler time: 106.53890075581148 Scheduler overhead time: 0.10979727655649185 Adapter cache time: 0.023609813768416643 Engine time: 0.10873161535710096 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.1_size_8-8-16/adapters_192_slots_32_rate_3.2-0.8-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.1_size_8-8-16/adapters_192_slots_32_rate_3.2-0.8-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 8640, 8640, 8640, 8640, 34560, 8640, 1080, 34560, 1080, 8640, 8640, 1080, 34560, 34560, 1080, 8640, 1080, 8640, 1080, 1080, 8640, 1080, 1080, 8640, 8640, 34560, 8640, 1080, 8640, 34560, 34560, 8640, 34560, 1080, 8640, 8640, 34560, 8640, 1080, 1080, 8640, 34560, 1080, 8640, 1080, 34560, 34560, 8640, 34560, 34560, 34560, 1080, 8640, 34560, 1080, 8640, 1080, 8640, 1080, 1080, 8640, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 8640, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 8640, 1080, 34560, 34560, 1080, 34560, 1080, 8640, 8640, 34560, 1080, 1080, 1080, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 1080, 34560, 8640, 8640, 8640, 34560, 8640, 1080, 8640, 34560, 34560, 8640, 34560, 8640, 1080, 34560, 8640, 1080, 8640, 8640, 1080, 8640, 34560, 1080, 8640, 34560, 1080, 8640, 34560, 34560, 8640, 1080, 34560, 8640, 1080, 1080, 8640, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 1080, 8640, 1080, 34560, 34560, 8640, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 34560, 8640, 34560, 1080, 34560, 8640, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 34560, 8640, 1080, 1080]
Prompts retrieved: 2833920 . Total input tokens: 631986954 . Total output tokens: 556995452
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 103.61101440014318,
    "estimated_duration": 3600.0950908393033,
    "input_throughput": 6666.319470579578,
    "output_throughput": 5830.457382476105,
    "total_throughput": 12496.776853055682,
    "itl": 96.81005140322426,
    "ttft": 2017074.1378237656,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 362,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.6483170770015603,
    "arrivals": 943308,
    "finished_requests": 97236,
    "scheduler_time": 235.27719071244238
}
#Debug simulation 
Total elapsed time: 103.61120542697608. Arrivals time: 0.8401567577384412 Scheduler time: 102.49370304122567 Scheduler overhead time: 0.10878935735672712 Adapter cache time: 0.024530860595405102 Engine time: 0.10896134562790394 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.1_size_8-8-32/adapters_192_slots_32_rate_3.2-0.8-0.1_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.1_size_8-8-32/adapters_192_slots_32_rate_3.2-0.8-0.1_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 8640, 8640, 8640, 8640, 34560, 8640, 1080, 34560, 1080, 8640, 8640, 1080, 34560, 34560, 1080, 8640, 1080, 8640, 1080, 1080, 8640, 1080, 1080, 8640, 8640, 34560, 8640, 1080, 8640, 34560, 34560, 8640, 34560, 1080, 8640, 8640, 34560, 8640, 1080, 1080, 8640, 34560, 1080, 8640, 1080, 34560, 34560, 8640, 34560, 34560, 34560, 1080, 8640, 34560, 1080, 8640, 1080, 8640, 1080, 1080, 8640, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 8640, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 8640, 1080, 34560, 34560, 1080, 34560, 1080, 8640, 8640, 34560, 1080, 1080, 1080, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 1080, 34560, 8640, 8640, 8640, 34560, 8640, 1080, 8640, 34560, 34560, 8640, 34560, 8640, 1080, 34560, 8640, 1080, 8640, 8640, 1080, 8640, 34560, 1080, 8640, 34560, 1080, 8640, 34560, 34560, 8640, 1080, 34560, 8640, 1080, 1080, 8640, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 1080, 8640, 1080, 34560, 34560, 8640, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 34560, 8640, 34560, 1080, 34560, 8640, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 34560, 8640, 1080, 1080]
Prompts retrieved: 2833920 . Total input tokens: 631986954 . Total output tokens: 556995452
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 102.52321390807629,
    "estimated_duration": 3600.019629743608,
    "input_throughput": 6526.511912845693,
    "output_throughput": 5703.190568842051,
    "total_throughput": 12229.702481687744,
    "itl": 91.4009905073538,
    "ttft": 2023874.0594860709,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 357,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.672975007863732,
    "arrivals": 943308,
    "finished_requests": 95045,
    "scheduler_time": 240.78041099558365
}
#Debug simulation 
Total elapsed time: 102.52338503627107. Arrivals time: 0.813264072407037 Scheduler time: 101.4263319466263 Scheduler overhead time: 0.11110591748729348 Adapter cache time: 0.02357414411380887 Engine time: 0.11124288663268089 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.1_size_8-16-16/adapters_192_slots_32_rate_3.2-0.8-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.1_size_8-16-16/adapters_192_slots_32_rate_3.2-0.8-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 8640, 8640, 8640, 8640, 34560, 8640, 1080, 34560, 1080, 8640, 8640, 1080, 34560, 34560, 1080, 8640, 1080, 8640, 1080, 1080, 8640, 1080, 1080, 8640, 8640, 34560, 8640, 1080, 8640, 34560, 34560, 8640, 34560, 1080, 8640, 8640, 34560, 8640, 1080, 1080, 8640, 34560, 1080, 8640, 1080, 34560, 34560, 8640, 34560, 34560, 34560, 1080, 8640, 34560, 1080, 8640, 1080, 8640, 1080, 1080, 8640, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 8640, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 8640, 1080, 34560, 34560, 1080, 34560, 1080, 8640, 8640, 34560, 1080, 1080, 1080, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 1080, 34560, 8640, 8640, 8640, 34560, 8640, 1080, 8640, 34560, 34560, 8640, 34560, 8640, 1080, 34560, 8640, 1080, 8640, 8640, 1080, 8640, 34560, 1080, 8640, 34560, 1080, 8640, 34560, 34560, 8640, 1080, 34560, 8640, 1080, 1080, 8640, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 1080, 8640, 1080, 34560, 34560, 8640, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 34560, 8640, 34560, 1080, 34560, 8640, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 34560, 8640, 1080, 1080]
Prompts retrieved: 2833920 . Total input tokens: 631986954 . Total output tokens: 556995452
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 95.83206533594057,
    "estimated_duration": 3600.0878863637613,
    "input_throughput": 6717.493228874034,
    "output_throughput": 5859.226681631249,
    "total_throughput": 12576.719910505284,
    "itl": 97.49715947682779,
    "ttft": 2018553.033839841,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 332,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2638367334939513,
    "arrivals": 943308,
    "finished_requests": 97832,
    "scheduler_time": 233.61831124566214
}
#Debug simulation 
Total elapsed time: 95.8322444180958. Arrivals time: 0.7877115970477462 Scheduler time: 94.7684074244462 Scheduler overhead time: 0.10896989004686475 Adapter cache time: 0.023130288813263178 Engine time: 0.1089187185280025 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.1_size_8-16-32/adapters_192_slots_32_rate_3.2-0.8-0.1_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.1_size_8-16-32/adapters_192_slots_32_rate_3.2-0.8-0.1_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 8640, 8640, 8640, 8640, 34560, 8640, 1080, 34560, 1080, 8640, 8640, 1080, 34560, 34560, 1080, 8640, 1080, 8640, 1080, 1080, 8640, 1080, 1080, 8640, 8640, 34560, 8640, 1080, 8640, 34560, 34560, 8640, 34560, 1080, 8640, 8640, 34560, 8640, 1080, 1080, 8640, 34560, 1080, 8640, 1080, 34560, 34560, 8640, 34560, 34560, 34560, 1080, 8640, 34560, 1080, 8640, 1080, 8640, 1080, 1080, 8640, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 8640, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 8640, 1080, 34560, 34560, 1080, 34560, 1080, 8640, 8640, 34560, 1080, 1080, 1080, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 1080, 34560, 8640, 8640, 8640, 34560, 8640, 1080, 8640, 34560, 34560, 8640, 34560, 8640, 1080, 34560, 8640, 1080, 8640, 8640, 1080, 8640, 34560, 1080, 8640, 34560, 1080, 8640, 34560, 34560, 8640, 1080, 34560, 8640, 1080, 1080, 8640, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 1080, 8640, 1080, 34560, 34560, 8640, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 34560, 8640, 34560, 1080, 34560, 8640, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 34560, 8640, 1080, 1080]
Prompts retrieved: 2833920 . Total input tokens: 631986954 . Total output tokens: 556995452
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 91.20795374689624,
    "estimated_duration": 3600.0025960575313,
    "input_throughput": 6522.12863004968,
    "output_throughput": 5691.062284909693,
    "total_throughput": 12213.190914959374,
    "itl": 91.22903419406178,
    "ttft": 2032700.48770213,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 349,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.595681121619434,
    "arrivals": 943308,
    "finished_requests": 95030,
    "scheduler_time": 240.94275004617842
}
#Debug simulation 
Total elapsed time: 91.208138957154. Arrivals time: 0.7856049435213208 Scheduler time: 90.14975032489747 Scheduler overhead time: 0.10543854301795363 Adapter cache time: 0.023810950107872486 Engine time: 0.10724658006802201 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.1_size_16-16-16/adapters_192_slots_32_rate_3.2-0.8-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.1_size_16-16-16/adapters_192_slots_32_rate_3.2-0.8-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 8640, 8640, 8640, 8640, 34560, 8640, 1080, 34560, 1080, 8640, 8640, 1080, 34560, 34560, 1080, 8640, 1080, 8640, 1080, 1080, 8640, 1080, 1080, 8640, 8640, 34560, 8640, 1080, 8640, 34560, 34560, 8640, 34560, 1080, 8640, 8640, 34560, 8640, 1080, 1080, 8640, 34560, 1080, 8640, 1080, 34560, 34560, 8640, 34560, 34560, 34560, 1080, 8640, 34560, 1080, 8640, 1080, 8640, 1080, 1080, 8640, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 8640, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 8640, 1080, 34560, 34560, 1080, 34560, 1080, 8640, 8640, 34560, 1080, 1080, 1080, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 1080, 34560, 8640, 8640, 8640, 34560, 8640, 1080, 8640, 34560, 34560, 8640, 34560, 8640, 1080, 34560, 8640, 1080, 8640, 8640, 1080, 8640, 34560, 1080, 8640, 34560, 1080, 8640, 34560, 34560, 8640, 1080, 34560, 8640, 1080, 1080, 8640, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 1080, 8640, 1080, 34560, 34560, 8640, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 34560, 8640, 34560, 1080, 34560, 8640, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 34560, 8640, 1080, 1080]
Prompts retrieved: 2833920 . Total input tokens: 631986954 . Total output tokens: 556995452
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 108.39536357671022,
    "estimated_duration": 3600.0338818965583,
    "input_throughput": 6707.107708464005,
    "output_throughput": 5846.137478270749,
    "total_throughput": 12553.245186734754,
    "itl": 97.29104565319929,
    "ttft": 2016864.331258819,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 328,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.093926068507127,
    "arrivals": 943308,
    "finished_requests": 97697,
    "scheduler_time": 234.17993692279762
}
#Debug simulation 
Total elapsed time: 108.39565302664414. Arrivals time: 0.839355044066906 Scheduler time: 107.279684712179 Scheduler overhead time: 0.10918780602514744 Adapter cache time: 0.0232481905259192 Engine time: 0.10835726791992784 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.1_size_16-16-32/adapters_192_slots_32_rate_3.2-0.8-0.1_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.1_size_16-16-32/adapters_192_slots_32_rate_3.2-0.8-0.1_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 8640, 8640, 8640, 8640, 34560, 8640, 1080, 34560, 1080, 8640, 8640, 1080, 34560, 34560, 1080, 8640, 1080, 8640, 1080, 1080, 8640, 1080, 1080, 8640, 8640, 34560, 8640, 1080, 8640, 34560, 34560, 8640, 34560, 1080, 8640, 8640, 34560, 8640, 1080, 1080, 8640, 34560, 1080, 8640, 1080, 34560, 34560, 8640, 34560, 34560, 34560, 1080, 8640, 34560, 1080, 8640, 1080, 8640, 1080, 1080, 8640, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 8640, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 8640, 1080, 34560, 34560, 1080, 34560, 1080, 8640, 8640, 34560, 1080, 1080, 1080, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 1080, 34560, 8640, 8640, 8640, 34560, 8640, 1080, 8640, 34560, 34560, 8640, 34560, 8640, 1080, 34560, 8640, 1080, 8640, 8640, 1080, 8640, 34560, 1080, 8640, 34560, 1080, 8640, 34560, 34560, 8640, 1080, 34560, 8640, 1080, 1080, 8640, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 1080, 8640, 1080, 34560, 34560, 8640, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 34560, 8640, 34560, 1080, 34560, 8640, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 34560, 8640, 1080, 1080]
Prompts retrieved: 2833920 . Total input tokens: 631986954 . Total output tokens: 556995452
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 69.28071130579337,
    "estimated_duration": 3600.075537079121,
    "input_throughput": 6534.4415020486795,
    "output_throughput": 5704.03559272559,
    "total_throughput": 12238.477094774269,
    "itl": 91.17527378273644,
    "ttft": 2031580.6263318823,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 365,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.687461238112318,
    "arrivals": 943308,
    "finished_requests": 95237,
    "scheduler_time": 240.85192022037035
}
#Debug simulation 
Total elapsed time: 69.28086358588189. Arrivals time: 0.46656960854306817 Scheduler time: 68.61088217422366 Scheduler overhead time: 0.07811036752536893 Adapter cache time: 0.01647339714691043 Engine time: 0.07828391855582595 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.05_size_8-8-8/adapters_192_slots_32_rate_3.2-0.8-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.05_size_8-8-8/adapters_192_slots_32_rate_3.2-0.8-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [64 64 64]
Adapter prompts. [34560, 540, 34560, 540, 34560, 540, 34560, 540, 540, 540, 8640, 8640, 8640, 8640, 34560, 8640, 540, 34560, 540, 8640, 8640, 540, 34560, 34560, 540, 8640, 540, 8640, 540, 540, 8640, 540, 540, 8640, 8640, 34560, 8640, 540, 8640, 34560, 34560, 8640, 34560, 540, 8640, 8640, 34560, 8640, 540, 540, 8640, 34560, 540, 8640, 540, 34560, 34560, 8640, 34560, 34560, 34560, 540, 8640, 34560, 540, 8640, 540, 8640, 540, 540, 8640, 34560, 34560, 540, 540, 540, 34560, 34560, 34560, 8640, 540, 540, 540, 540, 540, 34560, 540, 8640, 540, 34560, 34560, 540, 34560, 540, 8640, 8640, 34560, 540, 540, 540, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 540, 34560, 8640, 8640, 8640, 34560, 8640, 540, 8640, 34560, 34560, 8640, 34560, 8640, 540, 34560, 8640, 540, 8640, 8640, 540, 8640, 34560, 540, 8640, 34560, 540, 8640, 34560, 34560, 8640, 540, 34560, 8640, 540, 540, 8640, 34560, 34560, 34560, 540, 34560, 540, 34560, 540, 8640, 540, 34560, 34560, 8640, 34560, 540, 34560, 34560, 34560, 540, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 540, 34560, 8640, 34560, 540, 34560, 8640, 540, 8640, 540, 540, 8640, 8640, 8640, 34560, 8640, 540, 540]
Prompts retrieved: 2799360 . Total input tokens: 624241778 . Total output tokens: 550268966
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 83.84175038896501,
    "estimated_duration": 3600.061215117223,
    "input_throughput": 6802.8126569516,
    "output_throughput": 5922.5598471679705,
    "total_throughput": 12725.37250411957,
    "itl": 100.29809730442857,
    "ttft": 2001709.8152242494,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 298,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.970497891521079,
    "arrivals": 932003,
    "finished_requests": 99221,
    "scheduler_time": 230.9592799402939
}
#Debug simulation 
Total elapsed time: 83.8418973623775. Arrivals time: 0.5784885548055172 Scheduler time: 83.06586788035929 Scheduler overhead time: 0.07621558057144284 Adapter cache time: 0.015280141029506922 Engine time: 0.07653149031102657 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.05_size_8-8-16/adapters_192_slots_32_rate_3.2-0.8-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.05_size_8-8-16/adapters_192_slots_32_rate_3.2-0.8-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [64 64 64]
Adapter prompts. [34560, 540, 34560, 540, 34560, 540, 34560, 540, 540, 540, 8640, 8640, 8640, 8640, 34560, 8640, 540, 34560, 540, 8640, 8640, 540, 34560, 34560, 540, 8640, 540, 8640, 540, 540, 8640, 540, 540, 8640, 8640, 34560, 8640, 540, 8640, 34560, 34560, 8640, 34560, 540, 8640, 8640, 34560, 8640, 540, 540, 8640, 34560, 540, 8640, 540, 34560, 34560, 8640, 34560, 34560, 34560, 540, 8640, 34560, 540, 8640, 540, 8640, 540, 540, 8640, 34560, 34560, 540, 540, 540, 34560, 34560, 34560, 8640, 540, 540, 540, 540, 540, 34560, 540, 8640, 540, 34560, 34560, 540, 34560, 540, 8640, 8640, 34560, 540, 540, 540, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 540, 34560, 8640, 8640, 8640, 34560, 8640, 540, 8640, 34560, 34560, 8640, 34560, 8640, 540, 34560, 8640, 540, 8640, 8640, 540, 8640, 34560, 540, 8640, 34560, 540, 8640, 34560, 34560, 8640, 540, 34560, 8640, 540, 540, 8640, 34560, 34560, 34560, 540, 34560, 540, 34560, 540, 8640, 540, 34560, 34560, 8640, 34560, 540, 34560, 34560, 34560, 540, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 540, 34560, 8640, 34560, 540, 34560, 8640, 540, 8640, 540, 540, 8640, 8640, 8640, 34560, 8640, 540, 540]
Prompts retrieved: 2799360 . Total input tokens: 624241778 . Total output tokens: 550268966
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 104.2716255937703,
    "estimated_duration": 3600.04691925693,
    "input_throughput": 6763.435462398281,
    "output_throughput": 5879.327540644596,
    "total_throughput": 12642.763003042877,
    "itl": 98.18403452547982,
    "ttft": 2006023.0263804712,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 381,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.7904348894720936,
    "arrivals": 932003,
    "finished_requests": 98544,
    "scheduler_time": 232.59554608049953
}
#Debug simulation 
Total elapsed time: 104.27180799888447. Arrivals time: 0.8964997762814164 Scheduler time: 103.0957750165835 Scheduler overhead time: 0.11126442532986403 Adapter cache time: 0.022271144203841686 Engine time: 0.1104824235662818 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.05_size_8-8-32/adapters_192_slots_32_rate_3.2-0.8-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.05_size_8-8-32/adapters_192_slots_32_rate_3.2-0.8-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [64 64 64]
Adapter prompts. [34560, 540, 34560, 540, 34560, 540, 34560, 540, 540, 540, 8640, 8640, 8640, 8640, 34560, 8640, 540, 34560, 540, 8640, 8640, 540, 34560, 34560, 540, 8640, 540, 8640, 540, 540, 8640, 540, 540, 8640, 8640, 34560, 8640, 540, 8640, 34560, 34560, 8640, 34560, 540, 8640, 8640, 34560, 8640, 540, 540, 8640, 34560, 540, 8640, 540, 34560, 34560, 8640, 34560, 34560, 34560, 540, 8640, 34560, 540, 8640, 540, 8640, 540, 540, 8640, 34560, 34560, 540, 540, 540, 34560, 34560, 34560, 8640, 540, 540, 540, 540, 540, 34560, 540, 8640, 540, 34560, 34560, 540, 34560, 540, 8640, 8640, 34560, 540, 540, 540, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 540, 34560, 8640, 8640, 8640, 34560, 8640, 540, 8640, 34560, 34560, 8640, 34560, 8640, 540, 34560, 8640, 540, 8640, 8640, 540, 8640, 34560, 540, 8640, 34560, 540, 8640, 34560, 34560, 8640, 540, 34560, 8640, 540, 540, 8640, 34560, 34560, 34560, 540, 34560, 540, 34560, 540, 8640, 540, 34560, 34560, 8640, 34560, 540, 34560, 34560, 34560, 540, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 540, 34560, 8640, 34560, 540, 34560, 8640, 540, 8640, 540, 540, 8640, 8640, 8640, 34560, 8640, 540, 540]
Prompts retrieved: 2799360 . Total input tokens: 624241778 . Total output tokens: 550268966
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 102.36746104015037,
    "estimated_duration": 3600.0822810764353,
    "input_throughput": 6556.253484557196,
    "output_throughput": 5706.2037465037165,
    "total_throughput": 12262.457231060913,
    "itl": 91.82848496345059,
    "ttft": 2020919.4904003972,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 293,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.197117665419363,
    "arrivals": 932003,
    "finished_requests": 95599,
    "scheduler_time": 240.27558103424496
}
#Debug simulation 
Total elapsed time: 102.36764378007501. Arrivals time: 0.8057075729593635 Scheduler time: 101.27280050609261 Scheduler overhead time: 0.11477482132613659 Adapter cache time: 0.02188612660393119 Engine time: 0.11559483222663403 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.05_size_8-16-16/adapters_192_slots_32_rate_3.2-0.8-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.05_size_8-16-16/adapters_192_slots_32_rate_3.2-0.8-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [64 64 64]
Adapter prompts. [34560, 540, 34560, 540, 34560, 540, 34560, 540, 540, 540, 8640, 8640, 8640, 8640, 34560, 8640, 540, 34560, 540, 8640, 8640, 540, 34560, 34560, 540, 8640, 540, 8640, 540, 540, 8640, 540, 540, 8640, 8640, 34560, 8640, 540, 8640, 34560, 34560, 8640, 34560, 540, 8640, 8640, 34560, 8640, 540, 540, 8640, 34560, 540, 8640, 540, 34560, 34560, 8640, 34560, 34560, 34560, 540, 8640, 34560, 540, 8640, 540, 8640, 540, 540, 8640, 34560, 34560, 540, 540, 540, 34560, 34560, 34560, 8640, 540, 540, 540, 540, 540, 34560, 540, 8640, 540, 34560, 34560, 540, 34560, 540, 8640, 8640, 34560, 540, 540, 540, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 540, 34560, 8640, 8640, 8640, 34560, 8640, 540, 8640, 34560, 34560, 8640, 34560, 8640, 540, 34560, 8640, 540, 8640, 8640, 540, 8640, 34560, 540, 8640, 34560, 540, 8640, 34560, 34560, 8640, 540, 34560, 8640, 540, 540, 8640, 34560, 34560, 34560, 540, 34560, 540, 34560, 540, 8640, 540, 34560, 34560, 8640, 34560, 540, 34560, 34560, 34560, 540, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 540, 34560, 8640, 34560, 540, 34560, 8640, 540, 8640, 540, 540, 8640, 8640, 8640, 34560, 8640, 540, 540]
Prompts retrieved: 2799360 . Total input tokens: 624241778 . Total output tokens: 550268966
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 95.80707818875089,
    "estimated_duration": 3600.0918531490624,
    "input_throughput": 6759.046155646096,
    "output_throughput": 5878.927500554434,
    "total_throughput": 12637.973656200531,
    "itl": 98.02410565605348,
    "ttft": 2008912.2364106625,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 331,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.268558580339884,
    "arrivals": 932003,
    "finished_requests": 98557,
    "scheduler_time": 232.94190570010582
}
#Debug simulation 
Total elapsed time: 95.80726319365203. Arrivals time: 0.8402006747201085 Scheduler time: 94.69105463474989 Scheduler overhead time: 0.10765693057328463 Adapter cache time: 0.021871475502848625 Engine time: 0.1116884327493608 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.05_size_8-16-32/adapters_192_slots_32_rate_3.2-0.8-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.05_size_8-16-32/adapters_192_slots_32_rate_3.2-0.8-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [64 64 64]
Adapter prompts. [34560, 540, 34560, 540, 34560, 540, 34560, 540, 540, 540, 8640, 8640, 8640, 8640, 34560, 8640, 540, 34560, 540, 8640, 8640, 540, 34560, 34560, 540, 8640, 540, 8640, 540, 540, 8640, 540, 540, 8640, 8640, 34560, 8640, 540, 8640, 34560, 34560, 8640, 34560, 540, 8640, 8640, 34560, 8640, 540, 540, 8640, 34560, 540, 8640, 540, 34560, 34560, 8640, 34560, 34560, 34560, 540, 8640, 34560, 540, 8640, 540, 8640, 540, 540, 8640, 34560, 34560, 540, 540, 540, 34560, 34560, 34560, 8640, 540, 540, 540, 540, 540, 34560, 540, 8640, 540, 34560, 34560, 540, 34560, 540, 8640, 8640, 34560, 540, 540, 540, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 540, 34560, 8640, 8640, 8640, 34560, 8640, 540, 8640, 34560, 34560, 8640, 34560, 8640, 540, 34560, 8640, 540, 8640, 8640, 540, 8640, 34560, 540, 8640, 34560, 540, 8640, 34560, 34560, 8640, 540, 34560, 8640, 540, 540, 8640, 34560, 34560, 34560, 540, 34560, 540, 34560, 540, 8640, 540, 34560, 34560, 8640, 34560, 540, 34560, 34560, 34560, 540, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 540, 34560, 8640, 34560, 540, 34560, 8640, 540, 8640, 540, 540, 8640, 8640, 8640, 34560, 8640, 540, 540]
Prompts retrieved: 2799360 . Total input tokens: 624241778 . Total output tokens: 550268966
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 98.49452431919053,
    "estimated_duration": 3600.096438879298,
    "input_throughput": 6561.456450137051,
    "output_throughput": 5715.525778083156,
    "total_throughput": 12276.982228220208,
    "itl": 91.97809518577087,
    "ttft": 2017975.20948167,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 293,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.174904258539908,
    "arrivals": 932003,
    "finished_requests": 95731,
    "scheduler_time": 239.8838008065279
}
#Debug simulation 
Total elapsed time: 98.49471712810919. Arrivals time: 0.734153226017952 Scheduler time: 97.50882868096232 Scheduler overhead time: 0.09871877264231443 Adapter cache time: 0.01926417462527752 Engine time: 0.0997956832870841 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.05_size_16-16-16/adapters_192_slots_32_rate_3.2-0.8-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.05_size_16-16-16/adapters_192_slots_32_rate_3.2-0.8-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [64 64 64]
Adapter prompts. [34560, 540, 34560, 540, 34560, 540, 34560, 540, 540, 540, 8640, 8640, 8640, 8640, 34560, 8640, 540, 34560, 540, 8640, 8640, 540, 34560, 34560, 540, 8640, 540, 8640, 540, 540, 8640, 540, 540, 8640, 8640, 34560, 8640, 540, 8640, 34560, 34560, 8640, 34560, 540, 8640, 8640, 34560, 8640, 540, 540, 8640, 34560, 540, 8640, 540, 34560, 34560, 8640, 34560, 34560, 34560, 540, 8640, 34560, 540, 8640, 540, 8640, 540, 540, 8640, 34560, 34560, 540, 540, 540, 34560, 34560, 34560, 8640, 540, 540, 540, 540, 540, 34560, 540, 8640, 540, 34560, 34560, 540, 34560, 540, 8640, 8640, 34560, 540, 540, 540, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 540, 34560, 8640, 8640, 8640, 34560, 8640, 540, 8640, 34560, 34560, 8640, 34560, 8640, 540, 34560, 8640, 540, 8640, 8640, 540, 8640, 34560, 540, 8640, 34560, 540, 8640, 34560, 34560, 8640, 540, 34560, 8640, 540, 540, 8640, 34560, 34560, 34560, 540, 34560, 540, 34560, 540, 8640, 540, 34560, 34560, 8640, 34560, 540, 34560, 34560, 34560, 540, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 540, 34560, 8640, 34560, 540, 34560, 8640, 540, 8640, 540, 540, 8640, 8640, 8640, 34560, 8640, 540, 540]
Prompts retrieved: 2799360 . Total input tokens: 624241778 . Total output tokens: 550268966
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 108.49688383331522,
    "estimated_duration": 3600.080231397715,
    "input_throughput": 6748.26738252104,
    "output_throughput": 5863.655152986488,
    "total_throughput": 12611.922535507529,
    "itl": 97.82007022808291,
    "ttft": 2006153.7857260879,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 300,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9151762821711529,
    "arrivals": 932003,
    "finished_requests": 98281,
    "scheduler_time": 233.24252398682128
}
#Debug simulation 
Total elapsed time: 108.49709674995393. Arrivals time: 0.8191115059889853 Scheduler time: 107.42537295958027 Scheduler overhead time: 0.09862229926511645 Adapter cache time: 0.01945591438561678 Engine time: 0.10020845802500844 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.05_size_16-16-32/adapters_192_slots_32_rate_3.2-0.8-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.05_size_16-16-32/adapters_192_slots_32_rate_3.2-0.8-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [64 64 64]
Adapter prompts. [34560, 540, 34560, 540, 34560, 540, 34560, 540, 540, 540, 8640, 8640, 8640, 8640, 34560, 8640, 540, 34560, 540, 8640, 8640, 540, 34560, 34560, 540, 8640, 540, 8640, 540, 540, 8640, 540, 540, 8640, 8640, 34560, 8640, 540, 8640, 34560, 34560, 8640, 34560, 540, 8640, 8640, 34560, 8640, 540, 540, 8640, 34560, 540, 8640, 540, 34560, 34560, 8640, 34560, 34560, 34560, 540, 8640, 34560, 540, 8640, 540, 8640, 540, 540, 8640, 34560, 34560, 540, 540, 540, 34560, 34560, 34560, 8640, 540, 540, 540, 540, 540, 34560, 540, 8640, 540, 34560, 34560, 540, 34560, 540, 8640, 8640, 34560, 540, 540, 540, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 540, 34560, 8640, 8640, 8640, 34560, 8640, 540, 8640, 34560, 34560, 8640, 34560, 8640, 540, 34560, 8640, 540, 8640, 8640, 540, 8640, 34560, 540, 8640, 34560, 540, 8640, 34560, 34560, 8640, 540, 34560, 8640, 540, 540, 8640, 34560, 34560, 34560, 540, 34560, 540, 34560, 540, 8640, 540, 34560, 34560, 8640, 34560, 540, 34560, 34560, 34560, 540, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 540, 34560, 8640, 34560, 540, 34560, 8640, 540, 8640, 540, 540, 8640, 8640, 8640, 34560, 8640, 540, 540]
Prompts retrieved: 2799360 . Total input tokens: 624241778 . Total output tokens: 550268966
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 101.41330544883385,
    "estimated_duration": 3600.0791178213317,
    "input_throughput": 6556.196746665883,
    "output_throughput": 5706.97235466136,
    "total_throughput": 12263.169101327245,
    "itl": 91.83380782329989,
    "ttft": 2019852.3844076474,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 337,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.4791439783387013,
    "arrivals": 932003,
    "finished_requests": 95569,
    "scheduler_time": 240.24203103472166
}
#Debug simulation 
Total elapsed time: 101.41346713108942. Arrivals time: 0.7598472638055682 Scheduler time: 100.38759350497276 Scheduler overhead time: 0.10358320781961083 Adapter cache time: 0.020817700773477554 Engine time: 0.10634422907605767 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.025_size_8-8-8/adapters_192_slots_32_rate_3.2-0.8-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.025_size_8-8-8/adapters_192_slots_32_rate_3.2-0.8-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [64 64 64]
Adapter prompts. [34560, 270, 34560, 270, 34560, 270, 34560, 270, 270, 270, 8640, 8640, 8640, 8640, 34560, 8640, 270, 34560, 270, 8640, 8640, 270, 34560, 34560, 270, 8640, 270, 8640, 270, 270, 8640, 270, 270, 8640, 8640, 34560, 8640, 270, 8640, 34560, 34560, 8640, 34560, 270, 8640, 8640, 34560, 8640, 270, 270, 8640, 34560, 270, 8640, 270, 34560, 34560, 8640, 34560, 34560, 34560, 270, 8640, 34560, 270, 8640, 270, 8640, 270, 270, 8640, 34560, 34560, 270, 270, 270, 34560, 34560, 34560, 8640, 270, 270, 270, 270, 270, 34560, 270, 8640, 270, 34560, 34560, 270, 34560, 270, 8640, 8640, 34560, 270, 270, 270, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 270, 34560, 8640, 8640, 8640, 34560, 8640, 270, 8640, 34560, 34560, 8640, 34560, 8640, 270, 34560, 8640, 270, 8640, 8640, 270, 8640, 34560, 270, 8640, 34560, 270, 8640, 34560, 34560, 8640, 270, 34560, 8640, 270, 270, 8640, 34560, 34560, 34560, 270, 34560, 270, 34560, 270, 8640, 270, 34560, 34560, 8640, 34560, 270, 34560, 34560, 34560, 270, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 270, 34560, 8640, 34560, 270, 34560, 8640, 270, 8640, 270, 270, 8640, 8640, 8640, 34560, 8640, 270, 270]
Prompts retrieved: 2782080 . Total input tokens: 620399998 . Total output tokens: 546847589
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 96.13322657719254,
    "estimated_duration": 3600.025220649576,
    "input_throughput": 6815.519752267958,
    "output_throughput": 5936.148690687233,
    "total_throughput": 12751.668442955191,
    "itl": 100.83016422163874,
    "ttft": 2001066.7234229133,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 378,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.49949061407709,
    "arrivals": 926191,
    "finished_requests": 99515,
    "scheduler_time": 229.90469853891548
}
#Debug simulation 
Total elapsed time: 96.13340364722535. Arrivals time: 0.6670032097026706 Scheduler time: 95.22487442800775 Scheduler overhead time: 0.0940824099816382 Adapter cache time: 0.020005716010928154 Engine time: 0.09512829734012485 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.025_size_8-8-16/adapters_192_slots_32_rate_3.2-0.8-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.025_size_8-8-16/adapters_192_slots_32_rate_3.2-0.8-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [64 64 64]
Adapter prompts. [34560, 270, 34560, 270, 34560, 270, 34560, 270, 270, 270, 8640, 8640, 8640, 8640, 34560, 8640, 270, 34560, 270, 8640, 8640, 270, 34560, 34560, 270, 8640, 270, 8640, 270, 270, 8640, 270, 270, 8640, 8640, 34560, 8640, 270, 8640, 34560, 34560, 8640, 34560, 270, 8640, 8640, 34560, 8640, 270, 270, 8640, 34560, 270, 8640, 270, 34560, 34560, 8640, 34560, 34560, 34560, 270, 8640, 34560, 270, 8640, 270, 8640, 270, 270, 8640, 34560, 34560, 270, 270, 270, 34560, 34560, 34560, 8640, 270, 270, 270, 270, 270, 34560, 270, 8640, 270, 34560, 34560, 270, 34560, 270, 8640, 8640, 34560, 270, 270, 270, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 270, 34560, 8640, 8640, 8640, 34560, 8640, 270, 8640, 34560, 34560, 8640, 34560, 8640, 270, 34560, 8640, 270, 8640, 8640, 270, 8640, 34560, 270, 8640, 34560, 270, 8640, 34560, 34560, 8640, 270, 34560, 8640, 270, 270, 8640, 34560, 34560, 34560, 270, 34560, 270, 34560, 270, 8640, 270, 34560, 34560, 8640, 34560, 270, 34560, 34560, 34560, 270, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 270, 34560, 8640, 34560, 270, 34560, 8640, 270, 8640, 270, 270, 8640, 8640, 8640, 34560, 8640, 270, 270]
Prompts retrieved: 2782080 . Total input tokens: 620399998 . Total output tokens: 546847589
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 107.3094076779671,
    "estimated_duration": 3600.0412628391987,
    "input_throughput": 6756.434780643914,
    "output_throughput": 5881.228701057172,
    "total_throughput": 12637.663481701085,
    "itl": 98.30300227116513,
    "ttft": 2001036.8711324213,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 297,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1653393881721446,
    "arrivals": 926191,
    "finished_requests": 98712,
    "scheduler_time": 232.51537976455657
}
#Debug simulation 
Total elapsed time: 107.30956817325205. Arrivals time: 0.6835147170349956 Scheduler time: 106.37899363506585 Scheduler overhead time: 0.09776788204908371 Adapter cache time: 0.019221782684326172 Engine time: 0.09678157046437263 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.025_size_8-8-32/adapters_192_slots_32_rate_3.2-0.8-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.025_size_8-8-32/adapters_192_slots_32_rate_3.2-0.8-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [64 64 64]
Adapter prompts. [34560, 270, 34560, 270, 34560, 270, 34560, 270, 270, 270, 8640, 8640, 8640, 8640, 34560, 8640, 270, 34560, 270, 8640, 8640, 270, 34560, 34560, 270, 8640, 270, 8640, 270, 270, 8640, 270, 270, 8640, 8640, 34560, 8640, 270, 8640, 34560, 34560, 8640, 34560, 270, 8640, 8640, 34560, 8640, 270, 270, 8640, 34560, 270, 8640, 270, 34560, 34560, 8640, 34560, 34560, 34560, 270, 8640, 34560, 270, 8640, 270, 8640, 270, 270, 8640, 34560, 34560, 270, 270, 270, 34560, 34560, 34560, 8640, 270, 270, 270, 270, 270, 34560, 270, 8640, 270, 34560, 34560, 270, 34560, 270, 8640, 8640, 34560, 270, 270, 270, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 270, 34560, 8640, 8640, 8640, 34560, 8640, 270, 8640, 34560, 34560, 8640, 34560, 8640, 270, 34560, 8640, 270, 8640, 8640, 270, 8640, 34560, 270, 8640, 34560, 270, 8640, 34560, 34560, 8640, 270, 34560, 8640, 270, 270, 8640, 34560, 34560, 34560, 270, 34560, 270, 34560, 270, 8640, 270, 34560, 34560, 8640, 34560, 270, 34560, 34560, 34560, 270, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 270, 34560, 8640, 34560, 270, 34560, 8640, 270, 8640, 270, 270, 8640, 8640, 8640, 34560, 8640, 270, 270]
Prompts retrieved: 2782080 . Total input tokens: 620399998 . Total output tokens: 546847589
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 88.48705771099776,
    "estimated_duration": 3600.0252363471695,
    "input_throughput": 6587.610486881871,
    "output_throughput": 5735.0859076058305,
    "total_throughput": 12322.6963944877,
    "itl": 92.20382871960214,
    "ttft": 2017306.9886306894,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 359,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.689127154611066,
    "arrivals": 926191,
    "finished_requests": 96128,
    "scheduler_time": 239.03173091351624
}
#Debug simulation 
Total elapsed time: 88.48728243121877. Arrivals time: 0.6602590344846249 Scheduler time: 87.58171002939343 Scheduler overhead time: 0.09583288244903088 Adapter cache time: 0.019375798292458057 Engine time: 0.09652875177562237 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.025_size_8-16-16/adapters_192_slots_32_rate_3.2-0.8-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.025_size_8-16-16/adapters_192_slots_32_rate_3.2-0.8-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [64 64 64]
Adapter prompts. [34560, 270, 34560, 270, 34560, 270, 34560, 270, 270, 270, 8640, 8640, 8640, 8640, 34560, 8640, 270, 34560, 270, 8640, 8640, 270, 34560, 34560, 270, 8640, 270, 8640, 270, 270, 8640, 270, 270, 8640, 8640, 34560, 8640, 270, 8640, 34560, 34560, 8640, 34560, 270, 8640, 8640, 34560, 8640, 270, 270, 8640, 34560, 270, 8640, 270, 34560, 34560, 8640, 34560, 34560, 34560, 270, 8640, 34560, 270, 8640, 270, 8640, 270, 270, 8640, 34560, 34560, 270, 270, 270, 34560, 34560, 34560, 8640, 270, 270, 270, 270, 270, 34560, 270, 8640, 270, 34560, 34560, 270, 34560, 270, 8640, 8640, 34560, 270, 270, 270, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 270, 34560, 8640, 8640, 8640, 34560, 8640, 270, 8640, 34560, 34560, 8640, 34560, 8640, 270, 34560, 8640, 270, 8640, 8640, 270, 8640, 34560, 270, 8640, 34560, 270, 8640, 34560, 34560, 8640, 270, 34560, 8640, 270, 270, 8640, 34560, 34560, 34560, 270, 34560, 270, 34560, 270, 8640, 270, 34560, 34560, 8640, 34560, 270, 34560, 34560, 34560, 270, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 270, 34560, 8640, 34560, 270, 34560, 8640, 270, 8640, 270, 270, 8640, 8640, 8640, 34560, 8640, 270, 270]
Prompts retrieved: 2782080 . Total input tokens: 620399998 . Total output tokens: 546847589
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 107.89665322890505,
    "estimated_duration": 3600.0476631508363,
    "input_throughput": 6756.021107429695,
    "output_throughput": 5880.862694320654,
    "total_throughput": 12636.88380175035,
    "itl": 98.38052389248875,
    "ttft": 2000272.7536482713,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 346,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3754231622349447,
    "arrivals": 926191,
    "finished_requests": 98692,
    "scheduler_time": 232.20963833019613
}
#Debug simulation 
Total elapsed time: 107.8968555177562. Arrivals time: 0.6874527903273702 Scheduler time: 106.95820136275142 Scheduler overhead time: 0.0986254746094346 Adapter cache time: 0.020158749539405107 Engine time: 0.09951637499034405 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.025_size_8-16-32/adapters_192_slots_32_rate_3.2-0.8-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.025_size_8-16-32/adapters_192_slots_32_rate_3.2-0.8-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [64 64 64]
Adapter prompts. [34560, 270, 34560, 270, 34560, 270, 34560, 270, 270, 270, 8640, 8640, 8640, 8640, 34560, 8640, 270, 34560, 270, 8640, 8640, 270, 34560, 34560, 270, 8640, 270, 8640, 270, 270, 8640, 270, 270, 8640, 8640, 34560, 8640, 270, 8640, 34560, 34560, 8640, 34560, 270, 8640, 8640, 34560, 8640, 270, 270, 8640, 34560, 270, 8640, 270, 34560, 34560, 8640, 34560, 34560, 34560, 270, 8640, 34560, 270, 8640, 270, 8640, 270, 270, 8640, 34560, 34560, 270, 270, 270, 34560, 34560, 34560, 8640, 270, 270, 270, 270, 270, 34560, 270, 8640, 270, 34560, 34560, 270, 34560, 270, 8640, 8640, 34560, 270, 270, 270, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 270, 34560, 8640, 8640, 8640, 34560, 8640, 270, 8640, 34560, 34560, 8640, 34560, 8640, 270, 34560, 8640, 270, 8640, 8640, 270, 8640, 34560, 270, 8640, 34560, 270, 8640, 34560, 34560, 8640, 270, 34560, 8640, 270, 270, 8640, 34560, 34560, 34560, 270, 34560, 270, 34560, 270, 8640, 270, 34560, 34560, 8640, 34560, 270, 34560, 34560, 34560, 270, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 270, 34560, 8640, 34560, 270, 34560, 8640, 270, 8640, 270, 270, 8640, 8640, 8640, 34560, 8640, 270, 270]
Prompts retrieved: 2782080 . Total input tokens: 620399998 . Total output tokens: 546847589
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 96.64651612564921,
    "estimated_duration": 3600.098510907537,
    "input_throughput": 6580.2868805465405,
    "output_throughput": 5720.997894251506,
    "total_throughput": 12301.284774798047,
    "itl": 92.07842155572082,
    "ttft": 2015937.8590426103,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 333,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.4751632278086735,
    "arrivals": 926191,
    "finished_requests": 96015,
    "scheduler_time": 239.43110147838533
}
#Debug simulation 
Total elapsed time: 96.64668685477227. Arrivals time: 0.681810372043401 Scheduler time: 95.71487945783883 Scheduler overhead time: 0.09773829719051719 Adapter cache time: 0.02001391863450408 Engine time: 0.09820968518033624 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.025_size_16-16-16/adapters_192_slots_32_rate_3.2-0.8-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.025_size_16-16-16/adapters_192_slots_32_rate_3.2-0.8-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [64 64 64]
Adapter prompts. [34560, 270, 34560, 270, 34560, 270, 34560, 270, 270, 270, 8640, 8640, 8640, 8640, 34560, 8640, 270, 34560, 270, 8640, 8640, 270, 34560, 34560, 270, 8640, 270, 8640, 270, 270, 8640, 270, 270, 8640, 8640, 34560, 8640, 270, 8640, 34560, 34560, 8640, 34560, 270, 8640, 8640, 34560, 8640, 270, 270, 8640, 34560, 270, 8640, 270, 34560, 34560, 8640, 34560, 34560, 34560, 270, 8640, 34560, 270, 8640, 270, 8640, 270, 270, 8640, 34560, 34560, 270, 270, 270, 34560, 34560, 34560, 8640, 270, 270, 270, 270, 270, 34560, 270, 8640, 270, 34560, 34560, 270, 34560, 270, 8640, 8640, 34560, 270, 270, 270, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 270, 34560, 8640, 8640, 8640, 34560, 8640, 270, 8640, 34560, 34560, 8640, 34560, 8640, 270, 34560, 8640, 270, 8640, 8640, 270, 8640, 34560, 270, 8640, 34560, 270, 8640, 34560, 34560, 8640, 270, 34560, 8640, 270, 270, 8640, 34560, 34560, 34560, 270, 34560, 270, 34560, 270, 8640, 270, 34560, 34560, 8640, 34560, 270, 34560, 34560, 34560, 270, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 270, 34560, 8640, 34560, 270, 34560, 8640, 270, 8640, 270, 270, 8640, 8640, 8640, 34560, 8640, 270, 270]
Prompts retrieved: 2782080 . Total input tokens: 620399998 . Total output tokens: 546847589
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 107.01249099476263,
    "estimated_duration": 3600.0550947909614,
    "input_throughput": 6766.488667144817,
    "output_throughput": 5898.591671756911,
    "total_throughput": 12665.080338901727,
    "itl": 98.30829901832367,
    "ttft": 1999189.5008853131,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 307,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9598637287551464,
    "arrivals": 926191,
    "finished_requests": 98752,
    "scheduler_time": 232.46525468287675
}
#Debug simulation 
Total elapsed time: 107.01264460291713. Arrivals time: 0.6734837954863906 Scheduler time: 106.08928166888654 Scheduler overhead time: 0.09884598618373275 Adapter cache time: 0.019810143392533064 Engine time: 0.09728188486769795 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.025_size_16-16-32/adapters_192_slots_32_rate_3.2-0.8-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.025_size_16-16-32/adapters_192_slots_32_rate_3.2-0.8-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [64 64 64]
Adapter prompts. [34560, 270, 34560, 270, 34560, 270, 34560, 270, 270, 270, 8640, 8640, 8640, 8640, 34560, 8640, 270, 34560, 270, 8640, 8640, 270, 34560, 34560, 270, 8640, 270, 8640, 270, 270, 8640, 270, 270, 8640, 8640, 34560, 8640, 270, 8640, 34560, 34560, 8640, 34560, 270, 8640, 8640, 34560, 8640, 270, 270, 8640, 34560, 270, 8640, 270, 34560, 34560, 8640, 34560, 34560, 34560, 270, 8640, 34560, 270, 8640, 270, 8640, 270, 270, 8640, 34560, 34560, 270, 270, 270, 34560, 34560, 34560, 8640, 270, 270, 270, 270, 270, 34560, 270, 8640, 270, 34560, 34560, 270, 34560, 270, 8640, 8640, 34560, 270, 270, 270, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 270, 34560, 8640, 8640, 8640, 34560, 8640, 270, 8640, 34560, 34560, 8640, 34560, 8640, 270, 34560, 8640, 270, 8640, 8640, 270, 8640, 34560, 270, 8640, 34560, 270, 8640, 34560, 34560, 8640, 270, 34560, 8640, 270, 270, 8640, 34560, 34560, 34560, 270, 34560, 270, 34560, 270, 8640, 270, 34560, 34560, 8640, 34560, 270, 34560, 34560, 34560, 270, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 270, 34560, 8640, 34560, 270, 34560, 8640, 270, 8640, 270, 270, 8640, 8640, 8640, 34560, 8640, 270, 270]
Prompts retrieved: 2782080 . Total input tokens: 620399998 . Total output tokens: 546847589
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 68.46475808601826,
    "estimated_duration": 3600.0927441469603,
    "input_throughput": 6573.290934927644,
    "output_throughput": 5720.853728972506,
    "total_throughput": 12294.14466390015,
    "itl": 92.13658739911286,
    "ttft": 2016584.329962845,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 313,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2992991649173287,
    "arrivals": 926191,
    "finished_requests": 95969,
    "scheduler_time": 239.48495071930338
}
#Debug simulation 
Total elapsed time: 68.4648827672936. Arrivals time: 0.3865050682798028 Scheduler time: 67.89262414956465 Scheduler overhead time: 0.07197755854576826 Adapter cache time: 0.01414084155112505 Engine time: 0.0701783956028521 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.0125_size_8-8-8/adapters_192_slots_32_rate_3.2-0.8-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.0125_size_8-8-8/adapters_192_slots_32_rate_3.2-0.8-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 8640, 8640, 8640, 8640, 34560, 8640, 135, 34560, 135, 8640, 8640, 135, 34560, 34560, 135, 8640, 135, 8640, 135, 135, 8640, 135, 135, 8640, 8640, 34560, 8640, 135, 8640, 34560, 34560, 8640, 34560, 135, 8640, 8640, 34560, 8640, 135, 135, 8640, 34560, 135, 8640, 135, 34560, 34560, 8640, 34560, 34560, 34560, 135, 8640, 34560, 135, 8640, 135, 8640, 135, 135, 8640, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 8640, 135, 135, 135, 135, 135, 34560, 135, 8640, 135, 34560, 34560, 135, 34560, 135, 8640, 8640, 34560, 135, 135, 135, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 135, 34560, 8640, 8640, 8640, 34560, 8640, 135, 8640, 34560, 34560, 8640, 34560, 8640, 135, 34560, 8640, 135, 8640, 8640, 135, 8640, 34560, 135, 8640, 34560, 135, 8640, 34560, 34560, 8640, 135, 34560, 8640, 135, 135, 8640, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 8640, 135, 34560, 34560, 8640, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 135, 34560, 8640, 34560, 135, 34560, 8640, 135, 8640, 135, 135, 8640, 8640, 8640, 34560, 8640, 135, 135]
Prompts retrieved: 2773440 . Total input tokens: 618463244 . Total output tokens: 545160770
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 107.53150990093127,
    "estimated_duration": 3600.056193240014,
    "input_throughput": 6824.252645314774,
    "output_throughput": 5933.795989104941,
    "total_throughput": 12758.048634419714,
    "itl": 100.21490728895806,
    "ttft": 2001120.2421401844,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 306,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.023397163776679,
    "arrivals": 923294,
    "finished_requests": 99454,
    "scheduler_time": 229.9467829418011
}
#Debug simulation 
Total elapsed time: 107.53168779006228. Arrivals time: 0.6225138190202415 Scheduler time: 106.66624238109216 Scheduler overhead time: 0.09401648212224245 Adapter cache time: 0.020795312710106373 Engine time: 0.09577665803954005 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.0125_size_8-8-16/adapters_192_slots_32_rate_3.2-0.8-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.0125_size_8-8-16/adapters_192_slots_32_rate_3.2-0.8-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 8640, 8640, 8640, 8640, 34560, 8640, 135, 34560, 135, 8640, 8640, 135, 34560, 34560, 135, 8640, 135, 8640, 135, 135, 8640, 135, 135, 8640, 8640, 34560, 8640, 135, 8640, 34560, 34560, 8640, 34560, 135, 8640, 8640, 34560, 8640, 135, 135, 8640, 34560, 135, 8640, 135, 34560, 34560, 8640, 34560, 34560, 34560, 135, 8640, 34560, 135, 8640, 135, 8640, 135, 135, 8640, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 8640, 135, 135, 135, 135, 135, 34560, 135, 8640, 135, 34560, 34560, 135, 34560, 135, 8640, 8640, 34560, 135, 135, 135, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 135, 34560, 8640, 8640, 8640, 34560, 8640, 135, 8640, 34560, 34560, 8640, 34560, 8640, 135, 34560, 8640, 135, 8640, 8640, 135, 8640, 34560, 135, 8640, 34560, 135, 8640, 34560, 34560, 8640, 135, 34560, 8640, 135, 135, 8640, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 8640, 135, 34560, 34560, 8640, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 135, 34560, 8640, 34560, 135, 34560, 8640, 135, 8640, 135, 135, 8640, 8640, 8640, 34560, 8640, 135, 135]
Prompts retrieved: 2773440 . Total input tokens: 618463244 . Total output tokens: 545160770
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 99.64618106931448,
    "estimated_duration": 3600.077837265473,
    "input_throughput": 6760.455217959023,
    "output_throughput": 5877.49958652899,
    "total_throughput": 12637.954804488012,
    "itl": 97.94169625764972,
    "ttft": 2007177.0794059497,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 341,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.4878785387566342,
    "arrivals": 923294,
    "finished_requests": 98543,
    "scheduler_time": 232.43747117993001
}
#Debug simulation 
Total elapsed time: 99.64640579000115. Arrivals time: 0.6839044247753918 Scheduler time: 98.71169896004722 Scheduler overhead time: 0.09793244441971183 Adapter cache time: 0.020178869366645813 Engine time: 0.09868283849209547 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.0125_size_8-8-32/adapters_192_slots_32_rate_3.2-0.8-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.0125_size_8-8-32/adapters_192_slots_32_rate_3.2-0.8-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 8640, 8640, 8640, 8640, 34560, 8640, 135, 34560, 135, 8640, 8640, 135, 34560, 34560, 135, 8640, 135, 8640, 135, 135, 8640, 135, 135, 8640, 8640, 34560, 8640, 135, 8640, 34560, 34560, 8640, 34560, 135, 8640, 8640, 34560, 8640, 135, 135, 8640, 34560, 135, 8640, 135, 34560, 34560, 8640, 34560, 34560, 34560, 135, 8640, 34560, 135, 8640, 135, 8640, 135, 135, 8640, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 8640, 135, 135, 135, 135, 135, 34560, 135, 8640, 135, 34560, 34560, 135, 34560, 135, 8640, 8640, 34560, 135, 135, 135, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 135, 34560, 8640, 8640, 8640, 34560, 8640, 135, 8640, 34560, 34560, 8640, 34560, 8640, 135, 34560, 8640, 135, 8640, 8640, 135, 8640, 34560, 135, 8640, 34560, 135, 8640, 34560, 34560, 8640, 135, 34560, 8640, 135, 135, 8640, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 8640, 135, 34560, 34560, 8640, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 135, 34560, 8640, 34560, 135, 34560, 8640, 135, 8640, 135, 135, 8640, 8640, 8640, 34560, 8640, 135, 135]
Prompts retrieved: 2773440 . Total input tokens: 618463244 . Total output tokens: 545160770
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 93.57921850215644,
    "estimated_duration": 3600.0836768644904,
    "input_throughput": 6558.990045632988,
    "output_throughput": 5699.438358019123,
    "total_throughput": 12258.428403652111,
    "itl": 91.40153736367134,
    "ttft": 2019538.958748734,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 348,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.612251992262915,
    "arrivals": 923294,
    "finished_requests": 95489,
    "scheduler_time": 240.47139775323302
}
#Debug simulation 
Total elapsed time: 93.57942974427715. Arrivals time: 0.6824883627705276 Scheduler time: 92.647061499767 Scheduler overhead time: 0.0980164329521358 Adapter cache time: 0.020763827487826347 Engine time: 0.09754427056759596 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.0125_size_8-16-16/adapters_192_slots_32_rate_3.2-0.8-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.0125_size_8-16-16/adapters_192_slots_32_rate_3.2-0.8-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 8640, 8640, 8640, 8640, 34560, 8640, 135, 34560, 135, 8640, 8640, 135, 34560, 34560, 135, 8640, 135, 8640, 135, 135, 8640, 135, 135, 8640, 8640, 34560, 8640, 135, 8640, 34560, 34560, 8640, 34560, 135, 8640, 8640, 34560, 8640, 135, 135, 8640, 34560, 135, 8640, 135, 34560, 34560, 8640, 34560, 34560, 34560, 135, 8640, 34560, 135, 8640, 135, 8640, 135, 135, 8640, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 8640, 135, 135, 135, 135, 135, 34560, 135, 8640, 135, 34560, 34560, 135, 34560, 135, 8640, 8640, 34560, 135, 135, 135, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 135, 34560, 8640, 8640, 8640, 34560, 8640, 135, 8640, 34560, 34560, 8640, 34560, 8640, 135, 34560, 8640, 135, 8640, 8640, 135, 8640, 34560, 135, 8640, 34560, 135, 8640, 34560, 34560, 8640, 135, 34560, 8640, 135, 135, 8640, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 8640, 135, 34560, 34560, 8640, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 135, 34560, 8640, 34560, 135, 34560, 8640, 135, 8640, 135, 135, 8640, 8640, 8640, 34560, 8640, 135, 135]
Prompts retrieved: 2773440 . Total input tokens: 618463244 . Total output tokens: 545160770
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 108.46848520310596,
    "estimated_duration": 3600.013340468058,
    "input_throughput": 6756.443851632393,
    "output_throughput": 5876.591278756044,
    "total_throughput": 12633.035130388436,
    "itl": 97.92549927203974,
    "ttft": 2000614.9872969775,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 284,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9476909815333765,
    "arrivals": 923294,
    "finished_requests": 98444,
    "scheduler_time": 232.6506093800421
}
#Debug simulation 
Total elapsed time: 108.46866081794724. Arrivals time: 0.6974690482020378 Scheduler time: 107.52247158205137 Scheduler overhead time: 0.09768054354935884 Adapter cache time: 0.01982937240973115 Engine time: 0.09773433301597834 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.0125_size_8-16-32/adapters_192_slots_32_rate_3.2-0.8-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.0125_size_8-16-32/adapters_192_slots_32_rate_3.2-0.8-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 8640, 8640, 8640, 8640, 34560, 8640, 135, 34560, 135, 8640, 8640, 135, 34560, 34560, 135, 8640, 135, 8640, 135, 135, 8640, 135, 135, 8640, 8640, 34560, 8640, 135, 8640, 34560, 34560, 8640, 34560, 135, 8640, 8640, 34560, 8640, 135, 135, 8640, 34560, 135, 8640, 135, 34560, 34560, 8640, 34560, 34560, 34560, 135, 8640, 34560, 135, 8640, 135, 8640, 135, 135, 8640, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 8640, 135, 135, 135, 135, 135, 34560, 135, 8640, 135, 34560, 34560, 135, 34560, 135, 8640, 8640, 34560, 135, 135, 135, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 135, 34560, 8640, 8640, 8640, 34560, 8640, 135, 8640, 34560, 34560, 8640, 34560, 8640, 135, 34560, 8640, 135, 8640, 8640, 135, 8640, 34560, 135, 8640, 34560, 135, 8640, 34560, 34560, 8640, 135, 34560, 8640, 135, 135, 8640, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 8640, 135, 34560, 34560, 8640, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 135, 34560, 8640, 34560, 135, 34560, 8640, 135, 8640, 135, 135, 8640, 8640, 8640, 34560, 8640, 135, 135]
Prompts retrieved: 2773440 . Total input tokens: 618463244 . Total output tokens: 545160770
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 95.40256068482995,
    "estimated_duration": 3600.0787187051096,
    "input_throughput": 6567.67972243241,
    "output_throughput": 5708.411567009226,
    "total_throughput": 12276.091289441636,
    "itl": 91.8099881672327,
    "ttft": 2017124.1296865782,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 333,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.4835001426050582,
    "arrivals": 923294,
    "finished_requests": 95734,
    "scheduler_time": 240.06945704463243
}
#Debug simulation 
Total elapsed time: 95.40270583797246. Arrivals time: 0.6850234842859209 Scheduler time: 94.46805159654468 Scheduler overhead time: 0.09707384649664164 Adapter cache time: 0.020503622014075518 Engine time: 0.09781880490481853 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.0125_size_16-16-16/adapters_192_slots_32_rate_3.2-0.8-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.8-0.0125_size_16-16-16/adapters_192_slots_32_rate_3.2-0.8-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 8640, 8640, 8640, 8640, 34560, 8640, 135, 34560, 135, 8640, 8640, 135, 34560, 34560, 135, 8640, 135, 8640, 135, 135, 8640, 135, 135, 8640, 8640, 34560, 8640, 135, 8640, 34560, 34560, 8640, 34560, 135, 8640, 8640, 34560, 8640, 135, 135, 8640, 34560, 135, 8640, 135, 34560, 34560, 8640, 34560, 34560, 34560, 135, 8640, 34560, 135, 8640, 135, 8640, 135, 135, 8640, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 8640, 135, 135, 135, 135, 135, 34560, 135, 8640, 135, 34560, 34560, 135, 34560, 135, 8640, 8640, 34560, 135, 135, 135, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 135, 34560, 8640, 8640, 8640, 34560, 8640, 135, 8640, 34560, 34560, 8640, 34560, 8640, 135, 34560, 8640, 135, 8640, 8640, 135, 8640, 34560, 135, 8640, 34560, 135, 8640, 34560, 34560, 8640, 135, 34560, 8640, 135, 135, 8640, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 8640, 135, 34560, 34560, 8640, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 135, 34560, 8640, 34560, 135, 34560, 8640, 135, 8640, 135, 135, 8640, 8640, 8640, 34560, 8640, 135, 135]
Prompts retrieved: 2773440 . Total input tokens: 618463244 . Total output tokens: 545160770
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 100.01291758008301,
    "estimated_duration": 3600.0132462370493,
    "input_throughput": 6729.9052372444185,
    "output_throughput": 5855.449288147416,
    "total_throughput": 12585.354525391835,
    "itl": 97.76648034928124,
    "ttft": 2006881.346653001,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 286,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.825801389003166,
    "arrivals": 923294,
    "finished_requests": 98183,
    "scheduler_time": 233.48843665327024
}
#Debug simulation 
Total elapsed time: 100.0130673632957. Arrivals time: 0.7075437386520207 Scheduler time: 99.06343610398471 Scheduler overhead time: 0.09588203905150294 Adapter cache time: 0.01885243132710457 Engine time: 0.09490369400009513 
