INFO 05-31 19:30:52 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 05-31 19:30:52 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_8-8-8/adapters_128_slots_64_rate_0.4-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_8-8-8/adapters_128_slots_64_rate_0.4-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [42 43 43]
Adapter prompts. [4320, 540, 4320, 4320, 270, 270, 4320, 270, 540, 540, 540, 270, 4320, 540, 270, 4320, 540, 270, 270, 270, 270, 540, 540, 4320, 540, 270, 540, 540, 540, 540, 4320, 540, 270, 540, 270, 4320, 4320, 270, 540, 540, 270, 540, 270, 540, 540, 4320, 4320, 4320, 4320, 540, 540, 270, 540, 4320, 4320, 540, 270, 270, 270, 4320, 540, 540, 540, 540, 4320, 540, 4320, 270, 270, 540, 270, 4320, 4320, 270, 270, 540, 540, 540, 270, 4320, 270, 4320, 540, 270, 4320, 4320, 540, 540, 270, 270, 270, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 270, 4320, 270, 270, 4320, 540, 4320, 4320, 540, 4320, 270, 540, 4320, 270, 4320, 540, 270, 540, 540, 4320, 4320, 270, 270, 4320, 270, 270, 270, 540, 270]
Prompts retrieved: 220320 . Total input tokens: 49091549 . Total output tokens: 43375206
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 7.557232136838138,
    "estimated_duration": 3599.926750603425,
    "input_throughput": 5026.100877460111,
    "output_throughput": 4402.154293096,
    "total_throughput": 9428.25517055611,
    "itl": 87.72987781892303,
    "ttft": 42173.60280280535,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1321,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.734992331206081,
    "arrivals": 73678,
    "finished_requests": 73030,
    "scheduler_time": 57.78613441488937
}
#Debug simulation 
Total elapsed time: 7.557371665257961. Arrivals time: 0.1691051349043846 Scheduler time: 7.216960507910699 Scheduler overhead time: 0.06138044223189354 Adapter cache time: 0.02247064420953393 Engine time: 0.060186436865478754 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_8-8-16/adapters_128_slots_64_rate_0.4-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_8-8-16/adapters_128_slots_64_rate_0.4-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [42 43 43]
Adapter prompts. [4320, 540, 4320, 4320, 270, 270, 4320, 270, 540, 540, 540, 270, 4320, 540, 270, 4320, 540, 270, 270, 270, 270, 540, 540, 4320, 540, 270, 540, 540, 540, 540, 4320, 540, 270, 540, 270, 4320, 4320, 270, 540, 540, 270, 540, 270, 540, 540, 4320, 4320, 4320, 4320, 540, 540, 270, 540, 4320, 4320, 540, 270, 270, 270, 4320, 540, 540, 540, 540, 4320, 540, 4320, 270, 270, 540, 270, 4320, 4320, 270, 270, 540, 540, 540, 270, 4320, 270, 4320, 540, 270, 4320, 4320, 540, 540, 270, 270, 270, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 270, 4320, 270, 270, 4320, 540, 4320, 4320, 540, 4320, 270, 540, 4320, 270, 4320, 540, 270, 540, 540, 4320, 4320, 270, 270, 4320, 270, 270, 270, 540, 270]
Prompts retrieved: 220320 . Total input tokens: 49091549 . Total output tokens: 43375206
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 7.530080088879913,
    "estimated_duration": 3599.9433478813203,
    "input_throughput": 5025.813534162445,
    "output_throughput": 4402.617338222208,
    "total_throughput": 9428.430872384652,
    "itl": 87.80468879469583,
    "ttft": 41830.705901500296,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1310,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.554030027249787,
    "arrivals": 73678,
    "finished_requests": 73037,
    "scheduler_time": 57.78772251495994
}
#Debug simulation 
Total elapsed time: 7.530182180926204. Arrivals time: 0.17075021425262094 Scheduler time: 7.189306801185012 Scheduler overhead time: 0.06136726448312402 Adapter cache time: 0.022304524667561054 Engine time: 0.05909312190487981 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_8-8-32/adapters_128_slots_64_rate_0.4-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_8-8-32/adapters_128_slots_64_rate_0.4-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [42 43 43]
Adapter prompts. [4320, 540, 4320, 4320, 270, 270, 4320, 270, 540, 540, 540, 270, 4320, 540, 270, 4320, 540, 270, 270, 270, 270, 540, 540, 4320, 540, 270, 540, 540, 540, 540, 4320, 540, 270, 540, 270, 4320, 4320, 270, 540, 540, 270, 540, 270, 540, 540, 4320, 4320, 4320, 4320, 540, 540, 270, 540, 4320, 4320, 540, 270, 270, 270, 4320, 540, 540, 540, 540, 4320, 540, 4320, 270, 270, 540, 270, 4320, 4320, 270, 270, 540, 540, 540, 270, 4320, 270, 4320, 540, 270, 4320, 4320, 540, 540, 270, 270, 270, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 270, 4320, 270, 270, 4320, 540, 4320, 4320, 540, 4320, 270, 540, 4320, 270, 4320, 540, 270, 540, 540, 4320, 4320, 270, 270, 4320, 270, 270, 270, 540, 270]
Prompts retrieved: 220320 . Total input tokens: 49091549 . Total output tokens: 43375206
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 7.4644005270674825,
    "estimated_duration": 3599.9184955222363,
    "input_throughput": 5027.088813957904,
    "output_throughput": 4402.814124740536,
    "total_throughput": 9429.902938698438,
    "itl": 87.84973841811454,
    "ttft": 41272.711977510444,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1314,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.84299753542983,
    "arrivals": 73678,
    "finished_requests": 73050,
    "scheduler_time": 57.80981645506536
}
#Debug simulation 
Total elapsed time: 7.464536952320486. Arrivals time: 0.17299070162698627 Scheduler time: 7.120809966698289 Scheduler overhead time: 0.06133728427812457 Adapter cache time: 0.022472652606666088 Engine time: 0.059631265699863434 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_8-16-16/adapters_128_slots_64_rate_0.4-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_8-16-16/adapters_128_slots_64_rate_0.4-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [42 43 43]
Adapter prompts. [4320, 540, 4320, 4320, 270, 270, 4320, 270, 540, 540, 540, 270, 4320, 540, 270, 4320, 540, 270, 270, 270, 270, 540, 540, 4320, 540, 270, 540, 540, 540, 540, 4320, 540, 270, 540, 270, 4320, 4320, 270, 540, 540, 270, 540, 270, 540, 540, 4320, 4320, 4320, 4320, 540, 540, 270, 540, 4320, 4320, 540, 270, 270, 270, 4320, 540, 540, 540, 540, 4320, 540, 4320, 270, 270, 540, 270, 4320, 4320, 270, 270, 540, 540, 540, 270, 4320, 270, 4320, 540, 270, 4320, 4320, 540, 540, 270, 270, 270, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 270, 4320, 270, 270, 4320, 540, 4320, 4320, 540, 4320, 270, 540, 4320, 270, 4320, 540, 270, 540, 540, 4320, 4320, 270, 270, 4320, 270, 270, 270, 540, 270]
Prompts retrieved: 220320 . Total input tokens: 49091549 . Total output tokens: 43375206
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 7.551689087878913,
    "estimated_duration": 3599.9742618664186,
    "input_throughput": 5026.365380350997,
    "output_throughput": 4402.888700593756,
    "total_throughput": 9429.254080944753,
    "itl": 87.80138082009395,
    "ttft": 41126.02980172858,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1333,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.040067025586064,
    "arrivals": 73678,
    "finished_requests": 73050,
    "scheduler_time": 57.795498544178635
}
#Debug simulation 
Total elapsed time: 7.551801271736622. Arrivals time: 0.1708850208669901 Scheduler time: 7.2094611851498485 Scheduler overhead time: 0.061576506588608027 Adapter cache time: 0.022562142927199602 Engine time: 0.05987172853201628 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_8-16-32/adapters_128_slots_64_rate_0.4-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_8-16-32/adapters_128_slots_64_rate_0.4-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [42 43 43]
Adapter prompts. [4320, 540, 4320, 4320, 270, 270, 4320, 270, 540, 540, 540, 270, 4320, 540, 270, 4320, 540, 270, 270, 270, 270, 540, 540, 4320, 540, 270, 540, 540, 540, 540, 4320, 540, 270, 540, 270, 4320, 4320, 270, 540, 540, 270, 540, 270, 540, 540, 4320, 4320, 4320, 4320, 540, 540, 270, 540, 4320, 4320, 540, 270, 270, 270, 4320, 540, 540, 540, 540, 4320, 540, 4320, 270, 270, 540, 270, 4320, 4320, 270, 270, 540, 540, 540, 270, 4320, 270, 4320, 540, 270, 4320, 4320, 540, 540, 270, 270, 270, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 270, 4320, 270, 270, 4320, 540, 4320, 4320, 540, 4320, 270, 540, 4320, 270, 4320, 540, 270, 540, 540, 4320, 4320, 270, 270, 4320, 270, 270, 270, 540, 270]
Prompts retrieved: 220320 . Total input tokens: 49091549 . Total output tokens: 43375206
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 7.466320346109569,
    "estimated_duration": 3599.9350997970946,
    "input_throughput": 5025.495321018343,
    "output_throughput": 4402.173806103678,
    "total_throughput": 9427.66912712202,
    "itl": 87.82419772842788,
    "ttft": 42174.64832288742,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1306,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.679853041353578,
    "arrivals": 73678,
    "finished_requests": 73031,
    "scheduler_time": 57.803360998968905
}
#Debug simulation 
Total elapsed time: 7.466437518130988. Arrivals time: 0.17415405018255115 Scheduler time: 7.120808453299105 Scheduler overhead time: 0.06149116391316056 Adapter cache time: 0.022487143985927105 Engine time: 0.06002569245174527 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_16-16-16/adapters_128_slots_64_rate_0.4-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_16-16-16/adapters_128_slots_64_rate_0.4-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [42 43 43]
Adapter prompts. [4320, 540, 4320, 4320, 270, 270, 4320, 270, 540, 540, 540, 270, 4320, 540, 270, 4320, 540, 270, 270, 270, 270, 540, 540, 4320, 540, 270, 540, 540, 540, 540, 4320, 540, 270, 540, 270, 4320, 4320, 270, 540, 540, 270, 540, 270, 540, 540, 4320, 4320, 4320, 4320, 540, 540, 270, 540, 4320, 4320, 540, 270, 270, 270, 4320, 540, 540, 540, 540, 4320, 540, 4320, 270, 270, 540, 270, 4320, 4320, 270, 270, 540, 540, 540, 270, 4320, 270, 4320, 540, 270, 4320, 4320, 540, 540, 270, 270, 270, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 270, 4320, 270, 270, 4320, 540, 4320, 4320, 540, 4320, 270, 540, 4320, 270, 4320, 540, 270, 540, 540, 4320, 4320, 270, 270, 4320, 270, 270, 270, 540, 270]
Prompts retrieved: 220320 . Total input tokens: 49091549 . Total output tokens: 43375206
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 7.518782489001751,
    "estimated_duration": 3599.951197209138,
    "input_throughput": 5026.066746134519,
    "output_throughput": 4402.124398876774,
    "total_throughput": 9428.191145011293,
    "itl": 87.71095941393179,
    "ttft": 42171.809942442706,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1321,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.43315956249369,
    "arrivals": 73678,
    "finished_requests": 73030,
    "scheduler_time": 57.78513776780115
}
#Debug simulation 
Total elapsed time: 7.518899695016444. Arrivals time: 0.16903828596696258 Scheduler time: 7.179904903750867 Scheduler overhead time: 0.06109412480145693 Adapter cache time: 0.022414241917431355 Engine time: 0.05928600952029228 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_16-16-32/adapters_128_slots_64_rate_0.4-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.025_size_16-16-32/adapters_128_slots_64_rate_0.4-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [42 43 43]
Adapter prompts. [4320, 540, 4320, 4320, 270, 270, 4320, 270, 540, 540, 540, 270, 4320, 540, 270, 4320, 540, 270, 270, 270, 270, 540, 540, 4320, 540, 270, 540, 540, 540, 540, 4320, 540, 270, 540, 270, 4320, 4320, 270, 540, 540, 270, 540, 270, 540, 540, 4320, 4320, 4320, 4320, 540, 540, 270, 540, 4320, 4320, 540, 270, 270, 270, 4320, 540, 540, 540, 540, 4320, 540, 4320, 270, 270, 540, 270, 4320, 4320, 270, 270, 540, 540, 540, 270, 4320, 270, 4320, 540, 270, 4320, 4320, 540, 540, 270, 270, 270, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 270, 4320, 270, 270, 4320, 540, 4320, 4320, 540, 4320, 270, 540, 4320, 270, 4320, 540, 270, 540, 540, 4320, 4320, 270, 270, 4320, 270, 270, 270, 540, 270]
Prompts retrieved: 220320 . Total input tokens: 49091549 . Total output tokens: 43375206
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 7.48346764780581,
    "estimated_duration": 3599.948478030481,
    "input_throughput": 5025.418033176313,
    "output_throughput": 4402.707454488686,
    "total_throughput": 9428.125487664998,
    "itl": 87.85511818145875,
    "ttft": 42075.59762163548,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1325,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.746101745348366,
    "arrivals": 73678,
    "finished_requests": 73034,
    "scheduler_time": 57.82086024595957
}
#Debug simulation 
Total elapsed time: 7.483590242918581. Arrivals time: 0.18205802515149117 Scheduler time: 7.1311949784867465 Scheduler overhead time: 0.0609080963768065 Adapter cache time: 0.02288727182894945 Engine time: 0.05928264232352376 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-8/adapters_128_slots_64_rate_0.4-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-8/adapters_128_slots_64_rate_0.4-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [42 43 43]
Adapter prompts. [4320, 540, 4320, 4320, 135, 135, 4320, 135, 540, 540, 540, 135, 4320, 540, 135, 4320, 540, 135, 135, 135, 135, 540, 540, 4320, 540, 135, 540, 540, 540, 540, 4320, 540, 135, 540, 135, 4320, 4320, 135, 540, 540, 135, 540, 135, 540, 540, 4320, 4320, 4320, 4320, 540, 540, 135, 540, 4320, 4320, 540, 135, 135, 135, 4320, 540, 540, 540, 540, 4320, 540, 4320, 135, 135, 540, 135, 4320, 4320, 135, 135, 540, 540, 540, 135, 4320, 135, 4320, 540, 135, 4320, 4320, 540, 540, 135, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 135, 4320, 135, 135, 4320, 540, 4320, 4320, 540, 4320, 135, 540, 4320, 135, 4320, 540, 135, 540, 540, 4320, 4320, 135, 135, 4320, 135, 135, 135, 540, 135]
Prompts retrieved: 214650 . Total input tokens: 47812122 . Total output tokens: 42236124
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 6.399825789965689,
    "estimated_duration": 3600.077754729908,
    "input_throughput": 4908.3584310877495,
    "output_throughput": 4255.145595084316,
    "total_throughput": 9163.504026172064,
    "itl": 82.71455715238527,
    "ttft": 31877.11482304058,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1694,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.201420900123487,
    "arrivals": 71837,
    "finished_requests": 71320,
    "scheduler_time": 54.88818869053262
}
#Debug simulation 
Total elapsed time: 6.399926723912358. Arrivals time: 0.17067205486819148 Scheduler time: 6.048620667308569 Scheduler overhead time: 0.06341160601004958 Adapter cache time: 0.026723008137196302 Engine time: 0.06207576859742403 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-16/adapters_128_slots_64_rate_0.4-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-16/adapters_128_slots_64_rate_0.4-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [42 43 43]
Adapter prompts. [4320, 540, 4320, 4320, 135, 135, 4320, 135, 540, 540, 540, 135, 4320, 540, 135, 4320, 540, 135, 135, 135, 135, 540, 540, 4320, 540, 135, 540, 540, 540, 540, 4320, 540, 135, 540, 135, 4320, 4320, 135, 540, 540, 135, 540, 135, 540, 540, 4320, 4320, 4320, 4320, 540, 540, 135, 540, 4320, 4320, 540, 135, 135, 135, 4320, 540, 540, 540, 540, 4320, 540, 4320, 135, 135, 540, 135, 4320, 4320, 135, 135, 540, 540, 540, 135, 4320, 135, 4320, 540, 135, 4320, 4320, 540, 540, 135, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 135, 4320, 135, 135, 4320, 540, 4320, 4320, 540, 4320, 135, 540, 4320, 135, 4320, 540, 135, 540, 540, 4320, 4320, 135, 135, 4320, 135, 135, 135, 540, 135]
Prompts retrieved: 214650 . Total input tokens: 47812122 . Total output tokens: 42236124
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 6.38369464315474,
    "estimated_duration": 3600.0783132230963,
    "input_throughput": 4908.347947625595,
    "output_throughput": 4255.364096867257,
    "total_throughput": 9163.712044492853,
    "itl": 82.79739561649012,
    "ttft": 31730.23333933455,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1710,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.500464938925422,
    "arrivals": 71837,
    "finished_requests": 71321,
    "scheduler_time": 54.893628456431315
}
#Debug simulation 
Total elapsed time: 6.383795560337603. Arrivals time: 0.16686550853773952 Scheduler time: 6.037538829725236 Scheduler overhead time: 0.06273254239931703 Adapter cache time: 0.026708883699029684 Engine time: 0.061751003842800856 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-32/adapters_128_slots_64_rate_0.4-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-32/adapters_128_slots_64_rate_0.4-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [42 43 43]
Adapter prompts. [4320, 540, 4320, 4320, 135, 135, 4320, 135, 540, 540, 540, 135, 4320, 540, 135, 4320, 540, 135, 135, 135, 135, 540, 540, 4320, 540, 135, 540, 540, 540, 540, 4320, 540, 135, 540, 135, 4320, 4320, 135, 540, 540, 135, 540, 135, 540, 540, 4320, 4320, 4320, 4320, 540, 540, 135, 540, 4320, 4320, 540, 135, 135, 135, 4320, 540, 540, 540, 540, 4320, 540, 4320, 135, 135, 540, 135, 4320, 4320, 135, 135, 540, 540, 540, 135, 4320, 135, 4320, 540, 135, 4320, 4320, 540, 540, 135, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 135, 4320, 135, 135, 4320, 540, 4320, 4320, 540, 4320, 135, 540, 4320, 135, 4320, 540, 135, 540, 540, 4320, 4320, 135, 135, 4320, 135, 135, 135, 540, 135]
Prompts retrieved: 214650 . Total input tokens: 47812122 . Total output tokens: 42236124
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 6.420265791006386,
    "estimated_duration": 3600.0489292364737,
    "input_throughput": 4908.480508832349,
    "output_throughput": 4255.201054517044,
    "total_throughput": 9163.681563349393,
    "itl": 82.80596671987519,
    "ttft": 31800.765781525428,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1706,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.807179143344793,
    "arrivals": 71837,
    "finished_requests": 71320,
    "scheduler_time": 54.89819777153049
}
#Debug simulation 
Total elapsed time: 6.420358682051301. Arrivals time: 0.16728451242670417 Scheduler time: 6.073615436907858 Scheduler overhead time: 0.06309513840824366 Adapter cache time: 0.0267004887573421 Engine time: 0.061270929872989655 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-16/adapters_128_slots_64_rate_0.4-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-16/adapters_128_slots_64_rate_0.4-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [42 43 43]
Adapter prompts. [4320, 540, 4320, 4320, 135, 135, 4320, 135, 540, 540, 540, 135, 4320, 540, 135, 4320, 540, 135, 135, 135, 135, 540, 540, 4320, 540, 135, 540, 540, 540, 540, 4320, 540, 135, 540, 135, 4320, 4320, 135, 540, 540, 135, 540, 135, 540, 540, 4320, 4320, 4320, 4320, 540, 540, 135, 540, 4320, 4320, 540, 135, 135, 135, 4320, 540, 540, 540, 540, 4320, 540, 4320, 135, 135, 540, 135, 4320, 4320, 135, 135, 540, 540, 540, 135, 4320, 135, 4320, 540, 135, 4320, 4320, 540, 540, 135, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 135, 4320, 135, 135, 4320, 540, 4320, 4320, 540, 4320, 135, 540, 4320, 135, 4320, 540, 135, 540, 540, 4320, 4320, 135, 135, 4320, 135, 135, 135, 540, 135]
Prompts retrieved: 214650 . Total input tokens: 47812122 . Total output tokens: 42236124
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 6.357338041998446,
    "estimated_duration": 3600.045642411813,
    "input_throughput": 4908.208882641366,
    "output_throughput": 4254.982720090676,
    "total_throughput": 9163.19160273204,
    "itl": 82.74361789589507,
    "ttft": 31864.440936582756,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1710,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.618944620872087,
    "arrivals": 71837,
    "finished_requests": 71318,
    "scheduler_time": 54.8864979285888
}
#Debug simulation 
Total elapsed time: 6.357432212680578. Arrivals time: 0.17440228629857302 Scheduler time: 6.005090029910207 Scheduler overhead time: 0.06264779670163989 Adapter cache time: 0.026578165590763092 Engine time: 0.06050915410742164 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-32/adapters_128_slots_64_rate_0.4-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-32/adapters_128_slots_64_rate_0.4-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [42 43 43]
Adapter prompts. [4320, 540, 4320, 4320, 135, 135, 4320, 135, 540, 540, 540, 135, 4320, 540, 135, 4320, 540, 135, 135, 135, 135, 540, 540, 4320, 540, 135, 540, 540, 540, 540, 4320, 540, 135, 540, 135, 4320, 4320, 135, 540, 540, 135, 540, 135, 540, 540, 4320, 4320, 4320, 4320, 540, 540, 135, 540, 4320, 4320, 540, 135, 135, 135, 4320, 540, 540, 540, 540, 4320, 540, 4320, 135, 135, 540, 135, 4320, 4320, 135, 135, 540, 540, 540, 135, 4320, 135, 4320, 540, 135, 4320, 4320, 540, 540, 135, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 135, 4320, 135, 135, 4320, 540, 4320, 4320, 540, 4320, 135, 540, 4320, 135, 4320, 540, 135, 540, 540, 4320, 4320, 135, 135, 4320, 135, 135, 135, 540, 135]
Prompts retrieved: 214650 . Total input tokens: 47812122 . Total output tokens: 42236124
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 6.369643935002387,
    "estimated_duration": 3600.051669556784,
    "input_throughput": 4909.224817369315,
    "output_throughput": 4255.6966972327355,
    "total_throughput": 9164.92151460205,
    "itl": 82.80792763951933,
    "ttft": 31384.754171029526,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1703,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.651224398896849,
    "arrivals": 71837,
    "finished_requests": 71328,
    "scheduler_time": 54.899198283835695
}
#Debug simulation 
Total elapsed time: 6.369732844643295. Arrivals time: 0.16680130874738097 Scheduler time: 6.024627300910652 Scheduler overhead time: 0.06258317735046148 Adapter cache time: 0.02642704313620925 Engine time: 0.061118333134800196 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-16/adapters_128_slots_64_rate_0.4-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-16/adapters_128_slots_64_rate_0.4-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [42 43 43]
Adapter prompts. [4320, 540, 4320, 4320, 135, 135, 4320, 135, 540, 540, 540, 135, 4320, 540, 135, 4320, 540, 135, 135, 135, 135, 540, 540, 4320, 540, 135, 540, 540, 540, 540, 4320, 540, 135, 540, 135, 4320, 4320, 135, 540, 540, 135, 540, 135, 540, 540, 4320, 4320, 4320, 4320, 540, 540, 135, 540, 4320, 4320, 540, 135, 135, 135, 4320, 540, 540, 540, 540, 4320, 540, 4320, 135, 135, 540, 135, 4320, 4320, 135, 135, 540, 540, 540, 135, 4320, 135, 4320, 540, 135, 4320, 4320, 540, 540, 135, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 135, 4320, 135, 135, 4320, 540, 4320, 4320, 540, 4320, 135, 540, 4320, 135, 4320, 540, 135, 540, 540, 4320, 4320, 135, 135, 4320, 135, 135, 135, 540, 135]
Prompts retrieved: 214650 . Total input tokens: 47812122 . Total output tokens: 42236124
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 6.4221255029551685,
    "estimated_duration": 3600.0312323734674,
    "input_throughput": 4908.397971967059,
    "output_throughput": 4255.373915159066,
    "total_throughput": 9163.771887126126,
    "itl": 82.69561161249851,
    "ttft": 31773.893549498694,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1694,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.814362073326818,
    "arrivals": 71837,
    "finished_requests": 71321,
    "scheduler_time": 54.885218136787195
}
#Debug simulation 
Total elapsed time: 6.422242453787476. Arrivals time: 0.1678740424104035 Scheduler time: 6.074496427085251 Scheduler overhead time: 0.06281292624771595 Adapter cache time: 0.026856123469769955 Engine time: 0.06172914523631334 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-32/adapters_128_slots_64_rate_0.4-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-32/adapters_128_slots_64_rate_0.4-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [42 43 43]
Adapter prompts. [4320, 540, 4320, 4320, 135, 135, 4320, 135, 540, 540, 540, 135, 4320, 540, 135, 4320, 540, 135, 135, 135, 135, 540, 540, 4320, 540, 135, 540, 540, 540, 540, 4320, 540, 135, 540, 135, 4320, 4320, 135, 540, 540, 135, 540, 135, 540, 540, 4320, 4320, 4320, 4320, 540, 540, 135, 540, 4320, 4320, 540, 135, 135, 135, 4320, 540, 540, 540, 540, 4320, 540, 4320, 135, 135, 540, 135, 4320, 4320, 135, 135, 540, 540, 540, 135, 4320, 135, 4320, 540, 135, 4320, 4320, 540, 540, 135, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 135, 4320, 135, 135, 4320, 540, 4320, 4320, 540, 4320, 135, 540, 4320, 135, 4320, 540, 135, 540, 540, 4320, 4320, 135, 135, 4320, 135, 135, 135, 540, 135]
Prompts retrieved: 214650 . Total input tokens: 47812122 . Total output tokens: 42236124
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 6.368402635212988,
    "estimated_duration": 3600.004264783838,
    "input_throughput": 4908.414185187365,
    "output_throughput": 4255.139681319183,
    "total_throughput": 9163.553866506547,
    "itl": 82.80112589307629,
    "ttft": 31843.02233221949,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1708,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.58871939796936,
    "arrivals": 71837,
    "finished_requests": 71318,
    "scheduler_time": 54.893474849114405
}
#Debug simulation 
Total elapsed time: 6.368490654975176. Arrivals time: 0.16639088187366724 Scheduler time: 6.024749026168138 Scheduler overhead time: 0.06236444506794214 Adapter cache time: 0.02645130641758442 Engine time: 0.06042534951120615 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-8/adapters_128_slots_64_rate_0.4-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-8/adapters_128_slots_64_rate_0.4-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [42 43 43]
Adapter prompts. [4320, 540, 4320, 4320, 66, 66, 4320, 66, 540, 540, 540, 66, 4320, 540, 66, 4320, 540, 66, 66, 66, 66, 540, 540, 4320, 540, 66, 540, 540, 540, 540, 4320, 540, 66, 540, 66, 4320, 4320, 66, 540, 540, 66, 540, 66, 540, 540, 4320, 4320, 4320, 4320, 540, 540, 66, 540, 4320, 4320, 540, 66, 66, 66, 4320, 540, 540, 540, 540, 4320, 540, 4320, 66, 66, 540, 66, 4320, 4320, 66, 66, 540, 540, 540, 66, 4320, 66, 4320, 540, 66, 4320, 4320, 540, 540, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 66, 4320, 66, 66, 4320, 540, 4320, 4320, 540, 4320, 66, 540, 4320, 66, 4320, 540, 66, 540, 540, 4320, 4320, 66, 66, 4320, 66, 66, 66, 540, 66]
Prompts retrieved: 211752 . Total input tokens: 47167497 . Total output tokens: 41660537
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 5.769760997034609,
    "estimated_duration": 3600.040470721972,
    "input_throughput": 4882.246225547336,
    "output_throughput": 4195.5842226881705,
    "total_throughput": 9077.830448235507,
    "itl": 80.60865348359279,
    "ttft": 25245.335122396875,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1886,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.471003434257916,
    "arrivals": 70891,
    "finished_requests": 70460,
    "scheduler_time": 53.593700782794514
}
#Debug simulation 
Total elapsed time: 5.769883428234607. Arrivals time: 0.16774845635518432 Scheduler time: 5.420789289288223 Scheduler overhead time: 0.06268291268497705 Adapter cache time: 0.028319894801825285 Engine time: 0.06162609066814184 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-16/adapters_128_slots_64_rate_0.4-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-16/adapters_128_slots_64_rate_0.4-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [42 43 43]
Adapter prompts. [4320, 540, 4320, 4320, 66, 66, 4320, 66, 540, 540, 540, 66, 4320, 540, 66, 4320, 540, 66, 66, 66, 66, 540, 540, 4320, 540, 66, 540, 540, 540, 540, 4320, 540, 66, 540, 66, 4320, 4320, 66, 540, 540, 66, 540, 66, 540, 540, 4320, 4320, 4320, 4320, 540, 540, 66, 540, 4320, 4320, 540, 66, 66, 66, 4320, 540, 540, 540, 540, 4320, 540, 4320, 66, 66, 540, 66, 4320, 4320, 66, 66, 540, 540, 540, 66, 4320, 66, 4320, 540, 66, 4320, 4320, 540, 540, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 66, 4320, 66, 66, 4320, 540, 4320, 4320, 540, 4320, 66, 540, 4320, 66, 4320, 540, 66, 540, 540, 4320, 4320, 66, 66, 4320, 66, 66, 66, 540, 66]
Prompts retrieved: 211752 . Total input tokens: 47167497 . Total output tokens: 41660537
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 5.762607126031071,
    "estimated_duration": 3600.0213503664077,
    "input_throughput": 4882.726597777241,
    "output_throughput": 4195.585672974607,
    "total_throughput": 9078.312270751849,
    "itl": 80.6915037368862,
    "ttft": 25115.33476837791,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1888,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.788118952438039,
    "arrivals": 70891,
    "finished_requests": 70463,
    "scheduler_time": 53.60784437426355
}
#Debug simulation 
Total elapsed time: 5.762714186683297. Arrivals time: 0.16582142561674118 Scheduler time: 5.41547437151894 Scheduler overhead time: 0.06297209300100803 Adapter cache time: 0.02847603801637888 Engine time: 0.06128077255561948 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-32/adapters_128_slots_64_rate_0.4-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-32/adapters_128_slots_64_rate_0.4-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [42 43 43]
Adapter prompts. [4320, 540, 4320, 4320, 66, 66, 4320, 66, 540, 540, 540, 66, 4320, 540, 66, 4320, 540, 66, 66, 66, 66, 540, 540, 4320, 540, 66, 540, 540, 540, 540, 4320, 540, 66, 540, 66, 4320, 4320, 66, 540, 540, 66, 540, 66, 540, 540, 4320, 4320, 4320, 4320, 540, 540, 66, 540, 4320, 4320, 540, 66, 66, 66, 4320, 540, 540, 540, 540, 4320, 540, 4320, 66, 66, 540, 66, 4320, 4320, 66, 66, 540, 540, 540, 66, 4320, 66, 4320, 540, 66, 4320, 4320, 540, 540, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 66, 4320, 66, 66, 4320, 540, 4320, 4320, 540, 4320, 66, 540, 4320, 66, 4320, 540, 66, 540, 540, 4320, 4320, 66, 66, 4320, 66, 66, 66, 540, 66]
Prompts retrieved: 211752 . Total input tokens: 47167497 . Total output tokens: 41660537
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 5.769719311967492,
    "estimated_duration": 3600.075648987979,
    "input_throughput": 4882.861560129038,
    "output_throughput": 4196.013493284913,
    "total_throughput": 9078.87505341395,
    "itl": 80.69973003634598,
    "ttft": 25151.801588596216,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1865,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.988746426081972,
    "arrivals": 70891,
    "finished_requests": 70462,
    "scheduler_time": 53.606461283261176
}
#Debug simulation 
Total elapsed time: 5.769809513818473. Arrivals time: 0.16517748683691025 Scheduler time: 5.423873847350478 Scheduler overhead time: 0.06265084305778146 Adapter cache time: 0.028133278712630272 Engine time: 0.061378803569823503 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-16/adapters_128_slots_64_rate_0.4-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-16/adapters_128_slots_64_rate_0.4-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [42 43 43]
Adapter prompts. [4320, 540, 4320, 4320, 66, 66, 4320, 66, 540, 540, 540, 66, 4320, 540, 66, 4320, 540, 66, 66, 66, 66, 540, 540, 4320, 540, 66, 540, 540, 540, 540, 4320, 540, 66, 540, 66, 4320, 4320, 66, 540, 540, 66, 540, 66, 540, 540, 4320, 4320, 4320, 4320, 540, 540, 66, 540, 4320, 4320, 540, 66, 66, 66, 4320, 540, 540, 540, 540, 4320, 540, 4320, 66, 66, 540, 66, 4320, 4320, 66, 66, 540, 540, 540, 66, 4320, 66, 4320, 540, 66, 4320, 4320, 540, 540, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 66, 4320, 66, 66, 4320, 540, 4320, 4320, 540, 4320, 66, 540, 4320, 66, 4320, 540, 66, 540, 540, 4320, 4320, 66, 66, 4320, 66, 66, 66, 540, 66]
Prompts retrieved: 211752 . Total input tokens: 47167497 . Total output tokens: 41660537
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 5.761771015357226,
    "estimated_duration": 3600.015141515478,
    "input_throughput": 4882.340853877887,
    "output_throughput": 4195.672075323981,
    "total_throughput": 9078.012929201868,
    "itl": 80.63123319998911,
    "ttft": 25195.748900064187,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1886,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.806372871184953,
    "arrivals": 70891,
    "finished_requests": 70461,
    "scheduler_time": 53.59376680582942
}
#Debug simulation 
Total elapsed time: 5.761862128041685. Arrivals time: 0.17454965505748987 Scheduler time: 5.406510150525719 Scheduler overhead time: 0.06278798542916775 Adapter cache time: 0.028226768597960472 Engine time: 0.06126619968563318 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-32/adapters_128_slots_64_rate_0.4-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-32/adapters_128_slots_64_rate_0.4-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [42 43 43]
Adapter prompts. [4320, 540, 4320, 4320, 66, 66, 4320, 66, 540, 540, 540, 66, 4320, 540, 66, 4320, 540, 66, 66, 66, 66, 540, 540, 4320, 540, 66, 540, 540, 540, 540, 4320, 540, 66, 540, 66, 4320, 4320, 66, 540, 540, 66, 540, 66, 540, 540, 4320, 4320, 4320, 4320, 540, 540, 66, 540, 4320, 4320, 540, 66, 66, 66, 4320, 540, 540, 540, 540, 4320, 540, 4320, 66, 66, 540, 66, 4320, 4320, 66, 66, 540, 540, 540, 66, 4320, 66, 4320, 540, 66, 4320, 4320, 540, 540, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 66, 4320, 66, 66, 4320, 540, 4320, 4320, 540, 4320, 66, 540, 4320, 66, 4320, 540, 66, 540, 540, 4320, 4320, 66, 66, 4320, 66, 66, 66, 540, 66]
Prompts retrieved: 211752 . Total input tokens: 47167497 . Total output tokens: 41660537
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 5.742375246714801,
    "estimated_duration": 3600.0132953179077,
    "input_throughput": 4882.737522903437,
    "output_throughput": 4195.595060619405,
    "total_throughput": 9078.332583522842,
    "itl": 80.7006795514339,
    "ttft": 25103.24794781558,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1889,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.018327189744207,
    "arrivals": 70891,
    "finished_requests": 70463,
    "scheduler_time": 53.60812540268626
}
#Debug simulation 
Total elapsed time: 5.7424669759348035. Arrivals time: 0.16512328200042248 Scheduler time: 5.395675414707512 Scheduler overhead time: 0.06309084920212626 Adapter cache time: 0.028512284625321627 Engine time: 0.0615520472638309 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-16/adapters_128_slots_64_rate_0.4-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-16/adapters_128_slots_64_rate_0.4-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [42 43 43]
Adapter prompts. [4320, 540, 4320, 4320, 66, 66, 4320, 66, 540, 540, 540, 66, 4320, 540, 66, 4320, 540, 66, 66, 66, 66, 540, 540, 4320, 540, 66, 540, 540, 540, 540, 4320, 540, 66, 540, 66, 4320, 4320, 66, 540, 540, 66, 540, 66, 540, 540, 4320, 4320, 4320, 4320, 540, 540, 66, 540, 4320, 4320, 540, 66, 66, 66, 4320, 540, 540, 540, 540, 4320, 540, 4320, 66, 66, 540, 66, 4320, 4320, 66, 66, 540, 540, 540, 66, 4320, 66, 4320, 540, 66, 4320, 4320, 540, 540, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 66, 4320, 66, 66, 4320, 540, 4320, 4320, 540, 4320, 66, 540, 4320, 66, 4320, 540, 66, 540, 540, 4320, 4320, 66, 66, 4320, 66, 66, 66, 540, 66]
Prompts retrieved: 211752 . Total input tokens: 47167497 . Total output tokens: 41660537
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 5.777459392789751,
    "estimated_duration": 3600.0742327495927,
    "input_throughput": 4882.237938348242,
    "output_throughput": 4195.478210587937,
    "total_throughput": 9077.716148936179,
    "itl": 80.5939457211916,
    "ttft": 25393.678776101733,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1888,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.052842735797666,
    "arrivals": 70891,
    "finished_requests": 70457,
    "scheduler_time": 53.59247352385588
}
#Debug simulation 
Total elapsed time: 5.777547169942409. Arrivals time: 0.1679171654395759 Scheduler time: 5.4270671885460615 Scheduler overhead time: 0.0634381016716361 Adapter cache time: 0.02863120147958398 Engine time: 0.06170232221484184 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-32/adapters_128_slots_64_rate_0.4-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-32/adapters_128_slots_64_rate_0.4-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [42 43 43]
Adapter prompts. [4320, 540, 4320, 4320, 66, 66, 4320, 66, 540, 540, 540, 66, 4320, 540, 66, 4320, 540, 66, 66, 66, 66, 540, 540, 4320, 540, 66, 540, 540, 540, 540, 4320, 540, 66, 540, 66, 4320, 4320, 66, 540, 540, 66, 540, 66, 540, 540, 4320, 4320, 4320, 4320, 540, 540, 66, 540, 4320, 4320, 540, 66, 66, 66, 4320, 540, 540, 540, 540, 4320, 540, 4320, 66, 66, 540, 66, 4320, 4320, 66, 66, 540, 540, 540, 66, 4320, 66, 4320, 540, 66, 4320, 4320, 540, 540, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 66, 4320, 66, 66, 4320, 540, 4320, 4320, 540, 4320, 66, 540, 4320, 66, 4320, 540, 66, 540, 540, 4320, 4320, 66, 66, 4320, 66, 66, 66, 540, 66]
Prompts retrieved: 211752 . Total input tokens: 47167497 . Total output tokens: 41660537
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 5.779524012003094,
    "estimated_duration": 3600.0364951656916,
    "input_throughput": 4882.862444201681,
    "output_throughput": 4195.6538552548245,
    "total_throughput": 9078.516299456505,
    "itl": 80.68477310398,
    "ttft": 25030.844328273368,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1865,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.728037410955642,
    "arrivals": 70891,
    "finished_requests": 70465,
    "scheduler_time": 53.60878678686147
}
#Debug simulation 
Total elapsed time: 5.779615054838359. Arrivals time: 0.17307481449097395 Scheduler time: 5.424454686231911 Scheduler overhead time: 0.06326949642971158 Adapter cache time: 0.02817362453788519 Engine time: 0.062033687718212605 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-8/adapters_128_slots_64_rate_0.4-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-8/adapters_128_slots_64_rate_0.4-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [42 43 43]
Adapter prompts. [4320, 540, 4320, 4320, 33, 33, 4320, 33, 540, 540, 540, 33, 4320, 540, 33, 4320, 540, 33, 33, 33, 33, 540, 540, 4320, 540, 33, 540, 540, 540, 540, 4320, 540, 33, 540, 33, 4320, 4320, 33, 540, 540, 33, 540, 33, 540, 540, 4320, 4320, 4320, 4320, 540, 540, 33, 540, 4320, 4320, 540, 33, 33, 33, 4320, 540, 540, 540, 540, 4320, 540, 4320, 33, 33, 540, 33, 4320, 4320, 33, 33, 540, 540, 540, 33, 4320, 33, 4320, 540, 33, 4320, 4320, 540, 540, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 33, 4320, 33, 33, 4320, 540, 4320, 4320, 540, 4320, 33, 540, 4320, 33, 4320, 540, 33, 540, 540, 4320, 4320, 33, 33, 4320, 33, 33, 33, 540, 33]
Prompts retrieved: 210366 . Total input tokens: 46860121 . Total output tokens: 41379612
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 5.492753142956644,
    "estimated_duration": 3600.0578154450286,
    "input_throughput": 4786.538962255486,
    "output_throughput": 4211.822358782207,
    "total_throughput": 8998.361321037693,
    "itl": 81.30064985336965,
    "ttft": 25788.36992431475,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1839,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.16022020975626,
    "arrivals": 70422,
    "finished_requests": 69962,
    "scheduler_time": 53.837187197012135
}
#Debug simulation 
Total elapsed time: 5.492867687251419. Arrivals time: 0.16253665182739496 Scheduler time: 5.151776163838804 Scheduler overhead time: 0.06188881304115057 Adapter cache time: 0.027692871168255806 Engine time: 0.060688105411827564 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-16/adapters_128_slots_64_rate_0.4-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-16/adapters_128_slots_64_rate_0.4-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [42 43 43]
Adapter prompts. [4320, 540, 4320, 4320, 33, 33, 4320, 33, 540, 540, 540, 33, 4320, 540, 33, 4320, 540, 33, 33, 33, 33, 540, 540, 4320, 540, 33, 540, 540, 540, 540, 4320, 540, 33, 540, 33, 4320, 4320, 33, 540, 540, 33, 540, 33, 540, 540, 4320, 4320, 4320, 4320, 540, 540, 33, 540, 4320, 4320, 540, 33, 33, 33, 4320, 540, 540, 540, 540, 4320, 540, 4320, 33, 33, 540, 33, 4320, 4320, 33, 33, 540, 540, 540, 33, 4320, 33, 4320, 540, 33, 4320, 4320, 540, 540, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 33, 4320, 33, 33, 4320, 540, 4320, 4320, 540, 4320, 33, 540, 4320, 33, 4320, 540, 33, 540, 540, 4320, 4320, 33, 33, 4320, 33, 33, 33, 540, 33]
Prompts retrieved: 210366 . Total input tokens: 46860121 . Total output tokens: 41379612
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 5.476446685846895,
    "estimated_duration": 3600.0873850338307,
    "input_throughput": 4786.854083498325,
    "output_throughput": 4211.812486284277,
    "total_throughput": 8998.666569782603,
    "itl": 81.37177980388878,
    "ttft": 25691.211956423853,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1838,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.400900077717193,
    "arrivals": 70422,
    "finished_requests": 69965,
    "scheduler_time": 53.84523629437668
}
#Debug simulation 
Total elapsed time: 5.47653692914173. Arrivals time: 0.16457130573689938 Scheduler time: 5.133711821399629 Scheduler overhead time: 0.06157682603225112 Adapter cache time: 0.02823411813005805 Engine time: 0.060133067425340414 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-32/adapters_128_slots_64_rate_0.4-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-32/adapters_128_slots_64_rate_0.4-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [42 43 43]
Adapter prompts. [4320, 540, 4320, 4320, 33, 33, 4320, 33, 540, 540, 540, 33, 4320, 540, 33, 4320, 540, 33, 33, 33, 33, 540, 540, 4320, 540, 33, 540, 540, 540, 540, 4320, 540, 33, 540, 33, 4320, 4320, 33, 540, 540, 33, 540, 33, 540, 540, 4320, 4320, 4320, 4320, 540, 540, 33, 540, 4320, 4320, 540, 33, 33, 33, 4320, 540, 540, 540, 540, 4320, 540, 4320, 33, 33, 540, 33, 4320, 4320, 33, 33, 540, 540, 540, 33, 4320, 33, 4320, 540, 33, 4320, 4320, 540, 540, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 33, 4320, 33, 33, 4320, 540, 4320, 4320, 540, 4320, 33, 540, 4320, 33, 4320, 540, 33, 540, 540, 4320, 4320, 33, 33, 4320, 33, 33, 33, 540, 33]
Prompts retrieved: 210366 . Total input tokens: 46860121 . Total output tokens: 41379612
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 5.495811624452472,
    "estimated_duration": 3600.037999632804,
    "input_throughput": 4786.623363908278,
    "output_throughput": 4211.638877574764,
    "total_throughput": 8998.262241483042,
    "itl": 81.40223467556335,
    "ttft": 25799.40882296273,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1846,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.826757000009287,
    "arrivals": 70422,
    "finished_requests": 69962,
    "scheduler_time": 53.84605715823442
}
#Debug simulation 
Total elapsed time: 5.495925466064364. Arrivals time: 0.1628194861114025 Scheduler time: 5.154082584194839 Scheduler overhead time: 0.06217580335214734 Adapter cache time: 0.02780180238187313 Engine time: 0.060677912551909685 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-16/adapters_128_slots_64_rate_0.4-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-16/adapters_128_slots_64_rate_0.4-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [42 43 43]
Adapter prompts. [4320, 540, 4320, 4320, 33, 33, 4320, 33, 540, 540, 540, 33, 4320, 540, 33, 4320, 540, 33, 33, 33, 33, 540, 540, 4320, 540, 33, 540, 540, 540, 540, 4320, 540, 33, 540, 33, 4320, 4320, 33, 540, 540, 33, 540, 33, 540, 540, 4320, 4320, 4320, 4320, 540, 540, 33, 540, 4320, 4320, 540, 33, 33, 33, 4320, 540, 540, 540, 540, 4320, 540, 4320, 33, 33, 540, 33, 4320, 4320, 33, 33, 540, 540, 540, 33, 4320, 33, 4320, 540, 33, 4320, 4320, 540, 540, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 33, 4320, 33, 33, 4320, 540, 4320, 4320, 540, 4320, 33, 540, 4320, 33, 4320, 540, 33, 540, 540, 4320, 4320, 33, 33, 4320, 33, 33, 33, 540, 33]
Prompts retrieved: 210366 . Total input tokens: 46860121 . Total output tokens: 41379612
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 5.484549089334905,
    "estimated_duration": 3600.0875975112194,
    "input_throughput": 4786.689638305751,
    "output_throughput": 4211.869736303755,
    "total_throughput": 8998.559374609507,
    "itl": 81.32269010825262,
    "ttft": 25789.61938386861,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1839,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.53548122741767,
    "arrivals": 70422,
    "finished_requests": 69963,
    "scheduler_time": 53.839884794497316
}
#Debug simulation 
Total elapsed time: 5.4846499199047685. Arrivals time: 0.16479290649294853 Scheduler time: 5.141190788708627 Scheduler overhead time: 0.06204183446243405 Adapter cache time: 0.02757130330428481 Engine time: 0.06074580457061529 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-32/adapters_128_slots_64_rate_0.4-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-32/adapters_128_slots_64_rate_0.4-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [42 43 43]
Adapter prompts. [4320, 540, 4320, 4320, 33, 33, 4320, 33, 540, 540, 540, 33, 4320, 540, 33, 4320, 540, 33, 33, 33, 33, 540, 540, 4320, 540, 33, 540, 540, 540, 540, 4320, 540, 33, 540, 33, 4320, 4320, 33, 540, 540, 33, 540, 33, 540, 540, 4320, 4320, 4320, 4320, 540, 540, 33, 540, 4320, 4320, 540, 33, 33, 33, 4320, 540, 540, 540, 540, 4320, 540, 4320, 33, 33, 540, 33, 4320, 4320, 33, 33, 540, 540, 540, 33, 4320, 33, 4320, 540, 33, 4320, 4320, 540, 540, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 33, 4320, 33, 33, 4320, 540, 4320, 4320, 540, 4320, 33, 540, 4320, 33, 4320, 540, 33, 540, 540, 4320, 4320, 33, 33, 4320, 33, 33, 33, 540, 33]
Prompts retrieved: 210366 . Total input tokens: 46860121 . Total output tokens: 41379612
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 5.508322247304022,
    "estimated_duration": 3600.013109773248,
    "input_throughput": 4786.656180006351,
    "output_throughput": 4211.6582739208425,
    "total_throughput": 8998.314453927193,
    "itl": 81.3934462779043,
    "ttft": 25850.121127320414,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1840,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.648075724658327,
    "arrivals": 70422,
    "finished_requests": 69961,
    "scheduler_time": 53.84471510007029
}
#Debug simulation 
Total elapsed time: 5.508413420990109. Arrivals time: 0.16461733542382717 Scheduler time: 5.1632248582318425 Scheduler overhead time: 0.06250108359381557 Adapter cache time: 0.028003251645714045 Engine time: 0.061573006212711334 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-16/adapters_128_slots_64_rate_0.4-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-16/adapters_128_slots_64_rate_0.4-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [42 43 43]
Adapter prompts. [4320, 540, 4320, 4320, 33, 33, 4320, 33, 540, 540, 540, 33, 4320, 540, 33, 4320, 540, 33, 33, 33, 33, 540, 540, 4320, 540, 33, 540, 540, 540, 540, 4320, 540, 33, 540, 33, 4320, 4320, 33, 540, 540, 33, 540, 33, 540, 540, 4320, 4320, 4320, 4320, 540, 540, 33, 540, 4320, 4320, 540, 33, 33, 33, 4320, 540, 540, 540, 540, 4320, 540, 4320, 33, 33, 540, 33, 4320, 4320, 33, 33, 540, 540, 540, 33, 4320, 33, 4320, 540, 33, 4320, 4320, 540, 540, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 33, 4320, 33, 33, 4320, 540, 4320, 4320, 540, 4320, 33, 540, 4320, 33, 4320, 540, 33, 540, 540, 4320, 4320, 33, 33, 4320, 33, 33, 33, 540, 33]
Prompts retrieved: 210366 . Total input tokens: 46860121 . Total output tokens: 41379612
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 5.483150626067072,
    "estimated_duration": 3600.017711698397,
    "input_throughput": 4786.566172717665,
    "output_throughput": 4211.812611568144,
    "total_throughput": 8998.37878428581,
    "itl": 81.27502857520216,
    "ttft": 25838.221266079672,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1839,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.740030609709668,
    "arrivals": 70422,
    "finished_requests": 69961,
    "scheduler_time": 53.83425632153746
}
#Debug simulation 
Total elapsed time: 5.483238832093775. Arrivals time: 0.1634664204902947 Scheduler time: 5.141816815827042 Scheduler overhead time: 0.06173163605853915 Adapter cache time: 0.02761552343145013 Engine time: 0.060351576656103134 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-32/adapters_128_slots_64_rate_0.4-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-32/adapters_128_slots_64_rate_0.4-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [42 43 43]
Adapter prompts. [4320, 540, 4320, 4320, 33, 33, 4320, 33, 540, 540, 540, 33, 4320, 540, 33, 4320, 540, 33, 33, 33, 33, 540, 540, 4320, 540, 33, 540, 540, 540, 540, 4320, 540, 33, 540, 33, 4320, 4320, 33, 540, 540, 33, 540, 33, 540, 540, 4320, 4320, 4320, 4320, 540, 540, 33, 540, 4320, 4320, 540, 33, 33, 33, 4320, 540, 540, 540, 540, 4320, 540, 4320, 33, 33, 540, 33, 4320, 4320, 33, 33, 540, 540, 540, 33, 4320, 33, 4320, 540, 33, 4320, 4320, 540, 540, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 33, 4320, 33, 33, 4320, 540, 4320, 4320, 540, 4320, 33, 540, 4320, 33, 4320, 540, 33, 540, 540, 4320, 4320, 33, 33, 4320, 33, 33, 33, 540, 33]
Prompts retrieved: 210366 . Total input tokens: 46860121 . Total output tokens: 41379612
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 5.502805745229125,
    "estimated_duration": 3600.008641831668,
    "input_throughput": 4786.57823199907,
    "output_throughput": 4211.823222814637,
    "total_throughput": 8998.401454813707,
    "itl": 81.38543884220981,
    "ttft": 25840.53312957593,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1840,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.523805059939402,
    "arrivals": 70422,
    "finished_requests": 69961,
    "scheduler_time": 53.843929266852285
}
#Debug simulation 
Total elapsed time: 5.502895760815591. Arrivals time: 0.17224849248304963 Scheduler time: 5.151826239656657 Scheduler overhead time: 0.06212339922785759 Adapter cache time: 0.02775556594133377 Engine time: 0.060619054827839136 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-8/adapters_128_slots_64_rate_0.4-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-8/adapters_128_slots_64_rate_0.4-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [42 43 43]
Adapter prompts. [4320, 270, 4320, 4320, 135, 135, 4320, 135, 270, 270, 270, 135, 4320, 270, 135, 4320, 270, 135, 135, 135, 135, 270, 270, 4320, 270, 135, 270, 270, 270, 270, 4320, 270, 135, 270, 135, 4320, 4320, 135, 270, 270, 135, 270, 135, 270, 270, 4320, 4320, 4320, 4320, 270, 270, 135, 270, 4320, 4320, 270, 135, 135, 135, 4320, 270, 270, 270, 270, 4320, 270, 4320, 135, 135, 270, 135, 4320, 4320, 135, 135, 270, 270, 270, 135, 4320, 135, 4320, 270, 135, 4320, 4320, 270, 270, 135, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 135, 4320, 135, 135, 4320, 270, 4320, 4320, 270, 4320, 135, 270, 4320, 135, 4320, 270, 135, 270, 270, 4320, 4320, 135, 135, 4320, 135, 135, 135, 270, 135]
Prompts retrieved: 203040 . Total input tokens: 45249407 . Total output tokens: 39930037
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 5.26023230003193,
    "estimated_duration": 3600.032737213262,
    "input_throughput": 4646.270803900506,
    "output_throughput": 4094.354711732398,
    "total_throughput": 8740.625515632903,
    "itl": 78.05204364223933,
    "ttft": 19210.4268799237,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2801,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 18.521357698491627,
    "arrivals": 68030,
    "finished_requests": 67699,
    "scheduler_time": 51.65349718924059
}
#Debug simulation 
Total elapsed time: 5.2603210201486945. Arrivals time: 0.15723366430029273 Scheduler time: 4.908173273317516 Scheduler overhead time: 0.06479914532974362 Adapter cache time: 0.036981566809117794 Engine time: 0.06360162002965808 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-16/adapters_128_slots_64_rate_0.4-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-16/adapters_128_slots_64_rate_0.4-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [42 43 43]
Adapter prompts. [4320, 270, 4320, 4320, 135, 135, 4320, 135, 270, 270, 270, 135, 4320, 270, 135, 4320, 270, 135, 135, 135, 135, 270, 270, 4320, 270, 135, 270, 270, 270, 270, 4320, 270, 135, 270, 135, 4320, 4320, 135, 270, 270, 135, 270, 135, 270, 270, 4320, 4320, 4320, 4320, 270, 270, 135, 270, 4320, 4320, 270, 135, 135, 135, 4320, 270, 270, 270, 270, 4320, 270, 4320, 135, 135, 270, 135, 4320, 4320, 135, 135, 270, 270, 270, 135, 4320, 135, 4320, 270, 135, 4320, 4320, 270, 270, 135, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 135, 4320, 135, 135, 4320, 270, 4320, 4320, 270, 4320, 135, 270, 4320, 135, 4320, 270, 135, 270, 270, 4320, 4320, 135, 135, 4320, 135, 135, 135, 270, 135]
Prompts retrieved: 203040 . Total input tokens: 45249407 . Total output tokens: 39930037
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 5.253528736997396,
    "estimated_duration": 3600.0176572363794,
    "input_throughput": 4646.223322371257,
    "output_throughput": 4094.2601962999765,
    "total_throughput": 8740.483518671233,
    "itl": 78.15362973954342,
    "ttft": 19120.099984131233,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2800,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.44318743422581,
    "arrivals": 68030,
    "finished_requests": 67698,
    "scheduler_time": 51.66476428464135
}
#Debug simulation 
Total elapsed time: 5.253639093134552. Arrivals time: 0.15713421162217855 Scheduler time: 4.902225337456912 Scheduler overhead time: 0.06437447993084788 Adapter cache time: 0.036931070033460855 Engine time: 0.06349864229559898 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-32/adapters_128_slots_64_rate_0.4-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-32/adapters_128_slots_64_rate_0.4-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [42 43 43]
Adapter prompts. [4320, 270, 4320, 4320, 135, 135, 4320, 135, 270, 270, 270, 135, 4320, 270, 135, 4320, 270, 135, 135, 135, 135, 270, 270, 4320, 270, 135, 270, 270, 270, 270, 4320, 270, 135, 270, 135, 4320, 4320, 135, 270, 270, 135, 270, 135, 270, 270, 4320, 4320, 4320, 4320, 270, 270, 135, 270, 4320, 4320, 270, 135, 135, 135, 4320, 270, 270, 270, 270, 4320, 270, 4320, 135, 135, 270, 135, 4320, 4320, 135, 135, 270, 270, 270, 135, 4320, 135, 4320, 270, 135, 4320, 4320, 270, 270, 135, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 135, 4320, 135, 135, 4320, 270, 4320, 4320, 270, 4320, 135, 270, 4320, 135, 4320, 270, 135, 270, 270, 4320, 4320, 135, 135, 4320, 135, 135, 135, 270, 135]
Prompts retrieved: 203040 . Total input tokens: 45249407 . Total output tokens: 39930037
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 5.288801121991128,
    "estimated_duration": 3600.054917140989,
    "input_throughput": 4646.242178239786,
    "output_throughput": 4094.3294864250943,
    "total_throughput": 8740.57166466488,
    "itl": 78.18422088868745,
    "ttft": 19227.305006973518,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2798,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.973487224653592,
    "arrivals": 68030,
    "finished_requests": 67699,
    "scheduler_time": 51.66810344971258
}
#Debug simulation 
Total elapsed time: 5.288891565054655. Arrivals time: 0.1580121610313654 Scheduler time: 4.936113979667425 Scheduler overhead time: 0.06449915561825037 Adapter cache time: 0.03706719260662794 Engine time: 0.06358605716377497 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-16/adapters_128_slots_64_rate_0.4-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-16/adapters_128_slots_64_rate_0.4-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [42 43 43]
Adapter prompts. [4320, 270, 4320, 4320, 135, 135, 4320, 135, 270, 270, 270, 135, 4320, 270, 135, 4320, 270, 135, 135, 135, 135, 270, 270, 4320, 270, 135, 270, 270, 270, 270, 4320, 270, 135, 270, 135, 4320, 4320, 135, 270, 270, 135, 270, 135, 270, 270, 4320, 4320, 4320, 4320, 270, 270, 135, 270, 4320, 4320, 270, 135, 135, 135, 4320, 270, 270, 270, 270, 4320, 270, 4320, 135, 135, 270, 135, 4320, 4320, 135, 135, 270, 270, 270, 135, 4320, 135, 4320, 270, 135, 4320, 4320, 270, 270, 135, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 135, 4320, 135, 135, 4320, 270, 4320, 4320, 270, 4320, 135, 270, 4320, 135, 4320, 270, 135, 270, 270, 4320, 4320, 135, 135, 4320, 135, 135, 135, 270, 135]
Prompts retrieved: 203040 . Total input tokens: 45249407 . Total output tokens: 39930037
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 5.302737654186785,
    "estimated_duration": 3600.0403651892543,
    "input_throughput": 4646.260959110295,
    "output_throughput": 4094.3460363742693,
    "total_throughput": 8740.606995484564,
    "itl": 78.0759295971285,
    "ttft": 19212.42331249002,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2800,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 18.998049401008156,
    "arrivals": 68030,
    "finished_requests": 67699,
    "scheduler_time": 51.656215792442936
}
#Debug simulation 
Total elapsed time: 5.302833075169474. Arrivals time: 0.16811981657519937 Scheduler time: 4.938656241167337 Scheduler overhead time: 0.0645053070038557 Adapter cache time: 0.036658389028161764 Engine time: 0.06530603161081672 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-32/adapters_128_slots_64_rate_0.4-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-32/adapters_128_slots_64_rate_0.4-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [42 43 43]
Adapter prompts. [4320, 270, 4320, 4320, 135, 135, 4320, 135, 270, 270, 270, 135, 4320, 270, 135, 4320, 270, 135, 135, 135, 135, 270, 270, 4320, 270, 135, 270, 270, 270, 270, 4320, 270, 135, 270, 135, 4320, 4320, 135, 270, 270, 135, 270, 135, 270, 270, 4320, 4320, 4320, 4320, 270, 270, 135, 270, 4320, 4320, 270, 135, 135, 135, 4320, 270, 270, 270, 270, 4320, 270, 4320, 135, 135, 270, 135, 4320, 4320, 135, 135, 270, 270, 270, 135, 4320, 135, 4320, 270, 135, 4320, 4320, 270, 270, 135, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 135, 4320, 135, 135, 4320, 270, 4320, 4320, 270, 4320, 135, 270, 4320, 135, 4320, 270, 135, 270, 270, 4320, 4320, 135, 135, 4320, 135, 135, 135, 270, 135]
Prompts retrieved: 203040 . Total input tokens: 45249407 . Total output tokens: 39930037
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 5.236380148213357,
    "estimated_duration": 3600.064055831403,
    "input_throughput": 4646.230383847187,
    "output_throughput": 4094.319093051796,
    "total_throughput": 8740.549476898983,
    "itl": 78.17075417709592,
    "ttft": 19226.245560289957,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2800,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.77382327336839,
    "arrivals": 68030,
    "finished_requests": 67699,
    "scheduler_time": 51.66712291208879
}
#Debug simulation 
Total elapsed time: 5.2364913313649595. Arrivals time: 0.15829708939418197 Scheduler time: 4.885325885377824 Scheduler overhead time: 0.06393121276050806 Adapter cache time: 0.03680456569418311 Engine time: 0.06285087345167994 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-16/adapters_128_slots_64_rate_0.4-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-16/adapters_128_slots_64_rate_0.4-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [42 43 43]
Adapter prompts. [4320, 270, 4320, 4320, 135, 135, 4320, 135, 270, 270, 270, 135, 4320, 270, 135, 4320, 270, 135, 135, 135, 135, 270, 270, 4320, 270, 135, 270, 270, 270, 270, 4320, 270, 135, 270, 135, 4320, 4320, 135, 270, 270, 135, 270, 135, 270, 270, 4320, 4320, 4320, 4320, 270, 270, 135, 270, 4320, 4320, 270, 135, 135, 135, 4320, 270, 270, 270, 270, 4320, 270, 4320, 135, 135, 270, 135, 4320, 4320, 135, 135, 270, 270, 270, 135, 4320, 135, 4320, 270, 135, 4320, 4320, 270, 270, 135, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 135, 4320, 135, 135, 4320, 270, 4320, 4320, 270, 4320, 135, 270, 4320, 135, 4320, 270, 135, 270, 270, 4320, 4320, 135, 135, 4320, 135, 135, 135, 270, 135]
Prompts retrieved: 203040 . Total input tokens: 45249407 . Total output tokens: 39930037
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 5.282147745136172,
    "estimated_duration": 3600.033469049798,
    "input_throughput": 4646.461246488099,
    "output_throughput": 4094.573321811553,
    "total_throughput": 8741.034568299652,
    "itl": 78.01871582570632,
    "ttft": 19156.980466689623,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2808,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.92605000112334,
    "arrivals": 68030,
    "finished_requests": 67700,
    "scheduler_time": 51.64977301857878
}
#Debug simulation 
Total elapsed time: 5.282270156312734. Arrivals time: 0.16741382190957665 Scheduler time: 4.920031325891614 Scheduler overhead time: 0.06421894207596779 Adapter cache time: 0.03708744700998068 Engine time: 0.0641073901206255 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-32/adapters_128_slots_64_rate_0.4-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-32/adapters_128_slots_64_rate_0.4-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [42 43 43]
Adapter prompts. [4320, 270, 4320, 4320, 135, 135, 4320, 135, 270, 270, 270, 135, 4320, 270, 135, 4320, 270, 135, 135, 135, 135, 270, 270, 4320, 270, 135, 270, 270, 270, 270, 4320, 270, 135, 270, 135, 4320, 4320, 135, 270, 270, 135, 270, 135, 270, 270, 4320, 4320, 4320, 4320, 270, 270, 135, 270, 4320, 4320, 270, 135, 135, 135, 4320, 270, 270, 270, 270, 4320, 270, 4320, 135, 135, 270, 135, 4320, 4320, 135, 135, 270, 270, 270, 135, 4320, 135, 4320, 270, 135, 4320, 4320, 270, 270, 135, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 135, 4320, 135, 135, 4320, 270, 4320, 4320, 270, 4320, 135, 270, 4320, 135, 4320, 270, 135, 270, 270, 4320, 4320, 135, 135, 4320, 135, 135, 135, 270, 135]
Prompts retrieved: 203040 . Total input tokens: 45249407 . Total output tokens: 39930037
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 5.273148247972131,
    "estimated_duration": 3600.069066231066,
    "input_throughput": 4646.223917451482,
    "output_throughput": 4094.3133947791725,
    "total_throughput": 8740.537312230654,
    "itl": 78.16231946574878,
    "ttft": 19225.697578655432,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2800,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.60647259466369,
    "arrivals": 68030,
    "finished_requests": 67699,
    "scheduler_time": 51.6662367200859
}
#Debug simulation 
Total elapsed time: 5.2732478538528085. Arrivals time: 0.1606637160293758 Scheduler time: 4.918767832685262 Scheduler overhead time: 0.06402655551210046 Adapter cache time: 0.036975675728172064 Engine time: 0.06328966654837132 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-8/adapters_128_slots_64_rate_0.4-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-8/adapters_128_slots_64_rate_0.4-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [42 43 43]
Adapter prompts. [4320, 270, 4320, 4320, 66, 66, 4320, 66, 270, 270, 270, 66, 4320, 270, 66, 4320, 270, 66, 66, 66, 66, 270, 270, 4320, 270, 66, 270, 270, 270, 270, 4320, 270, 66, 270, 66, 4320, 4320, 66, 270, 270, 66, 270, 66, 270, 270, 4320, 4320, 4320, 4320, 270, 270, 66, 270, 4320, 4320, 270, 66, 66, 66, 4320, 270, 270, 270, 270, 4320, 270, 4320, 66, 66, 270, 66, 4320, 4320, 66, 66, 270, 270, 270, 66, 4320, 66, 4320, 270, 66, 4320, 4320, 270, 270, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 66, 4320, 66, 66, 4320, 270, 4320, 4320, 270, 4320, 66, 270, 4320, 66, 4320, 270, 66, 270, 270, 4320, 4320, 66, 66, 4320, 66, 66, 66, 270, 66]
Prompts retrieved: 200142 . Total input tokens: 44612235 . Total output tokens: 39356338
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 4.8646399830468,
    "estimated_duration": 3600.0494130793722,
    "input_throughput": 4578.382713336553,
    "output_throughput": 4024.9375320672943,
    "total_throughput": 8603.320245403847,
    "itl": 74.85031170618328,
    "ttft": 16180.031466958852,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3030,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.035599366807805,
    "arrivals": 67080,
    "finished_requests": 66786,
    "scheduler_time": 50.14885405555368
}
#Debug simulation 
Total elapsed time: 4.864729649852961. Arrivals time: 0.1554654873907566 Scheduler time: 4.510712676215917 Scheduler overhead time: 0.06461210688576102 Adapter cache time: 0.040077483747154474 Engine time: 0.06425382476300001 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-16/adapters_128_slots_64_rate_0.4-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-16/adapters_128_slots_64_rate_0.4-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [42 43 43]
Adapter prompts. [4320, 270, 4320, 4320, 66, 66, 4320, 66, 270, 270, 270, 66, 4320, 270, 66, 4320, 270, 66, 66, 66, 66, 270, 270, 4320, 270, 66, 270, 270, 270, 270, 4320, 270, 66, 270, 66, 4320, 4320, 66, 270, 270, 66, 270, 66, 270, 270, 4320, 4320, 4320, 4320, 270, 270, 66, 270, 4320, 4320, 270, 66, 66, 66, 4320, 270, 270, 270, 270, 4320, 270, 4320, 66, 66, 270, 66, 4320, 4320, 66, 66, 270, 270, 270, 66, 4320, 66, 4320, 270, 66, 4320, 4320, 270, 270, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 66, 4320, 66, 66, 4320, 270, 4320, 4320, 270, 4320, 66, 270, 4320, 66, 4320, 270, 66, 270, 270, 4320, 4320, 66, 66, 4320, 66, 66, 66, 270, 66]
Prompts retrieved: 200142 . Total input tokens: 44612235 . Total output tokens: 39356338
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 4.850557812023908,
    "estimated_duration": 3600.0712387580356,
    "input_throughput": 4578.326623804844,
    "output_throughput": 4024.795355160431,
    "total_throughput": 8603.121978965275,
    "itl": 74.97513292425047,
    "ttft": 16237.05538064506,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3026,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 22.099739596684888,
    "arrivals": 67080,
    "finished_requests": 66785,
    "scheduler_time": 50.16359447252734
}
#Debug simulation 
Total elapsed time: 4.8506495878100395. Arrivals time: 0.15362042328342795 Scheduler time: 4.499947309028357 Scheduler overhead time: 0.0644241152331233 Adapter cache time: 0.03998279757797718 Engine time: 0.06309542525559664 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-32/adapters_128_slots_64_rate_0.4-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-32/adapters_128_slots_64_rate_0.4-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [42 43 43]
Adapter prompts. [4320, 270, 4320, 4320, 66, 66, 4320, 66, 270, 270, 270, 66, 4320, 270, 66, 4320, 270, 66, 66, 66, 66, 270, 270, 4320, 270, 66, 270, 270, 270, 270, 4320, 270, 66, 270, 66, 4320, 4320, 66, 270, 270, 66, 270, 66, 270, 270, 4320, 4320, 4320, 4320, 270, 270, 66, 270, 4320, 4320, 270, 66, 66, 66, 4320, 270, 270, 270, 270, 4320, 270, 4320, 66, 66, 270, 66, 4320, 4320, 66, 66, 270, 270, 270, 66, 4320, 66, 4320, 270, 66, 4320, 4320, 270, 270, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 66, 4320, 66, 66, 4320, 270, 4320, 4320, 270, 4320, 66, 270, 4320, 66, 4320, 270, 66, 270, 270, 4320, 4320, 66, 66, 4320, 66, 66, 66, 270, 66]
Prompts retrieved: 200142 . Total input tokens: 44612235 . Total output tokens: 39356338
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 4.882013543974608,
    "estimated_duration": 3600.006418685778,
    "input_throughput": 4578.312948124387,
    "output_throughput": 4024.8089350044806,
    "total_throughput": 8603.121883128868,
    "itl": 75.00824929510522,
    "ttft": 16291.913332410964,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3021,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 22.65483513935977,
    "arrivals": 67080,
    "finished_requests": 66784,
    "scheduler_time": 50.166797393461295
}
#Debug simulation 
Total elapsed time: 4.882103255018592. Arrivals time: 0.15403623320162296 Scheduler time: 4.530290605966002 Scheduler overhead time: 0.06431213114410639 Adapter cache time: 0.03990062605589628 Engine time: 0.06390171777456999 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-16/adapters_128_slots_64_rate_0.4-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-16/adapters_128_slots_64_rate_0.4-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [42 43 43]
Adapter prompts. [4320, 270, 4320, 4320, 66, 66, 4320, 66, 270, 270, 270, 66, 4320, 270, 66, 4320, 270, 66, 66, 66, 66, 270, 270, 4320, 270, 66, 270, 270, 270, 270, 4320, 270, 66, 270, 66, 4320, 4320, 66, 270, 270, 66, 270, 66, 270, 270, 4320, 4320, 4320, 4320, 270, 270, 66, 270, 4320, 4320, 270, 66, 66, 66, 4320, 270, 270, 270, 270, 4320, 270, 4320, 66, 66, 270, 66, 4320, 4320, 66, 66, 270, 270, 270, 66, 4320, 66, 4320, 270, 66, 4320, 4320, 270, 270, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 66, 4320, 66, 66, 4320, 270, 4320, 4320, 270, 4320, 66, 270, 4320, 66, 4320, 270, 66, 270, 270, 4320, 4320, 66, 66, 4320, 66, 66, 66, 270, 66]
Prompts retrieved: 200142 . Total input tokens: 44612235 . Total output tokens: 39356338
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 4.907786870375276,
    "estimated_duration": 3600.04380220805,
    "input_throughput": 4578.361516015652,
    "output_throughput": 4024.8260288147003,
    "total_throughput": 8603.187544830353,
    "itl": 74.88466074675935,
    "ttft": 16234.505492929384,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3028,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.61322878738927,
    "arrivals": 67080,
    "finished_requests": 66785,
    "scheduler_time": 50.1527033981649
}
#Debug simulation 
Total elapsed time: 4.907900533173233. Arrivals time: 0.1544600361958146 Scheduler time: 4.55655336426571 Scheduler overhead time: 0.06433394178748131 Adapter cache time: 0.039778349455446005 Engine time: 0.06311113480478525 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-32/adapters_128_slots_64_rate_0.4-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-32/adapters_128_slots_64_rate_0.4-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [42 43 43]
Adapter prompts. [4320, 270, 4320, 4320, 66, 66, 4320, 66, 270, 270, 270, 66, 4320, 270, 66, 4320, 270, 66, 66, 66, 66, 270, 270, 4320, 270, 66, 270, 270, 270, 270, 4320, 270, 66, 270, 66, 4320, 4320, 66, 270, 270, 66, 270, 66, 270, 270, 4320, 4320, 4320, 4320, 270, 270, 66, 270, 4320, 4320, 270, 66, 66, 66, 4320, 270, 270, 270, 270, 4320, 270, 4320, 66, 66, 270, 66, 4320, 4320, 66, 66, 270, 270, 270, 66, 4320, 66, 4320, 270, 66, 4320, 4320, 270, 270, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 66, 4320, 66, 66, 4320, 270, 4320, 4320, 270, 4320, 66, 270, 4320, 66, 4320, 270, 66, 270, 270, 4320, 4320, 66, 66, 4320, 66, 66, 66, 270, 66]
Prompts retrieved: 200142 . Total input tokens: 44612235 . Total output tokens: 39356338
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 4.8457372090779245,
    "estimated_duration": 3600.0186263867054,
    "input_throughput": 4578.297423017152,
    "output_throughput": 4024.7952868351604,
    "total_throughput": 8603.092709852312,
    "itl": 74.9963779027055,
    "ttft": 16290.946937371358,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3027,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 22.47618741606868,
    "arrivals": 67080,
    "finished_requests": 66784,
    "scheduler_time": 50.165243172569305
}
#Debug simulation 
Total elapsed time: 4.8458562437444925. Arrivals time: 0.15246618213132024 Scheduler time: 4.496944316662848 Scheduler overhead time: 0.06392252212390304 Adapter cache time: 0.039741864427924156 Engine time: 0.06323495274409652 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-16/adapters_128_slots_64_rate_0.4-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-16/adapters_128_slots_64_rate_0.4-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [42 43 43]
Adapter prompts. [4320, 270, 4320, 4320, 66, 66, 4320, 66, 270, 270, 270, 66, 4320, 270, 66, 4320, 270, 66, 66, 66, 66, 270, 270, 4320, 270, 66, 270, 270, 270, 270, 4320, 270, 66, 270, 66, 4320, 4320, 66, 270, 270, 66, 270, 66, 270, 270, 4320, 4320, 4320, 4320, 270, 270, 66, 270, 4320, 4320, 270, 66, 66, 66, 4320, 270, 270, 270, 270, 4320, 270, 4320, 66, 66, 270, 66, 4320, 4320, 66, 66, 270, 270, 270, 66, 4320, 66, 4320, 270, 66, 4320, 4320, 270, 270, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 66, 4320, 66, 66, 4320, 270, 4320, 4320, 270, 4320, 66, 270, 4320, 66, 4320, 270, 66, 270, 270, 4320, 4320, 66, 66, 4320, 66, 66, 66, 270, 66]
Prompts retrieved: 200142 . Total input tokens: 44612235 . Total output tokens: 39356338
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 4.861999066080898,
    "estimated_duration": 3600.0194974725996,
    "input_throughput": 4578.296315220289,
    "output_throughput": 4024.7943129675455,
    "total_throughput": 8603.090628187834,
    "itl": 74.81001214532478,
    "ttft": 16286.709752701538,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3035,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.375200054633044,
    "arrivals": 67080,
    "finished_requests": 66784,
    "scheduler_time": 50.1438628836376
}
#Debug simulation 
Total elapsed time: 4.86209040787071. Arrivals time: 0.15958284540101886 Scheduler time: 4.504905983339995 Scheduler overhead time: 0.06425712769851089 Adapter cache time: 0.04006901802495122 Engine time: 0.06388631463050842 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-32/adapters_128_slots_64_rate_0.4-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-32/adapters_128_slots_64_rate_0.4-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [42 43 43]
Adapter prompts. [4320, 270, 4320, 4320, 66, 66, 4320, 66, 270, 270, 270, 66, 4320, 270, 66, 4320, 270, 66, 66, 66, 66, 270, 270, 4320, 270, 66, 270, 270, 270, 270, 4320, 270, 66, 270, 66, 4320, 4320, 66, 270, 270, 66, 270, 66, 270, 270, 4320, 4320, 4320, 4320, 270, 270, 66, 270, 4320, 4320, 270, 66, 66, 66, 4320, 270, 270, 270, 270, 4320, 270, 4320, 66, 66, 270, 66, 4320, 4320, 66, 66, 270, 270, 270, 66, 4320, 66, 4320, 270, 66, 4320, 4320, 270, 270, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 66, 4320, 66, 66, 4320, 270, 4320, 4320, 270, 4320, 66, 270, 4320, 66, 4320, 270, 66, 270, 270, 4320, 4320, 66, 66, 4320, 66, 66, 66, 270, 66]
Prompts retrieved: 200142 . Total input tokens: 44612235 . Total output tokens: 39356338
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 4.903595604933798,
    "estimated_duration": 3600.051641606557,
    "input_throughput": 4578.351546269658,
    "output_throughput": 4024.8172644362126,
    "total_throughput": 8603.16881070587,
    "itl": 74.98523302364394,
    "ttft": 16237.664742524043,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3024,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 22.2609971591089,
    "arrivals": 67080,
    "finished_requests": 66785,
    "scheduler_time": 50.1642444422785
}
#Debug simulation 
Total elapsed time: 4.9036904610693455. Arrivals time: 0.15335004264488816 Scheduler time: 4.551171774044633 Scheduler overhead time: 0.06456807116046548 Adapter cache time: 0.04022548208013177 Engine time: 0.0647100112400949 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-8/adapters_128_slots_64_rate_0.4-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-8/adapters_128_slots_64_rate_0.4-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [42 43 43]
Adapter prompts. [4320, 270, 4320, 4320, 33, 33, 4320, 33, 270, 270, 270, 33, 4320, 270, 33, 4320, 270, 33, 33, 33, 33, 270, 270, 4320, 270, 33, 270, 270, 270, 270, 4320, 270, 33, 270, 33, 4320, 4320, 33, 270, 270, 33, 270, 33, 270, 270, 4320, 4320, 4320, 4320, 270, 270, 33, 270, 4320, 4320, 270, 33, 33, 33, 4320, 270, 270, 270, 270, 4320, 270, 4320, 33, 33, 270, 33, 4320, 4320, 33, 33, 270, 270, 270, 33, 4320, 33, 4320, 270, 33, 4320, 4320, 270, 270, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 33, 4320, 33, 33, 4320, 270, 4320, 4320, 270, 4320, 33, 270, 4320, 33, 4320, 270, 33, 270, 270, 4320, 4320, 33, 33, 4320, 33, 33, 33, 270, 33]
Prompts retrieved: 198756 . Total input tokens: 44308115 . Total output tokens: 39084306
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 4.748216273263097,
    "estimated_duration": 3600.033714590595,
    "input_throughput": 4557.113155221021,
    "output_throughput": 3993.4498229094884,
    "total_throughput": 8550.562978130509,
    "itl": 71.36545909627918,
    "ttft": 17271.654139767008,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2654,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.549333570795216,
    "arrivals": 66631,
    "finished_requests": 66313,
    "scheduler_time": 49.29718019184756
}
#Debug simulation 
Total elapsed time: 4.74830942414701. Arrivals time: 0.15371139394119382 Scheduler time: 4.395709564909339 Scheduler overhead time: 0.0651751165278256 Adapter cache time: 0.0390722556039691 Engine time: 0.0644908887334168 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-16/adapters_128_slots_64_rate_0.4-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-16/adapters_128_slots_64_rate_0.4-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [42 43 43]
Adapter prompts. [4320, 270, 4320, 4320, 33, 33, 4320, 33, 270, 270, 270, 33, 4320, 270, 33, 4320, 270, 33, 33, 33, 33, 270, 270, 4320, 270, 33, 270, 270, 270, 270, 4320, 270, 33, 270, 33, 4320, 4320, 33, 270, 270, 33, 270, 33, 270, 270, 4320, 4320, 4320, 4320, 270, 270, 33, 270, 4320, 4320, 270, 33, 33, 33, 4320, 270, 270, 270, 270, 4320, 270, 4320, 33, 33, 270, 33, 4320, 4320, 33, 33, 270, 270, 270, 33, 4320, 33, 4320, 270, 33, 4320, 4320, 270, 270, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 33, 4320, 33, 33, 4320, 270, 4320, 4320, 270, 4320, 33, 270, 4320, 33, 4320, 270, 33, 270, 270, 4320, 4320, 33, 33, 4320, 33, 33, 33, 270, 33]
Prompts retrieved: 198756 . Total input tokens: 44308115 . Total output tokens: 39084306
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 4.728924205992371,
    "estimated_duration": 3600.0345080872085,
    "input_throughput": 4557.112150771245,
    "output_throughput": 3993.4489426987843,
    "total_throughput": 8550.561093470029,
    "itl": 71.46966236306154,
    "ttft": 17272.129644268778,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2648,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.307633155434907,
    "arrivals": 66631,
    "finished_requests": 66313,
    "scheduler_time": 49.3102032665836
}
#Debug simulation 
Total elapsed time: 4.72901690704748. Arrivals time: 0.15550920832902193 Scheduler time: 4.377184706740081 Scheduler overhead time: 0.06455148803070188 Adapter cache time: 0.037919926922768354 Engine time: 0.06395454984158278 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-32/adapters_128_slots_64_rate_0.4-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-32/adapters_128_slots_64_rate_0.4-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [42 43 43]
Adapter prompts. [4320, 270, 4320, 4320, 33, 33, 4320, 33, 270, 270, 270, 33, 4320, 270, 33, 4320, 270, 33, 33, 33, 33, 270, 270, 4320, 270, 33, 270, 270, 270, 270, 4320, 270, 33, 270, 33, 4320, 4320, 33, 270, 270, 33, 270, 33, 270, 270, 4320, 4320, 4320, 4320, 270, 270, 33, 270, 4320, 4320, 270, 33, 33, 33, 4320, 270, 270, 270, 270, 4320, 270, 4320, 33, 33, 270, 33, 4320, 4320, 33, 33, 270, 270, 270, 33, 4320, 33, 4320, 270, 33, 4320, 4320, 270, 270, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 33, 4320, 33, 33, 4320, 270, 4320, 4320, 270, 4320, 33, 270, 4320, 33, 4320, 270, 33, 270, 270, 4320, 4320, 33, 33, 4320, 33, 33, 33, 270, 33]
Prompts retrieved: 198756 . Total input tokens: 44308115 . Total output tokens: 39084306
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 4.719790690112859,
    "estimated_duration": 3600.0655641405247,
    "input_throughput": 4557.17144804744,
    "output_throughput": 3993.4150486596045,
    "total_throughput": 8550.586496707045,
    "itl": 71.50121568559827,
    "ttft": 17272.20199535767,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2649,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.828251709393307,
    "arrivals": 66631,
    "finished_requests": 66314,
    "scheduler_time": 49.31458252083882
}
#Debug simulation 
Total elapsed time: 4.719906353857368. Arrivals time: 0.15321202483028173 Scheduler time: 4.370436198078096 Scheduler overhead time: 0.06434937426820397 Adapter cache time: 0.037923773750662804 Engine time: 0.06415138626471162 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-16/adapters_128_slots_64_rate_0.4-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-16/adapters_128_slots_64_rate_0.4-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [42 43 43]
Adapter prompts. [4320, 270, 4320, 4320, 33, 33, 4320, 33, 270, 270, 270, 33, 4320, 270, 33, 4320, 270, 33, 33, 33, 33, 270, 270, 4320, 270, 33, 270, 270, 270, 270, 4320, 270, 33, 270, 33, 4320, 4320, 33, 270, 270, 33, 270, 33, 270, 270, 4320, 4320, 4320, 4320, 270, 270, 33, 270, 4320, 4320, 270, 33, 33, 33, 4320, 270, 270, 270, 270, 4320, 270, 4320, 33, 33, 270, 33, 4320, 4320, 33, 33, 270, 270, 270, 33, 4320, 33, 4320, 270, 33, 4320, 4320, 270, 270, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 33, 4320, 33, 33, 4320, 270, 4320, 4320, 270, 4320, 33, 270, 4320, 33, 4320, 270, 33, 270, 270, 4320, 4320, 33, 33, 4320, 33, 33, 33, 270, 33]
Prompts retrieved: 198756 . Total input tokens: 44308115 . Total output tokens: 39084306
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 4.712358408141881,
    "estimated_duration": 3600.022752533307,
    "input_throughput": 4557.127031615397,
    "output_throughput": 3993.461982950895,
    "total_throughput": 8550.589014566292,
    "itl": 71.39676863578393,
    "ttft": 17271.723465554416,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2651,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 18.095432914928985,
    "arrivals": 66631,
    "finished_requests": 66313,
    "scheduler_time": 49.30110074657281
}
#Debug simulation 
Total elapsed time: 4.712449664250016. Arrivals time: 0.15927896089851856 Scheduler time: 4.3563370034098625 Scheduler overhead time: 0.0643763062544167 Adapter cache time: 0.038280353881418705 Engine time: 0.06422122148796916 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-32/adapters_128_slots_64_rate_0.4-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-32/adapters_128_slots_64_rate_0.4-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [42 43 43]
Adapter prompts. [4320, 270, 4320, 4320, 33, 33, 4320, 33, 270, 270, 270, 33, 4320, 270, 33, 4320, 270, 33, 33, 33, 33, 270, 270, 4320, 270, 33, 270, 270, 270, 270, 4320, 270, 33, 270, 33, 4320, 4320, 33, 270, 270, 33, 270, 33, 270, 270, 4320, 4320, 4320, 4320, 270, 270, 33, 270, 4320, 4320, 270, 33, 33, 33, 4320, 270, 270, 270, 270, 4320, 270, 4320, 33, 33, 270, 33, 4320, 4320, 33, 33, 270, 270, 270, 33, 4320, 33, 4320, 270, 33, 4320, 4320, 270, 270, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 33, 4320, 33, 33, 4320, 270, 4320, 4320, 270, 4320, 33, 270, 4320, 33, 4320, 270, 33, 270, 270, 4320, 4320, 33, 33, 4320, 33, 33, 33, 270, 33]
Prompts retrieved: 198756 . Total input tokens: 44308115 . Total output tokens: 39084306
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 4.735423805192113,
    "estimated_duration": 3600.071906612536,
    "input_throughput": 4557.1634193932605,
    "output_throughput": 3993.40801321036,
    "total_throughput": 8550.57143260362,
    "itl": 71.48634578282277,
    "ttft": 17272.08886240024,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2652,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.666436835932615,
    "arrivals": 66631,
    "finished_requests": 66314,
    "scheduler_time": 49.31292457741209
}
#Debug simulation 
Total elapsed time: 4.7354945302940905. Arrivals time: 0.14887327887117863 Scheduler time: 4.389016597066075 Scheduler overhead time: 0.0646100016310811 Adapter cache time: 0.03833787655457854 Engine time: 0.0647378833964467 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-16/adapters_128_slots_64_rate_0.4-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-16/adapters_128_slots_64_rate_0.4-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [42 43 43]
Adapter prompts. [4320, 270, 4320, 4320, 33, 33, 4320, 33, 270, 270, 270, 33, 4320, 270, 33, 4320, 270, 33, 33, 33, 33, 270, 270, 4320, 270, 33, 270, 270, 270, 270, 4320, 270, 33, 270, 33, 4320, 4320, 33, 270, 270, 33, 270, 33, 270, 270, 4320, 4320, 4320, 4320, 270, 270, 33, 270, 4320, 4320, 270, 33, 33, 33, 4320, 270, 270, 270, 270, 4320, 270, 4320, 33, 33, 270, 33, 4320, 4320, 33, 33, 270, 270, 270, 33, 4320, 33, 4320, 270, 33, 4320, 4320, 270, 270, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 33, 4320, 33, 33, 4320, 270, 4320, 4320, 270, 4320, 33, 270, 4320, 33, 4320, 270, 33, 270, 270, 4320, 4320, 33, 33, 4320, 33, 33, 33, 270, 33]
Prompts retrieved: 198756 . Total input tokens: 44308115 . Total output tokens: 39084306
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 4.76338206557557,
    "estimated_duration": 3600.061055609543,
    "input_throughput": 4557.42659542813,
    "output_throughput": 3993.6311573376106,
    "total_throughput": 8551.05775276574,
    "itl": 71.33167229770689,
    "ttft": 17162.87698691549,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2653,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.936542255334775,
    "arrivals": 66631,
    "finished_requests": 66316,
    "scheduler_time": 49.29326273801859
}
#Debug simulation 
Total elapsed time: 4.763465380761772. Arrivals time: 0.1493784924969077 Scheduler time: 4.415755769237876 Scheduler overhead time: 0.06491038668900728 Adapter cache time: 0.038426865357905626 Engine time: 0.06486080400645733 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-32/adapters_128_slots_64_rate_0.4-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-32/adapters_128_slots_64_rate_0.4-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [42 43 43]
Adapter prompts. [4320, 270, 4320, 4320, 33, 33, 4320, 33, 270, 270, 270, 33, 4320, 270, 33, 4320, 270, 33, 33, 33, 33, 270, 270, 4320, 270, 33, 270, 270, 270, 270, 4320, 270, 33, 270, 33, 4320, 4320, 33, 270, 270, 33, 270, 33, 270, 270, 4320, 4320, 4320, 4320, 270, 270, 33, 270, 4320, 4320, 270, 33, 33, 33, 4320, 270, 270, 270, 270, 4320, 270, 4320, 33, 33, 270, 33, 4320, 4320, 33, 33, 270, 270, 270, 33, 4320, 33, 4320, 270, 33, 4320, 4320, 270, 270, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 33, 4320, 33, 33, 4320, 270, 4320, 4320, 270, 4320, 33, 270, 4320, 33, 4320, 270, 33, 270, 270, 4320, 4320, 33, 33, 4320, 33, 33, 33, 270, 33]
Prompts retrieved: 198756 . Total input tokens: 44308115 . Total output tokens: 39084306
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 4.68272571824491,
    "estimated_duration": 3600.0664172104694,
    "input_throughput": 4557.170368182365,
    "output_throughput": 3993.4141023819643,
    "total_throughput": 8550.584470564329,
    "itl": 71.48146046559486,
    "ttft": 17271.791304830258,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2649,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.469317642319993,
    "arrivals": 66631,
    "finished_requests": 66314,
    "scheduler_time": 49.311791544509425
}
#Debug simulation 
Total elapsed time: 4.682823906186968. Arrivals time: 0.14820893062278628 Scheduler time: 4.339324041735381 Scheduler overhead time: 0.06416023336350918 Adapter cache time: 0.03783430717885494 Engine time: 0.06370282266288996 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-8/adapters_128_slots_64_rate_0.4-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-8/adapters_128_slots_64_rate_0.4-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [42 43 43]
Adapter prompts. [4320, 135, 4320, 4320, 66, 66, 4320, 66, 135, 135, 135, 66, 4320, 135, 66, 4320, 135, 66, 66, 66, 66, 135, 135, 4320, 135, 66, 135, 135, 135, 135, 4320, 135, 66, 135, 66, 4320, 4320, 66, 135, 135, 66, 135, 66, 135, 135, 4320, 4320, 4320, 4320, 135, 135, 66, 135, 4320, 4320, 135, 66, 66, 66, 4320, 135, 135, 135, 135, 4320, 135, 4320, 66, 66, 135, 66, 4320, 4320, 66, 66, 135, 135, 135, 66, 4320, 66, 4320, 135, 66, 4320, 4320, 135, 135, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 66, 4320, 66, 66, 4320, 135, 4320, 4320, 135, 4320, 66, 135, 4320, 66, 4320, 135, 66, 135, 135, 4320, 4320, 66, 66, 4320, 66, 66, 66, 135, 66]
Prompts retrieved: 194337 . Total input tokens: 43336435 . Total output tokens: 38206996
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 4.603980979882181,
    "estimated_duration": 3599.952210994312,
    "input_throughput": 4451.845485908125,
    "output_throughput": 3924.958213847335,
    "total_throughput": 8376.803699755461,
    "itl": 64.39135434232547,
    "ttft": 15300.076621232276,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2238,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.79857141350437,
    "arrivals": 65160,
    "finished_requests": 64885,
    "scheduler_time": 47.2629597724955
}
#Debug simulation 
Total elapsed time: 4.6040526842698455. Arrivals time: 0.14556060172617435 Scheduler time: 4.255426459945738 Scheduler overhead time: 0.06836355291306973 Adapter cache time: 0.03459667693823576 Engine time: 0.06813382310792804 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-16/adapters_128_slots_64_rate_0.4-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-16/adapters_128_slots_64_rate_0.4-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [42 43 43]
Adapter prompts. [4320, 135, 4320, 4320, 66, 66, 4320, 66, 135, 135, 135, 66, 4320, 135, 66, 4320, 135, 66, 66, 66, 66, 135, 135, 4320, 135, 66, 135, 135, 135, 135, 4320, 135, 66, 135, 66, 4320, 4320, 66, 135, 135, 66, 135, 66, 135, 135, 4320, 4320, 4320, 4320, 135, 135, 66, 135, 4320, 4320, 135, 66, 66, 66, 4320, 135, 135, 135, 135, 4320, 135, 4320, 66, 66, 135, 66, 4320, 4320, 66, 66, 135, 135, 135, 66, 4320, 66, 4320, 135, 66, 4320, 4320, 135, 135, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 66, 4320, 66, 66, 4320, 135, 4320, 4320, 135, 4320, 66, 135, 4320, 66, 4320, 135, 66, 135, 135, 4320, 4320, 66, 66, 4320, 66, 66, 66, 135, 66]
Prompts retrieved: 194337 . Total input tokens: 43336435 . Total output tokens: 38206996
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 4.605447086971253,
    "estimated_duration": 3599.96352989326,
    "input_throughput": 4451.326483431108,
    "output_throughput": 3923.9958634855525,
    "total_throughput": 8375.32234691666,
    "itl": 65.05484333971955,
    "ttft": 15798.587594868373,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2247,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.396460952018096,
    "arrivals": 65160,
    "finished_requests": 64876,
    "scheduler_time": 47.36254651121337
}
#Debug simulation 
Total elapsed time: 4.605518025811762. Arrivals time: 0.14569574454799294 Scheduler time: 4.257955851498991 Scheduler overhead time: 0.0679930904880166 Adapter cache time: 0.03469885466620326 Engine time: 0.06750520970672369 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-32/adapters_128_slots_64_rate_0.4-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-32/adapters_128_slots_64_rate_0.4-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [42 43 43]
Adapter prompts. [4320, 135, 4320, 4320, 66, 66, 4320, 66, 135, 135, 135, 66, 4320, 135, 66, 4320, 135, 66, 66, 66, 66, 135, 135, 4320, 135, 66, 135, 135, 135, 135, 4320, 135, 66, 135, 66, 4320, 4320, 66, 135, 135, 66, 135, 66, 135, 135, 4320, 4320, 4320, 4320, 135, 135, 66, 135, 4320, 4320, 135, 66, 66, 66, 4320, 135, 135, 135, 135, 4320, 135, 4320, 66, 66, 135, 66, 4320, 4320, 66, 66, 135, 135, 135, 66, 4320, 66, 4320, 135, 66, 4320, 4320, 135, 135, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 66, 4320, 66, 66, 4320, 135, 4320, 4320, 135, 4320, 66, 135, 4320, 66, 4320, 135, 66, 135, 135, 4320, 4320, 66, 66, 4320, 66, 66, 66, 135, 66]
Prompts retrieved: 194337 . Total input tokens: 43336435 . Total output tokens: 38206996
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 4.602304640226066,
    "estimated_duration": 3599.9301997655602,
    "input_throughput": 4451.303806124786,
    "output_throughput": 3924.0105269040896,
    "total_throughput": 8375.314333028875,
    "itl": 65.07624013545079,
    "ttft": 15853.87408357353,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2248,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.84094082655827,
    "arrivals": 65160,
    "finished_requests": 64875,
    "scheduler_time": 47.36529484421139
}
#Debug simulation 
Total elapsed time: 4.6023771949112415. Arrivals time: 0.1451347153633833 Scheduler time: 4.2551672495901585 Scheduler overhead time: 0.06795447086915374 Adapter cache time: 0.03442887403070927 Engine time: 0.06797003000974655 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-16/adapters_128_slots_64_rate_0.4-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-16/adapters_128_slots_64_rate_0.4-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [42 43 43]
Adapter prompts. [4320, 135, 4320, 4320, 66, 66, 4320, 66, 135, 135, 135, 66, 4320, 135, 66, 4320, 135, 66, 66, 66, 66, 135, 135, 4320, 135, 66, 135, 135, 135, 135, 4320, 135, 66, 135, 66, 4320, 4320, 66, 135, 135, 66, 135, 66, 135, 135, 4320, 4320, 4320, 4320, 135, 135, 66, 135, 4320, 4320, 135, 66, 66, 66, 4320, 135, 135, 135, 135, 4320, 135, 4320, 66, 66, 135, 66, 4320, 4320, 66, 66, 135, 135, 135, 66, 4320, 66, 4320, 135, 66, 4320, 4320, 135, 135, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 66, 4320, 66, 66, 4320, 135, 4320, 4320, 135, 4320, 66, 135, 4320, 66, 4320, 135, 66, 135, 135, 4320, 4320, 66, 66, 4320, 66, 66, 66, 135, 66]
Prompts retrieved: 194337 . Total input tokens: 43336435 . Total output tokens: 38206996
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 4.602988794911653,
    "estimated_duration": 3599.912821336467,
    "input_throughput": 4451.7955837748095,
    "output_throughput": 3924.9183803163533,
    "total_throughput": 8376.713964091163,
    "itl": 64.40899397475765,
    "ttft": 15355.175715885573,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2237,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.21093919617623,
    "arrivals": 65160,
    "finished_requests": 64884,
    "scheduler_time": 47.265367450690235
}
#Debug simulation 
Total elapsed time: 4.603063292335719. Arrivals time: 0.1468515656888485 Scheduler time: 4.253386950585991 Scheduler overhead time: 0.06848824303597212 Adapter cache time: 0.034633387345820665 Engine time: 0.06790315546095371 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-32/adapters_128_slots_64_rate_0.4-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-32/adapters_128_slots_64_rate_0.4-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [42 43 43]
Adapter prompts. [4320, 135, 4320, 4320, 66, 66, 4320, 66, 135, 135, 135, 66, 4320, 135, 66, 4320, 135, 66, 66, 66, 66, 135, 135, 4320, 135, 66, 135, 135, 135, 135, 4320, 135, 66, 135, 66, 4320, 4320, 66, 135, 135, 66, 135, 66, 135, 135, 4320, 4320, 4320, 4320, 135, 135, 66, 135, 4320, 4320, 135, 66, 66, 66, 4320, 135, 135, 135, 135, 4320, 135, 4320, 66, 66, 135, 66, 4320, 4320, 66, 66, 135, 135, 135, 66, 4320, 66, 4320, 135, 66, 4320, 4320, 135, 135, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 66, 4320, 66, 66, 4320, 135, 4320, 4320, 135, 4320, 66, 135, 4320, 66, 4320, 135, 66, 135, 135, 4320, 4320, 66, 66, 4320, 66, 66, 66, 135, 66]
Prompts retrieved: 194337 . Total input tokens: 43336435 . Total output tokens: 38206996
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 4.563245278783143,
    "estimated_duration": 3599.917687273429,
    "input_throughput": 4451.319277840722,
    "output_throughput": 3924.024165868951,
    "total_throughput": 8375.343443709673,
    "itl": 65.06724556566245,
    "ttft": 15853.803853319883,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2247,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.66654966036298,
    "arrivals": 65160,
    "finished_requests": 64875,
    "scheduler_time": 47.36396478207948
}
#Debug simulation 
Total elapsed time: 4.563317711930722. Arrivals time: 0.14580724714323878 Scheduler time: 4.217094810679555 Scheduler overhead time: 0.06778500368818641 Adapter cache time: 0.03446471272036433 Engine time: 0.06653516832739115 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-16/adapters_128_slots_64_rate_0.4-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-16/adapters_128_slots_64_rate_0.4-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [42 43 43]
Adapter prompts. [4320, 135, 4320, 4320, 66, 66, 4320, 66, 135, 135, 135, 66, 4320, 135, 66, 4320, 135, 66, 66, 66, 66, 135, 135, 4320, 135, 66, 135, 135, 135, 135, 4320, 135, 66, 135, 66, 4320, 4320, 66, 135, 135, 66, 135, 66, 135, 135, 4320, 4320, 4320, 4320, 135, 135, 66, 135, 4320, 4320, 135, 66, 66, 66, 4320, 135, 135, 135, 135, 4320, 135, 4320, 66, 66, 135, 66, 4320, 4320, 66, 66, 135, 135, 135, 66, 4320, 66, 4320, 135, 66, 4320, 4320, 135, 135, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 66, 4320, 66, 66, 4320, 135, 4320, 4320, 135, 4320, 66, 135, 4320, 66, 4320, 135, 66, 135, 135, 4320, 4320, 66, 66, 4320, 66, 66, 66, 135, 66]
Prompts retrieved: 194337 . Total input tokens: 43336435 . Total output tokens: 38206996
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 4.594009330030531,
    "estimated_duration": 3599.9427692243403,
    "input_throughput": 4451.857162010697,
    "output_throughput": 3924.968508053377,
    "total_throughput": 8376.825670064074,
    "itl": 64.36794309235377,
    "ttft": 15299.991841410285,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2237,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.28083114405708,
    "arrivals": 65160,
    "finished_requests": 64885,
    "scheduler_time": 47.25919455669773
}
#Debug simulation 
Total elapsed time: 4.594081954099238. Arrivals time: 0.1451655155979097 Scheduler time: 4.246856735553592 Scheduler overhead time: 0.06812111986801028 Adapter cache time: 0.03471307689324021 Engine time: 0.067364611197263 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-32/adapters_128_slots_64_rate_0.4-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-32/adapters_128_slots_64_rate_0.4-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [42 43 43]
Adapter prompts. [4320, 135, 4320, 4320, 66, 66, 4320, 66, 135, 135, 135, 66, 4320, 135, 66, 4320, 135, 66, 66, 66, 66, 135, 135, 4320, 135, 66, 135, 135, 135, 135, 4320, 135, 66, 135, 66, 4320, 4320, 66, 135, 135, 66, 135, 66, 135, 135, 4320, 4320, 4320, 4320, 135, 135, 66, 135, 4320, 4320, 135, 66, 66, 66, 4320, 135, 135, 135, 135, 4320, 135, 4320, 66, 66, 135, 66, 4320, 4320, 66, 66, 135, 135, 135, 66, 4320, 66, 4320, 135, 66, 4320, 4320, 135, 135, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 66, 4320, 66, 66, 4320, 135, 4320, 4320, 135, 4320, 66, 135, 4320, 66, 4320, 135, 66, 135, 135, 4320, 4320, 66, 66, 4320, 66, 66, 66, 135, 66]
Prompts retrieved: 194337 . Total input tokens: 43336435 . Total output tokens: 38206996
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 4.612640682142228,
    "estimated_duration": 3599.959639019907,
    "input_throughput": 4451.836300132301,
    "output_throughput": 3924.9501152315183,
    "total_throughput": 8376.78641536382,
    "itl": 64.47096613799127,
    "ttft": 15300.103880239089,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2239,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.474305741097503,
    "arrivals": 65160,
    "finished_requests": 64885,
    "scheduler_time": 47.27526872354131
}
#Debug simulation 
Total elapsed time: 4.612738288938999. Arrivals time: 0.14599561132490635 Scheduler time: 4.263514949940145 Scheduler overhead time: 0.06873694760724902 Adapter cache time: 0.03452445147559047 Engine time: 0.06815933808684349 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-8/adapters_128_slots_64_rate_0.4-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-8/adapters_128_slots_64_rate_0.4-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [42 43 43]
Adapter prompts. [4320, 135, 4320, 4320, 33, 33, 4320, 33, 135, 135, 135, 33, 4320, 135, 33, 4320, 135, 33, 33, 33, 33, 135, 135, 4320, 135, 33, 135, 135, 135, 135, 4320, 135, 33, 135, 33, 4320, 4320, 33, 135, 135, 33, 135, 33, 135, 135, 4320, 4320, 4320, 4320, 135, 135, 33, 135, 4320, 4320, 135, 33, 33, 33, 4320, 135, 135, 135, 135, 4320, 135, 4320, 33, 33, 135, 33, 4320, 4320, 33, 33, 135, 135, 135, 33, 4320, 33, 4320, 135, 33, 4320, 4320, 135, 135, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 33, 4320, 33, 33, 4320, 135, 4320, 4320, 135, 4320, 33, 135, 4320, 33, 4320, 135, 33, 135, 135, 4320, 4320, 33, 33, 4320, 33, 33, 33, 135, 33]
Prompts retrieved: 192951 . Total input tokens: 43015888 . Total output tokens: 37927634
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 4.591301923152059,
    "estimated_duration": 3599.9949381748957,
    "input_throughput": 4445.009861072917,
    "output_throughput": 3889.8451915877895,
    "total_throughput": 8334.855052660707,
    "itl": 61.61409629745677,
    "ttft": 14850.069475064078,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1688,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.161746445931787,
    "arrivals": 64686,
    "finished_requests": 64421,
    "scheduler_time": 46.32181606555232
}
#Debug simulation 
Total elapsed time: 4.5913895620033145. Arrivals time: 0.14795652916654944 Scheduler time: 4.239176211878657 Scheduler overhead time: 0.07067252555862069 Adapter cache time: 0.031154326628893614 Engine time: 0.06953210523352027 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-16/adapters_128_slots_64_rate_0.4-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-16/adapters_128_slots_64_rate_0.4-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [42 43 43]
Adapter prompts. [4320, 135, 4320, 4320, 33, 33, 4320, 33, 135, 135, 135, 33, 4320, 135, 33, 4320, 135, 33, 33, 33, 33, 135, 135, 4320, 135, 33, 135, 135, 135, 135, 4320, 135, 33, 135, 33, 4320, 4320, 33, 135, 135, 33, 135, 33, 135, 135, 4320, 4320, 4320, 4320, 135, 135, 33, 135, 4320, 4320, 135, 33, 33, 33, 4320, 135, 135, 135, 135, 4320, 135, 4320, 33, 33, 135, 33, 4320, 4320, 33, 33, 135, 135, 135, 33, 4320, 33, 4320, 135, 33, 4320, 4320, 135, 135, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 33, 4320, 33, 33, 4320, 135, 4320, 4320, 135, 4320, 33, 135, 4320, 33, 4320, 135, 33, 135, 135, 4320, 4320, 33, 33, 4320, 33, 33, 33, 135, 33]
Prompts retrieved: 192951 . Total input tokens: 43015888 . Total output tokens: 37927634
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 4.57751093711704,
    "estimated_duration": 3599.9859557069854,
    "input_throughput": 4445.02095199353,
    "output_throughput": 3889.8548972949893,
    "total_throughput": 8334.875849288519,
    "itl": 61.66456504636631,
    "ttft": 14850.166980861333,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1689,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.308097318294314,
    "arrivals": 64686,
    "finished_requests": 64421,
    "scheduler_time": 46.33023301477547
}
#Debug simulation 
Total elapsed time: 4.5775873912498355. Arrivals time: 0.14655959140509367 Scheduler time: 4.227184447925538 Scheduler overhead time: 0.07034923415631056 Adapter cache time: 0.03083596331998706 Engine time: 0.07001292938366532 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-32/adapters_128_slots_64_rate_0.4-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-32/adapters_128_slots_64_rate_0.4-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [42 43 43]
Adapter prompts. [4320, 135, 4320, 4320, 33, 33, 4320, 33, 135, 135, 135, 33, 4320, 135, 33, 4320, 135, 33, 33, 33, 33, 135, 135, 4320, 135, 33, 135, 135, 135, 135, 4320, 135, 33, 135, 33, 4320, 4320, 33, 135, 135, 33, 135, 33, 135, 135, 4320, 4320, 4320, 4320, 135, 135, 33, 135, 4320, 4320, 135, 33, 33, 33, 4320, 135, 135, 135, 135, 4320, 135, 4320, 33, 33, 135, 33, 4320, 4320, 33, 33, 135, 135, 135, 33, 4320, 33, 4320, 135, 33, 4320, 4320, 135, 135, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 33, 4320, 33, 33, 4320, 135, 4320, 4320, 135, 4320, 33, 135, 4320, 33, 4320, 135, 33, 135, 135, 4320, 4320, 33, 33, 4320, 33, 33, 33, 135, 33]
Prompts retrieved: 192951 . Total input tokens: 43015888 . Total output tokens: 37927634
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 4.605673610698432,
    "estimated_duration": 3599.9932342878565,
    "input_throughput": 4445.01196490873,
    "output_throughput": 3889.8470326625848,
    "total_throughput": 8334.858997571315,
    "itl": 61.679806971933544,
    "ttft": 14850.122407513265,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1690,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.64036822868493,
    "arrivals": 64686,
    "finished_requests": 64421,
    "scheduler_time": 46.332772446720945
}
#Debug simulation 
Total elapsed time: 4.6057477267459035. Arrivals time: 0.14760379679501057 Scheduler time: 4.253175200428814 Scheduler overhead time: 0.07062771636992693 Adapter cache time: 0.031034347601234913 Engine time: 0.0703964582644403 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-16/adapters_128_slots_64_rate_0.4-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-16/adapters_128_slots_64_rate_0.4-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [42 43 43]
Adapter prompts. [4320, 135, 4320, 4320, 33, 33, 4320, 33, 135, 135, 135, 33, 4320, 135, 33, 4320, 135, 33, 33, 33, 33, 135, 135, 4320, 135, 33, 135, 135, 135, 135, 4320, 135, 33, 135, 33, 4320, 4320, 33, 135, 135, 33, 135, 33, 135, 135, 4320, 4320, 4320, 4320, 135, 135, 33, 135, 4320, 4320, 135, 33, 33, 33, 4320, 135, 135, 135, 135, 4320, 135, 4320, 33, 33, 135, 33, 4320, 4320, 33, 33, 135, 135, 135, 33, 4320, 33, 4320, 135, 33, 4320, 4320, 135, 135, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 33, 4320, 33, 33, 4320, 135, 4320, 4320, 135, 4320, 33, 135, 4320, 33, 4320, 135, 33, 135, 135, 4320, 4320, 33, 33, 4320, 33, 33, 33, 135, 33]
Prompts retrieved: 192951 . Total input tokens: 43015888 . Total output tokens: 37927634
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 4.562324630096555,
    "estimated_duration": 3600.0274314516514,
    "input_throughput": 4445.024185148327,
    "output_throughput": 3889.863693164492,
    "total_throughput": 8334.887878312818,
    "itl": 61.63140064039562,
    "ttft": 14794.408306901005,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1689,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.50431737474648,
    "arrivals": 64686,
    "finished_requests": 64422,
    "scheduler_time": 46.32520607331106
}
#Debug simulation 
Total elapsed time: 4.562399606220424. Arrivals time: 0.14615139039233327 Scheduler time: 4.210676390212029 Scheduler overhead time: 0.07065184414386749 Adapter cache time: 0.030934167094528675 Engine time: 0.07115269545465708 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-32/adapters_128_slots_64_rate_0.4-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-32/adapters_128_slots_64_rate_0.4-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [42 43 43]
Adapter prompts. [4320, 135, 4320, 4320, 33, 33, 4320, 33, 135, 135, 135, 33, 4320, 135, 33, 4320, 135, 33, 33, 33, 33, 135, 135, 4320, 135, 33, 135, 135, 135, 135, 4320, 135, 33, 135, 33, 4320, 4320, 33, 135, 135, 33, 135, 33, 135, 135, 4320, 4320, 4320, 4320, 135, 135, 33, 135, 4320, 4320, 135, 33, 33, 33, 4320, 135, 135, 135, 135, 4320, 135, 4320, 33, 33, 135, 33, 4320, 4320, 33, 33, 135, 135, 135, 33, 4320, 33, 4320, 135, 33, 4320, 4320, 135, 135, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 33, 4320, 33, 33, 4320, 135, 4320, 4320, 135, 4320, 33, 135, 4320, 33, 4320, 135, 33, 135, 135, 4320, 4320, 33, 33, 4320, 33, 33, 33, 135, 33]
Prompts retrieved: 192951 . Total input tokens: 43015888 . Total output tokens: 37927634
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 4.55099187605083,
    "estimated_duration": 3600.012315534136,
    "input_throughput": 4444.988404887102,
    "output_throughput": 3889.826415197222,
    "total_throughput": 8334.814820084324,
    "itl": 61.673974979543964,
    "ttft": 14850.277027258644,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1689,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.512371310051353,
    "arrivals": 64686,
    "finished_requests": 64421,
    "scheduler_time": 46.33203218570796
}
#Debug simulation 
Total elapsed time: 4.551064194180071. Arrivals time: 0.14476843923330307 Scheduler time: 4.202581430319697 Scheduler overhead time: 0.07074134470894933 Adapter cache time: 0.03094973089173436 Engine time: 0.0692456136457622 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-16/adapters_128_slots_64_rate_0.4-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-16/adapters_128_slots_64_rate_0.4-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [42 43 43]
Adapter prompts. [4320, 135, 4320, 4320, 33, 33, 4320, 33, 135, 135, 135, 33, 4320, 135, 33, 4320, 135, 33, 33, 33, 33, 135, 135, 4320, 135, 33, 135, 135, 135, 135, 4320, 135, 33, 135, 33, 4320, 4320, 33, 135, 135, 33, 135, 33, 135, 135, 4320, 4320, 4320, 4320, 135, 135, 33, 135, 4320, 4320, 135, 33, 33, 33, 4320, 135, 135, 135, 135, 4320, 135, 4320, 33, 33, 135, 33, 4320, 4320, 33, 33, 135, 135, 135, 33, 4320, 33, 4320, 135, 33, 4320, 4320, 135, 135, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 33, 4320, 33, 33, 4320, 135, 4320, 4320, 135, 4320, 33, 135, 4320, 33, 4320, 135, 33, 135, 135, 4320, 4320, 33, 33, 4320, 33, 33, 33, 135, 33]
Prompts retrieved: 192951 . Total input tokens: 43015888 . Total output tokens: 37927634
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 4.5684240949340165,
    "estimated_duration": 3600.009617502564,
    "input_throughput": 4445.046180488045,
    "output_throughput": 3889.8829414002325,
    "total_throughput": 8334.929121888277,
    "itl": 61.599138328867824,
    "ttft": 14794.357175550616,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1689,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.78244246862396,
    "arrivals": 64686,
    "finished_requests": 64422,
    "scheduler_time": 46.319400949663034
}
#Debug simulation 
Total elapsed time: 4.568533896934241. Arrivals time: 0.14564401702955365 Scheduler time: 4.2200607606209815 Scheduler overhead time: 0.06989862862974405 Adapter cache time: 0.030998608097434044 Engine time: 0.06906297896057367 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-32/adapters_128_slots_64_rate_0.4-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-32/adapters_128_slots_64_rate_0.4-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [42 43 43]
Adapter prompts. [4320, 135, 4320, 4320, 33, 33, 4320, 33, 135, 135, 135, 33, 4320, 135, 33, 4320, 135, 33, 33, 33, 33, 135, 135, 4320, 135, 33, 135, 135, 135, 135, 4320, 135, 33, 135, 33, 4320, 4320, 33, 135, 135, 33, 135, 33, 135, 135, 4320, 4320, 4320, 4320, 135, 135, 33, 135, 4320, 4320, 135, 33, 33, 33, 4320, 135, 135, 135, 135, 4320, 135, 4320, 33, 33, 135, 33, 4320, 4320, 33, 33, 135, 135, 135, 33, 4320, 33, 4320, 135, 33, 4320, 4320, 135, 135, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 33, 4320, 33, 33, 4320, 135, 4320, 4320, 135, 4320, 33, 135, 4320, 33, 4320, 135, 33, 135, 135, 4320, 4320, 33, 33, 4320, 33, 33, 33, 135, 33]
Prompts retrieved: 192951 . Total input tokens: 43015888 . Total output tokens: 37927634
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 4.729761580936611,
    "estimated_duration": 3600.018744954369,
    "input_throughput": 4445.034910562064,
    "output_throughput": 3889.87307902962,
    "total_throughput": 8334.907989591684,
    "itl": 61.66835699517461,
    "ttft": 14794.39557127688,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1689,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.404670378211708,
    "arrivals": 64686,
    "finished_requests": 64422,
    "scheduler_time": 46.33129824900875
}
#Debug simulation 
Total elapsed time: 4.7298472709953785. Arrivals time: 0.1506844824180007 Scheduler time: 4.374559635762125 Scheduler overhead time: 0.07076889835298061 Adapter cache time: 0.030901669058948755 Engine time: 0.06997234374284744 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-8/adapters_128_slots_64_rate_0.4-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-8/adapters_128_slots_64_rate_0.4-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [42 43 43]
Adapter prompts. [4320, 66, 4320, 4320, 33, 33, 4320, 33, 66, 66, 66, 33, 4320, 66, 33, 4320, 66, 33, 33, 33, 33, 66, 66, 4320, 66, 33, 66, 66, 66, 66, 4320, 66, 33, 66, 33, 4320, 4320, 33, 66, 66, 33, 66, 33, 66, 66, 4320, 4320, 4320, 4320, 66, 66, 33, 66, 4320, 4320, 66, 33, 33, 33, 4320, 66, 66, 66, 66, 4320, 66, 4320, 33, 33, 66, 33, 4320, 4320, 33, 33, 66, 66, 66, 33, 4320, 33, 4320, 66, 33, 4320, 4320, 66, 66, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 33, 4320, 33, 33, 4320, 66, 4320, 4320, 66, 4320, 33, 66, 4320, 33, 4320, 66, 33, 66, 66, 4320, 4320, 33, 33, 4320, 33, 33, 33, 66, 33]
Prompts retrieved: 189984 . Total input tokens: 42342655 . Total output tokens: 37357734
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 4.462053452152759,
    "estimated_duration": 3600.028427659477,
    "input_throughput": 4397.081111465408,
    "output_throughput": 3832.3922372384714,
    "total_throughput": 8229.47334870388,
    "itl": 57.25414640873508,
    "ttft": 12065.780419069142,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1100,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.273649935145098,
    "arrivals": 63755,
    "finished_requests": 63542,
    "scheduler_time": 44.67170096987631
}
#Debug simulation 
Total elapsed time: 4.46212745597586. Arrivals time: 0.144397952593863 Scheduler time: 4.115979532711208 Scheduler overhead time: 0.07231529103592038 Adapter cache time: 0.02540381858125329 Engine time: 0.07040115771815181 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-16/adapters_128_slots_64_rate_0.4-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-16/adapters_128_slots_64_rate_0.4-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [42 43 43]
Adapter prompts. [4320, 66, 4320, 4320, 33, 33, 4320, 33, 66, 66, 66, 33, 4320, 66, 33, 4320, 66, 33, 33, 33, 33, 66, 66, 4320, 66, 33, 66, 66, 66, 66, 4320, 66, 33, 66, 33, 4320, 4320, 33, 66, 66, 33, 66, 33, 66, 66, 4320, 4320, 4320, 4320, 66, 66, 33, 66, 4320, 4320, 66, 33, 33, 33, 4320, 66, 66, 66, 66, 4320, 66, 4320, 33, 33, 66, 33, 4320, 4320, 33, 33, 66, 66, 66, 33, 4320, 33, 4320, 66, 33, 4320, 4320, 66, 66, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 33, 4320, 33, 33, 4320, 66, 4320, 4320, 66, 4320, 33, 66, 4320, 33, 4320, 66, 33, 66, 66, 4320, 4320, 33, 33, 4320, 33, 33, 33, 66, 33]
Prompts retrieved: 189984 . Total input tokens: 42342655 . Total output tokens: 37357734
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 4.461944628041238,
    "estimated_duration": 3600.0402736481,
    "input_throughput": 4397.066642801487,
    "output_throughput": 3832.3796266920913,
    "total_throughput": 8229.44626949358,
    "itl": 57.279502082569664,
    "ttft": 12122.176294638784,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1100,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.001008820813158,
    "arrivals": 63755,
    "finished_requests": 63542,
    "scheduler_time": 44.676773464866
}
#Debug simulation 
Total elapsed time: 4.462016763165593. Arrivals time: 0.14393913513049483 Scheduler time: 4.115652274340391 Scheduler overhead time: 0.07230371003970504 Adapter cache time: 0.0254319510422647 Engine time: 0.0710913734510541 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-32/adapters_128_slots_64_rate_0.4-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-32/adapters_128_slots_64_rate_0.4-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [42 43 43]
Adapter prompts. [4320, 66, 4320, 4320, 33, 33, 4320, 33, 66, 66, 66, 33, 4320, 66, 33, 4320, 66, 33, 33, 33, 33, 66, 66, 4320, 66, 33, 66, 66, 66, 66, 4320, 66, 33, 66, 33, 4320, 4320, 33, 66, 66, 33, 66, 33, 66, 66, 4320, 4320, 4320, 4320, 66, 66, 33, 66, 4320, 4320, 66, 33, 33, 33, 4320, 66, 66, 66, 66, 4320, 66, 4320, 33, 33, 66, 33, 4320, 4320, 33, 33, 66, 66, 66, 33, 4320, 33, 4320, 66, 33, 4320, 4320, 66, 66, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 33, 4320, 33, 33, 4320, 66, 4320, 4320, 66, 4320, 33, 66, 4320, 33, 4320, 66, 33, 66, 66, 4320, 4320, 33, 33, 4320, 33, 33, 33, 66, 33]
Prompts retrieved: 189984 . Total input tokens: 42342655 . Total output tokens: 37357734
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 4.487964675761759,
    "estimated_duration": 3600.041414071334,
    "input_throughput": 4397.0652498961335,
    "output_throughput": 3832.378412668622,
    "total_throughput": 8229.443662564754,
    "itl": 57.285749089388204,
    "ttft": 12122.287761729334,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1098,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.192550038420595,
    "arrivals": 63755,
    "finished_requests": 63542,
    "scheduler_time": 44.67809367208042
}
#Debug simulation 
Total elapsed time: 4.488035911694169. Arrivals time: 0.1446951450780034 Scheduler time: 4.141051514539868 Scheduler overhead time: 0.07233034074306488 Adapter cache time: 0.025452804751694202 Engine time: 0.07070000981912017 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-16/adapters_128_slots_64_rate_0.4-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-16/adapters_128_slots_64_rate_0.4-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [42 43 43]
Adapter prompts. [4320, 66, 4320, 4320, 33, 33, 4320, 33, 66, 66, 66, 33, 4320, 66, 33, 4320, 66, 33, 33, 33, 33, 66, 66, 4320, 66, 33, 66, 66, 66, 66, 4320, 66, 33, 66, 33, 4320, 4320, 33, 66, 66, 33, 66, 33, 66, 66, 4320, 4320, 4320, 4320, 66, 66, 33, 66, 4320, 4320, 66, 33, 33, 33, 4320, 66, 66, 66, 66, 4320, 66, 4320, 33, 33, 66, 33, 4320, 4320, 33, 33, 66, 66, 66, 33, 4320, 33, 4320, 66, 33, 4320, 4320, 66, 66, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 33, 4320, 33, 33, 4320, 66, 4320, 4320, 66, 4320, 33, 66, 4320, 33, 4320, 66, 33, 66, 66, 4320, 4320, 33, 33, 4320, 33, 33, 33, 66, 33]
Prompts retrieved: 189984 . Total input tokens: 42342655 . Total output tokens: 37357734
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 4.455215003807098,
    "estimated_duration": 3600.005924709374,
    "input_throughput": 4397.062485745187,
    "output_throughput": 3832.3214707247384,
    "total_throughput": 8229.383956469925,
    "itl": 57.26110857637787,
    "ttft": 12122.258634919343,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1100,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.485978839714066,
    "arrivals": 63755,
    "finished_requests": 63541,
    "scheduler_time": 44.67281452355214
}
#Debug simulation 
Total elapsed time: 4.455311503726989. Arrivals time: 0.14369632955640554 Scheduler time: 4.10920842923224 Scheduler overhead time: 0.07236141804605722 Adapter cache time: 0.025835279375314713 Engine time: 0.07053250446915627 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-32/adapters_128_slots_64_rate_0.4-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-32/adapters_128_slots_64_rate_0.4-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [42 43 43]
Adapter prompts. [4320, 66, 4320, 4320, 33, 33, 4320, 33, 66, 66, 66, 33, 4320, 66, 33, 4320, 66, 33, 33, 33, 33, 66, 66, 4320, 66, 33, 66, 66, 66, 66, 4320, 66, 33, 66, 33, 4320, 4320, 33, 66, 66, 33, 66, 33, 66, 66, 4320, 4320, 4320, 4320, 66, 66, 33, 66, 4320, 4320, 66, 33, 33, 33, 4320, 66, 66, 66, 66, 4320, 66, 4320, 33, 33, 66, 33, 4320, 4320, 33, 33, 66, 66, 66, 33, 4320, 33, 4320, 66, 33, 4320, 4320, 66, 66, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 33, 4320, 33, 33, 4320, 66, 4320, 4320, 66, 4320, 33, 66, 4320, 33, 4320, 66, 33, 66, 66, 4320, 4320, 33, 33, 4320, 33, 33, 33, 66, 33]
Prompts retrieved: 189984 . Total input tokens: 42342655 . Total output tokens: 37357734
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 4.478545849211514,
    "estimated_duration": 3600.0433703164804,
    "input_throughput": 4397.062860553376,
    "output_throughput": 3832.376330173802,
    "total_throughput": 8229.439190727178,
    "itl": 57.28370599863708,
    "ttft": 12122.261055181978,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1098,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.116123800249774,
    "arrivals": 63755,
    "finished_requests": 63542,
    "scheduler_time": 44.67752237008596
}
#Debug simulation 
Total elapsed time: 4.478618699125946. Arrivals time: 0.1454913984052837 Scheduler time: 4.131048801355064 Scheduler overhead time: 0.07241990277543664 Adapter cache time: 0.02538572298362851 Engine time: 0.07068901415914297 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-16/adapters_128_slots_64_rate_0.4-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-16/adapters_128_slots_64_rate_0.4-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [42 43 43]
Adapter prompts. [4320, 66, 4320, 4320, 33, 33, 4320, 33, 66, 66, 66, 33, 4320, 66, 33, 4320, 66, 33, 33, 33, 33, 66, 66, 4320, 66, 33, 66, 66, 66, 66, 4320, 66, 33, 66, 33, 4320, 4320, 33, 66, 66, 33, 66, 33, 66, 66, 4320, 4320, 4320, 4320, 66, 66, 33, 66, 4320, 4320, 66, 33, 33, 33, 4320, 66, 66, 66, 66, 4320, 66, 4320, 33, 33, 66, 33, 4320, 4320, 33, 33, 66, 66, 66, 33, 4320, 33, 4320, 66, 33, 4320, 4320, 66, 66, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 33, 4320, 33, 33, 4320, 66, 4320, 4320, 66, 4320, 33, 66, 4320, 33, 4320, 66, 33, 66, 66, 4320, 4320, 33, 33, 4320, 33, 33, 33, 66, 33]
Prompts retrieved: 189984 . Total input tokens: 42342655 . Total output tokens: 37357734
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 4.472247632686049,
    "estimated_duration": 3600.0504796188975,
    "input_throughput": 4397.054455101898,
    "output_throughput": 3832.421816890897,
    "total_throughput": 8229.476271992795,
    "itl": 57.24511742646343,
    "ttft": 12065.703595170928,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1100,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.022313034627551,
    "arrivals": 63755,
    "finished_requests": 63543,
    "scheduler_time": 44.67030548614948
}
#Debug simulation 
Total elapsed time: 4.472342245746404. Arrivals time: 0.14423116715624928 Scheduler time: 4.124797724653035 Scheduler overhead time: 0.07266747718676925 Adapter cache time: 0.025463310070335865 Engine time: 0.07139711501076818 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-32/adapters_128_slots_64_rate_0.4-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-32/adapters_128_slots_64_rate_0.4-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [42 43 43]
Adapter prompts. [4320, 66, 4320, 4320, 33, 33, 4320, 33, 66, 66, 66, 33, 4320, 66, 33, 4320, 66, 33, 33, 33, 33, 66, 66, 4320, 66, 33, 66, 66, 66, 66, 4320, 66, 33, 66, 33, 4320, 4320, 33, 66, 66, 33, 66, 33, 66, 66, 4320, 4320, 4320, 4320, 66, 66, 33, 66, 4320, 4320, 66, 33, 33, 33, 4320, 66, 66, 66, 66, 4320, 66, 4320, 33, 33, 66, 33, 4320, 4320, 33, 33, 66, 66, 66, 33, 4320, 33, 4320, 66, 33, 4320, 4320, 66, 66, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 33, 4320, 33, 33, 4320, 66, 4320, 4320, 66, 4320, 33, 66, 4320, 33, 4320, 66, 33, 66, 66, 4320, 4320, 33, 33, 4320, 33, 33, 33, 66, 33]
Prompts retrieved: 189984 . Total input tokens: 42342655 . Total output tokens: 37357734
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 4.468484146054834,
    "estimated_duration": 3600.0461857515093,
    "input_throughput": 4397.05942180727,
    "output_throughput": 3832.3733330437635,
    "total_throughput": 8229.432754851034,
    "itl": 57.28024299745002,
    "ttft": 12122.079295831994,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1100,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.062684575654577,
    "arrivals": 63755,
    "finished_requests": 63542,
    "scheduler_time": 44.67717506698715
}
#Debug simulation 
Total elapsed time: 4.468585080001503. Arrivals time: 0.14485057955607772 Scheduler time: 4.1199157712981105 Scheduler overhead time: 0.07314469898119569 Adapter cache time: 0.025572411715984344 Engine time: 0.07127676159143448 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-8-8/adapters_128_slots_64_rate_0.1-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-8-8/adapters_128_slots_64_rate_0.1-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 270, 270, 1080, 270, 540, 540, 540, 270, 1080, 540, 270, 1080, 540, 270, 270, 270, 270, 540, 540, 1080, 540, 270, 540, 540, 540, 540, 1080, 540, 270, 540, 270, 1080, 1080, 270, 540, 540, 270, 540, 270, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 270, 540, 1080, 1080, 540, 270, 270, 270, 1080, 540, 540, 540, 540, 1080, 540, 1080, 270, 270, 540, 270, 1080, 1080, 270, 270, 540, 540, 540, 270, 1080, 270, 1080, 540, 270, 1080, 1080, 540, 540, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 270, 1080, 270, 270, 1080, 540, 1080, 1080, 540, 1080, 270, 540, 1080, 270, 1080, 540, 270, 540, 540, 1080, 1080, 270, 270, 1080, 270, 270, 270, 540, 270]
Prompts retrieved: 81000 . Total input tokens: 18042231 . Total output tokens: 15885629
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 2.2611361970193684,
    "estimated_duration": 3599.963437957379,
    "input_throughput": 1852.2163113365884,
    "output_throughput": 1605.5265837031618,
    "total_throughput": 3457.7428950397502,
    "itl": 36.734683326851496,
    "ttft": 10159.885272937534,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10939,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 72.33314240050021,
    "arrivals": 27111,
    "finished_requests": 27035,
    "scheduler_time": 5.783872050158672
}
#Debug simulation 
Total elapsed time: 2.2612080429680645. Arrivals time: 0.07468736544251442 Scheduler time: 1.826863291207701 Scheduler overhead time: 0.09497549384832382 Adapter cache time: 0.12674316903576255 Engine time: 0.0930647668428719 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-8-16/adapters_128_slots_64_rate_0.1-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-8-16/adapters_128_slots_64_rate_0.1-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 270, 270, 1080, 270, 540, 540, 540, 270, 1080, 540, 270, 1080, 540, 270, 270, 270, 270, 540, 540, 1080, 540, 270, 540, 540, 540, 540, 1080, 540, 270, 540, 270, 1080, 1080, 270, 540, 540, 270, 540, 270, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 270, 540, 1080, 1080, 540, 270, 270, 270, 1080, 540, 540, 540, 540, 1080, 540, 1080, 270, 270, 540, 270, 1080, 1080, 270, 270, 540, 540, 540, 270, 1080, 270, 1080, 540, 270, 1080, 1080, 540, 540, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 270, 1080, 270, 270, 1080, 540, 1080, 1080, 540, 1080, 270, 540, 1080, 270, 1080, 540, 270, 540, 540, 1080, 1080, 270, 270, 1080, 270, 270, 270, 540, 270]
Prompts retrieved: 81000 . Total input tokens: 18042231 . Total output tokens: 15885629
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 2.290479167830199,
    "estimated_duration": 3599.993701974474,
    "input_throughput": 1852.2007403354285,
    "output_throughput": 1605.5130865451115,
    "total_throughput": 3457.7138268805397,
    "itl": 36.88072887960664,
    "ttft": 10160.878426337615,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10937,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 79.96745042096597,
    "arrivals": 27111,
    "finished_requests": 27035,
    "scheduler_time": 5.846886743558646
}
#Debug simulation 
Total elapsed time: 2.290552925784141. Arrivals time: 0.07454688521102071 Scheduler time: 1.8585794777609408 Scheduler overhead time: 0.09447104390710592 Adapter cache time: 0.127218930516392 Engine time: 0.09111667796969414 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-8-32/adapters_128_slots_64_rate_0.1-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-8-32/adapters_128_slots_64_rate_0.1-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 270, 270, 1080, 270, 540, 540, 540, 270, 1080, 540, 270, 1080, 540, 270, 270, 270, 270, 540, 540, 1080, 540, 270, 540, 540, 540, 540, 1080, 540, 270, 540, 270, 1080, 1080, 270, 540, 540, 270, 540, 270, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 270, 540, 1080, 1080, 540, 270, 270, 270, 1080, 540, 540, 540, 540, 1080, 540, 1080, 270, 270, 540, 270, 1080, 1080, 270, 270, 540, 540, 540, 270, 1080, 270, 1080, 540, 270, 1080, 1080, 540, 540, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 270, 1080, 270, 270, 1080, 540, 1080, 1080, 540, 1080, 270, 540, 1080, 270, 1080, 540, 270, 540, 540, 1080, 1080, 270, 270, 1080, 270, 270, 270, 540, 270]
Prompts retrieved: 81000 . Total input tokens: 18042231 . Total output tokens: 15885629
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 2.2531956140883267,
    "estimated_duration": 3599.994131316396,
    "input_throughput": 1852.200519438561,
    "output_throughput": 1605.5128950686676,
    "total_throughput": 3457.7134145072287,
    "itl": 36.92098214947884,
    "ttft": 10161.084008301954,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10938,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 82.1297057359972,
    "arrivals": 27111,
    "finished_requests": 27035,
    "scheduler_time": 5.8647443294534565
}
#Debug simulation 
Total elapsed time: 2.253267086111009. Arrivals time: 0.0740261017344892 Scheduler time: 1.8177958182059228 Scheduler overhead time: 0.09484934993088245 Adapter cache time: 0.12673049652948976 Engine time: 0.09504692908376455 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-16-16/adapters_128_slots_64_rate_0.1-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-16-16/adapters_128_slots_64_rate_0.1-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 270, 270, 1080, 270, 540, 540, 540, 270, 1080, 540, 270, 1080, 540, 270, 270, 270, 270, 540, 540, 1080, 540, 270, 540, 540, 540, 540, 1080, 540, 270, 540, 270, 1080, 1080, 270, 540, 540, 270, 540, 270, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 270, 540, 1080, 1080, 540, 270, 270, 270, 1080, 540, 540, 540, 540, 1080, 540, 1080, 270, 270, 540, 270, 1080, 1080, 270, 270, 540, 540, 540, 270, 1080, 270, 1080, 540, 270, 1080, 1080, 540, 540, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 270, 1080, 270, 270, 1080, 540, 1080, 1080, 540, 1080, 270, 540, 1080, 270, 1080, 540, 270, 540, 540, 1080, 1080, 270, 270, 1080, 270, 270, 270, 540, 270]
Prompts retrieved: 81000 . Total input tokens: 18042231 . Total output tokens: 15885629
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 2.2651675706729293,
    "estimated_duration": 3599.980789775116,
    "input_throughput": 1852.2073837001035,
    "output_throughput": 1605.5188451050194,
    "total_throughput": 3457.726228805123,
    "itl": 36.7908468830932,
    "ttft": 10160.204891977532,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10942,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 75.16974925951001,
    "arrivals": 27111,
    "finished_requests": 27035,
    "scheduler_time": 5.807226534380195
}
#Debug simulation 
Total elapsed time: 2.2652382366359234. Arrivals time: 0.07399237155914307 Scheduler time: 1.8313255137763917 Scheduler overhead time: 0.0949622867628932 Adapter cache time: 0.12741704564541578 Engine time: 0.09271714184433222 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-16-32/adapters_128_slots_64_rate_0.1-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_8-16-32/adapters_128_slots_64_rate_0.1-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 270, 270, 1080, 270, 540, 540, 540, 270, 1080, 540, 270, 1080, 540, 270, 270, 270, 270, 540, 540, 1080, 540, 270, 540, 540, 540, 540, 1080, 540, 270, 540, 270, 1080, 1080, 270, 540, 540, 270, 540, 270, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 270, 540, 1080, 1080, 540, 270, 270, 270, 1080, 540, 540, 540, 540, 1080, 540, 1080, 270, 270, 540, 270, 1080, 1080, 270, 270, 540, 540, 540, 270, 1080, 270, 1080, 540, 270, 1080, 1080, 540, 540, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 270, 1080, 270, 270, 1080, 540, 1080, 1080, 540, 1080, 270, 540, 1080, 270, 1080, 540, 270, 540, 540, 1080, 1080, 270, 270, 1080, 270, 270, 270, 540, 270]
Prompts retrieved: 81000 . Total input tokens: 18042231 . Total output tokens: 15885629
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 2.266827101353556,
    "estimated_duration": 3599.9668253726895,
    "input_throughput": 1852.2145684800023,
    "output_throughput": 1605.5250729710926,
    "total_throughput": 3457.739641451095,
    "itl": 36.90414356734158,
    "ttft": 10161.016213950877,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10944,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 81.45527136087193,
    "arrivals": 27111,
    "finished_requests": 27035,
    "scheduler_time": 5.859284437535697
}
#Debug simulation 
Total elapsed time: 2.266897255089134. Arrivals time: 0.07429697411134839 Scheduler time: 1.832661960273981 Scheduler overhead time: 0.09489610092714429 Adapter cache time: 0.1274540820159018 Engine time: 0.09285643603652716 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_16-16-16/adapters_128_slots_64_rate_0.1-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_16-16-16/adapters_128_slots_64_rate_0.1-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 270, 270, 1080, 270, 540, 540, 540, 270, 1080, 540, 270, 1080, 540, 270, 270, 270, 270, 540, 540, 1080, 540, 270, 540, 540, 540, 540, 1080, 540, 270, 540, 270, 1080, 1080, 270, 540, 540, 270, 540, 270, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 270, 540, 1080, 1080, 540, 270, 270, 270, 1080, 540, 540, 540, 540, 1080, 540, 1080, 270, 270, 540, 270, 1080, 1080, 270, 270, 540, 540, 540, 270, 1080, 270, 1080, 540, 270, 1080, 1080, 540, 540, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 270, 1080, 270, 270, 1080, 540, 1080, 1080, 540, 1080, 270, 540, 1080, 270, 1080, 540, 270, 540, 540, 1080, 1080, 270, 270, 1080, 270, 270, 270, 540, 270]
Prompts retrieved: 81000 . Total input tokens: 18042231 . Total output tokens: 15885629
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 2.27286065928638,
    "estimated_duration": 3599.98371202998,
    "input_throughput": 1852.20588018718,
    "output_throughput": 1605.51754183933,
    "total_throughput": 3457.72342202651,
    "itl": 36.6862748995974,
    "ttft": 10159.604332934685,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10953,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 69.92308606207068,
    "arrivals": 27111,
    "finished_requests": 27035,
    "scheduler_time": 5.76404442337445
}
#Debug simulation 
Total elapsed time: 2.2729341192170978. Arrivals time: 0.07468816172331572 Scheduler time: 1.8367480225861073 Scheduler overhead time: 0.09529629396274686 Adapter cache time: 0.12829243578016758 Engine time: 0.09260648675262928 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_16-16-32/adapters_128_slots_64_rate_0.1-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.025_size_16-16-32/adapters_128_slots_64_rate_0.1-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 270, 270, 1080, 270, 540, 540, 540, 270, 1080, 540, 270, 1080, 540, 270, 270, 270, 270, 540, 540, 1080, 540, 270, 540, 540, 540, 540, 1080, 540, 270, 540, 270, 1080, 1080, 270, 540, 540, 270, 540, 270, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 270, 540, 1080, 1080, 540, 270, 270, 270, 1080, 540, 540, 540, 540, 1080, 540, 1080, 270, 270, 540, 270, 1080, 1080, 270, 270, 540, 540, 540, 270, 1080, 270, 1080, 540, 270, 1080, 1080, 540, 540, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 270, 1080, 270, 270, 1080, 540, 1080, 1080, 540, 1080, 270, 540, 1080, 270, 1080, 540, 270, 540, 540, 1080, 1080, 270, 270, 1080, 270, 270, 270, 540, 270]
Prompts retrieved: 81000 . Total input tokens: 18042231 . Total output tokens: 15885629
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 2.2522162389941514,
    "estimated_duration": 3599.978707495925,
    "input_throughput": 1852.2084550433547,
    "output_throughput": 1605.5197737600904,
    "total_throughput": 3457.7282288034453,
    "itl": 36.888805573449496,
    "ttft": 10160.96887502654,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10938,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 80.61650764364957,
    "arrivals": 27111,
    "finished_requests": 27035,
    "scheduler_time": 5.852229789105513
}
#Debug simulation 
Total elapsed time: 2.2522865370847285. Arrivals time: 0.07421954767778516 Scheduler time: 1.8182330229319632 Scheduler overhead time: 0.0946742407977581 Adapter cache time: 0.12751024449244142 Engine time: 0.09255882492288947 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-8/adapters_128_slots_64_rate_0.1-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-8/adapters_128_slots_64_rate_0.1-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 135, 135, 1080, 135, 540, 540, 540, 135, 1080, 540, 135, 1080, 540, 135, 135, 135, 135, 540, 540, 1080, 540, 135, 540, 540, 540, 540, 1080, 540, 135, 540, 135, 1080, 1080, 135, 540, 540, 135, 540, 135, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 135, 540, 1080, 1080, 540, 135, 135, 135, 1080, 540, 540, 540, 540, 1080, 540, 1080, 135, 135, 540, 135, 1080, 1080, 135, 135, 540, 540, 540, 135, 1080, 135, 1080, 540, 135, 1080, 1080, 540, 540, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 135, 1080, 135, 135, 1080, 540, 1080, 1080, 540, 1080, 135, 540, 1080, 135, 1080, 540, 135, 540, 540, 1080, 1080, 135, 135, 1080, 135, 135, 135, 540, 135]
Prompts retrieved: 75330 . Total input tokens: 16786254 . Total output tokens: 14767451
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 2.1521307420916855,
    "estimated_duration": 3600.012808206874,
    "input_throughput": 1728.9016266306392,
    "output_throughput": 1487.351652692316,
    "total_throughput": 3216.253279322955,
    "itl": 33.82476814360885,
    "ttft": 10206.211066817623,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8539,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 56.46336072382454,
    "arrivals": 25189,
    "finished_requests": 25116,
    "scheduler_time": 3.1097920203858593
}
#Debug simulation 
Total elapsed time: 2.1522190612740815. Arrivals time: 0.07142116641625762 Scheduler time: 1.7162172459065914 Scheduler overhead time: 0.1008037137798965 Adapter cache time: 0.11698251450434327 Engine time: 0.09891719231382012 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-16/adapters_128_slots_64_rate_0.1-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-16/adapters_128_slots_64_rate_0.1-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 135, 135, 1080, 135, 540, 540, 540, 135, 1080, 540, 135, 1080, 540, 135, 135, 135, 135, 540, 540, 1080, 540, 135, 540, 540, 540, 540, 1080, 540, 135, 540, 135, 1080, 1080, 135, 540, 540, 135, 540, 135, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 135, 540, 1080, 1080, 540, 135, 135, 135, 1080, 540, 540, 540, 540, 1080, 540, 1080, 135, 135, 540, 135, 1080, 1080, 135, 135, 540, 540, 540, 135, 1080, 135, 1080, 540, 135, 1080, 1080, 540, 540, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 135, 1080, 135, 135, 1080, 540, 1080, 1080, 540, 1080, 135, 540, 1080, 135, 1080, 540, 135, 540, 540, 1080, 1080, 135, 135, 1080, 135, 135, 135, 540, 135]
Prompts retrieved: 75330 . Total input tokens: 16786254 . Total output tokens: 14767451
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 2.0905622309073806,
    "estimated_duration": 3600.002400562303,
    "input_throughput": 1728.906624903314,
    "output_throughput": 1487.3559526414913,
    "total_throughput": 3216.2625775448055,
    "itl": 33.92366563416358,
    "ttft": 10206.560388687778,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8549,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 62.576457590137295,
    "arrivals": 25189,
    "finished_requests": 25116,
    "scheduler_time": 3.1508313944685087
}
#Debug simulation 
Total elapsed time: 2.090634962078184. Arrivals time: 0.06976432772353292 Scheduler time: 1.6602020170539618 Scheduler overhead time: 0.10007985960692167 Adapter cache time: 0.11642365576699376 Engine time: 0.09663100680336356 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-32/adapters_128_slots_64_rate_0.1-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-32/adapters_128_slots_64_rate_0.1-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 135, 135, 1080, 135, 540, 540, 540, 135, 1080, 540, 135, 1080, 540, 135, 135, 135, 135, 540, 540, 1080, 540, 135, 540, 540, 540, 540, 1080, 540, 135, 540, 135, 1080, 1080, 135, 540, 540, 135, 540, 135, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 135, 540, 1080, 1080, 540, 135, 135, 135, 1080, 540, 540, 540, 540, 1080, 540, 1080, 135, 135, 540, 135, 1080, 1080, 135, 135, 540, 540, 540, 135, 1080, 135, 1080, 540, 135, 1080, 1080, 540, 540, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 135, 1080, 135, 135, 1080, 540, 1080, 1080, 540, 1080, 135, 540, 1080, 135, 1080, 540, 135, 540, 540, 1080, 1080, 135, 135, 1080, 135, 135, 135, 540, 135]
Prompts retrieved: 75330 . Total input tokens: 16786254 . Total output tokens: 14767451
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 2.141081086359918,
    "estimated_duration": 3600.0118082986673,
    "input_throughput": 1728.9021068354323,
    "output_throughput": 1487.3520658062732,
    "total_throughput": 3216.2541726417053,
    "itl": 33.95309175407813,
    "ttft": 10206.677144609937,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8544,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 64.24465390204894,
    "arrivals": 25189,
    "finished_requests": 25116,
    "scheduler_time": 3.162410554274621
}
#Debug simulation 
Total elapsed time: 2.141154060140252. Arrivals time: 0.07058290485292673 Scheduler time: 1.705784103833139 Scheduler overhead time: 0.10064930515363812 Adapter cache time: 0.11767825344577432 Engine time: 0.09879065118730068 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-16/adapters_128_slots_64_rate_0.1-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-16/adapters_128_slots_64_rate_0.1-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 135, 135, 1080, 135, 540, 540, 540, 135, 1080, 540, 135, 1080, 540, 135, 135, 135, 135, 540, 540, 1080, 540, 135, 540, 540, 540, 540, 1080, 540, 135, 540, 135, 1080, 1080, 135, 540, 540, 135, 540, 135, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 135, 540, 1080, 1080, 540, 135, 135, 135, 1080, 540, 540, 540, 540, 1080, 540, 1080, 135, 135, 540, 135, 1080, 1080, 135, 135, 540, 540, 540, 135, 1080, 135, 1080, 540, 135, 1080, 1080, 540, 540, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 135, 1080, 135, 135, 1080, 540, 1080, 1080, 540, 1080, 135, 540, 1080, 135, 1080, 540, 135, 540, 540, 1080, 1080, 135, 135, 1080, 135, 135, 135, 540, 135]
Prompts retrieved: 75330 . Total input tokens: 16786254 . Total output tokens: 14767451
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 2.1316147060133517,
    "estimated_duration": 3600.029681885432,
    "input_throughput": 1728.8935231057008,
    "output_throughput": 1487.3446813348808,
    "total_throughput": 3216.2382044405813,
    "itl": 33.86302647102096,
    "ttft": 10348.832416037309,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8545,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 58.79023128967445,
    "arrivals": 25189,
    "finished_requests": 25116,
    "scheduler_time": 3.1254327930754116
}
#Debug simulation 
Total elapsed time: 2.1316872467286885. Arrivals time: 0.06993257068097591 Scheduler time: 1.6987017337232828 Scheduler overhead time: 0.10059612663462758 Adapter cache time: 0.11691138334572315 Engine time: 0.09779946086928248 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-32/adapters_128_slots_64_rate_0.1-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-32/adapters_128_slots_64_rate_0.1-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 135, 135, 1080, 135, 540, 540, 540, 135, 1080, 540, 135, 1080, 540, 135, 135, 135, 135, 540, 540, 1080, 540, 135, 540, 540, 540, 540, 1080, 540, 135, 540, 135, 1080, 1080, 135, 540, 540, 135, 540, 135, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 135, 540, 1080, 1080, 540, 135, 135, 135, 1080, 540, 540, 540, 540, 1080, 540, 1080, 135, 135, 540, 135, 1080, 1080, 135, 135, 540, 540, 540, 135, 1080, 135, 1080, 540, 135, 1080, 1080, 540, 540, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 135, 1080, 135, 135, 1080, 540, 1080, 1080, 540, 1080, 135, 540, 1080, 135, 1080, 540, 135, 540, 540, 1080, 1080, 135, 135, 1080, 135, 135, 135, 540, 135]
Prompts retrieved: 75330 . Total input tokens: 16786254 . Total output tokens: 14767451
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 2.138312265276909,
    "estimated_duration": 3600.007251721773,
    "input_throughput": 1728.9042951297442,
    "output_throughput": 1487.3539483674967,
    "total_throughput": 3216.258243497241,
    "itl": 33.945483182914465,
    "ttft": 10206.582710892655,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8544,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 63.68823378644848,
    "arrivals": 25189,
    "finished_requests": 25116,
    "scheduler_time": 3.1583904737016004
}
#Debug simulation 
Total elapsed time: 2.1383846714161336. Arrivals time: 0.07012030575424433 Scheduler time: 1.7037435439415276 Scheduler overhead time: 0.10040846094489098 Adapter cache time: 0.11710529262199998 Engine time: 0.09945039357990026 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-16/adapters_128_slots_64_rate_0.1-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-16/adapters_128_slots_64_rate_0.1-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 135, 135, 1080, 135, 540, 540, 540, 135, 1080, 540, 135, 1080, 540, 135, 135, 135, 135, 540, 540, 1080, 540, 135, 540, 540, 540, 540, 1080, 540, 135, 540, 135, 1080, 1080, 135, 540, 540, 135, 540, 135, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 135, 540, 1080, 1080, 540, 135, 135, 135, 1080, 540, 540, 540, 540, 1080, 540, 1080, 135, 135, 540, 135, 1080, 1080, 135, 135, 540, 540, 540, 135, 1080, 135, 1080, 540, 135, 1080, 1080, 540, 540, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 135, 1080, 135, 135, 1080, 540, 1080, 1080, 540, 1080, 135, 540, 1080, 135, 1080, 540, 135, 540, 540, 1080, 1080, 135, 135, 1080, 135, 135, 135, 540, 135]
Prompts retrieved: 75330 . Total input tokens: 16786254 . Total output tokens: 14767451
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 2.1386004029773176,
    "estimated_duration": 3600.022033555519,
    "input_throughput": 1728.8971961799002,
    "output_throughput": 1487.34784123299,
    "total_throughput": 3216.2450374128903,
    "itl": 33.79482504177034,
    "ttft": 10348.44522698505,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8539,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 54.51230091153795,
    "arrivals": 25189,
    "finished_requests": 25116,
    "scheduler_time": 3.0968831610962044
}
#Debug simulation 
Total elapsed time: 2.1386727588251233. Arrivals time: 0.07028557732701302 Scheduler time: 1.7037090542726219 Scheduler overhead time: 0.10113128554075956 Adapter cache time: 0.11723140766844153 Engine time: 0.09858586126938462 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-32/adapters_128_slots_64_rate_0.1-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-32/adapters_128_slots_64_rate_0.1-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 135, 135, 1080, 135, 540, 540, 540, 135, 1080, 540, 135, 1080, 540, 135, 135, 135, 135, 540, 540, 1080, 540, 135, 540, 540, 540, 540, 1080, 540, 135, 540, 135, 1080, 1080, 135, 540, 540, 135, 540, 135, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 135, 540, 1080, 1080, 540, 135, 135, 135, 1080, 540, 540, 540, 540, 1080, 540, 1080, 135, 135, 540, 135, 1080, 1080, 135, 135, 540, 540, 540, 135, 1080, 135, 1080, 540, 135, 1080, 1080, 540, 540, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 135, 1080, 135, 135, 1080, 540, 1080, 1080, 540, 1080, 135, 540, 1080, 135, 1080, 540, 135, 540, 540, 1080, 1080, 135, 135, 1080, 135, 135, 135, 540, 135]
Prompts retrieved: 75330 . Total input tokens: 16786254 . Total output tokens: 14767451
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 2.1344236456789076,
    "estimated_duration": 3600.039170636514,
    "input_throughput": 1728.8889661996477,
    "output_throughput": 1487.3407610876875,
    "total_throughput": 3216.229727287335,
    "itl": 33.932758162578345,
    "ttft": 10348.945398171774,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8546,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 63.06439349870636,
    "arrivals": 25189,
    "finished_requests": 25116,
    "scheduler_time": 3.1541871674147353
}
#Debug simulation 
Total elapsed time: 2.1345194880850613. Arrivals time: 0.06980780977755785 Scheduler time: 1.701803422998637 Scheduler overhead time: 0.10041175642982125 Adapter cache time: 0.11682779714465141 Engine time: 0.09818611294031143 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-8/adapters_128_slots_64_rate_0.1-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-8/adapters_128_slots_64_rate_0.1-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 66, 66, 1080, 66, 540, 540, 540, 66, 1080, 540, 66, 1080, 540, 66, 66, 66, 66, 540, 540, 1080, 540, 66, 540, 540, 540, 540, 1080, 540, 66, 540, 66, 1080, 1080, 66, 540, 540, 66, 540, 66, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 66, 540, 1080, 1080, 540, 66, 66, 66, 1080, 540, 540, 540, 540, 1080, 540, 1080, 66, 66, 540, 66, 1080, 1080, 66, 66, 540, 540, 540, 66, 1080, 66, 1080, 540, 66, 1080, 1080, 540, 540, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 66, 1080, 66, 66, 1080, 540, 1080, 1080, 540, 1080, 66, 540, 1080, 66, 1080, 540, 66, 540, 540, 1080, 1080, 66, 66, 1080, 66, 66, 66, 540, 66]
Prompts retrieved: 72432 . Total input tokens: 16124194 . Total output tokens: 14203096
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 2.0788895371370018,
    "estimated_duration": 3599.9647749172486,
    "input_throughput": 1646.0811064842198,
    "output_throughput": 1453.403665628998,
    "total_throughput": 3099.484772113218,
    "itl": 32.75159424019276,
    "ttft": 8949.259916962501,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7046,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 46.591034039120316,
    "arrivals": 24288,
    "finished_requests": 24228,
    "scheduler_time": 2.2415678481036503
}
#Debug simulation 
Total elapsed time: 2.078962729778141. Arrivals time: 0.0678715929389 Scheduler time: 1.6511927624233067 Scheduler overhead time: 0.10242307418957353 Adapter cache time: 0.10956758353859186 Engine time: 0.09946147305890918 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-16/adapters_128_slots_64_rate_0.1-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-16/adapters_128_slots_64_rate_0.1-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 66, 66, 1080, 66, 540, 540, 540, 66, 1080, 540, 66, 1080, 540, 66, 66, 66, 66, 540, 540, 1080, 540, 66, 540, 540, 540, 540, 1080, 540, 66, 540, 66, 1080, 1080, 66, 540, 540, 66, 540, 66, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 66, 540, 1080, 1080, 540, 66, 66, 66, 1080, 540, 540, 540, 540, 1080, 540, 1080, 66, 66, 540, 66, 1080, 1080, 66, 66, 540, 540, 540, 66, 1080, 66, 1080, 540, 66, 1080, 1080, 540, 540, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 66, 1080, 66, 66, 1080, 540, 1080, 1080, 540, 1080, 66, 540, 1080, 66, 1080, 540, 66, 540, 540, 1080, 1080, 66, 66, 1080, 66, 66, 66, 540, 66]
Prompts retrieved: 72432 . Total input tokens: 16124194 . Total output tokens: 14203096
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 2.0830540019087493,
    "estimated_duration": 3599.9798094363173,
    "input_throughput": 1646.0742319907242,
    "output_throughput": 1453.3975958101985,
    "total_throughput": 3099.4718278009227,
    "itl": 32.82859173393626,
    "ttft": 8949.670937047104,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7055,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 51.63677652187935,
    "arrivals": 24288,
    "finished_requests": 24228,
    "scheduler_time": 2.270372512329573
}
#Debug simulation 
Total elapsed time: 2.0831319582648575. Arrivals time: 0.06800857046619058 Scheduler time: 1.6537371152080595 Scheduler overhead time: 0.1028044749982655 Adapter cache time: 0.10945592727512121 Engine time: 0.10039127198979259 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-32/adapters_128_slots_64_rate_0.1-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-32/adapters_128_slots_64_rate_0.1-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 66, 66, 1080, 66, 540, 540, 540, 66, 1080, 540, 66, 1080, 540, 66, 66, 66, 66, 540, 540, 1080, 540, 66, 540, 540, 540, 540, 1080, 540, 66, 540, 66, 1080, 1080, 66, 540, 540, 66, 540, 66, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 66, 540, 1080, 1080, 540, 66, 66, 66, 1080, 540, 540, 540, 540, 1080, 540, 1080, 66, 66, 540, 66, 1080, 1080, 66, 66, 540, 540, 540, 66, 1080, 66, 1080, 540, 66, 1080, 1080, 540, 540, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 66, 1080, 66, 66, 1080, 540, 1080, 1080, 540, 1080, 66, 540, 1080, 66, 1080, 540, 66, 540, 540, 1080, 1080, 66, 66, 1080, 66, 66, 66, 540, 66]
Prompts retrieved: 72432 . Total input tokens: 16124194 . Total output tokens: 14203096
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 2.080672767944634,
    "estimated_duration": 3599.959111264145,
    "input_throughput": 1646.0836961892912,
    "output_throughput": 1453.4059522033526,
    "total_throughput": 3099.489648392644,
    "itl": 32.851112324169655,
    "ttft": 8949.672030439944,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7049,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 53.00653053537662,
    "arrivals": 24288,
    "finished_requests": 24228,
    "scheduler_time": 2.2782137276315857
}
#Debug simulation 
Total elapsed time: 2.080744757782668. Arrivals time: 0.06798544339835644 Scheduler time: 1.6496939919888973 Scheduler overhead time: 0.10428520711138844 Adapter cache time: 0.10908331163227558 Engine time: 0.10087407054379582 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-16/adapters_128_slots_64_rate_0.1-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-16/adapters_128_slots_64_rate_0.1-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 66, 66, 1080, 66, 540, 540, 540, 66, 1080, 540, 66, 1080, 540, 66, 66, 66, 66, 540, 540, 1080, 540, 66, 540, 540, 540, 540, 1080, 540, 66, 540, 66, 1080, 1080, 66, 540, 540, 66, 540, 66, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 66, 540, 1080, 1080, 540, 66, 66, 66, 1080, 540, 540, 540, 540, 1080, 540, 1080, 66, 66, 540, 66, 1080, 1080, 66, 66, 540, 540, 540, 66, 1080, 66, 1080, 540, 66, 1080, 1080, 540, 540, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 66, 1080, 66, 66, 1080, 540, 1080, 1080, 540, 1080, 66, 540, 1080, 66, 1080, 540, 66, 540, 540, 1080, 1080, 66, 66, 1080, 66, 66, 66, 540, 66]
Prompts retrieved: 72432 . Total input tokens: 16124194 . Total output tokens: 14203096
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 2.0648715626448393,
    "estimated_duration": 3599.9557698223084,
    "input_throughput": 1646.08522406721,
    "output_throughput": 1453.4073012397755,
    "total_throughput": 3099.4925253069855,
    "itl": 32.783911537918065,
    "ttft": 8949.363883285328,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7050,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 48.53688856615827,
    "arrivals": 24288,
    "finished_requests": 24228,
    "scheduler_time": 2.252573562889978
}
#Debug simulation 
Total elapsed time: 2.0649471818469465. Arrivals time: 0.06786126177757978 Scheduler time: 1.6352618825621903 Scheduler overhead time: 0.10222479933872819 Adapter cache time: 0.1113546909764409 Engine time: 0.09978626389056444 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-32/adapters_128_slots_64_rate_0.1-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-32/adapters_128_slots_64_rate_0.1-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 66, 66, 1080, 66, 540, 540, 540, 66, 1080, 540, 66, 1080, 540, 66, 66, 66, 66, 540, 540, 1080, 540, 66, 540, 540, 540, 540, 1080, 540, 66, 540, 66, 1080, 1080, 66, 540, 540, 66, 540, 66, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 66, 540, 1080, 1080, 540, 66, 66, 66, 1080, 540, 540, 540, 540, 1080, 540, 1080, 66, 66, 540, 66, 1080, 1080, 66, 66, 540, 540, 540, 66, 1080, 66, 1080, 540, 66, 1080, 1080, 540, 540, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 66, 1080, 66, 66, 1080, 540, 1080, 1080, 540, 1080, 66, 540, 1080, 66, 1080, 540, 66, 540, 540, 1080, 1080, 66, 66, 1080, 66, 66, 66, 540, 66]
Prompts retrieved: 72432 . Total input tokens: 16124194 . Total output tokens: 14203096
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 2.1051792902871966,
    "estimated_duration": 3599.9496686323664,
    "input_throughput": 1646.0880138502728,
    "output_throughput": 1453.4097644725493,
    "total_throughput": 3099.4977783228223,
    "itl": 32.84143308539424,
    "ttft": 8949.621645601268,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7048,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 52.536634668383826,
    "arrivals": 24288,
    "finished_requests": 24228,
    "scheduler_time": 2.2752686901435264
}
#Debug simulation 
Total elapsed time: 2.1052546612918377. Arrivals time: 0.06816990999504924 Scheduler time: 1.675490342080593 Scheduler overhead time: 0.10264855390414596 Adapter cache time: 0.11052579851821065 Engine time: 0.09976959740743041 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-16/adapters_128_slots_64_rate_0.1-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-16/adapters_128_slots_64_rate_0.1-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 66, 66, 1080, 66, 540, 540, 540, 66, 1080, 540, 66, 1080, 540, 66, 66, 66, 66, 540, 540, 1080, 540, 66, 540, 540, 540, 540, 1080, 540, 66, 540, 66, 1080, 1080, 66, 540, 540, 66, 540, 66, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 66, 540, 1080, 1080, 540, 66, 66, 66, 1080, 540, 540, 540, 540, 1080, 540, 1080, 66, 66, 540, 66, 1080, 1080, 66, 66, 540, 540, 540, 66, 1080, 66, 1080, 540, 66, 1080, 1080, 540, 540, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 66, 1080, 66, 66, 1080, 540, 1080, 1080, 540, 1080, 66, 540, 1080, 66, 1080, 540, 66, 540, 540, 1080, 1080, 66, 66, 1080, 66, 66, 66, 540, 66]
Prompts retrieved: 72432 . Total input tokens: 16124194 . Total output tokens: 14203096
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 2.080765680875629,
    "estimated_duration": 3599.970609382076,
    "input_throughput": 1646.0784386840178,
    "output_throughput": 1453.401310100721,
    "total_throughput": 3099.479748784739,
    "itl": 32.995962199587325,
    "ttft": 8949.608428967067,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7093,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 45.281151231471725,
    "arrivals": 24288,
    "finished_requests": 24228,
    "scheduler_time": 2.331502200601401
}
#Debug simulation 
Total elapsed time: 2.080839994829148. Arrivals time: 0.06787842372432351 Scheduler time: 1.653214263729751 Scheduler overhead time: 0.10230847308412194 Adapter cache time: 0.10900269635021687 Engine time: 0.09990785783156753 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-32/adapters_128_slots_64_rate_0.1-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-32/adapters_128_slots_64_rate_0.1-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 66, 66, 1080, 66, 540, 540, 540, 66, 1080, 540, 66, 1080, 540, 66, 66, 66, 66, 540, 540, 1080, 540, 66, 540, 540, 540, 540, 1080, 540, 66, 540, 66, 1080, 1080, 66, 540, 540, 66, 540, 66, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 66, 540, 1080, 1080, 540, 66, 66, 66, 1080, 540, 540, 540, 540, 1080, 540, 1080, 66, 66, 540, 66, 1080, 1080, 66, 66, 540, 540, 540, 66, 1080, 66, 1080, 540, 66, 1080, 1080, 540, 540, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 66, 1080, 66, 66, 1080, 540, 1080, 1080, 540, 1080, 66, 540, 1080, 66, 1080, 540, 66, 540, 540, 1080, 1080, 66, 66, 1080, 66, 66, 66, 540, 66]
Prompts retrieved: 72432 . Total input tokens: 16124194 . Total output tokens: 14203096
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 2.082411414012313,
    "estimated_duration": 3599.9813051845017,
    "input_throughput": 1646.0735480670216,
    "output_throughput": 1453.3969919412805,
    "total_throughput": 3099.470540008302,
    "itl": 32.83535799629441,
    "ttft": 8949.657946904497,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7048,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 52.00651807546354,
    "arrivals": 24288,
    "finished_requests": 24228,
    "scheduler_time": 2.2726318087986233
}
#Debug simulation 
Total elapsed time: 2.0824858797714114. Arrivals time: 0.06785032572224736 Scheduler time: 1.654061898123473 Scheduler overhead time: 0.10247706901282072 Adapter cache time: 0.10992432432249188 Engine time: 0.09960463689640164 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-8/adapters_128_slots_64_rate_0.1-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-8/adapters_128_slots_64_rate_0.1-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 33, 33, 1080, 33, 540, 540, 540, 33, 1080, 540, 33, 1080, 540, 33, 33, 33, 33, 540, 540, 1080, 540, 33, 540, 540, 540, 540, 1080, 540, 33, 540, 33, 1080, 1080, 33, 540, 540, 33, 540, 33, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 33, 540, 1080, 1080, 540, 33, 33, 33, 1080, 540, 540, 540, 540, 1080, 540, 1080, 33, 33, 540, 33, 1080, 1080, 33, 33, 540, 540, 540, 33, 1080, 33, 1080, 540, 33, 1080, 1080, 540, 540, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 540, 1080, 1080, 540, 1080, 33, 540, 1080, 33, 1080, 540, 33, 540, 540, 1080, 1080, 33, 33, 1080, 33, 33, 33, 540, 33]
Prompts retrieved: 71046 . Total input tokens: 15818280 . Total output tokens: 13940423
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 2.048338150139898,
    "estimated_duration": 3599.910493741463,
    "input_throughput": 1628.4015978151156,
    "output_throughput": 1411.9403826391465,
    "total_throughput": 3040.341980454262,
    "itl": 31.961635836591277,
    "ttft": 7918.926752227664,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6013,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 39.760415509113976,
    "arrivals": 23803,
    "finished_requests": 23751,
    "scheduler_time": 1.5925545336673366
}
#Debug simulation 
Total elapsed time: 2.0484113697893918. Arrivals time: 0.06758137373253703 Scheduler time: 1.616966541390866 Scheduler overhead time: 0.10413052560761571 Adapter cache time: 0.10626283334568143 Engine time: 0.10375112295150757 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-16/adapters_128_slots_64_rate_0.1-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-16/adapters_128_slots_64_rate_0.1-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 33, 33, 1080, 33, 540, 540, 540, 33, 1080, 540, 33, 1080, 540, 33, 33, 33, 33, 540, 540, 1080, 540, 33, 540, 540, 540, 540, 1080, 540, 33, 540, 33, 1080, 1080, 33, 540, 540, 33, 540, 33, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 33, 540, 1080, 1080, 540, 33, 33, 33, 1080, 540, 540, 540, 540, 1080, 540, 1080, 33, 33, 540, 33, 1080, 1080, 33, 33, 540, 540, 540, 33, 1080, 33, 1080, 540, 33, 1080, 1080, 540, 540, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 540, 1080, 1080, 540, 1080, 33, 540, 1080, 33, 1080, 540, 33, 540, 540, 1080, 1080, 33, 33, 1080, 33, 33, 33, 540, 33]
Prompts retrieved: 71046 . Total input tokens: 15818280 . Total output tokens: 13940423
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 2.049842589069158,
    "estimated_duration": 3599.9026107769128,
    "input_throughput": 1628.4051636427107,
    "output_throughput": 1411.943474466117,
    "total_throughput": 3040.348638108828,
    "itl": 32.02422102689335,
    "ttft": 7919.211013358468,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6018,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 44.085154233415075,
    "arrivals": 23803,
    "finished_requests": 23751,
    "scheduler_time": 1.6123012047169067
}
#Debug simulation 
Total elapsed time: 2.0499144322238863. Arrivals time: 0.06724008079618216 Scheduler time: 1.6192539022304118 Scheduler overhead time: 0.10485411947593093 Adapter cache time: 0.106158297508955 Engine time: 0.10273422487080097 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-32/adapters_128_slots_64_rate_0.1-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-32/adapters_128_slots_64_rate_0.1-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 33, 33, 1080, 33, 540, 540, 540, 33, 1080, 540, 33, 1080, 540, 33, 33, 33, 33, 540, 540, 1080, 540, 33, 540, 540, 540, 540, 1080, 540, 33, 540, 33, 1080, 1080, 33, 540, 540, 33, 540, 33, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 33, 540, 1080, 1080, 540, 33, 33, 33, 1080, 540, 540, 540, 540, 1080, 540, 1080, 33, 33, 540, 33, 1080, 1080, 33, 33, 540, 540, 540, 33, 1080, 33, 1080, 540, 33, 1080, 1080, 540, 540, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 540, 1080, 1080, 540, 1080, 33, 540, 1080, 33, 1080, 540, 33, 540, 540, 1080, 1080, 33, 33, 1080, 33, 33, 33, 540, 33]
Prompts retrieved: 71046 . Total input tokens: 15818280 . Total output tokens: 13940423
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 2.020035797264427,
    "estimated_duration": 3599.8904351854976,
    "input_throughput": 1628.2895564564471,
    "output_throughput": 1411.8335242439423,
    "total_throughput": 3040.1230807003894,
    "itl": 32.04030871766932,
    "ttft": 8070.726663417593,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6010,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 45.230660602193005,
    "arrivals": 23803,
    "finished_requests": 23750,
    "scheduler_time": 1.6174753486697204
}
#Debug simulation 
Total elapsed time: 2.020107952877879. Arrivals time: 0.06633321335539222 Scheduler time: 1.5922970571555197 Scheduler overhead time: 0.1045001083984971 Adapter cache time: 0.1060186605900526 Engine time: 0.10103053040802479 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-16/adapters_128_slots_64_rate_0.1-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-16/adapters_128_slots_64_rate_0.1-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 33, 33, 1080, 33, 540, 540, 540, 33, 1080, 540, 33, 1080, 540, 33, 33, 33, 33, 540, 540, 1080, 540, 33, 540, 540, 540, 540, 1080, 540, 33, 540, 33, 1080, 1080, 33, 540, 540, 33, 540, 33, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 33, 540, 1080, 1080, 540, 33, 33, 33, 1080, 540, 540, 540, 540, 1080, 540, 1080, 33, 33, 540, 33, 1080, 1080, 33, 33, 540, 540, 540, 33, 1080, 33, 1080, 540, 33, 1080, 1080, 540, 540, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 540, 1080, 1080, 540, 1080, 33, 540, 1080, 33, 1080, 540, 33, 540, 540, 1080, 1080, 33, 33, 1080, 33, 33, 33, 540, 33]
Prompts retrieved: 71046 . Total input tokens: 15818280 . Total output tokens: 13940423
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 2.045518815983087,
    "estimated_duration": 3599.8845919709806,
    "input_throughput": 1628.4133144364023,
    "output_throughput": 1411.950541785861,
    "total_throughput": 3040.3638562222636,
    "itl": 31.985744279674655,
    "ttft": 7919.117311583195,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6010,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 41.47281517013081,
    "arrivals": 23803,
    "finished_requests": 23751,
    "scheduler_time": 1.6004636767200557
}
#Debug simulation 
Total elapsed time: 2.045593297109008. Arrivals time: 0.06769982865080237 Scheduler time: 1.6119874231517315 Scheduler overhead time: 0.10537292156368494 Adapter cache time: 0.10642416635528207 Engine time: 0.10368664562702179 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-32/adapters_128_slots_64_rate_0.1-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-32/adapters_128_slots_64_rate_0.1-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 33, 33, 1080, 33, 540, 540, 540, 33, 1080, 540, 33, 1080, 540, 33, 33, 33, 33, 540, 540, 1080, 540, 33, 540, 540, 540, 540, 1080, 540, 33, 540, 33, 1080, 1080, 33, 540, 540, 33, 540, 33, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 33, 540, 1080, 1080, 540, 33, 33, 33, 1080, 540, 540, 540, 540, 1080, 540, 1080, 33, 33, 540, 33, 1080, 1080, 33, 33, 540, 540, 540, 33, 1080, 33, 1080, 540, 33, 1080, 1080, 540, 540, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 540, 1080, 1080, 540, 1080, 33, 540, 1080, 33, 1080, 540, 33, 540, 540, 1080, 1080, 33, 33, 1080, 33, 33, 33, 540, 33]
Prompts retrieved: 71046 . Total input tokens: 15818280 . Total output tokens: 13940423
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 2.041128057986498,
    "estimated_duration": 3599.8947010172,
    "input_throughput": 1628.408741606687,
    "output_throughput": 1411.9465768161963,
    "total_throughput": 3040.3553184228836,
    "itl": 32.038015628591516,
    "ttft": 7919.366721289441,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6017,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 44.90459582161971,
    "arrivals": 23803,
    "finished_requests": 23751,
    "scheduler_time": 1.6161428969841205
}
#Debug simulation 
Total elapsed time: 2.0412002173252404. Arrivals time: 0.0672141071408987 Scheduler time: 1.6099460208788514 Scheduler overhead time: 0.10496304230764508 Adapter cache time: 0.10556968115270138 Engine time: 0.10394849069416523 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-16/adapters_128_slots_64_rate_0.1-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-16/adapters_128_slots_64_rate_0.1-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 33, 33, 1080, 33, 540, 540, 540, 33, 1080, 540, 33, 1080, 540, 33, 33, 33, 33, 540, 540, 1080, 540, 33, 540, 540, 540, 540, 1080, 540, 33, 540, 33, 1080, 1080, 33, 540, 540, 33, 540, 33, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 33, 540, 1080, 1080, 540, 33, 33, 33, 1080, 540, 540, 540, 540, 1080, 540, 1080, 33, 33, 540, 33, 1080, 1080, 33, 33, 540, 540, 540, 33, 1080, 33, 1080, 540, 33, 1080, 1080, 540, 540, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 540, 1080, 1080, 540, 1080, 33, 540, 1080, 33, 1080, 540, 33, 540, 540, 1080, 1080, 33, 33, 1080, 33, 33, 33, 540, 33]
Prompts retrieved: 71046 . Total input tokens: 15818280 . Total output tokens: 13940423
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 2.0436591072939336,
    "estimated_duration": 3599.894475046042,
    "input_throughput": 1628.4088438245194,
    "output_throughput": 1411.9466654463506,
    "total_throughput": 3040.3555092708702,
    "itl": 31.938768097303083,
    "ttft": 7918.7049186676695,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6006,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 38.34182916907063,
    "arrivals": 23803,
    "finished_requests": 23751,
    "scheduler_time": 1.5861684901521633
}
#Debug simulation 
Total elapsed time: 2.0437346221879125. Arrivals time: 0.06710916105657816 Scheduler time: 1.6123251672834158 Scheduler overhead time: 0.10503766406327486 Adapter cache time: 0.10699089150875807 Engine time: 0.10225078370422125 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-32/adapters_128_slots_64_rate_0.1-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-32/adapters_128_slots_64_rate_0.1-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 33, 33, 1080, 33, 540, 540, 540, 33, 1080, 540, 33, 1080, 540, 33, 33, 33, 33, 540, 540, 1080, 540, 33, 540, 540, 540, 540, 1080, 540, 33, 540, 33, 1080, 1080, 33, 540, 540, 33, 540, 33, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 33, 540, 1080, 1080, 540, 33, 33, 33, 1080, 540, 540, 540, 540, 1080, 540, 1080, 33, 33, 540, 33, 1080, 1080, 33, 33, 540, 540, 540, 33, 1080, 33, 1080, 540, 33, 1080, 1080, 540, 540, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 540, 1080, 1080, 540, 1080, 33, 540, 1080, 33, 1080, 540, 33, 540, 540, 1080, 1080, 33, 33, 1080, 33, 33, 33, 540, 33]
Prompts retrieved: 71046 . Total input tokens: 15818280 . Total output tokens: 13940423
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 2.044643093831837,
    "estimated_duration": 3599.890937621285,
    "input_throughput": 1628.410443976818,
    "output_throughput": 1411.948052892575,
    "total_throughput": 3040.358496869393,
    "itl": 32.0296628795974,
    "ttft": 7919.208978982823,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6015,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 44.42299951003755,
    "arrivals": 23803,
    "finished_requests": 23751,
    "scheduler_time": 1.6137780601399732
}
#Debug simulation 
Total elapsed time: 2.044730694964528. Arrivals time: 0.06840019999071956 Scheduler time: 1.6107219019904733 Scheduler overhead time: 0.10490728542208672 Adapter cache time: 0.10595583915710449 Engine time: 0.10505490005016327 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-8/adapters_128_slots_64_rate_0.1-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-8/adapters_128_slots_64_rate_0.1-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [42 43 43]
Adapter prompts. [1080, 270, 1080, 1080, 135, 135, 1080, 135, 270, 270, 270, 135, 1080, 270, 135, 1080, 270, 135, 135, 135, 135, 270, 270, 1080, 270, 135, 270, 270, 270, 270, 1080, 270, 135, 270, 135, 1080, 1080, 135, 270, 270, 135, 270, 135, 270, 270, 1080, 1080, 1080, 1080, 270, 270, 135, 270, 1080, 1080, 270, 135, 135, 135, 1080, 270, 270, 270, 270, 1080, 270, 1080, 135, 135, 270, 135, 1080, 1080, 135, 135, 270, 270, 270, 135, 1080, 135, 1080, 270, 135, 1080, 1080, 270, 270, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 135, 1080, 135, 135, 1080, 270, 1080, 1080, 270, 1080, 135, 270, 1080, 135, 1080, 270, 135, 270, 270, 1080, 1080, 135, 135, 1080, 135, 135, 135, 270, 135]
Prompts retrieved: 63720 . Total input tokens: 14155266 . Total output tokens: 12505918
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.9060332281515002,
    "estimated_duration": 3599.7294489186434,
    "input_throughput": 1451.2446210559833,
    "output_throughput": 1292.1018276518594,
    "total_throughput": 2743.3464487078427,
    "itl": 30.29016887803083,
    "ttft": 9690.173814067412,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5846,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 38.656143200778004,
    "arrivals": 21290,
    "finished_requests": 21233,
    "scheduler_time": 0.513373667790653
}
#Debug simulation 
Total elapsed time: 1.9061042508110404. Arrivals time: 0.06117780227214098 Scheduler time: 1.4788168678060174 Scheduler overhead time: 0.10847168462350965 Adapter cache time: 0.10047153942286968 Engine time: 0.10535275703296065 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-16/adapters_128_slots_64_rate_0.1-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-16/adapters_128_slots_64_rate_0.1-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [42 43 43]
Adapter prompts. [1080, 270, 1080, 1080, 135, 135, 1080, 135, 270, 270, 270, 135, 1080, 270, 135, 1080, 270, 135, 135, 135, 135, 270, 270, 1080, 270, 135, 270, 270, 270, 270, 1080, 270, 135, 270, 135, 1080, 1080, 135, 270, 270, 135, 270, 135, 270, 270, 1080, 1080, 1080, 1080, 270, 270, 135, 270, 1080, 1080, 270, 135, 135, 135, 1080, 270, 270, 270, 270, 1080, 270, 1080, 135, 135, 270, 135, 1080, 1080, 135, 135, 270, 270, 270, 135, 1080, 135, 1080, 270, 135, 1080, 1080, 270, 270, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 135, 1080, 135, 135, 1080, 270, 1080, 1080, 270, 1080, 135, 270, 1080, 135, 1080, 270, 135, 270, 270, 1080, 1080, 135, 135, 1080, 135, 135, 135, 270, 135]
Prompts retrieved: 63720 . Total input tokens: 14155266 . Total output tokens: 12505918
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.9737559501081705,
    "estimated_duration": 3599.7363289986756,
    "input_throughput": 1451.1926770628543,
    "output_throughput": 1292.0162964529482,
    "total_throughput": 2743.2089735158024,
    "itl": 30.51118939937615,
    "ttft": 9859.746780707677,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5831,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 42.61510504383926,
    "arrivals": 21290,
    "finished_requests": 21232,
    "scheduler_time": 0.5452869582946579
}
#Debug simulation 
Total elapsed time: 1.9738286999054253. Arrivals time: 0.06198620004579425 Scheduler time: 1.5445264466106892 Scheduler overhead time: 0.1078609311953187 Adapter cache time: 0.09987672371789813 Engine time: 0.10750670498237014 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-32/adapters_128_slots_64_rate_0.1-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-32/adapters_128_slots_64_rate_0.1-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [42 43 43]
Adapter prompts. [1080, 270, 1080, 1080, 135, 135, 1080, 135, 270, 270, 270, 135, 1080, 270, 135, 1080, 270, 135, 135, 135, 135, 270, 270, 1080, 270, 135, 270, 270, 270, 270, 1080, 270, 135, 270, 135, 1080, 1080, 135, 270, 270, 135, 270, 135, 270, 270, 1080, 1080, 1080, 1080, 270, 270, 135, 270, 1080, 1080, 270, 135, 135, 135, 1080, 270, 270, 270, 270, 1080, 270, 1080, 135, 135, 270, 135, 1080, 1080, 135, 135, 270, 270, 270, 135, 1080, 135, 1080, 270, 135, 1080, 1080, 270, 270, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 135, 1080, 135, 135, 1080, 270, 1080, 1080, 270, 1080, 135, 270, 1080, 135, 1080, 270, 135, 270, 270, 1080, 1080, 135, 135, 1080, 135, 135, 135, 270, 135]
Prompts retrieved: 63720 . Total input tokens: 14155266 . Total output tokens: 12505918
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.894327238202095,
    "estimated_duration": 3599.725679305095,
    "input_throughput": 1451.196970378155,
    "output_throughput": 1292.0201188491205,
    "total_throughput": 2743.2170892272757,
    "itl": 30.524338440989855,
    "ttft": 9859.817494282579,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5829,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 43.74325922564053,
    "arrivals": 21290,
    "finished_requests": 21232,
    "scheduler_time": 0.5476913259792149
}
#Debug simulation 
Total elapsed time: 1.8943998622708023. Arrivals time: 0.06123759225010872 Scheduler time: 1.469259049743414 Scheduler overhead time: 0.10699122585356236 Adapter cache time: 0.09940297715365887 Engine time: 0.10633495869114995 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-16/adapters_128_slots_64_rate_0.1-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-16/adapters_128_slots_64_rate_0.1-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [42 43 43]
Adapter prompts. [1080, 270, 1080, 1080, 135, 135, 1080, 135, 270, 270, 270, 135, 1080, 270, 135, 1080, 270, 135, 135, 135, 135, 270, 270, 1080, 270, 135, 270, 270, 270, 270, 1080, 270, 135, 270, 135, 1080, 1080, 135, 270, 270, 135, 270, 135, 270, 270, 1080, 1080, 1080, 1080, 270, 270, 135, 270, 1080, 1080, 270, 135, 135, 135, 1080, 270, 270, 270, 270, 1080, 270, 1080, 135, 135, 270, 135, 1080, 1080, 135, 135, 270, 270, 270, 135, 1080, 135, 1080, 270, 135, 1080, 1080, 270, 270, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 135, 1080, 135, 135, 1080, 270, 1080, 1080, 270, 1080, 135, 270, 1080, 135, 1080, 270, 135, 270, 270, 1080, 1080, 135, 135, 1080, 135, 135, 135, 270, 135]
Prompts retrieved: 63720 . Total input tokens: 14155266 . Total output tokens: 12505918
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 1.9057201477698982,
    "estimated_duration": 3599.731920405572,
    "input_throughput": 1451.2436246673103,
    "output_throughput": 1292.1009405266934,
    "total_throughput": 2743.3445651940037,
    "itl": 30.309957906571327,
    "ttft": 9690.181105692312,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5851,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 40.08989318265243,
    "arrivals": 21290,
    "finished_requests": 21233,
    "scheduler_time": 0.5162793000423505
}
#Debug simulation 
Total elapsed time: 1.9057936198078096. Arrivals time: 0.061587991658598185 Scheduler time: 1.4767064293846488 Scheduler overhead time: 0.10816946206614375 Adapter cache time: 0.09974051406607032 Engine time: 0.1078117317520082 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-32/adapters_128_slots_64_rate_0.1-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-32/adapters_128_slots_64_rate_0.1-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [42 43 43]
Adapter prompts. [1080, 270, 1080, 1080, 135, 135, 1080, 135, 270, 270, 270, 135, 1080, 270, 135, 1080, 270, 135, 135, 135, 135, 270, 270, 1080, 270, 135, 270, 270, 270, 270, 1080, 270, 135, 270, 135, 1080, 1080, 135, 270, 270, 135, 270, 135, 270, 270, 1080, 1080, 1080, 1080, 270, 270, 135, 270, 1080, 1080, 270, 135, 135, 135, 1080, 270, 270, 270, 270, 1080, 270, 1080, 135, 135, 270, 135, 1080, 1080, 135, 135, 270, 270, 270, 135, 1080, 135, 1080, 270, 135, 1080, 1080, 270, 270, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 135, 1080, 135, 135, 1080, 270, 1080, 1080, 270, 1080, 135, 270, 1080, 135, 1080, 270, 135, 270, 270, 1080, 1080, 135, 135, 1080, 135, 135, 135, 270, 135]
Prompts retrieved: 63720 . Total input tokens: 14155266 . Total output tokens: 12505918
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 1.9362472225911915,
    "estimated_duration": 3599.7364123358693,
    "input_throughput": 1451.1926434664153,
    "output_throughput": 1292.016266541588,
    "total_throughput": 2743.2089100080034,
    "itl": 30.51870464658969,
    "ttft": 9859.828930969408,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5825,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 43.31971058552077,
    "arrivals": 21290,
    "finished_requests": 21232,
    "scheduler_time": 0.5468790284269278
}
#Debug simulation 
Total elapsed time: 1.9363235286436975. Arrivals time: 0.06241319049149752 Scheduler time: 1.5078342291526496 Scheduler overhead time: 0.10826166765764356 Adapter cache time: 0.09945395030081272 Engine time: 0.10675069643184543 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-16/adapters_128_slots_64_rate_0.1-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-16/adapters_128_slots_64_rate_0.1-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [42 43 43]
Adapter prompts. [1080, 270, 1080, 1080, 135, 135, 1080, 135, 270, 270, 270, 135, 1080, 270, 135, 1080, 270, 135, 135, 135, 135, 270, 270, 1080, 270, 135, 270, 270, 270, 270, 1080, 270, 135, 270, 135, 1080, 1080, 135, 270, 270, 135, 270, 135, 270, 270, 1080, 1080, 1080, 1080, 270, 270, 135, 270, 1080, 1080, 270, 135, 135, 135, 1080, 270, 270, 270, 270, 1080, 270, 1080, 135, 135, 270, 135, 1080, 1080, 135, 135, 270, 270, 270, 135, 1080, 135, 1080, 270, 135, 1080, 1080, 270, 270, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 135, 1080, 135, 135, 1080, 270, 1080, 1080, 270, 1080, 135, 270, 1080, 135, 1080, 270, 135, 270, 270, 1080, 1080, 135, 135, 1080, 135, 135, 135, 270, 135]
Prompts retrieved: 63720 . Total input tokens: 14155266 . Total output tokens: 12505918
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.8979405257850885,
    "estimated_duration": 3599.7264098661976,
    "input_throughput": 1451.245846262572,
    "output_throughput": 1292.1029185028776,
    "total_throughput": 2743.3487647654497,
    "itl": 30.275221124515173,
    "ttft": 9690.018677500944,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5853,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 37.365089265163206,
    "arrivals": 21290,
    "finished_requests": 21233,
    "scheduler_time": 0.5106761557111003
}
#Debug simulation 
Total elapsed time: 1.8980119270272553. Arrivals time: 0.06097120093181729 Scheduler time: 1.4693740531802177 Scheduler overhead time: 0.10846065683290362 Adapter cache time: 0.09999205637723207 Engine time: 0.10746769048273563 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-32/adapters_128_slots_64_rate_0.1-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-32/adapters_128_slots_64_rate_0.1-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [42 43 43]
Adapter prompts. [1080, 270, 1080, 1080, 135, 135, 1080, 135, 270, 270, 270, 135, 1080, 270, 135, 1080, 270, 135, 135, 135, 135, 270, 270, 1080, 270, 135, 270, 270, 270, 270, 1080, 270, 135, 270, 135, 1080, 1080, 135, 270, 270, 135, 270, 135, 270, 270, 1080, 1080, 1080, 1080, 270, 270, 135, 270, 1080, 1080, 270, 135, 135, 135, 1080, 270, 270, 270, 270, 1080, 270, 1080, 135, 135, 270, 135, 1080, 1080, 135, 135, 270, 270, 270, 135, 1080, 135, 1080, 270, 135, 1080, 1080, 270, 270, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 135, 1080, 135, 135, 1080, 270, 1080, 1080, 270, 1080, 135, 270, 1080, 135, 1080, 270, 135, 270, 270, 1080, 1080, 135, 135, 1080, 135, 135, 135, 270, 135]
Prompts retrieved: 63720 . Total input tokens: 14155266 . Total output tokens: 12505918
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.9091164208948612,
    "estimated_duration": 3599.7452167697816,
    "input_throughput": 1451.1890940680678,
    "output_throughput": 1292.0131064646528,
    "total_throughput": 2743.202200532721,
    "itl": 30.516467959090285,
    "ttft": 9859.851240590624,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5827,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 42.92561547437614,
    "arrivals": 21290,
    "finished_requests": 21232,
    "scheduler_time": 0.5460821593747842
}
#Debug simulation 
Total elapsed time: 1.9091893159784377. Arrivals time: 0.06145206093788147 Scheduler time: 1.4838433670811355 Scheduler overhead time: 0.1072022644802928 Adapter cache time: 0.09932457283139229 Engine time: 0.10595277464017272 
