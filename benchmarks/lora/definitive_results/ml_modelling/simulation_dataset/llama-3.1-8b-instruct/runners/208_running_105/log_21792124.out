INFO 05-31 19:31:05 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 05-31 19:31:05 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-32/adapters_256_slots_64_rate_3.2-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-32/adapters_256_slots_64_rate_3.2-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [135, 135, 34560, 33, 34560, 34560, 33, 34560, 135, 34560, 33, 135, 33, 34560, 135, 135, 135, 135, 34560, 33, 33, 33, 135, 34560, 33, 34560, 34560, 135, 135, 135, 33, 34560, 33, 135, 135, 33, 135, 33, 33, 135, 135, 34560, 135, 33, 135, 34560, 135, 135, 34560, 135, 34560, 33, 34560, 34560, 135, 33, 33, 34560, 135, 33, 135, 135, 34560, 135, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 34560, 34560, 33, 34560, 33, 135, 34560, 34560, 34560, 135, 33, 34560, 135, 33, 33, 33, 33, 33, 34560, 135, 33, 34560, 33, 34560, 33, 33, 135, 135, 34560, 135, 34560, 33, 135, 33, 34560, 34560, 33, 34560, 135, 33, 34560, 33, 33, 34560, 34560, 135, 34560, 34560, 33, 34560, 135, 135, 33, 135, 34560, 34560, 33, 34560, 135, 33, 135, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 135, 34560, 34560, 135, 33, 34560, 33, 135, 135, 33, 135, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 135, 34560, 135, 33, 135, 34560, 135, 34560, 33, 34560, 33, 135, 34560, 135, 34560, 135, 34560, 135, 34560, 135, 33, 34560, 33, 34560, 135, 135, 33, 135, 34560, 135, 135, 34560, 33, 34560, 34560, 135, 33, 34560, 34560, 135, 135, 34560, 34560, 135, 135, 135, 135, 34560, 34560, 135, 135, 34560, 33, 34560, 135, 34560, 34560, 33, 34560, 135, 135, 34560, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 34560, 135, 33, 33, 33, 33]
Prompts retrieved: 2986440 . Total input tokens: 665969540 . Total output tokens: 586163675
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 14.982775805983692,
    "estimated_duration": 3600.0865458849794,
    "input_throughput": 5286.677072181719,
    "output_throughput": 4561.355898171413,
    "total_throughput": 9848.032970353132,
    "itl": 96.66421560040953,
    "ttft": 2130006.678181049,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 615,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.6404031034373086,
    "arrivals": 994382,
    "finished_requests": 76584,
    "scheduler_time": 195.72470706097005
}
#Debug simulation 
Total elapsed time: 14.982922927010804. Arrivals time: 0.3934886287897825 Scheduler time: 14.429597708396614 Scheduler overhead time: 0.058351308573037386 Adapter cache time: 0.015788096468895674 Engine time: 0.059433397836983204 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_8-16-16/adapters_256_slots_64_rate_3.2-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_8-16-16/adapters_256_slots_64_rate_3.2-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [135, 135, 34560, 33, 34560, 34560, 33, 34560, 135, 34560, 33, 135, 33, 34560, 135, 135, 135, 135, 34560, 33, 33, 33, 135, 34560, 33, 34560, 34560, 135, 135, 135, 33, 34560, 33, 135, 135, 33, 135, 33, 33, 135, 135, 34560, 135, 33, 135, 34560, 135, 135, 34560, 135, 34560, 33, 34560, 34560, 135, 33, 33, 34560, 135, 33, 135, 135, 34560, 135, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 34560, 34560, 33, 34560, 33, 135, 34560, 34560, 34560, 135, 33, 34560, 135, 33, 33, 33, 33, 33, 34560, 135, 33, 34560, 33, 34560, 33, 33, 135, 135, 34560, 135, 34560, 33, 135, 33, 34560, 34560, 33, 34560, 135, 33, 34560, 33, 33, 34560, 34560, 135, 34560, 34560, 33, 34560, 135, 135, 33, 135, 34560, 34560, 33, 34560, 135, 33, 135, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 135, 34560, 34560, 135, 33, 34560, 33, 135, 135, 33, 135, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 135, 34560, 135, 33, 135, 34560, 135, 34560, 33, 34560, 33, 135, 34560, 135, 34560, 135, 34560, 135, 34560, 135, 33, 34560, 33, 34560, 135, 135, 33, 135, 34560, 135, 135, 34560, 33, 34560, 34560, 135, 33, 34560, 34560, 135, 135, 34560, 34560, 135, 135, 135, 135, 34560, 34560, 135, 135, 34560, 33, 34560, 135, 34560, 34560, 33, 34560, 135, 135, 34560, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 34560, 135, 33, 33, 33, 33]
Prompts retrieved: 2986440 . Total input tokens: 665969540 . Total output tokens: 586163675
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 31.163662916980684,
    "estimated_duration": 3600.010738110935,
    "input_throughput": 5662.659220482528,
    "output_throughput": 4884.476819429459,
    "total_throughput": 10547.136039911988,
    "itl": 107.36131891603553,
    "ttft": 2115248.545730145,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 472,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.2381024816259703,
    "arrivals": 994382,
    "finished_requests": 82056,
    "scheduler_time": 187.63053499170985
}
#Debug simulation 
Total elapsed time: 31.16385377710685. Arrivals time: 0.4531355854123831 Scheduler time: 30.54479203140363 Scheduler overhead time: 0.06312000146135688 Adapter cache time: 0.015851359348744154 Engine time: 0.06142508517950773 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_8-16-32/adapters_256_slots_64_rate_3.2-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_8-16-32/adapters_256_slots_64_rate_3.2-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [135, 135, 34560, 33, 34560, 34560, 33, 34560, 135, 34560, 33, 135, 33, 34560, 135, 135, 135, 135, 34560, 33, 33, 33, 135, 34560, 33, 34560, 34560, 135, 135, 135, 33, 34560, 33, 135, 135, 33, 135, 33, 33, 135, 135, 34560, 135, 33, 135, 34560, 135, 135, 34560, 135, 34560, 33, 34560, 34560, 135, 33, 33, 34560, 135, 33, 135, 135, 34560, 135, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 34560, 34560, 33, 34560, 33, 135, 34560, 34560, 34560, 135, 33, 34560, 135, 33, 33, 33, 33, 33, 34560, 135, 33, 34560, 33, 34560, 33, 33, 135, 135, 34560, 135, 34560, 33, 135, 33, 34560, 34560, 33, 34560, 135, 33, 34560, 33, 33, 34560, 34560, 135, 34560, 34560, 33, 34560, 135, 135, 33, 135, 34560, 34560, 33, 34560, 135, 33, 135, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 135, 34560, 34560, 135, 33, 34560, 33, 135, 135, 33, 135, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 135, 34560, 135, 33, 135, 34560, 135, 34560, 33, 34560, 33, 135, 34560, 135, 34560, 135, 34560, 135, 34560, 135, 33, 34560, 33, 34560, 135, 135, 33, 135, 34560, 135, 135, 34560, 33, 34560, 34560, 135, 33, 34560, 34560, 135, 135, 34560, 34560, 135, 135, 135, 135, 34560, 34560, 135, 135, 34560, 33, 34560, 135, 34560, 34560, 33, 34560, 135, 135, 34560, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 34560, 135, 33, 33, 33, 33]
Prompts retrieved: 2986440 . Total input tokens: 665969540 . Total output tokens: 586163675
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 15.1533368290402,
    "estimated_duration": 3600.0411350011304,
    "input_throughput": 5286.743758274869,
    "output_throughput": 4561.413435070331,
    "total_throughput": 9848.1571933452,
    "itl": 96.66306463008478,
    "ttft": 2129987.1006774986,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 615,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.595251558935303,
    "arrivals": 994382,
    "finished_requests": 76584,
    "scheduler_time": 195.72444772162285
}
#Debug simulation 
Total elapsed time: 15.15343426214531. Arrivals time: 0.46370041696354747 Scheduler time: 14.530141958966851 Scheduler overhead time: 0.05895133875310421 Adapter cache time: 0.015793267637491226 Engine time: 0.05890251696109772 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_16-16-16/adapters_256_slots_64_rate_3.2-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_16-16-16/adapters_256_slots_64_rate_3.2-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [135, 135, 34560, 33, 34560, 34560, 33, 34560, 135, 34560, 33, 135, 33, 34560, 135, 135, 135, 135, 34560, 33, 33, 33, 135, 34560, 33, 34560, 34560, 135, 135, 135, 33, 34560, 33, 135, 135, 33, 135, 33, 33, 135, 135, 34560, 135, 33, 135, 34560, 135, 135, 34560, 135, 34560, 33, 34560, 34560, 135, 33, 33, 34560, 135, 33, 135, 135, 34560, 135, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 34560, 34560, 33, 34560, 33, 135, 34560, 34560, 34560, 135, 33, 34560, 135, 33, 33, 33, 33, 33, 34560, 135, 33, 34560, 33, 34560, 33, 33, 135, 135, 34560, 135, 34560, 33, 135, 33, 34560, 34560, 33, 34560, 135, 33, 34560, 33, 33, 34560, 34560, 135, 34560, 34560, 33, 34560, 135, 135, 33, 135, 34560, 34560, 33, 34560, 135, 33, 135, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 135, 34560, 34560, 135, 33, 34560, 33, 135, 135, 33, 135, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 135, 34560, 135, 33, 135, 34560, 135, 34560, 33, 34560, 33, 135, 34560, 135, 34560, 135, 34560, 135, 34560, 135, 33, 34560, 33, 34560, 135, 135, 33, 135, 34560, 135, 135, 34560, 33, 34560, 34560, 135, 33, 34560, 34560, 135, 135, 34560, 34560, 135, 135, 135, 135, 34560, 34560, 135, 135, 34560, 33, 34560, 135, 34560, 34560, 33, 34560, 135, 135, 34560, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 34560, 135, 33, 33, 33, 33]
Prompts retrieved: 2986440 . Total input tokens: 665969540 . Total output tokens: 586163675
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 31.615295049734414,
    "estimated_duration": 3600.0359943558146,
    "input_throughput": 5674.829093939557,
    "output_throughput": 4895.528274614829,
    "total_throughput": 10570.357368554385,
    "itl": 107.34405378303317,
    "ttft": 2115832.7995503847,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 474,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.0259785258304195,
    "arrivals": 994382,
    "finished_requests": 82242,
    "scheduler_time": 187.8048904761059
}
#Debug simulation 
Total elapsed time: 31.615435370709747. Arrivals time: 0.4752905052155256 Scheduler time: 30.976017503999174 Scheduler overhead time: 0.06271484168246388 Adapter cache time: 0.015279538463801146 Engine time: 0.06099939299747348 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_16-16-32/adapters_256_slots_64_rate_3.2-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.0125-0.003125_size_16-16-32/adapters_256_slots_64_rate_3.2-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [135, 135, 34560, 33, 34560, 34560, 33, 34560, 135, 34560, 33, 135, 33, 34560, 135, 135, 135, 135, 34560, 33, 33, 33, 135, 34560, 33, 34560, 34560, 135, 135, 135, 33, 34560, 33, 135, 135, 33, 135, 33, 33, 135, 135, 34560, 135, 33, 135, 34560, 135, 135, 34560, 135, 34560, 33, 34560, 34560, 135, 33, 33, 34560, 135, 33, 135, 135, 34560, 135, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 34560, 34560, 33, 34560, 33, 135, 34560, 34560, 34560, 135, 33, 34560, 135, 33, 33, 33, 33, 33, 34560, 135, 33, 34560, 33, 34560, 33, 33, 135, 135, 34560, 135, 34560, 33, 135, 33, 34560, 34560, 33, 34560, 135, 33, 34560, 33, 33, 34560, 34560, 135, 34560, 34560, 33, 34560, 135, 135, 33, 135, 34560, 34560, 33, 34560, 135, 33, 135, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 135, 34560, 34560, 135, 33, 34560, 33, 135, 135, 33, 135, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 135, 34560, 135, 33, 135, 34560, 135, 34560, 33, 34560, 33, 135, 34560, 135, 34560, 135, 34560, 135, 34560, 135, 33, 34560, 33, 34560, 135, 135, 33, 135, 34560, 135, 135, 34560, 33, 34560, 34560, 135, 33, 34560, 34560, 135, 135, 34560, 34560, 135, 135, 135, 135, 34560, 34560, 135, 135, 34560, 33, 34560, 135, 34560, 34560, 33, 34560, 135, 135, 34560, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 34560, 135, 33, 33, 33, 33]
Prompts retrieved: 2986440 . Total input tokens: 665969540 . Total output tokens: 586163675
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 15.033167058136314,
    "estimated_duration": 3600.11057025296,
    "input_throughput": 5286.874841364284,
    "output_throughput": 4561.390179426115,
    "total_throughput": 9848.265020790399,
    "itl": 96.66159006246089,
    "ttft": 2130034.517653139,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 615,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.552585420552675,
    "arrivals": 994382,
    "finished_requests": 76586,
    "scheduler_time": 195.7301703042353
}
#Debug simulation 
Total elapsed time: 15.033263486810029. Arrivals time: 0.39639036543667316 Scheduler time: 14.477138664573431 Scheduler overhead time: 0.058762438129633665 Adapter cache time: 0.015913323499262333 Engine time: 0.0588034619577229 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-8/adapters_256_slots_64_rate_3.2-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-8/adapters_256_slots_64_rate_3.2-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [66, 66, 34560, 33, 34560, 34560, 33, 34560, 66, 34560, 33, 66, 33, 34560, 66, 66, 66, 66, 34560, 33, 33, 33, 66, 34560, 33, 34560, 34560, 66, 66, 66, 33, 34560, 33, 66, 66, 33, 66, 33, 33, 66, 66, 34560, 66, 33, 66, 34560, 66, 66, 34560, 66, 34560, 33, 34560, 34560, 66, 33, 33, 34560, 66, 33, 66, 66, 34560, 66, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 34560, 34560, 33, 34560, 33, 66, 34560, 34560, 34560, 66, 33, 34560, 66, 33, 33, 33, 33, 33, 34560, 66, 33, 34560, 33, 34560, 33, 33, 66, 66, 34560, 66, 34560, 33, 66, 33, 34560, 34560, 33, 34560, 66, 33, 34560, 33, 33, 34560, 34560, 66, 34560, 34560, 33, 34560, 66, 66, 33, 66, 34560, 34560, 33, 34560, 66, 33, 66, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 66, 34560, 34560, 66, 33, 34560, 33, 66, 66, 33, 66, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 66, 34560, 66, 33, 66, 34560, 66, 34560, 33, 34560, 33, 66, 34560, 66, 34560, 66, 34560, 66, 34560, 66, 33, 34560, 33, 34560, 66, 66, 33, 66, 34560, 66, 66, 34560, 33, 34560, 34560, 66, 33, 34560, 34560, 66, 66, 34560, 34560, 66, 66, 66, 66, 34560, 34560, 66, 66, 34560, 33, 34560, 66, 34560, 34560, 33, 34560, 66, 66, 34560, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 34560, 66, 33, 33, 33, 33]
Prompts retrieved: 2980575 . Total input tokens: 664668594 . Total output tokens: 585018182
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 52.96181994304061,
    "estimated_duration": 3600.0465549107553,
    "input_throughput": 5813.133713910761,
    "output_throughput": 5059.463460313927,
    "total_throughput": 10872.597174224687,
    "itl": 114.3513414820778,
    "ttft": 2125983.7827741145,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 326,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.155645344415682,
    "arrivals": 992438,
    "finished_requests": 84739,
    "scheduler_time": 183.067378802852
}
#Debug simulation 
Total elapsed time: 52.961985423229635. Arrivals time: 0.3863592534326017 Scheduler time: 52.40920124948025 Scheduler overhead time: 0.06477614026516676 Adapter cache time: 0.01475450862199068 Engine time: 0.062024811282753944 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-16/adapters_256_slots_64_rate_3.2-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-16/adapters_256_slots_64_rate_3.2-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [66, 66, 34560, 33, 34560, 34560, 33, 34560, 66, 34560, 33, 66, 33, 34560, 66, 66, 66, 66, 34560, 33, 33, 33, 66, 34560, 33, 34560, 34560, 66, 66, 66, 33, 34560, 33, 66, 66, 33, 66, 33, 33, 66, 66, 34560, 66, 33, 66, 34560, 66, 66, 34560, 66, 34560, 33, 34560, 34560, 66, 33, 33, 34560, 66, 33, 66, 66, 34560, 66, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 34560, 34560, 33, 34560, 33, 66, 34560, 34560, 34560, 66, 33, 34560, 66, 33, 33, 33, 33, 33, 34560, 66, 33, 34560, 33, 34560, 33, 33, 66, 66, 34560, 66, 34560, 33, 66, 33, 34560, 34560, 33, 34560, 66, 33, 34560, 33, 33, 34560, 34560, 66, 34560, 34560, 33, 34560, 66, 66, 33, 66, 34560, 34560, 33, 34560, 66, 33, 66, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 66, 34560, 34560, 66, 33, 34560, 33, 66, 66, 33, 66, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 66, 34560, 66, 33, 66, 34560, 66, 34560, 33, 34560, 33, 66, 34560, 66, 34560, 66, 34560, 66, 34560, 66, 33, 34560, 33, 34560, 66, 66, 33, 66, 34560, 66, 66, 34560, 33, 34560, 34560, 66, 33, 34560, 34560, 66, 66, 34560, 34560, 66, 66, 66, 66, 34560, 34560, 66, 66, 34560, 33, 34560, 66, 34560, 34560, 33, 34560, 66, 66, 34560, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 34560, 66, 33, 33, 33, 33]
Prompts retrieved: 2980575 . Total input tokens: 664668594 . Total output tokens: 585018182
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 45.5144384871237,
    "estimated_duration": 3600.077154369443,
    "input_throughput": 5626.326640087723,
    "output_throughput": 4905.984856064426,
    "total_throughput": 10532.311496152148,
    "itl": 107.06015272006343,
    "ttft": 2133472.8304676376,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 318,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.314672158630567,
    "arrivals": 992438,
    "finished_requests": 82073,
    "scheduler_time": 188.37970449843564
}
#Debug simulation 
Total elapsed time: 45.51458944519982. Arrivals time: 0.36478941095992923 Scheduler time: 44.98045195825398 Scheduler overhead time: 0.06510452926158905 Adapter cache time: 0.01453306432813406 Engine time: 0.06398716755211353 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-32/adapters_256_slots_64_rate_3.2-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-32/adapters_256_slots_64_rate_3.2-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [66, 66, 34560, 33, 34560, 34560, 33, 34560, 66, 34560, 33, 66, 33, 34560, 66, 66, 66, 66, 34560, 33, 33, 33, 66, 34560, 33, 34560, 34560, 66, 66, 66, 33, 34560, 33, 66, 66, 33, 66, 33, 33, 66, 66, 34560, 66, 33, 66, 34560, 66, 66, 34560, 66, 34560, 33, 34560, 34560, 66, 33, 33, 34560, 66, 33, 66, 66, 34560, 66, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 34560, 34560, 33, 34560, 33, 66, 34560, 34560, 34560, 66, 33, 34560, 66, 33, 33, 33, 33, 33, 34560, 66, 33, 34560, 33, 34560, 33, 33, 66, 66, 34560, 66, 34560, 33, 66, 33, 34560, 34560, 33, 34560, 66, 33, 34560, 33, 33, 34560, 34560, 66, 34560, 34560, 33, 34560, 66, 66, 33, 66, 34560, 34560, 33, 34560, 66, 33, 66, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 66, 34560, 34560, 66, 33, 34560, 33, 66, 66, 33, 66, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 66, 34560, 66, 33, 66, 34560, 66, 34560, 33, 34560, 33, 66, 34560, 66, 34560, 66, 34560, 66, 34560, 66, 33, 34560, 33, 34560, 66, 66, 33, 66, 34560, 66, 66, 34560, 33, 34560, 34560, 66, 33, 34560, 34560, 66, 66, 34560, 34560, 66, 66, 66, 66, 34560, 34560, 66, 66, 34560, 33, 34560, 66, 34560, 34560, 33, 34560, 66, 66, 34560, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 34560, 66, 33, 33, 33, 33]
Prompts retrieved: 2980575 . Total input tokens: 664668594 . Total output tokens: 585018182
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 16.140014531556517,
    "estimated_duration": 3600.060024665129,
    "input_throughput": 5280.903893197843,
    "output_throughput": 4601.4429999791155,
    "total_throughput": 9882.346893176958,
    "itl": 95.87243862777993,
    "ttft": 2149274.494562771,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 579,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.341120430012266,
    "arrivals": 992438,
    "finished_requests": 77031,
    "scheduler_time": 197.47640512435783
}
#Debug simulation 
Total elapsed time: 16.140108936000615. Arrivals time: 0.3037122576497495 Scheduler time: 15.673987883143127 Scheduler overhead time: 0.060032205656170845 Adapter cache time: 0.015673494897782803 Engine time: 0.06038385070860386 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_8-16-16/adapters_256_slots_64_rate_3.2-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_8-16-16/adapters_256_slots_64_rate_3.2-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [66, 66, 34560, 33, 34560, 34560, 33, 34560, 66, 34560, 33, 66, 33, 34560, 66, 66, 66, 66, 34560, 33, 33, 33, 66, 34560, 33, 34560, 34560, 66, 66, 66, 33, 34560, 33, 66, 66, 33, 66, 33, 33, 66, 66, 34560, 66, 33, 66, 34560, 66, 66, 34560, 66, 34560, 33, 34560, 34560, 66, 33, 33, 34560, 66, 33, 66, 66, 34560, 66, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 34560, 34560, 33, 34560, 33, 66, 34560, 34560, 34560, 66, 33, 34560, 66, 33, 33, 33, 33, 33, 34560, 66, 33, 34560, 33, 34560, 33, 33, 66, 66, 34560, 66, 34560, 33, 66, 33, 34560, 34560, 33, 34560, 66, 33, 34560, 33, 33, 34560, 34560, 66, 34560, 34560, 33, 34560, 66, 66, 33, 66, 34560, 34560, 33, 34560, 66, 33, 66, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 66, 34560, 34560, 66, 33, 34560, 33, 66, 66, 33, 66, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 66, 34560, 66, 33, 66, 34560, 66, 34560, 33, 34560, 33, 66, 34560, 66, 34560, 66, 34560, 66, 34560, 66, 33, 34560, 33, 34560, 66, 66, 33, 66, 34560, 66, 66, 34560, 33, 34560, 34560, 66, 33, 34560, 34560, 66, 66, 34560, 34560, 66, 66, 66, 66, 34560, 34560, 66, 66, 34560, 33, 34560, 66, 34560, 34560, 33, 34560, 66, 66, 34560, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 34560, 66, 33, 33, 33, 33]
Prompts retrieved: 2980575 . Total input tokens: 664668594 . Total output tokens: 585018182
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 45.703112022951245,
    "estimated_duration": 3600.0561573969903,
    "input_throughput": 5626.703894154352,
    "output_throughput": 4906.367075332325,
    "total_throughput": 10533.070969486678,
    "itl": 107.05706796414287,
    "ttft": 2133484.461743549,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 318,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.173073619352651,
    "arrivals": 992438,
    "finished_requests": 82076,
    "scheduler_time": 188.38457443344862
}
#Debug simulation 
Total elapsed time: 45.70326329302043. Arrivals time: 0.3721778863109648 Scheduler time: 45.1611156007275 Scheduler overhead time: 0.06517513561993837 Adapter cache time: 0.014757412485778332 Engine time: 0.06424364959821105 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_8-16-32/adapters_256_slots_64_rate_3.2-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_8-16-32/adapters_256_slots_64_rate_3.2-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [66, 66, 34560, 33, 34560, 34560, 33, 34560, 66, 34560, 33, 66, 33, 34560, 66, 66, 66, 66, 34560, 33, 33, 33, 66, 34560, 33, 34560, 34560, 66, 66, 66, 33, 34560, 33, 66, 66, 33, 66, 33, 33, 66, 66, 34560, 66, 33, 66, 34560, 66, 66, 34560, 66, 34560, 33, 34560, 34560, 66, 33, 33, 34560, 66, 33, 66, 66, 34560, 66, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 34560, 34560, 33, 34560, 33, 66, 34560, 34560, 34560, 66, 33, 34560, 66, 33, 33, 33, 33, 33, 34560, 66, 33, 34560, 33, 34560, 33, 33, 66, 66, 34560, 66, 34560, 33, 66, 33, 34560, 34560, 33, 34560, 66, 33, 34560, 33, 33, 34560, 34560, 66, 34560, 34560, 33, 34560, 66, 66, 33, 66, 34560, 34560, 33, 34560, 66, 33, 66, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 66, 34560, 34560, 66, 33, 34560, 33, 66, 66, 33, 66, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 66, 34560, 66, 33, 66, 34560, 66, 34560, 33, 34560, 33, 66, 34560, 66, 34560, 66, 34560, 66, 34560, 66, 33, 34560, 33, 34560, 66, 66, 33, 66, 34560, 66, 66, 34560, 33, 34560, 34560, 66, 33, 34560, 34560, 66, 66, 34560, 34560, 66, 66, 66, 66, 34560, 34560, 66, 66, 34560, 33, 34560, 66, 34560, 34560, 33, 34560, 66, 66, 34560, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 34560, 66, 33, 33, 33, 33]
Prompts retrieved: 2980575 . Total input tokens: 664668594 . Total output tokens: 585018182
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 16.258345685899258,
    "estimated_duration": 3600.019210725759,
    "input_throughput": 5280.9637635703875,
    "output_throughput": 4601.495167205073,
    "total_throughput": 9882.45893077546,
    "itl": 95.87138824587808,
    "ttft": 2149258.509015803,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 579,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.300525463395784,
    "arrivals": 992438,
    "finished_requests": 77031,
    "scheduler_time": 197.4761861516045
}
#Debug simulation 
Total elapsed time: 16.258450706023723. Arrivals time: 0.3124040914699435 Scheduler time: 15.782678798772395 Scheduler overhead time: 0.060384935699403286 Adapter cache time: 0.015852329786866903 Engine time: 0.06072169728577137 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_16-16-16/adapters_256_slots_64_rate_3.2-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_16-16-16/adapters_256_slots_64_rate_3.2-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [66, 66, 34560, 33, 34560, 34560, 33, 34560, 66, 34560, 33, 66, 33, 34560, 66, 66, 66, 66, 34560, 33, 33, 33, 66, 34560, 33, 34560, 34560, 66, 66, 66, 33, 34560, 33, 66, 66, 33, 66, 33, 33, 66, 66, 34560, 66, 33, 66, 34560, 66, 66, 34560, 66, 34560, 33, 34560, 34560, 66, 33, 33, 34560, 66, 33, 66, 66, 34560, 66, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 34560, 34560, 33, 34560, 33, 66, 34560, 34560, 34560, 66, 33, 34560, 66, 33, 33, 33, 33, 33, 34560, 66, 33, 34560, 33, 34560, 33, 33, 66, 66, 34560, 66, 34560, 33, 66, 33, 34560, 34560, 33, 34560, 66, 33, 34560, 33, 33, 34560, 34560, 66, 34560, 34560, 33, 34560, 66, 66, 33, 66, 34560, 34560, 33, 34560, 66, 33, 66, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 66, 34560, 34560, 66, 33, 34560, 33, 66, 66, 33, 66, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 66, 34560, 66, 33, 66, 34560, 66, 34560, 33, 34560, 33, 66, 34560, 66, 34560, 66, 34560, 66, 34560, 66, 33, 34560, 33, 34560, 66, 66, 33, 66, 34560, 66, 66, 34560, 33, 34560, 34560, 66, 33, 34560, 34560, 66, 66, 34560, 34560, 66, 66, 66, 66, 34560, 34560, 66, 66, 34560, 33, 34560, 66, 34560, 34560, 33, 34560, 66, 66, 34560, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 34560, 66, 33, 33, 33, 33]
Prompts retrieved: 2980575 . Total input tokens: 664668594 . Total output tokens: 585018182
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 45.45963812014088,
    "estimated_duration": 3600.0340924718716,
    "input_throughput": 5626.860879556594,
    "output_throughput": 4906.570200803734,
    "total_throughput": 10533.431080360328,
    "itl": 107.05379047904371,
    "ttft": 2133430.6778760785,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 318,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.030086859101422,
    "arrivals": 992438,
    "finished_requests": 82079,
    "scheduler_time": 188.3896229273113
}
#Debug simulation 
Total elapsed time: 45.45980153325945. Arrivals time: 0.3639931702055037 Scheduler time: 44.926345012150705 Scheduler overhead time: 0.06522209895774722 Adapter cache time: 0.014534443616867065 Engine time: 0.06364988815039396 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_16-16-32/adapters_256_slots_64_rate_3.2-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_3.2-0.00625-0.003125_size_16-16-32/adapters_256_slots_64_rate_3.2-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [66, 66, 34560, 33, 34560, 34560, 33, 34560, 66, 34560, 33, 66, 33, 34560, 66, 66, 66, 66, 34560, 33, 33, 33, 66, 34560, 33, 34560, 34560, 66, 66, 66, 33, 34560, 33, 66, 66, 33, 66, 33, 33, 66, 66, 34560, 66, 33, 66, 34560, 66, 66, 34560, 66, 34560, 33, 34560, 34560, 66, 33, 33, 34560, 66, 33, 66, 66, 34560, 66, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 34560, 34560, 33, 34560, 33, 66, 34560, 34560, 34560, 66, 33, 34560, 66, 33, 33, 33, 33, 33, 34560, 66, 33, 34560, 33, 34560, 33, 33, 66, 66, 34560, 66, 34560, 33, 66, 33, 34560, 34560, 33, 34560, 66, 33, 34560, 33, 33, 34560, 34560, 66, 34560, 34560, 33, 34560, 66, 66, 33, 66, 34560, 34560, 33, 34560, 66, 33, 66, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 66, 34560, 34560, 66, 33, 34560, 33, 66, 66, 33, 66, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 66, 34560, 66, 33, 66, 34560, 66, 34560, 33, 34560, 33, 66, 34560, 66, 34560, 66, 34560, 66, 34560, 66, 33, 34560, 33, 34560, 66, 66, 33, 66, 34560, 66, 66, 34560, 33, 34560, 34560, 66, 33, 34560, 34560, 66, 66, 34560, 34560, 66, 66, 66, 66, 34560, 34560, 66, 66, 34560, 33, 34560, 66, 34560, 34560, 33, 34560, 66, 66, 34560, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 34560, 66, 33, 33, 33, 33]
Prompts retrieved: 2980575 . Total input tokens: 664668594 . Total output tokens: 585018182
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 16.245213225018233,
    "estimated_duration": 3600.0917512097517,
    "input_throughput": 5280.947629629541,
    "output_throughput": 4601.543278565963,
    "total_throughput": 9882.490908195503,
    "itl": 95.869484626042,
    "ttft": 2149417.384825975,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 579,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.261794551368836,
    "arrivals": 992438,
    "finished_requests": 77034,
    "scheduler_time": 197.48192899676988
}
#Debug simulation 
Total elapsed time: 16.24535725498572. Arrivals time: 0.30686515383422375 Scheduler time: 15.775364673696458 Scheduler overhead time: 0.06019046623259783 Adapter cache time: 0.015483361668884754 Engine time: 0.06087605841457844 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_8-8-8/adapters_256_slots_64_rate_1.6-0.8-0.4_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_8-8-8/adapters_256_slots_64_rate_1.6-0.8-0.4_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 4320, 17280, 17280, 4320, 17280, 8640, 17280, 4320, 8640, 4320, 17280, 8640, 8640, 8640, 8640, 17280, 4320, 4320, 4320, 8640, 17280, 4320, 17280, 17280, 8640, 8640, 8640, 4320, 17280, 4320, 8640, 8640, 4320, 8640, 4320, 4320, 8640, 8640, 17280, 8640, 4320, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 4320, 17280, 17280, 8640, 4320, 4320, 17280, 8640, 4320, 8640, 8640, 17280, 8640, 4320, 4320, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 8640, 4320, 8640, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 17280, 17280, 4320, 17280, 4320, 8640, 17280, 17280, 17280, 8640, 4320, 17280, 8640, 4320, 4320, 4320, 4320, 4320, 17280, 8640, 4320, 17280, 4320, 17280, 4320, 4320, 8640, 8640, 17280, 8640, 17280, 4320, 8640, 4320, 17280, 17280, 4320, 17280, 8640, 4320, 17280, 4320, 4320, 17280, 17280, 8640, 17280, 17280, 4320, 17280, 8640, 8640, 4320, 8640, 17280, 17280, 4320, 17280, 8640, 4320, 8640, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 4320, 4320, 17280, 4320, 8640, 17280, 17280, 8640, 4320, 17280, 4320, 8640, 8640, 4320, 8640, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 17280, 8640, 17280, 8640, 4320, 8640, 17280, 8640, 17280, 4320, 17280, 4320, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 4320, 17280, 4320, 17280, 8640, 8640, 4320, 8640, 17280, 8640, 8640, 17280, 4320, 17280, 17280, 8640, 4320, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 4320, 17280, 8640, 17280, 17280, 4320, 17280, 8640, 8640, 17280, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 4320, 4320, 4320, 4320]
Prompts retrieved: 2587680 . Total input tokens: 576987541 . Total output tokens: 507916087
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 50.288739362731576,
    "estimated_duration": 3600.060657810657,
    "input_throughput": 5564.880957362378,
    "output_throughput": 4859.3486784855395,
    "total_throughput": 10424.229635847918,
    "itl": 119.3848449783162,
    "ttft": 2083739.49802152,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 516,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.4120030604862106,
    "arrivals": 861811,
    "finished_requests": 81311,
    "scheduler_time": 175.37489876631747
}
#Debug simulation 
Total elapsed time: 50.28890792513266. Arrivals time: 0.4122168584726751 Scheduler time: 49.71078802179545 Scheduler overhead time: 0.06327908346429467 Adapter cache time: 0.01722055021673441 Engine time: 0.061019329354166985 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_8-8-16/adapters_256_slots_64_rate_1.6-0.8-0.4_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_8-8-16/adapters_256_slots_64_rate_1.6-0.8-0.4_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 4320, 17280, 17280, 4320, 17280, 8640, 17280, 4320, 8640, 4320, 17280, 8640, 8640, 8640, 8640, 17280, 4320, 4320, 4320, 8640, 17280, 4320, 17280, 17280, 8640, 8640, 8640, 4320, 17280, 4320, 8640, 8640, 4320, 8640, 4320, 4320, 8640, 8640, 17280, 8640, 4320, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 4320, 17280, 17280, 8640, 4320, 4320, 17280, 8640, 4320, 8640, 8640, 17280, 8640, 4320, 4320, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 8640, 4320, 8640, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 17280, 17280, 4320, 17280, 4320, 8640, 17280, 17280, 17280, 8640, 4320, 17280, 8640, 4320, 4320, 4320, 4320, 4320, 17280, 8640, 4320, 17280, 4320, 17280, 4320, 4320, 8640, 8640, 17280, 8640, 17280, 4320, 8640, 4320, 17280, 17280, 4320, 17280, 8640, 4320, 17280, 4320, 4320, 17280, 17280, 8640, 17280, 17280, 4320, 17280, 8640, 8640, 4320, 8640, 17280, 17280, 4320, 17280, 8640, 4320, 8640, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 4320, 4320, 17280, 4320, 8640, 17280, 17280, 8640, 4320, 17280, 4320, 8640, 8640, 4320, 8640, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 17280, 8640, 17280, 8640, 4320, 8640, 17280, 8640, 17280, 4320, 17280, 4320, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 4320, 17280, 4320, 17280, 8640, 8640, 4320, 8640, 17280, 8640, 8640, 17280, 4320, 17280, 17280, 8640, 4320, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 4320, 17280, 8640, 17280, 17280, 4320, 17280, 8640, 8640, 17280, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 4320, 4320, 4320, 4320]
Prompts retrieved: 2587680 . Total input tokens: 576987541 . Total output tokens: 507916087
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 43.86585994809866,
    "estimated_duration": 3600.0543089779544,
    "input_throughput": 5395.294163080067,
    "output_throughput": 4708.648132814545,
    "total_throughput": 10103.94229589461,
    "itl": 111.57778631861964,
    "ttft": 2100424.5111677293,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 643,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.708737288177952,
    "arrivals": 861811,
    "finished_requests": 78739,
    "scheduler_time": 180.3847305353839
}
#Debug simulation 
Total elapsed time: 43.86606781417504. Arrivals time: 0.39353188360109925 Scheduler time: 43.302727471571416 Scheduler overhead time: 0.06332635367289186 Adapter cache time: 0.019012772012501955 Engine time: 0.06231957068666816 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_8-8-32/adapters_256_slots_64_rate_1.6-0.8-0.4_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_8-8-32/adapters_256_slots_64_rate_1.6-0.8-0.4_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 4320, 17280, 17280, 4320, 17280, 8640, 17280, 4320, 8640, 4320, 17280, 8640, 8640, 8640, 8640, 17280, 4320, 4320, 4320, 8640, 17280, 4320, 17280, 17280, 8640, 8640, 8640, 4320, 17280, 4320, 8640, 8640, 4320, 8640, 4320, 4320, 8640, 8640, 17280, 8640, 4320, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 4320, 17280, 17280, 8640, 4320, 4320, 17280, 8640, 4320, 8640, 8640, 17280, 8640, 4320, 4320, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 8640, 4320, 8640, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 17280, 17280, 4320, 17280, 4320, 8640, 17280, 17280, 17280, 8640, 4320, 17280, 8640, 4320, 4320, 4320, 4320, 4320, 17280, 8640, 4320, 17280, 4320, 17280, 4320, 4320, 8640, 8640, 17280, 8640, 17280, 4320, 8640, 4320, 17280, 17280, 4320, 17280, 8640, 4320, 17280, 4320, 4320, 17280, 17280, 8640, 17280, 17280, 4320, 17280, 8640, 8640, 4320, 8640, 17280, 17280, 4320, 17280, 8640, 4320, 8640, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 4320, 4320, 17280, 4320, 8640, 17280, 17280, 8640, 4320, 17280, 4320, 8640, 8640, 4320, 8640, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 17280, 8640, 17280, 8640, 4320, 8640, 17280, 8640, 17280, 4320, 17280, 4320, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 4320, 17280, 4320, 17280, 8640, 8640, 4320, 8640, 17280, 8640, 8640, 17280, 4320, 17280, 17280, 8640, 4320, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 4320, 17280, 8640, 17280, 17280, 4320, 17280, 8640, 8640, 17280, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 4320, 4320, 4320, 4320]
Prompts retrieved: 2587680 . Total input tokens: 576987541 . Total output tokens: 507916087
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 24.618274063803256,
    "estimated_duration": 3600.0797069590376,
    "input_throughput": 5081.472214250658,
    "output_throughput": 4442.576637701643,
    "total_throughput": 9524.048851952302,
    "itl": 99.20895516833365,
    "ttft": 2129657.8992943084,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 926,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.960675606452882,
    "arrivals": 861811,
    "finished_requests": 74259,
    "scheduler_time": 190.4502168799962
}
#Debug simulation 
Total elapsed time: 24.618397063110024. Arrivals time: 0.3418175191618502 Scheduler time: 24.10228176508099 Scheduler overhead time: 0.06279737129807472 Adapter cache time: 0.022907440084964037 Engine time: 0.062080114148557186 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_8-16-16/adapters_256_slots_64_rate_1.6-0.8-0.4_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_8-16-16/adapters_256_slots_64_rate_1.6-0.8-0.4_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 4320, 17280, 17280, 4320, 17280, 8640, 17280, 4320, 8640, 4320, 17280, 8640, 8640, 8640, 8640, 17280, 4320, 4320, 4320, 8640, 17280, 4320, 17280, 17280, 8640, 8640, 8640, 4320, 17280, 4320, 8640, 8640, 4320, 8640, 4320, 4320, 8640, 8640, 17280, 8640, 4320, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 4320, 17280, 17280, 8640, 4320, 4320, 17280, 8640, 4320, 8640, 8640, 17280, 8640, 4320, 4320, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 8640, 4320, 8640, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 17280, 17280, 4320, 17280, 4320, 8640, 17280, 17280, 17280, 8640, 4320, 17280, 8640, 4320, 4320, 4320, 4320, 4320, 17280, 8640, 4320, 17280, 4320, 17280, 4320, 4320, 8640, 8640, 17280, 8640, 17280, 4320, 8640, 4320, 17280, 17280, 4320, 17280, 8640, 4320, 17280, 4320, 4320, 17280, 17280, 8640, 17280, 17280, 4320, 17280, 8640, 8640, 4320, 8640, 17280, 17280, 4320, 17280, 8640, 4320, 8640, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 4320, 4320, 17280, 4320, 8640, 17280, 17280, 8640, 4320, 17280, 4320, 8640, 8640, 4320, 8640, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 17280, 8640, 17280, 8640, 4320, 8640, 17280, 8640, 17280, 4320, 17280, 4320, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 4320, 17280, 4320, 17280, 8640, 8640, 4320, 8640, 17280, 8640, 8640, 17280, 4320, 17280, 17280, 8640, 4320, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 4320, 17280, 8640, 17280, 17280, 4320, 17280, 8640, 8640, 17280, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 4320, 4320, 4320, 4320]
Prompts retrieved: 2587680 . Total input tokens: 576987541 . Total output tokens: 507916087
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 42.14911937015131,
    "estimated_duration": 3600.016930445728,
    "input_throughput": 5385.378839759952,
    "output_throughput": 4713.25533402399,
    "total_throughput": 10098.634173783943,
    "itl": 112.06308223872513,
    "ttft": 2099636.139214228,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 749,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.139717795602039,
    "arrivals": 861811,
    "finished_requests": 78730,
    "scheduler_time": 180.02914795407187
}
#Debug simulation 
Total elapsed time: 42.14928240515292. Arrivals time: 0.38607754092663527 Scheduler time: 41.595343904569745 Scheduler overhead time: 0.06245000520721078 Adapter cache time: 0.020141296088695526 Engine time: 0.06036476697772741 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_8-16-32/adapters_256_slots_64_rate_1.6-0.8-0.4_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_8-16-32/adapters_256_slots_64_rate_1.6-0.8-0.4_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 4320, 17280, 17280, 4320, 17280, 8640, 17280, 4320, 8640, 4320, 17280, 8640, 8640, 8640, 8640, 17280, 4320, 4320, 4320, 8640, 17280, 4320, 17280, 17280, 8640, 8640, 8640, 4320, 17280, 4320, 8640, 8640, 4320, 8640, 4320, 4320, 8640, 8640, 17280, 8640, 4320, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 4320, 17280, 17280, 8640, 4320, 4320, 17280, 8640, 4320, 8640, 8640, 17280, 8640, 4320, 4320, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 8640, 4320, 8640, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 17280, 17280, 4320, 17280, 4320, 8640, 17280, 17280, 17280, 8640, 4320, 17280, 8640, 4320, 4320, 4320, 4320, 4320, 17280, 8640, 4320, 17280, 4320, 17280, 4320, 4320, 8640, 8640, 17280, 8640, 17280, 4320, 8640, 4320, 17280, 17280, 4320, 17280, 8640, 4320, 17280, 4320, 4320, 17280, 17280, 8640, 17280, 17280, 4320, 17280, 8640, 8640, 4320, 8640, 17280, 17280, 4320, 17280, 8640, 4320, 8640, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 4320, 4320, 17280, 4320, 8640, 17280, 17280, 8640, 4320, 17280, 4320, 8640, 8640, 4320, 8640, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 17280, 8640, 17280, 8640, 4320, 8640, 17280, 8640, 17280, 4320, 17280, 4320, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 4320, 17280, 4320, 17280, 8640, 8640, 4320, 8640, 17280, 8640, 8640, 17280, 4320, 17280, 17280, 8640, 4320, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 4320, 17280, 8640, 17280, 17280, 4320, 17280, 8640, 8640, 17280, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 4320, 4320, 4320, 4320]
Prompts retrieved: 2587680 . Total input tokens: 576987541 . Total output tokens: 507916087
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 24.884321307297796,
    "estimated_duration": 3600.0097561188736,
    "input_throughput": 5093.21980831725,
    "output_throughput": 4447.752113111574,
    "total_throughput": 9540.971921428823,
    "itl": 99.52474194284576,
    "ttft": 2129684.043384395,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1078,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.01860476910138,
    "arrivals": 861811,
    "finished_requests": 74352,
    "scheduler_time": 190.0875501249913
}
#Debug simulation 
Total elapsed time: 24.884418569039553. Arrivals time: 0.3443871960043907 Scheduler time: 24.36515812156722 Scheduler overhead time: 0.06216440489515662 Adapter cache time: 0.024768847040832043 Engine time: 0.061842086259275675 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_16-16-16/adapters_256_slots_64_rate_1.6-0.8-0.4_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_16-16-16/adapters_256_slots_64_rate_1.6-0.8-0.4_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 4320, 17280, 17280, 4320, 17280, 8640, 17280, 4320, 8640, 4320, 17280, 8640, 8640, 8640, 8640, 17280, 4320, 4320, 4320, 8640, 17280, 4320, 17280, 17280, 8640, 8640, 8640, 4320, 17280, 4320, 8640, 8640, 4320, 8640, 4320, 4320, 8640, 8640, 17280, 8640, 4320, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 4320, 17280, 17280, 8640, 4320, 4320, 17280, 8640, 4320, 8640, 8640, 17280, 8640, 4320, 4320, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 8640, 4320, 8640, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 17280, 17280, 4320, 17280, 4320, 8640, 17280, 17280, 17280, 8640, 4320, 17280, 8640, 4320, 4320, 4320, 4320, 4320, 17280, 8640, 4320, 17280, 4320, 17280, 4320, 4320, 8640, 8640, 17280, 8640, 17280, 4320, 8640, 4320, 17280, 17280, 4320, 17280, 8640, 4320, 17280, 4320, 4320, 17280, 17280, 8640, 17280, 17280, 4320, 17280, 8640, 8640, 4320, 8640, 17280, 17280, 4320, 17280, 8640, 4320, 8640, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 4320, 4320, 17280, 4320, 8640, 17280, 17280, 8640, 4320, 17280, 4320, 8640, 8640, 4320, 8640, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 17280, 8640, 17280, 8640, 4320, 8640, 17280, 8640, 17280, 4320, 17280, 4320, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 4320, 17280, 4320, 17280, 8640, 8640, 4320, 8640, 17280, 8640, 8640, 17280, 4320, 17280, 17280, 8640, 4320, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 4320, 17280, 8640, 17280, 17280, 4320, 17280, 8640, 8640, 17280, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 4320, 4320, 4320, 4320]
Prompts retrieved: 2587680 . Total input tokens: 576987541 . Total output tokens: 507916087
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 38.2752374461852,
    "estimated_duration": 3600.0502846792597,
    "input_throughput": 5401.912879595406,
    "output_throughput": 4714.214985336528,
    "total_throughput": 10116.127864931934,
    "itl": 111.93689265263421,
    "ttft": 2101682.555650491,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 674,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.302762713944519,
    "arrivals": 861811,
    "finished_requests": 78864,
    "scheduler_time": 180.10838330960885
}
#Debug simulation 
Total elapsed time: 38.275414382107556. Arrivals time: 0.4047410599887371 Scheduler time: 37.70342064695433 Scheduler overhead time: 0.06226445687934756 Adapter cache time: 0.019244021270424128 Engine time: 0.060780822299420834 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_16-16-32/adapters_256_slots_64_rate_1.6-0.8-0.4_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.4_size_16-16-32/adapters_256_slots_64_rate_1.6-0.8-0.4_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 4320, 17280, 17280, 4320, 17280, 8640, 17280, 4320, 8640, 4320, 17280, 8640, 8640, 8640, 8640, 17280, 4320, 4320, 4320, 8640, 17280, 4320, 17280, 17280, 8640, 8640, 8640, 4320, 17280, 4320, 8640, 8640, 4320, 8640, 4320, 4320, 8640, 8640, 17280, 8640, 4320, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 4320, 17280, 17280, 8640, 4320, 4320, 17280, 8640, 4320, 8640, 8640, 17280, 8640, 4320, 4320, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 8640, 4320, 8640, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 17280, 17280, 4320, 17280, 4320, 8640, 17280, 17280, 17280, 8640, 4320, 17280, 8640, 4320, 4320, 4320, 4320, 4320, 17280, 8640, 4320, 17280, 4320, 17280, 4320, 4320, 8640, 8640, 17280, 8640, 17280, 4320, 8640, 4320, 17280, 17280, 4320, 17280, 8640, 4320, 17280, 4320, 4320, 17280, 17280, 8640, 17280, 17280, 4320, 17280, 8640, 8640, 4320, 8640, 17280, 17280, 4320, 17280, 8640, 4320, 8640, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 4320, 4320, 17280, 4320, 8640, 17280, 17280, 8640, 4320, 17280, 4320, 8640, 8640, 4320, 8640, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 17280, 8640, 17280, 8640, 4320, 8640, 17280, 8640, 17280, 4320, 17280, 4320, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 4320, 17280, 4320, 17280, 8640, 8640, 4320, 8640, 17280, 8640, 8640, 17280, 4320, 17280, 17280, 8640, 4320, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 4320, 17280, 8640, 17280, 17280, 4320, 17280, 8640, 8640, 17280, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 4320, 4320, 4320, 4320]
Prompts retrieved: 2587680 . Total input tokens: 576987541 . Total output tokens: 507916087
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 27.875814273022115,
    "estimated_duration": 3600.001938621433,
    "input_throughput": 5086.623094156514,
    "output_throughput": 4445.81621701261,
    "total_throughput": 9532.439311169122,
    "itl": 99.36775798758491,
    "ttft": 2129194.1946316045,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 925,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.837287852186736,
    "arrivals": 861811,
    "finished_requests": 74317,
    "scheduler_time": 190.30630637385102
}
#Debug simulation 
Total elapsed time: 27.875921927858144. Arrivals time: 0.3522742334753275 Scheduler time: 27.349405721761286 Scheduler overhead time: 0.06284383591264486 Adapter cache time: 0.022697956301271915 Engine time: 0.06235323427245021 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_8-8-8/adapters_256_slots_64_rate_1.6-0.8-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_8-8-8/adapters_256_slots_64_rate_1.6-0.8-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 1080, 17280, 17280, 1080, 17280, 8640, 17280, 1080, 8640, 1080, 17280, 8640, 8640, 8640, 8640, 17280, 1080, 1080, 1080, 8640, 17280, 1080, 17280, 17280, 8640, 8640, 8640, 1080, 17280, 1080, 8640, 8640, 1080, 8640, 1080, 1080, 8640, 8640, 17280, 8640, 1080, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 1080, 17280, 17280, 8640, 1080, 1080, 17280, 8640, 1080, 8640, 8640, 17280, 8640, 1080, 1080, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 8640, 1080, 8640, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 17280, 17280, 1080, 17280, 1080, 8640, 17280, 17280, 17280, 8640, 1080, 17280, 8640, 1080, 1080, 1080, 1080, 1080, 17280, 8640, 1080, 17280, 1080, 17280, 1080, 1080, 8640, 8640, 17280, 8640, 17280, 1080, 8640, 1080, 17280, 17280, 1080, 17280, 8640, 1080, 17280, 1080, 1080, 17280, 17280, 8640, 17280, 17280, 1080, 17280, 8640, 8640, 1080, 8640, 17280, 17280, 1080, 17280, 8640, 1080, 8640, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 1080, 1080, 17280, 1080, 8640, 17280, 17280, 8640, 1080, 17280, 1080, 8640, 8640, 1080, 8640, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 17280, 8640, 17280, 8640, 1080, 8640, 17280, 8640, 17280, 1080, 17280, 1080, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 1080, 17280, 1080, 17280, 8640, 8640, 1080, 8640, 17280, 8640, 8640, 17280, 1080, 17280, 17280, 8640, 1080, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 1080, 17280, 8640, 17280, 17280, 1080, 17280, 8640, 8640, 17280, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 1080, 1080, 1080, 1080]
Prompts retrieved: 2312280 . Total input tokens: 515550935 . Total output tokens: 453793415
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 47.478187344036996,
    "estimated_duration": 3600.08902167006,
    "input_throughput": 5606.847463631949,
    "output_throughput": 4846.886533907266,
    "total_throughput": 10453.733997539215,
    "itl": 119.0592755073268,
    "ttft": 2071558.1548514778,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 635,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.198879735288278,
    "arrivals": 769968,
    "finished_requests": 81543,
    "scheduler_time": 175.30328888133633
}
#Debug simulation 
Total elapsed time: 47.478357086889446. Arrivals time: 0.39603253547102213 Scheduler time: 46.920017193071544 Scheduler overhead time: 0.06035232776775956 Adapter cache time: 0.018702558241784573 Engine time: 0.05962724704295397 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_8-8-16/adapters_256_slots_64_rate_1.6-0.8-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_8-8-16/adapters_256_slots_64_rate_1.6-0.8-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 1080, 17280, 17280, 1080, 17280, 8640, 17280, 1080, 8640, 1080, 17280, 8640, 8640, 8640, 8640, 17280, 1080, 1080, 1080, 8640, 17280, 1080, 17280, 17280, 8640, 8640, 8640, 1080, 17280, 1080, 8640, 8640, 1080, 8640, 1080, 1080, 8640, 8640, 17280, 8640, 1080, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 1080, 17280, 17280, 8640, 1080, 1080, 17280, 8640, 1080, 8640, 8640, 17280, 8640, 1080, 1080, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 8640, 1080, 8640, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 17280, 17280, 1080, 17280, 1080, 8640, 17280, 17280, 17280, 8640, 1080, 17280, 8640, 1080, 1080, 1080, 1080, 1080, 17280, 8640, 1080, 17280, 1080, 17280, 1080, 1080, 8640, 8640, 17280, 8640, 17280, 1080, 8640, 1080, 17280, 17280, 1080, 17280, 8640, 1080, 17280, 1080, 1080, 17280, 17280, 8640, 17280, 17280, 1080, 17280, 8640, 8640, 1080, 8640, 17280, 17280, 1080, 17280, 8640, 1080, 8640, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 1080, 1080, 17280, 1080, 8640, 17280, 17280, 8640, 1080, 17280, 1080, 8640, 8640, 1080, 8640, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 17280, 8640, 17280, 8640, 1080, 8640, 17280, 8640, 17280, 1080, 17280, 1080, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 1080, 17280, 1080, 17280, 8640, 8640, 1080, 8640, 17280, 8640, 8640, 17280, 1080, 17280, 17280, 8640, 1080, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 1080, 17280, 8640, 17280, 17280, 1080, 17280, 8640, 8640, 17280, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 1080, 1080, 1080, 1080]
Prompts retrieved: 2312280 . Total input tokens: 515550935 . Total output tokens: 453793415
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 42.46432971814647,
    "estimated_duration": 3600.00603889878,
    "input_throughput": 5434.525050403696,
    "output_throughput": 4703.030166354685,
    "total_throughput": 10137.555216758381,
    "itl": 111.39472935802183,
    "ttft": 2086202.8204536245,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 792,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.787657837867744,
    "arrivals": 769968,
    "finished_requests": 78985,
    "scheduler_time": 180.30809862409572
}
#Debug simulation 
Total elapsed time: 42.464574426878244. Arrivals time: 0.3887601401656866 Scheduler time: 41.90783222112805 Scheduler overhead time: 0.06174964224919677 Adapter cache time: 0.0207808967679739 Engine time: 0.06073677912354469 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_8-8-32/adapters_256_slots_64_rate_1.6-0.8-0.1_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_8-8-32/adapters_256_slots_64_rate_1.6-0.8-0.1_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 1080, 17280, 17280, 1080, 17280, 8640, 17280, 1080, 8640, 1080, 17280, 8640, 8640, 8640, 8640, 17280, 1080, 1080, 1080, 8640, 17280, 1080, 17280, 17280, 8640, 8640, 8640, 1080, 17280, 1080, 8640, 8640, 1080, 8640, 1080, 1080, 8640, 8640, 17280, 8640, 1080, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 1080, 17280, 17280, 8640, 1080, 1080, 17280, 8640, 1080, 8640, 8640, 17280, 8640, 1080, 1080, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 8640, 1080, 8640, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 17280, 17280, 1080, 17280, 1080, 8640, 17280, 17280, 17280, 8640, 1080, 17280, 8640, 1080, 1080, 1080, 1080, 1080, 17280, 8640, 1080, 17280, 1080, 17280, 1080, 1080, 8640, 8640, 17280, 8640, 17280, 1080, 8640, 1080, 17280, 17280, 1080, 17280, 8640, 1080, 17280, 1080, 1080, 17280, 17280, 8640, 17280, 17280, 1080, 17280, 8640, 8640, 1080, 8640, 17280, 17280, 1080, 17280, 8640, 1080, 8640, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 1080, 1080, 17280, 1080, 8640, 17280, 17280, 8640, 1080, 17280, 1080, 8640, 8640, 1080, 8640, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 17280, 8640, 17280, 8640, 1080, 8640, 17280, 8640, 17280, 1080, 17280, 1080, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 1080, 17280, 1080, 17280, 8640, 8640, 1080, 8640, 17280, 8640, 8640, 17280, 1080, 17280, 17280, 8640, 1080, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 1080, 17280, 8640, 17280, 17280, 1080, 17280, 8640, 8640, 17280, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 1080, 1080, 1080, 1080]
Prompts retrieved: 2312280 . Total input tokens: 515550935 . Total output tokens: 453793415
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 23.076841474045068,
    "estimated_duration": 3600.012397280282,
    "input_throughput": 5140.200632081127,
    "output_throughput": 4444.784693543989,
    "total_throughput": 9584.985325625115,
    "itl": 99.33365121156015,
    "ttft": 2118492.308945061,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1248,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.383455367735538,
    "arrivals": 769968,
    "finished_requests": 74680,
    "scheduler_time": 189.91892398471958
}
#Debug simulation 
Total elapsed time: 23.076950722839683. Arrivals time: 0.38810420129448175 Scheduler time: 22.514439431019127 Scheduler overhead time: 0.06124690733850002 Adapter cache time: 0.026174348779022694 Engine time: 0.06075814412906766 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_8-16-16/adapters_256_slots_64_rate_1.6-0.8-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_8-16-16/adapters_256_slots_64_rate_1.6-0.8-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 1080, 17280, 17280, 1080, 17280, 8640, 17280, 1080, 8640, 1080, 17280, 8640, 8640, 8640, 8640, 17280, 1080, 1080, 1080, 8640, 17280, 1080, 17280, 17280, 8640, 8640, 8640, 1080, 17280, 1080, 8640, 8640, 1080, 8640, 1080, 1080, 8640, 8640, 17280, 8640, 1080, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 1080, 17280, 17280, 8640, 1080, 1080, 17280, 8640, 1080, 8640, 8640, 17280, 8640, 1080, 1080, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 8640, 1080, 8640, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 17280, 17280, 1080, 17280, 1080, 8640, 17280, 17280, 17280, 8640, 1080, 17280, 8640, 1080, 1080, 1080, 1080, 1080, 17280, 8640, 1080, 17280, 1080, 17280, 1080, 1080, 8640, 8640, 17280, 8640, 17280, 1080, 8640, 1080, 17280, 17280, 1080, 17280, 8640, 1080, 17280, 1080, 1080, 17280, 17280, 8640, 17280, 17280, 1080, 17280, 8640, 8640, 1080, 8640, 17280, 17280, 1080, 17280, 8640, 1080, 8640, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 1080, 1080, 17280, 1080, 8640, 17280, 17280, 8640, 1080, 17280, 1080, 8640, 8640, 1080, 8640, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 17280, 8640, 17280, 8640, 1080, 8640, 17280, 8640, 17280, 1080, 17280, 1080, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 1080, 17280, 1080, 17280, 8640, 8640, 1080, 8640, 17280, 8640, 8640, 17280, 1080, 17280, 17280, 8640, 1080, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 1080, 17280, 8640, 17280, 17280, 1080, 17280, 8640, 8640, 17280, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 1080, 1080, 1080, 1080]
Prompts retrieved: 2312280 . Total input tokens: 515550935 . Total output tokens: 453793415
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 34.993303616996855,
    "estimated_duration": 3600.079898426792,
    "input_throughput": 5458.856068330016,
    "output_throughput": 4710.965167026245,
    "total_throughput": 10169.821235356261,
    "itl": 111.63712079096595,
    "ttft": 2088072.5286774181,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 698,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.798867396926501,
    "arrivals": 769968,
    "finished_requests": 79302,
    "scheduler_time": 180.03179000444584
}
#Debug simulation 
Total elapsed time: 34.993479723110795. Arrivals time: 0.3798573431558907 Scheduler time: 34.44926470937207 Scheduler overhead time: 0.060526912566274405 Adapter cache time: 0.019050875678658485 Engine time: 0.06005729176104069 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_8-16-32/adapters_256_slots_64_rate_1.6-0.8-0.1_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_8-16-32/adapters_256_slots_64_rate_1.6-0.8-0.1_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 1080, 17280, 17280, 1080, 17280, 8640, 17280, 1080, 8640, 1080, 17280, 8640, 8640, 8640, 8640, 17280, 1080, 1080, 1080, 8640, 17280, 1080, 17280, 17280, 8640, 8640, 8640, 1080, 17280, 1080, 8640, 8640, 1080, 8640, 1080, 1080, 8640, 8640, 17280, 8640, 1080, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 1080, 17280, 17280, 8640, 1080, 1080, 17280, 8640, 1080, 8640, 8640, 17280, 8640, 1080, 1080, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 8640, 1080, 8640, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 17280, 17280, 1080, 17280, 1080, 8640, 17280, 17280, 17280, 8640, 1080, 17280, 8640, 1080, 1080, 1080, 1080, 1080, 17280, 8640, 1080, 17280, 1080, 17280, 1080, 1080, 8640, 8640, 17280, 8640, 17280, 1080, 8640, 1080, 17280, 17280, 1080, 17280, 8640, 1080, 17280, 1080, 1080, 17280, 17280, 8640, 17280, 17280, 1080, 17280, 8640, 8640, 1080, 8640, 17280, 17280, 1080, 17280, 8640, 1080, 8640, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 1080, 1080, 17280, 1080, 8640, 17280, 17280, 8640, 1080, 17280, 1080, 8640, 8640, 1080, 8640, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 17280, 8640, 17280, 8640, 1080, 8640, 17280, 8640, 17280, 1080, 17280, 1080, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 1080, 17280, 1080, 17280, 8640, 8640, 1080, 8640, 17280, 8640, 8640, 17280, 1080, 17280, 17280, 8640, 1080, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 1080, 17280, 8640, 17280, 17280, 1080, 17280, 8640, 8640, 17280, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 1080, 1080, 1080, 1080]
Prompts retrieved: 2312280 . Total input tokens: 515550935 . Total output tokens: 453793415
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 21.273916139267385,
    "estimated_duration": 3600.0443367283065,
    "input_throughput": 5141.203626625455,
    "output_throughput": 4445.791080046883,
    "total_throughput": 9586.994706672338,
    "itl": 99.23985805019288,
    "ttft": 2118267.4712898303,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1117,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.341287193940955,
    "arrivals": 769968,
    "finished_requests": 74732,
    "scheduler_time": 190.04528602998386
}
#Debug simulation 
Total elapsed time: 21.274009166285396. Arrivals time: 0.3326547904871404 Scheduler time: 20.77022409811616 Scheduler overhead time: 0.060419169254601 Adapter cache time: 0.02428352925926447 Engine time: 0.06032377341762185 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_16-16-16/adapters_256_slots_64_rate_1.6-0.8-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_16-16-16/adapters_256_slots_64_rate_1.6-0.8-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 1080, 17280, 17280, 1080, 17280, 8640, 17280, 1080, 8640, 1080, 17280, 8640, 8640, 8640, 8640, 17280, 1080, 1080, 1080, 8640, 17280, 1080, 17280, 17280, 8640, 8640, 8640, 1080, 17280, 1080, 8640, 8640, 1080, 8640, 1080, 1080, 8640, 8640, 17280, 8640, 1080, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 1080, 17280, 17280, 8640, 1080, 1080, 17280, 8640, 1080, 8640, 8640, 17280, 8640, 1080, 1080, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 8640, 1080, 8640, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 17280, 17280, 1080, 17280, 1080, 8640, 17280, 17280, 17280, 8640, 1080, 17280, 8640, 1080, 1080, 1080, 1080, 1080, 17280, 8640, 1080, 17280, 1080, 17280, 1080, 1080, 8640, 8640, 17280, 8640, 17280, 1080, 8640, 1080, 17280, 17280, 1080, 17280, 8640, 1080, 17280, 1080, 1080, 17280, 17280, 8640, 17280, 17280, 1080, 17280, 8640, 8640, 1080, 8640, 17280, 17280, 1080, 17280, 8640, 1080, 8640, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 1080, 1080, 17280, 1080, 8640, 17280, 17280, 8640, 1080, 17280, 1080, 8640, 8640, 1080, 8640, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 17280, 8640, 17280, 8640, 1080, 8640, 17280, 8640, 17280, 1080, 17280, 1080, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 1080, 17280, 1080, 17280, 8640, 8640, 1080, 8640, 17280, 8640, 8640, 17280, 1080, 17280, 17280, 8640, 1080, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 1080, 17280, 8640, 17280, 17280, 1080, 17280, 8640, 8640, 17280, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 1080, 1080, 1080, 1080]
Prompts retrieved: 2312280 . Total input tokens: 515550935 . Total output tokens: 453793415
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 32.304724478162825,
    "estimated_duration": 3600.0160446592545,
    "input_throughput": 5452.12542291816,
    "output_throughput": 4717.267309181503,
    "total_throughput": 10169.392732099663,
    "itl": 111.49502009785029,
    "ttft": 2086536.9318898097,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 729,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.653878365675896,
    "arrivals": 769968,
    "finished_requests": 79274,
    "scheduler_time": 180.26797467598283
}
#Debug simulation 
Total elapsed time: 32.30490357009694. Arrivals time: 0.3739685844630003 Scheduler time: 31.766682025045156 Scheduler overhead time: 0.0604976168833673 Adapter cache time: 0.019285571295768023 Engine time: 0.05962141137570143 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_16-16-32/adapters_256_slots_64_rate_1.6-0.8-0.1_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.1_size_16-16-32/adapters_256_slots_64_rate_1.6-0.8-0.1_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 1080, 17280, 17280, 1080, 17280, 8640, 17280, 1080, 8640, 1080, 17280, 8640, 8640, 8640, 8640, 17280, 1080, 1080, 1080, 8640, 17280, 1080, 17280, 17280, 8640, 8640, 8640, 1080, 17280, 1080, 8640, 8640, 1080, 8640, 1080, 1080, 8640, 8640, 17280, 8640, 1080, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 1080, 17280, 17280, 8640, 1080, 1080, 17280, 8640, 1080, 8640, 8640, 17280, 8640, 1080, 1080, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 8640, 1080, 8640, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 17280, 17280, 1080, 17280, 1080, 8640, 17280, 17280, 17280, 8640, 1080, 17280, 8640, 1080, 1080, 1080, 1080, 1080, 17280, 8640, 1080, 17280, 1080, 17280, 1080, 1080, 8640, 8640, 17280, 8640, 17280, 1080, 8640, 1080, 17280, 17280, 1080, 17280, 8640, 1080, 17280, 1080, 1080, 17280, 17280, 8640, 17280, 17280, 1080, 17280, 8640, 8640, 1080, 8640, 17280, 17280, 1080, 17280, 8640, 1080, 8640, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 1080, 1080, 17280, 1080, 8640, 17280, 17280, 8640, 1080, 17280, 1080, 8640, 8640, 1080, 8640, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 17280, 8640, 17280, 8640, 1080, 8640, 17280, 8640, 17280, 1080, 17280, 1080, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 1080, 17280, 1080, 17280, 8640, 8640, 1080, 8640, 17280, 8640, 8640, 17280, 1080, 17280, 17280, 8640, 1080, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 1080, 17280, 8640, 17280, 17280, 1080, 17280, 8640, 8640, 17280, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 1080, 1080, 1080, 1080]
Prompts retrieved: 2312280 . Total input tokens: 515550935 . Total output tokens: 453793415
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 21.803957676980644,
    "estimated_duration": 3600.048800038637,
    "input_throughput": 5145.695802735003,
    "output_throughput": 4447.233604118969,
    "total_throughput": 9592.929406853973,
    "itl": 99.29381570638311,
    "ttft": 2117117.174627879,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1187,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.750287143234136,
    "arrivals": 769968,
    "finished_requests": 74765,
    "scheduler_time": 190.01413581209064
}
#Debug simulation 
Total elapsed time: 21.804052290972322. Arrivals time: 0.3328870520927012 Scheduler time: 21.297644279897213 Scheduler overhead time: 0.06133330054581165 Adapter cache time: 0.02519337646663189 Engine time: 0.060930703300982714 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_8-8-8/adapters_256_slots_64_rate_1.6-0.8-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_8-8-8/adapters_256_slots_64_rate_1.6-0.8-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 540, 17280, 17280, 540, 17280, 8640, 17280, 540, 8640, 540, 17280, 8640, 8640, 8640, 8640, 17280, 540, 540, 540, 8640, 17280, 540, 17280, 17280, 8640, 8640, 8640, 540, 17280, 540, 8640, 8640, 540, 8640, 540, 540, 8640, 8640, 17280, 8640, 540, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 540, 17280, 17280, 8640, 540, 540, 17280, 8640, 540, 8640, 8640, 17280, 8640, 540, 540, 17280, 17280, 17280, 17280, 17280, 17280, 540, 8640, 540, 8640, 540, 540, 540, 8640, 8640, 8640, 540, 540, 17280, 17280, 540, 17280, 540, 8640, 17280, 17280, 17280, 8640, 540, 17280, 8640, 540, 540, 540, 540, 540, 17280, 8640, 540, 17280, 540, 17280, 540, 540, 8640, 8640, 17280, 8640, 17280, 540, 8640, 540, 17280, 17280, 540, 17280, 8640, 540, 17280, 540, 540, 17280, 17280, 8640, 17280, 17280, 540, 17280, 8640, 8640, 540, 8640, 17280, 17280, 540, 17280, 8640, 540, 8640, 17280, 540, 540, 540, 540, 540, 540, 17280, 540, 540, 540, 17280, 540, 8640, 17280, 17280, 8640, 540, 17280, 540, 8640, 8640, 540, 8640, 540, 17280, 540, 540, 17280, 540, 17280, 17280, 8640, 17280, 8640, 540, 8640, 17280, 8640, 17280, 540, 17280, 540, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 540, 17280, 540, 17280, 8640, 8640, 540, 8640, 17280, 8640, 8640, 17280, 540, 17280, 17280, 8640, 540, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 540, 17280, 8640, 17280, 17280, 540, 17280, 8640, 8640, 17280, 540, 8640, 540, 540, 540, 540, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 540, 540, 540, 540]
Prompts retrieved: 2266380 . Total input tokens: 505288460 . Total output tokens: 444846041
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 41.90056456020102,
    "estimated_duration": 3600.094504153197,
    "input_throughput": 5579.12076386573,
    "output_throughput": 4844.506159457706,
    "total_throughput": 10423.626923323436,
    "itl": 118.96803232608762,
    "ttft": 2073100.6386348635,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 861,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.693284176509012,
    "arrivals": 754714,
    "finished_requests": 81256,
    "scheduler_time": 175.0802864025028
}
#Debug simulation 
Total elapsed time: 41.900732612237334. Arrivals time: 0.39379033306613564 Scheduler time: 41.34369943337515 Scheduler overhead time: 0.059679420199245214 Adapter cache time: 0.021219878923147917 Engine time: 0.05828460631892085 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_8-8-16/adapters_256_slots_64_rate_1.6-0.8-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_8-8-16/adapters_256_slots_64_rate_1.6-0.8-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 540, 17280, 17280, 540, 17280, 8640, 17280, 540, 8640, 540, 17280, 8640, 8640, 8640, 8640, 17280, 540, 540, 540, 8640, 17280, 540, 17280, 17280, 8640, 8640, 8640, 540, 17280, 540, 8640, 8640, 540, 8640, 540, 540, 8640, 8640, 17280, 8640, 540, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 540, 17280, 17280, 8640, 540, 540, 17280, 8640, 540, 8640, 8640, 17280, 8640, 540, 540, 17280, 17280, 17280, 17280, 17280, 17280, 540, 8640, 540, 8640, 540, 540, 540, 8640, 8640, 8640, 540, 540, 17280, 17280, 540, 17280, 540, 8640, 17280, 17280, 17280, 8640, 540, 17280, 8640, 540, 540, 540, 540, 540, 17280, 8640, 540, 17280, 540, 17280, 540, 540, 8640, 8640, 17280, 8640, 17280, 540, 8640, 540, 17280, 17280, 540, 17280, 8640, 540, 17280, 540, 540, 17280, 17280, 8640, 17280, 17280, 540, 17280, 8640, 8640, 540, 8640, 17280, 17280, 540, 17280, 8640, 540, 8640, 17280, 540, 540, 540, 540, 540, 540, 17280, 540, 540, 540, 17280, 540, 8640, 17280, 17280, 8640, 540, 17280, 540, 8640, 8640, 540, 8640, 540, 17280, 540, 540, 17280, 540, 17280, 17280, 8640, 17280, 8640, 540, 8640, 17280, 8640, 17280, 540, 17280, 540, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 540, 17280, 540, 17280, 8640, 8640, 540, 8640, 17280, 8640, 8640, 17280, 540, 17280, 17280, 8640, 540, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 540, 17280, 8640, 17280, 17280, 540, 17280, 8640, 8640, 17280, 540, 8640, 540, 540, 540, 540, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 540, 540, 540, 540]
Prompts retrieved: 2266380 . Total input tokens: 505288460 . Total output tokens: 444846041
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 32.79221352888271,
    "estimated_duration": 3600.125231286039,
    "input_throughput": 5418.026248223651,
    "output_throughput": 4699.453744823293,
    "total_throughput": 10117.479993046943,
    "itl": 111.20751408676125,
    "ttft": 2089255.33241286,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 848,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.192356923632332,
    "arrivals": 754714,
    "finished_requests": 78778,
    "scheduler_time": 180.2457505030087
}
#Debug simulation 
Total elapsed time: 32.79240646306425. Arrivals time: 0.36998137971386313 Scheduler time: 32.25753179611638 Scheduler overhead time: 0.06029883772134781 Adapter cache time: 0.02085733925923705 Engine time: 0.05920541053637862 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_8-8-32/adapters_256_slots_64_rate_1.6-0.8-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_8-8-32/adapters_256_slots_64_rate_1.6-0.8-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 540, 17280, 17280, 540, 17280, 8640, 17280, 540, 8640, 540, 17280, 8640, 8640, 8640, 8640, 17280, 540, 540, 540, 8640, 17280, 540, 17280, 17280, 8640, 8640, 8640, 540, 17280, 540, 8640, 8640, 540, 8640, 540, 540, 8640, 8640, 17280, 8640, 540, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 540, 17280, 17280, 8640, 540, 540, 17280, 8640, 540, 8640, 8640, 17280, 8640, 540, 540, 17280, 17280, 17280, 17280, 17280, 17280, 540, 8640, 540, 8640, 540, 540, 540, 8640, 8640, 8640, 540, 540, 17280, 17280, 540, 17280, 540, 8640, 17280, 17280, 17280, 8640, 540, 17280, 8640, 540, 540, 540, 540, 540, 17280, 8640, 540, 17280, 540, 17280, 540, 540, 8640, 8640, 17280, 8640, 17280, 540, 8640, 540, 17280, 17280, 540, 17280, 8640, 540, 17280, 540, 540, 17280, 17280, 8640, 17280, 17280, 540, 17280, 8640, 8640, 540, 8640, 17280, 17280, 540, 17280, 8640, 540, 8640, 17280, 540, 540, 540, 540, 540, 540, 17280, 540, 540, 540, 17280, 540, 8640, 17280, 17280, 8640, 540, 17280, 540, 8640, 8640, 540, 8640, 540, 17280, 540, 540, 17280, 540, 17280, 17280, 8640, 17280, 8640, 540, 8640, 17280, 8640, 17280, 540, 17280, 540, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 540, 17280, 540, 17280, 8640, 8640, 540, 8640, 17280, 8640, 8640, 17280, 540, 17280, 17280, 8640, 540, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 540, 17280, 8640, 17280, 17280, 540, 17280, 8640, 8640, 17280, 540, 8640, 540, 540, 540, 540, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 540, 540, 540, 540]
Prompts retrieved: 2266380 . Total input tokens: 505288460 . Total output tokens: 444846041
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 22.758663777727634,
    "estimated_duration": 3600.0364415651125,
    "input_throughput": 5105.357764659055,
    "output_throughput": 4433.352344917183,
    "total_throughput": 9538.710109576237,
    "itl": 98.7633870487271,
    "ttft": 2117433.223757308,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1084,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.117078751870435,
    "arrivals": 754714,
    "finished_requests": 74243,
    "scheduler_time": 190.4828061574986
}
#Debug simulation 
Total elapsed time: 22.75876378780231. Arrivals time: 0.3301820904016495 Scheduler time: 22.25582208344713 Scheduler overhead time: 0.06150398822501302 Adapter cache time: 0.024217024445533752 Engine time: 0.06098103430122137 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_8-16-16/adapters_256_slots_64_rate_1.6-0.8-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_8-16-16/adapters_256_slots_64_rate_1.6-0.8-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 540, 17280, 17280, 540, 17280, 8640, 17280, 540, 8640, 540, 17280, 8640, 8640, 8640, 8640, 17280, 540, 540, 540, 8640, 17280, 540, 17280, 17280, 8640, 8640, 8640, 540, 17280, 540, 8640, 8640, 540, 8640, 540, 540, 8640, 8640, 17280, 8640, 540, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 540, 17280, 17280, 8640, 540, 540, 17280, 8640, 540, 8640, 8640, 17280, 8640, 540, 540, 17280, 17280, 17280, 17280, 17280, 17280, 540, 8640, 540, 8640, 540, 540, 540, 8640, 8640, 8640, 540, 540, 17280, 17280, 540, 17280, 540, 8640, 17280, 17280, 17280, 8640, 540, 17280, 8640, 540, 540, 540, 540, 540, 17280, 8640, 540, 17280, 540, 17280, 540, 540, 8640, 8640, 17280, 8640, 17280, 540, 8640, 540, 17280, 17280, 540, 17280, 8640, 540, 17280, 540, 540, 17280, 17280, 8640, 17280, 17280, 540, 17280, 8640, 8640, 540, 8640, 17280, 17280, 540, 17280, 8640, 540, 8640, 17280, 540, 540, 540, 540, 540, 540, 17280, 540, 540, 540, 17280, 540, 8640, 17280, 17280, 8640, 540, 17280, 540, 8640, 8640, 540, 8640, 540, 17280, 540, 540, 17280, 540, 17280, 17280, 8640, 17280, 8640, 540, 8640, 17280, 8640, 17280, 540, 17280, 540, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 540, 17280, 540, 17280, 8640, 8640, 540, 8640, 17280, 8640, 8640, 17280, 540, 17280, 17280, 8640, 540, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 540, 17280, 8640, 17280, 17280, 540, 17280, 8640, 8640, 17280, 540, 8640, 540, 540, 540, 540, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 540, 540, 540, 540]
Prompts retrieved: 2266380 . Total input tokens: 505288460 . Total output tokens: 444846041
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 41.65291609801352,
    "estimated_duration": 3600.103274394717,
    "input_throughput": 5414.396064312139,
    "output_throughput": 4704.641980818631,
    "total_throughput": 10119.03804513077,
    "itl": 111.31597962317733,
    "ttft": 2084939.3090604548,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 764,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.241029493603848,
    "arrivals": 754714,
    "finished_requests": 78837,
    "scheduler_time": 180.1868000336408
}
#Debug simulation 
Total elapsed time: 41.65309875737876. Arrivals time: 0.7038414180278778 Scheduler time: 40.78112086188048 Scheduler overhead time: 0.06234434247016907 Adapter cache time: 0.02005685865879059 Engine time: 0.06069793738424778 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_8-16-32/adapters_256_slots_64_rate_1.6-0.8-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_8-16-32/adapters_256_slots_64_rate_1.6-0.8-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 540, 17280, 17280, 540, 17280, 8640, 17280, 540, 8640, 540, 17280, 8640, 8640, 8640, 8640, 17280, 540, 540, 540, 8640, 17280, 540, 17280, 17280, 8640, 8640, 8640, 540, 17280, 540, 8640, 8640, 540, 8640, 540, 540, 8640, 8640, 17280, 8640, 540, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 540, 17280, 17280, 8640, 540, 540, 17280, 8640, 540, 8640, 8640, 17280, 8640, 540, 540, 17280, 17280, 17280, 17280, 17280, 17280, 540, 8640, 540, 8640, 540, 540, 540, 8640, 8640, 8640, 540, 540, 17280, 17280, 540, 17280, 540, 8640, 17280, 17280, 17280, 8640, 540, 17280, 8640, 540, 540, 540, 540, 540, 17280, 8640, 540, 17280, 540, 17280, 540, 540, 8640, 8640, 17280, 8640, 17280, 540, 8640, 540, 17280, 17280, 540, 17280, 8640, 540, 17280, 540, 540, 17280, 17280, 8640, 17280, 17280, 540, 17280, 8640, 8640, 540, 8640, 17280, 17280, 540, 17280, 8640, 540, 8640, 17280, 540, 540, 540, 540, 540, 540, 17280, 540, 540, 540, 17280, 540, 8640, 17280, 17280, 8640, 540, 17280, 540, 8640, 8640, 540, 8640, 540, 17280, 540, 540, 17280, 540, 17280, 17280, 8640, 17280, 8640, 540, 8640, 17280, 8640, 17280, 540, 17280, 540, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 540, 17280, 540, 17280, 8640, 8640, 540, 8640, 17280, 8640, 8640, 17280, 540, 17280, 17280, 8640, 540, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 540, 17280, 8640, 17280, 17280, 540, 17280, 8640, 8640, 17280, 540, 8640, 540, 540, 540, 540, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 540, 540, 540, 540]
Prompts retrieved: 2266380 . Total input tokens: 505288460 . Total output tokens: 444846041
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 24.005940223112702,
    "estimated_duration": 3600.0857806520294,
    "input_throughput": 5105.595566300924,
    "output_throughput": 4438.236745877244,
    "total_throughput": 9543.832312178167,
    "itl": 98.81960819438882,
    "ttft": 2119306.1381775523,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1071,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.963573944703693,
    "arrivals": 754714,
    "finished_requests": 74296,
    "scheduler_time": 190.44579199786577
}
#Debug simulation 
Total elapsed time: 24.006032145116478. Arrivals time: 0.4034369410946965 Scheduler time: 23.428637844044715 Scheduler overhead time: 0.06259026238694787 Adapter cache time: 0.024117776192724705 Engine time: 0.06111261248588562 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_16-16-16/adapters_256_slots_64_rate_1.6-0.8-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_16-16-16/adapters_256_slots_64_rate_1.6-0.8-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 540, 17280, 17280, 540, 17280, 8640, 17280, 540, 8640, 540, 17280, 8640, 8640, 8640, 8640, 17280, 540, 540, 540, 8640, 17280, 540, 17280, 17280, 8640, 8640, 8640, 540, 17280, 540, 8640, 8640, 540, 8640, 540, 540, 8640, 8640, 17280, 8640, 540, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 540, 17280, 17280, 8640, 540, 540, 17280, 8640, 540, 8640, 8640, 17280, 8640, 540, 540, 17280, 17280, 17280, 17280, 17280, 17280, 540, 8640, 540, 8640, 540, 540, 540, 8640, 8640, 8640, 540, 540, 17280, 17280, 540, 17280, 540, 8640, 17280, 17280, 17280, 8640, 540, 17280, 8640, 540, 540, 540, 540, 540, 17280, 8640, 540, 17280, 540, 17280, 540, 540, 8640, 8640, 17280, 8640, 17280, 540, 8640, 540, 17280, 17280, 540, 17280, 8640, 540, 17280, 540, 540, 17280, 17280, 8640, 17280, 17280, 540, 17280, 8640, 8640, 540, 8640, 17280, 17280, 540, 17280, 8640, 540, 8640, 17280, 540, 540, 540, 540, 540, 540, 17280, 540, 540, 540, 17280, 540, 8640, 17280, 17280, 8640, 540, 17280, 540, 8640, 8640, 540, 8640, 540, 17280, 540, 540, 17280, 540, 17280, 17280, 8640, 17280, 8640, 540, 8640, 17280, 8640, 17280, 540, 17280, 540, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 540, 17280, 540, 17280, 8640, 8640, 540, 8640, 17280, 8640, 8640, 17280, 540, 17280, 17280, 8640, 540, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 540, 17280, 8640, 17280, 17280, 540, 17280, 8640, 8640, 17280, 540, 8640, 540, 540, 540, 540, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 540, 540, 540, 540]
Prompts retrieved: 2266380 . Total input tokens: 505288460 . Total output tokens: 444846041
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 39.99143646005541,
    "estimated_duration": 3600.010499543643,
    "input_throughput": 5416.824757170015,
    "output_throughput": 4701.371843816984,
    "total_throughput": 10118.196600987,
    "itl": 111.18637901522808,
    "ttft": 2088382.5520394274,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 819,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.228431250327241,
    "arrivals": 754714,
    "finished_requests": 78788,
    "scheduler_time": 180.29821569873366
}
#Debug simulation 
Total elapsed time: 39.9916064129211. Arrivals time: 0.4657788327895105 Scheduler time: 39.35794232226908 Scheduler overhead time: 0.061592523474246264 Adapter cache time: 0.02071608044207096 Engine time: 0.06037372210994363 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_16-16-32/adapters_256_slots_64_rate_1.6-0.8-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.05_size_16-16-32/adapters_256_slots_64_rate_1.6-0.8-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 540, 17280, 17280, 540, 17280, 8640, 17280, 540, 8640, 540, 17280, 8640, 8640, 8640, 8640, 17280, 540, 540, 540, 8640, 17280, 540, 17280, 17280, 8640, 8640, 8640, 540, 17280, 540, 8640, 8640, 540, 8640, 540, 540, 8640, 8640, 17280, 8640, 540, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 540, 17280, 17280, 8640, 540, 540, 17280, 8640, 540, 8640, 8640, 17280, 8640, 540, 540, 17280, 17280, 17280, 17280, 17280, 17280, 540, 8640, 540, 8640, 540, 540, 540, 8640, 8640, 8640, 540, 540, 17280, 17280, 540, 17280, 540, 8640, 17280, 17280, 17280, 8640, 540, 17280, 8640, 540, 540, 540, 540, 540, 17280, 8640, 540, 17280, 540, 17280, 540, 540, 8640, 8640, 17280, 8640, 17280, 540, 8640, 540, 17280, 17280, 540, 17280, 8640, 540, 17280, 540, 540, 17280, 17280, 8640, 17280, 17280, 540, 17280, 8640, 8640, 540, 8640, 17280, 17280, 540, 17280, 8640, 540, 8640, 17280, 540, 540, 540, 540, 540, 540, 17280, 540, 540, 540, 17280, 540, 8640, 17280, 17280, 8640, 540, 17280, 540, 8640, 8640, 540, 8640, 540, 17280, 540, 540, 17280, 540, 17280, 17280, 8640, 17280, 8640, 540, 8640, 17280, 8640, 17280, 540, 17280, 540, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 540, 17280, 540, 17280, 8640, 8640, 540, 8640, 17280, 8640, 8640, 17280, 540, 17280, 17280, 8640, 540, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 540, 17280, 8640, 17280, 17280, 540, 17280, 8640, 8640, 17280, 540, 8640, 540, 540, 540, 540, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 540, 540, 540, 540]
Prompts retrieved: 2266380 . Total input tokens: 505288460 . Total output tokens: 444846041
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 23.194811064749956,
    "estimated_duration": 3600.010508071212,
    "input_throughput": 5108.346478092065,
    "output_throughput": 4440.492316386257,
    "total_throughput": 9548.83879447832,
    "itl": 99.00698557016133,
    "ttft": 2117472.4919121857,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1067,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.872086725179127,
    "arrivals": 754714,
    "finished_requests": 74355,
    "scheduler_time": 190.25582840349597
}
#Debug simulation 
Total elapsed time: 23.19491227576509. Arrivals time: 0.3271705759689212 Scheduler time: 22.693269793875515 Scheduler overhead time: 0.06160230003297329 Adapter cache time: 0.023817013017833233 Engine time: 0.06277162535116076 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_8-8-8/adapters_256_slots_64_rate_1.6-0.8-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_8-8-8/adapters_256_slots_64_rate_1.6-0.8-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 270, 17280, 17280, 270, 17280, 8640, 17280, 270, 8640, 270, 17280, 8640, 8640, 8640, 8640, 17280, 270, 270, 270, 8640, 17280, 270, 17280, 17280, 8640, 8640, 8640, 270, 17280, 270, 8640, 8640, 270, 8640, 270, 270, 8640, 8640, 17280, 8640, 270, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 270, 17280, 17280, 8640, 270, 270, 17280, 8640, 270, 8640, 8640, 17280, 8640, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 8640, 270, 8640, 270, 270, 270, 8640, 8640, 8640, 270, 270, 17280, 17280, 270, 17280, 270, 8640, 17280, 17280, 17280, 8640, 270, 17280, 8640, 270, 270, 270, 270, 270, 17280, 8640, 270, 17280, 270, 17280, 270, 270, 8640, 8640, 17280, 8640, 17280, 270, 8640, 270, 17280, 17280, 270, 17280, 8640, 270, 17280, 270, 270, 17280, 17280, 8640, 17280, 17280, 270, 17280, 8640, 8640, 270, 8640, 17280, 17280, 270, 17280, 8640, 270, 8640, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 8640, 17280, 17280, 8640, 270, 17280, 270, 8640, 8640, 270, 8640, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 8640, 17280, 8640, 270, 8640, 17280, 8640, 17280, 270, 17280, 270, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 270, 17280, 270, 17280, 8640, 8640, 270, 8640, 17280, 8640, 8640, 17280, 270, 17280, 17280, 8640, 270, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 270, 17280, 8640, 17280, 17280, 270, 17280, 8640, 8640, 17280, 270, 8640, 270, 270, 270, 270, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 270, 270, 270, 270]
Prompts retrieved: 2243430 . Total input tokens: 500197697 . Total output tokens: 440334485
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 39.57595158787444,
    "estimated_duration": 3600.026828229369,
    "input_throughput": 5543.117302215999,
    "output_throughput": 4836.147848532293,
    "total_throughput": 10379.265150748293,
    "itl": 119.28972224021359,
    "ttft": 2071066.0009365515,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 790,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.223803135240551,
    "arrivals": 746983,
    "finished_requests": 80706,
    "scheduler_time": 174.86870272939527
}
#Debug simulation 
Total elapsed time: 39.57611886924133. Arrivals time: 0.42001108173280954 Scheduler time: 38.99362490652129 Scheduler overhead time: 0.05969655327498913 Adapter cache time: 0.019612861797213554 Engine time: 0.05906502855941653 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_8-8-16/adapters_256_slots_64_rate_1.6-0.8-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_8-8-16/adapters_256_slots_64_rate_1.6-0.8-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 270, 17280, 17280, 270, 17280, 8640, 17280, 270, 8640, 270, 17280, 8640, 8640, 8640, 8640, 17280, 270, 270, 270, 8640, 17280, 270, 17280, 17280, 8640, 8640, 8640, 270, 17280, 270, 8640, 8640, 270, 8640, 270, 270, 8640, 8640, 17280, 8640, 270, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 270, 17280, 17280, 8640, 270, 270, 17280, 8640, 270, 8640, 8640, 17280, 8640, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 8640, 270, 8640, 270, 270, 270, 8640, 8640, 8640, 270, 270, 17280, 17280, 270, 17280, 270, 8640, 17280, 17280, 17280, 8640, 270, 17280, 8640, 270, 270, 270, 270, 270, 17280, 8640, 270, 17280, 270, 17280, 270, 270, 8640, 8640, 17280, 8640, 17280, 270, 8640, 270, 17280, 17280, 270, 17280, 8640, 270, 17280, 270, 270, 17280, 17280, 8640, 17280, 17280, 270, 17280, 8640, 8640, 270, 8640, 17280, 17280, 270, 17280, 8640, 270, 8640, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 8640, 17280, 17280, 8640, 270, 17280, 270, 8640, 8640, 270, 8640, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 8640, 17280, 8640, 270, 8640, 17280, 8640, 17280, 270, 17280, 270, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 270, 17280, 270, 17280, 8640, 8640, 270, 8640, 17280, 8640, 8640, 17280, 270, 17280, 17280, 8640, 270, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 270, 17280, 8640, 17280, 17280, 270, 17280, 8640, 8640, 17280, 270, 8640, 270, 270, 270, 270, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 270, 270, 270, 270]
Prompts retrieved: 2243430 . Total input tokens: 500197697 . Total output tokens: 440334485
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 28.687121557071805,
    "estimated_duration": 3600.0425113240867,
    "input_throughput": 5373.7682094439115,
    "output_throughput": 4699.697280457167,
    "total_throughput": 10073.465489901078,
    "itl": 111.6985999402206,
    "ttft": 2088212.6041119522,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 912,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.6578449237346735,
    "arrivals": 746983,
    "finished_requests": 78451,
    "scheduler_time": 179.97240082995987
}
#Debug simulation 
Total elapsed time: 28.687312974128872. Arrivals time: 0.36511538503691554 Scheduler time: 28.15661218110472 Scheduler overhead time: 0.06010705837979913 Adapter cache time: 0.021354184951633215 Engine time: 0.0596032883040607 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_8-8-32/adapters_256_slots_64_rate_1.6-0.8-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_8-8-32/adapters_256_slots_64_rate_1.6-0.8-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 270, 17280, 17280, 270, 17280, 8640, 17280, 270, 8640, 270, 17280, 8640, 8640, 8640, 8640, 17280, 270, 270, 270, 8640, 17280, 270, 17280, 17280, 8640, 8640, 8640, 270, 17280, 270, 8640, 8640, 270, 8640, 270, 270, 8640, 8640, 17280, 8640, 270, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 270, 17280, 17280, 8640, 270, 270, 17280, 8640, 270, 8640, 8640, 17280, 8640, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 8640, 270, 8640, 270, 270, 270, 8640, 8640, 8640, 270, 270, 17280, 17280, 270, 17280, 270, 8640, 17280, 17280, 17280, 8640, 270, 17280, 8640, 270, 270, 270, 270, 270, 17280, 8640, 270, 17280, 270, 17280, 270, 270, 8640, 8640, 17280, 8640, 17280, 270, 8640, 270, 17280, 17280, 270, 17280, 8640, 270, 17280, 270, 270, 17280, 17280, 8640, 17280, 17280, 270, 17280, 8640, 8640, 270, 8640, 17280, 17280, 270, 17280, 8640, 270, 8640, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 8640, 17280, 17280, 8640, 270, 17280, 270, 8640, 8640, 270, 8640, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 8640, 17280, 8640, 270, 8640, 17280, 8640, 17280, 270, 17280, 270, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 270, 17280, 270, 17280, 8640, 8640, 270, 8640, 17280, 8640, 8640, 17280, 270, 17280, 17280, 8640, 270, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 270, 17280, 8640, 17280, 17280, 270, 17280, 8640, 8640, 17280, 270, 8640, 270, 270, 270, 270, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 270, 270, 270, 270]
Prompts retrieved: 2243430 . Total input tokens: 500197697 . Total output tokens: 440334485
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 19.284405468963087,
    "estimated_duration": 3600.072741537581,
    "input_throughput": 5073.747757718557,
    "output_throughput": 4444.4963056958195,
    "total_throughput": 9518.244063414377,
    "itl": 99.52782122601701,
    "ttft": 2118227.7194582685,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1073,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.053874040679094,
    "arrivals": 746983,
    "finished_requests": 74044,
    "scheduler_time": 189.87570491913908
}
#Debug simulation 
Total elapsed time: 19.28454977925867. Arrivals time: 0.38638803316280246 Scheduler time: 18.727765453979373 Scheduler overhead time: 0.0600311579182744 Adapter cache time: 0.023751181084662676 Engine time: 0.06077238451689482 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_8-16-16/adapters_256_slots_64_rate_1.6-0.8-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_8-16-16/adapters_256_slots_64_rate_1.6-0.8-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 270, 17280, 17280, 270, 17280, 8640, 17280, 270, 8640, 270, 17280, 8640, 8640, 8640, 8640, 17280, 270, 270, 270, 8640, 17280, 270, 17280, 17280, 8640, 8640, 8640, 270, 17280, 270, 8640, 8640, 270, 8640, 270, 270, 8640, 8640, 17280, 8640, 270, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 270, 17280, 17280, 8640, 270, 270, 17280, 8640, 270, 8640, 8640, 17280, 8640, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 8640, 270, 8640, 270, 270, 270, 8640, 8640, 8640, 270, 270, 17280, 17280, 270, 17280, 270, 8640, 17280, 17280, 17280, 8640, 270, 17280, 8640, 270, 270, 270, 270, 270, 17280, 8640, 270, 17280, 270, 17280, 270, 270, 8640, 8640, 17280, 8640, 17280, 270, 8640, 270, 17280, 17280, 270, 17280, 8640, 270, 17280, 270, 270, 17280, 17280, 8640, 17280, 17280, 270, 17280, 8640, 8640, 270, 8640, 17280, 17280, 270, 17280, 8640, 270, 8640, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 8640, 17280, 17280, 8640, 270, 17280, 270, 8640, 8640, 270, 8640, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 8640, 17280, 8640, 270, 8640, 17280, 8640, 17280, 270, 17280, 270, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 270, 17280, 270, 17280, 8640, 8640, 270, 8640, 17280, 8640, 8640, 17280, 270, 17280, 17280, 8640, 270, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 270, 17280, 8640, 17280, 17280, 270, 17280, 8640, 8640, 17280, 270, 8640, 270, 270, 270, 270, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 270, 270, 270, 270]
Prompts retrieved: 2243430 . Total input tokens: 500197697 . Total output tokens: 440334485
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 31.555121124722064,
    "estimated_duration": 3600.028961906237,
    "input_throughput": 5398.233238020865,
    "output_throughput": 4713.379025432946,
    "total_throughput": 10111.612263453811,
    "itl": 111.65489160555846,
    "ttft": 2089176.9847855526,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 843,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.760629678615359,
    "arrivals": 746983,
    "finished_requests": 78660,
    "scheduler_time": 180.16365986266504
}
#Debug simulation 
Total elapsed time: 31.555224545765668. Arrivals time: 0.4934001788496971 Scheduler time: 30.896916324272752 Scheduler overhead time: 0.060336328111588955 Adapter cache time: 0.01997318957000971 Engine time: 0.06022982019931078 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_8-16-32/adapters_256_slots_64_rate_1.6-0.8-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_8-16-32/adapters_256_slots_64_rate_1.6-0.8-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 270, 17280, 17280, 270, 17280, 8640, 17280, 270, 8640, 270, 17280, 8640, 8640, 8640, 8640, 17280, 270, 270, 270, 8640, 17280, 270, 17280, 17280, 8640, 8640, 8640, 270, 17280, 270, 8640, 8640, 270, 8640, 270, 270, 8640, 8640, 17280, 8640, 270, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 270, 17280, 17280, 8640, 270, 270, 17280, 8640, 270, 8640, 8640, 17280, 8640, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 8640, 270, 8640, 270, 270, 270, 8640, 8640, 8640, 270, 270, 17280, 17280, 270, 17280, 270, 8640, 17280, 17280, 17280, 8640, 270, 17280, 8640, 270, 270, 270, 270, 270, 17280, 8640, 270, 17280, 270, 17280, 270, 270, 8640, 8640, 17280, 8640, 17280, 270, 8640, 270, 17280, 17280, 270, 17280, 8640, 270, 17280, 270, 270, 17280, 17280, 8640, 17280, 17280, 270, 17280, 8640, 8640, 270, 8640, 17280, 17280, 270, 17280, 8640, 270, 8640, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 8640, 17280, 17280, 8640, 270, 17280, 270, 8640, 8640, 270, 8640, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 8640, 17280, 8640, 270, 8640, 17280, 8640, 17280, 270, 17280, 270, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 270, 17280, 270, 17280, 8640, 8640, 270, 8640, 17280, 8640, 8640, 17280, 270, 17280, 17280, 8640, 270, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 270, 17280, 8640, 17280, 17280, 270, 17280, 8640, 8640, 17280, 270, 8640, 270, 270, 270, 270, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 270, 270, 270, 270]
Prompts retrieved: 2243430 . Total input tokens: 500197697 . Total output tokens: 440334485
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 18.711609348189086,
    "estimated_duration": 3600.0438491893847,
    "input_throughput": 5079.551184943917,
    "output_throughput": 4446.988611987267,
    "total_throughput": 9526.539796931185,
    "itl": 99.57211467386118,
    "ttft": 2117771.8153975317,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1122,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.34371145475656,
    "arrivals": 746983,
    "finished_requests": 74061,
    "scheduler_time": 189.87956785798346
}
#Debug simulation 
Total elapsed time: 18.711752652190626. Arrivals time: 0.41650511091575027 Scheduler time: 18.125331739895046 Scheduler overhead time: 0.05959199974313378 Adapter cache time: 0.023886049166321754 Engine time: 0.06061334768310189 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_16-16-16/adapters_256_slots_64_rate_1.6-0.8-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_16-16-16/adapters_256_slots_64_rate_1.6-0.8-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 270, 17280, 17280, 270, 17280, 8640, 17280, 270, 8640, 270, 17280, 8640, 8640, 8640, 8640, 17280, 270, 270, 270, 8640, 17280, 270, 17280, 17280, 8640, 8640, 8640, 270, 17280, 270, 8640, 8640, 270, 8640, 270, 270, 8640, 8640, 17280, 8640, 270, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 270, 17280, 17280, 8640, 270, 270, 17280, 8640, 270, 8640, 8640, 17280, 8640, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 8640, 270, 8640, 270, 270, 270, 8640, 8640, 8640, 270, 270, 17280, 17280, 270, 17280, 270, 8640, 17280, 17280, 17280, 8640, 270, 17280, 8640, 270, 270, 270, 270, 270, 17280, 8640, 270, 17280, 270, 17280, 270, 270, 8640, 8640, 17280, 8640, 17280, 270, 8640, 270, 17280, 17280, 270, 17280, 8640, 270, 17280, 270, 270, 17280, 17280, 8640, 17280, 17280, 270, 17280, 8640, 8640, 270, 8640, 17280, 17280, 270, 17280, 8640, 270, 8640, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 8640, 17280, 17280, 8640, 270, 17280, 270, 8640, 8640, 270, 8640, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 8640, 17280, 8640, 270, 8640, 17280, 8640, 17280, 270, 17280, 270, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 270, 17280, 270, 17280, 8640, 8640, 270, 8640, 17280, 8640, 8640, 17280, 270, 17280, 17280, 8640, 270, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 270, 17280, 8640, 17280, 17280, 270, 17280, 8640, 8640, 17280, 270, 8640, 270, 270, 270, 270, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 270, 270, 270, 270]
Prompts retrieved: 2243430 . Total input tokens: 500197697 . Total output tokens: 440334485
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 41.91624934738502,
    "estimated_duration": 3600.0419275342256,
    "input_throughput": 5381.135106187128,
    "output_throughput": 4703.419388117397,
    "total_throughput": 10084.554494304524,
    "itl": 111.59456154345459,
    "ttft": 2083214.496436483,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 764,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.877315598595864,
    "arrivals": 746983,
    "finished_requests": 78544,
    "scheduler_time": 180.10231674055183
}
#Debug simulation 
Total elapsed time: 41.916371998377144. Arrivals time: 0.4460995593108237 Scheduler time: 41.303579800296575 Scheduler overhead time: 0.06192377582192421 Adapter cache time: 0.019726580940186977 Engine time: 0.060494350735098124 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_16-16-32/adapters_256_slots_64_rate_1.6-0.8-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.025_size_16-16-32/adapters_256_slots_64_rate_1.6-0.8-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 270, 17280, 17280, 270, 17280, 8640, 17280, 270, 8640, 270, 17280, 8640, 8640, 8640, 8640, 17280, 270, 270, 270, 8640, 17280, 270, 17280, 17280, 8640, 8640, 8640, 270, 17280, 270, 8640, 8640, 270, 8640, 270, 270, 8640, 8640, 17280, 8640, 270, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 270, 17280, 17280, 8640, 270, 270, 17280, 8640, 270, 8640, 8640, 17280, 8640, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 8640, 270, 8640, 270, 270, 270, 8640, 8640, 8640, 270, 270, 17280, 17280, 270, 17280, 270, 8640, 17280, 17280, 17280, 8640, 270, 17280, 8640, 270, 270, 270, 270, 270, 17280, 8640, 270, 17280, 270, 17280, 270, 270, 8640, 8640, 17280, 8640, 17280, 270, 8640, 270, 17280, 17280, 270, 17280, 8640, 270, 17280, 270, 270, 17280, 17280, 8640, 17280, 17280, 270, 17280, 8640, 8640, 270, 8640, 17280, 17280, 270, 17280, 8640, 270, 8640, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 8640, 17280, 17280, 8640, 270, 17280, 270, 8640, 8640, 270, 8640, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 8640, 17280, 8640, 270, 8640, 17280, 8640, 17280, 270, 17280, 270, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 270, 17280, 270, 17280, 8640, 8640, 270, 8640, 17280, 8640, 8640, 17280, 270, 17280, 17280, 8640, 270, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 270, 17280, 8640, 17280, 17280, 270, 17280, 8640, 8640, 17280, 270, 8640, 270, 270, 270, 270, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 270, 270, 270, 270]
Prompts retrieved: 2243430 . Total input tokens: 500197697 . Total output tokens: 440334485
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 25.389134554658085,
    "estimated_duration": 3600.0868397872473,
    "input_throughput": 5077.674182181752,
    "output_throughput": 4443.495313281212,
    "total_throughput": 9521.169495462964,
    "itl": 99.23469979518522,
    "ttft": 2117156.2986214953,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 848,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.259910320155348,
    "arrivals": 746983,
    "finished_requests": 74039,
    "scheduler_time": 190.29094397333455
}
#Debug simulation 
Total elapsed time: 25.389301768969744. Arrivals time: 0.46108659310266376 Scheduler time: 24.755419244989753 Scheduler overhead time: 0.06297364877536893 Adapter cache time: 0.02138363104313612 Engine time: 0.061821890994906425 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-8/adapters_256_slots_64_rate_1.6-0.8-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-8/adapters_256_slots_64_rate_1.6-0.8-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 135, 17280, 17280, 135, 17280, 8640, 17280, 135, 8640, 135, 17280, 8640, 8640, 8640, 8640, 17280, 135, 135, 135, 8640, 17280, 135, 17280, 17280, 8640, 8640, 8640, 135, 17280, 135, 8640, 8640, 135, 8640, 135, 135, 8640, 8640, 17280, 8640, 135, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 135, 17280, 17280, 8640, 135, 135, 17280, 8640, 135, 8640, 8640, 17280, 8640, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 8640, 135, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 135, 17280, 17280, 135, 17280, 135, 8640, 17280, 17280, 17280, 8640, 135, 17280, 8640, 135, 135, 135, 135, 135, 17280, 8640, 135, 17280, 135, 17280, 135, 135, 8640, 8640, 17280, 8640, 17280, 135, 8640, 135, 17280, 17280, 135, 17280, 8640, 135, 17280, 135, 135, 17280, 17280, 8640, 17280, 17280, 135, 17280, 8640, 8640, 135, 8640, 17280, 17280, 135, 17280, 8640, 135, 8640, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 8640, 17280, 17280, 8640, 135, 17280, 135, 8640, 8640, 135, 8640, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 8640, 17280, 8640, 135, 8640, 17280, 8640, 17280, 135, 17280, 135, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 135, 17280, 135, 17280, 8640, 8640, 135, 8640, 17280, 8640, 8640, 17280, 135, 17280, 17280, 8640, 135, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 135, 17280, 8640, 17280, 17280, 135, 17280, 8640, 8640, 17280, 135, 8640, 135, 135, 135, 135, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 135, 135, 135, 135]
Prompts retrieved: 2231955 . Total input tokens: 497594670 . Total output tokens: 438105315
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 47.831567571964115,
    "estimated_duration": 3600.0738805211404,
    "input_throughput": 5624.744011383655,
    "output_throughput": 4876.617975811818,
    "total_throughput": 10501.361987195472,
    "itl": 118.72057646823258,
    "ttft": 2064557.8726537437,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 607,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.013732282393674,
    "arrivals": 743226,
    "finished_requests": 81947,
    "scheduler_time": 175.61224531752734
}
#Debug simulation 
Total elapsed time: 47.831744926050305. Arrivals time: 0.3939716164022684 Scheduler time: 47.273963924497366 Scheduler overhead time: 0.0619954988360405 Adapter cache time: 0.017512275837361813 Engine time: 0.060245136730372906 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-16/adapters_256_slots_64_rate_1.6-0.8-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-16/adapters_256_slots_64_rate_1.6-0.8-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 135, 17280, 17280, 135, 17280, 8640, 17280, 135, 8640, 135, 17280, 8640, 8640, 8640, 8640, 17280, 135, 135, 135, 8640, 17280, 135, 17280, 17280, 8640, 8640, 8640, 135, 17280, 135, 8640, 8640, 135, 8640, 135, 135, 8640, 8640, 17280, 8640, 135, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 135, 17280, 17280, 8640, 135, 135, 17280, 8640, 135, 8640, 8640, 17280, 8640, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 8640, 135, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 135, 17280, 17280, 135, 17280, 135, 8640, 17280, 17280, 17280, 8640, 135, 17280, 8640, 135, 135, 135, 135, 135, 17280, 8640, 135, 17280, 135, 17280, 135, 135, 8640, 8640, 17280, 8640, 17280, 135, 8640, 135, 17280, 17280, 135, 17280, 8640, 135, 17280, 135, 135, 17280, 17280, 8640, 17280, 17280, 135, 17280, 8640, 8640, 135, 8640, 17280, 17280, 135, 17280, 8640, 135, 8640, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 8640, 17280, 17280, 8640, 135, 17280, 135, 8640, 8640, 135, 8640, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 8640, 17280, 8640, 135, 8640, 17280, 8640, 17280, 135, 17280, 135, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 135, 17280, 135, 17280, 8640, 8640, 135, 8640, 17280, 8640, 8640, 17280, 135, 17280, 17280, 8640, 135, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 135, 17280, 8640, 17280, 17280, 135, 17280, 8640, 8640, 17280, 135, 8640, 135, 135, 135, 135, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 135, 135, 135, 135]
Prompts retrieved: 2231955 . Total input tokens: 497594670 . Total output tokens: 438105315
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 38.28797140298411,
    "estimated_duration": 3600.0922075180015,
    "input_throughput": 5468.165220571386,
    "output_throughput": 4743.232399531426,
    "total_throughput": 10211.397620102813,
    "itl": 111.11595348172072,
    "ttft": 2082023.6750731186,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 586,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.275442745899786,
    "arrivals": 743226,
    "finished_requests": 79786,
    "scheduler_time": 180.75594390493495
}
#Debug simulation 
Total elapsed time: 38.288174752146006. Arrivals time: 0.418465759139508 Scheduler time: 37.70370958093554 Scheduler overhead time: 0.06206753710284829 Adapter cache time: 0.017386180348694324 Engine time: 0.06153066409751773 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-32/adapters_256_slots_64_rate_1.6-0.8-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-32/adapters_256_slots_64_rate_1.6-0.8-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 135, 17280, 17280, 135, 17280, 8640, 17280, 135, 8640, 135, 17280, 8640, 8640, 8640, 8640, 17280, 135, 135, 135, 8640, 17280, 135, 17280, 17280, 8640, 8640, 8640, 135, 17280, 135, 8640, 8640, 135, 8640, 135, 135, 8640, 8640, 17280, 8640, 135, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 135, 17280, 17280, 8640, 135, 135, 17280, 8640, 135, 8640, 8640, 17280, 8640, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 8640, 135, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 135, 17280, 17280, 135, 17280, 135, 8640, 17280, 17280, 17280, 8640, 135, 17280, 8640, 135, 135, 135, 135, 135, 17280, 8640, 135, 17280, 135, 17280, 135, 135, 8640, 8640, 17280, 8640, 17280, 135, 8640, 135, 17280, 17280, 135, 17280, 8640, 135, 17280, 135, 135, 17280, 17280, 8640, 17280, 17280, 135, 17280, 8640, 8640, 135, 8640, 17280, 17280, 135, 17280, 8640, 135, 8640, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 8640, 17280, 17280, 8640, 135, 17280, 135, 8640, 8640, 135, 8640, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 8640, 17280, 8640, 135, 8640, 17280, 8640, 17280, 135, 17280, 135, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 135, 17280, 135, 17280, 8640, 8640, 135, 8640, 17280, 8640, 8640, 17280, 135, 17280, 17280, 8640, 135, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 135, 17280, 8640, 17280, 17280, 135, 17280, 8640, 8640, 17280, 135, 8640, 135, 135, 135, 135, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 135, 135, 135, 135]
Prompts retrieved: 2231955 . Total input tokens: 497594670 . Total output tokens: 438105315
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 22.31972974492237,
    "estimated_duration": 3600.0682790612564,
    "input_throughput": 5147.168210051803,
    "output_throughput": 4471.599356498229,
    "total_throughput": 9618.767566550032,
    "itl": 98.86226147052075,
    "ttft": 2114152.766544933,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 948,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.126387575911378,
    "arrivals": 743226,
    "finished_requests": 75077,
    "scheduler_time": 190.70818631133776
}
#Debug simulation 
Total elapsed time: 22.31987203564495. Arrivals time: 0.34988232608884573 Scheduler time: 21.799315330106765 Scheduler overhead time: 0.06179768033325672 Adapter cache time: 0.021369113121181726 Engine time: 0.061151472851634026 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_8-16-16/adapters_256_slots_64_rate_1.6-0.8-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_8-16-16/adapters_256_slots_64_rate_1.6-0.8-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 135, 17280, 17280, 135, 17280, 8640, 17280, 135, 8640, 135, 17280, 8640, 8640, 8640, 8640, 17280, 135, 135, 135, 8640, 17280, 135, 17280, 17280, 8640, 8640, 8640, 135, 17280, 135, 8640, 8640, 135, 8640, 135, 135, 8640, 8640, 17280, 8640, 135, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 135, 17280, 17280, 8640, 135, 135, 17280, 8640, 135, 8640, 8640, 17280, 8640, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 8640, 135, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 135, 17280, 17280, 135, 17280, 135, 8640, 17280, 17280, 17280, 8640, 135, 17280, 8640, 135, 135, 135, 135, 135, 17280, 8640, 135, 17280, 135, 17280, 135, 135, 8640, 8640, 17280, 8640, 17280, 135, 8640, 135, 17280, 17280, 135, 17280, 8640, 135, 17280, 135, 135, 17280, 17280, 8640, 17280, 17280, 135, 17280, 8640, 8640, 135, 8640, 17280, 17280, 135, 17280, 8640, 135, 8640, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 8640, 17280, 17280, 8640, 135, 17280, 135, 8640, 8640, 135, 8640, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 8640, 17280, 8640, 135, 8640, 17280, 8640, 17280, 135, 17280, 135, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 135, 17280, 135, 17280, 8640, 8640, 135, 8640, 17280, 8640, 8640, 17280, 135, 17280, 17280, 8640, 135, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 135, 17280, 8640, 17280, 17280, 135, 17280, 8640, 8640, 17280, 135, 8640, 135, 135, 135, 135, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 135, 135, 135, 135]
Prompts retrieved: 2231955 . Total input tokens: 497594670 . Total output tokens: 438105315
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 35.81746423104778,
    "estimated_duration": 3600.097794124089,
    "input_throughput": 5473.5901986224735,
    "output_throughput": 4745.849689940698,
    "total_throughput": 10219.43988856317,
    "itl": 110.89514112212808,
    "ttft": 2083635.5197353833,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 688,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.7072637680545375,
    "arrivals": 743226,
    "finished_requests": 79771,
    "scheduler_time": 181.08690716008658
}
#Debug simulation 
Total elapsed time: 35.817594347987324. Arrivals time: 0.4155950821004808 Scheduler time: 35.23667131643742 Scheduler overhead time: 0.06144908536225557 Adapter cache time: 0.018483910243958235 Engine time: 0.06054740259423852 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_8-16-32/adapters_256_slots_64_rate_1.6-0.8-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_8-16-32/adapters_256_slots_64_rate_1.6-0.8-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 135, 17280, 17280, 135, 17280, 8640, 17280, 135, 8640, 135, 17280, 8640, 8640, 8640, 8640, 17280, 135, 135, 135, 8640, 17280, 135, 17280, 17280, 8640, 8640, 8640, 135, 17280, 135, 8640, 8640, 135, 8640, 135, 135, 8640, 8640, 17280, 8640, 135, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 135, 17280, 17280, 8640, 135, 135, 17280, 8640, 135, 8640, 8640, 17280, 8640, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 8640, 135, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 135, 17280, 17280, 135, 17280, 135, 8640, 17280, 17280, 17280, 8640, 135, 17280, 8640, 135, 135, 135, 135, 135, 17280, 8640, 135, 17280, 135, 17280, 135, 135, 8640, 8640, 17280, 8640, 17280, 135, 8640, 135, 17280, 17280, 135, 17280, 8640, 135, 17280, 135, 135, 17280, 17280, 8640, 17280, 17280, 135, 17280, 8640, 8640, 135, 8640, 17280, 17280, 135, 17280, 8640, 135, 8640, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 8640, 17280, 17280, 8640, 135, 17280, 135, 8640, 8640, 135, 8640, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 8640, 17280, 8640, 135, 8640, 17280, 8640, 17280, 135, 17280, 135, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 135, 17280, 135, 17280, 8640, 8640, 135, 8640, 17280, 8640, 8640, 17280, 135, 17280, 17280, 8640, 135, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 135, 17280, 8640, 17280, 17280, 135, 17280, 8640, 8640, 17280, 135, 8640, 135, 135, 135, 135, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 135, 135, 135, 135]
Prompts retrieved: 2231955 . Total input tokens: 497594670 . Total output tokens: 438105315
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 21.54657764500007,
    "estimated_duration": 3600.020351563186,
    "input_throughput": 5157.118345716703,
    "output_throughput": 4467.641132366445,
    "total_throughput": 9624.759478083148,
    "itl": 98.92864608486181,
    "ttft": 2113131.0513348714,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 955,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.119179868111408,
    "arrivals": 743226,
    "finished_requests": 75134,
    "scheduler_time": 190.54002892604453
}
#Debug simulation 
Total elapsed time: 21.546685084700584. Arrivals time: 0.3466135887429118 Scheduler time: 21.030146865639836 Scheduler overhead time: 0.060754495207220316 Adapter cache time: 0.021573476493358612 Engine time: 0.06148673454299569 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_16-16-16/adapters_256_slots_64_rate_1.6-0.8-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_16-16-16/adapters_256_slots_64_rate_1.6-0.8-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 135, 17280, 17280, 135, 17280, 8640, 17280, 135, 8640, 135, 17280, 8640, 8640, 8640, 8640, 17280, 135, 135, 135, 8640, 17280, 135, 17280, 17280, 8640, 8640, 8640, 135, 17280, 135, 8640, 8640, 135, 8640, 135, 135, 8640, 8640, 17280, 8640, 135, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 135, 17280, 17280, 8640, 135, 135, 17280, 8640, 135, 8640, 8640, 17280, 8640, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 8640, 135, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 135, 17280, 17280, 135, 17280, 135, 8640, 17280, 17280, 17280, 8640, 135, 17280, 8640, 135, 135, 135, 135, 135, 17280, 8640, 135, 17280, 135, 17280, 135, 135, 8640, 8640, 17280, 8640, 17280, 135, 8640, 135, 17280, 17280, 135, 17280, 8640, 135, 17280, 135, 135, 17280, 17280, 8640, 17280, 17280, 135, 17280, 8640, 8640, 135, 8640, 17280, 17280, 135, 17280, 8640, 135, 8640, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 8640, 17280, 17280, 8640, 135, 17280, 135, 8640, 8640, 135, 8640, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 8640, 17280, 8640, 135, 8640, 17280, 8640, 17280, 135, 17280, 135, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 135, 17280, 135, 17280, 8640, 8640, 135, 8640, 17280, 8640, 8640, 17280, 135, 17280, 17280, 8640, 135, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 135, 17280, 8640, 17280, 17280, 135, 17280, 8640, 8640, 17280, 135, 8640, 135, 135, 135, 135, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 135, 135, 135, 135]
Prompts retrieved: 2231955 . Total input tokens: 497594670 . Total output tokens: 438105315
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 36.426885318011045,
    "estimated_duration": 3600.10770264385,
    "input_throughput": 5470.874936751427,
    "output_throughput": 4748.3871072651455,
    "total_throughput": 10219.262044016572,
    "itl": 110.86054229782087,
    "ttft": 2082451.4222292479,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 678,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.328298397706801,
    "arrivals": 743226,
    "finished_requests": 79788,
    "scheduler_time": 181.14958987572237
}
#Debug simulation 
Total elapsed time: 36.427041351329535. Arrivals time: 0.4053901731967926 Scheduler time: 35.85575461667031 Scheduler overhead time: 0.06159998523071408 Adapter cache time: 0.018620419315993786 Engine time: 0.060718066059052944 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_16-16-32/adapters_256_slots_64_rate_1.6-0.8-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.0125_size_16-16-32/adapters_256_slots_64_rate_1.6-0.8-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 135, 17280, 17280, 135, 17280, 8640, 17280, 135, 8640, 135, 17280, 8640, 8640, 8640, 8640, 17280, 135, 135, 135, 8640, 17280, 135, 17280, 17280, 8640, 8640, 8640, 135, 17280, 135, 8640, 8640, 135, 8640, 135, 135, 8640, 8640, 17280, 8640, 135, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 135, 17280, 17280, 8640, 135, 135, 17280, 8640, 135, 8640, 8640, 17280, 8640, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 8640, 135, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 135, 17280, 17280, 135, 17280, 135, 8640, 17280, 17280, 17280, 8640, 135, 17280, 8640, 135, 135, 135, 135, 135, 17280, 8640, 135, 17280, 135, 17280, 135, 135, 8640, 8640, 17280, 8640, 17280, 135, 8640, 135, 17280, 17280, 135, 17280, 8640, 135, 17280, 135, 135, 17280, 17280, 8640, 17280, 17280, 135, 17280, 8640, 8640, 135, 8640, 17280, 17280, 135, 17280, 8640, 135, 8640, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 8640, 17280, 17280, 8640, 135, 17280, 135, 8640, 8640, 135, 8640, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 8640, 17280, 8640, 135, 8640, 17280, 8640, 17280, 135, 17280, 135, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 135, 17280, 135, 17280, 8640, 8640, 135, 8640, 17280, 8640, 8640, 17280, 135, 17280, 17280, 8640, 135, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 135, 17280, 8640, 17280, 17280, 135, 17280, 8640, 8640, 17280, 135, 8640, 135, 135, 135, 135, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 135, 135, 135, 135]
Prompts retrieved: 2231955 . Total input tokens: 497594670 . Total output tokens: 438105315
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 19.23680975381285,
    "estimated_duration": 3600.0600344643262,
    "input_throughput": 5138.573752354827,
    "output_throughput": 4457.277058266515,
    "total_throughput": 9595.850810621341,
    "itl": 99.19355409928771,
    "ttft": 2114428.549341506,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1055,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.786669386122393,
    "arrivals": 743226,
    "finished_requests": 74934,
    "scheduler_time": 190.07478986091692
}
#Debug simulation 
Total elapsed time: 19.23692087084055. Arrivals time: 0.3364869519136846 Scheduler time: 18.73175832349807 Scheduler overhead time: 0.06051900936290622 Adapter cache time: 0.022383200004696846 Engine time: 0.05988134257495403 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-8/adapters_256_slots_64_rate_1.6-0.8-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-8/adapters_256_slots_64_rate_1.6-0.8-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 66, 17280, 17280, 66, 17280, 8640, 17280, 66, 8640, 66, 17280, 8640, 8640, 8640, 8640, 17280, 66, 66, 66, 8640, 17280, 66, 17280, 17280, 8640, 8640, 8640, 66, 17280, 66, 8640, 8640, 66, 8640, 66, 66, 8640, 8640, 17280, 8640, 66, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 66, 17280, 17280, 8640, 66, 66, 17280, 8640, 66, 8640, 8640, 17280, 8640, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 8640, 66, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 66, 17280, 17280, 66, 17280, 66, 8640, 17280, 17280, 17280, 8640, 66, 17280, 8640, 66, 66, 66, 66, 66, 17280, 8640, 66, 17280, 66, 17280, 66, 66, 8640, 8640, 17280, 8640, 17280, 66, 8640, 66, 17280, 17280, 66, 17280, 8640, 66, 17280, 66, 66, 17280, 17280, 8640, 17280, 17280, 66, 17280, 8640, 8640, 66, 8640, 17280, 17280, 66, 17280, 8640, 66, 8640, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 8640, 17280, 17280, 8640, 66, 17280, 66, 8640, 8640, 66, 8640, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 8640, 17280, 8640, 66, 8640, 17280, 8640, 17280, 66, 17280, 66, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 66, 17280, 66, 17280, 8640, 8640, 66, 8640, 17280, 8640, 8640, 17280, 66, 17280, 17280, 8640, 66, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 66, 17280, 8640, 17280, 17280, 66, 17280, 8640, 8640, 17280, 66, 8640, 66, 66, 66, 66, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 66, 66, 66, 66]
Prompts retrieved: 2226090 . Total input tokens: 496272302 . Total output tokens: 436960987
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 41.41756935091689,
    "estimated_duration": 3600.0548350991508,
    "input_throughput": 5603.407149059278,
    "output_throughput": 4883.94033017993,
    "total_throughput": 10487.347479239208,
    "itl": 118.47700033458442,
    "ttft": 2063014.8234784561,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 496,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.2797548798472076,
    "arrivals": 741292,
    "finished_requests": 81461,
    "scheduler_time": 176.17942360048264
}
#Debug simulation 
Total elapsed time: 41.4177356781438. Arrivals time: 0.38682470144703984 Scheduler time: 40.872551748063415 Scheduler overhead time: 0.0597064564935863 Adapter cache time: 0.01610512239858508 Engine time: 0.058906310237944126 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-16/adapters_256_slots_64_rate_1.6-0.8-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-16/adapters_256_slots_64_rate_1.6-0.8-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 66, 17280, 17280, 66, 17280, 8640, 17280, 66, 8640, 66, 17280, 8640, 8640, 8640, 8640, 17280, 66, 66, 66, 8640, 17280, 66, 17280, 17280, 8640, 8640, 8640, 66, 17280, 66, 8640, 8640, 66, 8640, 66, 66, 8640, 8640, 17280, 8640, 66, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 66, 17280, 17280, 8640, 66, 66, 17280, 8640, 66, 8640, 8640, 17280, 8640, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 8640, 66, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 66, 17280, 17280, 66, 17280, 66, 8640, 17280, 17280, 17280, 8640, 66, 17280, 8640, 66, 66, 66, 66, 66, 17280, 8640, 66, 17280, 66, 17280, 66, 66, 8640, 8640, 17280, 8640, 17280, 66, 8640, 66, 17280, 17280, 66, 17280, 8640, 66, 17280, 66, 66, 17280, 17280, 8640, 17280, 17280, 66, 17280, 8640, 8640, 66, 8640, 17280, 17280, 66, 17280, 8640, 66, 8640, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 8640, 17280, 17280, 8640, 66, 17280, 66, 8640, 8640, 66, 8640, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 8640, 17280, 8640, 66, 8640, 17280, 8640, 17280, 66, 17280, 66, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 66, 17280, 66, 17280, 8640, 8640, 66, 8640, 17280, 8640, 8640, 17280, 66, 17280, 17280, 8640, 66, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 66, 17280, 8640, 17280, 17280, 66, 17280, 8640, 8640, 17280, 66, 8640, 66, 66, 66, 66, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 66, 66, 66, 66]
Prompts retrieved: 2226090 . Total input tokens: 496272302 . Total output tokens: 436960987
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 35.45922602340579,
    "estimated_duration": 3600.028543560872,
    "input_throughput": 5446.124318949718,
    "output_throughput": 4748.330407150551,
    "total_throughput": 10194.454726100268,
    "itl": 110.67968393915983,
    "ttft": 2082455.0835831333,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 647,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.717614320260478,
    "arrivals": 741292,
    "finished_requests": 79205,
    "scheduler_time": 181.65943459101052
}
#Debug simulation 
Total elapsed time: 35.45936454134062. Arrivals time: 0.3784772092476487 Scheduler time: 34.9184466204606 Scheduler overhead time: 0.06014725798740983 Adapter cache time: 0.01771452883258462 Engine time: 0.05991520592942834 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-32/adapters_256_slots_64_rate_1.6-0.8-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-32/adapters_256_slots_64_rate_1.6-0.8-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 66, 17280, 17280, 66, 17280, 8640, 17280, 66, 8640, 66, 17280, 8640, 8640, 8640, 8640, 17280, 66, 66, 66, 8640, 17280, 66, 17280, 17280, 8640, 8640, 8640, 66, 17280, 66, 8640, 8640, 66, 8640, 66, 66, 8640, 8640, 17280, 8640, 66, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 66, 17280, 17280, 8640, 66, 66, 17280, 8640, 66, 8640, 8640, 17280, 8640, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 8640, 66, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 66, 17280, 17280, 66, 17280, 66, 8640, 17280, 17280, 17280, 8640, 66, 17280, 8640, 66, 66, 66, 66, 66, 17280, 8640, 66, 17280, 66, 17280, 66, 66, 8640, 8640, 17280, 8640, 17280, 66, 8640, 66, 17280, 17280, 66, 17280, 8640, 66, 17280, 66, 66, 17280, 17280, 8640, 17280, 17280, 66, 17280, 8640, 8640, 66, 8640, 17280, 17280, 66, 17280, 8640, 66, 8640, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 8640, 17280, 17280, 8640, 66, 17280, 66, 8640, 8640, 66, 8640, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 8640, 17280, 8640, 66, 8640, 17280, 8640, 17280, 66, 17280, 66, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 66, 17280, 66, 17280, 8640, 8640, 66, 8640, 17280, 8640, 8640, 17280, 66, 17280, 17280, 8640, 66, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 66, 17280, 8640, 17280, 17280, 66, 17280, 8640, 8640, 17280, 66, 8640, 66, 66, 66, 66, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 66, 66, 66, 66]
Prompts retrieved: 2226090 . Total input tokens: 496272302 . Total output tokens: 436960987
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 17.347428603097796,
    "estimated_duration": 3600.0701921268787,
    "input_throughput": 5103.019668943315,
    "output_throughput": 4447.367730499996,
    "total_throughput": 9550.38739944331,
    "itl": 98.61522296281234,
    "ttft": 2115115.4808897325,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1032,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.750095934672297,
    "arrivals": 741292,
    "finished_requests": 74131,
    "scheduler_time": 190.9745065330128
}
#Debug simulation 
Total elapsed time: 17.34755116002634. Arrivals time: 0.31530972849577665 Scheduler time: 16.86649454664439 Scheduler overhead time: 0.05907394364476204 Adapter cache time: 0.021884115878492594 Engine time: 0.05904686311259866 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_8-16-16/adapters_256_slots_64_rate_1.6-0.8-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_8-16-16/adapters_256_slots_64_rate_1.6-0.8-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 66, 17280, 17280, 66, 17280, 8640, 17280, 66, 8640, 66, 17280, 8640, 8640, 8640, 8640, 17280, 66, 66, 66, 8640, 17280, 66, 17280, 17280, 8640, 8640, 8640, 66, 17280, 66, 8640, 8640, 66, 8640, 66, 66, 8640, 8640, 17280, 8640, 66, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 66, 17280, 17280, 8640, 66, 66, 17280, 8640, 66, 8640, 8640, 17280, 8640, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 8640, 66, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 66, 17280, 17280, 66, 17280, 66, 8640, 17280, 17280, 17280, 8640, 66, 17280, 8640, 66, 66, 66, 66, 66, 17280, 8640, 66, 17280, 66, 17280, 66, 66, 8640, 8640, 17280, 8640, 17280, 66, 8640, 66, 17280, 17280, 66, 17280, 8640, 66, 17280, 66, 66, 17280, 17280, 8640, 17280, 17280, 66, 17280, 8640, 8640, 66, 8640, 17280, 17280, 66, 17280, 8640, 66, 8640, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 8640, 17280, 17280, 8640, 66, 17280, 66, 8640, 8640, 66, 8640, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 8640, 17280, 8640, 66, 8640, 17280, 8640, 17280, 66, 17280, 66, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 66, 17280, 66, 17280, 8640, 8640, 66, 8640, 17280, 8640, 8640, 17280, 66, 17280, 17280, 8640, 66, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 66, 17280, 8640, 17280, 17280, 66, 17280, 8640, 8640, 17280, 66, 8640, 66, 66, 66, 66, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 66, 66, 66, 66]
Prompts retrieved: 2226090 . Total input tokens: 496272302 . Total output tokens: 436960987
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 32.66159030981362,
    "estimated_duration": 3600.0521219954953,
    "input_throughput": 5452.438002236391,
    "output_throughput": 4755.864198574352,
    "total_throughput": 10208.302200810744,
    "itl": 110.37937473774687,
    "ttft": 2080411.8447418995,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 603,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.136866068639787,
    "arrivals": 741292,
    "finished_requests": 79250,
    "scheduler_time": 182.01287577924236
}
#Debug simulation 
Total elapsed time: 32.66170198190957. Arrivals time: 0.3733859108760953 Scheduler time: 32.12536893039942 Scheduler overhead time: 0.06049381196498871 Adapter cache time: 0.017712685279548168 Engine time: 0.06010221689939499 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_8-16-32/adapters_256_slots_64_rate_1.6-0.8-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_8-16-32/adapters_256_slots_64_rate_1.6-0.8-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 66, 17280, 17280, 66, 17280, 8640, 17280, 66, 8640, 66, 17280, 8640, 8640, 8640, 8640, 17280, 66, 66, 66, 8640, 17280, 66, 17280, 17280, 8640, 8640, 8640, 66, 17280, 66, 8640, 8640, 66, 8640, 66, 66, 8640, 8640, 17280, 8640, 66, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 66, 17280, 17280, 8640, 66, 66, 17280, 8640, 66, 8640, 8640, 17280, 8640, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 8640, 66, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 66, 17280, 17280, 66, 17280, 66, 8640, 17280, 17280, 17280, 8640, 66, 17280, 8640, 66, 66, 66, 66, 66, 17280, 8640, 66, 17280, 66, 17280, 66, 66, 8640, 8640, 17280, 8640, 17280, 66, 8640, 66, 17280, 17280, 66, 17280, 8640, 66, 17280, 66, 66, 17280, 17280, 8640, 17280, 17280, 66, 17280, 8640, 8640, 66, 8640, 17280, 17280, 66, 17280, 8640, 66, 8640, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 8640, 17280, 17280, 8640, 66, 17280, 66, 8640, 8640, 66, 8640, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 8640, 17280, 8640, 66, 8640, 17280, 8640, 17280, 66, 17280, 66, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 66, 17280, 66, 17280, 8640, 8640, 66, 8640, 17280, 8640, 8640, 17280, 66, 17280, 17280, 8640, 66, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 66, 17280, 8640, 17280, 17280, 66, 17280, 8640, 8640, 17280, 66, 8640, 66, 66, 66, 66, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 66, 66, 66, 66]
Prompts retrieved: 2226090 . Total input tokens: 496272302 . Total output tokens: 436960987
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 17.92356252623722,
    "estimated_duration": 3600.063828495671,
    "input_throughput": 5109.6285722485545,
    "output_throughput": 4454.9957345344565,
    "total_throughput": 9564.624306783011,
    "itl": 98.94207503992651,
    "ttft": 2111350.450472219,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 945,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.03727981052829,
    "arrivals": 741292,
    "finished_requests": 74313,
    "scheduler_time": 190.68198717908408
}
#Debug simulation 
Total elapsed time: 17.923655522987247. Arrivals time: 0.3173691243864596 Scheduler time: 17.4401571219787 Scheduler overhead time: 0.059582156129181385 Adapter cache time: 0.02126101916655898 Engine time: 0.05928593408316374 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_16-16-16/adapters_256_slots_64_rate_1.6-0.8-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_16-16-16/adapters_256_slots_64_rate_1.6-0.8-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 66, 17280, 17280, 66, 17280, 8640, 17280, 66, 8640, 66, 17280, 8640, 8640, 8640, 8640, 17280, 66, 66, 66, 8640, 17280, 66, 17280, 17280, 8640, 8640, 8640, 66, 17280, 66, 8640, 8640, 66, 8640, 66, 66, 8640, 8640, 17280, 8640, 66, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 66, 17280, 17280, 8640, 66, 66, 17280, 8640, 66, 8640, 8640, 17280, 8640, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 8640, 66, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 66, 17280, 17280, 66, 17280, 66, 8640, 17280, 17280, 17280, 8640, 66, 17280, 8640, 66, 66, 66, 66, 66, 17280, 8640, 66, 17280, 66, 17280, 66, 66, 8640, 8640, 17280, 8640, 17280, 66, 8640, 66, 17280, 17280, 66, 17280, 8640, 66, 17280, 66, 66, 17280, 17280, 8640, 17280, 17280, 66, 17280, 8640, 8640, 66, 8640, 17280, 17280, 66, 17280, 8640, 66, 8640, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 8640, 17280, 17280, 8640, 66, 17280, 66, 8640, 8640, 66, 8640, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 8640, 17280, 8640, 66, 8640, 17280, 8640, 17280, 66, 17280, 66, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 66, 17280, 66, 17280, 8640, 8640, 66, 8640, 17280, 8640, 8640, 17280, 66, 17280, 17280, 8640, 66, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 66, 17280, 8640, 17280, 17280, 66, 17280, 8640, 8640, 17280, 66, 8640, 66, 66, 66, 66, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 66, 66, 66, 66]
Prompts retrieved: 2226090 . Total input tokens: 496272302 . Total output tokens: 436960987
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 33.49151687696576,
    "estimated_duration": 3600.0313937994397,
    "input_throughput": 5463.709020393005,
    "output_throughput": 4752.813275314795,
    "total_throughput": 10216.522295707799,
    "itl": 110.67735077757521,
    "ttft": 2080910.1210580475,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 652,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.162316453251968,
    "arrivals": 741292,
    "finished_requests": 79331,
    "scheduler_time": 181.72326962867757
}
#Debug simulation 
Total elapsed time: 33.491664096713066. Arrivals time: 0.37468544486910105 Scheduler time: 32.95371610065922 Scheduler overhead time: 0.06023164000362158 Adapter cache time: 0.017953738570213318 Engine time: 0.06023886101320386 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_16-16-32/adapters_256_slots_64_rate_1.6-0.8-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.00625_size_16-16-32/adapters_256_slots_64_rate_1.6-0.8-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 66, 17280, 17280, 66, 17280, 8640, 17280, 66, 8640, 66, 17280, 8640, 8640, 8640, 8640, 17280, 66, 66, 66, 8640, 17280, 66, 17280, 17280, 8640, 8640, 8640, 66, 17280, 66, 8640, 8640, 66, 8640, 66, 66, 8640, 8640, 17280, 8640, 66, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 66, 17280, 17280, 8640, 66, 66, 17280, 8640, 66, 8640, 8640, 17280, 8640, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 8640, 66, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 66, 17280, 17280, 66, 17280, 66, 8640, 17280, 17280, 17280, 8640, 66, 17280, 8640, 66, 66, 66, 66, 66, 17280, 8640, 66, 17280, 66, 17280, 66, 66, 8640, 8640, 17280, 8640, 17280, 66, 8640, 66, 17280, 17280, 66, 17280, 8640, 66, 17280, 66, 66, 17280, 17280, 8640, 17280, 17280, 66, 17280, 8640, 8640, 66, 8640, 17280, 17280, 66, 17280, 8640, 66, 8640, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 8640, 17280, 17280, 8640, 66, 17280, 66, 8640, 8640, 66, 8640, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 8640, 17280, 8640, 66, 8640, 17280, 8640, 17280, 66, 17280, 66, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 66, 17280, 66, 17280, 8640, 8640, 66, 8640, 17280, 8640, 8640, 17280, 66, 17280, 17280, 8640, 66, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 66, 17280, 8640, 17280, 17280, 66, 17280, 8640, 8640, 17280, 66, 8640, 66, 66, 66, 66, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 66, 66, 66, 66]
Prompts retrieved: 2226090 . Total input tokens: 496272302 . Total output tokens: 436960987
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 17.876892236992717,
    "estimated_duration": 3600.077639247818,
    "input_throughput": 5106.942361343449,
    "output_throughput": 4447.366863828312,
    "total_throughput": 9554.30922517176,
    "itl": 99.1190229691445,
    "ttft": 2114654.80435542,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 994,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.312669814974083,
    "arrivals": 741292,
    "finished_requests": 74232,
    "scheduler_time": 190.28312530324268
}
#Debug simulation 
Total elapsed time: 17.877041446976364. Arrivals time: 0.31860958179458976 Scheduler time: 17.392253145575523 Scheduler overhead time: 0.05900324834510684 Adapter cache time: 0.022063118405640125 Engine time: 0.05938277253881097 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-8/adapters_256_slots_64_rate_1.6-0.8-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-8/adapters_256_slots_64_rate_1.6-0.8-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 33, 17280, 17280, 33, 17280, 8640, 17280, 33, 8640, 33, 17280, 8640, 8640, 8640, 8640, 17280, 33, 33, 33, 8640, 17280, 33, 17280, 17280, 8640, 8640, 8640, 33, 17280, 33, 8640, 8640, 33, 8640, 33, 33, 8640, 8640, 17280, 8640, 33, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 33, 17280, 17280, 8640, 33, 33, 17280, 8640, 33, 8640, 8640, 17280, 8640, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 8640, 33, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 33, 17280, 17280, 33, 17280, 33, 8640, 17280, 17280, 17280, 8640, 33, 17280, 8640, 33, 33, 33, 33, 33, 17280, 8640, 33, 17280, 33, 17280, 33, 33, 8640, 8640, 17280, 8640, 17280, 33, 8640, 33, 17280, 17280, 33, 17280, 8640, 33, 17280, 33, 33, 17280, 17280, 8640, 17280, 17280, 33, 17280, 8640, 8640, 33, 8640, 17280, 17280, 33, 17280, 8640, 33, 8640, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 8640, 17280, 17280, 8640, 33, 17280, 33, 8640, 8640, 33, 8640, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 8640, 17280, 8640, 33, 8640, 17280, 8640, 17280, 33, 17280, 33, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 33, 17280, 33, 17280, 8640, 8640, 33, 8640, 17280, 8640, 8640, 17280, 33, 17280, 17280, 8640, 33, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 33, 17280, 8640, 17280, 17280, 33, 17280, 8640, 8640, 17280, 33, 8640, 33, 33, 33, 33, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 33, 33, 33, 33]
Prompts retrieved: 2223285 . Total input tokens: 495650329 . Total output tokens: 436414531
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 36.33356934413314,
    "estimated_duration": 3600.00892771656,
    "input_throughput": 5643.338504964827,
    "output_throughput": 4895.215360251324,
    "total_throughput": 10538.55386521615,
    "itl": 118.44431887501345,
    "ttft": 2061551.754245605,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 519,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.431840287582061,
    "arrivals": 740358,
    "finished_requests": 82113,
    "scheduler_time": 176.29594527160276
}
#Debug simulation 
Total elapsed time: 36.33368699019775. Arrivals time: 0.38584137009456754 Scheduler time: 35.79083755239844 Scheduler overhead time: 0.05916154105216265 Adapter cache time: 0.01575942523777485 Engine time: 0.05850252881646156 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-16/adapters_256_slots_64_rate_1.6-0.8-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-16/adapters_256_slots_64_rate_1.6-0.8-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 33, 17280, 17280, 33, 17280, 8640, 17280, 33, 8640, 33, 17280, 8640, 8640, 8640, 8640, 17280, 33, 33, 33, 8640, 17280, 33, 17280, 17280, 8640, 8640, 8640, 33, 17280, 33, 8640, 8640, 33, 8640, 33, 33, 8640, 8640, 17280, 8640, 33, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 33, 17280, 17280, 8640, 33, 33, 17280, 8640, 33, 8640, 8640, 17280, 8640, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 8640, 33, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 33, 17280, 17280, 33, 17280, 33, 8640, 17280, 17280, 17280, 8640, 33, 17280, 8640, 33, 33, 33, 33, 33, 17280, 8640, 33, 17280, 33, 17280, 33, 33, 8640, 8640, 17280, 8640, 17280, 33, 8640, 33, 17280, 17280, 33, 17280, 8640, 33, 17280, 33, 33, 17280, 17280, 8640, 17280, 17280, 33, 17280, 8640, 8640, 33, 8640, 17280, 17280, 33, 17280, 8640, 33, 8640, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 8640, 17280, 17280, 8640, 33, 17280, 33, 8640, 8640, 33, 8640, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 8640, 17280, 8640, 33, 8640, 17280, 8640, 17280, 33, 17280, 33, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 33, 17280, 33, 17280, 8640, 8640, 33, 8640, 17280, 8640, 8640, 17280, 33, 17280, 17280, 8640, 33, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 33, 17280, 8640, 17280, 17280, 33, 17280, 8640, 8640, 17280, 33, 8640, 33, 33, 33, 33, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 33, 33, 33, 33]
Prompts retrieved: 2223285 . Total input tokens: 495650329 . Total output tokens: 436414531
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 32.985698846168816,
    "estimated_duration": 3600.019605345054,
    "input_throughput": 5456.261396697948,
    "output_throughput": 4745.735821725467,
    "total_throughput": 10201.997218423414,
    "itl": 110.7170813871183,
    "ttft": 2076072.8894085386,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 534,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.903220448764046,
    "arrivals": 740358,
    "finished_requests": 79571,
    "scheduler_time": 181.45628422983216
}
#Debug simulation 
Total elapsed time: 32.98580255918205. Arrivals time: 0.37466059857979417 Scheduler time: 32.44909326406196 Scheduler overhead time: 0.0605447799898684 Adapter cache time: 0.01646054768934846 Engine time: 0.06008422980085015 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-32/adapters_256_slots_64_rate_1.6-0.8-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-32/adapters_256_slots_64_rate_1.6-0.8-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 33, 17280, 17280, 33, 17280, 8640, 17280, 33, 8640, 33, 17280, 8640, 8640, 8640, 8640, 17280, 33, 33, 33, 8640, 17280, 33, 17280, 17280, 8640, 8640, 8640, 33, 17280, 33, 8640, 8640, 33, 8640, 33, 33, 8640, 8640, 17280, 8640, 33, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 33, 17280, 17280, 8640, 33, 33, 17280, 8640, 33, 8640, 8640, 17280, 8640, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 8640, 33, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 33, 17280, 17280, 33, 17280, 33, 8640, 17280, 17280, 17280, 8640, 33, 17280, 8640, 33, 33, 33, 33, 33, 17280, 8640, 33, 17280, 33, 17280, 33, 33, 8640, 8640, 17280, 8640, 17280, 33, 8640, 33, 17280, 17280, 33, 17280, 8640, 33, 17280, 33, 33, 17280, 17280, 8640, 17280, 17280, 33, 17280, 8640, 8640, 33, 8640, 17280, 17280, 33, 17280, 8640, 33, 8640, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 8640, 17280, 17280, 8640, 33, 17280, 33, 8640, 8640, 33, 8640, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 8640, 17280, 8640, 33, 8640, 17280, 8640, 17280, 33, 17280, 33, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 33, 17280, 33, 17280, 8640, 8640, 33, 8640, 17280, 8640, 8640, 17280, 33, 17280, 17280, 8640, 33, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 33, 17280, 8640, 17280, 17280, 33, 17280, 8640, 8640, 17280, 33, 8640, 33, 33, 33, 33, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 33, 33, 33, 33]
Prompts retrieved: 2223285 . Total input tokens: 495650329 . Total output tokens: 436414531
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 17.630011716857553,
    "estimated_duration": 3600.098519558897,
    "input_throughput": 5113.572836961032,
    "output_throughput": 4446.0791595117735,
    "total_throughput": 9559.651996472805,
    "itl": 99.09167139347446,
    "ttft": 2112601.301586173,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1015,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.614511493714545,
    "arrivals": 740358,
    "finished_requests": 74571,
    "scheduler_time": 190.22022574756457
}
#Debug simulation 
Total elapsed time: 17.630121887195855. Arrivals time: 0.3855258016847074 Scheduler time: 17.077656837180257 Scheduler overhead time: 0.06010003574192524 Adapter cache time: 0.022124033886939287 Engine time: 0.058785447385162115 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_8-16-16/adapters_256_slots_64_rate_1.6-0.8-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_8-16-16/adapters_256_slots_64_rate_1.6-0.8-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 33, 17280, 17280, 33, 17280, 8640, 17280, 33, 8640, 33, 17280, 8640, 8640, 8640, 8640, 17280, 33, 33, 33, 8640, 17280, 33, 17280, 17280, 8640, 8640, 8640, 33, 17280, 33, 8640, 8640, 33, 8640, 33, 33, 8640, 8640, 17280, 8640, 33, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 33, 17280, 17280, 8640, 33, 33, 17280, 8640, 33, 8640, 8640, 17280, 8640, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 8640, 33, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 33, 17280, 17280, 33, 17280, 33, 8640, 17280, 17280, 17280, 8640, 33, 17280, 8640, 33, 33, 33, 33, 33, 17280, 8640, 33, 17280, 33, 17280, 33, 33, 8640, 8640, 17280, 8640, 17280, 33, 8640, 33, 17280, 17280, 33, 17280, 8640, 33, 17280, 33, 33, 17280, 17280, 8640, 17280, 17280, 33, 17280, 8640, 8640, 33, 8640, 17280, 17280, 33, 17280, 8640, 33, 8640, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 8640, 17280, 17280, 8640, 33, 17280, 33, 8640, 8640, 33, 8640, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 8640, 17280, 8640, 33, 8640, 17280, 8640, 17280, 33, 17280, 33, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 33, 17280, 33, 17280, 8640, 8640, 33, 8640, 17280, 8640, 8640, 17280, 33, 17280, 17280, 8640, 33, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 33, 17280, 8640, 17280, 17280, 33, 17280, 8640, 8640, 17280, 33, 8640, 33, 33, 33, 33, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 33, 33, 33, 33]
Prompts retrieved: 2223285 . Total input tokens: 495650329 . Total output tokens: 436414531
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 28.89236498111859,
    "estimated_duration": 3600.021620008155,
    "input_throughput": 5467.521331151176,
    "output_throughput": 4748.016763288571,
    "total_throughput": 10215.538094439748,
    "itl": 111.04047983077889,
    "ttft": 2078024.2513503425,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 653,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.48382653513457,
    "arrivals": 740358,
    "finished_requests": 79672,
    "scheduler_time": 181.19310410956373
}
#Debug simulation 
Total elapsed time: 28.892523477319628. Arrivals time: 0.4280419312417507 Scheduler time: 28.303146712016314 Scheduler overhead time: 0.059994506649672985 Adapter cache time: 0.01758749270811677 Engine time: 0.059209735598415136 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_8-16-32/adapters_256_slots_64_rate_1.6-0.8-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_8-16-32/adapters_256_slots_64_rate_1.6-0.8-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 33, 17280, 17280, 33, 17280, 8640, 17280, 33, 8640, 33, 17280, 8640, 8640, 8640, 8640, 17280, 33, 33, 33, 8640, 17280, 33, 17280, 17280, 8640, 8640, 8640, 33, 17280, 33, 8640, 8640, 33, 8640, 33, 33, 8640, 8640, 17280, 8640, 33, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 33, 17280, 17280, 8640, 33, 33, 17280, 8640, 33, 8640, 8640, 17280, 8640, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 8640, 33, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 33, 17280, 17280, 33, 17280, 33, 8640, 17280, 17280, 17280, 8640, 33, 17280, 8640, 33, 33, 33, 33, 33, 17280, 8640, 33, 17280, 33, 17280, 33, 33, 8640, 8640, 17280, 8640, 17280, 33, 8640, 33, 17280, 17280, 33, 17280, 8640, 33, 17280, 33, 33, 17280, 17280, 8640, 17280, 17280, 33, 17280, 8640, 8640, 33, 8640, 17280, 17280, 33, 17280, 8640, 33, 8640, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 8640, 17280, 17280, 8640, 33, 17280, 33, 8640, 8640, 33, 8640, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 8640, 17280, 8640, 33, 8640, 17280, 8640, 17280, 33, 17280, 33, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 33, 17280, 33, 17280, 8640, 8640, 33, 8640, 17280, 8640, 8640, 17280, 33, 17280, 17280, 8640, 33, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 33, 17280, 8640, 17280, 17280, 33, 17280, 8640, 8640, 17280, 33, 8640, 33, 33, 33, 33, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 33, 33, 33, 33]
Prompts retrieved: 2223285 . Total input tokens: 495650329 . Total output tokens: 436414531
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 18.81042484100908,
    "estimated_duration": 3600.038283492533,
    "input_throughput": 5117.1894711430805,
    "output_throughput": 4454.499573944117,
    "total_throughput": 9571.689045087198,
    "itl": 98.91254957325674,
    "ttft": 2110332.1485141427,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 900,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.68835542857649,
    "arrivals": 740358,
    "finished_requests": 74604,
    "scheduler_time": 190.59343479810508
}
#Debug simulation 
Total elapsed time: 18.810564429033548. Arrivals time: 0.3438972639851272 Scheduler time: 18.300032964907587 Scheduler overhead time: 0.05993862636387348 Adapter cache time: 0.020936613902449608 Engine time: 0.05991218984127045 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_16-16-16/adapters_256_slots_64_rate_1.6-0.8-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_16-16-16/adapters_256_slots_64_rate_1.6-0.8-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 33, 17280, 17280, 33, 17280, 8640, 17280, 33, 8640, 33, 17280, 8640, 8640, 8640, 8640, 17280, 33, 33, 33, 8640, 17280, 33, 17280, 17280, 8640, 8640, 8640, 33, 17280, 33, 8640, 8640, 33, 8640, 33, 33, 8640, 8640, 17280, 8640, 33, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 33, 17280, 17280, 8640, 33, 33, 17280, 8640, 33, 8640, 8640, 17280, 8640, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 8640, 33, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 33, 17280, 17280, 33, 17280, 33, 8640, 17280, 17280, 17280, 8640, 33, 17280, 8640, 33, 33, 33, 33, 33, 17280, 8640, 33, 17280, 33, 17280, 33, 33, 8640, 8640, 17280, 8640, 17280, 33, 8640, 33, 17280, 17280, 33, 17280, 8640, 33, 17280, 33, 33, 17280, 17280, 8640, 17280, 17280, 33, 17280, 8640, 8640, 33, 8640, 17280, 17280, 33, 17280, 8640, 33, 8640, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 8640, 17280, 17280, 8640, 33, 17280, 33, 8640, 8640, 33, 8640, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 8640, 17280, 8640, 33, 8640, 17280, 8640, 17280, 33, 17280, 33, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 33, 17280, 33, 17280, 8640, 8640, 33, 8640, 17280, 8640, 8640, 17280, 33, 17280, 17280, 8640, 33, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 33, 17280, 8640, 17280, 17280, 33, 17280, 8640, 8640, 17280, 33, 8640, 33, 33, 33, 33, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 33, 33, 33, 33]
Prompts retrieved: 2223285 . Total input tokens: 495650329 . Total output tokens: 436414531
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 37.939730184618384,
    "estimated_duration": 3600.0533049124087,
    "input_throughput": 5480.589127132397,
    "output_throughput": 4758.462597380013,
    "total_throughput": 10239.05172451241,
    "itl": 110.89497964129139,
    "ttft": 2071309.555694157,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 544,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.4728529916703543,
    "arrivals": 740358,
    "finished_requests": 79861,
    "scheduler_time": 181.46187557113532
}
#Debug simulation 
Total elapsed time: 37.93986294185743. Arrivals time: 0.36555264983326197 Scheduler time: 37.411308909766376 Scheduler overhead time: 0.06094631925225258 Adapter cache time: 0.01693747378885746 Engine time: 0.060010652989149094 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_16-16-32/adapters_256_slots_64_rate_1.6-0.8-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.8-0.003125_size_16-16-32/adapters_256_slots_64_rate_1.6-0.8-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 33, 17280, 17280, 33, 17280, 8640, 17280, 33, 8640, 33, 17280, 8640, 8640, 8640, 8640, 17280, 33, 33, 33, 8640, 17280, 33, 17280, 17280, 8640, 8640, 8640, 33, 17280, 33, 8640, 8640, 33, 8640, 33, 33, 8640, 8640, 17280, 8640, 33, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 33, 17280, 17280, 8640, 33, 33, 17280, 8640, 33, 8640, 8640, 17280, 8640, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 8640, 33, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 33, 17280, 17280, 33, 17280, 33, 8640, 17280, 17280, 17280, 8640, 33, 17280, 8640, 33, 33, 33, 33, 33, 17280, 8640, 33, 17280, 33, 17280, 33, 33, 8640, 8640, 17280, 8640, 17280, 33, 8640, 33, 17280, 17280, 33, 17280, 8640, 33, 17280, 33, 33, 17280, 17280, 8640, 17280, 17280, 33, 17280, 8640, 8640, 33, 8640, 17280, 17280, 33, 17280, 8640, 33, 8640, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 8640, 17280, 17280, 8640, 33, 17280, 33, 8640, 8640, 33, 8640, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 8640, 17280, 8640, 33, 8640, 17280, 8640, 17280, 33, 17280, 33, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 33, 17280, 33, 17280, 8640, 8640, 33, 8640, 17280, 8640, 8640, 17280, 33, 17280, 17280, 8640, 33, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 33, 17280, 8640, 17280, 17280, 33, 17280, 8640, 8640, 17280, 33, 8640, 33, 33, 33, 33, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 33, 33, 33, 33]
Prompts retrieved: 2223285 . Total input tokens: 495650329 . Total output tokens: 436414531
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 22.72906231833622,
    "estimated_duration": 3600.046441725042,
    "input_throughput": 5116.706769808632,
    "output_throughput": 4452.553393260993,
    "total_throughput": 9569.260163069626,
    "itl": 98.92768405926365,
    "ttft": 2109202.9502149234,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 707,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.204448308218299,
    "arrivals": 740358,
    "finished_requests": 74574,
    "scheduler_time": 190.57943334946964
}
#Debug simulation 
Total elapsed time: 22.729199282359332. Arrivals time: 0.3581882636062801 Scheduler time: 22.2024676091969 Scheduler overhead time: 0.062060633674263954 Adapter cache time: 0.018730923999100924 Engine time: 0.06129121407866478 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_8-8-8/adapters_256_slots_64_rate_1.6-0.4-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_8-8-8/adapters_256_slots_64_rate_1.6-0.4-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 1080, 17280, 17280, 1080, 17280, 4320, 17280, 1080, 4320, 1080, 17280, 4320, 4320, 4320, 4320, 17280, 1080, 1080, 1080, 4320, 17280, 1080, 17280, 17280, 4320, 4320, 4320, 1080, 17280, 1080, 4320, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 17280, 4320, 1080, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 1080, 17280, 17280, 4320, 1080, 1080, 17280, 4320, 1080, 4320, 4320, 17280, 4320, 1080, 1080, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 4320, 1080, 4320, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 17280, 17280, 1080, 17280, 1080, 4320, 17280, 17280, 17280, 4320, 1080, 17280, 4320, 1080, 1080, 1080, 1080, 1080, 17280, 4320, 1080, 17280, 1080, 17280, 1080, 1080, 4320, 4320, 17280, 4320, 17280, 1080, 4320, 1080, 17280, 17280, 1080, 17280, 4320, 1080, 17280, 1080, 1080, 17280, 17280, 4320, 17280, 17280, 1080, 17280, 4320, 4320, 1080, 4320, 17280, 17280, 1080, 17280, 4320, 1080, 4320, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 1080, 1080, 17280, 1080, 4320, 17280, 17280, 4320, 1080, 17280, 1080, 4320, 4320, 1080, 4320, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 17280, 4320, 17280, 4320, 1080, 4320, 17280, 4320, 17280, 1080, 17280, 1080, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 1080, 17280, 1080, 17280, 4320, 4320, 1080, 4320, 17280, 4320, 4320, 17280, 1080, 17280, 17280, 4320, 1080, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 1080, 17280, 4320, 17280, 17280, 1080, 17280, 4320, 4320, 17280, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 1080, 1080, 1080, 1080]
Prompts retrieved: 1945080 . Total input tokens: 433780535 . Total output tokens: 381721736
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 51.8157938439399,
    "estimated_duration": 3600.051313283174,
    "input_throughput": 5537.339961362925,
    "output_throughput": 4838.5493661517285,
    "total_throughput": 10375.889327514655,
    "itl": 118.95078604294464,
    "ttft": 2037233.3683521547,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 475,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.1408942901762544,
    "arrivals": 648144,
    "finished_requests": 81160,
    "scheduler_time": 174.73171190920553
}
#Debug simulation 
Total elapsed time: 51.81595756392926. Arrivals time: 0.39261093409731984 Scheduler time: 51.256813131738454 Scheduler overhead time: 0.06388019816949964 Adapter cache time: 0.01697458839043975 Engine time: 0.06121837627142668 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_8-8-16/adapters_256_slots_64_rate_1.6-0.4-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_8-8-16/adapters_256_slots_64_rate_1.6-0.4-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 1080, 17280, 17280, 1080, 17280, 4320, 17280, 1080, 4320, 1080, 17280, 4320, 4320, 4320, 4320, 17280, 1080, 1080, 1080, 4320, 17280, 1080, 17280, 17280, 4320, 4320, 4320, 1080, 17280, 1080, 4320, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 17280, 4320, 1080, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 1080, 17280, 17280, 4320, 1080, 1080, 17280, 4320, 1080, 4320, 4320, 17280, 4320, 1080, 1080, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 4320, 1080, 4320, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 17280, 17280, 1080, 17280, 1080, 4320, 17280, 17280, 17280, 4320, 1080, 17280, 4320, 1080, 1080, 1080, 1080, 1080, 17280, 4320, 1080, 17280, 1080, 17280, 1080, 1080, 4320, 4320, 17280, 4320, 17280, 1080, 4320, 1080, 17280, 17280, 1080, 17280, 4320, 1080, 17280, 1080, 1080, 17280, 17280, 4320, 17280, 17280, 1080, 17280, 4320, 4320, 1080, 4320, 17280, 17280, 1080, 17280, 4320, 1080, 4320, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 1080, 1080, 17280, 1080, 4320, 17280, 17280, 4320, 1080, 17280, 1080, 4320, 4320, 1080, 4320, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 17280, 4320, 17280, 4320, 1080, 4320, 17280, 4320, 17280, 1080, 17280, 1080, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 1080, 17280, 1080, 17280, 4320, 4320, 1080, 4320, 17280, 4320, 4320, 17280, 1080, 17280, 17280, 4320, 1080, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 1080, 17280, 4320, 17280, 17280, 1080, 17280, 4320, 4320, 17280, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 1080, 1080, 1080, 1080]
Prompts retrieved: 1945080 . Total input tokens: 433780535 . Total output tokens: 381721736
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 34.05442947195843,
    "estimated_duration": 3600.115016230428,
    "input_throughput": 5411.594327449959,
    "output_throughput": 4710.161181948929,
    "total_throughput": 10121.755509398889,
    "itl": 111.76440636946931,
    "ttft": 2061277.2985501233,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 806,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.879809172982357,
    "arrivals": 648144,
    "finished_requests": 79148,
    "scheduler_time": 179.40596577115645
}
#Debug simulation 
Total elapsed time: 34.05466975597665. Arrivals time: 0.36545713851228356 Scheduler time: 33.524324574973434 Scheduler overhead time: 0.059909203089773655 Adapter cache time: 0.021338333375751972 Engine time: 0.058918693102896214 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_8-8-32/adapters_256_slots_64_rate_1.6-0.4-0.1_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_8-8-32/adapters_256_slots_64_rate_1.6-0.4-0.1_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 1080, 17280, 17280, 1080, 17280, 4320, 17280, 1080, 4320, 1080, 17280, 4320, 4320, 4320, 4320, 17280, 1080, 1080, 1080, 4320, 17280, 1080, 17280, 17280, 4320, 4320, 4320, 1080, 17280, 1080, 4320, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 17280, 4320, 1080, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 1080, 17280, 17280, 4320, 1080, 1080, 17280, 4320, 1080, 4320, 4320, 17280, 4320, 1080, 1080, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 4320, 1080, 4320, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 17280, 17280, 1080, 17280, 1080, 4320, 17280, 17280, 17280, 4320, 1080, 17280, 4320, 1080, 1080, 1080, 1080, 1080, 17280, 4320, 1080, 17280, 1080, 17280, 1080, 1080, 4320, 4320, 17280, 4320, 17280, 1080, 4320, 1080, 17280, 17280, 1080, 17280, 4320, 1080, 17280, 1080, 1080, 17280, 17280, 4320, 17280, 17280, 1080, 17280, 4320, 4320, 1080, 4320, 17280, 17280, 1080, 17280, 4320, 1080, 4320, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 1080, 1080, 17280, 1080, 4320, 17280, 17280, 4320, 1080, 17280, 1080, 4320, 4320, 1080, 4320, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 17280, 4320, 17280, 4320, 1080, 4320, 17280, 4320, 17280, 1080, 17280, 1080, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 1080, 17280, 1080, 17280, 4320, 4320, 1080, 4320, 17280, 4320, 4320, 17280, 1080, 17280, 17280, 4320, 1080, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 1080, 17280, 4320, 17280, 17280, 1080, 17280, 4320, 4320, 17280, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 1080, 1080, 1080, 1080]
Prompts retrieved: 1945080 . Total input tokens: 433780535 . Total output tokens: 381721736
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 20.694235153030604,
    "estimated_duration": 3600.064583178526,
    "input_throughput": 5100.267391255706,
    "output_throughput": 4451.1920910740355,
    "total_throughput": 9551.459482329741,
    "itl": 99.48745654637781,
    "ttft": 2092946.7852202028,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1041,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.803983724694715,
    "arrivals": 648144,
    "finished_requests": 74705,
    "scheduler_time": 189.23802622993207
}
#Debug simulation 
Total elapsed time: 20.694326423108578. Arrivals time: 0.31796261854469776 Scheduler time: 20.206604308448732 Scheduler overhead time: 0.06074452959001064 Adapter cache time: 0.023281538859009743 Engine time: 0.059676419012248516 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_8-16-16/adapters_256_slots_64_rate_1.6-0.4-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_8-16-16/adapters_256_slots_64_rate_1.6-0.4-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 1080, 17280, 17280, 1080, 17280, 4320, 17280, 1080, 4320, 1080, 17280, 4320, 4320, 4320, 4320, 17280, 1080, 1080, 1080, 4320, 17280, 1080, 17280, 17280, 4320, 4320, 4320, 1080, 17280, 1080, 4320, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 17280, 4320, 1080, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 1080, 17280, 17280, 4320, 1080, 1080, 17280, 4320, 1080, 4320, 4320, 17280, 4320, 1080, 1080, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 4320, 1080, 4320, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 17280, 17280, 1080, 17280, 1080, 4320, 17280, 17280, 17280, 4320, 1080, 17280, 4320, 1080, 1080, 1080, 1080, 1080, 17280, 4320, 1080, 17280, 1080, 17280, 1080, 1080, 4320, 4320, 17280, 4320, 17280, 1080, 4320, 1080, 17280, 17280, 1080, 17280, 4320, 1080, 17280, 1080, 1080, 17280, 17280, 4320, 17280, 17280, 1080, 17280, 4320, 4320, 1080, 4320, 17280, 17280, 1080, 17280, 4320, 1080, 4320, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 1080, 1080, 17280, 1080, 4320, 17280, 17280, 4320, 1080, 17280, 1080, 4320, 4320, 1080, 4320, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 17280, 4320, 17280, 4320, 1080, 4320, 17280, 4320, 17280, 1080, 17280, 1080, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 1080, 17280, 1080, 17280, 4320, 4320, 1080, 4320, 17280, 4320, 4320, 17280, 1080, 17280, 17280, 4320, 1080, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 1080, 17280, 4320, 17280, 17280, 1080, 17280, 4320, 4320, 17280, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 1080, 1080, 1080, 1080]
Prompts retrieved: 1945080 . Total input tokens: 433780535 . Total output tokens: 381721736
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 31.91730198590085,
    "estimated_duration": 3600.090807597351,
    "input_throughput": 5396.539709220832,
    "output_throughput": 4708.793168279435,
    "total_throughput": 10105.332877500266,
    "itl": 111.66248604634443,
    "ttft": 2059563.4910429271,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 735,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.026743145887733,
    "arrivals": 648144,
    "finished_requests": 78999,
    "scheduler_time": 179.49936159854337
}
#Debug simulation 
Total elapsed time: 31.91747103491798. Arrivals time: 0.36307594599202275 Scheduler time: 31.392197412904352 Scheduler overhead time: 0.05937399948015809 Adapter cache time: 0.019793254788964987 Engine time: 0.05841931467875838 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_8-16-32/adapters_256_slots_64_rate_1.6-0.4-0.1_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_8-16-32/adapters_256_slots_64_rate_1.6-0.4-0.1_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 1080, 17280, 17280, 1080, 17280, 4320, 17280, 1080, 4320, 1080, 17280, 4320, 4320, 4320, 4320, 17280, 1080, 1080, 1080, 4320, 17280, 1080, 17280, 17280, 4320, 4320, 4320, 1080, 17280, 1080, 4320, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 17280, 4320, 1080, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 1080, 17280, 17280, 4320, 1080, 1080, 17280, 4320, 1080, 4320, 4320, 17280, 4320, 1080, 1080, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 4320, 1080, 4320, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 17280, 17280, 1080, 17280, 1080, 4320, 17280, 17280, 17280, 4320, 1080, 17280, 4320, 1080, 1080, 1080, 1080, 1080, 17280, 4320, 1080, 17280, 1080, 17280, 1080, 1080, 4320, 4320, 17280, 4320, 17280, 1080, 4320, 1080, 17280, 17280, 1080, 17280, 4320, 1080, 17280, 1080, 1080, 17280, 17280, 4320, 17280, 17280, 1080, 17280, 4320, 4320, 1080, 4320, 17280, 17280, 1080, 17280, 4320, 1080, 4320, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 1080, 1080, 17280, 1080, 4320, 17280, 17280, 4320, 1080, 17280, 1080, 4320, 4320, 1080, 4320, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 17280, 4320, 17280, 4320, 1080, 4320, 17280, 4320, 17280, 1080, 17280, 1080, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 1080, 17280, 1080, 17280, 4320, 4320, 1080, 4320, 17280, 4320, 4320, 17280, 1080, 17280, 17280, 4320, 1080, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 1080, 17280, 4320, 17280, 17280, 1080, 17280, 4320, 4320, 17280, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 1080, 1080, 1080, 1080]
Prompts retrieved: 1945080 . Total input tokens: 433780535 . Total output tokens: 381721736
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 25.427546721883118,
    "estimated_duration": 3600.072390104887,
    "input_throughput": 5088.7718397979925,
    "output_throughput": 4444.0673037504885,
    "total_throughput": 9532.839143548481,
    "itl": 99.04172165025088,
    "ttft": 2089560.1148331147,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 849,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.311790779507744,
    "arrivals": 648144,
    "finished_requests": 74505,
    "scheduler_time": 189.72338585343462
}
#Debug simulation 
Total elapsed time: 25.427654918748885. Arrivals time: 0.3394924672320485 Scheduler time: 24.913314575329423 Scheduler overhead time: 0.06351127754896879 Adapter cache time: 0.02195310778915882 Engine time: 0.06271130917593837 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_16-16-16/adapters_256_slots_64_rate_1.6-0.4-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_16-16-16/adapters_256_slots_64_rate_1.6-0.4-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 1080, 17280, 17280, 1080, 17280, 4320, 17280, 1080, 4320, 1080, 17280, 4320, 4320, 4320, 4320, 17280, 1080, 1080, 1080, 4320, 17280, 1080, 17280, 17280, 4320, 4320, 4320, 1080, 17280, 1080, 4320, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 17280, 4320, 1080, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 1080, 17280, 17280, 4320, 1080, 1080, 17280, 4320, 1080, 4320, 4320, 17280, 4320, 1080, 1080, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 4320, 1080, 4320, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 17280, 17280, 1080, 17280, 1080, 4320, 17280, 17280, 17280, 4320, 1080, 17280, 4320, 1080, 1080, 1080, 1080, 1080, 17280, 4320, 1080, 17280, 1080, 17280, 1080, 1080, 4320, 4320, 17280, 4320, 17280, 1080, 4320, 1080, 17280, 17280, 1080, 17280, 4320, 1080, 17280, 1080, 1080, 17280, 17280, 4320, 17280, 17280, 1080, 17280, 4320, 4320, 1080, 4320, 17280, 17280, 1080, 17280, 4320, 1080, 4320, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 1080, 1080, 17280, 1080, 4320, 17280, 17280, 4320, 1080, 17280, 1080, 4320, 4320, 1080, 4320, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 17280, 4320, 17280, 4320, 1080, 4320, 17280, 4320, 17280, 1080, 17280, 1080, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 1080, 17280, 1080, 17280, 4320, 4320, 1080, 4320, 17280, 4320, 4320, 17280, 1080, 17280, 17280, 4320, 1080, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 1080, 17280, 4320, 17280, 17280, 1080, 17280, 4320, 4320, 17280, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 1080, 1080, 1080, 1080]
Prompts retrieved: 1945080 . Total input tokens: 433780535 . Total output tokens: 381721736
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 50.39762658532709,
    "estimated_duration": 3600.0146846466996,
    "input_throughput": 5398.69881167092,
    "output_throughput": 4707.256909887598,
    "total_throughput": 10105.95572155852,
    "itl": 111.58371973048168,
    "ttft": 2057760.071516945,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 603,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.8495043271640137,
    "arrivals": 648144,
    "finished_requests": 79021,
    "scheduler_time": 179.75459428515998
}
#Debug simulation 
Total elapsed time: 50.397794526070356. Arrivals time: 0.3779059089720249 Scheduler time: 49.850565371569246 Scheduler overhead time: 0.06334897270426154 Adapter cache time: 0.019324291963130236 Engine time: 0.061501437332481146 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_16-16-32/adapters_256_slots_64_rate_1.6-0.4-0.1_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.1_size_16-16-32/adapters_256_slots_64_rate_1.6-0.4-0.1_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 1080, 17280, 17280, 1080, 17280, 4320, 17280, 1080, 4320, 1080, 17280, 4320, 4320, 4320, 4320, 17280, 1080, 1080, 1080, 4320, 17280, 1080, 17280, 17280, 4320, 4320, 4320, 1080, 17280, 1080, 4320, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 17280, 4320, 1080, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 1080, 17280, 17280, 4320, 1080, 1080, 17280, 4320, 1080, 4320, 4320, 17280, 4320, 1080, 1080, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 4320, 1080, 4320, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 17280, 17280, 1080, 17280, 1080, 4320, 17280, 17280, 17280, 4320, 1080, 17280, 4320, 1080, 1080, 1080, 1080, 1080, 17280, 4320, 1080, 17280, 1080, 17280, 1080, 1080, 4320, 4320, 17280, 4320, 17280, 1080, 4320, 1080, 17280, 17280, 1080, 17280, 4320, 1080, 17280, 1080, 1080, 17280, 17280, 4320, 17280, 17280, 1080, 17280, 4320, 4320, 1080, 4320, 17280, 17280, 1080, 17280, 4320, 1080, 4320, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 1080, 1080, 17280, 1080, 4320, 17280, 17280, 4320, 1080, 17280, 1080, 4320, 4320, 1080, 4320, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 17280, 4320, 17280, 4320, 1080, 4320, 17280, 4320, 17280, 1080, 17280, 1080, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 1080, 17280, 1080, 17280, 4320, 4320, 1080, 4320, 17280, 4320, 4320, 17280, 1080, 17280, 17280, 4320, 1080, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 1080, 17280, 4320, 17280, 17280, 1080, 17280, 4320, 4320, 17280, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 1080, 1080, 1080, 1080]
Prompts retrieved: 1945080 . Total input tokens: 433780535 . Total output tokens: 381721736
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 23.80097851064056,
    "estimated_duration": 3600.000568174738,
    "input_throughput": 5094.599195938177,
    "output_throughput": 4446.49957600313,
    "total_throughput": 9541.098771941308,
    "itl": 99.23930062847127,
    "ttft": 2091084.955598856,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 965,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.103992045093346,
    "arrivals": 648144,
    "finished_requests": 74600,
    "scheduler_time": 189.49555303255582
}
#Debug simulation 
Total elapsed time: 23.801130185835063. Arrivals time: 0.3330331714823842 Scheduler time: 23.294738875702024 Scheduler overhead time: 0.0620916117914021 Adapter cache time: 0.023495161905884743 Engine time: 0.06154651753604412 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_8-8-8/adapters_256_slots_64_rate_1.6-0.4-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_8-8-8/adapters_256_slots_64_rate_1.6-0.4-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 540, 17280, 17280, 540, 17280, 4320, 17280, 540, 4320, 540, 17280, 4320, 4320, 4320, 4320, 17280, 540, 540, 540, 4320, 17280, 540, 17280, 17280, 4320, 4320, 4320, 540, 17280, 540, 4320, 4320, 540, 4320, 540, 540, 4320, 4320, 17280, 4320, 540, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 540, 17280, 17280, 4320, 540, 540, 17280, 4320, 540, 4320, 4320, 17280, 4320, 540, 540, 17280, 17280, 17280, 17280, 17280, 17280, 540, 4320, 540, 4320, 540, 540, 540, 4320, 4320, 4320, 540, 540, 17280, 17280, 540, 17280, 540, 4320, 17280, 17280, 17280, 4320, 540, 17280, 4320, 540, 540, 540, 540, 540, 17280, 4320, 540, 17280, 540, 17280, 540, 540, 4320, 4320, 17280, 4320, 17280, 540, 4320, 540, 17280, 17280, 540, 17280, 4320, 540, 17280, 540, 540, 17280, 17280, 4320, 17280, 17280, 540, 17280, 4320, 4320, 540, 4320, 17280, 17280, 540, 17280, 4320, 540, 4320, 17280, 540, 540, 540, 540, 540, 540, 17280, 540, 540, 540, 17280, 540, 4320, 17280, 17280, 4320, 540, 17280, 540, 4320, 4320, 540, 4320, 540, 17280, 540, 540, 17280, 540, 17280, 17280, 4320, 17280, 4320, 540, 4320, 17280, 4320, 17280, 540, 17280, 540, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 540, 17280, 540, 17280, 4320, 4320, 540, 4320, 17280, 4320, 4320, 17280, 540, 17280, 17280, 4320, 540, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 540, 17280, 4320, 17280, 17280, 540, 17280, 4320, 4320, 17280, 540, 4320, 540, 540, 540, 540, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 540, 540, 540, 540]
Prompts retrieved: 1899180 . Total input tokens: 423505645 . Total output tokens: 372714612
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 42.48839625297114,
    "estimated_duration": 3600.1314035798473,
    "input_throughput": 5546.558933972289,
    "output_throughput": 4835.056015647439,
    "total_throughput": 10381.614949619729,
    "itl": 118.74752216165311,
    "ttft": 2038642.3889602271,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 641,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.238554189479979,
    "arrivals": 632850,
    "finished_requests": 80979,
    "scheduler_time": 174.6827628510057
}
#Debug simulation 
Total elapsed time: 42.488542697858065. Arrivals time: 0.3697615065611899 Scheduler time: 41.954996798653156 Scheduler overhead time: 0.06103774206712842 Adapter cache time: 0.019052715972065926 Engine time: 0.059541286900639534 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_8-8-16/adapters_256_slots_64_rate_1.6-0.4-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_8-8-16/adapters_256_slots_64_rate_1.6-0.4-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 540, 17280, 17280, 540, 17280, 4320, 17280, 540, 4320, 540, 17280, 4320, 4320, 4320, 4320, 17280, 540, 540, 540, 4320, 17280, 540, 17280, 17280, 4320, 4320, 4320, 540, 17280, 540, 4320, 4320, 540, 4320, 540, 540, 4320, 4320, 17280, 4320, 540, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 540, 17280, 17280, 4320, 540, 540, 17280, 4320, 540, 4320, 4320, 17280, 4320, 540, 540, 17280, 17280, 17280, 17280, 17280, 17280, 540, 4320, 540, 4320, 540, 540, 540, 4320, 4320, 4320, 540, 540, 17280, 17280, 540, 17280, 540, 4320, 17280, 17280, 17280, 4320, 540, 17280, 4320, 540, 540, 540, 540, 540, 17280, 4320, 540, 17280, 540, 17280, 540, 540, 4320, 4320, 17280, 4320, 17280, 540, 4320, 540, 17280, 17280, 540, 17280, 4320, 540, 17280, 540, 540, 17280, 17280, 4320, 17280, 17280, 540, 17280, 4320, 4320, 540, 4320, 17280, 17280, 540, 17280, 4320, 540, 4320, 17280, 540, 540, 540, 540, 540, 540, 17280, 540, 540, 540, 17280, 540, 4320, 17280, 17280, 4320, 540, 17280, 540, 4320, 4320, 540, 4320, 540, 17280, 540, 540, 17280, 540, 17280, 17280, 4320, 17280, 4320, 540, 4320, 17280, 4320, 17280, 540, 17280, 540, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 540, 17280, 540, 17280, 4320, 4320, 540, 4320, 17280, 4320, 4320, 17280, 540, 17280, 17280, 4320, 540, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 540, 17280, 4320, 17280, 17280, 540, 17280, 4320, 4320, 17280, 540, 4320, 540, 540, 540, 540, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 540, 540, 540, 540]
Prompts retrieved: 1899180 . Total input tokens: 423505645 . Total output tokens: 372714612
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 33.49172254931182,
    "estimated_duration": 3600.0888354039143,
    "input_throughput": 5385.155168768178,
    "output_throughput": 4704.989452878206,
    "total_throughput": 10090.144621646385,
    "itl": 111.4612174720962,
    "ttft": 2055574.3363291363,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 813,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.949484597085984,
    "arrivals": 632850,
    "finished_requests": 78698,
    "scheduler_time": 179.58391943270806
}
#Debug simulation 
Total elapsed time: 33.49195981025696. Arrivals time: 0.6671453583985567 Scheduler time: 32.65782297914848 Scheduler overhead time: 0.06125580193474889 Adapter cache time: 0.02115422347560525 Engine time: 0.059719727374613285 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_8-8-32/adapters_256_slots_64_rate_1.6-0.4-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_8-8-32/adapters_256_slots_64_rate_1.6-0.4-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 540, 17280, 17280, 540, 17280, 4320, 17280, 540, 4320, 540, 17280, 4320, 4320, 4320, 4320, 17280, 540, 540, 540, 4320, 17280, 540, 17280, 17280, 4320, 4320, 4320, 540, 17280, 540, 4320, 4320, 540, 4320, 540, 540, 4320, 4320, 17280, 4320, 540, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 540, 17280, 17280, 4320, 540, 540, 17280, 4320, 540, 4320, 4320, 17280, 4320, 540, 540, 17280, 17280, 17280, 17280, 17280, 17280, 540, 4320, 540, 4320, 540, 540, 540, 4320, 4320, 4320, 540, 540, 17280, 17280, 540, 17280, 540, 4320, 17280, 17280, 17280, 4320, 540, 17280, 4320, 540, 540, 540, 540, 540, 17280, 4320, 540, 17280, 540, 17280, 540, 540, 4320, 4320, 17280, 4320, 17280, 540, 4320, 540, 17280, 17280, 540, 17280, 4320, 540, 17280, 540, 540, 17280, 17280, 4320, 17280, 17280, 540, 17280, 4320, 4320, 540, 4320, 17280, 17280, 540, 17280, 4320, 540, 4320, 17280, 540, 540, 540, 540, 540, 540, 17280, 540, 540, 540, 17280, 540, 4320, 17280, 17280, 4320, 540, 17280, 540, 4320, 4320, 540, 4320, 540, 17280, 540, 540, 17280, 540, 17280, 17280, 4320, 17280, 4320, 540, 4320, 17280, 4320, 17280, 540, 17280, 540, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 540, 17280, 540, 17280, 4320, 4320, 540, 4320, 17280, 4320, 4320, 17280, 540, 17280, 17280, 4320, 540, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 540, 17280, 4320, 17280, 17280, 540, 17280, 4320, 4320, 17280, 540, 4320, 540, 540, 540, 540, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 540, 540, 540, 540]
Prompts retrieved: 1899180 . Total input tokens: 423505645 . Total output tokens: 372714612
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 25.260850050020963,
    "estimated_duration": 3600.0470858572003,
    "input_throughput": 5101.58466319807,
    "output_throughput": 4444.223261093934,
    "total_throughput": 9545.807924292005,
    "itl": 99.1702375433645,
    "ttft": 2084427.1942019355,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 960,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.195959554081802,
    "arrivals": 632850,
    "finished_requests": 74359,
    "scheduler_time": 189.5099299243754
}
#Debug simulation 
Total elapsed time: 25.260967838112265. Arrivals time: 0.3323156014084816 Scheduler time: 24.753893995657563 Scheduler overhead time: 0.06285466998815536 Adapter cache time: 0.023421096615493298 Engine time: 0.062208425253629684 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_8-16-16/adapters_256_slots_64_rate_1.6-0.4-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_8-16-16/adapters_256_slots_64_rate_1.6-0.4-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 540, 17280, 17280, 540, 17280, 4320, 17280, 540, 4320, 540, 17280, 4320, 4320, 4320, 4320, 17280, 540, 540, 540, 4320, 17280, 540, 17280, 17280, 4320, 4320, 4320, 540, 17280, 540, 4320, 4320, 540, 4320, 540, 540, 4320, 4320, 17280, 4320, 540, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 540, 17280, 17280, 4320, 540, 540, 17280, 4320, 540, 4320, 4320, 17280, 4320, 540, 540, 17280, 17280, 17280, 17280, 17280, 17280, 540, 4320, 540, 4320, 540, 540, 540, 4320, 4320, 4320, 540, 540, 17280, 17280, 540, 17280, 540, 4320, 17280, 17280, 17280, 4320, 540, 17280, 4320, 540, 540, 540, 540, 540, 17280, 4320, 540, 17280, 540, 17280, 540, 540, 4320, 4320, 17280, 4320, 17280, 540, 4320, 540, 17280, 17280, 540, 17280, 4320, 540, 17280, 540, 540, 17280, 17280, 4320, 17280, 17280, 540, 17280, 4320, 4320, 540, 4320, 17280, 17280, 540, 17280, 4320, 540, 4320, 17280, 540, 540, 540, 540, 540, 540, 17280, 540, 540, 540, 17280, 540, 4320, 17280, 17280, 4320, 540, 17280, 540, 4320, 4320, 540, 4320, 540, 17280, 540, 540, 17280, 540, 17280, 17280, 4320, 17280, 4320, 540, 4320, 17280, 4320, 17280, 540, 17280, 540, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 540, 17280, 540, 17280, 4320, 4320, 540, 4320, 17280, 4320, 4320, 17280, 540, 17280, 17280, 4320, 540, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 540, 17280, 4320, 17280, 17280, 540, 17280, 4320, 4320, 17280, 540, 4320, 540, 540, 540, 540, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 540, 540, 540, 540]
Prompts retrieved: 1899180 . Total input tokens: 423505645 . Total output tokens: 372714612
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 56.153905778657645,
    "estimated_duration": 3600.0553396385862,
    "input_throughput": 5422.039985074119,
    "output_throughput": 4707.243195239677,
    "total_throughput": 10129.283180313796,
    "itl": 111.37051365262101,
    "ttft": 2043738.853001223,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 605,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.146857468574303,
    "arrivals": 632850,
    "finished_requests": 79030,
    "scheduler_time": 179.68944241092362
}
#Debug simulation 
Total elapsed time: 56.15408163284883. Arrivals time: 0.3942965525202453 Scheduler time: 55.58642984787002 Scheduler overhead time: 0.06499012978747487 Adapter cache time: 0.019296184182167053 Engine time: 0.06350517552345991 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_8-16-32/adapters_256_slots_64_rate_1.6-0.4-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_8-16-32/adapters_256_slots_64_rate_1.6-0.4-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 540, 17280, 17280, 540, 17280, 4320, 17280, 540, 4320, 540, 17280, 4320, 4320, 4320, 4320, 17280, 540, 540, 540, 4320, 17280, 540, 17280, 17280, 4320, 4320, 4320, 540, 17280, 540, 4320, 4320, 540, 4320, 540, 540, 4320, 4320, 17280, 4320, 540, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 540, 17280, 17280, 4320, 540, 540, 17280, 4320, 540, 4320, 4320, 17280, 4320, 540, 540, 17280, 17280, 17280, 17280, 17280, 17280, 540, 4320, 540, 4320, 540, 540, 540, 4320, 4320, 4320, 540, 540, 17280, 17280, 540, 17280, 540, 4320, 17280, 17280, 17280, 4320, 540, 17280, 4320, 540, 540, 540, 540, 540, 17280, 4320, 540, 17280, 540, 17280, 540, 540, 4320, 4320, 17280, 4320, 17280, 540, 4320, 540, 17280, 17280, 540, 17280, 4320, 540, 17280, 540, 540, 17280, 17280, 4320, 17280, 17280, 540, 17280, 4320, 4320, 540, 4320, 17280, 17280, 540, 17280, 4320, 540, 4320, 17280, 540, 540, 540, 540, 540, 540, 17280, 540, 540, 540, 17280, 540, 4320, 17280, 17280, 4320, 540, 17280, 540, 4320, 4320, 540, 4320, 540, 17280, 540, 540, 17280, 540, 17280, 17280, 4320, 17280, 4320, 540, 4320, 17280, 4320, 17280, 540, 17280, 540, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 540, 17280, 540, 17280, 4320, 4320, 540, 4320, 17280, 4320, 4320, 17280, 540, 17280, 17280, 4320, 540, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 540, 17280, 4320, 17280, 17280, 540, 17280, 4320, 4320, 17280, 540, 4320, 540, 540, 540, 540, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 540, 540, 540, 540]
Prompts retrieved: 1899180 . Total input tokens: 423505645 . Total output tokens: 372714612
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 23.23903629044071,
    "estimated_duration": 3600.1061019167487,
    "input_throughput": 5106.866986562262,
    "output_throughput": 4443.129326517248,
    "total_throughput": 9549.996313079511,
    "itl": 99.17452717782777,
    "ttft": 2088593.3342733146,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1026,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.625420014685971,
    "arrivals": 632850,
    "finished_requests": 74447,
    "scheduler_time": 189.5256665892155
}
#Debug simulation 
Total elapsed time: 23.23920995509252. Arrivals time: 0.33973095705732703 Scheduler time: 22.724779956508428 Scheduler overhead time: 0.06232942268252373 Adapter cache time: 0.02418686356395483 Engine time: 0.06156931119039655 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_16-16-16/adapters_256_slots_64_rate_1.6-0.4-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_16-16-16/adapters_256_slots_64_rate_1.6-0.4-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 540, 17280, 17280, 540, 17280, 4320, 17280, 540, 4320, 540, 17280, 4320, 4320, 4320, 4320, 17280, 540, 540, 540, 4320, 17280, 540, 17280, 17280, 4320, 4320, 4320, 540, 17280, 540, 4320, 4320, 540, 4320, 540, 540, 4320, 4320, 17280, 4320, 540, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 540, 17280, 17280, 4320, 540, 540, 17280, 4320, 540, 4320, 4320, 17280, 4320, 540, 540, 17280, 17280, 17280, 17280, 17280, 17280, 540, 4320, 540, 4320, 540, 540, 540, 4320, 4320, 4320, 540, 540, 17280, 17280, 540, 17280, 540, 4320, 17280, 17280, 17280, 4320, 540, 17280, 4320, 540, 540, 540, 540, 540, 17280, 4320, 540, 17280, 540, 17280, 540, 540, 4320, 4320, 17280, 4320, 17280, 540, 4320, 540, 17280, 17280, 540, 17280, 4320, 540, 17280, 540, 540, 17280, 17280, 4320, 17280, 17280, 540, 17280, 4320, 4320, 540, 4320, 17280, 17280, 540, 17280, 4320, 540, 4320, 17280, 540, 540, 540, 540, 540, 540, 17280, 540, 540, 540, 17280, 540, 4320, 17280, 17280, 4320, 540, 17280, 540, 4320, 4320, 540, 4320, 540, 17280, 540, 540, 17280, 540, 17280, 17280, 4320, 17280, 4320, 540, 4320, 17280, 4320, 17280, 540, 17280, 540, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 540, 17280, 540, 17280, 4320, 4320, 540, 4320, 17280, 4320, 4320, 17280, 540, 17280, 17280, 4320, 540, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 540, 17280, 4320, 17280, 17280, 540, 17280, 4320, 4320, 17280, 540, 4320, 540, 540, 540, 540, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 540, 540, 540, 540]
Prompts retrieved: 1899180 . Total input tokens: 423505645 . Total output tokens: 372714612
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 60.71604241337627,
    "estimated_duration": 3600.025469811524,
    "input_throughput": 5410.7156083592345,
    "output_throughput": 4710.574172934346,
    "total_throughput": 10121.28978129358,
    "itl": 111.25246258816338,
    "ttft": 2028317.596646806,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 440,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.8089252138510226,
    "arrivals": 632850,
    "finished_requests": 78880,
    "scheduler_time": 180.01709030510446
}
#Debug simulation 
Total elapsed time: 60.71621317835525. Arrivals time: 0.6838480830192566 Scheduler time: 59.86019009258598 Scheduler overhead time: 0.06541207013651729 Adapter cache time: 0.01735353423282504 Engine time: 0.0641928631812334 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_16-16-32/adapters_256_slots_64_rate_1.6-0.4-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.05_size_16-16-32/adapters_256_slots_64_rate_1.6-0.4-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 540, 17280, 17280, 540, 17280, 4320, 17280, 540, 4320, 540, 17280, 4320, 4320, 4320, 4320, 17280, 540, 540, 540, 4320, 17280, 540, 17280, 17280, 4320, 4320, 4320, 540, 17280, 540, 4320, 4320, 540, 4320, 540, 540, 4320, 4320, 17280, 4320, 540, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 540, 17280, 17280, 4320, 540, 540, 17280, 4320, 540, 4320, 4320, 17280, 4320, 540, 540, 17280, 17280, 17280, 17280, 17280, 17280, 540, 4320, 540, 4320, 540, 540, 540, 4320, 4320, 4320, 540, 540, 17280, 17280, 540, 17280, 540, 4320, 17280, 17280, 17280, 4320, 540, 17280, 4320, 540, 540, 540, 540, 540, 17280, 4320, 540, 17280, 540, 17280, 540, 540, 4320, 4320, 17280, 4320, 17280, 540, 4320, 540, 17280, 17280, 540, 17280, 4320, 540, 17280, 540, 540, 17280, 17280, 4320, 17280, 17280, 540, 17280, 4320, 4320, 540, 4320, 17280, 17280, 540, 17280, 4320, 540, 4320, 17280, 540, 540, 540, 540, 540, 540, 17280, 540, 540, 540, 17280, 540, 4320, 17280, 17280, 4320, 540, 17280, 540, 4320, 4320, 540, 4320, 540, 17280, 540, 540, 17280, 540, 17280, 17280, 4320, 17280, 4320, 540, 4320, 17280, 4320, 17280, 540, 17280, 540, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 540, 17280, 540, 17280, 4320, 4320, 540, 4320, 17280, 4320, 4320, 17280, 540, 17280, 17280, 4320, 540, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 540, 17280, 4320, 17280, 17280, 540, 17280, 4320, 4320, 17280, 540, 4320, 540, 540, 540, 540, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 540, 540, 540, 540]
Prompts retrieved: 1899180 . Total input tokens: 423505645 . Total output tokens: 372714612
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 24.220267496071756,
    "estimated_duration": 3600.053722189499,
    "input_throughput": 5084.884674683869,
    "output_throughput": 4425.191463618228,
    "total_throughput": 9510.076138302098,
    "itl": 98.35557884130188,
    "ttft": 2088585.8351206006,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 961,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.078522977177076,
    "arrivals": 632850,
    "finished_requests": 74139,
    "scheduler_time": 190.28815536888888
}
#Debug simulation 
Total elapsed time: 24.220371295697987. Arrivals time: 0.3296162039041519 Scheduler time: 23.71573602827266 Scheduler overhead time: 0.06300734914839268 Adapter cache time: 0.02352478029206395 Engine time: 0.06206534802913666 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_8-8-8/adapters_256_slots_64_rate_1.6-0.4-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_8-8-8/adapters_256_slots_64_rate_1.6-0.4-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 270, 17280, 17280, 270, 17280, 4320, 17280, 270, 4320, 270, 17280, 4320, 4320, 4320, 4320, 17280, 270, 270, 270, 4320, 17280, 270, 17280, 17280, 4320, 4320, 4320, 270, 17280, 270, 4320, 4320, 270, 4320, 270, 270, 4320, 4320, 17280, 4320, 270, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 270, 17280, 17280, 4320, 270, 270, 17280, 4320, 270, 4320, 4320, 17280, 4320, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 4320, 270, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 270, 17280, 17280, 270, 17280, 270, 4320, 17280, 17280, 17280, 4320, 270, 17280, 4320, 270, 270, 270, 270, 270, 17280, 4320, 270, 17280, 270, 17280, 270, 270, 4320, 4320, 17280, 4320, 17280, 270, 4320, 270, 17280, 17280, 270, 17280, 4320, 270, 17280, 270, 270, 17280, 17280, 4320, 17280, 17280, 270, 17280, 4320, 4320, 270, 4320, 17280, 17280, 270, 17280, 4320, 270, 4320, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 4320, 17280, 17280, 4320, 270, 17280, 270, 4320, 4320, 270, 4320, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 4320, 17280, 4320, 270, 4320, 17280, 4320, 17280, 270, 17280, 270, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 270, 17280, 270, 17280, 4320, 4320, 270, 4320, 17280, 4320, 4320, 17280, 270, 17280, 17280, 4320, 270, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 270, 17280, 4320, 17280, 17280, 270, 17280, 4320, 4320, 17280, 270, 4320, 270, 270, 270, 270, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 270, 270, 270, 270]
Prompts retrieved: 1876230 . Total input tokens: 418405157 . Total output tokens: 368275763
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 46.99226122396067,
    "estimated_duration": 3600.058651771311,
    "input_throughput": 5588.424785829854,
    "output_throughput": 4840.617802553234,
    "total_throughput": 10429.042588383087,
    "itl": 118.91112947411611,
    "ttft": 2033918.016050066,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 385,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.545777477300741,
    "arrivals": 625482,
    "finished_requests": 81365,
    "scheduler_time": 174.61749251691856
}
#Debug simulation 
Total elapsed time: 46.99244245328009. Arrivals time: 0.3861552090384066 Scheduler time: 46.44631587853655 Scheduler overhead time: 0.06076287478208542 Adapter cache time: 0.015419501811265945 Engine time: 0.05977864610031247 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_8-8-16/adapters_256_slots_64_rate_1.6-0.4-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_8-8-16/adapters_256_slots_64_rate_1.6-0.4-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 270, 17280, 17280, 270, 17280, 4320, 17280, 270, 4320, 270, 17280, 4320, 4320, 4320, 4320, 17280, 270, 270, 270, 4320, 17280, 270, 17280, 17280, 4320, 4320, 4320, 270, 17280, 270, 4320, 4320, 270, 4320, 270, 270, 4320, 4320, 17280, 4320, 270, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 270, 17280, 17280, 4320, 270, 270, 17280, 4320, 270, 4320, 4320, 17280, 4320, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 4320, 270, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 270, 17280, 17280, 270, 17280, 270, 4320, 17280, 17280, 17280, 4320, 270, 17280, 4320, 270, 270, 270, 270, 270, 17280, 4320, 270, 17280, 270, 17280, 270, 270, 4320, 4320, 17280, 4320, 17280, 270, 4320, 270, 17280, 17280, 270, 17280, 4320, 270, 17280, 270, 270, 17280, 17280, 4320, 17280, 17280, 270, 17280, 4320, 4320, 270, 4320, 17280, 17280, 270, 17280, 4320, 270, 4320, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 4320, 17280, 17280, 4320, 270, 17280, 270, 4320, 4320, 270, 4320, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 4320, 17280, 4320, 270, 4320, 17280, 4320, 17280, 270, 17280, 270, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 270, 17280, 270, 17280, 4320, 4320, 270, 4320, 17280, 4320, 4320, 17280, 270, 17280, 17280, 4320, 270, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 270, 17280, 4320, 17280, 17280, 270, 17280, 4320, 4320, 17280, 270, 4320, 270, 270, 270, 270, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 270, 270, 270, 270]
Prompts retrieved: 1876230 . Total input tokens: 418405157 . Total output tokens: 368275763
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 35.589229120872915,
    "estimated_duration": 3600.1008993448786,
    "input_throughput": 5423.7563184835235,
    "output_throughput": 4705.05812853256,
    "total_throughput": 10128.814447016082,
    "itl": 111.35024707550599,
    "ttft": 2060756.1934816362,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 678,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.97104470835068,
    "arrivals": 625482,
    "finished_requests": 78998,
    "scheduler_time": 179.5731908041918
}
#Debug simulation 
Total elapsed time: 35.589450147002935. Arrivals time: 0.35785648599267006 Scheduler time: 35.06998299015686 Scheduler overhead time: 0.05915718758478761 Adapter cache time: 0.018969654571264982 Engine time: 0.05912140104919672 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_8-8-32/adapters_256_slots_64_rate_1.6-0.4-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_8-8-32/adapters_256_slots_64_rate_1.6-0.4-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 270, 17280, 17280, 270, 17280, 4320, 17280, 270, 4320, 270, 17280, 4320, 4320, 4320, 4320, 17280, 270, 270, 270, 4320, 17280, 270, 17280, 17280, 4320, 4320, 4320, 270, 17280, 270, 4320, 4320, 270, 4320, 270, 270, 4320, 4320, 17280, 4320, 270, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 270, 17280, 17280, 4320, 270, 270, 17280, 4320, 270, 4320, 4320, 17280, 4320, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 4320, 270, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 270, 17280, 17280, 270, 17280, 270, 4320, 17280, 17280, 17280, 4320, 270, 17280, 4320, 270, 270, 270, 270, 270, 17280, 4320, 270, 17280, 270, 17280, 270, 270, 4320, 4320, 17280, 4320, 17280, 270, 4320, 270, 17280, 17280, 270, 17280, 4320, 270, 17280, 270, 270, 17280, 17280, 4320, 17280, 17280, 270, 17280, 4320, 4320, 270, 4320, 17280, 17280, 270, 17280, 4320, 270, 4320, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 4320, 17280, 17280, 4320, 270, 17280, 270, 4320, 4320, 270, 4320, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 4320, 17280, 4320, 270, 4320, 17280, 4320, 17280, 270, 17280, 270, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 270, 17280, 270, 17280, 4320, 4320, 270, 4320, 17280, 4320, 4320, 17280, 270, 17280, 17280, 4320, 270, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 270, 17280, 4320, 17280, 17280, 270, 17280, 4320, 4320, 17280, 270, 4320, 270, 270, 270, 270, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 270, 270, 270, 270]
Prompts retrieved: 1876230 . Total input tokens: 418405157 . Total output tokens: 368275763
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 20.97555558476597,
    "estimated_duration": 3600.080930015433,
    "input_throughput": 5128.792479651519,
    "output_throughput": 4451.33715367096,
    "total_throughput": 9580.12963332248,
    "itl": 99.07735972647059,
    "ttft": 2091065.5883431467,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1002,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.521484184619057,
    "arrivals": 625482,
    "finished_requests": 74721,
    "scheduler_time": 189.5894536886676
}
#Debug simulation 
Total elapsed time: 20.97571065975353. Arrivals time: 0.320121050812304 Scheduler time: 20.485484352335334 Scheduler overhead time: 0.060956102795898914 Adapter cache time: 0.02294929139316082 Engine time: 0.06011269288137555 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_8-16-16/adapters_256_slots_64_rate_1.6-0.4-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_8-16-16/adapters_256_slots_64_rate_1.6-0.4-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 270, 17280, 17280, 270, 17280, 4320, 17280, 270, 4320, 270, 17280, 4320, 4320, 4320, 4320, 17280, 270, 270, 270, 4320, 17280, 270, 17280, 17280, 4320, 4320, 4320, 270, 17280, 270, 4320, 4320, 270, 4320, 270, 270, 4320, 4320, 17280, 4320, 270, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 270, 17280, 17280, 4320, 270, 270, 17280, 4320, 270, 4320, 4320, 17280, 4320, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 4320, 270, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 270, 17280, 17280, 270, 17280, 270, 4320, 17280, 17280, 17280, 4320, 270, 17280, 4320, 270, 270, 270, 270, 270, 17280, 4320, 270, 17280, 270, 17280, 270, 270, 4320, 4320, 17280, 4320, 17280, 270, 4320, 270, 17280, 17280, 270, 17280, 4320, 270, 17280, 270, 270, 17280, 17280, 4320, 17280, 17280, 270, 17280, 4320, 4320, 270, 4320, 17280, 17280, 270, 17280, 4320, 270, 4320, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 4320, 17280, 17280, 4320, 270, 17280, 270, 4320, 4320, 270, 4320, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 4320, 17280, 4320, 270, 4320, 17280, 4320, 17280, 270, 17280, 270, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 270, 17280, 270, 17280, 4320, 4320, 270, 4320, 17280, 4320, 4320, 17280, 270, 17280, 17280, 4320, 270, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 270, 17280, 4320, 17280, 17280, 270, 17280, 4320, 4320, 17280, 270, 4320, 270, 270, 270, 270, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 270, 270, 270, 270]
Prompts retrieved: 1876230 . Total input tokens: 418405157 . Total output tokens: 368275763
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 32.48978924192488,
    "estimated_duration": 3600.0892789341888,
    "input_throughput": 5435.6396421905865,
    "output_throughput": 4709.255711852562,
    "total_throughput": 10144.895354043148,
    "itl": 111.63752295117287,
    "ttft": 2058600.017246261,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 716,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.906836868990205,
    "arrivals": 625482,
    "finished_requests": 79144,
    "scheduler_time": 179.3497068135134
}
#Debug simulation 
Total elapsed time: 32.48990166420117. Arrivals time: 0.35283350897952914 Scheduler time: 31.973090330138803 Scheduler overhead time: 0.05988316936418414 Adapter cache time: 0.019141886848956347 Engine time: 0.060439301654696465 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_8-16-32/adapters_256_slots_64_rate_1.6-0.4-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_8-16-32/adapters_256_slots_64_rate_1.6-0.4-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 270, 17280, 17280, 270, 17280, 4320, 17280, 270, 4320, 270, 17280, 4320, 4320, 4320, 4320, 17280, 270, 270, 270, 4320, 17280, 270, 17280, 17280, 4320, 4320, 4320, 270, 17280, 270, 4320, 4320, 270, 4320, 270, 270, 4320, 4320, 17280, 4320, 270, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 270, 17280, 17280, 4320, 270, 270, 17280, 4320, 270, 4320, 4320, 17280, 4320, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 4320, 270, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 270, 17280, 17280, 270, 17280, 270, 4320, 17280, 17280, 17280, 4320, 270, 17280, 4320, 270, 270, 270, 270, 270, 17280, 4320, 270, 17280, 270, 17280, 270, 270, 4320, 4320, 17280, 4320, 17280, 270, 4320, 270, 17280, 17280, 270, 17280, 4320, 270, 17280, 270, 270, 17280, 17280, 4320, 17280, 17280, 270, 17280, 4320, 4320, 270, 4320, 17280, 17280, 270, 17280, 4320, 270, 4320, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 4320, 17280, 17280, 4320, 270, 17280, 270, 4320, 4320, 270, 4320, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 4320, 17280, 4320, 270, 4320, 17280, 4320, 17280, 270, 17280, 270, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 270, 17280, 270, 17280, 4320, 4320, 270, 4320, 17280, 4320, 4320, 17280, 270, 17280, 17280, 4320, 270, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 270, 17280, 4320, 17280, 17280, 270, 17280, 4320, 4320, 17280, 270, 4320, 270, 270, 270, 270, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 270, 270, 270, 270]
Prompts retrieved: 1876230 . Total input tokens: 418405157 . Total output tokens: 368275763
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 21.63563421415165,
    "estimated_duration": 3600.084882061789,
    "input_throughput": 5125.479705198602,
    "output_throughput": 4442.0947071784985,
    "total_throughput": 9567.5744123771,
    "itl": 99.01937540971447,
    "ttft": 2090229.2140404112,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1058,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.879660150129368,
    "arrivals": 625482,
    "finished_requests": 74648,
    "scheduler_time": 189.45952470422017
}
#Debug simulation 
Total elapsed time: 21.635780787095428. Arrivals time: 0.32770683988928795 Scheduler time: 21.1376188499853 Scheduler overhead time: 0.06074813799932599 Adapter cache time: 0.023523268289864063 Engine time: 0.060218457132577896 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_16-16-16/adapters_256_slots_64_rate_1.6-0.4-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_16-16-16/adapters_256_slots_64_rate_1.6-0.4-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 270, 17280, 17280, 270, 17280, 4320, 17280, 270, 4320, 270, 17280, 4320, 4320, 4320, 4320, 17280, 270, 270, 270, 4320, 17280, 270, 17280, 17280, 4320, 4320, 4320, 270, 17280, 270, 4320, 4320, 270, 4320, 270, 270, 4320, 4320, 17280, 4320, 270, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 270, 17280, 17280, 4320, 270, 270, 17280, 4320, 270, 4320, 4320, 17280, 4320, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 4320, 270, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 270, 17280, 17280, 270, 17280, 270, 4320, 17280, 17280, 17280, 4320, 270, 17280, 4320, 270, 270, 270, 270, 270, 17280, 4320, 270, 17280, 270, 17280, 270, 270, 4320, 4320, 17280, 4320, 17280, 270, 4320, 270, 17280, 17280, 270, 17280, 4320, 270, 17280, 270, 270, 17280, 17280, 4320, 17280, 17280, 270, 17280, 4320, 4320, 270, 4320, 17280, 17280, 270, 17280, 4320, 270, 4320, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 4320, 17280, 17280, 4320, 270, 17280, 270, 4320, 4320, 270, 4320, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 4320, 17280, 4320, 270, 4320, 17280, 4320, 17280, 270, 17280, 270, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 270, 17280, 270, 17280, 4320, 4320, 270, 4320, 17280, 4320, 4320, 17280, 270, 17280, 17280, 4320, 270, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 270, 17280, 4320, 17280, 17280, 270, 17280, 4320, 4320, 17280, 270, 4320, 270, 270, 270, 270, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 270, 270, 270, 270]
Prompts retrieved: 1876230 . Total input tokens: 418405157 . Total output tokens: 368275763
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 40.22506641037762,
    "estimated_duration": 3600.119643671051,
    "input_throughput": 5427.118522115774,
    "output_throughput": 4711.622856706893,
    "total_throughput": 10138.741378822666,
    "itl": 111.5651401481849,
    "ttft": 2055496.264308656,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 606,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.868656089985725,
    "arrivals": 625482,
    "finished_requests": 79132,
    "scheduler_time": 179.40944974028903
}
#Debug simulation 
Total elapsed time: 40.225185892079026. Arrivals time: 0.3539871354587376 Scheduler time: 39.706793755758554 Scheduler overhead time: 0.060909454710781574 Adapter cache time: 0.018542183563113213 Engine time: 0.06025807512924075 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_16-16-32/adapters_256_slots_64_rate_1.6-0.4-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_16-16-32/adapters_256_slots_64_rate_1.6-0.4-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 270, 17280, 17280, 270, 17280, 4320, 17280, 270, 4320, 270, 17280, 4320, 4320, 4320, 4320, 17280, 270, 270, 270, 4320, 17280, 270, 17280, 17280, 4320, 4320, 4320, 270, 17280, 270, 4320, 4320, 270, 4320, 270, 270, 4320, 4320, 17280, 4320, 270, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 270, 17280, 17280, 4320, 270, 270, 17280, 4320, 270, 4320, 4320, 17280, 4320, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 4320, 270, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 270, 17280, 17280, 270, 17280, 270, 4320, 17280, 17280, 17280, 4320, 270, 17280, 4320, 270, 270, 270, 270, 270, 17280, 4320, 270, 17280, 270, 17280, 270, 270, 4320, 4320, 17280, 4320, 17280, 270, 4320, 270, 17280, 17280, 270, 17280, 4320, 270, 17280, 270, 270, 17280, 17280, 4320, 17280, 17280, 270, 17280, 4320, 4320, 270, 4320, 17280, 17280, 270, 17280, 4320, 270, 4320, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 4320, 17280, 17280, 4320, 270, 17280, 270, 4320, 4320, 270, 4320, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 4320, 17280, 4320, 270, 4320, 17280, 4320, 17280, 270, 17280, 270, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 270, 17280, 270, 17280, 4320, 4320, 270, 4320, 17280, 4320, 4320, 17280, 270, 17280, 17280, 4320, 270, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 270, 17280, 4320, 17280, 17280, 270, 17280, 4320, 4320, 17280, 270, 4320, 270, 270, 270, 270, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 270, 270, 270, 270]
Prompts retrieved: 1876230 . Total input tokens: 418405157 . Total output tokens: 368275763
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 23.808569692075253,
    "estimated_duration": 3600.0393833383,
    "input_throughput": 5122.202575156428,
    "output_throughput": 4443.300280000529,
    "total_throughput": 9565.502855156958,
    "itl": 98.97191909707752,
    "ttft": 2092519.1588616227,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 913,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.747365445476051,
    "arrivals": 625482,
    "finished_requests": 74602,
    "scheduler_time": 189.57122798344992
}
#Debug simulation 
Total elapsed time: 23.808712870813906. Arrivals time: 0.33607358299195766 Scheduler time: 23.30226862197742 Scheduler overhead time: 0.061393823474645615 Adapter cache time: 0.02202508319169283 Engine time: 0.060542572289705276 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-8/adapters_256_slots_64_rate_1.6-0.4-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-8/adapters_256_slots_64_rate_1.6-0.4-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 135, 17280, 17280, 135, 17280, 4320, 17280, 135, 4320, 135, 17280, 4320, 4320, 4320, 4320, 17280, 135, 135, 135, 4320, 17280, 135, 17280, 17280, 4320, 4320, 4320, 135, 17280, 135, 4320, 4320, 135, 4320, 135, 135, 4320, 4320, 17280, 4320, 135, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 135, 17280, 17280, 4320, 135, 135, 17280, 4320, 135, 4320, 4320, 17280, 4320, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 4320, 135, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 135, 17280, 17280, 135, 17280, 135, 4320, 17280, 17280, 17280, 4320, 135, 17280, 4320, 135, 135, 135, 135, 135, 17280, 4320, 135, 17280, 135, 17280, 135, 135, 4320, 4320, 17280, 4320, 17280, 135, 4320, 135, 17280, 17280, 135, 17280, 4320, 135, 17280, 135, 135, 17280, 17280, 4320, 17280, 17280, 135, 17280, 4320, 4320, 135, 4320, 17280, 17280, 135, 17280, 4320, 135, 4320, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 4320, 17280, 17280, 4320, 135, 17280, 135, 4320, 4320, 135, 4320, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 4320, 17280, 4320, 135, 4320, 17280, 4320, 17280, 135, 17280, 135, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 135, 17280, 135, 17280, 4320, 4320, 135, 4320, 17280, 4320, 4320, 17280, 135, 17280, 17280, 4320, 135, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 135, 17280, 4320, 17280, 17280, 135, 17280, 4320, 4320, 17280, 135, 4320, 135, 135, 135, 135, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 135, 135, 135, 135]
Prompts retrieved: 1864755 . Total input tokens: 415797701 . Total output tokens: 366005492
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 50.977427336387336,
    "estimated_duration": 3600.1079239817877,
    "input_throughput": 5612.02675770178,
    "output_throughput": 4840.901264072261,
    "total_throughput": 10452.928021774042,
    "itl": 119.10915341170862,
    "ttft": 2036908.736253169,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 590,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.9013213288505217,
    "arrivals": 621618,
    "finished_requests": 81693,
    "scheduler_time": 174.35021281159337
}
#Debug simulation 
Total elapsed time: 50.97759320912883. Arrivals time: 0.3733638455159962 Scheduler time: 50.4429109361954 Scheduler overhead time: 0.06030122563242912 Adapter cache time: 0.01814592583104968 Engine time: 0.058928880374878645 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-16/adapters_256_slots_64_rate_1.6-0.4-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-16/adapters_256_slots_64_rate_1.6-0.4-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 135, 17280, 17280, 135, 17280, 4320, 17280, 135, 4320, 135, 17280, 4320, 4320, 4320, 4320, 17280, 135, 135, 135, 4320, 17280, 135, 17280, 17280, 4320, 4320, 4320, 135, 17280, 135, 4320, 4320, 135, 4320, 135, 135, 4320, 4320, 17280, 4320, 135, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 135, 17280, 17280, 4320, 135, 135, 17280, 4320, 135, 4320, 4320, 17280, 4320, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 4320, 135, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 135, 17280, 17280, 135, 17280, 135, 4320, 17280, 17280, 17280, 4320, 135, 17280, 4320, 135, 135, 135, 135, 135, 17280, 4320, 135, 17280, 135, 17280, 135, 135, 4320, 4320, 17280, 4320, 17280, 135, 4320, 135, 17280, 17280, 135, 17280, 4320, 135, 17280, 135, 135, 17280, 17280, 4320, 17280, 17280, 135, 17280, 4320, 4320, 135, 4320, 17280, 17280, 135, 17280, 4320, 135, 4320, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 4320, 17280, 17280, 4320, 135, 17280, 135, 4320, 4320, 135, 4320, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 4320, 17280, 4320, 135, 4320, 17280, 4320, 17280, 135, 17280, 135, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 135, 17280, 135, 17280, 4320, 4320, 135, 4320, 17280, 4320, 4320, 17280, 135, 17280, 17280, 4320, 135, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 135, 17280, 4320, 17280, 17280, 135, 17280, 4320, 4320, 17280, 135, 4320, 135, 135, 135, 135, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 135, 135, 135, 135]
Prompts retrieved: 1864755 . Total input tokens: 415797701 . Total output tokens: 366005492
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 47.93855206063017,
    "estimated_duration": 3600.0777760022156,
    "input_throughput": 5443.459897069718,
    "output_throughput": 4710.23490465545,
    "total_throughput": 10153.694801725167,
    "itl": 111.60458160285235,
    "ttft": 2042331.7613414945,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 562,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.109734654566278,
    "arrivals": 621618,
    "finished_requests": 79305,
    "scheduler_time": 179.41495479982967
}
#Debug simulation 
Total elapsed time: 47.93880484485999. Arrivals time: 0.41465794295072556 Scheduler time: 47.35617332486436 Scheduler overhead time: 0.06313079874962568 Adapter cache time: 0.01827982859686017 Engine time: 0.06147648813202977 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-32/adapters_256_slots_64_rate_1.6-0.4-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-32/adapters_256_slots_64_rate_1.6-0.4-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 135, 17280, 17280, 135, 17280, 4320, 17280, 135, 4320, 135, 17280, 4320, 4320, 4320, 4320, 17280, 135, 135, 135, 4320, 17280, 135, 17280, 17280, 4320, 4320, 4320, 135, 17280, 135, 4320, 4320, 135, 4320, 135, 135, 4320, 4320, 17280, 4320, 135, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 135, 17280, 17280, 4320, 135, 135, 17280, 4320, 135, 4320, 4320, 17280, 4320, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 4320, 135, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 135, 17280, 17280, 135, 17280, 135, 4320, 17280, 17280, 17280, 4320, 135, 17280, 4320, 135, 135, 135, 135, 135, 17280, 4320, 135, 17280, 135, 17280, 135, 135, 4320, 4320, 17280, 4320, 17280, 135, 4320, 135, 17280, 17280, 135, 17280, 4320, 135, 17280, 135, 135, 17280, 17280, 4320, 17280, 17280, 135, 17280, 4320, 4320, 135, 4320, 17280, 17280, 135, 17280, 4320, 135, 4320, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 4320, 17280, 17280, 4320, 135, 17280, 135, 4320, 4320, 135, 4320, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 4320, 17280, 4320, 135, 4320, 17280, 4320, 17280, 135, 17280, 135, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 135, 17280, 135, 17280, 4320, 4320, 135, 4320, 17280, 4320, 4320, 17280, 135, 17280, 17280, 4320, 135, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 135, 17280, 4320, 17280, 17280, 135, 17280, 4320, 4320, 17280, 135, 4320, 135, 135, 135, 135, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 135, 135, 135, 135]
Prompts retrieved: 1864755 . Total input tokens: 415797701 . Total output tokens: 366005492
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 16.53459833515808,
    "estimated_duration": 3600.0384368986106,
    "input_throughput": 5134.399347114686,
    "output_throughput": 4439.129548229898,
    "total_throughput": 9573.528895344585,
    "itl": 99.08776409851532,
    "ttft": 2085563.5079321987,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1217,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.139932318730246,
    "arrivals": 621618,
    "finished_requests": 74795,
    "scheduler_time": 189.42485830562887
}
#Debug simulation 
Total elapsed time: 16.53468950930983. Arrivals time: 0.31231739930808544 Scheduler time: 16.054128971882164 Scheduler overhead time: 0.05873500928282738 Adapter cache time: 0.025654219556599855 Engine time: 0.058279728051275015 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_8-16-16/adapters_256_slots_64_rate_1.6-0.4-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_8-16-16/adapters_256_slots_64_rate_1.6-0.4-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 135, 17280, 17280, 135, 17280, 4320, 17280, 135, 4320, 135, 17280, 4320, 4320, 4320, 4320, 17280, 135, 135, 135, 4320, 17280, 135, 17280, 17280, 4320, 4320, 4320, 135, 17280, 135, 4320, 4320, 135, 4320, 135, 135, 4320, 4320, 17280, 4320, 135, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 135, 17280, 17280, 4320, 135, 135, 17280, 4320, 135, 4320, 4320, 17280, 4320, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 4320, 135, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 135, 17280, 17280, 135, 17280, 135, 4320, 17280, 17280, 17280, 4320, 135, 17280, 4320, 135, 135, 135, 135, 135, 17280, 4320, 135, 17280, 135, 17280, 135, 135, 4320, 4320, 17280, 4320, 17280, 135, 4320, 135, 17280, 17280, 135, 17280, 4320, 135, 17280, 135, 135, 17280, 17280, 4320, 17280, 17280, 135, 17280, 4320, 4320, 135, 4320, 17280, 17280, 135, 17280, 4320, 135, 4320, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 4320, 17280, 17280, 4320, 135, 17280, 135, 4320, 4320, 135, 4320, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 4320, 17280, 4320, 135, 4320, 17280, 4320, 17280, 135, 17280, 135, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 135, 17280, 135, 17280, 4320, 4320, 135, 4320, 17280, 4320, 4320, 17280, 135, 17280, 17280, 4320, 135, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 135, 17280, 4320, 17280, 17280, 135, 17280, 4320, 4320, 17280, 135, 4320, 135, 135, 135, 135, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 135, 135, 135, 135]
Prompts retrieved: 1864755 . Total input tokens: 415797701 . Total output tokens: 366005492
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 32.41441270010546,
    "estimated_duration": 3600.0087755870795,
    "input_throughput": 5451.81282142829,
    "output_throughput": 4708.031578960808,
    "total_throughput": 10159.844400389096,
    "itl": 111.41652525730792,
    "ttft": 2054075.9242415985,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 655,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.49104149312246,
    "arrivals": 621618,
    "finished_requests": 79394,
    "scheduler_time": 179.484023255015
}
#Debug simulation 
Total elapsed time: 32.414571343921125. Arrivals time: 0.3495898270048201 Scheduler time: 31.902423912193626 Scheduler overhead time: 0.05991858011111617 Adapter cache time: 0.01920592552050948 Engine time: 0.058939661365002394 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_8-16-32/adapters_256_slots_64_rate_1.6-0.4-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_8-16-32/adapters_256_slots_64_rate_1.6-0.4-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 135, 17280, 17280, 135, 17280, 4320, 17280, 135, 4320, 135, 17280, 4320, 4320, 4320, 4320, 17280, 135, 135, 135, 4320, 17280, 135, 17280, 17280, 4320, 4320, 4320, 135, 17280, 135, 4320, 4320, 135, 4320, 135, 135, 4320, 4320, 17280, 4320, 135, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 135, 17280, 17280, 4320, 135, 135, 17280, 4320, 135, 4320, 4320, 17280, 4320, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 4320, 135, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 135, 17280, 17280, 135, 17280, 135, 4320, 17280, 17280, 17280, 4320, 135, 17280, 4320, 135, 135, 135, 135, 135, 17280, 4320, 135, 17280, 135, 17280, 135, 135, 4320, 4320, 17280, 4320, 17280, 135, 4320, 135, 17280, 17280, 135, 17280, 4320, 135, 17280, 135, 135, 17280, 17280, 4320, 17280, 17280, 135, 17280, 4320, 4320, 135, 4320, 17280, 17280, 135, 17280, 4320, 135, 4320, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 4320, 17280, 17280, 4320, 135, 17280, 135, 4320, 4320, 135, 4320, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 4320, 17280, 4320, 135, 4320, 17280, 4320, 17280, 135, 17280, 135, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 135, 17280, 135, 17280, 4320, 4320, 135, 4320, 17280, 4320, 4320, 17280, 135, 17280, 17280, 4320, 135, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 135, 17280, 4320, 17280, 17280, 135, 17280, 4320, 4320, 17280, 135, 4320, 135, 135, 135, 135, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 135, 135, 135, 135]
Prompts retrieved: 1864755 . Total input tokens: 415797701 . Total output tokens: 366005492
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 20.412586803082377,
    "estimated_duration": 3600.0548473273075,
    "input_throughput": 5136.708129246654,
    "output_throughput": 4441.508720865958,
    "total_throughput": 9578.21685011261,
    "itl": 99.02046671215949,
    "ttft": 2086940.8440377442,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1056,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.849371448890321,
    "arrivals": 621618,
    "finished_requests": 74859,
    "scheduler_time": 189.4946019832567
}
#Debug simulation 
Total elapsed time: 20.41267840610817. Arrivals time: 0.3100951611995697 Scheduler time: 19.932025216519833 Scheduler overhead time: 0.06050111912190914 Adapter cache time: 0.023799975402653217 Engine time: 0.06023031147196889 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_16-16-16/adapters_256_slots_64_rate_1.6-0.4-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_16-16-16/adapters_256_slots_64_rate_1.6-0.4-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 135, 17280, 17280, 135, 17280, 4320, 17280, 135, 4320, 135, 17280, 4320, 4320, 4320, 4320, 17280, 135, 135, 135, 4320, 17280, 135, 17280, 17280, 4320, 4320, 4320, 135, 17280, 135, 4320, 4320, 135, 4320, 135, 135, 4320, 4320, 17280, 4320, 135, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 135, 17280, 17280, 4320, 135, 135, 17280, 4320, 135, 4320, 4320, 17280, 4320, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 4320, 135, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 135, 17280, 17280, 135, 17280, 135, 4320, 17280, 17280, 17280, 4320, 135, 17280, 4320, 135, 135, 135, 135, 135, 17280, 4320, 135, 17280, 135, 17280, 135, 135, 4320, 4320, 17280, 4320, 17280, 135, 4320, 135, 17280, 17280, 135, 17280, 4320, 135, 17280, 135, 135, 17280, 17280, 4320, 17280, 17280, 135, 17280, 4320, 4320, 135, 4320, 17280, 17280, 135, 17280, 4320, 135, 4320, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 4320, 17280, 17280, 4320, 135, 17280, 135, 4320, 4320, 135, 4320, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 4320, 17280, 4320, 135, 4320, 17280, 4320, 17280, 135, 17280, 135, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 135, 17280, 135, 17280, 4320, 4320, 135, 4320, 17280, 4320, 4320, 17280, 135, 17280, 17280, 4320, 135, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 135, 17280, 4320, 17280, 17280, 135, 17280, 4320, 4320, 17280, 135, 4320, 135, 135, 135, 135, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 135, 135, 135, 135]
Prompts retrieved: 1864755 . Total input tokens: 415797701 . Total output tokens: 366005492
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 52.064954955130816,
    "estimated_duration": 3600.063146223053,
    "input_throughput": 5440.617901535678,
    "output_throughput": 4713.098440454058,
    "total_throughput": 10153.716341989737,
    "itl": 111.63839049330353,
    "ttft": 2037290.867401448,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 540,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.4473173079080723,
    "arrivals": 621618,
    "finished_requests": 79380,
    "scheduler_time": 179.40476137509486
}
#Debug simulation 
Total elapsed time: 52.06512936204672. Arrivals time: 0.37855555210262537 Scheduler time: 51.51797361718491 Scheduler overhead time: 0.06328927632421255 Adapter cache time: 0.017857804894447327 Engine time: 0.06221731239929795 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_16-16-32/adapters_256_slots_64_rate_1.6-0.4-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_16-16-32/adapters_256_slots_64_rate_1.6-0.4-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 135, 17280, 17280, 135, 17280, 4320, 17280, 135, 4320, 135, 17280, 4320, 4320, 4320, 4320, 17280, 135, 135, 135, 4320, 17280, 135, 17280, 17280, 4320, 4320, 4320, 135, 17280, 135, 4320, 4320, 135, 4320, 135, 135, 4320, 4320, 17280, 4320, 135, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 135, 17280, 17280, 4320, 135, 135, 17280, 4320, 135, 4320, 4320, 17280, 4320, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 4320, 135, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 135, 17280, 17280, 135, 17280, 135, 4320, 17280, 17280, 17280, 4320, 135, 17280, 4320, 135, 135, 135, 135, 135, 17280, 4320, 135, 17280, 135, 17280, 135, 135, 4320, 4320, 17280, 4320, 17280, 135, 4320, 135, 17280, 17280, 135, 17280, 4320, 135, 17280, 135, 135, 17280, 17280, 4320, 17280, 17280, 135, 17280, 4320, 4320, 135, 4320, 17280, 17280, 135, 17280, 4320, 135, 4320, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 4320, 17280, 17280, 4320, 135, 17280, 135, 4320, 4320, 135, 4320, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 4320, 17280, 4320, 135, 4320, 17280, 4320, 17280, 135, 17280, 135, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 135, 17280, 135, 17280, 4320, 4320, 135, 4320, 17280, 4320, 4320, 17280, 135, 17280, 17280, 4320, 135, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 135, 17280, 4320, 17280, 17280, 135, 17280, 4320, 4320, 17280, 135, 4320, 135, 135, 135, 135, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 135, 135, 135, 135]
Prompts retrieved: 1864755 . Total input tokens: 415797701 . Total output tokens: 366005492
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 22.119562757667154,
    "estimated_duration": 3600.005234322904,
    "input_throughput": 5137.714752094999,
    "output_throughput": 4441.65631970461,
    "total_throughput": 9579.37107179961,
    "itl": 98.95126785521809,
    "ttft": 2086334.1845116892,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 970,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.156852029040477,
    "arrivals": 621618,
    "finished_requests": 74826,
    "scheduler_time": 189.61308473905444
}
#Debug simulation 
Total elapsed time: 22.11967046977952. Arrivals time: 0.3549509225413203 Scheduler time: 21.592828697524965 Scheduler overhead time: 0.06184565369039774 Adapter cache time: 0.022833968978375196 Engine time: 0.06117330119013786 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-8/adapters_256_slots_64_rate_1.6-0.4-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-8/adapters_256_slots_64_rate_1.6-0.4-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 66, 17280, 17280, 66, 17280, 4320, 17280, 66, 4320, 66, 17280, 4320, 4320, 4320, 4320, 17280, 66, 66, 66, 4320, 17280, 66, 17280, 17280, 4320, 4320, 4320, 66, 17280, 66, 4320, 4320, 66, 4320, 66, 66, 4320, 4320, 17280, 4320, 66, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 66, 17280, 17280, 4320, 66, 66, 17280, 4320, 66, 4320, 4320, 17280, 4320, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 4320, 66, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 66, 17280, 17280, 66, 17280, 66, 4320, 17280, 17280, 17280, 4320, 66, 17280, 4320, 66, 66, 66, 66, 66, 17280, 4320, 66, 17280, 66, 17280, 66, 66, 4320, 4320, 17280, 4320, 17280, 66, 4320, 66, 17280, 17280, 66, 17280, 4320, 66, 17280, 66, 66, 17280, 17280, 4320, 17280, 17280, 66, 17280, 4320, 4320, 66, 4320, 17280, 17280, 66, 17280, 4320, 66, 4320, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 4320, 17280, 17280, 4320, 66, 17280, 66, 4320, 4320, 66, 4320, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 4320, 17280, 4320, 66, 4320, 17280, 4320, 17280, 66, 17280, 66, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 66, 17280, 66, 17280, 4320, 4320, 66, 4320, 17280, 4320, 4320, 17280, 66, 17280, 17280, 4320, 66, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 66, 17280, 4320, 17280, 17280, 66, 17280, 4320, 4320, 17280, 66, 4320, 66, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 66, 66, 66, 66]
Prompts retrieved: 1858890 . Total input tokens: 414491744 . Total output tokens: 364854398
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 38.736247695051134,
    "estimated_duration": 3600.1100179573323,
    "input_throughput": 5595.207340754867,
    "output_throughput": 4853.960271446101,
    "total_throughput": 10449.167612200967,
    "itl": 119.11758509936632,
    "ttft": 2034330.4394040073,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 487,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.2202431985596562,
    "arrivals": 619780,
    "finished_requests": 81388,
    "scheduler_time": 174.54369710849014
}
#Debug simulation 
Total elapsed time: 38.7364232391119. Arrivals time: 0.37650591507554054 Scheduler time: 38.202729113865644 Scheduler overhead time: 0.0593108762986958 Adapter cache time: 0.01675798138603568 Engine time: 0.057734709698706865 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-16/adapters_256_slots_64_rate_1.6-0.4-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-16/adapters_256_slots_64_rate_1.6-0.4-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 66, 17280, 17280, 66, 17280, 4320, 17280, 66, 4320, 66, 17280, 4320, 4320, 4320, 4320, 17280, 66, 66, 66, 4320, 17280, 66, 17280, 17280, 4320, 4320, 4320, 66, 17280, 66, 4320, 4320, 66, 4320, 66, 66, 4320, 4320, 17280, 4320, 66, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 66, 17280, 17280, 4320, 66, 66, 17280, 4320, 66, 4320, 4320, 17280, 4320, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 4320, 66, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 66, 17280, 17280, 66, 17280, 66, 4320, 17280, 17280, 17280, 4320, 66, 17280, 4320, 66, 66, 66, 66, 66, 17280, 4320, 66, 17280, 66, 17280, 66, 66, 4320, 4320, 17280, 4320, 17280, 66, 4320, 66, 17280, 17280, 66, 17280, 4320, 66, 17280, 66, 66, 17280, 17280, 4320, 17280, 17280, 66, 17280, 4320, 4320, 66, 4320, 17280, 17280, 66, 17280, 4320, 66, 4320, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 4320, 17280, 17280, 4320, 66, 17280, 66, 4320, 4320, 66, 4320, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 4320, 17280, 4320, 66, 4320, 17280, 4320, 17280, 66, 17280, 66, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 66, 17280, 66, 17280, 4320, 4320, 66, 4320, 17280, 4320, 4320, 17280, 66, 17280, 17280, 4320, 66, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 66, 17280, 4320, 17280, 17280, 66, 17280, 4320, 4320, 17280, 66, 4320, 66, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 66, 66, 66, 66]
Prompts retrieved: 1858890 . Total input tokens: 414491744 . Total output tokens: 364854398
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 26.527737095952034,
    "estimated_duration": 3600.0571566992116,
    "input_throughput": 5427.146611725982,
    "output_throughput": 4703.4225466367325,
    "total_throughput": 10130.569158362714,
    "itl": 111.36729241866358,
    "ttft": 2056301.47880726,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 772,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.650261872243144,
    "arrivals": 619780,
    "finished_requests": 78858,
    "scheduler_time": 179.52548314754333
}
#Debug simulation 
Total elapsed time: 26.52783965598792. Arrivals time: 0.34259169083088636 Scheduler time: 26.02577177947387 Scheduler overhead time: 0.05756674101576209 Adapter cache time: 0.019856613595038652 Engine time: 0.05794518208131194 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-32/adapters_256_slots_64_rate_1.6-0.4-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-32/adapters_256_slots_64_rate_1.6-0.4-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 66, 17280, 17280, 66, 17280, 4320, 17280, 66, 4320, 66, 17280, 4320, 4320, 4320, 4320, 17280, 66, 66, 66, 4320, 17280, 66, 17280, 17280, 4320, 4320, 4320, 66, 17280, 66, 4320, 4320, 66, 4320, 66, 66, 4320, 4320, 17280, 4320, 66, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 66, 17280, 17280, 4320, 66, 66, 17280, 4320, 66, 4320, 4320, 17280, 4320, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 4320, 66, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 66, 17280, 17280, 66, 17280, 66, 4320, 17280, 17280, 17280, 4320, 66, 17280, 4320, 66, 66, 66, 66, 66, 17280, 4320, 66, 17280, 66, 17280, 66, 66, 4320, 4320, 17280, 4320, 17280, 66, 4320, 66, 17280, 17280, 66, 17280, 4320, 66, 17280, 66, 66, 17280, 17280, 4320, 17280, 17280, 66, 17280, 4320, 4320, 66, 4320, 17280, 17280, 66, 17280, 4320, 66, 4320, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 4320, 17280, 17280, 4320, 66, 17280, 66, 4320, 4320, 66, 4320, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 4320, 17280, 4320, 66, 4320, 17280, 4320, 17280, 66, 17280, 66, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 66, 17280, 66, 17280, 4320, 4320, 66, 4320, 17280, 4320, 4320, 17280, 66, 17280, 17280, 4320, 66, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 66, 17280, 4320, 17280, 17280, 66, 17280, 4320, 4320, 17280, 66, 4320, 66, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 66, 66, 66, 66]
Prompts retrieved: 1858890 . Total input tokens: 414491744 . Total output tokens: 364854398
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 15.127500782255083,
    "estimated_duration": 3600.0906399747337,
    "input_throughput": 5116.160908695695,
    "output_throughput": 4433.133661354706,
    "total_throughput": 9549.294570050402,
    "itl": 98.76997531134388,
    "ttft": 2090866.3950219676,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1182,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.88973707214927,
    "arrivals": 619780,
    "finished_requests": 74344,
    "scheduler_time": 189.69652860697485
}
#Debug simulation 
Total elapsed time: 15.127632386051118. Arrivals time: 0.3100123256444931 Scheduler time: 14.652217871975154 Scheduler overhead time: 0.057185182347893715 Adapter cache time: 0.024677962996065617 Engine time: 0.05805127788335085 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_8-16-16/adapters_256_slots_64_rate_1.6-0.4-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_8-16-16/adapters_256_slots_64_rate_1.6-0.4-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 66, 17280, 17280, 66, 17280, 4320, 17280, 66, 4320, 66, 17280, 4320, 4320, 4320, 4320, 17280, 66, 66, 66, 4320, 17280, 66, 17280, 17280, 4320, 4320, 4320, 66, 17280, 66, 4320, 4320, 66, 4320, 66, 66, 4320, 4320, 17280, 4320, 66, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 66, 17280, 17280, 4320, 66, 66, 17280, 4320, 66, 4320, 4320, 17280, 4320, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 4320, 66, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 66, 17280, 17280, 66, 17280, 66, 4320, 17280, 17280, 17280, 4320, 66, 17280, 4320, 66, 66, 66, 66, 66, 17280, 4320, 66, 17280, 66, 17280, 66, 66, 4320, 4320, 17280, 4320, 17280, 66, 4320, 66, 17280, 17280, 66, 17280, 4320, 66, 17280, 66, 66, 17280, 17280, 4320, 17280, 17280, 66, 17280, 4320, 4320, 66, 4320, 17280, 17280, 66, 17280, 4320, 66, 4320, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 4320, 17280, 17280, 4320, 66, 17280, 66, 4320, 4320, 66, 4320, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 4320, 17280, 4320, 66, 4320, 17280, 4320, 17280, 66, 17280, 66, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 66, 17280, 66, 17280, 4320, 4320, 66, 4320, 17280, 4320, 4320, 17280, 66, 17280, 17280, 4320, 66, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 66, 17280, 4320, 17280, 17280, 66, 17280, 4320, 4320, 17280, 66, 4320, 66, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 66, 66, 66, 66]
Prompts retrieved: 1858890 . Total input tokens: 414491744 . Total output tokens: 364854398
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 21.594110209029168,
    "estimated_duration": 3600.093159684052,
    "input_throughput": 5439.550625883974,
    "output_throughput": 4706.268768191248,
    "total_throughput": 10145.819394075223,
    "itl": 111.43145407414072,
    "ttft": 2057401.9931126654,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 858,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.902199784843243,
    "arrivals": 619780,
    "finished_requests": 78991,
    "scheduler_time": 179.42543217846196
}
#Debug simulation 
Total elapsed time: 21.594233995769173. Arrivals time: 0.3290884871967137 Scheduler time: 21.108099553268403 Scheduler overhead time: 0.0562449861317873 Adapter cache time: 0.02109126839786768 Engine time: 0.05603727465495467 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_8-16-32/adapters_256_slots_64_rate_1.6-0.4-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_8-16-32/adapters_256_slots_64_rate_1.6-0.4-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 66, 17280, 17280, 66, 17280, 4320, 17280, 66, 4320, 66, 17280, 4320, 4320, 4320, 4320, 17280, 66, 66, 66, 4320, 17280, 66, 17280, 17280, 4320, 4320, 4320, 66, 17280, 66, 4320, 4320, 66, 4320, 66, 66, 4320, 4320, 17280, 4320, 66, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 66, 17280, 17280, 4320, 66, 66, 17280, 4320, 66, 4320, 4320, 17280, 4320, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 4320, 66, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 66, 17280, 17280, 66, 17280, 66, 4320, 17280, 17280, 17280, 4320, 66, 17280, 4320, 66, 66, 66, 66, 66, 17280, 4320, 66, 17280, 66, 17280, 66, 66, 4320, 4320, 17280, 4320, 17280, 66, 4320, 66, 17280, 17280, 66, 17280, 4320, 66, 17280, 66, 66, 17280, 17280, 4320, 17280, 17280, 66, 17280, 4320, 4320, 66, 4320, 17280, 17280, 66, 17280, 4320, 66, 4320, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 4320, 17280, 17280, 4320, 66, 17280, 66, 4320, 4320, 66, 4320, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 4320, 17280, 4320, 66, 4320, 17280, 4320, 17280, 66, 17280, 66, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 66, 17280, 66, 17280, 4320, 4320, 66, 4320, 17280, 4320, 4320, 17280, 66, 17280, 17280, 4320, 66, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 66, 17280, 4320, 17280, 17280, 66, 17280, 4320, 4320, 17280, 66, 4320, 66, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 66, 66, 66, 66]
Prompts retrieved: 1858890 . Total input tokens: 414491744 . Total output tokens: 364854398
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 15.17810711497441,
    "estimated_duration": 3600.0768911341406,
    "input_throughput": 5106.873701858098,
    "output_throughput": 4427.515712026521,
    "total_throughput": 9534.389413884619,
    "itl": 98.51241544264671,
    "ttft": 2093147.7086715153,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1181,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.796794466595138,
    "arrivals": 619780,
    "finished_requests": 74230,
    "scheduler_time": 189.94997905844298
}
#Debug simulation 
Total elapsed time: 15.178201217204332. Arrivals time: 0.30059820506721735 Scheduler time: 14.711394124664366 Scheduler overhead time: 0.058266875334084034 Adapter cache time: 0.02489804569631815 Engine time: 0.05746595049276948 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_16-16-16/adapters_256_slots_64_rate_1.6-0.4-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_16-16-16/adapters_256_slots_64_rate_1.6-0.4-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 66, 17280, 17280, 66, 17280, 4320, 17280, 66, 4320, 66, 17280, 4320, 4320, 4320, 4320, 17280, 66, 66, 66, 4320, 17280, 66, 17280, 17280, 4320, 4320, 4320, 66, 17280, 66, 4320, 4320, 66, 4320, 66, 66, 4320, 4320, 17280, 4320, 66, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 66, 17280, 17280, 4320, 66, 66, 17280, 4320, 66, 4320, 4320, 17280, 4320, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 4320, 66, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 66, 17280, 17280, 66, 17280, 66, 4320, 17280, 17280, 17280, 4320, 66, 17280, 4320, 66, 66, 66, 66, 66, 17280, 4320, 66, 17280, 66, 17280, 66, 66, 4320, 4320, 17280, 4320, 17280, 66, 4320, 66, 17280, 17280, 66, 17280, 4320, 66, 17280, 66, 66, 17280, 17280, 4320, 17280, 17280, 66, 17280, 4320, 4320, 66, 4320, 17280, 17280, 66, 17280, 4320, 66, 4320, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 4320, 17280, 17280, 4320, 66, 17280, 66, 4320, 4320, 66, 4320, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 4320, 17280, 4320, 66, 4320, 17280, 4320, 17280, 66, 17280, 66, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 66, 17280, 66, 17280, 4320, 4320, 66, 4320, 17280, 4320, 4320, 17280, 66, 17280, 17280, 4320, 66, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 66, 17280, 4320, 17280, 17280, 66, 17280, 4320, 4320, 17280, 66, 4320, 66, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 66, 66, 66, 66]
Prompts retrieved: 1858890 . Total input tokens: 414491744 . Total output tokens: 364854398
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 25.62897915299982,
    "estimated_duration": 3600.025310659907,
    "input_throughput": 5433.218467126439,
    "output_throughput": 4709.296890163337,
    "total_throughput": 10142.515357289774,
    "itl": 111.50356205685121,
    "ttft": 2057369.3980504854,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 761,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.858163835774152,
    "arrivals": 619780,
    "finished_requests": 78949,
    "scheduler_time": 179.4405730935151
}
#Debug simulation 
Total elapsed time: 25.629090833012015. Arrivals time: 0.38969489373266697 Scheduler time: 25.08161996025592 Scheduler overhead time: 0.057264664210379124 Adapter cache time: 0.01983600575476885 Engine time: 0.05672177718952298 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_16-16-32/adapters_256_slots_64_rate_1.6-0.4-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_16-16-32/adapters_256_slots_64_rate_1.6-0.4-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 66, 17280, 17280, 66, 17280, 4320, 17280, 66, 4320, 66, 17280, 4320, 4320, 4320, 4320, 17280, 66, 66, 66, 4320, 17280, 66, 17280, 17280, 4320, 4320, 4320, 66, 17280, 66, 4320, 4320, 66, 4320, 66, 66, 4320, 4320, 17280, 4320, 66, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 66, 17280, 17280, 4320, 66, 66, 17280, 4320, 66, 4320, 4320, 17280, 4320, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 4320, 66, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 66, 17280, 17280, 66, 17280, 66, 4320, 17280, 17280, 17280, 4320, 66, 17280, 4320, 66, 66, 66, 66, 66, 17280, 4320, 66, 17280, 66, 17280, 66, 66, 4320, 4320, 17280, 4320, 17280, 66, 4320, 66, 17280, 17280, 66, 17280, 4320, 66, 17280, 66, 66, 17280, 17280, 4320, 17280, 17280, 66, 17280, 4320, 4320, 66, 4320, 17280, 17280, 66, 17280, 4320, 66, 4320, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 4320, 17280, 17280, 4320, 66, 17280, 66, 4320, 4320, 66, 4320, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 4320, 17280, 4320, 66, 4320, 17280, 4320, 17280, 66, 17280, 66, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 66, 17280, 66, 17280, 4320, 4320, 66, 4320, 17280, 4320, 4320, 17280, 66, 17280, 17280, 4320, 66, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 66, 17280, 4320, 17280, 17280, 66, 17280, 4320, 4320, 17280, 66, 4320, 66, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 66, 66, 66, 66]
Prompts retrieved: 1858890 . Total input tokens: 414491744 . Total output tokens: 364854398
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 14.878212560899556,
    "estimated_duration": 3600.0815242668964,
    "input_throughput": 5124.707558881446,
    "output_throughput": 4440.261114157734,
    "total_throughput": 9564.968673039179,
    "itl": 99.08619197357162,
    "ttft": 2091056.6674622814,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1198,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.841350729055678,
    "arrivals": 619780,
    "finished_requests": 74413,
    "scheduler_time": 189.41442735514727
}
#Debug simulation 
Total elapsed time: 14.878344077151269. Arrivals time: 0.3133676606230438 Scheduler time: 14.398362343199551 Scheduler overhead time: 0.05785232037305832 Adapter cache time: 0.025455453898757696 Engine time: 0.057860791217535734 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-8/adapters_256_slots_64_rate_1.6-0.4-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-8/adapters_256_slots_64_rate_1.6-0.4-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 33, 17280, 17280, 33, 17280, 4320, 17280, 33, 4320, 33, 17280, 4320, 4320, 4320, 4320, 17280, 33, 33, 33, 4320, 17280, 33, 17280, 17280, 4320, 4320, 4320, 33, 17280, 33, 4320, 4320, 33, 4320, 33, 33, 4320, 4320, 17280, 4320, 33, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 33, 17280, 17280, 4320, 33, 33, 17280, 4320, 33, 4320, 4320, 17280, 4320, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 4320, 33, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 33, 17280, 17280, 33, 17280, 33, 4320, 17280, 17280, 17280, 4320, 33, 17280, 4320, 33, 33, 33, 33, 33, 17280, 4320, 33, 17280, 33, 17280, 33, 33, 4320, 4320, 17280, 4320, 17280, 33, 4320, 33, 17280, 17280, 33, 17280, 4320, 33, 17280, 33, 33, 17280, 17280, 4320, 17280, 17280, 33, 17280, 4320, 4320, 33, 4320, 17280, 17280, 33, 17280, 4320, 33, 4320, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 4320, 17280, 17280, 4320, 33, 17280, 33, 4320, 4320, 33, 4320, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 4320, 17280, 4320, 33, 4320, 17280, 4320, 17280, 33, 17280, 33, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 33, 17280, 33, 17280, 4320, 4320, 33, 4320, 17280, 4320, 4320, 17280, 33, 17280, 17280, 4320, 33, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 33, 17280, 4320, 17280, 17280, 33, 17280, 4320, 4320, 17280, 33, 4320, 33, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 33, 33, 33, 33]
Prompts retrieved: 1856085 . Total input tokens: 413859425 . Total output tokens: 364317658
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 43.36095224367455,
    "estimated_duration": 3600.094489440281,
    "input_throughput": 5579.675494329331,
    "output_throughput": 4848.262191783101,
    "total_throughput": 10427.937686112431,
    "itl": 119.34177886433201,
    "ttft": 2028562.864044104,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 446,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.9491344282497,
    "arrivals": 618816,
    "finished_requests": 81359,
    "scheduler_time": 174.28671642767088
}
#Debug simulation 
Total elapsed time: 43.36110805068165. Arrivals time: 0.4038321548141539 Scheduler time: 42.79654802335426 Scheduler overhead time: 0.06131292041391134 Adapter cache time: 0.015798314940184355 Engine time: 0.05943654337897897 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-16/adapters_256_slots_64_rate_1.6-0.4-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-16/adapters_256_slots_64_rate_1.6-0.4-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 33, 17280, 17280, 33, 17280, 4320, 17280, 33, 4320, 33, 17280, 4320, 4320, 4320, 4320, 17280, 33, 33, 33, 4320, 17280, 33, 17280, 17280, 4320, 4320, 4320, 33, 17280, 33, 4320, 4320, 33, 4320, 33, 33, 4320, 4320, 17280, 4320, 33, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 33, 17280, 17280, 4320, 33, 33, 17280, 4320, 33, 4320, 4320, 17280, 4320, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 4320, 33, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 33, 17280, 17280, 33, 17280, 33, 4320, 17280, 17280, 17280, 4320, 33, 17280, 4320, 33, 33, 33, 33, 33, 17280, 4320, 33, 17280, 33, 17280, 33, 33, 4320, 4320, 17280, 4320, 17280, 33, 4320, 33, 17280, 17280, 33, 17280, 4320, 33, 17280, 33, 33, 17280, 17280, 4320, 17280, 17280, 33, 17280, 4320, 4320, 33, 4320, 17280, 17280, 33, 17280, 4320, 33, 4320, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 4320, 17280, 17280, 4320, 33, 17280, 33, 4320, 4320, 33, 4320, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 4320, 17280, 4320, 33, 4320, 17280, 4320, 17280, 33, 17280, 33, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 33, 17280, 33, 17280, 4320, 4320, 33, 4320, 17280, 4320, 4320, 17280, 33, 17280, 17280, 4320, 33, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 33, 17280, 4320, 17280, 17280, 33, 17280, 4320, 4320, 17280, 33, 4320, 33, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 33, 33, 33, 33]
Prompts retrieved: 1856085 . Total input tokens: 413859425 . Total output tokens: 364317658
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 50.09336614375934,
    "estimated_duration": 3600.02461485626,
    "input_throughput": 5424.047357737206,
    "output_throughput": 4702.830900137049,
    "total_throughput": 10126.878257874256,
    "itl": 111.09222789527888,
    "ttft": 2036051.2251689653,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 382,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.788489484572786,
    "arrivals": 618816,
    "finished_requests": 78998,
    "scheduler_time": 179.85278963768727
}
#Debug simulation 
Total elapsed time: 50.093539570923895. Arrivals time: 0.37712840363383293 Scheduler time: 49.548936418257654 Scheduler overhead time: 0.06377226859331131 Adapter cache time: 0.015905865468084812 Engine time: 0.06251777336001396 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-32/adapters_256_slots_64_rate_1.6-0.4-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-32/adapters_256_slots_64_rate_1.6-0.4-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 33, 17280, 17280, 33, 17280, 4320, 17280, 33, 4320, 33, 17280, 4320, 4320, 4320, 4320, 17280, 33, 33, 33, 4320, 17280, 33, 17280, 17280, 4320, 4320, 4320, 33, 17280, 33, 4320, 4320, 33, 4320, 33, 33, 4320, 4320, 17280, 4320, 33, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 33, 17280, 17280, 4320, 33, 33, 17280, 4320, 33, 4320, 4320, 17280, 4320, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 4320, 33, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 33, 17280, 17280, 33, 17280, 33, 4320, 17280, 17280, 17280, 4320, 33, 17280, 4320, 33, 33, 33, 33, 33, 17280, 4320, 33, 17280, 33, 17280, 33, 33, 4320, 4320, 17280, 4320, 17280, 33, 4320, 33, 17280, 17280, 33, 17280, 4320, 33, 17280, 33, 33, 17280, 17280, 4320, 17280, 17280, 33, 17280, 4320, 4320, 33, 4320, 17280, 17280, 33, 17280, 4320, 33, 4320, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 4320, 17280, 17280, 4320, 33, 17280, 33, 4320, 4320, 33, 4320, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 4320, 17280, 4320, 33, 4320, 17280, 4320, 17280, 33, 17280, 33, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 33, 17280, 33, 17280, 4320, 4320, 33, 4320, 17280, 4320, 4320, 17280, 33, 17280, 17280, 4320, 33, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 33, 17280, 4320, 17280, 17280, 33, 17280, 4320, 4320, 17280, 33, 4320, 33, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 33, 33, 33, 33]
Prompts retrieved: 1856085 . Total input tokens: 413859425 . Total output tokens: 364317658
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 16.851284206844866,
    "estimated_duration": 3600.036195415203,
    "input_throughput": 5088.503283197473,
    "output_throughput": 4438.660928006879,
    "total_throughput": 9527.164211204352,
    "itl": 99.05202172627205,
    "ttft": 2086182.6577143783,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 934,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.025284193442224,
    "arrivals": 618816,
    "finished_requests": 74261,
    "scheduler_time": 189.593946090851
}
#Debug simulation 
Total elapsed time: 16.85137931490317. Arrivals time: 0.302058944478631 Scheduler time: 16.38434528466314 Scheduler overhead time: 0.05902893887832761 Adapter cache time: 0.021516216918826103 Engine time: 0.05875655869022012 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_8-16-16/adapters_256_slots_64_rate_1.6-0.4-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_8-16-16/adapters_256_slots_64_rate_1.6-0.4-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 33, 17280, 17280, 33, 17280, 4320, 17280, 33, 4320, 33, 17280, 4320, 4320, 4320, 4320, 17280, 33, 33, 33, 4320, 17280, 33, 17280, 17280, 4320, 4320, 4320, 33, 17280, 33, 4320, 4320, 33, 4320, 33, 33, 4320, 4320, 17280, 4320, 33, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 33, 17280, 17280, 4320, 33, 33, 17280, 4320, 33, 4320, 4320, 17280, 4320, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 4320, 33, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 33, 17280, 17280, 33, 17280, 33, 4320, 17280, 17280, 17280, 4320, 33, 17280, 4320, 33, 33, 33, 33, 33, 17280, 4320, 33, 17280, 33, 17280, 33, 33, 4320, 4320, 17280, 4320, 17280, 33, 4320, 33, 17280, 17280, 33, 17280, 4320, 33, 17280, 33, 33, 17280, 17280, 4320, 17280, 17280, 33, 17280, 4320, 4320, 33, 4320, 17280, 17280, 33, 17280, 4320, 33, 4320, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 4320, 17280, 17280, 4320, 33, 17280, 33, 4320, 4320, 33, 4320, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 4320, 17280, 4320, 33, 4320, 17280, 4320, 17280, 33, 17280, 33, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 33, 17280, 33, 17280, 4320, 4320, 33, 4320, 17280, 4320, 4320, 17280, 33, 17280, 17280, 4320, 33, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 33, 17280, 4320, 17280, 17280, 33, 17280, 4320, 4320, 17280, 33, 4320, 33, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 33, 33, 33, 33]
Prompts retrieved: 1856085 . Total input tokens: 413859425 . Total output tokens: 364317658
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 25.667886996176094,
    "estimated_duration": 3600.0758276685865,
    "input_throughput": 5393.180846575038,
    "output_throughput": 4707.56001019436,
    "total_throughput": 10100.740856769398,
    "itl": 111.62960669695141,
    "ttft": 2053471.65347247,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 728,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.990385025143616,
    "arrivals": 618816,
    "finished_requests": 78903,
    "scheduler_time": 179.42374442727782
}
#Debug simulation 
Total elapsed time: 25.66802862798795. Arrivals time: 0.3542846590280533 Scheduler time: 25.155420859344304 Scheduler overhead time: 0.05791744124144316 Adapter cache time: 0.01887408271431923 Engine time: 0.05720835272222757 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_8-16-32/adapters_256_slots_64_rate_1.6-0.4-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_8-16-32/adapters_256_slots_64_rate_1.6-0.4-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 33, 17280, 17280, 33, 17280, 4320, 17280, 33, 4320, 33, 17280, 4320, 4320, 4320, 4320, 17280, 33, 33, 33, 4320, 17280, 33, 17280, 17280, 4320, 4320, 4320, 33, 17280, 33, 4320, 4320, 33, 4320, 33, 33, 4320, 4320, 17280, 4320, 33, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 33, 17280, 17280, 4320, 33, 33, 17280, 4320, 33, 4320, 4320, 17280, 4320, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 4320, 33, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 33, 17280, 17280, 33, 17280, 33, 4320, 17280, 17280, 17280, 4320, 33, 17280, 4320, 33, 33, 33, 33, 33, 17280, 4320, 33, 17280, 33, 17280, 33, 33, 4320, 4320, 17280, 4320, 17280, 33, 4320, 33, 17280, 17280, 33, 17280, 4320, 33, 17280, 33, 33, 17280, 17280, 4320, 17280, 17280, 33, 17280, 4320, 4320, 33, 4320, 17280, 17280, 33, 17280, 4320, 33, 4320, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 4320, 17280, 17280, 4320, 33, 17280, 33, 4320, 4320, 33, 4320, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 4320, 17280, 4320, 33, 4320, 17280, 4320, 17280, 33, 17280, 33, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 33, 17280, 33, 17280, 4320, 4320, 33, 4320, 17280, 4320, 4320, 17280, 33, 17280, 17280, 4320, 33, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 33, 17280, 4320, 17280, 17280, 33, 17280, 4320, 4320, 17280, 33, 4320, 33, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 33, 33, 33, 33]
Prompts retrieved: 1856085 . Total input tokens: 413859425 . Total output tokens: 364317658
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 16.385974435135722,
    "estimated_duration": 3600.0929505571185,
    "input_throughput": 5097.2242250468125,
    "output_throughput": 4446.434639284191,
    "total_throughput": 9543.658864331004,
    "itl": 99.3549798626315,
    "ttft": 2087154.6887493574,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 956,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.120575964101611,
    "arrivals": 618816,
    "finished_requests": 74445,
    "scheduler_time": 189.32296520585143
}
#Debug simulation 
Total elapsed time: 16.3861194238998. Arrivals time: 0.2991696521639824 Scheduler time: 15.92409664299339 Scheduler overhead time: 0.058193594217300415 Adapter cache time: 0.021395544055849314 Engine time: 0.057732618413865566 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_16-16-16/adapters_256_slots_64_rate_1.6-0.4-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_16-16-16/adapters_256_slots_64_rate_1.6-0.4-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 33, 17280, 17280, 33, 17280, 4320, 17280, 33, 4320, 33, 17280, 4320, 4320, 4320, 4320, 17280, 33, 33, 33, 4320, 17280, 33, 17280, 17280, 4320, 4320, 4320, 33, 17280, 33, 4320, 4320, 33, 4320, 33, 33, 4320, 4320, 17280, 4320, 33, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 33, 17280, 17280, 4320, 33, 33, 17280, 4320, 33, 4320, 4320, 17280, 4320, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 4320, 33, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 33, 17280, 17280, 33, 17280, 33, 4320, 17280, 17280, 17280, 4320, 33, 17280, 4320, 33, 33, 33, 33, 33, 17280, 4320, 33, 17280, 33, 17280, 33, 33, 4320, 4320, 17280, 4320, 17280, 33, 4320, 33, 17280, 17280, 33, 17280, 4320, 33, 17280, 33, 33, 17280, 17280, 4320, 17280, 17280, 33, 17280, 4320, 4320, 33, 4320, 17280, 17280, 33, 17280, 4320, 33, 4320, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 4320, 17280, 17280, 4320, 33, 17280, 33, 4320, 4320, 33, 4320, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 4320, 17280, 4320, 33, 4320, 17280, 4320, 17280, 33, 17280, 33, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 33, 17280, 33, 17280, 4320, 4320, 33, 4320, 17280, 4320, 4320, 17280, 33, 17280, 17280, 4320, 33, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 33, 17280, 4320, 17280, 17280, 33, 17280, 4320, 4320, 17280, 33, 4320, 33, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 33, 33, 33, 33]
Prompts retrieved: 1856085 . Total input tokens: 413859425 . Total output tokens: 364317658
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 25.503181421663612,
    "estimated_duration": 3600.0233601691452,
    "input_throughput": 5392.163621707149,
    "output_throughput": 4709.864715767663,
    "total_throughput": 10102.028337474812,
    "itl": 111.60827031640424,
    "ttft": 2051903.9237905454,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 774,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.941154808001569,
    "arrivals": 618816,
    "finished_requests": 78880,
    "scheduler_time": 179.46200685487443
}
#Debug simulation 
Total elapsed time: 25.503277463838458. Arrivals time: 0.3203183878213167 Scheduler time: 25.0251726526767 Scheduler overhead time: 0.057946191634982824 Adapter cache time: 0.019196278415620327 Engine time: 0.05670877266675234 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_16-16-32/adapters_256_slots_64_rate_1.6-0.4-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 215104,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_16-16-32/adapters_256_slots_64_rate_1.6-0.4-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 33, 17280, 17280, 33, 17280, 4320, 17280, 33, 4320, 33, 17280, 4320, 4320, 4320, 4320, 17280, 33, 33, 33, 4320, 17280, 33, 17280, 17280, 4320, 4320, 4320, 33, 17280, 33, 4320, 4320, 33, 4320, 33, 33, 4320, 4320, 17280, 4320, 33, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 33, 17280, 17280, 4320, 33, 33, 17280, 4320, 33, 4320, 4320, 17280, 4320, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 4320, 33, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 33, 17280, 17280, 33, 17280, 33, 4320, 17280, 17280, 17280, 4320, 33, 17280, 4320, 33, 33, 33, 33, 33, 17280, 4320, 33, 17280, 33, 17280, 33, 33, 4320, 4320, 17280, 4320, 17280, 33, 4320, 33, 17280, 17280, 33, 17280, 4320, 33, 17280, 33, 33, 17280, 17280, 4320, 17280, 17280, 33, 17280, 4320, 4320, 33, 4320, 17280, 17280, 33, 17280, 4320, 33, 4320, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 4320, 17280, 17280, 4320, 33, 17280, 33, 4320, 4320, 33, 4320, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 4320, 17280, 4320, 33, 4320, 17280, 4320, 17280, 33, 17280, 33, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 33, 17280, 33, 17280, 4320, 4320, 33, 4320, 17280, 4320, 4320, 17280, 33, 17280, 17280, 4320, 33, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 33, 17280, 4320, 17280, 17280, 33, 17280, 4320, 4320, 17280, 33, 4320, 33, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 33, 33, 33, 33]
Prompts retrieved: 1856085 . Total input tokens: 413859425 . Total output tokens: 364317658
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 19.39766917191446,
    "estimated_duration": 3600.0146772286953,
    "input_throughput": 5095.725335798299,
    "output_throughput": 4446.22215049463,
    "total_throughput": 9541.94748629293,
    "itl": 99.18918675830784,
    "ttft": 2087681.180043793,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 858,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.326586368382003,
    "arrivals": 618816,
    "finished_requests": 74441,
    "scheduler_time": 189.46980164570064
}
#Debug simulation 
Total elapsed time: 19.397769348695874. Arrivals time: 0.3083070032298565 Scheduler time: 18.923417527694255 Scheduler overhead time: 0.06047098571434617 Adapter cache time: 0.020606346894055605 Engine time: 0.05921220639720559 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_8-8-8/adapters_256_slots_64_rate_1.6-0.1-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 282640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_8-8-8/adapters_256_slots_64_rate_1.6-0.1-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 540, 17280, 17280, 540, 17280, 1080, 17280, 540, 1080, 540, 17280, 1080, 1080, 1080, 1080, 17280, 540, 540, 540, 1080, 17280, 540, 17280, 17280, 1080, 1080, 1080, 540, 17280, 540, 1080, 1080, 540, 1080, 540, 540, 1080, 1080, 17280, 1080, 540, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 540, 17280, 17280, 1080, 540, 540, 17280, 1080, 540, 1080, 1080, 17280, 1080, 540, 540, 17280, 17280, 17280, 17280, 17280, 17280, 540, 1080, 540, 1080, 540, 540, 540, 1080, 1080, 1080, 540, 540, 17280, 17280, 540, 17280, 540, 1080, 17280, 17280, 17280, 1080, 540, 17280, 1080, 540, 540, 540, 540, 540, 17280, 1080, 540, 17280, 540, 17280, 540, 540, 1080, 1080, 17280, 1080, 17280, 540, 1080, 540, 17280, 17280, 540, 17280, 1080, 540, 17280, 540, 540, 17280, 17280, 1080, 17280, 17280, 540, 17280, 1080, 1080, 540, 1080, 17280, 17280, 540, 17280, 1080, 540, 1080, 17280, 540, 540, 540, 540, 540, 540, 17280, 540, 540, 540, 17280, 540, 1080, 17280, 17280, 1080, 540, 17280, 540, 1080, 1080, 540, 1080, 540, 17280, 540, 540, 17280, 540, 17280, 17280, 1080, 17280, 1080, 540, 1080, 17280, 1080, 17280, 540, 17280, 540, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 540, 17280, 540, 17280, 1080, 1080, 540, 1080, 17280, 1080, 1080, 17280, 540, 17280, 17280, 1080, 540, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 540, 17280, 1080, 17280, 17280, 540, 17280, 1080, 1080, 17280, 540, 1080, 540, 540, 540, 540, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 540, 540, 540, 540]
Prompts retrieved: 1623780 . Total input tokens: 361899243 . Total output tokens: 318860863
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 66.52891127904877,
    "estimated_duration": 3600.1121369003395,
    "input_throughput": 5558.267975849426,
    "output_throughput": 4845.890165804839,
    "total_throughput": 10404.158141654265,
    "itl": 119.72073128473835,
    "ttft": 2012903.6665954879,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 692,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.575787050109437,
    "arrivals": 541365,
    "finished_requests": 81374,
    "scheduler_time": 173.65360894201228
}
#Debug simulation 
Total elapsed time: 66.52907103905454. Arrivals time: 0.7161945337429643 Scheduler time: 65.64267231756821 Scheduler overhead time: 0.06300316331908107 Adapter cache time: 0.02001785673201084 Engine time: 0.062242051120847464 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_8-8-16/adapters_256_slots_64_rate_1.6-0.1-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 256640,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_8-8-16/adapters_256_slots_64_rate_1.6-0.1-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 540, 17280, 17280, 540, 17280, 1080, 17280, 540, 1080, 540, 17280, 1080, 1080, 1080, 1080, 17280, 540, 540, 540, 1080, 17280, 540, 17280, 17280, 1080, 1080, 1080, 540, 17280, 540, 1080, 1080, 540, 1080, 540, 540, 1080, 1080, 17280, 1080, 540, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 540, 17280, 17280, 1080, 540, 540, 17280, 1080, 540, 1080, 1080, 17280, 1080, 540, 540, 17280, 17280, 17280, 17280, 17280, 17280, 540, 1080, 540, 1080, 540, 540, 540, 1080, 1080, 1080, 540, 540, 17280, 17280, 540, 17280, 540, 1080, 17280, 17280, 17280, 1080, 540, 17280, 1080, 540, 540, 540, 540, 540, 17280, 1080, 540, 17280, 540, 17280, 540, 540, 1080, 1080, 17280, 1080, 17280, 540, 1080, 540, 17280, 17280, 540, 17280, 1080, 540, 17280, 540, 540, 17280, 17280, 1080, 17280, 17280, 540, 17280, 1080, 1080, 540, 1080, 17280, 17280, 540, 17280, 1080, 540, 1080, 17280, 540, 540, 540, 540, 540, 540, 17280, 540, 540, 540, 17280, 540, 1080, 17280, 17280, 1080, 540, 17280, 540, 1080, 1080, 540, 1080, 540, 17280, 540, 540, 17280, 540, 17280, 17280, 1080, 17280, 1080, 540, 1080, 17280, 1080, 17280, 540, 17280, 540, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 540, 17280, 540, 17280, 1080, 1080, 540, 1080, 17280, 1080, 1080, 17280, 540, 17280, 17280, 1080, 540, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 540, 17280, 1080, 17280, 17280, 540, 17280, 1080, 1080, 17280, 540, 1080, 540, 540, 540, 540, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 540, 540, 540, 540]
Prompts retrieved: 1623780 . Total input tokens: 361899243 . Total output tokens: 318860863
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 34.55543890222907,
    "estimated_duration": 3600.109549721737,
    "input_throughput": 5393.267546955827,
    "output_throughput": 4708.00839971941,
    "total_throughput": 10101.275946675238,
    "itl": 111.61265133408537,
    "ttft": 2025865.1878775917,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 666,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.876390784410766,
    "arrivals": 541365,
    "finished_requests": 78883,
    "scheduler_time": 178.996624277869
}
#Debug simulation 
Total elapsed time: 34.55565416812897. Arrivals time: 0.33252024417743087 Scheduler time: 34.056143234018236 Scheduler overhead time: 0.062265992164611816 Adapter cache time: 0.018797073047608137 Engine time: 0.06098732352256775 
