INFO 05-31 19:30:51 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 05-31 19:30:52 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-8/adapters_96_slots_96_rate_0.1-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-8/adapters_96_slots_96_rate_0.1-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 1080, 270, 270, 270, 270, 1080, 270, 1080, 270, 66, 1080, 66, 66, 1080, 270, 1080, 270, 1080, 1080, 270, 66, 1080, 270, 66, 66, 270, 1080, 66, 270, 66, 66, 270, 270, 270, 66, 66, 1080, 270, 270, 66, 1080, 1080, 270, 1080, 1080, 270, 1080, 66, 1080, 270, 270, 270, 1080, 1080, 66, 66, 270, 66, 1080, 66, 66, 1080, 66, 270, 270, 66, 270, 1080, 1080, 1080, 270, 1080, 1080, 66, 66, 1080, 270, 1080, 66, 270, 1080, 66, 1080, 270, 66, 1080, 66, 66, 1080, 66, 66, 270]
Prompts retrieved: 45312 . Total input tokens: 10038919 . Total output tokens: 8932037
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 1.5918934387154877,
    "estimated_duration": 3599.7479140676696,
    "input_throughput": 1052.9092843385006,
    "output_throughput": 911.009070158559,
    "total_throughput": 1963.9183544970595,
    "itl": 25.454768943740742,
    "ttft": 6602.511435483865,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6347912670671934,
    "arrivals": 15365,
    "finished_requests": 15337,
    "scheduler_time": 1.6679720180528082e-06
}
#Debug simulation 
Total elapsed time: 1.592027838807553. Arrivals time: 0.04931822931393981 Scheduler time: 1.1581964092329144 Scheduler overhead time: 0.11984292417764664 Adapter cache time: 0.08171562291681767 Engine time: 0.12263947492465377 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-16/adapters_96_slots_96_rate_0.1-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-16/adapters_96_slots_96_rate_0.1-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 1080, 270, 270, 270, 270, 1080, 270, 1080, 270, 66, 1080, 66, 66, 1080, 270, 1080, 270, 1080, 1080, 270, 66, 1080, 270, 66, 66, 270, 1080, 66, 270, 66, 66, 270, 270, 270, 66, 66, 1080, 270, 270, 66, 1080, 1080, 270, 1080, 1080, 270, 1080, 66, 1080, 270, 270, 270, 1080, 1080, 66, 66, 270, 66, 1080, 66, 66, 1080, 66, 270, 270, 66, 270, 1080, 1080, 1080, 270, 1080, 1080, 66, 66, 1080, 270, 1080, 66, 270, 1080, 66, 1080, 270, 66, 1080, 66, 66, 1080, 66, 66, 270]
Prompts retrieved: 45312 . Total input tokens: 10038919 . Total output tokens: 8932037
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.4899091268889606,
    "estimated_duration": 3599.748339805547,
    "input_throughput": 1052.9091598121943,
    "output_throughput": 911.0089624146194,
    "total_throughput": 1963.9181222268137,
    "itl": 25.455294365345082,
    "ttft": 6602.542574756657,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7017025525867944,
    "arrivals": 15365,
    "finished_requests": 15337,
    "scheduler_time": 1.6679720180528082e-06
}
#Debug simulation 
Total elapsed time: 1.4900077190250158. Arrivals time: 0.049783103633672 Scheduler time: 1.0628032945096493 Scheduler overhead time: 0.11966742156073451 Adapter cache time: 0.08168220659717917 Engine time: 0.11723120557144284 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-32/adapters_96_slots_96_rate_0.1-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-32/adapters_96_slots_96_rate_0.1-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 1080, 270, 270, 270, 270, 1080, 270, 1080, 270, 66, 1080, 66, 66, 1080, 270, 1080, 270, 1080, 1080, 270, 66, 1080, 270, 66, 66, 270, 1080, 66, 270, 66, 66, 270, 270, 270, 66, 66, 1080, 270, 270, 66, 1080, 1080, 270, 1080, 1080, 270, 1080, 66, 1080, 270, 270, 270, 1080, 1080, 66, 66, 270, 66, 1080, 66, 66, 1080, 66, 270, 270, 66, 270, 1080, 1080, 1080, 270, 1080, 1080, 66, 66, 1080, 270, 1080, 66, 270, 1080, 66, 1080, 270, 66, 1080, 66, 66, 1080, 66, 66, 270]
Prompts retrieved: 45312 . Total input tokens: 10038919 . Total output tokens: 8932037
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.4853854225948453,
    "estimated_duration": 3599.7482836574136,
    "input_throughput": 1052.9091762352548,
    "output_throughput": 911.0089766243498,
    "total_throughput": 1963.9181528596048,
    "itl": 25.45547577523215,
    "ttft": 6602.509574822759,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.720621239244938,
    "arrivals": 15365,
    "finished_requests": 15337,
    "scheduler_time": 1.6679720180528082e-06
}
#Debug simulation 
Total elapsed time: 1.4854779709130526. Arrivals time: 0.04732469981536269 Scheduler time: 1.0578743712976575 Scheduler overhead time: 0.11944490019232035 Adapter cache time: 0.08241958264261484 Engine time: 0.11950572626665235 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-16/adapters_96_slots_96_rate_0.1-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-16/adapters_96_slots_96_rate_0.1-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 1080, 270, 270, 270, 270, 1080, 270, 1080, 270, 66, 1080, 66, 66, 1080, 270, 1080, 270, 1080, 1080, 270, 66, 1080, 270, 66, 66, 270, 1080, 66, 270, 66, 66, 270, 270, 270, 66, 66, 1080, 270, 270, 66, 1080, 1080, 270, 1080, 1080, 270, 1080, 66, 1080, 270, 270, 270, 1080, 1080, 66, 66, 270, 66, 1080, 66, 66, 1080, 66, 270, 270, 66, 270, 1080, 1080, 1080, 270, 1080, 1080, 66, 66, 1080, 270, 1080, 66, 270, 1080, 66, 1080, 270, 66, 1080, 66, 66, 1080, 66, 66, 270]
Prompts retrieved: 45312 . Total input tokens: 10038919 . Total output tokens: 8932037
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 1.4977675080299377,
    "estimated_duration": 3599.7483376515193,
    "input_throughput": 1052.9091604422372,
    "output_throughput": 911.0089629597516,
    "total_throughput": 1963.9181234019886,
    "itl": 25.45501772680432,
    "ttft": 6602.529828523965,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6572794814407825,
    "arrivals": 15365,
    "finished_requests": 15337,
    "scheduler_time": 1.6679720180528082e-06
}
#Debug simulation 
Total elapsed time: 1.4978588069789112. Arrivals time: 0.047938084695488214 Scheduler time: 1.0683398498222232 Scheduler overhead time: 0.11939261294901371 Adapter cache time: 0.0831136261112988 Engine time: 0.12013103999197483 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-32/adapters_96_slots_96_rate_0.1-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-32/adapters_96_slots_96_rate_0.1-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 1080, 270, 270, 270, 270, 1080, 270, 1080, 270, 66, 1080, 66, 66, 1080, 270, 1080, 270, 1080, 1080, 270, 66, 1080, 270, 66, 66, 270, 1080, 66, 270, 66, 66, 270, 270, 270, 66, 66, 1080, 270, 270, 66, 1080, 1080, 270, 1080, 1080, 270, 1080, 66, 1080, 270, 270, 270, 1080, 1080, 66, 66, 270, 66, 1080, 66, 66, 1080, 66, 270, 270, 66, 270, 1080, 1080, 1080, 270, 1080, 1080, 66, 66, 1080, 270, 1080, 66, 270, 1080, 66, 1080, 270, 66, 1080, 66, 66, 1080, 66, 66, 270]
Prompts retrieved: 45312 . Total input tokens: 10038919 . Total output tokens: 8932037
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 1.4909316250123084,
    "estimated_duration": 3599.743806013019,
    "input_throughput": 1052.9104859264787,
    "output_throughput": 911.0101098089477,
    "total_throughput": 1963.9205957354266,
    "itl": 25.455704388456347,
    "ttft": 6602.4005465103555,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7139934895932676,
    "arrivals": 15365,
    "finished_requests": 15337,
    "scheduler_time": 1.6679720180528082e-06
}
#Debug simulation 
Total elapsed time: 1.4910238310694695. Arrivals time: 0.04720490472391248 Scheduler time: 1.0647270777262747 Scheduler overhead time: 0.11844453308731318 Adapter cache time: 0.08264177944511175 Engine time: 0.11938951490446925 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-16/adapters_96_slots_96_rate_0.1-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-16/adapters_96_slots_96_rate_0.1-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 1080, 270, 270, 270, 270, 1080, 270, 1080, 270, 66, 1080, 66, 66, 1080, 270, 1080, 270, 1080, 1080, 270, 66, 1080, 270, 66, 66, 270, 1080, 66, 270, 66, 66, 270, 270, 270, 66, 66, 1080, 270, 270, 66, 1080, 1080, 270, 1080, 1080, 270, 1080, 66, 1080, 270, 270, 270, 1080, 1080, 66, 66, 270, 66, 1080, 66, 66, 1080, 66, 270, 270, 66, 270, 1080, 1080, 1080, 270, 1080, 1080, 66, 66, 1080, 270, 1080, 66, 270, 1080, 66, 1080, 270, 66, 1080, 66, 66, 1080, 66, 66, 270]
Prompts retrieved: 45312 . Total input tokens: 10038919 . Total output tokens: 8932037
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 1.503420111257583,
    "estimated_duration": 3599.744375949505,
    "input_throughput": 1052.910319222391,
    "output_throughput": 911.0099655715113,
    "total_throughput": 1963.9202847939023,
    "itl": 25.454678735708942,
    "ttft": 6602.568033718554,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6128564102947712,
    "arrivals": 15365,
    "finished_requests": 15337,
    "scheduler_time": 1.6679720180528082e-06
}
#Debug simulation 
Total elapsed time: 1.5035094823688269. Arrivals time: 0.04744094982743263 Scheduler time: 1.0697714006528258 Scheduler overhead time: 0.12363492604345083 Adapter cache time: 0.08299513859674335 Engine time: 0.11963347299024463 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-32/adapters_96_slots_96_rate_0.1-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-32/adapters_96_slots_96_rate_0.1-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 1080, 270, 270, 270, 270, 1080, 270, 1080, 270, 66, 1080, 66, 66, 1080, 270, 1080, 270, 1080, 1080, 270, 66, 1080, 270, 66, 66, 270, 1080, 66, 270, 66, 66, 270, 270, 270, 66, 66, 1080, 270, 270, 66, 1080, 1080, 270, 1080, 1080, 270, 1080, 66, 1080, 270, 270, 270, 1080, 1080, 66, 66, 270, 66, 1080, 66, 66, 1080, 66, 270, 270, 66, 270, 1080, 1080, 1080, 270, 1080, 1080, 66, 66, 1080, 270, 1080, 66, 270, 1080, 66, 1080, 270, 66, 1080, 66, 66, 1080, 66, 66, 270]
Prompts retrieved: 45312 . Total input tokens: 10038919 . Total output tokens: 8932037
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.5221533011645079,
    "estimated_duration": 3599.743707802001,
    "input_throughput": 1052.9105146528045,
    "output_throughput": 911.0101346638368,
    "total_throughput": 1963.9206493166414,
    "itl": 25.45552380850458,
    "ttft": 6602.377337771425,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.707365739941597,
    "arrivals": 15365,
    "finished_requests": 15337,
    "scheduler_time": 1.6679720180528082e-06
}
#Debug simulation 
Total elapsed time: 1.522248612716794. Arrivals time: 0.048202252481132746 Scheduler time: 1.09271335368976 Scheduler overhead time: 0.11928146565333009 Adapter cache time: 0.08364696521311998 Engine time: 0.11953561054542661 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-8/adapters_96_slots_96_rate_0.1-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-8/adapters_96_slots_96_rate_0.1-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 1080, 270, 270, 270, 270, 1080, 270, 1080, 270, 33, 1080, 33, 33, 1080, 270, 1080, 270, 1080, 1080, 270, 33, 1080, 270, 33, 33, 270, 1080, 33, 270, 33, 33, 270, 270, 270, 33, 33, 1080, 270, 270, 33, 1080, 1080, 270, 1080, 1080, 270, 1080, 33, 1080, 270, 270, 270, 1080, 1080, 33, 33, 270, 33, 1080, 33, 33, 1080, 33, 270, 270, 33, 270, 1080, 1080, 1080, 270, 1080, 1080, 33, 33, 1080, 270, 1080, 33, 270, 1080, 33, 1080, 270, 33, 1080, 33, 33, 1080, 33, 33, 270]
Prompts retrieved: 44256 . Total input tokens: 9794058 . Total output tokens: 8729348
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 1.5240594567731023,
    "estimated_duration": 3599.7519957347904,
    "input_throughput": 1016.6383696255119,
    "output_throughput": 896.1634034295487,
    "total_throughput": 1912.8017730550605,
    "itl": 25.282997856705116,
    "ttft": 6760.403918020824,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6347912670671934,
    "arrivals": 15003,
    "finished_requests": 14975,
    "scheduler_time": 3.3359440361056163e-06
}
#Debug simulation 
Total elapsed time: 1.5241531198844314. Arrivals time: 0.04806935368105769 Scheduler time: 1.0923355733975768 Scheduler overhead time: 0.1199087998829782 Adapter cache time: 0.07948347833007574 Engine time: 0.12446686485782266 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-16/adapters_96_slots_96_rate_0.1-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-16/adapters_96_slots_96_rate_0.1-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 1080, 270, 270, 270, 270, 1080, 270, 1080, 270, 33, 1080, 33, 33, 1080, 270, 1080, 270, 1080, 1080, 270, 33, 1080, 270, 33, 33, 270, 1080, 33, 270, 33, 33, 270, 270, 270, 33, 33, 1080, 270, 270, 33, 1080, 1080, 270, 1080, 1080, 270, 1080, 33, 1080, 270, 270, 270, 1080, 1080, 33, 33, 270, 33, 1080, 33, 33, 1080, 33, 270, 270, 33, 270, 1080, 1080, 1080, 270, 1080, 1080, 33, 33, 1080, 270, 1080, 33, 270, 1080, 33, 1080, 270, 33, 1080, 33, 33, 1080, 33, 33, 270]
Prompts retrieved: 44256 . Total input tokens: 9794058 . Total output tokens: 8729348
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.5245714127086103,
    "estimated_duration": 3599.752003278032,
    "input_throughput": 1016.6383674951571,
    "output_throughput": 896.1634015516479,
    "total_throughput": 1912.801769046805,
    "itl": 25.283370815912996,
    "ttft": 6760.525363639762,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7017025525867945,
    "arrivals": 15003,
    "finished_requests": 14975,
    "scheduler_time": 3.3359440361056163e-06
}
#Debug simulation 
Total elapsed time: 1.5246791867539287. Arrivals time: 0.04706511553376913 Scheduler time: 1.088733984157443 Scheduler overhead time: 0.12303902162238955 Adapter cache time: 0.07931265980005264 Engine time: 0.12709569791331887 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-32/adapters_96_slots_96_rate_0.1-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-32/adapters_96_slots_96_rate_0.1-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 1080, 270, 270, 270, 270, 1080, 270, 1080, 270, 33, 1080, 33, 33, 1080, 270, 1080, 270, 1080, 1080, 270, 33, 1080, 270, 33, 33, 270, 1080, 33, 270, 33, 33, 270, 270, 270, 33, 33, 1080, 270, 270, 33, 1080, 1080, 270, 1080, 1080, 270, 1080, 33, 1080, 270, 270, 270, 1080, 1080, 33, 33, 270, 33, 1080, 33, 33, 1080, 33, 270, 270, 33, 270, 1080, 1080, 1080, 270, 1080, 1080, 33, 33, 1080, 270, 1080, 33, 270, 1080, 33, 1080, 270, 33, 1080, 33, 33, 1080, 33, 33, 270]
Prompts retrieved: 44256 . Total input tokens: 9794058 . Total output tokens: 8729348
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.5104133100248873,
    "estimated_duration": 3599.7530787734036,
    "input_throughput": 1016.6380637549186,
    "output_throughput": 896.1631338056194,
    "total_throughput": 1912.801197560538,
    "itl": 25.283807150724197,
    "ttft": 6760.447045635386,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.720621239244938,
    "arrivals": 15003,
    "finished_requests": 14975,
    "scheduler_time": 3.3359440361056163e-06
}
#Debug simulation 
Total elapsed time: 1.5104985912330449. Arrivals time: 0.04700348665937781 Scheduler time: 1.084668988827616 Scheduler overhead time: 0.11945337755605578 Adapter cache time: 0.07924982346594334 Engine time: 0.12100306944921613 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-16/adapters_96_slots_96_rate_0.1-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-16/adapters_96_slots_96_rate_0.1-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 1080, 270, 270, 270, 270, 1080, 270, 1080, 270, 33, 1080, 33, 33, 1080, 270, 1080, 270, 1080, 1080, 270, 33, 1080, 270, 33, 33, 270, 1080, 33, 270, 33, 33, 270, 270, 270, 33, 33, 1080, 270, 270, 33, 1080, 1080, 270, 1080, 1080, 270, 1080, 33, 1080, 270, 270, 270, 1080, 1080, 33, 33, 270, 33, 1080, 33, 33, 1080, 33, 270, 270, 33, 270, 1080, 1080, 1080, 270, 1080, 1080, 33, 33, 1080, 270, 1080, 33, 270, 1080, 33, 1080, 270, 33, 1080, 33, 33, 1080, 33, 33, 270]
Prompts retrieved: 44256 . Total input tokens: 9794058 . Total output tokens: 8729348
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 1.5192527743056417,
    "estimated_duration": 3599.7586755323614,
    "input_throughput": 1016.6364831272424,
    "output_throughput": 896.1617404874837,
    "total_throughput": 1912.798223614726,
    "itl": 25.417337296698893,
    "ttft": 6760.6384813447885,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6572794814407824,
    "arrivals": 15003,
    "finished_requests": 14975,
    "scheduler_time": 3.3359440361056163e-06
}
#Debug simulation 
Total elapsed time: 1.5193427139893174. Arrivals time: 0.04733493598178029 Scheduler time: 1.0926448656246066 Scheduler overhead time: 0.11969920853152871 Adapter cache time: 0.07833378855139017 Engine time: 0.12247152347117662 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-32/adapters_96_slots_96_rate_0.1-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-32/adapters_96_slots_96_rate_0.1-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 1080, 270, 270, 270, 270, 1080, 270, 1080, 270, 33, 1080, 33, 33, 1080, 270, 1080, 270, 1080, 1080, 270, 33, 1080, 270, 33, 33, 270, 1080, 33, 270, 33, 33, 270, 270, 270, 33, 33, 1080, 270, 270, 33, 1080, 1080, 270, 1080, 1080, 270, 1080, 33, 1080, 270, 270, 270, 1080, 1080, 33, 33, 270, 33, 1080, 33, 33, 1080, 33, 270, 270, 33, 270, 1080, 1080, 1080, 270, 1080, 1080, 33, 33, 1080, 270, 1080, 33, 270, 1080, 33, 1080, 270, 33, 1080, 33, 33, 1080, 33, 33, 270]
Prompts retrieved: 44256 . Total input tokens: 9794058 . Total output tokens: 8729348
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 1.5193428890779614,
    "estimated_duration": 3599.7461954235664,
    "input_throughput": 1016.6400077462642,
    "output_throughput": 896.1648474276434,
    "total_throughput": 1912.8048551739078,
    "itl": 25.28397995704171,
    "ttft": 6760.441002018792,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7139934895932676,
    "arrivals": 15003,
    "finished_requests": 14975,
    "scheduler_time": 3.3359440361056163e-06
}
#Debug simulation 
Total elapsed time: 1.519445946905762. Arrivals time: 0.04753873683512211 Scheduler time: 1.0913657336495817 Scheduler overhead time: 0.12023515859618783 Adapter cache time: 0.07999599212780595 Engine time: 0.12088947789743543 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-16/adapters_96_slots_96_rate_0.1-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-16/adapters_96_slots_96_rate_0.1-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 1080, 270, 270, 270, 270, 1080, 270, 1080, 270, 33, 1080, 33, 33, 1080, 270, 1080, 270, 1080, 1080, 270, 33, 1080, 270, 33, 33, 270, 1080, 33, 270, 33, 33, 270, 270, 270, 33, 33, 1080, 270, 270, 33, 1080, 1080, 270, 1080, 1080, 270, 1080, 33, 1080, 270, 270, 270, 1080, 1080, 33, 33, 270, 33, 1080, 33, 33, 1080, 33, 270, 270, 33, 270, 1080, 1080, 1080, 270, 1080, 1080, 33, 33, 1080, 270, 1080, 33, 270, 1080, 33, 1080, 270, 33, 1080, 33, 33, 1080, 33, 33, 270]
Prompts retrieved: 44256 . Total input tokens: 9794058 . Total output tokens: 8729348
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 1.5112874917685986,
    "estimated_duration": 3599.7525958023616,
    "input_throughput": 1016.638200155055,
    "output_throughput": 896.1632540418942,
    "total_throughput": 1912.8014541969492,
    "itl": 25.28315034677137,
    "ttft": 6760.392729309036,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6128564102947712,
    "arrivals": 15003,
    "finished_requests": 14975,
    "scheduler_time": 3.3359440361056163e-06
}
#Debug simulation 
Total elapsed time: 1.511391962878406. Arrivals time: 0.04741655010730028 Scheduler time: 1.0861524031497538 Scheduler overhead time: 0.1190950758755207 Adapter cache time: 0.07917119236662984 Engine time: 0.12045695073902607 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-32/adapters_96_slots_96_rate_0.1-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-32/adapters_96_slots_96_rate_0.1-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 1080, 270, 270, 270, 270, 1080, 270, 1080, 270, 33, 1080, 33, 33, 1080, 270, 1080, 270, 1080, 1080, 270, 33, 1080, 270, 33, 33, 270, 1080, 33, 270, 33, 33, 270, 270, 270, 33, 33, 1080, 270, 270, 33, 1080, 1080, 270, 1080, 1080, 270, 1080, 33, 1080, 270, 270, 270, 1080, 1080, 33, 33, 270, 33, 1080, 33, 33, 1080, 33, 270, 270, 33, 270, 1080, 1080, 1080, 270, 1080, 1080, 33, 33, 1080, 270, 1080, 33, 270, 1080, 33, 1080, 270, 33, 1080, 33, 33, 1080, 33, 33, 270]
Prompts retrieved: 44256 . Total input tokens: 9794058 . Total output tokens: 8729348
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.5100882560946047,
    "estimated_duration": 3599.7519972951945,
    "input_throughput": 1016.6383691848241,
    "output_throughput": 896.1634030410838,
    "total_throughput": 1912.801772225908,
    "itl": 25.2833589544814,
    "ttft": 6760.561085895853,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7073657399415971,
    "arrivals": 15003,
    "finished_requests": 14975,
    "scheduler_time": 3.3359440361056163e-06
}
#Debug simulation 
Total elapsed time: 1.5101799289695919. Arrivals time: 0.04751391941681504 Scheduler time: 1.0798642849549651 Scheduler overhead time: 0.12056926963850856 Adapter cache time: 0.07976153958588839 Engine time: 0.12308783456683159 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-8/adapters_96_slots_96_rate_0.1-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-8/adapters_96_slots_96_rate_0.1-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 1080, 135, 135, 135, 135, 1080, 135, 1080, 135, 66, 1080, 66, 66, 1080, 135, 1080, 135, 1080, 1080, 135, 66, 1080, 135, 66, 66, 135, 1080, 66, 135, 66, 66, 135, 135, 135, 66, 66, 1080, 135, 135, 66, 1080, 1080, 135, 1080, 1080, 135, 1080, 66, 1080, 135, 135, 135, 1080, 1080, 66, 66, 135, 66, 1080, 66, 66, 1080, 66, 135, 135, 66, 135, 1080, 1080, 1080, 135, 1080, 1080, 66, 66, 1080, 135, 1080, 66, 135, 1080, 66, 1080, 135, 66, 1080, 66, 66, 1080, 66, 66, 135]
Prompts retrieved: 40992 . Total input tokens: 9071342 . Total output tokens: 8100246
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 1.4423299618065357,
    "estimated_duration": 3599.929259406674,
    "input_throughput": 938.8273370007917,
    "output_throughput": 833.6841598089197,
    "total_throughput": 1772.5114968097114,
    "itl": 24.812263970584,
    "ttft": 5222.291446125623,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6347912670671934,
    "arrivals": 13896,
    "finished_requests": 13876,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4424043376930058. Arrivals time: 0.04464483633637428 Scheduler time: 1.0130616673268378 Scheduler overhead time: 0.12485828530043364 Adapter cache time: 0.07532777404412627 Engine time: 0.12397346319630742 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-16/adapters_96_slots_96_rate_0.1-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-16/adapters_96_slots_96_rate_0.1-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 1080, 135, 135, 135, 135, 1080, 135, 1080, 135, 66, 1080, 66, 66, 1080, 135, 1080, 135, 1080, 1080, 135, 66, 1080, 135, 66, 66, 135, 1080, 66, 135, 66, 66, 135, 135, 135, 66, 66, 1080, 135, 135, 66, 1080, 1080, 135, 1080, 1080, 135, 1080, 66, 1080, 135, 135, 135, 1080, 1080, 66, 66, 135, 66, 1080, 66, 66, 1080, 66, 135, 135, 66, 135, 1080, 1080, 1080, 135, 1080, 1080, 66, 66, 1080, 135, 1080, 66, 135, 1080, 66, 1080, 135, 66, 1080, 66, 66, 1080, 66, 66, 135]
Prompts retrieved: 40992 . Total input tokens: 9071342 . Total output tokens: 8100246
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.4301934028044343,
    "estimated_duration": 3599.929268607763,
    "input_throughput": 938.8273346012352,
    "output_throughput": 833.6841576780996,
    "total_throughput": 1772.5114922793348,
    "itl": 24.812531380869512,
    "ttft": 5222.2512500510275,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7017025525867943,
    "arrivals": 13896,
    "finished_requests": 13876,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4302725652232766. Arrivals time: 0.0444304496049881 Scheduler time: 1.0033270637504756 Scheduler overhead time: 0.12370177078992128 Adapter cache time: 0.07544140750542283 Engine time: 0.1230069394223392 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-32/adapters_96_slots_96_rate_0.1-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-32/adapters_96_slots_96_rate_0.1-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 1080, 135, 135, 135, 135, 1080, 135, 1080, 135, 66, 1080, 66, 66, 1080, 135, 1080, 135, 1080, 1080, 135, 66, 1080, 135, 66, 66, 135, 1080, 66, 135, 66, 66, 135, 135, 135, 66, 66, 1080, 135, 135, 66, 1080, 1080, 135, 1080, 1080, 135, 1080, 66, 1080, 135, 135, 135, 1080, 1080, 66, 66, 135, 66, 1080, 66, 66, 1080, 66, 135, 135, 66, 135, 1080, 1080, 1080, 135, 1080, 1080, 66, 66, 1080, 135, 1080, 66, 135, 1080, 66, 1080, 135, 66, 1080, 66, 66, 1080, 66, 66, 135]
Prompts retrieved: 40992 . Total input tokens: 9071342 . Total output tokens: 8100246
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.4765512561425567,
    "estimated_duration": 3599.941304821974,
    "input_throughput": 938.8241956814724,
    "output_throughput": 833.681370299013,
    "total_throughput": 1772.5055659804855,
    "itl": 24.8122636973835,
    "ttft": 5222.210465620624,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.720621239244938,
    "arrivals": 13896,
    "finished_requests": 13876,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4766524378210306. Arrivals time: 0.044976584147661924 Scheduler time: 1.0351089709438384 Scheduler overhead time: 0.1260796608403325 Adapter cache time: 0.07582996040582657 Engine time: 0.13386754924431443 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-16/adapters_96_slots_96_rate_0.1-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-16/adapters_96_slots_96_rate_0.1-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 1080, 135, 135, 135, 135, 1080, 135, 1080, 135, 66, 1080, 66, 66, 1080, 135, 1080, 135, 1080, 1080, 135, 66, 1080, 135, 66, 66, 135, 1080, 66, 135, 66, 66, 135, 135, 135, 66, 66, 1080, 135, 135, 66, 1080, 1080, 135, 1080, 1080, 135, 1080, 66, 1080, 135, 135, 135, 1080, 1080, 66, 66, 135, 66, 1080, 66, 66, 1080, 66, 135, 135, 66, 135, 1080, 1080, 1080, 135, 1080, 1080, 66, 66, 1080, 135, 1080, 66, 135, 1080, 66, 1080, 135, 66, 1080, 66, 66, 1080, 66, 66, 135]
Prompts retrieved: 40992 . Total input tokens: 9071342 . Total output tokens: 8100246
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 1.4235771279782057,
    "estimated_duration": 3599.9240631797607,
    "input_throughput": 938.8286921293416,
    "output_throughput": 833.6853631709887,
    "total_throughput": 1772.5140553003303,
    "itl": 24.811640597160757,
    "ttft": 5222.238192069566,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6572794814407827,
    "arrivals": 13896,
    "finished_requests": 13876,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.423652155790478. Arrivals time: 0.04449765011668205 Scheduler time: 0.9975577276200056 Scheduler overhead time: 0.1234730202704668 Adapter cache time: 0.07536639086902142 Engine time: 0.12238919362425804 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-32/adapters_96_slots_96_rate_0.1-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-32/adapters_96_slots_96_rate_0.1-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 1080, 135, 135, 135, 135, 1080, 135, 1080, 135, 66, 1080, 66, 66, 1080, 135, 1080, 135, 1080, 1080, 135, 66, 1080, 135, 66, 66, 135, 1080, 66, 135, 66, 66, 135, 135, 135, 66, 66, 1080, 135, 135, 66, 1080, 1080, 135, 1080, 1080, 135, 1080, 66, 1080, 135, 135, 135, 1080, 1080, 66, 66, 135, 66, 1080, 66, 66, 1080, 66, 135, 135, 66, 135, 1080, 1080, 1080, 135, 1080, 1080, 66, 66, 1080, 135, 1080, 66, 135, 1080, 66, 1080, 135, 66, 1080, 66, 66, 1080, 66, 66, 135]
Prompts retrieved: 40992 . Total input tokens: 9071342 . Total output tokens: 8100246
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 1.3999244081787765,
    "estimated_duration": 3599.935485577145,
    "input_throughput": 938.8257132775149,
    "output_throughput": 833.6827179331643,
    "total_throughput": 1772.5084312106792,
    "itl": 24.81191613023566,
    "ttft": 5222.285798415269,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7139934895932676,
    "arrivals": 13896,
    "finished_requests": 13876,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.400041852146387. Arrivals time: 0.04407972050830722 Scheduler time: 0.9691423228941858 Scheduler overhead time: 0.1257090144790709 Adapter cache time: 0.07695762673392892 Engine time: 0.12349896132946014 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-16/adapters_96_slots_96_rate_0.1-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-16/adapters_96_slots_96_rate_0.1-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 1080, 135, 135, 135, 135, 1080, 135, 1080, 135, 66, 1080, 66, 66, 1080, 135, 1080, 135, 1080, 1080, 135, 66, 1080, 135, 66, 66, 135, 1080, 66, 135, 66, 66, 135, 135, 135, 66, 66, 1080, 135, 135, 66, 1080, 1080, 135, 1080, 1080, 135, 1080, 66, 1080, 135, 135, 135, 1080, 1080, 66, 66, 135, 66, 1080, 66, 66, 1080, 66, 135, 135, 66, 135, 1080, 1080, 1080, 135, 1080, 1080, 66, 66, 1080, 135, 1080, 66, 135, 1080, 66, 1080, 135, 66, 1080, 66, 66, 1080, 66, 66, 135]
Prompts retrieved: 40992 . Total input tokens: 9071342 . Total output tokens: 8100246
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 1.415588506963104,
    "estimated_duration": 3599.923709307584,
    "input_throughput": 938.8287844161175,
    "output_throughput": 833.6854451221849,
    "total_throughput": 1772.5142295383025,
    "itl": 24.811462209787276,
    "ttft": 5222.301068870059,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6128564102947712,
    "arrivals": 13896,
    "finished_requests": 13876,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.415658628102392. Arrivals time: 0.04433949291706085 Scheduler time: 0.9921730747446418 Scheduler overhead time: 0.12244212534278631 Adapter cache time: 0.07513822708278894 Engine time: 0.12148269452154636 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-32/adapters_96_slots_96_rate_0.1-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-32/adapters_96_slots_96_rate_0.1-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 1080, 135, 135, 135, 135, 1080, 135, 1080, 135, 66, 1080, 66, 66, 1080, 135, 1080, 135, 1080, 1080, 135, 66, 1080, 135, 66, 66, 135, 1080, 66, 135, 66, 66, 135, 135, 135, 66, 66, 1080, 135, 135, 66, 1080, 1080, 135, 1080, 1080, 135, 1080, 66, 1080, 135, 135, 135, 1080, 1080, 66, 66, 135, 66, 1080, 66, 66, 1080, 66, 135, 135, 66, 135, 1080, 1080, 1080, 135, 1080, 1080, 66, 66, 1080, 135, 1080, 66, 135, 1080, 66, 1080, 135, 66, 1080, 66, 66, 1080, 66, 66, 135]
Prompts retrieved: 40992 . Total input tokens: 9071342 . Total output tokens: 8100246
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.4340877663344145,
    "estimated_duration": 3599.929570089575,
    "input_throughput": 938.8272559776508,
    "output_throughput": 833.6840878598974,
    "total_throughput": 1772.5113438375483,
    "itl": 24.8122069420643,
    "ttft": 5222.312686659968,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7073657399415971,
    "arrivals": 13896,
    "finished_requests": 13876,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4341805279254913. Arrivals time: 0.04498140746727586 Scheduler time: 1.0083782654255629 Scheduler overhead time: 0.12227488914504647 Adapter cache time: 0.07572064269334078 Engine time: 0.12266559200361371 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-8/adapters_96_slots_96_rate_0.1-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-8/adapters_96_slots_96_rate_0.1-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 1080, 135, 135, 135, 135, 1080, 135, 1080, 135, 33, 1080, 33, 33, 1080, 135, 1080, 135, 1080, 1080, 135, 33, 1080, 135, 33, 33, 135, 1080, 33, 135, 33, 33, 135, 135, 135, 33, 33, 1080, 135, 135, 33, 1080, 1080, 135, 1080, 1080, 135, 1080, 33, 1080, 135, 135, 135, 1080, 1080, 33, 33, 135, 33, 1080, 33, 33, 1080, 33, 135, 135, 33, 135, 1080, 1080, 1080, 135, 1080, 1080, 33, 33, 1080, 135, 1080, 33, 135, 1080, 33, 1080, 135, 33, 1080, 33, 33, 1080, 33, 33, 135]
Prompts retrieved: 39936 . Total input tokens: 8842285 . Total output tokens: 7885916
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 1.3690923331305385,
    "estimated_duration": 3599.978825686337,
    "input_throughput": 932.337706003063,
    "output_throughput": 805.7577948245233,
    "total_throughput": 1738.0955008275862,
    "itl": 24.41754815688862,
    "ttft": 6161.582477982719,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6347912670671934,
    "arrivals": 13527,
    "finished_requests": 13504,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3691651769913733. Arrivals time: 0.04319960763677955 Scheduler time: 0.9470544145442545 Scheduler overhead time: 0.12379127508029342 Adapter cache time: 0.07238756213337183 Engine time: 0.12191833602264524 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-16/adapters_96_slots_96_rate_0.1-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-16/adapters_96_slots_96_rate_0.1-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 1080, 135, 135, 135, 135, 1080, 135, 1080, 135, 33, 1080, 33, 33, 1080, 135, 1080, 135, 1080, 1080, 135, 33, 1080, 135, 33, 33, 135, 1080, 33, 135, 33, 33, 135, 135, 135, 33, 33, 1080, 135, 135, 33, 1080, 1080, 135, 1080, 1080, 135, 1080, 33, 1080, 135, 135, 135, 1080, 1080, 33, 33, 135, 33, 1080, 33, 33, 1080, 33, 135, 135, 33, 135, 1080, 1080, 1080, 135, 1080, 1080, 33, 33, 1080, 135, 1080, 33, 135, 1080, 33, 1080, 135, 33, 1080, 33, 33, 1080, 33, 33, 135]
Prompts retrieved: 39936 . Total input tokens: 8842285 . Total output tokens: 7885916
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.3672433807514608,
    "estimated_duration": 3599.9794763295536,
    "input_throughput": 932.3375374967679,
    "output_throughput": 805.7576491956811,
    "total_throughput": 1738.095186692449,
    "itl": 24.417896298589955,
    "ttft": 6161.634159135088,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7017025525867943,
    "arrivals": 13527,
    "finished_requests": 13504,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3673225650563836. Arrivals time: 0.042741003446280956 Scheduler time: 0.9417763142846525 Scheduler overhead time: 0.12374284630641341 Adapter cache time: 0.07246667146682739 Engine time: 0.1255414793267846 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-32/adapters_96_slots_96_rate_0.1-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-32/adapters_96_slots_96_rate_0.1-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 1080, 135, 135, 135, 135, 1080, 135, 1080, 135, 33, 1080, 33, 33, 1080, 135, 1080, 135, 1080, 1080, 135, 33, 1080, 135, 33, 33, 135, 1080, 33, 135, 33, 33, 135, 135, 135, 33, 33, 1080, 135, 135, 33, 1080, 1080, 135, 1080, 1080, 135, 1080, 33, 1080, 135, 135, 135, 1080, 1080, 33, 33, 135, 33, 1080, 33, 33, 1080, 33, 135, 135, 33, 135, 1080, 1080, 1080, 135, 1080, 1080, 33, 33, 1080, 135, 1080, 33, 135, 1080, 33, 1080, 135, 33, 1080, 33, 33, 1080, 33, 33, 135]
Prompts retrieved: 39936 . Total input tokens: 8842285 . Total output tokens: 7885916
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.3776599578559399,
    "estimated_duration": 3599.9770087808092,
    "input_throughput": 932.3381765531603,
    "output_throughput": 805.7582014898403,
    "total_throughput": 1738.0963780430006,
    "itl": 24.41814520548722,
    "ttft": 6161.605253604413,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.720621239244938,
    "arrivals": 13527,
    "finished_requests": 13504,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3777455231174827. Arrivals time: 0.04354332061484456 Scheduler time: 0.9556840904988348 Scheduler overhead time: 0.12332500144839287 Adapter cache time: 0.07260973053053021 Engine time: 0.1218786402605474 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-16/adapters_96_slots_96_rate_0.1-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-16/adapters_96_slots_96_rate_0.1-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 1080, 135, 135, 135, 135, 1080, 135, 1080, 135, 33, 1080, 33, 33, 1080, 135, 1080, 135, 1080, 1080, 135, 33, 1080, 135, 33, 33, 135, 1080, 33, 135, 33, 33, 135, 135, 135, 33, 33, 1080, 135, 135, 33, 1080, 1080, 135, 1080, 1080, 135, 1080, 33, 1080, 135, 135, 135, 1080, 1080, 33, 33, 135, 33, 1080, 33, 33, 1080, 33, 135, 135, 33, 135, 1080, 1080, 1080, 135, 1080, 1080, 33, 33, 1080, 135, 1080, 33, 135, 1080, 33, 1080, 135, 33, 1080, 33, 33, 1080, 33, 33, 135]
Prompts retrieved: 39936 . Total input tokens: 8842285 . Total output tokens: 7885916
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 1.3983039832673967,
    "estimated_duration": 3599.980230253703,
    "input_throughput": 932.337342242422,
    "output_throughput": 805.7574804502681,
    "total_throughput": 1738.09482269269,
    "itl": 24.41758924692736,
    "ttft": 6161.615114061081,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6572794814407824,
    "arrivals": 13527,
    "finished_requests": 13504,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3983793472871184. Arrivals time: 0.04369767988100648 Scheduler time: 0.975065007340163 Scheduler overhead time: 0.12255072128027678 Adapter cache time: 0.07310594385489821 Engine time: 0.12310328613966703 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-32/adapters_96_slots_96_rate_0.1-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-32/adapters_96_slots_96_rate_0.1-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 1080, 135, 135, 135, 135, 1080, 135, 1080, 135, 33, 1080, 33, 33, 1080, 135, 1080, 135, 1080, 1080, 135, 33, 1080, 135, 33, 33, 135, 1080, 33, 135, 33, 33, 135, 135, 135, 33, 33, 1080, 135, 135, 33, 1080, 1080, 135, 1080, 1080, 135, 1080, 33, 1080, 135, 135, 135, 1080, 1080, 33, 33, 135, 33, 1080, 33, 33, 1080, 33, 135, 135, 33, 135, 1080, 1080, 1080, 135, 1080, 1080, 33, 33, 1080, 135, 1080, 33, 135, 1080, 33, 1080, 135, 33, 1080, 33, 33, 1080, 33, 33, 135]
Prompts retrieved: 39936 . Total input tokens: 8842285 . Total output tokens: 7885916
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 1.3686590697616339,
    "estimated_duration": 3599.986731096324,
    "input_throughput": 932.3356586311245,
    "output_throughput": 805.7560254164132,
    "total_throughput": 1738.0916840475377,
    "itl": 24.41786461245381,
    "ttft": 6161.524265046807,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7139934895932676,
    "arrivals": 13527,
    "finished_requests": 13504,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.36873409897089. Arrivals time: 0.044136961456388235 Scheduler time: 0.9462803904898465 Scheduler overhead time: 0.12192001473158598 Adapter cache time: 0.07254121638834476 Engine time: 0.12349113496020436 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-16/adapters_96_slots_96_rate_0.1-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-16/adapters_96_slots_96_rate_0.1-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 1080, 135, 135, 135, 135, 1080, 135, 1080, 135, 33, 1080, 33, 33, 1080, 135, 1080, 135, 1080, 1080, 135, 33, 1080, 135, 33, 33, 135, 1080, 33, 135, 33, 33, 135, 135, 135, 33, 33, 1080, 135, 135, 33, 1080, 1080, 135, 1080, 1080, 135, 1080, 33, 1080, 135, 135, 135, 1080, 1080, 33, 33, 135, 33, 1080, 33, 33, 1080, 33, 135, 135, 33, 135, 1080, 1080, 1080, 135, 1080, 1080, 33, 33, 1080, 135, 1080, 33, 135, 1080, 33, 1080, 135, 33, 1080, 33, 33, 1080, 33, 33, 135]
Prompts retrieved: 39936 . Total input tokens: 8842285 . Total output tokens: 7885916
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 1.3729082755744457,
    "estimated_duration": 3599.9788207361453,
    "input_throughput": 932.3377072850845,
    "output_throughput": 805.7577959324898,
    "total_throughput": 1738.0955032175743,
    "itl": 24.417385528098972,
    "ttft": 6161.563479424228,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6128564102947712,
    "arrivals": 13527,
    "finished_requests": 13504,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.372977053746581. Arrivals time: 0.04277748009189963 Scheduler time: 0.9529020567424595 Scheduler overhead time: 0.12291227746754885 Adapter cache time: 0.07312304340302944 Engine time: 0.12060891184955835 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-32/adapters_96_slots_96_rate_0.1-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-32/adapters_96_slots_96_rate_0.1-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 1080, 135, 135, 135, 135, 1080, 135, 1080, 135, 33, 1080, 33, 33, 1080, 135, 1080, 135, 1080, 1080, 135, 33, 1080, 135, 33, 33, 135, 1080, 33, 135, 33, 33, 135, 135, 135, 33, 33, 1080, 135, 135, 33, 1080, 1080, 135, 1080, 1080, 135, 1080, 33, 1080, 135, 135, 135, 1080, 1080, 33, 33, 135, 33, 1080, 33, 33, 1080, 33, 135, 135, 33, 135, 1080, 1080, 1080, 135, 1080, 1080, 33, 33, 1080, 135, 1080, 33, 135, 1080, 33, 1080, 135, 33, 1080, 33, 33, 1080, 33, 33, 135]
Prompts retrieved: 39936 . Total input tokens: 8842285 . Total output tokens: 7885916
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.3753682202659547,
    "estimated_duration": 3599.9802219295684,
    "input_throughput": 932.3373443982399,
    "output_throughput": 805.7574823133989,
    "total_throughput": 1738.0948267116387,
    "itl": 24.417942255761414,
    "ttft": 6161.5193763097495,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7073657399415971,
    "arrivals": 13527,
    "finished_requests": 13504,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3754223212599754. Arrivals time: 0.043298293836414814 Scheduler time: 0.9546822807751596 Scheduler overhead time: 0.1229136916808784 Adapter cache time: 0.07290868554264307 Engine time: 0.12123725423589349 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-8/adapters_96_slots_96_rate_0.1-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-8/adapters_96_slots_96_rate_0.1-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 1080, 66, 66, 66, 66, 1080, 66, 1080, 66, 33, 1080, 33, 33, 1080, 66, 1080, 66, 1080, 1080, 66, 33, 1080, 66, 33, 33, 66, 1080, 33, 66, 33, 33, 66, 66, 66, 33, 33, 1080, 66, 66, 33, 1080, 1080, 66, 1080, 1080, 66, 1080, 33, 1080, 66, 66, 66, 1080, 1080, 33, 33, 66, 33, 1080, 33, 33, 1080, 33, 66, 66, 33, 66, 1080, 1080, 1080, 66, 1080, 1080, 33, 33, 1080, 66, 1080, 33, 66, 1080, 33, 1080, 66, 33, 1080, 33, 33, 1080, 33, 33, 66]
Prompts retrieved: 37728 . Total input tokens: 8351156 . Total output tokens: 7442954
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 1.3296128143556416,
    "estimated_duration": 3599.821786363051,
    "input_throughput": 875.0008158549241,
    "output_throughput": 757.8625170654093,
    "total_throughput": 1632.8633329203333,
    "itl": 24.095989359798356,
    "ttft": 5696.6266904508,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6347912670671934,
    "arrivals": 12728,
    "finished_requests": 12708,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3296755673363805. Arrivals time: 0.04137398209422827 Scheduler time: 0.9095760877244174 Scheduler overhead time: 0.12425544438883662 Adapter cache time: 0.06788636092096567 Engine time: 0.12514705350622535 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-16/adapters_96_slots_96_rate_0.1-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-16/adapters_96_slots_96_rate_0.1-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 1080, 66, 66, 66, 66, 1080, 66, 1080, 66, 33, 1080, 33, 33, 1080, 66, 1080, 66, 1080, 1080, 66, 33, 1080, 66, 33, 33, 66, 1080, 33, 66, 33, 33, 66, 66, 66, 33, 33, 1080, 66, 66, 33, 1080, 1080, 66, 1080, 1080, 66, 1080, 33, 1080, 66, 66, 66, 1080, 1080, 33, 33, 66, 33, 1080, 33, 33, 1080, 33, 66, 66, 33, 66, 1080, 1080, 1080, 66, 1080, 1080, 33, 33, 1080, 66, 1080, 33, 66, 1080, 33, 1080, 66, 33, 1080, 33, 33, 1080, 33, 33, 66]
Prompts retrieved: 37728 . Total input tokens: 8351156 . Total output tokens: 7442954
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.3121268581598997,
    "estimated_duration": 3599.8238542116505,
    "input_throughput": 875.000313227772,
    "output_throughput": 757.8620817260683,
    "total_throughput": 1632.8623949538403,
    "itl": 24.09658029086194,
    "ttft": 5696.60623819827,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7017025525867944,
    "arrivals": 12728,
    "finished_requests": 12708,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3122083181515336. Arrivals time: 0.041194765362888575 Scheduler time: 0.8957511698827147 Scheduler overhead time: 0.12391393259167671 Adapter cache time: 0.06784256314858794 Engine time: 0.12233373243361712 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-32/adapters_96_slots_96_rate_0.1-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-32/adapters_96_slots_96_rate_0.1-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 1080, 66, 66, 66, 66, 1080, 66, 1080, 66, 33, 1080, 33, 33, 1080, 66, 1080, 66, 1080, 1080, 66, 33, 1080, 66, 33, 33, 66, 1080, 33, 66, 33, 33, 66, 66, 66, 33, 33, 1080, 66, 66, 33, 1080, 1080, 66, 1080, 1080, 66, 1080, 33, 1080, 66, 66, 66, 1080, 1080, 33, 33, 66, 33, 1080, 33, 33, 1080, 33, 66, 66, 33, 66, 1080, 1080, 1080, 66, 1080, 1080, 33, 33, 1080, 66, 1080, 33, 66, 1080, 33, 1080, 66, 33, 1080, 33, 33, 1080, 33, 33, 66]
Prompts retrieved: 37728 . Total input tokens: 8351156 . Total output tokens: 7442954
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.3078177249990404,
    "estimated_duration": 3599.823989964757,
    "input_throughput": 875.0002802306003,
    "output_throughput": 757.862053146301,
    "total_throughput": 1632.8623333769012,
    "itl": 24.09650696249376,
    "ttft": 5696.527139550584,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.720621239244938,
    "arrivals": 12728,
    "finished_requests": 12708,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3079130137339234. Arrivals time: 0.04125245055183768 Scheduler time: 0.8909296025522053 Scheduler overhead time: 0.12456804979592562 Adapter cache time: 0.06741956528276205 Engine time: 0.12270784517750144 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-16/adapters_96_slots_96_rate_0.1-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-16/adapters_96_slots_96_rate_0.1-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 1080, 66, 66, 66, 66, 1080, 66, 1080, 66, 33, 1080, 33, 33, 1080, 66, 1080, 66, 1080, 1080, 66, 33, 1080, 66, 33, 33, 66, 1080, 33, 66, 33, 33, 66, 66, 66, 33, 33, 1080, 66, 66, 33, 1080, 1080, 66, 1080, 1080, 66, 1080, 33, 1080, 66, 66, 66, 1080, 1080, 33, 33, 66, 33, 1080, 33, 33, 1080, 33, 66, 66, 33, 66, 1080, 1080, 1080, 66, 1080, 1080, 33, 33, 1080, 66, 1080, 33, 66, 1080, 33, 1080, 66, 33, 1080, 33, 33, 1080, 33, 33, 66]
Prompts retrieved: 37728 . Total input tokens: 8351156 . Total output tokens: 7442954
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 1.3280808283016086,
    "estimated_duration": 3599.816169221635,
    "input_throughput": 875.0021812033449,
    "output_throughput": 757.8636996316105,
    "total_throughput": 1632.8658808349555,
    "itl": 24.096190898444206,
    "ttft": 5696.650632503596,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6572794814407825,
    "arrivals": 12728,
    "finished_requests": 12708,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3281475873664021. Arrivals time: 0.04136271821334958 Scheduler time: 0.9087740904651582 Scheduler overhead time: 0.12471045646816492 Adapter cache time: 0.06796715967357159 Engine time: 0.12384421424940228 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-32/adapters_96_slots_96_rate_0.1-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-32/adapters_96_slots_96_rate_0.1-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 1080, 66, 66, 66, 66, 1080, 66, 1080, 66, 33, 1080, 33, 33, 1080, 66, 1080, 66, 1080, 1080, 66, 33, 1080, 66, 33, 33, 66, 1080, 33, 66, 33, 33, 66, 66, 66, 33, 33, 1080, 66, 66, 33, 1080, 1080, 66, 1080, 1080, 66, 1080, 33, 1080, 66, 66, 66, 1080, 1080, 33, 33, 66, 33, 1080, 33, 33, 1080, 33, 66, 66, 33, 66, 1080, 1080, 1080, 66, 1080, 1080, 33, 33, 1080, 66, 1080, 33, 66, 1080, 33, 1080, 66, 33, 1080, 33, 33, 1080, 33, 33, 66]
Prompts retrieved: 37728 . Total input tokens: 8351156 . Total output tokens: 7442954
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 1.3244836730882525,
    "estimated_duration": 3599.826028108009,
    "input_throughput": 874.9997848244604,
    "output_throughput": 757.8616240612793,
    "total_throughput": 1632.8614088857398,
    "itl": 24.09671856276997,
    "ttft": 5696.466971402202,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7139934895932676,
    "arrivals": 12728,
    "finished_requests": 12708,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3245498570613563. Arrivals time: 0.04173250263556838 Scheduler time: 0.9001880502328277 Scheduler overhead time: 0.12512921914458275 Adapter cache time: 0.06809682631865144 Engine time: 0.1252724602818489 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-16/adapters_96_slots_96_rate_0.1-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-16/adapters_96_slots_96_rate_0.1-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 1080, 66, 66, 66, 66, 1080, 66, 1080, 66, 33, 1080, 33, 33, 1080, 66, 1080, 66, 1080, 1080, 66, 33, 1080, 66, 33, 33, 66, 1080, 33, 66, 33, 33, 66, 66, 66, 33, 33, 1080, 66, 66, 33, 1080, 1080, 66, 1080, 1080, 66, 1080, 33, 1080, 66, 66, 66, 1080, 1080, 33, 33, 66, 33, 1080, 33, 33, 1080, 33, 66, 66, 33, 66, 1080, 1080, 1080, 66, 1080, 1080, 33, 33, 1080, 66, 1080, 33, 66, 1080, 33, 1080, 66, 33, 1080, 33, 33, 1080, 33, 33, 66]
Prompts retrieved: 37728 . Total input tokens: 8351156 . Total output tokens: 7442954
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 1.317916409112513,
    "estimated_duration": 3599.8356556330787,
    "input_throughput": 875.0849486894152,
    "output_throughput": 757.9982146490872,
    "total_throughput": 1633.0831633385023,
    "itl": 24.095997162237058,
    "ttft": 5413.776950508703,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6128564102947712,
    "arrivals": 12728,
    "finished_requests": 12709,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3179797870106995. Arrivals time: 0.04089658614248037 Scheduler time: 0.9016417828388512 Scheduler overhead time: 0.1241415748372674 Adapter cache time: 0.06796292122453451 Engine time: 0.12211156031116843 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-32/adapters_96_slots_96_rate_0.1-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-32/adapters_96_slots_96_rate_0.1-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 1080, 66, 66, 66, 66, 1080, 66, 1080, 66, 33, 1080, 33, 33, 1080, 66, 1080, 66, 1080, 1080, 66, 33, 1080, 66, 33, 33, 66, 1080, 33, 66, 33, 33, 66, 66, 66, 33, 33, 1080, 66, 66, 33, 1080, 1080, 66, 1080, 1080, 66, 1080, 33, 1080, 66, 66, 66, 1080, 1080, 33, 33, 66, 33, 1080, 33, 33, 1080, 33, 66, 66, 33, 66, 1080, 1080, 1080, 66, 1080, 1080, 33, 33, 1080, 66, 1080, 33, 66, 1080, 33, 1080, 66, 33, 1080, 33, 33, 1080, 33, 33, 66]
Prompts retrieved: 37728 . Total input tokens: 8351156 . Total output tokens: 7442954
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.3173733833245933,
    "estimated_duration": 3599.8260716523896,
    "input_throughput": 874.999774240248,
    "output_throughput": 757.8616148939989,
    "total_throughput": 1632.861389134247,
    "itl": 24.096744117816545,
    "ttft": 5696.604055614446,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7073657399415971,
    "arrivals": 12728,
    "finished_requests": 12708,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3174632503651083. Arrivals time: 0.041045859921723604 Scheduler time: 0.8997872434556484 Scheduler overhead time: 0.12427411414682865 Adapter cache time: 0.06810875283554196 Engine time: 0.12283799471333623 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-8/adapters_96_slots_96_rate_0.05-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-8/adapters_96_slots_96_rate_0.05-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 540, 270, 270, 270, 270, 540, 270, 540, 270, 135, 540, 135, 135, 540, 270, 540, 270, 540, 540, 270, 135, 540, 270, 135, 135, 270, 540, 135, 270, 135, 135, 270, 270, 270, 135, 135, 540, 270, 270, 135, 540, 540, 270, 540, 540, 270, 540, 135, 540, 270, 270, 270, 540, 540, 135, 135, 270, 135, 540, 135, 135, 540, 135, 270, 270, 135, 270, 540, 540, 540, 270, 540, 540, 135, 135, 540, 270, 540, 135, 270, 540, 135, 540, 270, 135, 540, 135, 135, 540, 135, 135, 270]
Prompts retrieved: 30240 . Total input tokens: 6689008 . Total output tokens: 5959246
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 1.162603813689202,
    "estimated_duration": 3599.89265502171,
    "input_throughput": 689.454447075737,
    "output_throughput": 611.8885231000634,
    "total_throughput": 1301.3429701758002,
    "itl": 23.31840567799023,
    "ttft": 5345.670116864396,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6347912670671934,
    "arrivals": 10175,
    "finished_requests": 10160,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1626778109930456. Arrivals time: 0.03539633844047785 Scheduler time: 0.743960116058588 Scheduler overhead time: 0.12472649803385139 Adapter cache time: 0.07252889219671488 Engine time: 0.12408463656902313 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-16/adapters_96_slots_96_rate_0.05-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-16/adapters_96_slots_96_rate_0.05-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 540, 270, 270, 270, 270, 540, 270, 540, 270, 135, 540, 135, 135, 540, 270, 540, 270, 540, 540, 270, 135, 540, 270, 135, 135, 270, 540, 135, 270, 135, 135, 270, 270, 270, 135, 135, 540, 270, 270, 135, 540, 540, 270, 540, 540, 270, 540, 135, 540, 270, 270, 270, 540, 540, 135, 135, 270, 135, 540, 135, 135, 540, 135, 270, 270, 135, 270, 540, 540, 540, 270, 540, 540, 135, 135, 540, 270, 540, 135, 270, 540, 135, 540, 270, 135, 540, 135, 135, 540, 135, 135, 270]
Prompts retrieved: 30240 . Total input tokens: 6689008 . Total output tokens: 5959246
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.155126673169434,
    "estimated_duration": 3599.8950562585323,
    "input_throughput": 689.4539871891626,
    "output_throughput": 611.8881149522618,
    "total_throughput": 1301.3421021414244,
    "itl": 23.31875223437073,
    "ttft": 5345.725448321859,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7017025525867939,
    "arrivals": 10175,
    "finished_requests": 10160,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1552180000580847. Arrivals time: 0.035418704617768526 Scheduler time: 0.7346162521280348 Scheduler overhead time: 0.1252736086025834 Adapter cache time: 0.07302302308380604 Engine time: 0.12486476451158524 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-32/adapters_96_slots_96_rate_0.05-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-32/adapters_96_slots_96_rate_0.05-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 540, 270, 270, 270, 270, 540, 270, 540, 270, 135, 540, 135, 135, 540, 270, 540, 270, 540, 540, 270, 135, 540, 270, 135, 135, 270, 540, 135, 270, 135, 135, 270, 270, 270, 135, 135, 540, 270, 270, 135, 540, 540, 270, 540, 540, 270, 540, 135, 540, 270, 270, 270, 540, 540, 135, 135, 270, 135, 540, 135, 135, 540, 135, 270, 270, 135, 270, 540, 540, 540, 270, 540, 540, 135, 135, 540, 270, 540, 135, 270, 540, 135, 540, 270, 135, 540, 135, 135, 540, 135, 135, 270]
Prompts retrieved: 30240 . Total input tokens: 6689008 . Total output tokens: 5959246
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.1612892970442772,
    "estimated_duration": 3599.8852542894283,
    "input_throughput": 689.4516976735985,
    "output_throughput": 611.827834616564,
    "total_throughput": 1301.2795322901625,
    "itl": 23.52578247441605,
    "ttft": 5699.950365774444,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.720621239244938,
    "arrivals": 10175,
    "finished_requests": 10159,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1613789508119226. Arrivals time: 0.035803715232759714 Scheduler time: 0.7456275946460664 Scheduler overhead time: 0.12398311542347074 Adapter cache time: 0.07274254783987999 Engine time: 0.12164830882102251 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-16/adapters_96_slots_96_rate_0.05-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-16/adapters_96_slots_96_rate_0.05-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 540, 270, 270, 270, 270, 540, 270, 540, 270, 135, 540, 135, 135, 540, 270, 540, 270, 540, 540, 270, 135, 540, 270, 135, 135, 270, 540, 135, 270, 135, 135, 270, 270, 270, 135, 135, 540, 270, 270, 135, 540, 540, 270, 540, 540, 270, 540, 135, 540, 270, 270, 270, 540, 540, 135, 135, 270, 135, 540, 135, 135, 540, 135, 270, 270, 135, 270, 540, 540, 540, 270, 540, 540, 135, 135, 540, 270, 540, 135, 270, 540, 135, 540, 270, 135, 540, 135, 135, 540, 135, 135, 270]
Prompts retrieved: 30240 . Total input tokens: 6689008 . Total output tokens: 5959246
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 1.1501176641322672,
    "estimated_duration": 3599.8918110783657,
    "input_throughput": 689.4546087085089,
    "output_throughput": 611.8886665486095,
    "total_throughput": 1301.3432752571184,
    "itl": 23.318524648305548,
    "ttft": 5345.715672954988,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6572794814407827,
    "arrivals": 10175,
    "finished_requests": 10160,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1502253538928926. Arrivals time: 0.03532763244584203 Scheduler time: 0.7303588516078889 Scheduler overhead time: 0.1255982769653201 Adapter cache time: 0.0727748409844935 Engine time: 0.12397304456681013 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-32/adapters_96_slots_96_rate_0.05-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-32/adapters_96_slots_96_rate_0.05-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 540, 270, 270, 270, 270, 540, 270, 540, 270, 135, 540, 135, 135, 540, 270, 540, 270, 540, 540, 270, 135, 540, 270, 135, 135, 270, 540, 135, 270, 135, 135, 270, 270, 270, 135, 135, 540, 270, 270, 135, 540, 540, 270, 540, 540, 270, 540, 135, 540, 270, 270, 270, 540, 540, 135, 135, 270, 135, 540, 135, 135, 540, 135, 270, 270, 135, 270, 540, 540, 540, 270, 540, 540, 135, 135, 540, 270, 540, 135, 270, 540, 135, 540, 270, 135, 540, 135, 135, 540, 135, 135, 270]
Prompts retrieved: 30240 . Total input tokens: 6689008 . Total output tokens: 5959246
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 1.155146162956953,
    "estimated_duration": 3599.894695545622,
    "input_throughput": 689.4498894845648,
    "output_throughput": 611.8262300075903,
    "total_throughput": 1301.276119492155,
    "itl": 23.525687150851684,
    "ttft": 5699.867515658348,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7139934895932676,
    "arrivals": 10175,
    "finished_requests": 10159,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1552405897527933. Arrivals time: 0.03569557145237923 Scheduler time: 0.7371688759885728 Scheduler overhead time: 0.12447770778089762 Adapter cache time: 0.07261538039892912 Engine time: 0.12381534371525049 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-16/adapters_96_slots_96_rate_0.05-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-16/adapters_96_slots_96_rate_0.05-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 540, 270, 270, 270, 270, 540, 270, 540, 270, 135, 540, 135, 135, 540, 270, 540, 270, 540, 540, 270, 135, 540, 270, 135, 135, 270, 540, 135, 270, 135, 135, 270, 270, 270, 135, 135, 540, 270, 270, 135, 540, 540, 270, 540, 540, 270, 540, 135, 540, 270, 270, 270, 540, 540, 135, 135, 270, 135, 540, 135, 135, 540, 135, 270, 270, 135, 270, 540, 540, 540, 270, 540, 540, 135, 135, 540, 270, 540, 135, 270, 540, 135, 540, 270, 135, 540, 135, 135, 540, 135, 135, 270]
Prompts retrieved: 30240 . Total input tokens: 6689008 . Total output tokens: 5959246
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 1.150762570090592,
    "estimated_duration": 3599.8908411984776,
    "input_throughput": 689.454794460852,
    "output_throughput": 611.8888314031947,
    "total_throughput": 1301.3436258640468,
    "itl": 23.318307754282266,
    "ttft": 5345.689698626169,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6128564102947712,
    "arrivals": 10175,
    "finished_requests": 10160,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1508522271178663. Arrivals time: 0.03470423445105553 Scheduler time: 0.733212208840996 Scheduler overhead time: 0.12529798271134496 Adapter cache time: 0.07231951830908656 Engine time: 0.12349374080076814 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-32/adapters_96_slots_96_rate_0.05-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-32/adapters_96_slots_96_rate_0.05-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 540, 270, 270, 270, 270, 540, 270, 540, 270, 135, 540, 135, 135, 540, 270, 540, 270, 540, 540, 270, 135, 540, 270, 135, 135, 270, 540, 135, 270, 135, 135, 270, 270, 270, 135, 135, 540, 270, 270, 135, 540, 540, 270, 540, 540, 270, 540, 135, 540, 270, 270, 270, 540, 540, 135, 135, 270, 135, 540, 135, 135, 540, 135, 270, 270, 135, 270, 540, 540, 540, 270, 540, 540, 135, 135, 540, 270, 540, 135, 270, 540, 135, 540, 270, 135, 540, 135, 135, 540, 135, 135, 270]
Prompts retrieved: 30240 . Total input tokens: 6689008 . Total output tokens: 5959246
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.1568170716054738,
    "estimated_duration": 3599.880529614118,
    "input_throughput": 689.4526025467982,
    "output_throughput": 611.8286376120636,
    "total_throughput": 1301.281240158862,
    "itl": 23.319248689907855,
    "ttft": 5699.508392902161,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7073657399415971,
    "arrivals": 10175,
    "finished_requests": 10159,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1568712638691068. Arrivals time: 0.03519361140206456 Scheduler time: 0.7377927582710981 Scheduler overhead time: 0.12545374082401395 Adapter cache time: 0.07246972341090441 Engine time: 0.12375090131536126 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-8/adapters_96_slots_96_rate_0.05-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-8/adapters_96_slots_96_rate_0.05-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 540, 270, 270, 270, 270, 540, 270, 540, 270, 66, 540, 66, 66, 540, 270, 540, 270, 540, 540, 270, 66, 540, 270, 66, 66, 270, 540, 66, 270, 66, 66, 270, 270, 270, 66, 66, 540, 270, 270, 66, 540, 540, 270, 540, 540, 270, 540, 66, 540, 270, 270, 270, 540, 540, 66, 66, 270, 66, 540, 66, 66, 540, 66, 270, 270, 66, 270, 540, 540, 540, 270, 540, 540, 66, 66, 540, 270, 540, 66, 270, 540, 66, 540, 270, 66, 540, 66, 66, 540, 66, 66, 270]
Prompts retrieved: 28032 . Total input tokens: 6199612 . Total output tokens: 5515691
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 1.1168315168470144,
    "estimated_duration": 3599.9877195873905,
    "input_throughput": 648.1519332147705,
    "output_throughput": 576.8728011766726,
    "total_throughput": 1225.0247343914432,
    "itl": 23.24237974051273,
    "ttft": 6863.637066540545,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6347912670671934,
    "arrivals": 9494,
    "finished_requests": 9476,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.116906986106187. Arrivals time: 0.034074722323566675 Scheduler time: 0.7015075534582138 Scheduler overhead time: 0.1264629070647061 Adapter cache time: 0.06752230320125818 Engine time: 0.1246293531730771 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-16/adapters_96_slots_96_rate_0.05-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-16/adapters_96_slots_96_rate_0.05-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 540, 270, 270, 270, 270, 540, 270, 540, 270, 66, 540, 66, 66, 540, 270, 540, 270, 540, 540, 270, 66, 540, 270, 66, 66, 270, 540, 66, 270, 66, 66, 270, 270, 270, 66, 66, 540, 270, 270, 66, 540, 540, 270, 540, 540, 270, 540, 66, 540, 270, 270, 270, 540, 540, 66, 66, 270, 66, 540, 66, 66, 540, 66, 270, 270, 66, 270, 540, 540, 540, 270, 540, 540, 66, 66, 540, 270, 540, 66, 270, 540, 66, 540, 270, 66, 540, 66, 66, 540, 66, 66, 270]
Prompts retrieved: 28032 . Total input tokens: 6199612 . Total output tokens: 5515691
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.1166442772373557,
    "estimated_duration": 3599.988082807268,
    "input_throughput": 648.1518678196468,
    "output_throughput": 576.8727429732389,
    "total_throughput": 1225.0246107928856,
    "itl": 23.243213827251417,
    "ttft": 6863.62757618821,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7017025525867946,
    "arrivals": 9494,
    "finished_requests": 9476,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.116709802299738. Arrivals time: 0.03376942314207554 Scheduler time: 0.7020374280400574 Scheduler overhead time: 0.12763117672875524 Adapter cache time: 0.06736362539231777 Engine time: 0.1231558583676815 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-32/adapters_96_slots_96_rate_0.05-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-32/adapters_96_slots_96_rate_0.05-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 540, 270, 270, 270, 270, 540, 270, 540, 270, 66, 540, 66, 66, 540, 270, 540, 270, 540, 540, 270, 66, 540, 270, 66, 66, 270, 540, 66, 270, 66, 66, 270, 270, 270, 66, 66, 540, 270, 270, 66, 540, 540, 270, 540, 540, 270, 540, 66, 540, 270, 270, 270, 540, 540, 66, 66, 270, 66, 540, 66, 66, 540, 66, 270, 270, 66, 270, 540, 540, 540, 270, 540, 540, 66, 66, 540, 270, 540, 66, 270, 540, 66, 540, 270, 66, 540, 66, 66, 540, 66, 66, 270]
Prompts retrieved: 28032 . Total input tokens: 6199612 . Total output tokens: 5515691
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.118570476770401,
    "estimated_duration": 3599.987367222689,
    "input_throughput": 648.1519966555104,
    "output_throughput": 576.872857640652,
    "total_throughput": 1225.0248542961624,
    "itl": 23.242951787174942,
    "ttft": 6863.737600934574,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.720621239244938,
    "arrivals": 9494,
    "finished_requests": 9476,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1186356586404145. Arrivals time: 0.03334961272776127 Scheduler time: 0.6971889319829643 Scheduler overhead time: 0.13060531625524163 Adapter cache time: 0.06741863256320357 Engine time: 0.12713971827179193 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-16/adapters_96_slots_96_rate_0.05-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-16/adapters_96_slots_96_rate_0.05-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 540, 270, 270, 270, 270, 540, 270, 540, 270, 66, 540, 66, 66, 540, 270, 540, 270, 540, 540, 270, 66, 540, 270, 66, 66, 270, 540, 66, 270, 66, 66, 270, 270, 270, 66, 66, 540, 270, 270, 66, 540, 540, 270, 540, 540, 270, 540, 66, 540, 270, 270, 270, 540, 540, 66, 66, 270, 66, 540, 66, 66, 540, 66, 270, 270, 66, 270, 540, 540, 540, 270, 540, 540, 66, 66, 540, 270, 540, 66, 270, 540, 66, 540, 270, 66, 540, 66, 66, 540, 66, 66, 270]
Prompts retrieved: 28032 . Total input tokens: 6199612 . Total output tokens: 5515691
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 1.11888267705217,
    "estimated_duration": 3599.9873372156458,
    "input_throughput": 648.1520020580641,
    "output_throughput": 576.8728624490714,
    "total_throughput": 1225.0248645071356,
    "itl": 23.2428550116025,
    "ttft": 6863.614826523796,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6572794814407829,
    "arrivals": 9494,
    "finished_requests": 9476,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1189535921439528. Arrivals time: 0.036681883968412876 Scheduler time: 0.7014343589544296 Scheduler overhead time: 0.12669210834428668 Adapter cache time: 0.0680321934632957 Engine time: 0.12323065893724561 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-32/adapters_96_slots_96_rate_0.05-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-32/adapters_96_slots_96_rate_0.05-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 540, 270, 270, 270, 270, 540, 270, 540, 270, 66, 540, 66, 66, 540, 270, 540, 270, 540, 540, 270, 66, 540, 270, 66, 66, 270, 540, 66, 270, 66, 66, 270, 270, 270, 66, 66, 540, 270, 270, 66, 540, 540, 270, 540, 540, 270, 540, 66, 540, 270, 270, 270, 540, 540, 66, 66, 270, 66, 540, 66, 66, 540, 66, 270, 270, 66, 270, 540, 540, 540, 270, 540, 540, 66, 66, 540, 270, 540, 66, 270, 540, 66, 540, 270, 66, 540, 66, 66, 540, 66, 66, 270]
Prompts retrieved: 28032 . Total input tokens: 6199612 . Total output tokens: 5515691
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 1.12302858941257,
    "estimated_duration": 3599.9815864590664,
    "input_throughput": 648.1530374423572,
    "output_throughput": 576.8737839691763,
    "total_throughput": 1225.0268214115335,
    "itl": 23.24305910254195,
    "ttft": 6863.654119948559,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7139934895932676,
    "arrivals": 9494,
    "finished_requests": 9476,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1230829521082342. Arrivals time: 0.03372460324317217 Scheduler time: 0.7050488009117544 Scheduler overhead time: 0.12593303574249148 Adapter cache time: 0.06816825922578573 Engine time: 0.12745379703119397 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-16/adapters_96_slots_96_rate_0.05-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-16/adapters_96_slots_96_rate_0.05-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 540, 270, 270, 270, 270, 540, 270, 540, 270, 66, 540, 66, 66, 540, 270, 540, 270, 540, 540, 270, 66, 540, 270, 66, 66, 270, 540, 66, 270, 66, 66, 270, 270, 270, 66, 66, 540, 270, 270, 66, 540, 540, 270, 540, 540, 270, 540, 66, 540, 270, 270, 270, 540, 540, 66, 66, 270, 66, 540, 66, 66, 540, 66, 270, 270, 66, 270, 540, 540, 540, 270, 540, 540, 66, 66, 540, 270, 540, 66, 270, 540, 66, 540, 270, 66, 540, 66, 66, 540, 66, 66, 270]
Prompts retrieved: 28032 . Total input tokens: 6199612 . Total output tokens: 5515691
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 1.108887149952352,
    "estimated_duration": 3599.9868010098207,
    "input_throughput": 648.1520985981067,
    "output_throughput": 576.8729483723279,
    "total_throughput": 1225.0250469704345,
    "itl": 23.24257835878947,
    "ttft": 6863.617470989318,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6128564102947712,
    "arrivals": 9494,
    "finished_requests": 9476,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1089617772959173. Arrivals time: 0.03347564348950982 Scheduler time: 0.6955245276913047 Scheduler overhead time: 0.12554049864411354 Adapter cache time: 0.06769420811906457 Engine time: 0.124396329279989 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-32/adapters_96_slots_96_rate_0.05-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-32/adapters_96_slots_96_rate_0.05-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 540, 270, 270, 270, 270, 540, 270, 540, 270, 66, 540, 66, 66, 540, 270, 540, 270, 540, 540, 270, 66, 540, 270, 66, 66, 270, 540, 66, 270, 66, 66, 270, 270, 270, 66, 66, 540, 270, 270, 66, 540, 540, 270, 540, 540, 270, 540, 66, 540, 270, 270, 270, 540, 540, 66, 66, 270, 66, 540, 66, 66, 540, 66, 270, 270, 66, 270, 540, 540, 540, 270, 540, 540, 66, 66, 540, 270, 540, 66, 270, 540, 66, 540, 270, 66, 540, 66, 66, 540, 66, 66, 270]
Prompts retrieved: 28032 . Total input tokens: 6199612 . Total output tokens: 5515691
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.114260405767709,
    "estimated_duration": 3599.992031660449,
    "input_throughput": 648.1511568579161,
    "output_throughput": 576.8721101980143,
    "total_throughput": 1225.0232670559305,
    "itl": 23.242742706950377,
    "ttft": 6863.600505271248,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7073657399415971,
    "arrivals": 9494,
    "finished_requests": 9476,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1143117710016668. Arrivals time: 0.033344284165650606 Scheduler time: 0.7004909715615213 Scheduler overhead time: 0.1265873466618359 Adapter cache time: 0.06834772974252701 Engine time: 0.12295724265277386 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-8/adapters_96_slots_96_rate_0.05-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-8/adapters_96_slots_96_rate_0.05-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 540, 270, 270, 270, 270, 540, 270, 540, 270, 33, 540, 33, 33, 540, 270, 540, 270, 540, 540, 270, 33, 540, 270, 33, 33, 270, 540, 33, 270, 33, 33, 270, 270, 270, 33, 33, 540, 270, 270, 33, 540, 540, 270, 540, 540, 270, 540, 33, 540, 270, 270, 270, 540, 540, 33, 33, 270, 33, 540, 33, 33, 540, 33, 270, 270, 33, 270, 540, 540, 540, 270, 540, 540, 33, 33, 540, 270, 540, 33, 270, 540, 33, 540, 270, 33, 540, 33, 33, 540, 33, 33, 270]
Prompts retrieved: 26976 . Total input tokens: 5970497 . Total output tokens: 5305411
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 1.07896983390674,
    "estimated_duration": 3599.93926049535,
    "input_throughput": 614.0281377124794,
    "output_throughput": 541.1799641674861,
    "total_throughput": 1155.2081018799654,
    "itl": 22.93346140135782,
    "ttft": 5182.833740481128,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6347912670671934,
    "arrivals": 9096,
    "finished_requests": 9083,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.079040267970413. Arrivals time: 0.03257210087031126 Scheduler time: 0.6672095996327698 Scheduler overhead time: 0.12581862276419997 Adapter cache time: 0.06493422156199813 Engine time: 0.12541582435369492 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-16/adapters_96_slots_96_rate_0.05-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-16/adapters_96_slots_96_rate_0.05-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 540, 270, 270, 270, 270, 540, 270, 540, 270, 33, 540, 33, 33, 540, 270, 540, 270, 540, 540, 270, 33, 540, 270, 33, 33, 270, 540, 33, 270, 33, 33, 270, 270, 270, 33, 33, 540, 270, 270, 33, 540, 540, 270, 540, 540, 270, 540, 33, 540, 270, 270, 270, 540, 540, 33, 33, 270, 33, 540, 33, 33, 540, 33, 270, 270, 33, 270, 540, 540, 540, 270, 540, 540, 33, 33, 540, 270, 540, 33, 270, 540, 33, 540, 270, 33, 540, 33, 33, 540, 33, 33, 270]
Prompts retrieved: 26976 . Total input tokens: 5970497 . Total output tokens: 5305411
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.0781644899398088,
    "estimated_duration": 3599.943499825137,
    "input_throughput": 614.0274146267492,
    "output_throughput": 541.1793268685001,
    "total_throughput": 1155.2067414952492,
    "itl": 22.933874128668837,
    "ttft": 5182.789977991818,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7017025525867944,
    "arrivals": 9096,
    "finished_requests": 9083,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0782315386459231. Arrivals time: 0.03272528573870659 Scheduler time: 0.6638266635127366 Scheduler overhead time: 0.12660644622519612 Adapter cache time: 0.06506700348109007 Engine time: 0.12672598008066416 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-32/adapters_96_slots_96_rate_0.05-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-32/adapters_96_slots_96_rate_0.05-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 540, 270, 270, 270, 270, 540, 270, 540, 270, 33, 540, 33, 33, 540, 270, 540, 270, 540, 540, 270, 33, 540, 270, 33, 33, 270, 540, 33, 270, 33, 33, 270, 270, 270, 33, 33, 540, 270, 270, 33, 540, 540, 270, 540, 540, 270, 540, 33, 540, 270, 270, 270, 540, 540, 33, 33, 270, 33, 540, 33, 33, 540, 33, 270, 270, 33, 270, 540, 540, 540, 270, 540, 540, 33, 33, 540, 270, 540, 33, 270, 540, 33, 540, 270, 33, 540, 33, 33, 540, 33, 33, 270]
Prompts retrieved: 26976 . Total input tokens: 5970497 . Total output tokens: 5305411
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.0705681848339736,
    "estimated_duration": 3599.948091679094,
    "input_throughput": 614.0266314142856,
    "output_throughput": 541.1786365762041,
    "total_throughput": 1155.2052679904898,
    "itl": 22.933991495031382,
    "ttft": 5182.7757085805615,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7206212392449379,
    "arrivals": 9096,
    "finished_requests": 9083,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0706287329085171. Arrivals time: 0.03206728398799896 Scheduler time: 0.6597308241762221 Scheduler overhead time: 0.1271050637587905 Adapter cache time: 0.06515400530770421 Engine time: 0.1236416744068265 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-16/adapters_96_slots_96_rate_0.05-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-16/adapters_96_slots_96_rate_0.05-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 540, 270, 270, 270, 270, 540, 270, 540, 270, 33, 540, 33, 33, 540, 270, 540, 270, 540, 540, 270, 33, 540, 270, 33, 33, 270, 540, 33, 270, 33, 33, 270, 270, 270, 33, 33, 540, 270, 270, 33, 540, 540, 270, 540, 540, 270, 540, 33, 540, 270, 270, 270, 540, 540, 33, 33, 270, 33, 540, 33, 33, 540, 33, 270, 270, 33, 270, 540, 540, 540, 270, 540, 540, 33, 33, 540, 270, 540, 33, 270, 540, 33, 540, 270, 33, 540, 33, 33, 540, 33, 33, 270]
Prompts retrieved: 26976 . Total input tokens: 5970497 . Total output tokens: 5305411
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 1.077055986970663,
    "estimated_duration": 3599.9393396412024,
    "input_throughput": 614.0281242128685,
    "output_throughput": 541.1799522694663,
    "total_throughput": 1155.2080764823347,
    "itl": 22.9335801121331,
    "ttft": 5182.874224629284,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.657279481440783,
    "arrivals": 9096,
    "finished_requests": 9083,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0771612096577883. Arrivals time: 0.03310614777728915 Scheduler time: 0.6639118460007012 Scheduler overhead time: 0.1269419020973146 Adapter cache time: 0.06542111188173294 Engine time: 0.1250436259433627 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-32/adapters_96_slots_96_rate_0.05-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-32/adapters_96_slots_96_rate_0.05-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 540, 270, 270, 270, 270, 540, 270, 540, 270, 33, 540, 33, 33, 540, 270, 540, 270, 540, 540, 270, 33, 540, 270, 33, 33, 270, 540, 33, 270, 33, 33, 270, 270, 270, 33, 33, 540, 270, 270, 33, 540, 540, 270, 540, 540, 270, 540, 33, 540, 270, 270, 270, 540, 540, 33, 33, 270, 33, 540, 33, 33, 540, 33, 270, 270, 33, 270, 540, 540, 540, 270, 540, 540, 33, 33, 540, 270, 540, 33, 270, 540, 33, 540, 270, 33, 540, 33, 33, 540, 33, 33, 270]
Prompts retrieved: 26976 . Total input tokens: 5970497 . Total output tokens: 5305411
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 1.0723287030123174,
    "estimated_duration": 3599.93505916564,
    "input_throughput": 614.0288543183668,
    "output_throughput": 541.1805957553967,
    "total_throughput": 1155.2094500737635,
    "itl": 22.933907029679567,
    "ttft": 5183.0265348631265,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7139934895932675,
    "arrivals": 9096,
    "finished_requests": 9083,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0723822098225355. Arrivals time: 0.032438711263239384 Scheduler time: 0.6584952967241406 Scheduler overhead time: 0.12662618095055223 Adapter cache time: 0.06501449318602681 Engine time: 0.12654078286141157 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-16/adapters_96_slots_96_rate_0.05-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-16/adapters_96_slots_96_rate_0.05-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 540, 270, 270, 270, 270, 540, 270, 540, 270, 33, 540, 33, 33, 540, 270, 540, 270, 540, 540, 270, 33, 540, 270, 33, 33, 270, 540, 33, 270, 33, 33, 270, 270, 270, 33, 33, 540, 270, 270, 33, 540, 540, 270, 540, 540, 270, 540, 33, 540, 270, 270, 270, 540, 540, 33, 33, 270, 33, 540, 33, 33, 540, 33, 270, 270, 33, 270, 540, 540, 540, 270, 540, 540, 33, 33, 540, 270, 540, 33, 270, 540, 33, 540, 270, 33, 540, 33, 33, 540, 33, 33, 270]
Prompts retrieved: 26976 . Total input tokens: 5970497 . Total output tokens: 5305411
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 1.080869317986071,
    "estimated_duration": 3599.9391768518044,
    "input_throughput": 614.0281519792455,
    "output_throughput": 541.1799767416461,
    "total_throughput": 1155.2081287208916,
    "itl": 22.93367105238946,
    "ttft": 5182.878247790665,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6128564102947712,
    "arrivals": 9096,
    "finished_requests": 9083,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0809435080736876. Arrivals time: 0.0326824258081615 Scheduler time: 0.6671870774589479 Scheduler overhead time: 0.12599549302831292 Adapter cache time: 0.06547825364395976 Engine time: 0.12632576562464237 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-32/adapters_96_slots_96_rate_0.05-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-32/adapters_96_slots_96_rate_0.05-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 540, 270, 270, 270, 270, 540, 270, 540, 270, 33, 540, 33, 33, 540, 270, 540, 270, 540, 540, 270, 33, 540, 270, 33, 33, 270, 540, 33, 270, 33, 33, 270, 270, 270, 33, 33, 540, 270, 270, 33, 540, 540, 270, 540, 540, 270, 540, 33, 540, 270, 270, 270, 540, 540, 33, 33, 270, 33, 540, 33, 33, 540, 33, 270, 270, 33, 270, 540, 540, 540, 270, 540, 540, 33, 33, 540, 270, 540, 33, 270, 540, 33, 540, 270, 33, 540, 33, 33, 540, 33, 33, 270]
Prompts retrieved: 26976 . Total input tokens: 5970497 . Total output tokens: 5305411
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.0727373929694295,
    "estimated_duration": 3599.9320104691424,
    "input_throughput": 614.0293743247481,
    "output_throughput": 541.1810540683264,
    "total_throughput": 1155.2104283930746,
    "itl": 22.933874717018067,
    "ttft": 5182.723381877731,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.707365739941597,
    "arrivals": 9096,
    "finished_requests": 9083,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0727912257425487. Arrivals time: 0.03248177282512188 Scheduler time: 0.6613947516307235 Scheduler overhead time: 0.12684534676373005 Adapter cache time: 0.06510724686086178 Engine time: 0.12381205521523952 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-8/adapters_96_slots_96_rate_0.05-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-8/adapters_96_slots_96_rate_0.05-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 540, 135, 135, 135, 135, 540, 135, 540, 135, 66, 540, 66, 66, 540, 135, 540, 135, 540, 540, 135, 66, 540, 135, 66, 66, 135, 540, 66, 135, 66, 66, 135, 135, 135, 66, 66, 540, 135, 135, 66, 540, 540, 135, 540, 540, 135, 540, 66, 540, 135, 135, 135, 540, 540, 66, 66, 135, 66, 540, 66, 66, 540, 66, 135, 135, 66, 135, 540, 540, 540, 135, 540, 540, 66, 66, 540, 135, 540, 66, 135, 540, 66, 540, 135, 66, 540, 66, 66, 540, 66, 66, 135]
Prompts retrieved: 23712 . Total input tokens: 5259212 . Total output tokens: 4661994
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 1.0266069453209639,
    "estimated_duration": 3599.837073234568,
    "input_throughput": 538.6885463284524,
    "output_throughput": 486.7934199103721,
    "total_throughput": 1025.4819662388245,
    "itl": 22.500424627355923,
    "ttft": 6743.5460963355445,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6347912670671934,
    "arrivals": 8052,
    "finished_requests": 8037,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0266835852526128. Arrivals time: 0.030395060312002897 Scheduler time: 0.6161180250346661 Scheduler overhead time: 0.128582373727113 Adapter cache time: 0.06082339119166136 Engine time: 0.126674585044384 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-16/adapters_96_slots_96_rate_0.05-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-16/adapters_96_slots_96_rate_0.05-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 540, 135, 135, 135, 135, 540, 135, 540, 135, 66, 540, 66, 66, 540, 135, 540, 135, 540, 540, 135, 66, 540, 135, 66, 66, 135, 540, 66, 135, 66, 66, 135, 135, 135, 66, 66, 540, 135, 135, 66, 540, 540, 135, 540, 540, 135, 540, 66, 540, 135, 135, 135, 540, 540, 66, 66, 135, 66, 540, 66, 66, 540, 66, 135, 135, 66, 135, 540, 540, 540, 135, 540, 540, 66, 66, 540, 135, 540, 66, 135, 540, 66, 540, 135, 66, 540, 66, 66, 540, 66, 66, 135]
Prompts retrieved: 23712 . Total input tokens: 5259212 . Total output tokens: 4661994
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.031421909108758,
    "estimated_duration": 3599.8416240726638,
    "input_throughput": 538.6878653306158,
    "output_throughput": 486.79280451717665,
    "total_throughput": 1025.4806698477923,
    "itl": 22.500731207115578,
    "ttft": 6743.497572578359,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7017025525867945,
    "arrivals": 8052,
    "finished_requests": 8037,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0314732501283288. Arrivals time: 0.030753054190427065 Scheduler time: 0.6194717874750495 Scheduler overhead time: 0.12828185595571995 Adapter cache time: 0.06133298063650727 Engine time: 0.12776910606771708 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-32/adapters_96_slots_96_rate_0.05-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-32/adapters_96_slots_96_rate_0.05-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 540, 135, 135, 135, 135, 540, 135, 540, 135, 66, 540, 66, 66, 540, 135, 540, 135, 540, 540, 135, 66, 540, 135, 66, 66, 135, 540, 66, 135, 66, 66, 135, 135, 135, 66, 66, 540, 135, 135, 66, 540, 540, 135, 540, 540, 135, 540, 66, 540, 135, 135, 135, 540, 540, 66, 66, 135, 66, 540, 66, 66, 540, 66, 135, 135, 66, 135, 540, 540, 540, 135, 540, 540, 66, 66, 540, 135, 540, 66, 135, 540, 66, 540, 135, 66, 540, 66, 66, 540, 66, 66, 135]
Prompts retrieved: 23712 . Total input tokens: 5259212 . Total output tokens: 4661994
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.034673879854381,
    "estimated_duration": 3599.839019618314,
    "input_throughput": 538.6882550669195,
    "output_throughput": 486.7931567078247,
    "total_throughput": 1025.4814117747442,
    "itl": 22.501161414971186,
    "ttft": 6743.5571654841515,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.720621239244938,
    "arrivals": 8052,
    "finished_requests": 8037,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0348329711705446. Arrivals time: 0.030570486560463905 Scheduler time: 0.6102356505580246 Scheduler overhead time: 0.13190251076593995 Adapter cache time: 0.06129470327869058 Engine time: 0.13630062574520707 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-16/adapters_96_slots_96_rate_0.05-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-16/adapters_96_slots_96_rate_0.05-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 540, 135, 135, 135, 135, 540, 135, 540, 135, 66, 540, 66, 66, 540, 135, 540, 135, 540, 540, 135, 66, 540, 135, 66, 66, 135, 540, 66, 135, 66, 66, 135, 135, 135, 66, 66, 540, 135, 135, 66, 540, 540, 135, 540, 540, 135, 540, 66, 540, 135, 135, 135, 540, 540, 66, 66, 135, 66, 540, 66, 66, 540, 66, 135, 135, 66, 135, 540, 540, 540, 135, 540, 540, 66, 66, 540, 135, 540, 66, 135, 540, 66, 540, 135, 66, 540, 66, 66, 540, 66, 66, 135]
Prompts retrieved: 23712 . Total input tokens: 5259212 . Total output tokens: 4661994
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 1.0291954311542213,
    "estimated_duration": 3599.8407012847674,
    "input_throughput": 538.688003418571,
    "output_throughput": 486.79292930228394,
    "total_throughput": 1025.480932720855,
    "itl": 22.664722575116667,
    "ttft": 6743.691371700369,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6572794814407825,
    "arrivals": 8052,
    "finished_requests": 8037,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0292457533068955. Arrivals time: 0.030607244931161404 Scheduler time: 0.6202990640886128 Scheduler overhead time: 0.1273862812668085 Adapter cache time: 0.060279762372374535 Engine time: 0.12683533178642392 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-32/adapters_96_slots_96_rate_0.05-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-32/adapters_96_slots_96_rate_0.05-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 540, 135, 135, 135, 135, 540, 135, 540, 135, 66, 540, 66, 66, 540, 135, 540, 135, 540, 540, 135, 66, 540, 135, 66, 66, 135, 540, 66, 135, 66, 66, 135, 135, 135, 66, 66, 540, 135, 135, 66, 540, 540, 135, 540, 540, 135, 540, 66, 540, 135, 135, 135, 540, 540, 66, 66, 135, 66, 540, 66, 66, 540, 66, 135, 135, 66, 135, 540, 540, 540, 135, 540, 540, 66, 66, 540, 135, 540, 66, 135, 540, 66, 540, 135, 66, 540, 66, 66, 540, 66, 66, 135]
Prompts retrieved: 23712 . Total input tokens: 5259212 . Total output tokens: 4661994
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 1.0195812210440636,
    "estimated_duration": 3599.836955241811,
    "input_throughput": 538.6885639851816,
    "output_throughput": 486.79343586612185,
    "total_throughput": 1025.4819998513035,
    "itl": 22.500946240740028,
    "ttft": 6743.5086886104045,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7139934895932676,
    "arrivals": 8052,
    "finished_requests": 8037,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0196633492596447. Arrivals time: 0.030405510682612658 Scheduler time: 0.607724198140204 Scheduler overhead time: 0.129096413962543 Adapter cache time: 0.06061880849301815 Engine time: 0.1276220022700727 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-16/adapters_96_slots_96_rate_0.05-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-16/adapters_96_slots_96_rate_0.05-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 540, 135, 135, 135, 135, 540, 135, 540, 135, 66, 540, 66, 66, 540, 135, 540, 135, 540, 540, 135, 66, 540, 135, 66, 66, 135, 540, 66, 135, 66, 66, 135, 135, 135, 66, 66, 540, 135, 135, 66, 540, 540, 135, 540, 540, 135, 540, 66, 540, 135, 135, 135, 540, 540, 66, 66, 135, 66, 540, 66, 66, 540, 66, 135, 135, 66, 135, 540, 540, 540, 135, 540, 540, 66, 66, 540, 135, 540, 66, 135, 540, 66, 540, 135, 66, 540, 66, 66, 540, 66, 66, 135]
Prompts retrieved: 23712 . Total input tokens: 5259212 . Total output tokens: 4661994
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 1.0263449270278215,
    "estimated_duration": 3599.836982324049,
    "input_throughput": 538.6885599325282,
    "output_throughput": 486.793432203885,
    "total_throughput": 1025.4819921364133,
    "itl": 22.50024148639138,
    "ttft": 6743.554116209835,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6128564102947712,
    "arrivals": 8052,
    "finished_requests": 8037,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0263949371874332. Arrivals time: 0.030260139144957066 Scheduler time: 0.6065543866716325 Scheduler overhead time: 0.13119270326569676 Adapter cache time: 0.06111838249489665 Engine time: 0.13327706651762128 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-32/adapters_96_slots_96_rate_0.05-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-32/adapters_96_slots_96_rate_0.05-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 540, 135, 135, 135, 135, 540, 135, 540, 135, 66, 540, 66, 66, 540, 135, 540, 135, 540, 540, 135, 66, 540, 135, 66, 66, 135, 540, 66, 135, 66, 66, 135, 135, 135, 66, 66, 540, 135, 135, 66, 540, 540, 135, 540, 540, 135, 540, 66, 540, 135, 135, 135, 540, 540, 66, 66, 135, 66, 540, 66, 66, 540, 66, 135, 135, 66, 135, 540, 540, 540, 135, 540, 540, 66, 66, 540, 135, 540, 66, 135, 540, 66, 540, 135, 66, 540, 66, 66, 540, 66, 66, 135]
Prompts retrieved: 23712 . Total input tokens: 5259212 . Total output tokens: 4661994
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.0350127569399774,
    "estimated_duration": 3599.8251564804746,
    "input_throughput": 538.6903295869887,
    "output_throughput": 486.79503137682593,
    "total_throughput": 1025.4853609638146,
    "itl": 22.50070022283698,
    "ttft": 6743.33812317204,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7073657399415971,
    "arrivals": 8052,
    "finished_requests": 8037,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0350903780199587. Arrivals time: 0.03096357313916087 Scheduler time: 0.6207823599688709 Scheduler overhead time: 0.12860653921961784 Adapter cache time: 0.061466018203645945 Engine time: 0.12907469924539328 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-8/adapters_96_slots_96_rate_0.05-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-8/adapters_96_slots_96_rate_0.05-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 540, 135, 135, 135, 135, 540, 135, 540, 135, 33, 540, 33, 33, 540, 135, 540, 135, 540, 540, 135, 33, 540, 135, 33, 33, 135, 540, 33, 135, 33, 33, 135, 135, 135, 33, 33, 540, 135, 135, 33, 540, 540, 135, 540, 540, 135, 540, 33, 540, 135, 135, 135, 540, 540, 33, 33, 135, 33, 540, 33, 33, 540, 33, 135, 135, 33, 135, 540, 540, 540, 135, 540, 540, 33, 33, 540, 135, 540, 33, 135, 540, 33, 540, 135, 33, 540, 33, 33, 540, 33, 33, 135]
Prompts retrieved: 22656 . Total input tokens: 5036055 . Total output tokens: 4457254
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 0.9972136840224266,
    "estimated_duration": 3599.4346424090777,
    "input_throughput": 518.0424664557863,
    "output_throughput": 458.11611095023596,
    "total_throughput": 976.1585774060223,
    "itl": 22.220914850958135,
    "ttft": 6636.962852311343,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6347912670671934,
    "arrivals": 7636,
    "finished_requests": 7622,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9972664397209883. Arrivals time: 0.02993891341611743 Scheduler time: 0.5864886273629963 Scheduler overhead time: 0.12893934454768896 Adapter cache time: 0.057908018585294485 Engine time: 0.12913723709061742 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-16/adapters_96_slots_96_rate_0.05-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-16/adapters_96_slots_96_rate_0.05-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 540, 135, 135, 135, 135, 540, 135, 540, 135, 33, 540, 33, 33, 540, 135, 540, 135, 540, 540, 135, 33, 540, 135, 33, 33, 135, 540, 33, 135, 33, 33, 135, 135, 135, 33, 33, 540, 135, 135, 33, 540, 540, 135, 540, 540, 135, 540, 33, 540, 135, 135, 135, 540, 540, 33, 33, 135, 33, 540, 33, 33, 540, 33, 135, 135, 33, 135, 540, 540, 540, 135, 540, 540, 33, 33, 540, 135, 540, 33, 135, 540, 33, 540, 135, 33, 540, 33, 33, 540, 33, 33, 135]
Prompts retrieved: 22656 . Total input tokens: 5036055 . Total output tokens: 4457254
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.0011474331840873,
    "estimated_duration": 3599.4420248015954,
    "input_throughput": 518.0414039597656,
    "output_throughput": 458.11517136212024,
    "total_throughput": 976.1565753218858,
    "itl": 22.22125283907039,
    "ttft": 6636.974976185726,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7017025525867941,
    "arrivals": 7636,
    "finished_requests": 7622,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0012513939291239. Arrivals time: 0.030047496780753136 Scheduler time: 0.5892207371070981 Scheduler overhead time: 0.1302790534682572 Adapter cache time: 0.05845884792506695 Engine time: 0.12852679938077927 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-32/adapters_96_slots_96_rate_0.05-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-32/adapters_96_slots_96_rate_0.05-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 540, 135, 135, 135, 135, 540, 135, 540, 135, 33, 540, 33, 33, 540, 135, 540, 135, 540, 540, 135, 33, 540, 135, 33, 33, 135, 540, 33, 135, 33, 33, 135, 135, 135, 33, 33, 540, 135, 135, 33, 540, 540, 135, 540, 540, 135, 540, 33, 540, 135, 135, 135, 540, 540, 33, 33, 135, 33, 540, 33, 33, 540, 33, 135, 135, 33, 135, 540, 540, 540, 135, 540, 540, 33, 33, 540, 135, 540, 33, 135, 540, 33, 540, 135, 33, 540, 33, 33, 540, 33, 33, 135]
Prompts retrieved: 22656 . Total input tokens: 5036055 . Total output tokens: 4457254
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 0.9937612982466817,
    "estimated_duration": 3599.4371668043736,
    "input_throughput": 518.0421031367715,
    "output_throughput": 458.1157896594058,
    "total_throughput": 976.1578927961773,
    "itl": 22.221332182617065,
    "ttft": 6636.92317855991,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.720621239244938,
    "arrivals": 7636,
    "finished_requests": 7622,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9938119729049504. Arrivals time: 0.029537121299654245 Scheduler time: 0.5831971876323223 Scheduler overhead time: 0.12925670249387622 Adapter cache time: 0.0577151644974947 Engine time: 0.12943103583529592 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-16/adapters_96_slots_96_rate_0.05-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-16/adapters_96_slots_96_rate_0.05-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 540, 135, 135, 135, 135, 540, 135, 540, 135, 33, 540, 33, 33, 540, 135, 540, 135, 540, 540, 135, 33, 540, 135, 33, 33, 135, 540, 33, 135, 33, 33, 135, 135, 135, 33, 33, 540, 135, 135, 33, 540, 540, 135, 540, 540, 135, 540, 33, 540, 135, 135, 135, 540, 540, 33, 33, 135, 33, 540, 33, 33, 540, 33, 135, 135, 33, 135, 540, 540, 540, 135, 540, 540, 33, 33, 540, 135, 540, 33, 135, 540, 33, 540, 135, 33, 540, 33, 33, 540, 33, 33, 135]
Prompts retrieved: 22656 . Total input tokens: 5036055 . Total output tokens: 4457254
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 0.9938813890330493,
    "estimated_duration": 3599.4419532863008,
    "input_throughput": 518.04141425244,
    "output_throughput": 458.1151804641538,
    "total_throughput": 976.1565947165938,
    "itl": 22.221030476108687,
    "ttft": 6636.975531460603,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6572794814407825,
    "arrivals": 7636,
    "finished_requests": 7622,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9939480009488761. Arrivals time: 0.029645463917404413 Scheduler time: 0.5831282720901072 Scheduler overhead time: 0.12911470420658588 Adapter cache time: 0.057749176397919655 Engine time: 0.12971639027819037 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-32/adapters_96_slots_96_rate_0.05-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-32/adapters_96_slots_96_rate_0.05-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 540, 135, 135, 135, 135, 540, 135, 540, 135, 33, 540, 33, 33, 540, 135, 540, 135, 540, 540, 135, 33, 540, 135, 33, 33, 135, 540, 33, 135, 33, 33, 135, 135, 135, 33, 33, 540, 135, 135, 33, 540, 540, 135, 540, 540, 135, 540, 33, 540, 135, 135, 135, 540, 540, 33, 33, 135, 33, 540, 33, 33, 540, 33, 135, 135, 33, 135, 540, 540, 540, 135, 540, 540, 33, 33, 540, 135, 540, 33, 135, 540, 33, 540, 135, 33, 540, 33, 33, 540, 33, 33, 135]
Prompts retrieved: 22656 . Total input tokens: 5036055 . Total output tokens: 4457254
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 0.9872925626114011,
    "estimated_duration": 3599.429936887467,
    "input_throughput": 518.0431436908108,
    "output_throughput": 458.1167098437547,
    "total_throughput": 976.1598535345654,
    "itl": 22.2214608619325,
    "ttft": 6636.935017287045,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7139934895932676,
    "arrivals": 7636,
    "finished_requests": 7622,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9873458077199757. Arrivals time: 0.029272119980305433 Scheduler time: 0.5803053146228194 Scheduler overhead time: 0.12930490169674158 Adapter cache time: 0.05770094320178032 Engine time: 0.12602218333631754 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-16/adapters_96_slots_96_rate_0.05-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-16/adapters_96_slots_96_rate_0.05-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 540, 135, 135, 135, 135, 540, 135, 540, 135, 33, 540, 33, 33, 540, 135, 540, 135, 540, 540, 135, 33, 540, 135, 33, 33, 135, 540, 33, 135, 33, 33, 135, 135, 135, 33, 33, 540, 135, 135, 33, 540, 540, 135, 540, 540, 135, 540, 33, 540, 135, 135, 135, 540, 540, 33, 33, 135, 33, 540, 33, 33, 540, 33, 135, 135, 33, 135, 540, 540, 540, 135, 540, 540, 33, 33, 540, 135, 540, 33, 135, 540, 33, 540, 135, 33, 540, 33, 33, 540, 33, 33, 135]
Prompts retrieved: 22656 . Total input tokens: 5036055 . Total output tokens: 4457254
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 0.9882293702103198,
    "estimated_duration": 3599.431863927136,
    "input_throughput": 518.04286634435,
    "output_throughput": 458.11646458030583,
    "total_throughput": 976.1593309246558,
    "itl": 22.221309397161427,
    "ttft": 6636.810497724475,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6128564102947712,
    "arrivals": 7636,
    "finished_requests": 7622,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9882975281216204. Arrivals time: 0.0295314472168684 Scheduler time: 0.5796238901093602 Scheduler overhead time: 0.1300276843830943 Adapter cache time: 0.057273991871625185 Engine time: 0.12698131566867232 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-32/adapters_96_slots_96_rate_0.05-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-32/adapters_96_slots_96_rate_0.05-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 540, 135, 135, 135, 135, 540, 135, 540, 135, 33, 540, 33, 33, 540, 135, 540, 135, 540, 540, 135, 33, 540, 135, 33, 33, 135, 540, 33, 135, 33, 33, 135, 135, 135, 33, 33, 540, 135, 135, 33, 540, 540, 135, 540, 540, 135, 540, 33, 540, 135, 135, 135, 540, 540, 33, 33, 135, 33, 540, 33, 33, 540, 33, 135, 135, 33, 135, 540, 540, 540, 135, 540, 540, 33, 33, 540, 135, 540, 33, 135, 540, 33, 540, 135, 33, 540, 33, 33, 540, 33, 33, 135]
Prompts retrieved: 22656 . Total input tokens: 5036055 . Total output tokens: 4457254
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 0.9916736870072782,
    "estimated_duration": 3599.4241735106793,
    "input_throughput": 518.0439731784414,
    "output_throughput": 458.1174433775324,
    "total_throughput": 976.1614165559738,
    "itl": 22.22121961534017,
    "ttft": 6637.013054437312,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7073657399415971,
    "arrivals": 7636,
    "finished_requests": 7622,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9917231262661517. Arrivals time: 0.02945612883195281 Scheduler time: 0.5819532861933112 Scheduler overhead time: 0.1300942380912602 Adapter cache time: 0.057362979743629694 Engine time: 0.1278152847662568 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-8/adapters_96_slots_96_rate_0.05-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-8/adapters_96_slots_96_rate_0.05-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 540, 66, 66, 66, 66, 540, 66, 540, 66, 33, 540, 33, 33, 540, 66, 540, 66, 540, 540, 66, 33, 540, 66, 33, 33, 66, 540, 33, 66, 33, 33, 66, 66, 66, 33, 33, 540, 66, 66, 33, 540, 540, 66, 540, 540, 66, 540, 33, 540, 66, 66, 66, 540, 540, 33, 33, 66, 33, 540, 33, 33, 540, 33, 66, 66, 33, 66, 540, 540, 540, 66, 540, 540, 33, 33, 540, 66, 540, 33, 66, 540, 33, 540, 66, 33, 540, 33, 33, 540, 33, 33, 66]
Prompts retrieved: 20448 . Total input tokens: 4545729 . Total output tokens: 4043414
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 0.9433958567678928,
    "estimated_duration": 3599.3614413648384,
    "input_throughput": 468.7845406712433,
    "output_throughput": 420.6904543117586,
    "total_throughput": 889.4749949830019,
    "itl": 21.948370707641747,
    "ttft": 5738.902497428137,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6347912670671934,
    "arrivals": 6944,
    "finished_requests": 6933,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9434637031517923. Arrivals time: 0.02790462877601385 Scheduler time: 0.5400226609781384 Scheduler overhead time: 0.12980410363525152 Adapter cache time: 0.05296096624806523 Engine time: 0.12752431770786643 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-16/adapters_96_slots_96_rate_0.05-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-16/adapters_96_slots_96_rate_0.05-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 540, 66, 66, 66, 66, 540, 66, 540, 66, 33, 540, 33, 33, 540, 66, 540, 66, 540, 540, 66, 33, 540, 66, 33, 33, 66, 540, 33, 66, 33, 33, 66, 66, 66, 33, 33, 540, 66, 66, 33, 540, 540, 66, 540, 540, 66, 540, 33, 540, 66, 66, 66, 540, 540, 33, 33, 66, 33, 540, 33, 33, 540, 33, 66, 66, 33, 66, 540, 540, 540, 66, 540, 540, 33, 33, 540, 66, 540, 33, 66, 540, 33, 540, 66, 33, 540, 33, 33, 540, 33, 33, 66]
Prompts retrieved: 20448 . Total input tokens: 4545729 . Total output tokens: 4043414
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 0.9410179620608687,
    "estimated_duration": 3599.3614413648384,
    "input_throughput": 468.7845406712433,
    "output_throughput": 420.6904543117586,
    "total_throughput": 889.4749949830019,
    "itl": 21.94830923488698,
    "ttft": 5738.962275068761,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7017025525867941,
    "arrivals": 6944,
    "finished_requests": 6933,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.941066921222955. Arrivals time: 0.027712823823094368 Scheduler time: 0.5408404408954084 Scheduler overhead time: 0.1297051440924406 Adapter cache time: 0.052330026403069496 Engine time: 0.12549779005348682 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-32/adapters_96_slots_96_rate_0.05-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-32/adapters_96_slots_96_rate_0.05-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 540, 66, 66, 66, 66, 540, 66, 540, 66, 33, 540, 33, 33, 540, 66, 540, 66, 540, 540, 66, 33, 540, 66, 33, 33, 66, 540, 33, 66, 33, 33, 66, 66, 66, 33, 33, 540, 66, 66, 33, 540, 540, 66, 540, 540, 66, 540, 33, 540, 66, 66, 66, 540, 540, 33, 33, 66, 33, 540, 33, 33, 540, 33, 66, 66, 33, 66, 540, 540, 540, 66, 540, 540, 33, 33, 540, 66, 540, 33, 66, 540, 33, 540, 66, 33, 540, 33, 33, 540, 33, 33, 66]
Prompts retrieved: 20448 . Total input tokens: 4545729 . Total output tokens: 4043414
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 0.9369174051098526,
    "estimated_duration": 3599.3614413648384,
    "input_throughput": 468.7845406712433,
    "output_throughput": 420.6904543117586,
    "total_throughput": 889.4749949830019,
    "itl": 21.949059266566174,
    "ttft": 5738.809381485299,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.720621239244938,
    "arrivals": 6944,
    "finished_requests": 6933,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9370233048684895. Arrivals time: 0.027516720816493034 Scheduler time: 0.5374039965681732 Scheduler overhead time: 0.12915252661332488 Adapter cache time: 0.05255098594352603 Engine time: 0.12571217119693756 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-16/adapters_96_slots_96_rate_0.05-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-16/adapters_96_slots_96_rate_0.05-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 540, 66, 66, 66, 66, 540, 66, 540, 66, 33, 540, 33, 33, 540, 66, 540, 66, 540, 540, 66, 33, 540, 66, 33, 33, 66, 540, 33, 66, 33, 33, 66, 66, 66, 33, 33, 540, 66, 66, 33, 540, 540, 66, 540, 540, 66, 540, 33, 540, 66, 66, 66, 540, 540, 33, 33, 66, 33, 540, 33, 33, 540, 33, 66, 66, 33, 66, 540, 540, 540, 66, 540, 540, 33, 33, 540, 66, 540, 33, 66, 540, 33, 540, 66, 33, 540, 33, 33, 540, 33, 33, 66]
Prompts retrieved: 20448 . Total input tokens: 4545729 . Total output tokens: 4043414
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 0.9465977321378887,
    "estimated_duration": 3599.3614413648384,
    "input_throughput": 468.7845406712433,
    "output_throughput": 420.6904543117586,
    "total_throughput": 889.4749949830019,
    "itl": 21.948285512574127,
    "ttft": 5738.868836620054,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6572794814407825,
    "arrivals": 6944,
    "finished_requests": 6933,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9466493320651352. Arrivals time: 0.027965484652668238 Scheduler time: 0.5447566593065858 Scheduler overhead time: 0.12892496213316917 Adapter cache time: 0.0526226838119328 Engine time: 0.12714480329304934 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-32/adapters_96_slots_96_rate_0.05-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-32/adapters_96_slots_96_rate_0.05-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 540, 66, 66, 66, 66, 540, 66, 540, 66, 33, 540, 33, 33, 540, 66, 540, 66, 540, 540, 66, 33, 540, 66, 33, 33, 66, 540, 33, 66, 33, 33, 66, 66, 66, 33, 33, 540, 66, 66, 33, 540, 540, 66, 540, 540, 66, 540, 33, 540, 66, 66, 66, 540, 540, 33, 33, 66, 33, 540, 33, 33, 540, 33, 66, 66, 33, 66, 540, 540, 540, 66, 540, 540, 33, 33, 540, 66, 540, 33, 66, 540, 33, 540, 66, 33, 540, 33, 33, 540, 33, 33, 66]
Prompts retrieved: 20448 . Total input tokens: 4545729 . Total output tokens: 4043414
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 0.9625389240682125,
    "estimated_duration": 3599.3614413648384,
    "input_throughput": 468.7845406712433,
    "output_throughput": 420.6904543117586,
    "total_throughput": 889.4749949830019,
    "itl": 21.948852246492482,
    "ttft": 5738.891560500763,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7139934895932676,
    "arrivals": 6944,
    "finished_requests": 6933,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9626443423330784. Arrivals time: 0.02856797305867076 Scheduler time: 0.5469072381965816 Scheduler overhead time: 0.1327086635865271 Adapter cache time: 0.05313720507547259 Engine time: 0.1360818175598979 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-16/adapters_96_slots_96_rate_0.05-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-16/adapters_96_slots_96_rate_0.05-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 540, 66, 66, 66, 66, 540, 66, 540, 66, 33, 540, 33, 33, 540, 66, 540, 66, 540, 540, 66, 33, 540, 66, 33, 33, 66, 540, 33, 66, 33, 33, 66, 66, 66, 33, 33, 540, 66, 66, 33, 540, 540, 66, 540, 540, 66, 540, 33, 540, 66, 66, 66, 540, 540, 33, 33, 66, 33, 540, 33, 33, 540, 33, 66, 66, 33, 66, 540, 540, 540, 66, 540, 540, 33, 33, 540, 66, 540, 33, 66, 540, 33, 540, 66, 33, 540, 33, 33, 540, 33, 33, 66]
Prompts retrieved: 20448 . Total input tokens: 4545729 . Total output tokens: 4043414
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 0.9587817350402474,
    "estimated_duration": 3599.3614413648384,
    "input_throughput": 468.7845406712433,
    "output_throughput": 420.6904543117586,
    "total_throughput": 889.4749949830019,
    "itl": 21.947675463152105,
    "ttft": 5738.8756640792335,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6128564102947712,
    "arrivals": 6944,
    "finished_requests": 6933,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9588416111655533. Arrivals time: 0.027994513977319002 Scheduler time: 0.5471850992180407 Scheduler overhead time: 0.13288872176781297 Adapter cache time: 0.05274515273049474 Engine time: 0.13282939698547125 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-32/adapters_96_slots_96_rate_0.05-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-32/adapters_96_slots_96_rate_0.05-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 540, 66, 66, 66, 66, 540, 66, 540, 66, 33, 540, 33, 33, 540, 66, 540, 66, 540, 540, 66, 33, 540, 66, 33, 33, 66, 540, 33, 66, 33, 33, 66, 66, 66, 33, 33, 540, 66, 66, 33, 540, 540, 66, 540, 540, 66, 540, 33, 540, 66, 66, 66, 540, 540, 33, 33, 66, 33, 540, 33, 33, 540, 33, 66, 66, 33, 66, 540, 540, 540, 66, 540, 540, 33, 33, 540, 66, 540, 33, 66, 540, 33, 540, 66, 33, 540, 33, 33, 540, 33, 33, 66]
Prompts retrieved: 20448 . Total input tokens: 4545729 . Total output tokens: 4043414
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 0.9494483917951584,
    "estimated_duration": 3599.3614413648384,
    "input_throughput": 468.7845406712433,
    "output_throughput": 420.6904543117586,
    "total_throughput": 889.4749949830019,
    "itl": 21.948289254543415,
    "ttft": 5739.060457624455,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7073657399415971,
    "arrivals": 6944,
    "finished_requests": 6933,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9494993258267641. Arrivals time: 0.028336844407022 Scheduler time: 0.546811263076961 Scheduler overhead time: 0.1295204432681203 Adapter cache time: 0.05267545348033309 Engine time: 0.12714180769398808 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-8/adapters_96_slots_96_rate_0.025-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-8/adapters_96_slots_96_rate_0.025-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 270, 135, 135, 135, 135, 270, 135, 270, 135, 66, 270, 66, 66, 270, 135, 270, 135, 270, 270, 135, 66, 270, 135, 66, 66, 135, 270, 66, 135, 66, 66, 135, 135, 135, 66, 66, 270, 135, 135, 66, 270, 270, 135, 270, 270, 135, 270, 66, 270, 135, 135, 135, 270, 270, 66, 66, 135, 66, 270, 66, 66, 270, 66, 135, 135, 66, 135, 270, 270, 270, 135, 270, 270, 66, 66, 270, 135, 270, 66, 135, 270, 66, 270, 135, 66, 270, 66, 66, 270, 66, 66, 135]
Prompts retrieved: 15072 . Total input tokens: 3332730 . Total output tokens: 3000837
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 0.8198557561263442,
    "estimated_duration": 3599.4959956400994,
    "input_throughput": 348.83550405970396,
    "output_throughput": 300.51818402082665,
    "total_throughput": 649.3536880805306,
    "itl": 21.186922776086572,
    "ttft": 5715.534134391023,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6347912670671934,
    "arrivals": 5070,
    "finished_requests": 5062,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8200011379085481. Arrivals time: 0.024017561692744493 Scheduler time: 0.4206486758776009 Scheduler overhead time: 0.13080186303704977 Adapter cache time: 0.048632736783474684 Engine time: 0.12919454090297222 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-16/adapters_96_slots_96_rate_0.025-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-16/adapters_96_slots_96_rate_0.025-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 270, 135, 135, 135, 135, 270, 135, 270, 135, 66, 270, 66, 66, 270, 135, 270, 135, 270, 270, 135, 66, 270, 135, 66, 66, 135, 270, 66, 135, 66, 66, 135, 135, 135, 66, 66, 270, 135, 135, 66, 270, 270, 135, 270, 270, 135, 270, 66, 270, 135, 135, 135, 270, 270, 66, 66, 135, 66, 270, 66, 66, 270, 66, 135, 135, 66, 135, 270, 270, 270, 135, 270, 270, 66, 66, 270, 135, 270, 66, 135, 270, 66, 270, 135, 66, 270, 66, 66, 270, 66, 66, 135]
Prompts retrieved: 15072 . Total input tokens: 3332730 . Total output tokens: 3000837
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 0.8326709461398423,
    "estimated_duration": 3599.4959956400994,
    "input_throughput": 348.83550405970396,
    "output_throughput": 300.51818402082665,
    "total_throughput": 649.3536880805306,
    "itl": 21.188155492794234,
    "ttft": 5715.479301778485,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7017025525867943,
    "arrivals": 5070,
    "finished_requests": 5062,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.832723509054631. Arrivals time: 0.027347654104232788 Scheduler time: 0.42717833910137415 Scheduler overhead time: 0.13194534555077553 Adapter cache time: 0.04913042485713959 Engine time: 0.13028864050284028 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-32/adapters_96_slots_96_rate_0.025-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-32/adapters_96_slots_96_rate_0.025-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 270, 135, 135, 135, 135, 270, 135, 270, 135, 66, 270, 66, 66, 270, 135, 270, 135, 270, 270, 135, 66, 270, 135, 66, 66, 135, 270, 66, 135, 66, 66, 135, 135, 135, 66, 66, 270, 135, 135, 66, 270, 270, 135, 270, 270, 135, 270, 66, 270, 135, 135, 135, 270, 270, 66, 66, 135, 66, 270, 66, 66, 270, 66, 135, 135, 66, 135, 270, 270, 270, 135, 270, 270, 66, 66, 270, 135, 270, 66, 135, 270, 66, 270, 135, 66, 270, 66, 66, 270, 66, 66, 135]
Prompts retrieved: 15072 . Total input tokens: 3332730 . Total output tokens: 3000837
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 0.8160046362318099,
    "estimated_duration": 3599.4959956400994,
    "input_throughput": 348.83550405970396,
    "output_throughput": 300.51818402082665,
    "total_throughput": 649.3536880805306,
    "itl": 21.186760804752232,
    "ttft": 5715.489373653089,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.720621239244938,
    "arrivals": 5070,
    "finished_requests": 5062,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8160528033040464. Arrivals time: 0.024261973798274994 Scheduler time: 0.41835489636287093 Scheduler overhead time: 0.13009266648441553 Adapter cache time: 0.04845068883150816 Engine time: 0.1288800179027021 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-16/adapters_96_slots_96_rate_0.025-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-16/adapters_96_slots_96_rate_0.025-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 270, 135, 135, 135, 135, 270, 135, 270, 135, 66, 270, 66, 66, 270, 135, 270, 135, 270, 270, 135, 66, 270, 135, 66, 66, 135, 270, 66, 135, 66, 66, 135, 135, 135, 66, 66, 270, 135, 135, 66, 270, 270, 135, 270, 270, 135, 270, 66, 270, 135, 135, 135, 270, 270, 66, 66, 135, 66, 270, 66, 66, 270, 66, 135, 135, 66, 135, 270, 270, 270, 135, 270, 270, 66, 66, 270, 135, 270, 66, 135, 270, 66, 270, 135, 66, 270, 66, 66, 270, 66, 66, 135]
Prompts retrieved: 15072 . Total input tokens: 3332730 . Total output tokens: 3000837
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 0.8233219347894192,
    "estimated_duration": 3599.4959956400994,
    "input_throughput": 348.83550405970396,
    "output_throughput": 300.51818402082665,
    "total_throughput": 649.3536880805306,
    "itl": 21.18790207195833,
    "ttft": 5715.491105313342,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6572794814407826,
    "arrivals": 5070,
    "finished_requests": 5062,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8233960680663586. Arrivals time: 0.024418442975729704 Scheduler time: 0.422823881264776 Scheduler overhead time: 0.1322391559369862 Adapter cache time: 0.04861131543293595 Engine time: 0.1285126325674355 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-32/adapters_96_slots_96_rate_0.025-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-32/adapters_96_slots_96_rate_0.025-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 270, 135, 135, 135, 135, 270, 135, 270, 135, 66, 270, 66, 66, 270, 135, 270, 135, 270, 270, 135, 66, 270, 135, 66, 66, 135, 270, 66, 135, 66, 66, 135, 135, 135, 66, 66, 270, 135, 135, 66, 270, 270, 135, 270, 270, 135, 270, 66, 270, 135, 135, 135, 270, 270, 66, 66, 135, 66, 270, 66, 66, 270, 66, 135, 135, 66, 135, 270, 270, 270, 135, 270, 270, 66, 66, 270, 135, 270, 66, 135, 270, 66, 270, 135, 66, 270, 66, 66, 270, 66, 66, 135]
Prompts retrieved: 15072 . Total input tokens: 3332730 . Total output tokens: 3000837
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 0.8213881449773908,
    "estimated_duration": 3599.4959956400994,
    "input_throughput": 348.83550405970396,
    "output_throughput": 300.51818402082665,
    "total_throughput": 649.3536880805306,
    "itl": 21.186665740246422,
    "ttft": 5715.561858798173,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7139934895932676,
    "arrivals": 5070,
    "finished_requests": 5062,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8214534199796617. Arrivals time: 0.024601686280220747 Scheduler time: 0.4211319833993912 Scheduler overhead time: 0.13097105082124472 Adapter cache time: 0.048324065282940865 Engine time: 0.130041369702667 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-16/adapters_96_slots_96_rate_0.025-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-16/adapters_96_slots_96_rate_0.025-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 270, 135, 135, 135, 135, 270, 135, 270, 135, 66, 270, 66, 66, 270, 135, 270, 135, 270, 270, 135, 66, 270, 135, 66, 66, 135, 270, 66, 135, 66, 66, 135, 135, 135, 66, 66, 270, 135, 135, 66, 270, 270, 135, 270, 270, 135, 270, 66, 270, 135, 135, 135, 270, 270, 66, 66, 135, 66, 270, 66, 66, 270, 66, 135, 135, 66, 135, 270, 270, 270, 135, 270, 270, 66, 66, 270, 135, 270, 66, 135, 270, 66, 270, 135, 66, 270, 66, 66, 270, 66, 66, 135]
Prompts retrieved: 15072 . Total input tokens: 3332730 . Total output tokens: 3000837
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 0.8201414770446718,
    "estimated_duration": 3599.4959956400994,
    "input_throughput": 348.83550405970396,
    "output_throughput": 300.51818402082665,
    "total_throughput": 649.3536880805306,
    "itl": 21.18740108002492,
    "ttft": 5715.514080584659,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6128564102947712,
    "arrivals": 5070,
    "finished_requests": 5062,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.820191599894315. Arrivals time: 0.024321697652339935 Scheduler time: 0.41935337521135807 Scheduler overhead time: 0.1313196332193911 Adapter cache time: 0.04859838401898742 Engine time: 0.13013141555711627 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-32/adapters_96_slots_96_rate_0.025-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-32/adapters_96_slots_96_rate_0.025-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 270, 135, 135, 135, 135, 270, 135, 270, 135, 66, 270, 66, 66, 270, 135, 270, 135, 270, 270, 135, 66, 270, 135, 66, 66, 135, 270, 66, 135, 66, 66, 135, 135, 135, 66, 66, 270, 135, 135, 66, 270, 270, 135, 270, 270, 135, 270, 66, 270, 135, 135, 135, 270, 270, 66, 66, 135, 66, 270, 66, 66, 270, 66, 135, 135, 66, 135, 270, 270, 270, 135, 270, 270, 66, 66, 270, 135, 270, 66, 135, 270, 66, 270, 135, 66, 270, 66, 66, 270, 66, 66, 135]
Prompts retrieved: 15072 . Total input tokens: 3332730 . Total output tokens: 3000837
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 0.8339463681913912,
    "estimated_duration": 3599.4959956400994,
    "input_throughput": 348.83550405970396,
    "output_throughput": 300.51818402082665,
    "total_throughput": 649.3536880805306,
    "itl": 21.188222166137088,
    "ttft": 5715.587549173714,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7073657399415971,
    "arrivals": 5070,
    "finished_requests": 5062,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8340011802501976. Arrivals time: 0.024632434360682964 Scheduler time: 0.4229520126245916 Scheduler overhead time: 0.13495253631845117 Adapter cache time: 0.04904281673952937 Engine time: 0.13582068588584661 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-8/adapters_96_slots_96_rate_0.025-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-8/adapters_96_slots_96_rate_0.025-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 270, 135, 135, 135, 135, 270, 135, 270, 135, 33, 270, 33, 33, 270, 135, 270, 135, 270, 270, 135, 33, 270, 135, 33, 33, 135, 270, 33, 135, 33, 33, 135, 135, 135, 33, 33, 270, 135, 135, 33, 270, 270, 135, 270, 270, 135, 270, 33, 270, 135, 135, 135, 270, 270, 33, 33, 135, 33, 270, 33, 33, 270, 33, 135, 135, 33, 135, 270, 270, 270, 135, 270, 270, 33, 33, 270, 135, 270, 33, 135, 270, 33, 270, 135, 33, 270, 33, 33, 270, 33, 33, 135]
Prompts retrieved: 14016 . Total input tokens: 3084908 . Total output tokens: 2787633
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 0.803786417003721,
    "estimated_duration": 3598.5694800716064,
    "input_throughput": 318.6066036377282,
    "output_throughput": 284.909046685851,
    "total_throughput": 603.5156503235793,
    "itl": 21.054480082391375,
    "ttft": 7681.498280834003,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6347912670671934,
    "arrivals": 4708,
    "finished_requests": 4698,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8038382469676435. Arrivals time: 0.023302185349166393 Scheduler time: 0.40712203783914447 Scheduler overhead time: 0.13116336846724153 Adapter cache time: 0.046703520230948925 Engine time: 0.1287540071643889 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-16/adapters_96_slots_96_rate_0.025-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-16/adapters_96_slots_96_rate_0.025-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 270, 135, 135, 135, 135, 270, 135, 270, 135, 33, 270, 33, 33, 270, 135, 270, 135, 270, 270, 135, 33, 270, 135, 33, 33, 135, 270, 33, 135, 33, 33, 135, 135, 135, 33, 33, 270, 135, 135, 33, 270, 270, 135, 270, 270, 135, 270, 33, 270, 135, 135, 135, 270, 270, 33, 33, 135, 33, 270, 33, 33, 270, 33, 135, 135, 33, 135, 270, 270, 270, 135, 270, 270, 33, 33, 270, 135, 270, 33, 135, 270, 33, 270, 135, 33, 270, 33, 33, 270, 33, 33, 135]
Prompts retrieved: 14016 . Total input tokens: 3084908 . Total output tokens: 2787633
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 0.8032941040582955,
    "estimated_duration": 3598.5694800716064,
    "input_throughput": 318.6066036377282,
    "output_throughput": 284.909046685851,
    "total_throughput": 603.5156503235793,
    "itl": 21.054844352132758,
    "ttft": 7681.637282114182,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.701702552586794,
    "arrivals": 4708,
    "finished_requests": 4698,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8033443512395024. Arrivals time: 0.02314969291910529 Scheduler time: 0.4056889866478741 Scheduler overhead time: 0.13215825939550996 Adapter cache time: 0.046269462909549475 Engine time: 0.1293049925006926 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-32/adapters_96_slots_96_rate_0.025-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-32/adapters_96_slots_96_rate_0.025-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 270, 135, 135, 135, 135, 270, 135, 270, 135, 33, 270, 33, 33, 270, 135, 270, 135, 270, 270, 135, 33, 270, 135, 33, 33, 135, 270, 33, 135, 33, 33, 135, 135, 135, 33, 33, 270, 135, 135, 33, 270, 270, 135, 270, 270, 135, 270, 33, 270, 135, 135, 135, 270, 270, 33, 33, 135, 33, 270, 33, 33, 270, 33, 135, 135, 33, 135, 270, 270, 270, 135, 270, 270, 33, 33, 270, 135, 270, 33, 135, 270, 33, 270, 135, 33, 270, 33, 33, 270, 33, 33, 135]
Prompts retrieved: 14016 . Total input tokens: 3084908 . Total output tokens: 2787633
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 0.8087462689727545,
    "estimated_duration": 3598.5694800716064,
    "input_throughput": 318.6066036377282,
    "output_throughput": 284.909046685851,
    "total_throughput": 603.5156503235793,
    "itl": 21.054924286953444,
    "ttft": 7681.479115295412,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.720621239244938,
    "arrivals": 4708,
    "finished_requests": 4698,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8088039848953485. Arrivals time: 0.023299898952245712 Scheduler time: 0.40809525130316615 Scheduler overhead time: 0.13200361980125308 Adapter cache time: 0.04587456351146102 Engine time: 0.13267483562231064 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-16/adapters_96_slots_96_rate_0.025-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-16/adapters_96_slots_96_rate_0.025-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 270, 135, 135, 135, 135, 270, 135, 270, 135, 33, 270, 33, 33, 270, 135, 270, 135, 270, 270, 135, 33, 270, 135, 33, 33, 135, 270, 33, 135, 33, 33, 135, 135, 135, 33, 33, 270, 135, 135, 33, 270, 270, 135, 270, 270, 135, 270, 33, 270, 135, 135, 135, 270, 270, 33, 33, 135, 33, 270, 33, 33, 270, 33, 135, 135, 33, 135, 270, 270, 270, 135, 270, 270, 33, 33, 270, 135, 270, 33, 135, 270, 33, 270, 135, 33, 270, 33, 33, 270, 33, 33, 135]
Prompts retrieved: 14016 . Total input tokens: 3084908 . Total output tokens: 2787633
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 0.7978943530470133,
    "estimated_duration": 3598.5694800716064,
    "input_throughput": 318.6066036377282,
    "output_throughput": 284.909046685851,
    "total_throughput": 603.5156503235793,
    "itl": 21.054624243332615,
    "ttft": 7681.494560360284,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6572794814407824,
    "arrivals": 4708,
    "finished_requests": 4698,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.79794851411134. Arrivals time: 0.022995335049927235 Scheduler time: 0.4021823820658028 Scheduler overhead time: 0.13143069483339787 Adapter cache time: 0.04621555795893073 Engine time: 0.12839364493265748 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-32/adapters_96_slots_96_rate_0.025-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-32/adapters_96_slots_96_rate_0.025-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 270, 135, 135, 135, 135, 270, 135, 270, 135, 33, 270, 33, 33, 270, 135, 270, 135, 270, 270, 135, 33, 270, 135, 33, 33, 135, 270, 33, 135, 33, 33, 135, 135, 135, 33, 33, 270, 135, 135, 33, 270, 270, 135, 270, 270, 135, 270, 33, 270, 135, 135, 135, 270, 270, 33, 33, 135, 33, 270, 33, 33, 270, 33, 135, 135, 33, 135, 270, 270, 270, 135, 270, 270, 33, 33, 270, 135, 270, 33, 135, 270, 33, 270, 135, 33, 270, 33, 33, 270, 33, 33, 135]
Prompts retrieved: 14016 . Total input tokens: 3084908 . Total output tokens: 2787633
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 0.7972120903432369,
    "estimated_duration": 3598.5694800716064,
    "input_throughput": 318.6066036377282,
    "output_throughput": 284.909046685851,
    "total_throughput": 603.5156503235793,
    "itl": 21.055038043798593,
    "ttft": 7681.384030652521,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7139934895932676,
    "arrivals": 4708,
    "finished_requests": 4698,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7972618602216244. Arrivals time: 0.023244875948876143 Scheduler time: 0.4018064080737531 Scheduler overhead time: 0.1310725579969585 Adapter cache time: 0.046094412449747324 Engine time: 0.12842726288363338 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-16/adapters_96_slots_96_rate_0.025-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-16/adapters_96_slots_96_rate_0.025-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 270, 135, 135, 135, 135, 270, 135, 270, 135, 33, 270, 33, 33, 270, 135, 270, 135, 270, 270, 135, 33, 270, 135, 33, 33, 135, 270, 33, 135, 33, 33, 135, 135, 135, 33, 33, 270, 135, 135, 33, 270, 270, 135, 270, 270, 135, 270, 33, 270, 135, 135, 135, 270, 270, 33, 33, 135, 33, 270, 33, 33, 270, 33, 135, 135, 33, 135, 270, 270, 270, 135, 270, 270, 33, 33, 270, 135, 270, 33, 135, 270, 33, 270, 135, 33, 270, 33, 33, 270, 33, 33, 135]
Prompts retrieved: 14016 . Total input tokens: 3084908 . Total output tokens: 2787633
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 0.8143909410573542,
    "estimated_duration": 3598.5694800716064,
    "input_throughput": 318.6066036377282,
    "output_throughput": 284.909046685851,
    "total_throughput": 603.5156503235793,
    "itl": 21.054392729433438,
    "ttft": 7681.490620595421,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6128564102947712,
    "arrivals": 4708,
    "finished_requests": 4698,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8144562160596251. Arrivals time: 0.0230866726487875 Scheduler time: 0.4068265799432993 Scheduler overhead time: 0.1353101464919746 Adapter cache time: 0.04623229196295142 Engine time: 0.13617274118587375 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-32/adapters_96_slots_96_rate_0.025-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-32/adapters_96_slots_96_rate_0.025-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 270, 135, 135, 135, 135, 270, 135, 270, 135, 33, 270, 33, 33, 270, 135, 270, 135, 270, 270, 135, 33, 270, 135, 33, 33, 135, 270, 33, 135, 33, 33, 135, 135, 135, 33, 33, 270, 135, 135, 33, 270, 270, 135, 270, 270, 135, 270, 33, 270, 135, 135, 135, 270, 270, 33, 33, 135, 33, 270, 33, 33, 270, 33, 135, 135, 33, 135, 270, 270, 270, 135, 270, 270, 33, 33, 270, 135, 270, 33, 135, 270, 33, 270, 135, 33, 270, 33, 33, 270, 33, 33, 135]
Prompts retrieved: 14016 . Total input tokens: 3084908 . Total output tokens: 2787633
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 0.8158633792772889,
    "estimated_duration": 3598.5694800716064,
    "input_throughput": 318.6066036377282,
    "output_throughput": 284.909046685851,
    "total_throughput": 603.5156503235793,
    "itl": 21.054783335290164,
    "ttft": 7681.330215867595,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7073657399415971,
    "arrivals": 4708,
    "finished_requests": 4698,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8159179650247097. Arrivals time: 0.0237798560410738 Scheduler time: 0.4061325192451477 Scheduler overhead time: 0.13563724886626005 Adapter cache time: 0.046083889435976744 Engine time: 0.1375176189467311 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-8/adapters_96_slots_96_rate_0.025-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-8/adapters_96_slots_96_rate_0.025-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 270, 66, 66, 66, 66, 270, 66, 270, 66, 33, 270, 33, 33, 270, 66, 270, 66, 270, 270, 66, 33, 270, 66, 33, 33, 66, 270, 33, 66, 33, 33, 66, 66, 66, 33, 33, 270, 66, 66, 33, 270, 270, 66, 270, 270, 66, 270, 33, 270, 66, 66, 66, 270, 270, 33, 33, 66, 33, 270, 33, 33, 270, 33, 66, 66, 33, 66, 270, 270, 270, 66, 270, 270, 33, 33, 270, 66, 270, 33, 66, 270, 33, 270, 66, 33, 270, 33, 33, 270, 33, 33, 66]
Prompts retrieved: 11808 . Total input tokens: 2580649 . Total output tokens: 2350802
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 0.7466441029682755,
    "estimated_duration": 3599.59168569064,
    "input_throughput": 263.39042946702773,
    "output_throughput": 238.3270312047634,
    "total_throughput": 501.7174606717911,
    "itl": 20.800427811918052,
    "ttft": 3701.1171620481086,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6347912670671934,
    "arrivals": 3927,
    "finished_requests": 3923,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7467041597701609. Arrivals time: 0.02129328018054366 Scheduler time: 0.3560397899709642 Scheduler overhead time: 0.13099308870732784 Adapter cache time: 0.04185239737853408 Engine time: 0.13001568103209138 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-16/adapters_96_slots_96_rate_0.025-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-16/adapters_96_slots_96_rate_0.025-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 270, 66, 66, 66, 66, 270, 66, 270, 66, 33, 270, 33, 33, 270, 66, 270, 66, 270, 270, 66, 33, 270, 66, 33, 33, 66, 270, 33, 66, 33, 33, 66, 66, 66, 33, 33, 270, 66, 66, 33, 270, 270, 66, 270, 270, 66, 270, 33, 270, 66, 66, 66, 270, 270, 33, 33, 66, 33, 270, 33, 33, 270, 33, 66, 66, 33, 66, 270, 270, 270, 66, 270, 270, 33, 33, 270, 66, 270, 33, 66, 270, 33, 270, 66, 33, 270, 33, 33, 270, 33, 33, 66]
Prompts retrieved: 11808 . Total input tokens: 2580649 . Total output tokens: 2350802
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 0.7484368369914591,
    "estimated_duration": 3599.59168569064,
    "input_throughput": 263.39042946702773,
    "output_throughput": 238.3270312047634,
    "total_throughput": 501.7174606717911,
    "itl": 20.800782470218653,
    "ttft": 3701.060236985446,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.701702552586794,
    "arrivals": 3927,
    "finished_requests": 3923,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.74849863210693. Arrivals time: 0.021735867019742727 Scheduler time: 0.3568423194810748 Scheduler overhead time: 0.13197539327666163 Adapter cache time: 0.04163737269118428 Engine time: 0.12938173627480865 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-32/adapters_96_slots_96_rate_0.025-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-32/adapters_96_slots_96_rate_0.025-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 270, 66, 66, 66, 66, 270, 66, 270, 66, 33, 270, 33, 33, 270, 66, 270, 66, 270, 270, 66, 33, 270, 66, 33, 33, 66, 270, 33, 66, 33, 33, 66, 66, 66, 33, 33, 270, 66, 66, 33, 270, 270, 66, 270, 270, 66, 270, 33, 270, 66, 66, 66, 270, 270, 33, 33, 66, 33, 270, 33, 33, 270, 33, 66, 66, 33, 66, 270, 270, 270, 66, 270, 270, 33, 33, 270, 66, 270, 33, 66, 270, 33, 270, 66, 33, 270, 33, 33, 270, 33, 33, 66]
Prompts retrieved: 11808 . Total input tokens: 2580649 . Total output tokens: 2350802
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 0.7488034390844405,
    "estimated_duration": 3599.59168569064,
    "input_throughput": 263.39042946702773,
    "output_throughput": 238.3270312047634,
    "total_throughput": 501.7174606717911,
    "itl": 20.800918979101024,
    "ttft": 3701.123493207341,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.720621239244938,
    "arrivals": 3927,
    "finished_requests": 3923,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7488677129149437. Arrivals time: 0.021762768272310495 Scheduler time: 0.35576612362638116 Scheduler overhead time: 0.13156254636123776 Adapter cache time: 0.04196505667641759 Engine time: 0.1310586635954678 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-16/adapters_96_slots_96_rate_0.025-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-16/adapters_96_slots_96_rate_0.025-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 270, 66, 66, 66, 66, 270, 66, 270, 66, 33, 270, 33, 33, 270, 66, 270, 66, 270, 270, 66, 33, 270, 66, 33, 33, 66, 270, 33, 66, 33, 33, 66, 66, 66, 33, 33, 270, 66, 66, 33, 270, 270, 66, 270, 270, 66, 270, 33, 270, 66, 66, 66, 270, 270, 33, 33, 66, 33, 270, 33, 33, 270, 33, 66, 66, 33, 66, 270, 270, 270, 66, 270, 270, 33, 33, 270, 66, 270, 33, 66, 270, 33, 270, 66, 33, 270, 33, 33, 270, 33, 33, 66]
Prompts retrieved: 11808 . Total input tokens: 2580649 . Total output tokens: 2350802
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 0.755361087154597,
    "estimated_duration": 3599.59168569064,
    "input_throughput": 263.39042946702773,
    "output_throughput": 238.3270312047634,
    "total_throughput": 501.7174606717911,
    "itl": 20.800493342405517,
    "ttft": 3701.1645500671775,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6572794814407824,
    "arrivals": 3927,
    "finished_requests": 3923,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7554256380535662. Arrivals time: 0.021890516858547926 Scheduler time: 0.3606831254437566 Scheduler overhead time: 0.13110680459067225 Adapter cache time: 0.042005809023976326 Engine time: 0.132592826616019 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-32/adapters_96_slots_96_rate_0.025-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-32/adapters_96_slots_96_rate_0.025-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 270, 66, 66, 66, 66, 270, 66, 270, 66, 33, 270, 33, 33, 270, 66, 270, 66, 270, 270, 66, 33, 270, 66, 33, 33, 66, 270, 33, 66, 33, 33, 66, 66, 66, 33, 33, 270, 66, 66, 33, 270, 270, 66, 270, 270, 66, 270, 33, 270, 66, 66, 66, 270, 270, 33, 33, 66, 33, 270, 33, 33, 270, 33, 66, 66, 33, 66, 270, 270, 270, 66, 270, 270, 33, 33, 270, 66, 270, 33, 66, 270, 33, 270, 66, 33, 270, 33, 33, 270, 33, 33, 66]
Prompts retrieved: 11808 . Total input tokens: 2580649 . Total output tokens: 2350802
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 0.7442009449005127,
    "estimated_duration": 3599.59168569064,
    "input_throughput": 263.39042946702773,
    "output_throughput": 238.3270312047634,
    "total_throughput": 501.7174606717911,
    "itl": 20.8008818595932,
    "ttft": 3701.1210522892256,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7139934895932676,
    "arrivals": 3927,
    "finished_requests": 3923,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7442506197839975. Arrivals time: 0.021676156669855118 Scheduler time: 0.35459997598081827 Scheduler overhead time: 0.1311393710784614 Adapter cache time: 0.041669979225844145 Engine time: 0.12846124172210693 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-16/adapters_96_slots_96_rate_0.025-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-16/adapters_96_slots_96_rate_0.025-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 270, 66, 66, 66, 66, 270, 66, 270, 66, 33, 270, 33, 33, 270, 66, 270, 66, 270, 270, 66, 33, 270, 66, 33, 33, 66, 270, 33, 66, 33, 33, 66, 66, 66, 33, 33, 270, 66, 66, 33, 270, 270, 66, 270, 270, 66, 270, 33, 270, 66, 66, 66, 270, 270, 33, 33, 66, 33, 270, 33, 33, 270, 33, 66, 66, 33, 66, 270, 270, 270, 66, 270, 270, 33, 33, 270, 66, 270, 33, 66, 270, 33, 270, 66, 33, 270, 33, 33, 270, 33, 33, 66]
Prompts retrieved: 11808 . Total input tokens: 2580649 . Total output tokens: 2350802
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 0.7520084059797227,
    "estimated_duration": 3599.59168569064,
    "input_throughput": 263.39042946702773,
    "output_throughput": 238.3270312047634,
    "total_throughput": 501.7174606717911,
    "itl": 20.800251473427075,
    "ttft": 3701.1115864637177,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6128564102947712,
    "arrivals": 3927,
    "finished_requests": 3923,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7520721619948745. Arrivals time: 0.02160738594830036 Scheduler time: 0.35723126120865345 Scheduler overhead time: 0.13321372773498297 Adapter cache time: 0.04208602337166667 Engine time: 0.13061023550108075 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-32/adapters_96_slots_96_rate_0.025-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-32/adapters_96_slots_96_rate_0.025-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 270, 66, 66, 66, 66, 270, 66, 270, 66, 33, 270, 33, 33, 270, 66, 270, 66, 270, 270, 66, 33, 270, 66, 33, 33, 66, 270, 33, 66, 33, 33, 66, 66, 66, 33, 33, 270, 66, 66, 33, 270, 270, 66, 270, 270, 66, 270, 33, 270, 66, 66, 66, 270, 270, 33, 33, 66, 33, 270, 33, 33, 270, 33, 66, 66, 33, 66, 270, 270, 270, 66, 270, 270, 33, 33, 270, 66, 270, 33, 66, 270, 33, 270, 66, 33, 270, 33, 33, 270, 33, 33, 66]
Prompts retrieved: 11808 . Total input tokens: 2580649 . Total output tokens: 2350802
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 0.747756436932832,
    "estimated_duration": 3599.59168569064,
    "input_throughput": 263.39042946702773,
    "output_throughput": 238.3270312047634,
    "total_throughput": 501.7174606717911,
    "itl": 20.800853600208292,
    "ttft": 3701.0836376470097,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.707365739941597,
    "arrivals": 3927,
    "finished_requests": 3923,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7478103102184832. Arrivals time: 0.021563781891018152 Scheduler time: 0.3564217993989587 Scheduler overhead time: 0.1322676851414144 Adapter cache time: 0.04178759129717946 Engine time: 0.12881295243278146 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-8/adapters_96_slots_96_rate_0.0125-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-8/adapters_96_slots_96_rate_0.0125-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 135, 66, 66, 66, 66, 135, 66, 135, 66, 33, 135, 33, 33, 135, 66, 135, 66, 135, 135, 66, 33, 135, 66, 33, 33, 66, 135, 33, 66, 33, 33, 66, 66, 66, 33, 33, 135, 66, 66, 33, 135, 135, 66, 135, 135, 66, 135, 33, 135, 66, 66, 66, 135, 135, 33, 33, 66, 33, 135, 33, 33, 135, 33, 66, 66, 33, 66, 135, 135, 135, 66, 135, 135, 33, 33, 135, 66, 135, 33, 66, 135, 33, 135, 66, 33, 135, 33, 33, 135, 33, 33, 66]
Prompts retrieved: 7488 . Total input tokens: 1633565 . Total output tokens: 1492335
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 0.6414426448754966,
    "estimated_duration": 3599.0290315187226,
    "input_throughput": 167.93112661971477,
    "output_throughput": 146.67678292587672,
    "total_throughput": 314.6079095455915,
    "itl": 20.207250520481608,
    "ttft": 10424.78446202714,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6347912670671934,
    "arrivals": 2425,
    "finished_requests": 2418,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.641493781004101. Arrivals time: 0.018399279098957777 Scheduler time: 0.26373403146862984 Scheduler overhead time: 0.12902030907571316 Adapter cache time: 0.033772111404687166 Engine time: 0.13080104067921638 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-16/adapters_96_slots_96_rate_0.0125-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-16/adapters_96_slots_96_rate_0.0125-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 135, 66, 66, 66, 66, 135, 66, 135, 66, 33, 135, 33, 33, 135, 66, 135, 66, 135, 135, 66, 33, 135, 66, 33, 33, 66, 135, 33, 66, 33, 33, 66, 66, 66, 33, 33, 135, 66, 66, 33, 135, 135, 66, 135, 135, 66, 135, 33, 135, 66, 66, 66, 135, 135, 33, 33, 66, 33, 135, 33, 33, 135, 33, 66, 66, 33, 66, 135, 135, 135, 66, 135, 135, 33, 33, 135, 66, 135, 33, 66, 135, 33, 135, 66, 33, 135, 33, 33, 135, 33, 33, 66]
Prompts retrieved: 7488 . Total input tokens: 1633565 . Total output tokens: 1492335
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 0.6380193387158215,
    "estimated_duration": 3599.0290315187226,
    "input_throughput": 167.93112661971477,
    "output_throughput": 146.67678292587672,
    "total_throughput": 314.6079095455915,
    "itl": 20.207657279291805,
    "ttft": 10424.810270401234,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7017025525867939,
    "arrivals": 2425,
    "finished_requests": 2418,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6380919707007706. Arrivals time: 0.018164129927754402 Scheduler time: 0.2624824861995876 Scheduler overhead time: 0.12878973223268986 Adapter cache time: 0.03377714613452554 Engine time: 0.1286143404431641 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-32/adapters_96_slots_96_rate_0.0125-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-32/adapters_96_slots_96_rate_0.0125-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 135, 66, 66, 66, 66, 135, 66, 135, 66, 33, 135, 33, 33, 135, 66, 135, 66, 135, 135, 66, 33, 135, 66, 33, 33, 66, 135, 33, 66, 33, 33, 66, 66, 66, 33, 33, 135, 66, 66, 33, 135, 135, 66, 135, 135, 66, 135, 33, 135, 66, 66, 66, 135, 135, 33, 33, 66, 33, 135, 33, 33, 135, 33, 66, 66, 33, 66, 135, 135, 135, 66, 135, 135, 33, 33, 135, 66, 135, 33, 66, 135, 33, 135, 66, 33, 135, 33, 33, 135, 33, 33, 66]
Prompts retrieved: 7488 . Total input tokens: 1633565 . Total output tokens: 1492335
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 0.6384264356456697,
    "estimated_duration": 3599.0290315187226,
    "input_throughput": 167.93112661971477,
    "output_throughput": 146.67678292587672,
    "total_throughput": 314.6079095455915,
    "itl": 20.20777481807439,
    "ttft": 10424.871199297018,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.720621239244938,
    "arrivals": 2425,
    "finished_requests": 2418,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6384831829927862. Arrivals time: 0.01821297174319625 Scheduler time: 0.2617027093656361 Scheduler overhead time: 0.1298147109337151 Adapter cache time: 0.03396022645756602 Engine time: 0.12853711936622858 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-16/adapters_96_slots_96_rate_0.0125-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-16/adapters_96_slots_96_rate_0.0125-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 135, 66, 66, 66, 66, 135, 66, 135, 66, 33, 135, 33, 33, 135, 66, 135, 66, 135, 135, 66, 33, 135, 66, 33, 33, 66, 135, 33, 66, 33, 33, 66, 66, 66, 33, 33, 135, 66, 66, 33, 135, 135, 66, 135, 135, 66, 135, 33, 135, 66, 66, 66, 135, 135, 33, 33, 66, 33, 135, 33, 33, 135, 33, 66, 66, 33, 66, 135, 135, 135, 66, 135, 135, 33, 33, 135, 66, 135, 33, 66, 135, 33, 135, 66, 33, 135, 33, 33, 135, 33, 33, 66]
Prompts retrieved: 7488 . Total input tokens: 1633565 . Total output tokens: 1492335
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 0.6357358726672828,
    "estimated_duration": 3599.0290315187226,
    "input_throughput": 167.93112661971477,
    "output_throughput": 146.67678292587672,
    "total_throughput": 314.6079095455915,
    "itl": 20.207368779843307,
    "ttft": 10424.763818474708,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6572794814407824,
    "arrivals": 2425,
    "finished_requests": 2418,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6357887657359242. Arrivals time: 0.01803991524502635 Scheduler time: 0.25829469971358776 Scheduler overhead time: 0.13137561921030283 Adapter cache time: 0.0335987857542932 Engine time: 0.12809124449267983 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-32/adapters_96_slots_96_rate_0.0125-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-32/adapters_96_slots_96_rate_0.0125-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 135, 66, 66, 66, 66, 135, 66, 135, 66, 33, 135, 33, 33, 135, 66, 135, 66, 135, 135, 66, 33, 135, 66, 33, 33, 66, 135, 33, 66, 33, 33, 66, 66, 66, 33, 33, 135, 66, 66, 33, 135, 135, 66, 135, 135, 66, 135, 33, 135, 66, 66, 66, 135, 135, 33, 33, 66, 33, 135, 33, 33, 135, 33, 66, 66, 33, 66, 135, 135, 135, 66, 135, 135, 33, 33, 135, 66, 135, 33, 66, 135, 33, 135, 66, 33, 135, 33, 33, 135, 33, 33, 66]
Prompts retrieved: 7488 . Total input tokens: 1633565 . Total output tokens: 1492335
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 0.6321820593439043,
    "estimated_duration": 3599.0290315187226,
    "input_throughput": 167.93112661971477,
    "output_throughput": 146.67678292587672,
    "total_throughput": 314.6079095455915,
    "itl": 20.2077402984798,
    "ttft": 10424.83908680615,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7139934895932675,
    "arrivals": 2425,
    "finished_requests": 2418,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6322355079464614. Arrivals time: 0.018032880499958992 Scheduler time: 0.2574703134596348 Scheduler overhead time: 0.12838438991457224 Adapter cache time: 0.03367626667022705 Engine time: 0.1284964131191373 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-16/adapters_96_slots_96_rate_0.0125-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-16/adapters_96_slots_96_rate_0.0125-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 135, 66, 66, 66, 66, 135, 66, 135, 66, 33, 135, 33, 33, 135, 66, 135, 66, 135, 135, 66, 33, 135, 66, 33, 33, 66, 135, 33, 66, 33, 33, 66, 66, 66, 33, 33, 135, 66, 66, 33, 135, 135, 66, 135, 135, 66, 135, 33, 135, 66, 66, 66, 135, 135, 33, 33, 66, 33, 135, 33, 33, 135, 33, 66, 66, 33, 66, 135, 135, 135, 66, 135, 135, 33, 33, 135, 66, 135, 33, 66, 135, 33, 135, 66, 33, 135, 33, 33, 135, 33, 33, 66]
Prompts retrieved: 7488 . Total input tokens: 1633565 . Total output tokens: 1492335
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 0.6317984843626618,
    "estimated_duration": 3599.0290315187226,
    "input_throughput": 167.93112661971477,
    "output_throughput": 146.67678292587672,
    "total_throughput": 314.6079095455915,
    "itl": 20.207129200630284,
    "ttft": 10424.789396443484,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6128564102947712,
    "arrivals": 2425,
    "finished_requests": 2418,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6318476074375212. Arrivals time: 0.01786155439913273 Scheduler time: 0.2570841652341187 Scheduler overhead time: 0.12870608968660235 Adapter cache time: 0.033551763743162155 Engine time: 0.12920659082010388 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-32/adapters_96_slots_96_rate_0.0125-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-32/adapters_96_slots_96_rate_0.0125-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 135, 66, 66, 66, 66, 135, 66, 135, 66, 33, 135, 33, 33, 135, 66, 135, 66, 135, 135, 66, 33, 135, 66, 33, 33, 66, 135, 33, 66, 33, 33, 66, 66, 66, 33, 33, 135, 66, 66, 33, 135, 135, 66, 135, 135, 66, 135, 33, 135, 66, 66, 66, 135, 135, 33, 33, 66, 33, 135, 33, 33, 135, 33, 66, 66, 33, 66, 135, 135, 135, 66, 135, 135, 33, 33, 135, 66, 135, 33, 66, 135, 33, 135, 66, 33, 135, 33, 33, 135, 33, 33, 66]
Prompts retrieved: 7488 . Total input tokens: 1633565 . Total output tokens: 1492335
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 0.6385817984119058,
    "estimated_duration": 3599.0290315187226,
    "input_throughput": 167.93112661971477,
    "output_throughput": 146.67678292587672,
    "total_throughput": 314.6079095455915,
    "itl": 20.207702340627176,
    "ttft": 10424.795378467004,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.707365739941597,
    "arrivals": 2425,
    "finished_requests": 2418,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6386371743865311. Arrivals time: 0.018683428410440683 Scheduler time: 0.26066536689177155 Scheduler overhead time: 0.13002686016261578 Adapter cache time: 0.033473147079348564 Engine time: 0.1297023710794747 
