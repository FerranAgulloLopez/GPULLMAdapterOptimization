INFO 05-31 19:30:52 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 05-31 19:30:52 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_8-8-8/adapters_128_slots_96_rate_1.6-0.4-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_8-8-8/adapters_128_slots_96_rate_1.6-0.4-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [42 43 43]
Adapter prompts. [17280, 4320, 17280, 17280, 270, 270, 17280, 270, 4320, 4320, 4320, 270, 17280, 4320, 270, 17280, 4320, 270, 270, 270, 270, 4320, 4320, 17280, 4320, 270, 4320, 4320, 4320, 4320, 17280, 4320, 270, 4320, 270, 17280, 17280, 270, 4320, 4320, 270, 4320, 270, 4320, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 270, 4320, 17280, 17280, 4320, 270, 270, 270, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 270, 270, 4320, 270, 17280, 17280, 270, 270, 4320, 4320, 4320, 270, 17280, 270, 17280, 4320, 270, 17280, 17280, 4320, 4320, 270, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 270, 17280, 270, 270, 17280, 4320, 17280, 17280, 4320, 17280, 270, 4320, 17280, 270, 17280, 4320, 270, 4320, 4320, 17280, 17280, 270, 270, 17280, 270, 270, 270, 4320, 270]
Prompts retrieved: 940140 . Total input tokens: 209178264 . Total output tokens: 184716690
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 5.283294565975666,
    "estimated_duration": 3600.018146456987,
    "input_throughput": 4872.397106459857,
    "output_throughput": 4257.052985991972,
    "total_throughput": 9129.450092451829,
    "itl": 129.69011787992818,
    "ttft": 1958188.177683772,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 883,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.838757175211915,
    "arrivals": 313505,
    "finished_requests": 71226,
    "scheduler_time": 73.34463989038836
}
#Debug simulation 
Total elapsed time: 5.283440858125687. Arrivals time: 0.2257763254456222 Scheduler time: 4.921743464889005 Scheduler overhead time: 0.04124186630360782 Adapter cache time: 0.03104354441165924 Engine time: 0.04388096695765853 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_8-8-16/adapters_128_slots_96_rate_1.6-0.4-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_8-8-16/adapters_128_slots_96_rate_1.6-0.4-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [42 43 43]
Adapter prompts. [17280, 4320, 17280, 17280, 270, 270, 17280, 270, 4320, 4320, 4320, 270, 17280, 4320, 270, 17280, 4320, 270, 270, 270, 270, 4320, 4320, 17280, 4320, 270, 4320, 4320, 4320, 4320, 17280, 4320, 270, 4320, 270, 17280, 17280, 270, 4320, 4320, 270, 4320, 270, 4320, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 270, 4320, 17280, 17280, 4320, 270, 270, 270, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 270, 270, 4320, 270, 17280, 17280, 270, 270, 4320, 4320, 4320, 270, 17280, 270, 17280, 4320, 270, 17280, 17280, 4320, 4320, 270, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 270, 17280, 270, 270, 17280, 4320, 17280, 17280, 4320, 17280, 270, 4320, 17280, 270, 17280, 4320, 270, 4320, 4320, 17280, 17280, 270, 270, 17280, 270, 270, 270, 4320, 270]
Prompts retrieved: 940140 . Total input tokens: 209178264 . Total output tokens: 184716690
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 5.156578297959641,
    "estimated_duration": 3600.1028316217735,
    "input_throughput": 4736.626090293722,
    "output_throughput": 4137.165713483371,
    "total_throughput": 8873.791803777094,
    "itl": 117.20832455393449,
    "ttft": 1980669.982063058,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 853,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.2381587380683134,
    "arrivals": 313505,
    "finished_requests": 69186,
    "scheduler_time": 72.74048305488415
}
#Debug simulation 
Total elapsed time: 5.1566895339637995. Arrivals time: 0.22925219708122313 Scheduler time: 4.7789981765672565 Scheduler overhead time: 0.044568380108103156 Adapter cache time: 0.035643843933939934 Engine time: 0.0468026336748153 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_8-8-32/adapters_128_slots_96_rate_1.6-0.4-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_8-8-32/adapters_128_slots_96_rate_1.6-0.4-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [42 43 43]
Adapter prompts. [17280, 4320, 17280, 17280, 270, 270, 17280, 270, 4320, 4320, 4320, 270, 17280, 4320, 270, 17280, 4320, 270, 270, 270, 270, 4320, 4320, 17280, 4320, 270, 4320, 4320, 4320, 4320, 17280, 4320, 270, 4320, 270, 17280, 17280, 270, 4320, 4320, 270, 4320, 270, 4320, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 270, 4320, 17280, 17280, 4320, 270, 270, 270, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 270, 270, 4320, 270, 17280, 17280, 270, 270, 4320, 4320, 4320, 270, 17280, 270, 17280, 4320, 270, 17280, 17280, 4320, 4320, 270, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 270, 17280, 270, 270, 17280, 4320, 17280, 17280, 4320, 17280, 270, 4320, 17280, 270, 17280, 4320, 270, 4320, 4320, 17280, 17280, 270, 270, 17280, 270, 270, 270, 4320, 270]
Prompts retrieved: 940140 . Total input tokens: 209178264 . Total output tokens: 184716690
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 4.815020449925214,
    "estimated_duration": 3600.027113763537,
    "input_throughput": 4340.042034757369,
    "output_throughput": 3791.435055535122,
    "total_throughput": 8131.477090292491,
    "itl": 91.2344330605969,
    "ttft": 2045113.5848287402,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 770,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.787957286285267,
    "arrivals": 313505,
    "finished_requests": 63362,
    "scheduler_time": 71.10226230259973
}
#Debug simulation 
Total elapsed time: 4.815159331075847. Arrivals time: 0.21188023150898516 Scheduler time: 4.413202308584005 Scheduler overhead time: 0.054687332129105926 Adapter cache time: 0.05117547791451216 Engine time: 0.05788500257767737 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_8-16-16/adapters_128_slots_96_rate_1.6-0.4-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_8-16-16/adapters_128_slots_96_rate_1.6-0.4-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [42 43 43]
Adapter prompts. [17280, 4320, 17280, 17280, 270, 270, 17280, 270, 4320, 4320, 4320, 270, 17280, 4320, 270, 17280, 4320, 270, 270, 270, 270, 4320, 4320, 17280, 4320, 270, 4320, 4320, 4320, 4320, 17280, 4320, 270, 4320, 270, 17280, 17280, 270, 4320, 4320, 270, 4320, 270, 4320, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 270, 4320, 17280, 17280, 4320, 270, 270, 270, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 270, 270, 4320, 270, 17280, 17280, 270, 270, 4320, 4320, 4320, 270, 17280, 270, 17280, 4320, 270, 17280, 17280, 4320, 4320, 270, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 270, 17280, 270, 270, 17280, 4320, 17280, 17280, 4320, 17280, 270, 4320, 17280, 270, 17280, 4320, 270, 4320, 4320, 17280, 17280, 270, 270, 17280, 270, 270, 270, 4320, 270]
Prompts retrieved: 940140 . Total input tokens: 209178264 . Total output tokens: 184716690
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 5.1351356990635395,
    "estimated_duration": 3600.09136564014,
    "input_throughput": 4737.5833743506355,
    "output_throughput": 4138.164420544087,
    "total_throughput": 8875.747794894722,
    "itl": 117.19008222193396,
    "ttft": 1980494.3242828143,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 853,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.766163607141921,
    "arrivals": 313505,
    "finished_requests": 69201,
    "scheduler_time": 72.74898657536976
}
#Debug simulation 
Total elapsed time: 5.135260408977047. Arrivals time: 0.22299018502235413 Scheduler time: 4.763898382894695 Scheduler overhead time: 0.04459517169743776 Adapter cache time: 0.035610148683190346 Engine time: 0.04679695959202945 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_8-16-32/adapters_128_slots_96_rate_1.6-0.4-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_8-16-32/adapters_128_slots_96_rate_1.6-0.4-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [42 43 43]
Adapter prompts. [17280, 4320, 17280, 17280, 270, 270, 17280, 270, 4320, 4320, 4320, 270, 17280, 4320, 270, 17280, 4320, 270, 270, 270, 270, 4320, 4320, 17280, 4320, 270, 4320, 4320, 4320, 4320, 17280, 4320, 270, 4320, 270, 17280, 17280, 270, 4320, 4320, 270, 4320, 270, 4320, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 270, 4320, 17280, 17280, 4320, 270, 270, 270, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 270, 270, 4320, 270, 17280, 17280, 270, 270, 4320, 4320, 4320, 270, 17280, 270, 17280, 4320, 270, 17280, 17280, 4320, 4320, 270, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 270, 17280, 270, 270, 17280, 4320, 17280, 17280, 4320, 17280, 270, 4320, 17280, 270, 17280, 4320, 270, 4320, 4320, 17280, 17280, 270, 270, 17280, 270, 270, 270, 4320, 270]
Prompts retrieved: 940140 . Total input tokens: 209178264 . Total output tokens: 184716690
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 4.828653004951775,
    "estimated_duration": 3600.0893086287692,
    "input_throughput": 4329.219823142766,
    "output_throughput": 3782.215337648468,
    "total_throughput": 8111.435160791233,
    "itl": 90.67514188749213,
    "ttft": 2046796.3461210171,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 765,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.689325482556628,
    "arrivals": 313505,
    "finished_requests": 63220,
    "scheduler_time": 71.07188477232282
}
#Debug simulation 
Total elapsed time: 4.828757221112028. Arrivals time: 0.22472792374901474 Scheduler time: 4.412252040579915 Scheduler overhead time: 0.05499378219246864 Adapter cache time: 0.052007177378982306 Engine time: 0.05835321010090411 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_16-16-16/adapters_128_slots_96_rate_1.6-0.4-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_16-16-16/adapters_128_slots_96_rate_1.6-0.4-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [42 43 43]
Adapter prompts. [17280, 4320, 17280, 17280, 270, 270, 17280, 270, 4320, 4320, 4320, 270, 17280, 4320, 270, 17280, 4320, 270, 270, 270, 270, 4320, 4320, 17280, 4320, 270, 4320, 4320, 4320, 4320, 17280, 4320, 270, 4320, 270, 17280, 17280, 270, 4320, 4320, 270, 4320, 270, 4320, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 270, 4320, 17280, 17280, 4320, 270, 270, 270, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 270, 270, 4320, 270, 17280, 17280, 270, 270, 4320, 4320, 4320, 270, 17280, 270, 17280, 4320, 270, 17280, 17280, 4320, 4320, 270, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 270, 17280, 270, 270, 17280, 4320, 17280, 17280, 4320, 17280, 270, 4320, 17280, 270, 17280, 4320, 270, 4320, 4320, 17280, 17280, 270, 270, 17280, 270, 270, 270, 4320, 270]
Prompts retrieved: 940140 . Total input tokens: 209178264 . Total output tokens: 184716690
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 5.178169453982264,
    "estimated_duration": 3600.1190102582536,
    "input_throughput": 4737.903372471128,
    "output_throughput": 4138.477355205883,
    "total_throughput": 8876.380727677011,
    "itl": 117.18339411808992,
    "ttft": 1980485.955271796,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 854,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.451868483247209,
    "arrivals": 313505,
    "finished_requests": 69207,
    "scheduler_time": 72.75441218723336
}
#Debug simulation 
Total elapsed time: 5.17826273618266. Arrivals time: 0.22266804776154459 Scheduler time: 4.806150999153033 Scheduler overhead time: 0.04458325309678912 Adapter cache time: 0.036108198342844844 Engine time: 0.04738875827752054 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_16-16-32/adapters_128_slots_96_rate_1.6-0.4-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.025_size_16-16-32/adapters_128_slots_96_rate_1.6-0.4-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [42 43 43]
Adapter prompts. [17280, 4320, 17280, 17280, 270, 270, 17280, 270, 4320, 4320, 4320, 270, 17280, 4320, 270, 17280, 4320, 270, 270, 270, 270, 4320, 4320, 17280, 4320, 270, 4320, 4320, 4320, 4320, 17280, 4320, 270, 4320, 270, 17280, 17280, 270, 4320, 4320, 270, 4320, 270, 4320, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 270, 4320, 17280, 17280, 4320, 270, 270, 270, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 270, 270, 4320, 270, 17280, 17280, 270, 270, 4320, 4320, 4320, 270, 17280, 270, 17280, 4320, 270, 17280, 17280, 4320, 4320, 270, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 270, 17280, 270, 270, 17280, 4320, 17280, 17280, 4320, 17280, 270, 4320, 17280, 270, 17280, 4320, 270, 4320, 4320, 17280, 17280, 270, 270, 17280, 270, 270, 270, 4320, 270]
Prompts retrieved: 940140 . Total input tokens: 209178264 . Total output tokens: 184716690
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 4.826885767048225,
    "estimated_duration": 3600.039106020364,
    "input_throughput": 4333.211540372572,
    "output_throughput": 3785.8758192953096,
    "total_throughput": 8119.087359667882,
    "itl": 90.92249982014982,
    "ttft": 2045853.8034864138,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 767,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.660067098643662,
    "arrivals": 313505,
    "finished_requests": 63269,
    "scheduler_time": 71.08832890581415
}
#Debug simulation 
Total elapsed time: 4.826981702819467. Arrivals time: 0.2163638910278678 Scheduler time: 4.419555399334058 Scheduler overhead time: 0.05472954269498587 Adapter cache time: 0.051982846576720476 Engine time: 0.057946796994656324 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-8/adapters_128_slots_96_rate_1.6-0.4-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-8/adapters_128_slots_96_rate_1.6-0.4-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [42 43 43]
Adapter prompts. [17280, 4320, 17280, 17280, 135, 135, 17280, 135, 4320, 4320, 4320, 135, 17280, 4320, 135, 17280, 4320, 135, 135, 135, 135, 4320, 4320, 17280, 4320, 135, 4320, 4320, 4320, 4320, 17280, 4320, 135, 4320, 135, 17280, 17280, 135, 4320, 4320, 135, 4320, 135, 4320, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 135, 4320, 17280, 17280, 4320, 135, 135, 135, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 135, 135, 4320, 135, 17280, 17280, 135, 135, 4320, 4320, 4320, 135, 17280, 135, 17280, 4320, 135, 17280, 17280, 4320, 4320, 135, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 135, 17280, 135, 135, 17280, 4320, 17280, 17280, 4320, 17280, 135, 4320, 17280, 135, 17280, 4320, 135, 4320, 4320, 17280, 17280, 135, 135, 17280, 135, 135, 135, 4320, 135]
Prompts retrieved: 934470 . Total input tokens: 207911889 . Total output tokens: 183599983
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 5.360900303116068,
    "estimated_duration": 3600.0722177510856,
    "input_throughput": 4979.909545036679,
    "output_throughput": 4322.881891997653,
    "total_throughput": 9302.791437034333,
    "itl": 127.15425179665996,
    "ttft": 1946478.263065489,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 419,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.770599384387046,
    "arrivals": 311621,
    "finished_requests": 72534,
    "scheduler_time": 74.5149531958822
}
#Debug simulation 
Total elapsed time: 5.360998573014513. Arrivals time: 0.2305603427812457 Scheduler time: 5.000616854755208 Scheduler overhead time: 0.041570176370441914 Adapter cache time: 0.02465419820509851 Engine time: 0.043651935644447803 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-16/adapters_128_slots_96_rate_1.6-0.4-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-16/adapters_128_slots_96_rate_1.6-0.4-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [42 43 43]
Adapter prompts. [17280, 4320, 17280, 17280, 135, 135, 17280, 135, 4320, 4320, 4320, 135, 17280, 4320, 135, 17280, 4320, 135, 135, 135, 135, 4320, 4320, 17280, 4320, 135, 4320, 4320, 4320, 4320, 17280, 4320, 135, 4320, 135, 17280, 17280, 135, 4320, 4320, 135, 4320, 135, 4320, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 135, 4320, 17280, 17280, 4320, 135, 135, 135, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 135, 135, 4320, 135, 17280, 17280, 135, 135, 4320, 4320, 4320, 135, 17280, 135, 17280, 4320, 135, 17280, 17280, 4320, 4320, 135, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 135, 17280, 135, 135, 17280, 4320, 17280, 17280, 4320, 17280, 135, 4320, 17280, 135, 17280, 4320, 135, 4320, 4320, 17280, 17280, 135, 135, 17280, 135, 135, 135, 4320, 135]
Prompts retrieved: 934470 . Total input tokens: 207911889 . Total output tokens: 183599983
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 5.237230128142983,
    "estimated_duration": 3600.092773714887,
    "input_throughput": 4827.4258727134575,
    "output_throughput": 4195.481602662772,
    "total_throughput": 9022.90747537623,
    "itl": 115.15065884266386,
    "ttft": 1969360.9799801048,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 400,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.932552701942627,
    "arrivals": 311621,
    "finished_requests": 70312,
    "scheduler_time": 73.785412094083
}
#Debug simulation 
Total elapsed time: 5.2373225970659405. Arrivals time: 0.25216443114914 Scheduler time: 4.840930011821911 Scheduler overhead time: 0.04526098305359483 Adapter cache time: 0.029848925303667784 Engine time: 0.047428508987650275 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-32/adapters_128_slots_96_rate_1.6-0.4-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-32/adapters_128_slots_96_rate_1.6-0.4-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [42 43 43]
Adapter prompts. [17280, 4320, 17280, 17280, 135, 135, 17280, 135, 4320, 4320, 4320, 135, 17280, 4320, 135, 17280, 4320, 135, 135, 135, 135, 4320, 4320, 17280, 4320, 135, 4320, 4320, 4320, 4320, 17280, 4320, 135, 4320, 135, 17280, 17280, 135, 4320, 4320, 135, 4320, 135, 4320, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 135, 4320, 17280, 17280, 4320, 135, 135, 135, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 135, 135, 4320, 135, 17280, 17280, 135, 135, 4320, 4320, 4320, 135, 17280, 135, 17280, 4320, 135, 17280, 17280, 4320, 4320, 135, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 135, 17280, 135, 135, 17280, 4320, 17280, 17280, 4320, 17280, 135, 4320, 17280, 135, 17280, 4320, 135, 4320, 4320, 17280, 17280, 135, 135, 17280, 135, 135, 135, 4320, 135]
Prompts retrieved: 934470 . Total input tokens: 207911889 . Total output tokens: 183599983
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 4.888162403134629,
    "estimated_duration": 3600.0681322623664,
    "input_throughput": 4399.99561620674,
    "output_throughput": 3832.1452520206285,
    "total_throughput": 8232.140868227369,
    "itl": 90.195830750578,
    "ttft": 2037855.6295825043,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 367,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.769114999151806,
    "arrivals": 311621,
    "finished_requests": 64124,
    "scheduler_time": 71.86965520359294
}
#Debug simulation 
Total elapsed time: 4.888256152160466. Arrivals time: 0.21418588981032372 Scheduler time: 4.486634962726384 Scheduler overhead time: 0.0554476382676512 Adapter cache time: 0.046330171870067716 Engine time: 0.0590020299423486 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_8-16-16/adapters_128_slots_96_rate_1.6-0.4-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_8-16-16/adapters_128_slots_96_rate_1.6-0.4-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [42 43 43]
Adapter prompts. [17280, 4320, 17280, 17280, 135, 135, 17280, 135, 4320, 4320, 4320, 135, 17280, 4320, 135, 17280, 4320, 135, 135, 135, 135, 4320, 4320, 17280, 4320, 135, 4320, 4320, 4320, 4320, 17280, 4320, 135, 4320, 135, 17280, 17280, 135, 4320, 4320, 135, 4320, 135, 4320, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 135, 4320, 17280, 17280, 4320, 135, 135, 135, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 135, 135, 4320, 135, 17280, 17280, 135, 135, 4320, 4320, 4320, 135, 17280, 135, 17280, 4320, 135, 17280, 17280, 4320, 4320, 135, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 135, 17280, 135, 135, 17280, 4320, 17280, 17280, 4320, 17280, 135, 4320, 17280, 135, 17280, 4320, 135, 4320, 4320, 17280, 17280, 135, 135, 17280, 135, 135, 135, 4320, 135]
Prompts retrieved: 934470 . Total input tokens: 207911889 . Total output tokens: 183599983
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 5.252249700017273,
    "estimated_duration": 3600.0403026548242,
    "input_throughput": 4827.739008139215,
    "output_throughput": 4195.680528593307,
    "total_throughput": 9023.419536732521,
    "itl": 115.13901843035624,
    "ttft": 1969220.8161691967,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 400,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.7034962413459955,
    "arrivals": 311621,
    "finished_requests": 70315,
    "scheduler_time": 73.78831302552686
}
#Debug simulation 
Total elapsed time: 5.252345690038055. Arrivals time: 0.25110106309875846 Scheduler time: 4.856887818779796 Scheduler overhead time: 0.045275844633579254 Adapter cache time: 0.029670444782823324 Engine time: 0.04766787006519735 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_8-16-32/adapters_128_slots_96_rate_1.6-0.4-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_8-16-32/adapters_128_slots_96_rate_1.6-0.4-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [42 43 43]
Adapter prompts. [17280, 4320, 17280, 17280, 135, 135, 17280, 135, 4320, 4320, 4320, 135, 17280, 4320, 135, 17280, 4320, 135, 135, 135, 135, 4320, 4320, 17280, 4320, 135, 4320, 4320, 4320, 4320, 17280, 4320, 135, 4320, 135, 17280, 17280, 135, 4320, 4320, 135, 4320, 135, 4320, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 135, 4320, 17280, 17280, 4320, 135, 135, 135, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 135, 135, 4320, 135, 17280, 17280, 135, 135, 4320, 4320, 4320, 135, 17280, 135, 17280, 4320, 135, 17280, 17280, 4320, 4320, 135, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 135, 17280, 135, 135, 17280, 4320, 17280, 17280, 4320, 17280, 135, 4320, 17280, 135, 17280, 4320, 135, 4320, 4320, 17280, 17280, 135, 135, 17280, 135, 135, 135, 4320, 135]
Prompts retrieved: 934470 . Total input tokens: 207911889 . Total output tokens: 183599983
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 5.149662073003128,
    "estimated_duration": 3600.017247164117,
    "input_throughput": 4400.05780874468,
    "output_throughput": 3832.1994181743626,
    "total_throughput": 8232.257226919042,
    "itl": 90.19658443857479,
    "ttft": 2037852.7067839492,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 367,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.7372189539531413,
    "arrivals": 311621,
    "finished_requests": 64124,
    "scheduler_time": 71.86981230597942
}
#Debug simulation 
Total elapsed time: 5.149771215161309. Arrivals time: 0.46745385346002877 Scheduler time: 4.494962706230581 Scheduler overhead time: 0.05539619270712137 Adapter cache time: 0.046456074342131615 Engine time: 0.0589156283531338 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_16-16-16/adapters_128_slots_96_rate_1.6-0.4-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_16-16-16/adapters_128_slots_96_rate_1.6-0.4-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [42 43 43]
Adapter prompts. [17280, 4320, 17280, 17280, 135, 135, 17280, 135, 4320, 4320, 4320, 135, 17280, 4320, 135, 17280, 4320, 135, 135, 135, 135, 4320, 4320, 17280, 4320, 135, 4320, 4320, 4320, 4320, 17280, 4320, 135, 4320, 135, 17280, 17280, 135, 4320, 4320, 135, 4320, 135, 4320, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 135, 4320, 17280, 17280, 4320, 135, 135, 135, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 135, 135, 4320, 135, 17280, 17280, 135, 135, 4320, 4320, 4320, 135, 17280, 135, 17280, 4320, 135, 17280, 17280, 4320, 4320, 135, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 135, 17280, 135, 135, 17280, 4320, 17280, 17280, 4320, 17280, 135, 4320, 17280, 135, 17280, 4320, 135, 4320, 4320, 17280, 17280, 135, 135, 17280, 135, 135, 135, 4320, 135]
Prompts retrieved: 934470 . Total input tokens: 207911889 . Total output tokens: 183599983
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 5.50239206594415,
    "estimated_duration": 3600.0703719782928,
    "input_throughput": 4827.923402633086,
    "output_throughput": 4195.64604002443,
    "total_throughput": 9023.569442657516,
    "itl": 115.13554206525767,
    "ttft": 1969224.2703090452,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 400,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.5535683762282027,
    "arrivals": 311621,
    "finished_requests": 70316,
    "scheduler_time": 73.79053523275128
}
#Debug simulation 
Total elapsed time: 5.502458086004481. Arrivals time: 0.4767010058276355 Scheduler time: 4.881614150712267 Scheduler overhead time: 0.04516558279283345 Adapter cache time: 0.02951423288322985 Engine time: 0.04778024763800204 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_16-16-32/adapters_128_slots_96_rate_1.6-0.4-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.0125_size_16-16-32/adapters_128_slots_96_rate_1.6-0.4-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [42 43 43]
Adapter prompts. [17280, 4320, 17280, 17280, 135, 135, 17280, 135, 4320, 4320, 4320, 135, 17280, 4320, 135, 17280, 4320, 135, 135, 135, 135, 4320, 4320, 17280, 4320, 135, 4320, 4320, 4320, 4320, 17280, 4320, 135, 4320, 135, 17280, 17280, 135, 4320, 4320, 135, 4320, 135, 4320, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 135, 4320, 17280, 17280, 4320, 135, 135, 135, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 135, 135, 4320, 135, 17280, 17280, 135, 135, 4320, 4320, 4320, 135, 17280, 135, 17280, 4320, 135, 17280, 17280, 4320, 4320, 135, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 135, 17280, 135, 135, 17280, 4320, 17280, 17280, 4320, 17280, 135, 4320, 17280, 135, 17280, 4320, 135, 4320, 4320, 17280, 17280, 135, 135, 17280, 135, 135, 135, 4320, 135]
Prompts retrieved: 934470 . Total input tokens: 207911889 . Total output tokens: 183599983
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 5.165405378909782,
    "estimated_duration": 3600.0017697854896,
    "input_throughput": 4400.021725807054,
    "output_throughput": 3832.108949441441,
    "total_throughput": 8232.130675248494,
    "itl": 90.1914149368679,
    "ttft": 2037774.7670626524,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 366,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.7088453972712325,
    "arrivals": 311621,
    "finished_requests": 64123,
    "scheduler_time": 71.86956108059444
}
#Debug simulation 
Total elapsed time: 5.165472174063325. Arrivals time: 0.46515141846612096 Scheduler time: 4.513012117007747 Scheduler overhead time: 0.05528786755166948 Adapter cache time: 0.04659667913801968 Engine time: 0.05877492297440767 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-8/adapters_128_slots_96_rate_1.6-0.4-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-8/adapters_128_slots_96_rate_1.6-0.4-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [42 43 43]
Adapter prompts. [17280, 4320, 17280, 17280, 66, 66, 17280, 66, 4320, 4320, 4320, 66, 17280, 4320, 66, 17280, 4320, 66, 66, 66, 66, 4320, 4320, 17280, 4320, 66, 4320, 4320, 4320, 4320, 17280, 4320, 66, 4320, 66, 17280, 17280, 66, 4320, 4320, 66, 4320, 66, 4320, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 66, 4320, 17280, 17280, 4320, 66, 66, 66, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 66, 66, 4320, 66, 17280, 17280, 66, 66, 4320, 4320, 4320, 66, 17280, 66, 17280, 4320, 66, 17280, 17280, 4320, 4320, 66, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 66, 17280, 66, 66, 17280, 4320, 17280, 17280, 4320, 17280, 66, 4320, 17280, 66, 17280, 4320, 66, 4320, 4320, 17280, 17280, 66, 66, 17280, 66, 66, 66, 4320, 66]
Prompts retrieved: 931572 . Total input tokens: 207282110 . Total output tokens: 183031835
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 5.35162760480307,
    "estimated_duration": 3600.063689499374,
    "input_throughput": 4965.862979631352,
    "output_throughput": 4355.991824739279,
    "total_throughput": 9321.85480437063,
    "itl": 126.34882717838913,
    "ttft": 1945559.9845811261,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 261,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7258387573389316,
    "arrivals": 310685,
    "finished_requests": 72614,
    "scheduler_time": 75.06963631780202
}
#Debug simulation 
Total elapsed time: 5.351750948000699. Arrivals time: 0.23294557840563357 Scheduler time: 4.990065118530765 Scheduler overhead time: 0.04192652413621545 Adapter cache time: 0.022436761064454913 Engine time: 0.044302287278696895 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-16/adapters_128_slots_96_rate_1.6-0.4-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-16/adapters_128_slots_96_rate_1.6-0.4-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [42 43 43]
Adapter prompts. [17280, 4320, 17280, 17280, 66, 66, 17280, 66, 4320, 4320, 4320, 66, 17280, 4320, 66, 17280, 4320, 66, 66, 66, 66, 4320, 4320, 17280, 4320, 66, 4320, 4320, 4320, 4320, 17280, 4320, 66, 4320, 66, 17280, 17280, 66, 4320, 4320, 66, 4320, 66, 4320, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 66, 4320, 17280, 17280, 4320, 66, 66, 66, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 66, 66, 4320, 66, 17280, 17280, 66, 66, 4320, 4320, 4320, 66, 17280, 66, 17280, 4320, 66, 17280, 17280, 4320, 4320, 66, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 66, 17280, 66, 66, 17280, 4320, 17280, 17280, 4320, 17280, 66, 4320, 17280, 66, 17280, 4320, 66, 4320, 4320, 17280, 17280, 66, 66, 17280, 66, 66, 66, 4320, 66]
Prompts retrieved: 931572 . Total input tokens: 207282110 . Total output tokens: 183031835
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 5.238156512146816,
    "estimated_duration": 3600.0714653185755,
    "input_throughput": 4808.930368960881,
    "output_throughput": 4222.4136788503565,
    "total_throughput": 9031.344047811239,
    "itl": 114.58928167081498,
    "ttft": 1969641.2568840843,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8758342101424954,
    "arrivals": 310685,
    "finished_requests": 70336,
    "scheduler_time": 74.24026373084227
}
#Debug simulation 
Total elapsed time: 5.2382549261674285. Arrivals time: 0.2269676278810948 Scheduler time: 4.868093625176698 Scheduler overhead time: 0.045532874995842576 Adapter cache time: 0.027978522004559636 Engine time: 0.04786414955742657 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-32/adapters_128_slots_96_rate_1.6-0.4-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-32/adapters_128_slots_96_rate_1.6-0.4-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [42 43 43]
Adapter prompts. [17280, 4320, 17280, 17280, 66, 66, 17280, 66, 4320, 4320, 4320, 66, 17280, 4320, 66, 17280, 4320, 66, 66, 66, 66, 4320, 4320, 17280, 4320, 66, 4320, 4320, 4320, 4320, 17280, 4320, 66, 4320, 66, 17280, 17280, 66, 4320, 4320, 66, 4320, 66, 4320, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 66, 4320, 17280, 17280, 4320, 66, 66, 66, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 66, 66, 4320, 66, 17280, 17280, 66, 66, 4320, 4320, 4320, 66, 17280, 66, 17280, 4320, 66, 17280, 17280, 4320, 4320, 66, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 66, 17280, 66, 66, 17280, 4320, 17280, 17280, 4320, 17280, 66, 4320, 17280, 66, 17280, 4320, 66, 4320, 4320, 17280, 17280, 66, 66, 17280, 66, 66, 66, 4320, 66]
Prompts retrieved: 931572 . Total input tokens: 207282110 . Total output tokens: 183031835
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 4.902597381034866,
    "estimated_duration": 3600.0671065173533,
    "input_throughput": 4371.529067196887,
    "output_throughput": 3844.4741696465057,
    "total_throughput": 8216.003236843393,
    "itl": 89.69873869050642,
    "ttft": 2038954.746019018,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 236,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7760840301960747,
    "arrivals": 310685,
    "finished_requests": 63944,
    "scheduler_time": 72.14038115618295
}
#Debug simulation 
Total elapsed time: 4.902695514028892. Arrivals time: 0.21379735972732306 Scheduler time: 4.5027194356080145 Scheduler overhead time: 0.05539342598058283 Adapter cache time: 0.04493289114907384 Engine time: 0.05895470408722758 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_8-16-16/adapters_128_slots_96_rate_1.6-0.4-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_8-16-16/adapters_128_slots_96_rate_1.6-0.4-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [42 43 43]
Adapter prompts. [17280, 4320, 17280, 17280, 66, 66, 17280, 66, 4320, 4320, 4320, 66, 17280, 4320, 66, 17280, 4320, 66, 66, 66, 66, 4320, 4320, 17280, 4320, 66, 4320, 4320, 4320, 4320, 17280, 4320, 66, 4320, 66, 17280, 17280, 66, 4320, 4320, 66, 4320, 66, 4320, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 66, 4320, 17280, 17280, 4320, 66, 66, 66, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 66, 66, 4320, 66, 17280, 17280, 66, 66, 4320, 4320, 4320, 66, 17280, 66, 17280, 4320, 66, 17280, 17280, 4320, 4320, 66, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 66, 17280, 66, 66, 17280, 4320, 17280, 17280, 4320, 17280, 66, 4320, 17280, 66, 17280, 4320, 66, 4320, 4320, 17280, 17280, 66, 66, 17280, 66, 66, 66, 4320, 66]
Prompts retrieved: 931572 . Total input tokens: 207282110 . Total output tokens: 183031835
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 5.4982032352127135,
    "estimated_duration": 3600.1107480317273,
    "input_throughput": 4808.916783869846,
    "output_throughput": 4222.432603861117,
    "total_throughput": 9031.349387730963,
    "itl": 114.5848071449946,
    "ttft": 1969503.1925094624,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7397885547578302,
    "arrivals": 310685,
    "finished_requests": 70336,
    "scheduler_time": 74.24260994163943
}
#Debug simulation 
Total elapsed time: 5.498308410169557. Arrivals time: 0.23276939615607262 Scheduler time: 5.122146299108863 Scheduler overhead time: 0.04549573245458305 Adapter cache time: 0.02812782395631075 Engine time: 0.04799237521365285 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_8-16-32/adapters_128_slots_96_rate_1.6-0.4-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_8-16-32/adapters_128_slots_96_rate_1.6-0.4-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [42 43 43]
Adapter prompts. [17280, 4320, 17280, 17280, 66, 66, 17280, 66, 4320, 4320, 4320, 66, 17280, 4320, 66, 17280, 4320, 66, 66, 66, 66, 4320, 4320, 17280, 4320, 66, 4320, 4320, 4320, 4320, 17280, 4320, 66, 4320, 66, 17280, 17280, 66, 4320, 4320, 66, 4320, 66, 4320, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 66, 4320, 17280, 17280, 4320, 66, 66, 66, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 66, 66, 4320, 66, 17280, 17280, 66, 66, 4320, 4320, 4320, 66, 17280, 66, 17280, 4320, 66, 17280, 17280, 4320, 4320, 66, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 66, 17280, 66, 66, 17280, 4320, 17280, 17280, 4320, 17280, 66, 4320, 17280, 66, 17280, 4320, 66, 4320, 4320, 17280, 17280, 66, 66, 17280, 66, 66, 66, 4320, 66]
Prompts retrieved: 931572 . Total input tokens: 207282110 . Total output tokens: 183031835
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 4.8746527309995145,
    "estimated_duration": 3600.0235801021286,
    "input_throughput": 4373.867462155152,
    "output_throughput": 3846.830080931617,
    "total_throughput": 8220.697543086768,
    "itl": 89.82886899049092,
    "ttft": 2038452.3145377906,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 236,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7576506014773663,
    "arrivals": 310685,
    "finished_requests": 63982,
    "scheduler_time": 72.15190520033131
}
#Debug simulation 
Total elapsed time: 4.8747483510524035. Arrivals time: 0.21773009980097413 Scheduler time: 4.471522776177153 Scheduler overhead time: 0.05535105732269585 Adapter cache time: 0.0445624515414238 Engine time: 0.05886694206856191 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_16-16-16/adapters_128_slots_96_rate_1.6-0.4-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_16-16-16/adapters_128_slots_96_rate_1.6-0.4-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [42 43 43]
Adapter prompts. [17280, 4320, 17280, 17280, 66, 66, 17280, 66, 4320, 4320, 4320, 66, 17280, 4320, 66, 17280, 4320, 66, 66, 66, 66, 4320, 4320, 17280, 4320, 66, 4320, 4320, 4320, 4320, 17280, 4320, 66, 4320, 66, 17280, 17280, 66, 4320, 4320, 66, 4320, 66, 4320, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 66, 4320, 17280, 17280, 4320, 66, 66, 66, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 66, 66, 4320, 66, 17280, 17280, 66, 66, 4320, 4320, 4320, 66, 17280, 66, 17280, 4320, 66, 17280, 17280, 4320, 4320, 66, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 66, 17280, 66, 66, 17280, 4320, 17280, 17280, 4320, 17280, 66, 4320, 17280, 66, 17280, 4320, 66, 4320, 4320, 17280, 17280, 66, 66, 17280, 66, 66, 66, 4320, 66]
Prompts retrieved: 931572 . Total input tokens: 207282110 . Total output tokens: 183031835
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 5.256918688071892,
    "estimated_duration": 3600.1035516488023,
    "input_throughput": 4809.2294434337955,
    "output_throughput": 4222.653260359047,
    "total_throughput": 9031.882703792842,
    "itl": 114.58131752666166,
    "ttft": 1969453.2798293151,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 256,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.634283760786051,
    "arrivals": 310685,
    "finished_requests": 70342,
    "scheduler_time": 74.24463027674436
}
#Debug simulation 
Total elapsed time: 5.257021255092695. Arrivals time: 0.22713027242571115 Scheduler time: 4.885658298386261 Scheduler overhead time: 0.04566471907310188 Adapter cache time: 0.028293445939198136 Engine time: 0.04845032608136535 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_16-16-32/adapters_128_slots_96_rate_1.6-0.4-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.00625_size_16-16-32/adapters_128_slots_96_rate_1.6-0.4-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [42 43 43]
Adapter prompts. [17280, 4320, 17280, 17280, 66, 66, 17280, 66, 4320, 4320, 4320, 66, 17280, 4320, 66, 17280, 4320, 66, 66, 66, 66, 4320, 4320, 17280, 4320, 66, 4320, 4320, 4320, 4320, 17280, 4320, 66, 4320, 66, 17280, 17280, 66, 4320, 4320, 66, 4320, 66, 4320, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 66, 4320, 17280, 17280, 4320, 66, 66, 66, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 66, 66, 4320, 66, 17280, 17280, 66, 66, 4320, 4320, 4320, 66, 17280, 66, 17280, 4320, 66, 17280, 17280, 4320, 4320, 66, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 66, 17280, 66, 66, 17280, 4320, 17280, 17280, 4320, 17280, 66, 4320, 17280, 66, 17280, 4320, 66, 4320, 4320, 17280, 17280, 66, 66, 17280, 66, 66, 66, 4320, 66]
Prompts retrieved: 931572 . Total input tokens: 207282110 . Total output tokens: 183031835
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 4.893363055773079,
    "estimated_duration": 3600.0412569296946,
    "input_throughput": 4371.751843039325,
    "output_throughput": 3844.67677234464,
    "total_throughput": 8216.428615383966,
    "itl": 89.69663583478953,
    "ttft": 2038887.282496166,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 236,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7429452819377222,
    "arrivals": 310685,
    "finished_requests": 63947,
    "scheduler_time": 72.14204573927265
}
#Debug simulation 
Total elapsed time: 4.893469080794603. Arrivals time: 0.22160022100433707 Scheduler time: 4.48642073944211 Scheduler overhead time: 0.055321475956588984 Adapter cache time: 0.04444783856160939 Engine time: 0.05909155122935772 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-8/adapters_128_slots_96_rate_1.6-0.4-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-8/adapters_128_slots_96_rate_1.6-0.4-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [42 43 43]
Adapter prompts. [17280, 4320, 17280, 17280, 33, 33, 17280, 33, 4320, 4320, 4320, 33, 17280, 4320, 33, 17280, 4320, 33, 33, 33, 33, 4320, 4320, 17280, 4320, 33, 4320, 4320, 4320, 4320, 17280, 4320, 33, 4320, 33, 17280, 17280, 33, 4320, 4320, 33, 4320, 33, 4320, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 33, 4320, 17280, 17280, 4320, 33, 33, 33, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 33, 33, 4320, 33, 17280, 17280, 33, 33, 4320, 4320, 4320, 33, 17280, 33, 17280, 4320, 33, 17280, 17280, 4320, 4320, 33, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 33, 17280, 33, 33, 17280, 4320, 17280, 17280, 4320, 17280, 33, 4320, 17280, 33, 17280, 4320, 33, 4320, 4320, 17280, 17280, 33, 33, 17280, 33, 33, 33, 4320, 33]
Prompts retrieved: 930186 . Total input tokens: 206969333 . Total output tokens: 182762594
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 5.383696697885171,
    "estimated_duration": 3600.056013059205,
    "input_throughput": 4959.195338971631,
    "output_throughput": 4378.485485453688,
    "total_throughput": 9337.680824425319,
    "itl": 125.39312647897385,
    "ttft": 1945912.919942217,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 173,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1439467625273378,
    "arrivals": 310219,
    "finished_requests": 72823,
    "scheduler_time": 75.47341487618056
}
#Debug simulation 
Total elapsed time: 5.383790667867288. Arrivals time: 0.2614196874201298 Scheduler time: 4.992414778331295 Scheduler overhead time: 0.04234763258136809 Adapter cache time: 0.022878399351611733 Engine time: 0.044616363709792495 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-16/adapters_128_slots_96_rate_1.6-0.4-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-16/adapters_128_slots_96_rate_1.6-0.4-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [42 43 43]
Adapter prompts. [17280, 4320, 17280, 17280, 33, 33, 17280, 33, 4320, 4320, 4320, 33, 17280, 4320, 33, 17280, 4320, 33, 33, 33, 33, 4320, 4320, 17280, 4320, 33, 4320, 4320, 4320, 4320, 17280, 4320, 33, 4320, 33, 17280, 17280, 33, 4320, 4320, 33, 4320, 33, 4320, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 33, 4320, 17280, 17280, 4320, 33, 33, 33, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 33, 33, 4320, 33, 17280, 17280, 33, 33, 4320, 4320, 4320, 33, 17280, 33, 17280, 4320, 33, 17280, 17280, 4320, 4320, 33, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 33, 17280, 33, 33, 17280, 4320, 17280, 17280, 4320, 17280, 33, 4320, 17280, 33, 17280, 4320, 33, 4320, 4320, 17280, 17280, 33, 33, 17280, 33, 33, 33, 4320, 33]
Prompts retrieved: 930186 . Total input tokens: 206969333 . Total output tokens: 182762594
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 5.30548141989857,
    "estimated_duration": 3600.053946607755,
    "input_throughput": 4805.486600083143,
    "output_throughput": 4249.639373992109,
    "total_throughput": 9055.125974075252,
    "itl": 114.34117389900578,
    "ttft": 1969225.8452065198,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 169,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2371398299140863,
    "arrivals": 310219,
    "finished_requests": 70614,
    "scheduler_time": 74.65976444590416
}
#Debug simulation 
Total elapsed time: 5.305580467917025. Arrivals time: 0.23005408607423306 Scheduler time: 4.932322235777974 Scheduler overhead time: 0.045793845085427165 Adapter cache time: 0.026784497778862715 Engine time: 0.048634888837113976 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-32/adapters_128_slots_96_rate_1.6-0.4-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-32/adapters_128_slots_96_rate_1.6-0.4-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [42 43 43]
Adapter prompts. [17280, 4320, 17280, 17280, 33, 33, 17280, 33, 4320, 4320, 4320, 33, 17280, 4320, 33, 17280, 4320, 33, 33, 33, 33, 4320, 4320, 17280, 4320, 33, 4320, 4320, 4320, 4320, 17280, 4320, 33, 4320, 33, 17280, 17280, 33, 4320, 4320, 33, 4320, 33, 4320, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 33, 4320, 17280, 17280, 4320, 33, 33, 33, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 33, 33, 4320, 33, 17280, 17280, 33, 33, 4320, 4320, 4320, 33, 17280, 33, 17280, 4320, 33, 17280, 17280, 4320, 4320, 33, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 33, 17280, 33, 33, 17280, 4320, 17280, 17280, 4320, 17280, 33, 4320, 17280, 33, 17280, 4320, 33, 4320, 4320, 17280, 17280, 33, 33, 17280, 33, 33, 33, 4320, 33]
Prompts retrieved: 930186 . Total input tokens: 206969333 . Total output tokens: 182762594
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 4.902525057084858,
    "estimated_duration": 3600.0498640653113,
    "input_throughput": 4352.831652810604,
    "output_throughput": 3861.847620160568,
    "total_throughput": 8214.679272971172,
    "itl": 89.62084094895724,
    "ttft": 2040035.3813192865,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 163,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2241244145995018,
    "arrivals": 310219,
    "finished_requests": 64039,
    "scheduler_time": 72.43250808748496
}
#Debug simulation 
Total elapsed time: 4.9026190841104835. Arrivals time: 0.23926059482619166 Scheduler time: 4.478095944039524 Scheduler overhead time: 0.05558812199160457 Adapter cache time: 0.0437307886313647 Engine time: 0.05922176339663565 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_8-16-16/adapters_128_slots_96_rate_1.6-0.4-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_8-16-16/adapters_128_slots_96_rate_1.6-0.4-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [42 43 43]
Adapter prompts. [17280, 4320, 17280, 17280, 33, 33, 17280, 33, 4320, 4320, 4320, 33, 17280, 4320, 33, 17280, 4320, 33, 33, 33, 33, 4320, 4320, 17280, 4320, 33, 4320, 4320, 4320, 4320, 17280, 4320, 33, 4320, 33, 17280, 17280, 33, 4320, 4320, 33, 4320, 33, 4320, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 33, 4320, 17280, 17280, 4320, 33, 33, 33, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 33, 33, 4320, 33, 17280, 17280, 33, 33, 4320, 4320, 4320, 33, 17280, 33, 17280, 4320, 33, 17280, 17280, 4320, 4320, 33, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 33, 17280, 33, 33, 17280, 4320, 17280, 17280, 4320, 17280, 33, 4320, 17280, 33, 17280, 4320, 33, 4320, 4320, 17280, 17280, 33, 33, 17280, 33, 33, 33, 4320, 33]
Prompts retrieved: 930186 . Total input tokens: 206969333 . Total output tokens: 182762594
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 5.286510213976726,
    "estimated_duration": 3600.076590456516,
    "input_throughput": 4801.347017400013,
    "output_throughput": 4246.882147043774,
    "total_throughput": 9048.229164443786,
    "itl": 114.0899342763598,
    "ttft": 1969228.1322950055,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 169,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1580112344352516,
    "arrivals": 310219,
    "finished_requests": 70564,
    "scheduler_time": 74.641660034774
}
#Debug simulation 
Total elapsed time: 5.286603811895475. Arrivals time: 0.2582396643701941 Scheduler time: 4.885486382292584 Scheduler overhead time: 0.04574744449928403 Adapter cache time: 0.02688161307014525 Engine time: 0.04831914231181145 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_8-16-32/adapters_128_slots_96_rate_1.6-0.4-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_8-16-32/adapters_128_slots_96_rate_1.6-0.4-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [42 43 43]
Adapter prompts. [17280, 4320, 17280, 17280, 33, 33, 17280, 33, 4320, 4320, 4320, 33, 17280, 4320, 33, 17280, 4320, 33, 33, 33, 33, 4320, 4320, 17280, 4320, 33, 4320, 4320, 4320, 4320, 17280, 4320, 33, 4320, 33, 17280, 17280, 33, 4320, 4320, 33, 4320, 33, 4320, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 33, 4320, 17280, 17280, 4320, 33, 33, 33, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 33, 33, 4320, 33, 17280, 17280, 33, 33, 4320, 4320, 4320, 33, 17280, 33, 17280, 4320, 33, 17280, 17280, 4320, 4320, 33, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 33, 17280, 33, 33, 17280, 4320, 17280, 17280, 4320, 17280, 33, 4320, 17280, 33, 17280, 4320, 33, 4320, 4320, 17280, 17280, 33, 33, 17280, 33, 33, 33, 4320, 33]
Prompts retrieved: 930186 . Total input tokens: 206969333 . Total output tokens: 182762594
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 4.913722445024177,
    "estimated_duration": 3600.020226016209,
    "input_throughput": 4352.806933349003,
    "output_throughput": 3861.6005264458777,
    "total_throughput": 8214.40745979488,
    "itl": 89.60197150556489,
    "ttft": 2040079.8962455527,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 163,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2131472042389229,
    "arrivals": 310219,
    "finished_requests": 64035,
    "scheduler_time": 72.4278886961805
}
#Debug simulation 
Total elapsed time: 4.913815000094473. Arrivals time: 0.2400645196903497 Scheduler time: 4.489651527721435 Scheduler overhead time: 0.05540789617225528 Adapter cache time: 0.043061181204393506 Engine time: 0.05886095273308456 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_16-16-16/adapters_128_slots_96_rate_1.6-0.4-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_16-16-16/adapters_128_slots_96_rate_1.6-0.4-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [42 43 43]
Adapter prompts. [17280, 4320, 17280, 17280, 33, 33, 17280, 33, 4320, 4320, 4320, 33, 17280, 4320, 33, 17280, 4320, 33, 33, 33, 33, 4320, 4320, 17280, 4320, 33, 4320, 4320, 4320, 4320, 17280, 4320, 33, 4320, 33, 17280, 17280, 33, 4320, 4320, 33, 4320, 33, 4320, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 33, 4320, 17280, 17280, 4320, 33, 33, 33, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 33, 33, 4320, 33, 17280, 17280, 33, 33, 4320, 4320, 4320, 33, 17280, 33, 17280, 4320, 33, 17280, 17280, 4320, 4320, 33, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 33, 17280, 33, 33, 17280, 4320, 17280, 17280, 4320, 17280, 33, 4320, 17280, 33, 17280, 4320, 33, 4320, 4320, 17280, 17280, 33, 33, 17280, 33, 33, 33, 4320, 33]
Prompts retrieved: 930186 . Total input tokens: 206969333 . Total output tokens: 182762594
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 5.292624745052308,
    "estimated_duration": 3600.084031116447,
    "input_throughput": 4801.345982649063,
    "output_throughput": 4247.09280890267,
    "total_throughput": 9048.438791551735,
    "itl": 114.0866096921669,
    "ttft": 1969159.922432745,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 169,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0788826389564177,
    "arrivals": 310219,
    "finished_requests": 70566,
    "scheduler_time": 74.64415694944812
}
#Debug simulation 
Total elapsed time: 5.29271949804388. Arrivals time: 0.2557216468267143 Scheduler time: 4.894404691876844 Scheduler overhead time: 0.04551763250492513 Adapter cache time: 0.02699741767719388 Engine time: 0.04820444528013468 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_16-16-32/adapters_128_slots_96_rate_1.6-0.4-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.4-0.003125_size_16-16-32/adapters_128_slots_96_rate_1.6-0.4-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [42 43 43]
Adapter prompts. [17280, 4320, 17280, 17280, 33, 33, 17280, 33, 4320, 4320, 4320, 33, 17280, 4320, 33, 17280, 4320, 33, 33, 33, 33, 4320, 4320, 17280, 4320, 33, 4320, 4320, 4320, 4320, 17280, 4320, 33, 4320, 33, 17280, 17280, 33, 4320, 4320, 33, 4320, 33, 4320, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 33, 4320, 17280, 17280, 4320, 33, 33, 33, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 33, 33, 4320, 33, 17280, 17280, 33, 33, 4320, 4320, 4320, 33, 17280, 33, 17280, 4320, 33, 17280, 17280, 4320, 4320, 33, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 33, 17280, 33, 33, 17280, 4320, 17280, 17280, 4320, 17280, 33, 4320, 17280, 33, 17280, 4320, 33, 4320, 4320, 17280, 17280, 33, 33, 17280, 33, 33, 33, 4320, 33]
Prompts retrieved: 930186 . Total input tokens: 206969333 . Total output tokens: 182762594
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 4.921726702013984,
    "estimated_duration": 3600.0493042880726,
    "input_throughput": 4340.772772580212,
    "output_throughput": 3851.7791918803146,
    "total_throughput": 8192.551964460527,
    "itl": 89.06583872066305,
    "ttft": 2041847.6127993658,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 163,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2015486423484996,
    "arrivals": 310219,
    "finished_requests": 63859,
    "scheduler_time": 72.37713522985003
}
#Debug simulation 
Total elapsed time: 4.921848169062287. Arrivals time: 0.23981544887647033 Scheduler time: 4.496381510049105 Scheduler overhead time: 0.05578651581890881 Adapter cache time: 0.04353421134874225 Engine time: 0.05939013627357781 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_8-8-8/adapters_128_slots_96_rate_1.6-0.1-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_8-8-8/adapters_128_slots_96_rate_1.6-0.1-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [42 43 43]
Adapter prompts. [17280, 1080, 17280, 17280, 540, 540, 17280, 540, 1080, 1080, 1080, 540, 17280, 1080, 540, 17280, 1080, 540, 540, 540, 540, 1080, 1080, 17280, 1080, 540, 1080, 1080, 1080, 1080, 17280, 1080, 540, 1080, 540, 17280, 17280, 540, 1080, 1080, 540, 1080, 540, 1080, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 540, 1080, 17280, 17280, 1080, 540, 540, 540, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 540, 540, 1080, 540, 17280, 17280, 540, 540, 1080, 1080, 1080, 540, 17280, 540, 17280, 1080, 540, 17280, 17280, 1080, 1080, 540, 540, 540, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 540, 17280, 540, 540, 17280, 1080, 17280, 17280, 1080, 17280, 540, 1080, 17280, 540, 17280, 1080, 540, 1080, 1080, 17280, 17280, 540, 540, 17280, 540, 540, 540, 1080, 540]
Prompts retrieved: 812160 . Total input tokens: 180767437 . Total output tokens: 159578454
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 5.517589730909094,
    "estimated_duration": 3600.0856384117183,
    "input_throughput": 5073.624861895882,
    "output_throughput": 4447.931135067267,
    "total_throughput": 9521.555996963149,
    "itl": 123.87869777866946,
    "ttft": 1884297.0849234993,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2202,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.560524688354164,
    "arrivals": 270597,
    "finished_requests": 74143,
    "scheduler_time": 76.45624099753785
}
#Debug simulation 
Total elapsed time: 5.51768744410947. Arrivals time: 0.2331724411342293 Scheduler time: 5.12384955608286 Scheduler overhead time: 0.042968419613316655 Adapter cache time: 0.05165173509158194 Engine time: 0.04547557118348777 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_8-8-16/adapters_128_slots_96_rate_1.6-0.1-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_8-8-16/adapters_128_slots_96_rate_1.6-0.1-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [42 43 43]
Adapter prompts. [17280, 1080, 17280, 17280, 540, 540, 17280, 540, 1080, 1080, 1080, 540, 17280, 1080, 540, 17280, 1080, 540, 540, 540, 540, 1080, 1080, 17280, 1080, 540, 1080, 1080, 1080, 1080, 17280, 1080, 540, 1080, 540, 17280, 17280, 540, 1080, 1080, 540, 1080, 540, 1080, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 540, 1080, 17280, 17280, 1080, 540, 540, 540, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 540, 540, 1080, 540, 17280, 17280, 540, 540, 1080, 1080, 1080, 540, 17280, 540, 17280, 1080, 540, 17280, 17280, 1080, 1080, 540, 540, 540, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 540, 17280, 540, 540, 17280, 1080, 17280, 17280, 1080, 17280, 540, 1080, 17280, 540, 17280, 1080, 540, 1080, 1080, 17280, 17280, 540, 540, 17280, 540, 540, 540, 1080, 540]
Prompts retrieved: 812160 . Total input tokens: 180767437 . Total output tokens: 159578454
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 5.474376388126984,
    "estimated_duration": 3600.071765614564,
    "input_throughput": 4973.1428053750715,
    "output_throughput": 4363.932172146042,
    "total_throughput": 9337.074977521113,
    "itl": 111.06349855708282,
    "ttft": 1901482.992905094,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2154,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.719463046146293,
    "arrivals": 270597,
    "finished_requests": 72698,
    "scheduler_time": 76.48342682371533
}
#Debug simulation 
Total elapsed time: 5.474499890115112. Arrivals time: 0.2575475994963199 Scheduler time: 5.042097029509023 Scheduler overhead time: 0.047254388220608234 Adapter cache time: 0.055043945321813226 Engine time: 0.04978192294947803 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_8-8-32/adapters_128_slots_96_rate_1.6-0.1-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_8-8-32/adapters_128_slots_96_rate_1.6-0.1-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [42 43 43]
Adapter prompts. [17280, 1080, 17280, 17280, 540, 540, 17280, 540, 1080, 1080, 1080, 540, 17280, 1080, 540, 17280, 1080, 540, 540, 540, 540, 1080, 1080, 17280, 1080, 540, 1080, 1080, 1080, 1080, 17280, 1080, 540, 1080, 540, 17280, 17280, 540, 1080, 1080, 540, 1080, 540, 1080, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 540, 1080, 17280, 17280, 1080, 540, 540, 540, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 540, 540, 1080, 540, 17280, 17280, 540, 540, 1080, 1080, 1080, 540, 17280, 540, 17280, 1080, 540, 17280, 17280, 1080, 1080, 540, 540, 540, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 540, 17280, 540, 540, 17280, 1080, 17280, 17280, 1080, 17280, 540, 1080, 17280, 540, 17280, 1080, 540, 1080, 1080, 17280, 17280, 540, 540, 17280, 540, 540, 540, 1080, 540]
Prompts retrieved: 812160 . Total input tokens: 180767437 . Total output tokens: 159578454
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 5.169487686129287,
    "estimated_duration": 3600.012709864263,
    "input_throughput": 4629.782821135771,
    "output_throughput": 4063.750930632576,
    "total_throughput": 8693.533751768347,
    "itl": 85.26833880034329,
    "ttft": 1959891.9880809975,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2038,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.28508754244511,
    "arrivals": 270597,
    "finished_requests": 67626,
    "scheduler_time": 75.90754102429322
}
#Debug simulation 
Total elapsed time: 5.1695814749691635. Arrivals time: 0.22397621790878475 Scheduler time: 4.735469019273296 Scheduler overhead time: 0.05841386690735817 Adapter cache time: 0.06190086202695966 Engine time: 0.06173720466904342 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_8-16-16/adapters_128_slots_96_rate_1.6-0.1-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_8-16-16/adapters_128_slots_96_rate_1.6-0.1-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [42 43 43]
Adapter prompts. [17280, 1080, 17280, 17280, 540, 540, 17280, 540, 1080, 1080, 1080, 540, 17280, 1080, 540, 17280, 1080, 540, 540, 540, 540, 1080, 1080, 17280, 1080, 540, 1080, 1080, 1080, 1080, 17280, 1080, 540, 1080, 540, 17280, 17280, 540, 1080, 1080, 540, 1080, 540, 1080, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 540, 1080, 17280, 17280, 1080, 540, 540, 540, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 540, 540, 1080, 540, 17280, 17280, 540, 540, 1080, 1080, 1080, 540, 17280, 540, 17280, 1080, 540, 17280, 17280, 1080, 1080, 540, 540, 540, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 540, 17280, 540, 540, 17280, 1080, 17280, 17280, 1080, 17280, 540, 1080, 17280, 540, 17280, 1080, 540, 1080, 1080, 17280, 17280, 540, 540, 17280, 540, 540, 540, 1080, 540]
Prompts retrieved: 812160 . Total input tokens: 180767437 . Total output tokens: 159578454
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 5.482805790845305,
    "estimated_duration": 3600.0257780462834,
    "input_throughput": 4974.474102160099,
    "output_throughput": 4365.269297746112,
    "total_throughput": 9339.743399906212,
    "itl": 111.02369742117571,
    "ttft": 1901076.535711662,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2154,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.593615836790178,
    "arrivals": 270597,
    "finished_requests": 72720,
    "scheduler_time": 76.50477162834062
}
#Debug simulation 
Total elapsed time: 5.482918711844832. Arrivals time: 0.23629068466834724 Scheduler time: 5.072569205891341 Scheduler overhead time: 0.047026822343468666 Adapter cache time: 0.05442253313958645 Engine time: 0.049997422844171524 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_8-16-32/adapters_128_slots_96_rate_1.6-0.1-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_8-16-32/adapters_128_slots_96_rate_1.6-0.1-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [42 43 43]
Adapter prompts. [17280, 1080, 17280, 17280, 540, 540, 17280, 540, 1080, 1080, 1080, 540, 17280, 1080, 540, 17280, 1080, 540, 540, 540, 540, 1080, 1080, 17280, 1080, 540, 1080, 1080, 1080, 1080, 17280, 1080, 540, 1080, 540, 17280, 17280, 540, 1080, 1080, 540, 1080, 540, 1080, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 540, 1080, 17280, 17280, 1080, 540, 540, 540, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 540, 540, 1080, 540, 17280, 17280, 540, 540, 1080, 1080, 1080, 540, 17280, 540, 17280, 1080, 540, 17280, 17280, 1080, 1080, 540, 540, 540, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 540, 17280, 540, 540, 17280, 1080, 17280, 17280, 1080, 17280, 540, 1080, 17280, 540, 17280, 1080, 540, 1080, 1080, 17280, 17280, 540, 540, 17280, 540, 540, 540, 1080, 540]
Prompts retrieved: 812160 . Total input tokens: 180767437 . Total output tokens: 159578454
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 5.154011173872277,
    "estimated_duration": 3600.0341953091265,
    "input_throughput": 4629.8682445067125,
    "output_throughput": 4063.953619958247,
    "total_throughput": 8693.821864464959,
    "itl": 85.25891745998628,
    "ttft": 1959815.802863747,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2038,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.127523240023006,
    "arrivals": 270597,
    "finished_requests": 67629,
    "scheduler_time": 75.91156082321814
}
#Debug simulation 
Total elapsed time: 5.154102894011885. Arrivals time: 0.24530288437381387 Scheduler time: 4.698353392304853 Scheduler overhead time: 0.058379675494506955 Adapter cache time: 0.06169442133978009 Engine time: 0.062098590191453695 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_16-16-16/adapters_128_slots_96_rate_1.6-0.1-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_16-16-16/adapters_128_slots_96_rate_1.6-0.1-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [42 43 43]
Adapter prompts. [17280, 1080, 17280, 17280, 540, 540, 17280, 540, 1080, 1080, 1080, 540, 17280, 1080, 540, 17280, 1080, 540, 540, 540, 540, 1080, 1080, 17280, 1080, 540, 1080, 1080, 1080, 1080, 17280, 1080, 540, 1080, 540, 17280, 17280, 540, 1080, 1080, 540, 1080, 540, 1080, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 540, 1080, 17280, 17280, 1080, 540, 540, 540, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 540, 540, 1080, 540, 17280, 17280, 540, 540, 1080, 1080, 1080, 540, 17280, 540, 17280, 1080, 540, 17280, 17280, 1080, 1080, 540, 540, 540, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 540, 17280, 540, 540, 17280, 1080, 17280, 17280, 1080, 17280, 540, 1080, 17280, 540, 17280, 1080, 540, 1080, 1080, 17280, 17280, 540, 540, 17280, 540, 540, 540, 1080, 540]
Prompts retrieved: 812160 . Total input tokens: 180767437 . Total output tokens: 159578454
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 5.452571460045874,
    "estimated_duration": 3600.0872883150532,
    "input_throughput": 4975.612690875516,
    "output_throughput": 4366.6344010668545,
    "total_throughput": 9342.24709194237,
    "itl": 110.99707591028165,
    "ttft": 1900859.94513904,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2149,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.719046101286798,
    "arrivals": 270597,
    "finished_requests": 72740,
    "scheduler_time": 76.52395966806482
}
#Debug simulation 
Total elapsed time: 5.452668507117778. Arrivals time: 0.22992618568241596 Scheduler time: 5.048108832677826 Scheduler overhead time: 0.04706268245354295 Adapter cache time: 0.05506546841934323 Engine time: 0.04985285666771233 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_16-16-32/adapters_128_slots_96_rate_1.6-0.1-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.05_size_16-16-32/adapters_128_slots_96_rate_1.6-0.1-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [42 43 43]
Adapter prompts. [17280, 1080, 17280, 17280, 540, 540, 17280, 540, 1080, 1080, 1080, 540, 17280, 1080, 540, 17280, 1080, 540, 540, 540, 540, 1080, 1080, 17280, 1080, 540, 1080, 1080, 1080, 1080, 17280, 1080, 540, 1080, 540, 17280, 17280, 540, 1080, 1080, 540, 1080, 540, 1080, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 540, 1080, 17280, 17280, 1080, 540, 540, 540, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 540, 540, 1080, 540, 17280, 17280, 540, 540, 1080, 1080, 1080, 540, 17280, 540, 17280, 1080, 540, 17280, 17280, 1080, 1080, 540, 540, 540, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 540, 17280, 540, 540, 17280, 1080, 17280, 17280, 1080, 17280, 540, 1080, 17280, 540, 17280, 1080, 540, 1080, 1080, 17280, 17280, 540, 540, 17280, 540, 540, 540, 1080, 540]
Prompts retrieved: 812160 . Total input tokens: 180767437 . Total output tokens: 159578454
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 5.148305522976443,
    "estimated_duration": 3600.01946589081,
    "input_throughput": 4630.337740653091,
    "output_throughput": 4064.3408011071533,
    "total_throughput": 8694.678541760244,
    "itl": 85.25554123680477,
    "ttft": 1959633.5620816383,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2037,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.00190834829555,
    "arrivals": 270597,
    "finished_requests": 67635,
    "scheduler_time": 75.91608146884856
}
#Debug simulation 
Total elapsed time: 5.148405944928527. Arrivals time: 0.21998304571025074 Scheduler time: 4.718300835695118 Scheduler overhead time: 0.05831842985935509 Adapter cache time: 0.061517116613686085 Engine time: 0.062078366288915277 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_8-8-8/adapters_128_slots_96_rate_1.6-0.1-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_8-8-8/adapters_128_slots_96_rate_1.6-0.1-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [42 43 43]
Adapter prompts. [17280, 1080, 17280, 17280, 270, 270, 17280, 270, 1080, 1080, 1080, 270, 17280, 1080, 270, 17280, 1080, 270, 270, 270, 270, 1080, 1080, 17280, 1080, 270, 1080, 1080, 1080, 1080, 17280, 1080, 270, 1080, 270, 17280, 17280, 270, 1080, 1080, 270, 1080, 270, 1080, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 270, 1080, 17280, 17280, 1080, 270, 270, 270, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 270, 270, 1080, 270, 17280, 17280, 270, 270, 1080, 1080, 1080, 270, 17280, 270, 17280, 1080, 270, 17280, 17280, 1080, 1080, 270, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 270, 17280, 270, 270, 17280, 1080, 17280, 17280, 1080, 17280, 270, 1080, 17280, 270, 17280, 1080, 270, 1080, 1080, 17280, 17280, 270, 270, 17280, 270, 270, 270, 1080, 270]
Prompts retrieved: 800820 . Total input tokens: 178243290 . Total output tokens: 157358313
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 5.705831561004743,
    "estimated_duration": 3600.0311921937637,
    "input_throughput": 5250.342286196134,
    "output_throughput": 4591.802158782594,
    "total_throughput": 9842.144444978729,
    "itl": 120.05251330073816,
    "ttft": 1850068.645677675,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1326,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.768054376365832,
    "arrivals": 266811,
    "finished_requests": 76662,
    "scheduler_time": 78.86494972138021
}
#Debug simulation 
Total elapsed time: 5.705926624126732. Arrivals time: 0.26965578901581466 Scheduler time: 5.279201259370893 Scheduler overhead time: 0.04446063353680074 Adapter cache time: 0.044297315645962954 Engine time: 0.0468104921746999 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_8-8-16/adapters_128_slots_96_rate_1.6-0.1-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_8-8-16/adapters_128_slots_96_rate_1.6-0.1-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [42 43 43]
Adapter prompts. [17280, 1080, 17280, 17280, 270, 270, 17280, 270, 1080, 1080, 1080, 270, 17280, 1080, 270, 17280, 1080, 270, 270, 270, 270, 1080, 1080, 17280, 1080, 270, 1080, 1080, 1080, 1080, 17280, 1080, 270, 1080, 270, 17280, 17280, 270, 1080, 1080, 270, 1080, 270, 1080, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 270, 1080, 17280, 17280, 1080, 270, 270, 270, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 270, 270, 1080, 270, 17280, 17280, 270, 270, 1080, 1080, 1080, 270, 17280, 270, 17280, 1080, 270, 17280, 17280, 1080, 1080, 270, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 270, 17280, 270, 270, 17280, 1080, 17280, 17280, 1080, 17280, 270, 1080, 17280, 270, 17280, 1080, 270, 1080, 1080, 17280, 17280, 270, 270, 17280, 270, 270, 270, 1080, 270]
Prompts retrieved: 800820 . Total input tokens: 178243290 . Total output tokens: 157358313
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 5.6060893998946995,
    "estimated_duration": 3600.076105266571,
    "input_throughput": 5136.981124633928,
    "output_throughput": 4496.068562639866,
    "total_throughput": 9633.049687273793,
    "itl": 107.8099052041466,
    "ttft": 1869642.0181803,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1289,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.369991732458546,
    "arrivals": 266811,
    "finished_requests": 75055,
    "scheduler_time": 78.74200654999252
}
#Debug simulation 
Total elapsed time: 5.606210472993553. Arrivals time: 0.25519498717039824 Scheduler time: 5.180087879532948 Scheduler overhead time: 0.04834553087130189 Adapter cache time: 0.04824348073452711 Engine time: 0.05101963970810175 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_8-8-32/adapters_128_slots_96_rate_1.6-0.1-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_8-8-32/adapters_128_slots_96_rate_1.6-0.1-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [42 43 43]
Adapter prompts. [17280, 1080, 17280, 17280, 270, 270, 17280, 270, 1080, 1080, 1080, 270, 17280, 1080, 270, 17280, 1080, 270, 270, 270, 270, 1080, 1080, 17280, 1080, 270, 1080, 1080, 1080, 1080, 17280, 1080, 270, 1080, 270, 17280, 17280, 270, 1080, 1080, 270, 1080, 270, 1080, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 270, 1080, 17280, 17280, 1080, 270, 270, 270, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 270, 270, 1080, 270, 17280, 17280, 270, 270, 1080, 1080, 1080, 270, 17280, 270, 17280, 1080, 270, 17280, 17280, 1080, 1080, 270, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 270, 17280, 270, 270, 17280, 1080, 17280, 17280, 1080, 17280, 270, 1080, 17280, 270, 17280, 1080, 270, 1080, 1080, 17280, 17280, 270, 270, 17280, 270, 270, 270, 1080, 270]
Prompts retrieved: 800820 . Total input tokens: 178243290 . Total output tokens: 157358313
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 5.249495082069188,
    "estimated_duration": 3600.013430506804,
    "input_throughput": 4750.480055179249,
    "output_throughput": 4163.114746460853,
    "total_throughput": 8913.594801640102,
    "itl": 83.25212387108895,
    "ttft": 1933191.8804103467,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1206,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.004957738965716,
    "arrivals": 266811,
    "finished_requests": 69450,
    "scheduler_time": 77.67666303582969
}
#Debug simulation 
Total elapsed time: 5.2495937088970095. Arrivals time: 0.2446731231175363 Scheduler time: 4.799867007648572 Scheduler overhead time: 0.05948428064584732 Adapter cache time: 0.05376346712000668 Engine time: 0.0630814922042191 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_8-16-16/adapters_128_slots_96_rate_1.6-0.1-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_8-16-16/adapters_128_slots_96_rate_1.6-0.1-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [42 43 43]
Adapter prompts. [17280, 1080, 17280, 17280, 270, 270, 17280, 270, 1080, 1080, 1080, 270, 17280, 1080, 270, 17280, 1080, 270, 270, 270, 270, 1080, 1080, 17280, 1080, 270, 1080, 1080, 1080, 1080, 17280, 1080, 270, 1080, 270, 17280, 17280, 270, 1080, 1080, 270, 1080, 270, 1080, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 270, 1080, 17280, 17280, 1080, 270, 270, 270, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 270, 270, 1080, 270, 17280, 17280, 270, 270, 1080, 1080, 1080, 270, 17280, 270, 17280, 1080, 270, 17280, 17280, 1080, 1080, 270, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 270, 17280, 270, 270, 17280, 1080, 17280, 17280, 1080, 17280, 270, 1080, 17280, 270, 17280, 1080, 270, 1080, 1080, 17280, 17280, 270, 270, 17280, 270, 270, 270, 1080, 270]
Prompts retrieved: 800820 . Total input tokens: 178243290 . Total output tokens: 157358313
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 5.585892309900373,
    "estimated_duration": 3600.044410045044,
    "input_throughput": 5137.500512047457,
    "output_throughput": 4496.608140397206,
    "total_throughput": 9634.108652444662,
    "itl": 107.7894957273694,
    "ttft": 1869383.799373508,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1292,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.738067858796594,
    "arrivals": 266811,
    "finished_requests": 75064,
    "scheduler_time": 78.75582025592651
}
#Debug simulation 
Total elapsed time: 5.58601667592302. Arrivals time: 0.2365380849223584 Scheduler time: 5.179246543440968 Scheduler overhead time: 0.04834990901872516 Adapter cache time: 0.04734248574823141 Engine time: 0.051256172358989716 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_8-16-32/adapters_128_slots_96_rate_1.6-0.1-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_8-16-32/adapters_128_slots_96_rate_1.6-0.1-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [42 43 43]
Adapter prompts. [17280, 1080, 17280, 17280, 270, 270, 17280, 270, 1080, 1080, 1080, 270, 17280, 1080, 270, 17280, 1080, 270, 270, 270, 270, 1080, 1080, 17280, 1080, 270, 1080, 1080, 1080, 1080, 17280, 1080, 270, 1080, 270, 17280, 17280, 270, 1080, 1080, 270, 1080, 270, 1080, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 270, 1080, 17280, 17280, 1080, 270, 270, 270, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 270, 270, 1080, 270, 17280, 17280, 270, 270, 1080, 1080, 1080, 270, 17280, 270, 17280, 1080, 270, 17280, 17280, 1080, 1080, 270, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 270, 17280, 270, 270, 17280, 1080, 17280, 17280, 1080, 17280, 270, 1080, 17280, 270, 17280, 1080, 270, 1080, 1080, 17280, 17280, 270, 270, 17280, 270, 270, 270, 1080, 270]
Prompts retrieved: 800820 . Total input tokens: 178243290 . Total output tokens: 157358313
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 5.236873200861737,
    "estimated_duration": 3600.053212005435,
    "input_throughput": 4739.88160594284,
    "output_throughput": 4152.08223871593,
    "total_throughput": 8891.96384465877,
    "itl": 83.48868539629102,
    "ttft": 1935447.796820134,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1193,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.808578241239275,
    "arrivals": 266811,
    "finished_requests": 69289,
    "scheduler_time": 77.45329777907935
}
#Debug simulation 
Total elapsed time: 5.236965674906969. Arrivals time: 0.24667436233721673 Scheduler time: 4.786189534468576 Scheduler overhead time: 0.059258102206513286 Adapter cache time: 0.053114564856514335 Engine time: 0.06307537434622645 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_16-16-16/adapters_128_slots_96_rate_1.6-0.1-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_16-16-16/adapters_128_slots_96_rate_1.6-0.1-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [42 43 43]
Adapter prompts. [17280, 1080, 17280, 17280, 270, 270, 17280, 270, 1080, 1080, 1080, 270, 17280, 1080, 270, 17280, 1080, 270, 270, 270, 270, 1080, 1080, 17280, 1080, 270, 1080, 1080, 1080, 1080, 17280, 1080, 270, 1080, 270, 17280, 17280, 270, 1080, 1080, 270, 1080, 270, 1080, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 270, 1080, 17280, 17280, 1080, 270, 270, 270, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 270, 270, 1080, 270, 17280, 17280, 270, 270, 1080, 1080, 1080, 270, 17280, 270, 17280, 1080, 270, 17280, 17280, 1080, 1080, 270, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 270, 17280, 270, 270, 17280, 1080, 17280, 17280, 1080, 17280, 270, 1080, 17280, 270, 17280, 1080, 270, 1080, 1080, 17280, 17280, 270, 270, 17280, 270, 270, 270, 1080, 270]
Prompts retrieved: 800820 . Total input tokens: 178243290 . Total output tokens: 157358313
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 5.616889117984101,
    "estimated_duration": 3600.080000951837,
    "input_throughput": 5138.116096061573,
    "output_throughput": 4497.475054920762,
    "total_throughput": 9635.591150982336,
    "itl": 107.77311602636993,
    "ttft": 1869064.3601872122,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1290,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.235258013335978,
    "arrivals": 266811,
    "finished_requests": 75076,
    "scheduler_time": 78.76669169264518
}
#Debug simulation 
Total elapsed time: 5.617002262966707. Arrivals time: 0.2399975957814604 Scheduler time: 5.206144307274371 Scheduler overhead time: 0.048432909650728106 Adapter cache time: 0.04782645544037223 Engine time: 0.0512795839458704 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_16-16-32/adapters_128_slots_96_rate_1.6-0.1-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.025_size_16-16-32/adapters_128_slots_96_rate_1.6-0.1-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [42 43 43]
Adapter prompts. [17280, 1080, 17280, 17280, 270, 270, 17280, 270, 1080, 1080, 1080, 270, 17280, 1080, 270, 17280, 1080, 270, 270, 270, 270, 1080, 1080, 17280, 1080, 270, 1080, 1080, 1080, 1080, 17280, 1080, 270, 1080, 270, 17280, 17280, 270, 1080, 1080, 270, 1080, 270, 1080, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 270, 1080, 17280, 17280, 1080, 270, 270, 270, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 270, 270, 1080, 270, 17280, 17280, 270, 270, 1080, 1080, 1080, 270, 17280, 270, 17280, 1080, 270, 17280, 17280, 1080, 1080, 270, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 270, 17280, 270, 270, 17280, 1080, 17280, 17280, 1080, 17280, 270, 1080, 17280, 270, 17280, 1080, 270, 1080, 1080, 17280, 17280, 270, 270, 17280, 270, 270, 270, 1080, 270]
Prompts retrieved: 800820 . Total input tokens: 178243290 . Total output tokens: 157358313
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 5.247097967891023,
    "estimated_duration": 3600.0864631977415,
    "input_throughput": 4751.2369980155345,
    "output_throughput": 4163.797495764936,
    "total_throughput": 8915.03449378047,
    "itl": 83.26300561606821,
    "ttft": 1932948.8211269637,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1206,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.841231431476741,
    "arrivals": 266811,
    "finished_requests": 69461,
    "scheduler_time": 77.68245796673065
}
#Debug simulation 
Total elapsed time: 5.247194099938497. Arrivals time: 0.24982195440679789 Scheduler time: 4.790645941859111 Scheduler overhead time: 0.059602843364700675 Adapter cache time: 0.05433859443292022 Engine time: 0.06357961264438927 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-8/adapters_128_slots_96_rate_1.6-0.1-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-8/adapters_128_slots_96_rate_1.6-0.1-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [42 43 43]
Adapter prompts. [17280, 1080, 17280, 17280, 135, 135, 17280, 135, 1080, 1080, 1080, 135, 17280, 1080, 135, 17280, 1080, 135, 135, 135, 135, 1080, 1080, 17280, 1080, 135, 1080, 1080, 1080, 1080, 17280, 1080, 135, 1080, 135, 17280, 17280, 135, 1080, 1080, 135, 1080, 135, 1080, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 135, 1080, 17280, 17280, 1080, 135, 135, 135, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 135, 135, 1080, 135, 17280, 17280, 135, 135, 1080, 1080, 1080, 135, 17280, 135, 17280, 1080, 135, 17280, 17280, 1080, 1080, 135, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 135, 17280, 135, 135, 17280, 1080, 17280, 17280, 1080, 17280, 135, 1080, 17280, 135, 17280, 1080, 135, 1080, 1080, 17280, 17280, 135, 135, 17280, 135, 135, 135, 1080, 135]
Prompts retrieved: 795150 . Total input tokens: 176975216 . Total output tokens: 156255932
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 5.812576588010415,
    "estimated_duration": 3600.003796561107,
    "input_throughput": 5352.792688276519,
    "output_throughput": 4687.51616765512,
    "total_throughput": 10040.308855931638,
    "itl": 117.20559487773512,
    "ttft": 1833416.30274149,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 764,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.0518805004098475,
    "arrivals": 264887,
    "finished_requests": 78105,
    "scheduler_time": 80.45801819856116
}
#Debug simulation 
Total elapsed time: 5.812669040868059. Arrivals time: 0.26788411289453506 Scheduler time: 5.3905893007759005 Scheduler overhead time: 0.045261787017807364 Adapter cache time: 0.03958358149975538 Engine time: 0.047654081834480166 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-16/adapters_128_slots_96_rate_1.6-0.1-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-16/adapters_128_slots_96_rate_1.6-0.1-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [42 43 43]
Adapter prompts. [17280, 1080, 17280, 17280, 135, 135, 17280, 135, 1080, 1080, 1080, 135, 17280, 1080, 135, 17280, 1080, 135, 135, 135, 135, 1080, 1080, 17280, 1080, 135, 1080, 1080, 1080, 1080, 17280, 1080, 135, 1080, 135, 17280, 17280, 135, 1080, 1080, 135, 1080, 135, 1080, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 135, 1080, 17280, 17280, 1080, 135, 135, 135, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 135, 135, 1080, 135, 17280, 17280, 135, 135, 1080, 1080, 1080, 135, 17280, 135, 17280, 1080, 135, 17280, 17280, 1080, 1080, 135, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 135, 17280, 135, 135, 17280, 1080, 17280, 17280, 1080, 17280, 135, 1080, 17280, 135, 17280, 1080, 135, 1080, 1080, 17280, 17280, 135, 135, 17280, 135, 135, 135, 1080, 135]
Prompts retrieved: 795150 . Total input tokens: 176975216 . Total output tokens: 156255932
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 5.691276238067076,
    "estimated_duration": 3600.0415514303622,
    "input_throughput": 5226.004403344989,
    "output_throughput": 4576.059405051749,
    "total_throughput": 9802.063808396739,
    "itl": 105.4848847169567,
    "ttft": 1853985.102435397,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 742,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.4101565099600775,
    "arrivals": 264887,
    "finished_requests": 76249,
    "scheduler_time": 80.14372610066584
}
#Debug simulation 
Total elapsed time: 5.6913719470612705. Arrivals time: 0.23915393697097898 Scheduler time: 5.284202607115731 Scheduler overhead time: 0.04950244422070682 Adapter cache time: 0.04232252179645002 Engine time: 0.05217089829966426 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-32/adapters_128_slots_96_rate_1.6-0.1-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-32/adapters_128_slots_96_rate_1.6-0.1-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [42 43 43]
Adapter prompts. [17280, 1080, 17280, 17280, 135, 135, 17280, 135, 1080, 1080, 1080, 135, 17280, 1080, 135, 17280, 1080, 135, 135, 135, 135, 1080, 1080, 17280, 1080, 135, 1080, 1080, 1080, 1080, 17280, 1080, 135, 1080, 135, 17280, 17280, 135, 1080, 1080, 135, 1080, 135, 1080, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 135, 1080, 17280, 17280, 1080, 135, 135, 135, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 135, 135, 1080, 135, 17280, 17280, 135, 135, 1080, 1080, 1080, 135, 17280, 135, 17280, 1080, 135, 17280, 17280, 1080, 1080, 135, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 135, 17280, 135, 135, 17280, 1080, 17280, 17280, 1080, 17280, 135, 1080, 17280, 135, 17280, 1080, 135, 1080, 1080, 17280, 17280, 135, 135, 17280, 135, 135, 135, 1080, 135]
Prompts retrieved: 795150 . Total input tokens: 176975216 . Total output tokens: 156255932
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 5.325167246861383,
    "estimated_duration": 3600.085290569158,
    "input_throughput": 4809.276337245544,
    "output_throughput": 4221.212214002147,
    "total_throughput": 9030.48855124769,
    "itl": 81.79267772707503,
    "ttft": 1922540.8139451311,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 651,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.871333521078369,
    "arrivals": 264887,
    "finished_requests": 70290,
    "scheduler_time": 78.77493677086383
}
#Debug simulation 
Total elapsed time: 5.325266724918038. Arrivals time: 0.2266599154099822 Scheduler time: 4.895880496595055 Scheduler overhead time: 0.06041004997678101 Adapter cache time: 0.04904807475395501 Engine time: 0.06400551274418831 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-16-16/adapters_128_slots_96_rate_1.6-0.1-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-16-16/adapters_128_slots_96_rate_1.6-0.1-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [42 43 43]
Adapter prompts. [17280, 1080, 17280, 17280, 135, 135, 17280, 135, 1080, 1080, 1080, 135, 17280, 1080, 135, 17280, 1080, 135, 135, 135, 135, 1080, 1080, 17280, 1080, 135, 1080, 1080, 1080, 1080, 17280, 1080, 135, 1080, 135, 17280, 17280, 135, 1080, 1080, 135, 1080, 135, 1080, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 135, 1080, 17280, 17280, 1080, 135, 135, 135, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 135, 135, 1080, 135, 17280, 17280, 135, 135, 1080, 1080, 1080, 135, 17280, 135, 17280, 1080, 135, 17280, 17280, 1080, 1080, 135, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 135, 17280, 135, 135, 17280, 1080, 17280, 17280, 1080, 17280, 135, 1080, 17280, 135, 17280, 1080, 135, 1080, 1080, 17280, 17280, 135, 135, 17280, 135, 135, 135, 1080, 135]
Prompts retrieved: 795150 . Total input tokens: 176975216 . Total output tokens: 156255932
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 5.65089361416176,
    "estimated_duration": 3600.0999328422386,
    "input_throughput": 5226.273812112122,
    "output_throughput": 4576.273244446617,
    "total_throughput": 9802.547056558738,
    "itl": 105.47137634364081,
    "ttft": 1853952.4879250873,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 743,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.029226779346343,
    "arrivals": 264887,
    "finished_requests": 76256,
    "scheduler_time": 80.15231417234274
}
#Debug simulation 
Total elapsed time: 5.65098565001972. Arrivals time: 0.2599956919439137 Scheduler time: 5.224009444238618 Scheduler overhead time: 0.04922894621267915 Adapter cache time: 0.04238310316577554 Engine time: 0.051710102474316955 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-16-32/adapters_128_slots_96_rate_1.6-0.1-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_8-16-32/adapters_128_slots_96_rate_1.6-0.1-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [42 43 43]
Adapter prompts. [17280, 1080, 17280, 17280, 135, 135, 17280, 135, 1080, 1080, 1080, 135, 17280, 1080, 135, 17280, 1080, 135, 135, 135, 135, 1080, 1080, 17280, 1080, 135, 1080, 1080, 1080, 1080, 17280, 1080, 135, 1080, 135, 17280, 17280, 135, 1080, 1080, 135, 1080, 135, 1080, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 135, 1080, 17280, 17280, 1080, 135, 135, 135, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 135, 135, 1080, 135, 17280, 17280, 135, 135, 1080, 1080, 1080, 135, 17280, 135, 17280, 1080, 135, 17280, 17280, 1080, 1080, 135, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 135, 17280, 135, 135, 17280, 1080, 17280, 17280, 1080, 17280, 135, 1080, 17280, 135, 17280, 1080, 135, 1080, 1080, 17280, 17280, 135, 135, 17280, 135, 135, 135, 1080, 135]
Prompts retrieved: 795150 . Total input tokens: 176975216 . Total output tokens: 156255932
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 5.5774535208474845,
    "estimated_duration": 3600.0269536768274,
    "input_throughput": 4809.832599257368,
    "output_throughput": 4221.661447417131,
    "total_throughput": 9031.4940466745,
    "itl": 81.788933466464,
    "ttft": 1922593.3357763505,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 652,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.829080120534665,
    "arrivals": 264887,
    "finished_requests": 70300,
    "scheduler_time": 78.77507219179962
}
#Debug simulation 
Total elapsed time: 5.5775210708379745. Arrivals time: 0.4955932970624417 Scheduler time: 4.8794640123378485 Scheduler overhead time: 0.0608375770971179 Adapter cache time: 0.047859918558970094 Engine time: 0.0645070681348443 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_16-16-16/adapters_128_slots_96_rate_1.6-0.1-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_16-16-16/adapters_128_slots_96_rate_1.6-0.1-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [42 43 43]
Adapter prompts. [17280, 1080, 17280, 17280, 135, 135, 17280, 135, 1080, 1080, 1080, 135, 17280, 1080, 135, 17280, 1080, 135, 135, 135, 135, 1080, 1080, 17280, 1080, 135, 1080, 1080, 1080, 1080, 17280, 1080, 135, 1080, 135, 17280, 17280, 135, 1080, 1080, 135, 1080, 135, 1080, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 135, 1080, 17280, 17280, 1080, 135, 135, 135, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 135, 135, 1080, 135, 17280, 17280, 135, 135, 1080, 1080, 1080, 135, 17280, 135, 17280, 1080, 135, 17280, 17280, 1080, 1080, 135, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 135, 17280, 135, 135, 17280, 1080, 17280, 17280, 1080, 17280, 135, 1080, 17280, 135, 17280, 1080, 135, 1080, 1080, 17280, 17280, 135, 135, 17280, 135, 135, 135, 1080, 135]
Prompts retrieved: 795150 . Total input tokens: 176975216 . Total output tokens: 156255932
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 5.675583156989887,
    "estimated_duration": 3600.0410312708877,
    "input_throughput": 5226.487097386699,
    "output_throughput": 4576.311452256982,
    "total_throughput": 9802.798549643681,
    "itl": 105.46247840608036,
    "ttft": 1853888.1404733702,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 745,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.756021100725024,
    "arrivals": 264887,
    "finished_requests": 76257,
    "scheduler_time": 80.1566868851256
}
#Debug simulation 
Total elapsed time: 5.675678656902164. Arrivals time: 0.2391754079144448 Scheduler time: 5.269187388243154 Scheduler overhead time: 0.04929021140560508 Adapter cache time: 0.04231712920591235 Engine time: 0.0520572739187628 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_16-16-32/adapters_128_slots_96_rate_1.6-0.1-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.0125_size_16-16-32/adapters_128_slots_96_rate_1.6-0.1-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [42 43 43]
Adapter prompts. [17280, 1080, 17280, 17280, 135, 135, 17280, 135, 1080, 1080, 1080, 135, 17280, 1080, 135, 17280, 1080, 135, 135, 135, 135, 1080, 1080, 17280, 1080, 135, 1080, 1080, 1080, 1080, 17280, 1080, 135, 1080, 135, 17280, 17280, 135, 1080, 1080, 135, 1080, 135, 1080, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 135, 1080, 17280, 17280, 1080, 135, 135, 135, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 135, 135, 1080, 135, 17280, 17280, 135, 135, 1080, 1080, 1080, 135, 17280, 135, 17280, 1080, 135, 17280, 17280, 1080, 1080, 135, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 135, 17280, 135, 135, 17280, 1080, 17280, 17280, 1080, 17280, 135, 1080, 17280, 135, 17280, 1080, 135, 1080, 1080, 17280, 17280, 135, 135, 17280, 135, 135, 135, 1080, 135]
Prompts retrieved: 795150 . Total input tokens: 176975216 . Total output tokens: 156255932
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 5.293502358021215,
    "estimated_duration": 3600.04364674486,
    "input_throughput": 4809.712519917998,
    "output_throughput": 4221.733537520395,
    "total_throughput": 9031.446057438394,
    "itl": 81.78604730437955,
    "ttft": 1922555.5765030358,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 650,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.775439764820068,
    "arrivals": 264887,
    "finished_requests": 70300,
    "scheduler_time": 78.77604251764129
}
#Debug simulation 
Total elapsed time: 5.293596180854365. Arrivals time: 0.2523189652711153 Scheduler time: 4.839736771769822 Scheduler overhead time: 0.0602868776768446 Adapter cache time: 0.048105721129104495 Engine time: 0.06405797763727605 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-8/adapters_128_slots_96_rate_1.6-0.1-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-8/adapters_128_slots_96_rate_1.6-0.1-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [42 43 43]
Adapter prompts. [17280, 1080, 17280, 17280, 66, 66, 17280, 66, 1080, 1080, 1080, 66, 17280, 1080, 66, 17280, 1080, 66, 66, 66, 66, 1080, 1080, 17280, 1080, 66, 1080, 1080, 1080, 1080, 17280, 1080, 66, 1080, 66, 17280, 17280, 66, 1080, 1080, 66, 1080, 66, 1080, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 66, 1080, 17280, 17280, 1080, 66, 66, 66, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 66, 66, 1080, 66, 17280, 17280, 66, 66, 1080, 1080, 1080, 66, 17280, 66, 17280, 1080, 66, 17280, 17280, 1080, 1080, 66, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 66, 17280, 66, 66, 17280, 1080, 17280, 17280, 1080, 17280, 66, 1080, 17280, 66, 17280, 1080, 66, 1080, 1080, 17280, 17280, 66, 66, 17280, 66, 66, 66, 1080, 66]
Prompts retrieved: 792252 . Total input tokens: 176338065 . Total output tokens: 155698882
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 5.811692470218986,
    "estimated_duration": 3600.0500493466707,
    "input_throughput": 5413.335296140311,
    "output_throughput": 4731.885047845787,
    "total_throughput": 10145.220343986099,
    "itl": 115.9685869788675,
    "ttft": 1817968.4433471288,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 341,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2548314798949343,
    "arrivals": 263940,
    "finished_requests": 79136,
    "scheduler_time": 81.24158296345688
}
#Debug simulation 
Total elapsed time: 5.811816974077374. Arrivals time: 0.26379010593518615 Scheduler time: 5.396460890537128 Scheduler overhead time: 0.04524294985458255 Adapter cache time: 0.03660686872899532 Engine time: 0.04796938016079366 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-16/adapters_128_slots_96_rate_1.6-0.1-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-16/adapters_128_slots_96_rate_1.6-0.1-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [42 43 43]
Adapter prompts. [17280, 1080, 17280, 17280, 66, 66, 17280, 66, 1080, 1080, 1080, 66, 17280, 1080, 66, 17280, 1080, 66, 66, 66, 66, 1080, 1080, 17280, 1080, 66, 1080, 1080, 1080, 1080, 17280, 1080, 66, 1080, 66, 17280, 17280, 66, 1080, 1080, 66, 1080, 66, 1080, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 66, 1080, 17280, 17280, 1080, 66, 66, 66, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 66, 66, 1080, 66, 17280, 17280, 66, 66, 1080, 1080, 1080, 66, 17280, 66, 17280, 1080, 66, 17280, 17280, 1080, 1080, 66, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 66, 17280, 66, 66, 17280, 1080, 17280, 17280, 1080, 17280, 66, 1080, 17280, 66, 17280, 1080, 66, 1080, 1080, 17280, 17280, 66, 66, 17280, 66, 66, 66, 1080, 66]
Prompts retrieved: 792252 . Total input tokens: 176338065 . Total output tokens: 155698882
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 5.700660397065803,
    "estimated_duration": 3600.065734466264,
    "input_throughput": 5283.418804801338,
    "output_throughput": 4620.032306845052,
    "total_throughput": 9903.45111164639,
    "itl": 104.4038776572529,
    "ttft": 1840024.9889848132,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 334,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.452908638985831,
    "arrivals": 263940,
    "finished_requests": 77231,
    "scheduler_time": 80.8846331840578
}
#Debug simulation 
Total elapsed time: 5.700754440156743. Arrivals time: 0.23991515231318772 Scheduler time: 5.295487743802369 Scheduler overhead time: 0.04949109139852226 Adapter cache time: 0.03972717956639826 Engine time: 0.052291495027020574 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-32/adapters_128_slots_96_rate_1.6-0.1-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-32/adapters_128_slots_96_rate_1.6-0.1-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [42 43 43]
Adapter prompts. [17280, 1080, 17280, 17280, 66, 66, 17280, 66, 1080, 1080, 1080, 66, 17280, 1080, 66, 17280, 1080, 66, 66, 66, 66, 1080, 1080, 17280, 1080, 66, 1080, 1080, 1080, 1080, 17280, 1080, 66, 1080, 66, 17280, 17280, 66, 1080, 1080, 66, 1080, 66, 1080, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 66, 1080, 17280, 17280, 1080, 66, 66, 66, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 66, 66, 1080, 66, 17280, 17280, 66, 66, 1080, 1080, 1080, 66, 17280, 66, 17280, 1080, 66, 17280, 17280, 1080, 1080, 66, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 66, 17280, 66, 66, 17280, 1080, 17280, 17280, 1080, 17280, 66, 1080, 17280, 66, 17280, 1080, 66, 1080, 1080, 17280, 17280, 66, 66, 17280, 66, 66, 66, 1080, 66]
Prompts retrieved: 792252 . Total input tokens: 176338065 . Total output tokens: 155698882
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 5.357698851032183,
    "estimated_duration": 3600.0076435937444,
    "input_throughput": 4859.001627712654,
    "output_throughput": 4252.813192562135,
    "total_throughput": 9111.814820274789,
    "itl": 81.06529911453778,
    "ttft": 1910579.5676078214,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 315,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3782088924292593,
    "arrivals": 263940,
    "finished_requests": 70967,
    "scheduler_time": 79.32706739642249
}
#Debug simulation 
Total elapsed time: 5.357807561056688. Arrivals time: 0.23292167345061898 Scheduler time: 4.923194522038102 Scheduler overhead time: 0.060885206097736955 Adapter cache time: 0.04681457323022187 Engine time: 0.0645578489638865 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-16-16/adapters_128_slots_96_rate_1.6-0.1-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-16-16/adapters_128_slots_96_rate_1.6-0.1-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [42 43 43]
Adapter prompts. [17280, 1080, 17280, 17280, 66, 66, 17280, 66, 1080, 1080, 1080, 66, 17280, 1080, 66, 17280, 1080, 66, 66, 66, 66, 1080, 1080, 17280, 1080, 66, 1080, 1080, 1080, 1080, 17280, 1080, 66, 1080, 66, 17280, 17280, 66, 1080, 1080, 66, 1080, 66, 1080, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 66, 1080, 17280, 17280, 1080, 66, 66, 66, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 66, 66, 1080, 66, 17280, 17280, 66, 66, 1080, 1080, 1080, 66, 17280, 66, 17280, 1080, 66, 17280, 17280, 1080, 1080, 66, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 66, 17280, 66, 66, 17280, 1080, 17280, 17280, 1080, 17280, 66, 1080, 17280, 66, 17280, 1080, 66, 1080, 1080, 17280, 17280, 66, 66, 17280, 66, 66, 66, 1080, 66]
Prompts retrieved: 792252 . Total input tokens: 176338065 . Total output tokens: 155698882
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 5.741559237008914,
    "estimated_duration": 3600.084197322301,
    "input_throughput": 5283.616426012462,
    "output_throughput": 4620.0230573415565,
    "total_throughput": 9903.639483354018,
    "itl": 104.39697705330259,
    "ttft": 1840137.7334448253,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 334,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.269663470508527,
    "arrivals": 263940,
    "finished_requests": 77233,
    "scheduler_time": 80.88871780853383
}
#Debug simulation 
Total elapsed time: 5.741654150187969. Arrivals time: 0.24305488262325525 Scheduler time: 5.332455804105848 Scheduler overhead time: 0.04960166197270155 Adapter cache time: 0.04010992217808962 Engine time: 0.052533365320414305 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-16-32/adapters_128_slots_96_rate_1.6-0.1-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_8-16-32/adapters_128_slots_96_rate_1.6-0.1-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [42 43 43]
Adapter prompts. [17280, 1080, 17280, 17280, 66, 66, 17280, 66, 1080, 1080, 1080, 66, 17280, 1080, 66, 17280, 1080, 66, 66, 66, 66, 1080, 1080, 17280, 1080, 66, 1080, 1080, 1080, 1080, 17280, 1080, 66, 1080, 66, 17280, 17280, 66, 1080, 1080, 66, 1080, 66, 1080, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 66, 1080, 17280, 17280, 1080, 66, 66, 66, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 66, 66, 1080, 66, 17280, 17280, 66, 66, 1080, 1080, 1080, 66, 17280, 66, 17280, 1080, 66, 17280, 17280, 1080, 1080, 66, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 66, 17280, 66, 66, 17280, 1080, 17280, 17280, 1080, 17280, 66, 1080, 17280, 66, 17280, 1080, 66, 1080, 1080, 17280, 17280, 66, 66, 17280, 66, 66, 66, 1080, 66]
Prompts retrieved: 792252 . Total input tokens: 176338065 . Total output tokens: 155698882
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 5.361341665033251,
    "estimated_duration": 3600.083000026935,
    "input_throughput": 4859.024916889172,
    "output_throughput": 4252.756394751302,
    "total_throughput": 9111.781311640474,
    "itl": 81.06381289891155,
    "ttft": 1910729.3385510405,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 314,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.344450289155368,
    "arrivals": 263940,
    "finished_requests": 70968,
    "scheduler_time": 79.33128902223471
}
#Debug simulation 
Total elapsed time: 5.361435618950054. Arrivals time: 0.24865056690759957 Scheduler time: 4.912837882293388 Scheduler overhead time: 0.06041509425267577 Adapter cache time: 0.045652362052351236 Engine time: 0.0645291528198868 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_16-16-16/adapters_128_slots_96_rate_1.6-0.1-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_16-16-16/adapters_128_slots_96_rate_1.6-0.1-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [42 43 43]
Adapter prompts. [17280, 1080, 17280, 17280, 66, 66, 17280, 66, 1080, 1080, 1080, 66, 17280, 1080, 66, 17280, 1080, 66, 66, 66, 66, 1080, 1080, 17280, 1080, 66, 1080, 1080, 1080, 1080, 17280, 1080, 66, 1080, 66, 17280, 17280, 66, 1080, 1080, 66, 1080, 66, 1080, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 66, 1080, 17280, 17280, 1080, 66, 66, 66, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 66, 66, 1080, 66, 17280, 17280, 66, 66, 1080, 1080, 1080, 66, 17280, 66, 17280, 1080, 66, 17280, 17280, 1080, 1080, 66, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 66, 17280, 66, 66, 17280, 1080, 17280, 17280, 1080, 17280, 66, 1080, 17280, 66, 17280, 1080, 66, 1080, 1080, 17280, 17280, 66, 66, 17280, 66, 66, 66, 1080, 66]
Prompts retrieved: 792252 . Total input tokens: 176338065 . Total output tokens: 155698882
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 5.715418698033318,
    "estimated_duration": 3600.001284449006,
    "input_throughput": 5283.900059194395,
    "output_throughput": 4620.23279598516,
    "total_throughput": 9904.132855179554,
    "itl": 104.38952468197645,
    "ttft": 1840083.259193829,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 335,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1386135150911203,
    "arrivals": 263940,
    "finished_requests": 77236,
    "scheduler_time": 80.88761134744243
}
#Debug simulation 
Total elapsed time: 5.715512808179483. Arrivals time: 0.24020698596723378 Scheduler time: 5.309338306775317 Scheduler overhead time: 0.049614816438406706 Adapter cache time: 0.03997134789824486 Engine time: 0.05238847527652979 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_16-16-32/adapters_128_slots_96_rate_1.6-0.1-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.00625_size_16-16-32/adapters_128_slots_96_rate_1.6-0.1-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [42 43 43]
Adapter prompts. [17280, 1080, 17280, 17280, 66, 66, 17280, 66, 1080, 1080, 1080, 66, 17280, 1080, 66, 17280, 1080, 66, 66, 66, 66, 1080, 1080, 17280, 1080, 66, 1080, 1080, 1080, 1080, 17280, 1080, 66, 1080, 66, 17280, 17280, 66, 1080, 1080, 66, 1080, 66, 1080, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 66, 1080, 17280, 17280, 1080, 66, 66, 66, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 66, 66, 1080, 66, 17280, 17280, 66, 66, 1080, 1080, 1080, 66, 17280, 66, 17280, 1080, 66, 17280, 17280, 1080, 1080, 66, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 66, 17280, 66, 66, 17280, 1080, 17280, 17280, 1080, 17280, 66, 1080, 17280, 66, 17280, 1080, 66, 1080, 1080, 17280, 17280, 66, 66, 17280, 66, 66, 66, 1080, 66]
Prompts retrieved: 792252 . Total input tokens: 176338065 . Total output tokens: 155698882
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 5.348503669956699,
    "estimated_duration": 3600.010264906925,
    "input_throughput": 4859.565865835748,
    "output_throughput": 4253.014262001237,
    "total_throughput": 9112.580127836984,
    "itl": 81.0617681238014,
    "ttft": 1910646.6019326276,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 315,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.333057347927254,
    "arrivals": 263940,
    "finished_requests": 70971,
    "scheduler_time": 79.32911494182855
}
#Debug simulation 
Total elapsed time: 5.348601313075051. Arrivals time: 0.2283055461011827 Scheduler time: 4.919905539369211 Scheduler overhead time: 0.06078297831118107 Adapter cache time: 0.045473945094272494 Engine time: 0.06474065803922713 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-8/adapters_128_slots_96_rate_1.6-0.1-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-8/adapters_128_slots_96_rate_1.6-0.1-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [42 43 43]
Adapter prompts. [17280, 1080, 17280, 17280, 33, 33, 17280, 33, 1080, 1080, 1080, 33, 17280, 1080, 33, 17280, 1080, 33, 33, 33, 33, 1080, 1080, 17280, 1080, 33, 1080, 1080, 1080, 1080, 17280, 1080, 33, 1080, 33, 17280, 17280, 33, 1080, 1080, 33, 1080, 33, 1080, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 33, 1080, 17280, 17280, 1080, 33, 33, 33, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 33, 33, 1080, 33, 17280, 17280, 33, 33, 1080, 1080, 1080, 33, 17280, 33, 17280, 1080, 33, 17280, 17280, 1080, 1080, 33, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 33, 17280, 33, 33, 17280, 1080, 17280, 17280, 1080, 17280, 33, 1080, 17280, 33, 17280, 1080, 33, 1080, 1080, 17280, 17280, 33, 33, 17280, 33, 33, 33, 1080, 33]
Prompts retrieved: 790866 . Total input tokens: 176031437 . Total output tokens: 155441759
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 5.839689987944439,
    "estimated_duration": 3600.0943277542333,
    "input_throughput": 5482.856892895142,
    "output_throughput": 4769.845575327456,
    "total_throughput": 10252.702468222597,
    "itl": 114.86101556411126,
    "ttft": 1819230.1521756218,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 207,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3687686696136354,
    "arrivals": 263449,
    "finished_requests": 79830,
    "scheduler_time": 81.94453247879426
}
#Debug simulation 
Total elapsed time: 5.839790081838146. Arrivals time: 0.24685585079714656 Scheduler time: 5.440773963928223 Scheduler overhead time: 0.04571931343525648 Adapter cache time: 0.035822169622406363 Engine time: 0.04856677632778883 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-16/adapters_128_slots_96_rate_1.6-0.1-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-16/adapters_128_slots_96_rate_1.6-0.1-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [42 43 43]
Adapter prompts. [17280, 1080, 17280, 17280, 33, 33, 17280, 33, 1080, 1080, 1080, 33, 17280, 1080, 33, 17280, 1080, 33, 33, 33, 33, 1080, 1080, 17280, 1080, 33, 1080, 1080, 1080, 1080, 17280, 1080, 33, 1080, 33, 17280, 17280, 33, 1080, 1080, 33, 1080, 33, 1080, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 33, 1080, 17280, 17280, 1080, 33, 33, 33, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 33, 33, 1080, 33, 17280, 17280, 33, 33, 1080, 1080, 1080, 33, 17280, 33, 17280, 1080, 33, 17280, 17280, 1080, 1080, 33, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 33, 17280, 33, 33, 17280, 1080, 17280, 17280, 1080, 17280, 33, 1080, 17280, 33, 17280, 1080, 33, 1080, 1080, 17280, 17280, 33, 33, 17280, 33, 33, 33, 1080, 33]
Prompts retrieved: 790866 . Total input tokens: 176031437 . Total output tokens: 155441759
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 5.730599371017888,
    "estimated_duration": 3600.082952150885,
    "input_throughput": 5344.030472549419,
    "output_throughput": 4650.875888844867,
    "total_throughput": 9994.906361394285,
    "itl": 103.6259619885858,
    "ttft": 1841900.5485239134,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 204,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4911179242469383,
    "arrivals": 263449,
    "finished_requests": 77802,
    "scheduler_time": 81.47850309452225
}
#Debug simulation 
Total elapsed time: 5.730696304934099. Arrivals time: 0.24149195128120482 Scheduler time: 5.3237090616021305 Scheduler overhead time: 0.05003296956419945 Adapter cache time: 0.03823888651095331 Engine time: 0.05317865824326873 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-32/adapters_128_slots_96_rate_1.6-0.1-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-32/adapters_128_slots_96_rate_1.6-0.1-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [42 43 43]
Adapter prompts. [17280, 1080, 17280, 17280, 33, 33, 17280, 33, 1080, 1080, 1080, 33, 17280, 1080, 33, 17280, 1080, 33, 33, 33, 33, 1080, 1080, 17280, 1080, 33, 1080, 1080, 1080, 1080, 17280, 1080, 33, 1080, 33, 17280, 17280, 33, 1080, 1080, 33, 1080, 33, 1080, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 33, 1080, 17280, 17280, 1080, 33, 33, 33, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 33, 33, 1080, 33, 17280, 17280, 33, 33, 1080, 1080, 1080, 33, 17280, 33, 17280, 1080, 33, 17280, 17280, 1080, 1080, 33, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 33, 17280, 33, 33, 17280, 1080, 17280, 17280, 1080, 17280, 33, 1080, 17280, 33, 17280, 1080, 33, 1080, 1080, 17280, 17280, 33, 33, 17280, 33, 33, 33, 1080, 33]
Prompts retrieved: 790866 . Total input tokens: 176031437 . Total output tokens: 155441759
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 5.3458163370378315,
    "estimated_duration": 3600.079211243227,
    "input_throughput": 4901.834644328814,
    "output_throughput": 4272.797096230542,
    "total_throughput": 9174.631740559356,
    "itl": 80.632804909006,
    "ttft": 1914901.6318691983,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 196,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4718379655899505,
    "arrivals": 263449,
    "finished_requests": 71362,
    "scheduler_time": 79.80348074565357
}
#Debug simulation 
Total elapsed time: 5.345940649975091. Arrivals time: 0.2334294158499688 Scheduler time: 4.912349501624703 Scheduler overhead time: 0.061155779752880335 Adapter cache time: 0.04458258324302733 Engine time: 0.06495466595515609 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-16-16/adapters_128_slots_96_rate_1.6-0.1-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-16-16/adapters_128_slots_96_rate_1.6-0.1-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [42 43 43]
Adapter prompts. [17280, 1080, 17280, 17280, 33, 33, 17280, 33, 1080, 1080, 1080, 33, 17280, 1080, 33, 17280, 1080, 33, 33, 33, 33, 1080, 1080, 17280, 1080, 33, 1080, 1080, 1080, 1080, 17280, 1080, 33, 1080, 33, 17280, 17280, 33, 1080, 1080, 33, 1080, 33, 1080, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 33, 1080, 17280, 17280, 1080, 33, 33, 33, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 33, 33, 1080, 33, 17280, 17280, 33, 33, 1080, 1080, 1080, 33, 17280, 33, 17280, 1080, 33, 17280, 17280, 1080, 1080, 33, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 33, 17280, 33, 33, 17280, 1080, 17280, 17280, 1080, 17280, 33, 1080, 17280, 33, 17280, 1080, 33, 1080, 1080, 17280, 17280, 33, 33, 17280, 33, 33, 33, 1080, 33]
Prompts retrieved: 790866 . Total input tokens: 176031437 . Total output tokens: 155441759
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 5.725931904045865,
    "estimated_duration": 3600.044052902894,
    "input_throughput": 5344.202103439915,
    "output_throughput": 4651.047807734048,
    "total_throughput": 9995.249911173962,
    "itl": 103.62189023089178,
    "ttft": 1841816.3702660361,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 204,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3786720254085931,
    "arrivals": 263449,
    "finished_requests": 77804,
    "scheduler_time": 81.47918390066543
}
#Debug simulation 
Total elapsed time: 5.72605612501502. Arrivals time: 0.24546767864376307 Scheduler time: 5.315683813532814 Scheduler overhead time: 0.0497070848941803 Adapter cache time: 0.038261623587459326 Engine time: 0.05296053062193096 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-16-32/adapters_128_slots_96_rate_1.6-0.1-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_8-16-32/adapters_128_slots_96_rate_1.6-0.1-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [42 43 43]
Adapter prompts. [17280, 1080, 17280, 17280, 33, 33, 17280, 33, 1080, 1080, 1080, 33, 17280, 1080, 33, 17280, 1080, 33, 33, 33, 33, 1080, 1080, 17280, 1080, 33, 1080, 1080, 1080, 1080, 17280, 1080, 33, 1080, 33, 17280, 17280, 33, 1080, 1080, 33, 1080, 33, 1080, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 33, 1080, 17280, 17280, 1080, 33, 33, 33, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 33, 33, 1080, 33, 17280, 17280, 33, 33, 1080, 1080, 1080, 33, 17280, 33, 17280, 1080, 33, 17280, 17280, 1080, 1080, 33, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 33, 17280, 33, 33, 17280, 1080, 17280, 17280, 1080, 17280, 33, 1080, 17280, 33, 17280, 1080, 33, 1080, 1080, 17280, 17280, 33, 33, 17280, 33, 33, 33, 1080, 33]
Prompts retrieved: 790866 . Total input tokens: 176031437 . Total output tokens: 155441759
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 5.453777594957501,
    "estimated_duration": 3600.036037140373,
    "input_throughput": 4902.109261666781,
    "output_throughput": 4273.129724617856,
    "total_throughput": 9175.238986284638,
    "itl": 80.63251704598396,
    "ttft": 1914867.7583133786,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 196,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.456097060167233,
    "arrivals": 263449,
    "finished_requests": 71364,
    "scheduler_time": 79.80239575200208
}
#Debug simulation 
Total elapsed time: 5.453900670865551. Arrivals time: 0.2384792601224035 Scheduler time: 5.013633802300319 Scheduler overhead time: 0.0613207072019577 Adapter cache time: 0.04504580469802022 Engine time: 0.06575572188012302 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_16-16-16/adapters_128_slots_96_rate_1.6-0.1-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_16-16-16/adapters_128_slots_96_rate_1.6-0.1-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [42 43 43]
Adapter prompts. [17280, 1080, 17280, 17280, 33, 33, 17280, 33, 1080, 1080, 1080, 33, 17280, 1080, 33, 17280, 1080, 33, 33, 33, 33, 1080, 1080, 17280, 1080, 33, 1080, 1080, 1080, 1080, 17280, 1080, 33, 1080, 33, 17280, 17280, 33, 1080, 1080, 33, 1080, 33, 1080, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 33, 1080, 17280, 17280, 1080, 33, 33, 33, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 33, 33, 1080, 33, 17280, 17280, 33, 33, 1080, 1080, 1080, 33, 17280, 33, 17280, 1080, 33, 17280, 17280, 1080, 1080, 33, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 33, 17280, 33, 33, 17280, 1080, 17280, 17280, 1080, 17280, 33, 1080, 17280, 33, 17280, 1080, 33, 1080, 1080, 17280, 17280, 33, 33, 17280, 33, 33, 33, 1080, 33]
Prompts retrieved: 790866 . Total input tokens: 176031437 . Total output tokens: 155441759
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 5.7776780819986016,
    "estimated_duration": 3600.0422302589636,
    "input_throughput": 5344.272030557827,
    "output_throughput": 4651.001274169931,
    "total_throughput": 9995.273304727758,
    "itl": 103.62084725264366,
    "ttft": 1841843.14640801,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 204,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.302319871876385,
    "arrivals": 263449,
    "finished_requests": 77804,
    "scheduler_time": 81.480437781432
}
#Debug simulation 
Total elapsed time: 5.777798529015854. Arrivals time: 0.2549085000064224 Scheduler time: 5.357338677160442 Scheduler overhead time: 0.04996322887018323 Adapter cache time: 0.03845729352906346 Engine time: 0.052994262892752886 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_16-16-32/adapters_128_slots_96_rate_1.6-0.1-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.1-0.003125_size_16-16-32/adapters_128_slots_96_rate_1.6-0.1-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [42 43 43]
Adapter prompts. [17280, 1080, 17280, 17280, 33, 33, 17280, 33, 1080, 1080, 1080, 33, 17280, 1080, 33, 17280, 1080, 33, 33, 33, 33, 1080, 1080, 17280, 1080, 33, 1080, 1080, 1080, 1080, 17280, 1080, 33, 1080, 33, 17280, 17280, 33, 1080, 1080, 33, 1080, 33, 1080, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 33, 1080, 17280, 17280, 1080, 33, 33, 33, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 33, 33, 1080, 33, 17280, 17280, 33, 33, 1080, 1080, 1080, 33, 17280, 33, 17280, 1080, 33, 17280, 17280, 1080, 1080, 33, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 33, 17280, 33, 33, 17280, 1080, 17280, 17280, 1080, 17280, 33, 1080, 17280, 33, 17280, 1080, 33, 1080, 1080, 17280, 17280, 33, 33, 17280, 33, 33, 33, 1080, 33]
Prompts retrieved: 790866 . Total input tokens: 176031437 . Total output tokens: 155441759
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 5.360538246110082,
    "estimated_duration": 3600.0483110536707,
    "input_throughput": 4901.867551559341,
    "output_throughput": 4272.756827393219,
    "total_throughput": 9174.624378952562,
    "itl": 80.63336699047635,
    "ttft": 1914934.148445837,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 196,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4447056154534244,
    "arrivals": 263449,
    "finished_requests": 71361,
    "scheduler_time": 79.80310104416583
}
#Debug simulation 
Total elapsed time: 5.36063788109459. Arrivals time: 0.23373180418275297 Scheduler time: 4.925448113121092 Scheduler overhead time: 0.061612480552867055 Adapter cache time: 0.04425003263168037 Engine time: 0.06593915307894349 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-8-8/adapters_128_slots_96_rate_1.6-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-8-8/adapters_128_slots_96_rate_1.6-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [42 43 43]
Adapter prompts. [17280, 540, 17280, 17280, 270, 270, 17280, 270, 540, 540, 540, 270, 17280, 540, 270, 17280, 540, 270, 270, 270, 270, 540, 540, 17280, 540, 270, 540, 540, 540, 540, 17280, 540, 270, 540, 270, 17280, 17280, 270, 540, 540, 270, 540, 270, 540, 540, 17280, 17280, 17280, 17280, 540, 540, 270, 540, 17280, 17280, 540, 270, 270, 270, 17280, 540, 540, 540, 540, 17280, 540, 17280, 270, 270, 540, 270, 17280, 17280, 270, 270, 540, 540, 540, 270, 17280, 270, 17280, 540, 270, 17280, 17280, 540, 540, 270, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 270, 17280, 270, 270, 17280, 540, 17280, 17280, 540, 17280, 270, 540, 17280, 270, 17280, 540, 270, 540, 540, 17280, 17280, 270, 270, 17280, 270, 270, 270, 540, 270]
Prompts retrieved: 777600 . Total input tokens: 173082175 . Total output tokens: 152832153
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 5.996098447125405,
    "estimated_duration": 3600.094337299334,
    "input_throughput": 5600.616570266155,
    "output_throughput": 4852.10451821213,
    "total_throughput": 10452.721088478283,
    "itl": 112.90922800908908,
    "ttft": 1789914.4712653772,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1232,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.146487927362518,
    "arrivals": 259027,
    "finished_requests": 81446,
    "scheduler_time": 83.21257871067841
}
#Debug simulation 
Total elapsed time: 5.9961940760258585. Arrivals time: 0.25328393024392426 Scheduler time: 5.585952860536054 Scheduler overhead time: 0.046714173862710595 Adapter cache time: 0.03834468754939735 Engine time: 0.04938517254777253 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-8-16/adapters_128_slots_96_rate_1.6-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-8-16/adapters_128_slots_96_rate_1.6-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [42 43 43]
Adapter prompts. [17280, 540, 17280, 17280, 270, 270, 17280, 270, 540, 540, 540, 270, 17280, 540, 270, 17280, 540, 270, 270, 270, 270, 540, 540, 17280, 540, 270, 540, 540, 540, 540, 17280, 540, 270, 540, 270, 17280, 17280, 270, 540, 540, 270, 540, 270, 540, 540, 17280, 17280, 17280, 17280, 540, 540, 270, 540, 17280, 17280, 540, 270, 270, 270, 17280, 540, 540, 540, 540, 17280, 540, 17280, 270, 270, 540, 270, 17280, 17280, 270, 270, 540, 540, 540, 270, 17280, 270, 17280, 540, 270, 17280, 17280, 540, 540, 270, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 270, 17280, 270, 270, 17280, 540, 17280, 17280, 540, 17280, 270, 540, 17280, 270, 17280, 540, 270, 540, 540, 17280, 17280, 270, 270, 17280, 270, 270, 270, 540, 270]
Prompts retrieved: 777600 . Total input tokens: 173082175 . Total output tokens: 152832153
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 5.881943369982764,
    "estimated_duration": 3600.004290144178,
    "input_throughput": 5460.112659813739,
    "output_throughput": 4737.963520403719,
    "total_throughput": 10198.076180217458,
    "itl": 101.67642961233392,
    "ttft": 1811790.2269823384,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1199,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.769062649314282,
    "arrivals": 259027,
    "finished_requests": 79457,
    "scheduler_time": 82.86856635956455
}
#Debug simulation 
Total elapsed time: 5.882044564932585. Arrivals time: 0.27101693325676024 Scheduler time: 5.4409738392569125 Scheduler overhead time: 0.05099235149100423 Adapter cache time: 0.040278280852362514 Engine time: 0.054206982953473926 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-8-32/adapters_128_slots_96_rate_1.6-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-8-32/adapters_128_slots_96_rate_1.6-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [42 43 43]
Adapter prompts. [17280, 540, 17280, 17280, 270, 270, 17280, 270, 540, 540, 540, 270, 17280, 540, 270, 17280, 540, 270, 270, 270, 270, 540, 540, 17280, 540, 270, 540, 540, 540, 540, 17280, 540, 270, 540, 270, 17280, 17280, 270, 540, 540, 270, 540, 270, 540, 540, 17280, 17280, 17280, 17280, 540, 540, 270, 540, 17280, 17280, 540, 270, 270, 270, 17280, 540, 540, 540, 540, 17280, 540, 17280, 270, 270, 540, 270, 17280, 17280, 270, 270, 540, 540, 540, 270, 17280, 270, 17280, 540, 270, 17280, 17280, 540, 540, 270, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 270, 17280, 270, 270, 17280, 540, 17280, 17280, 540, 17280, 270, 540, 17280, 270, 17280, 540, 270, 540, 540, 17280, 17280, 270, 270, 17280, 270, 270, 270, 540, 270]
Prompts retrieved: 777600 . Total input tokens: 173082175 . Total output tokens: 152832153
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 5.467519388068467,
    "estimated_duration": 3600.0014762916585,
    "input_throughput": 5019.535997139133,
    "output_throughput": 4357.921546232437,
    "total_throughput": 9377.457543371569,
    "itl": 79.06971935971553,
    "ttft": 1887391.40513357,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1087,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.177191906278031,
    "arrivals": 259027,
    "finished_requests": 73024,
    "scheduler_time": 81.2285998479324
}
#Debug simulation 
Total elapsed time: 5.4676125170663. Arrivals time: 0.2384916136506945 Scheduler time: 5.027660117018968 Scheduler overhead time: 0.062162566697224975 Adapter cache time: 0.042962512001395226 Engine time: 0.06627746834419668 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-16-16/adapters_128_slots_96_rate_1.6-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-16-16/adapters_128_slots_96_rate_1.6-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [42 43 43]
Adapter prompts. [17280, 540, 17280, 17280, 270, 270, 17280, 270, 540, 540, 540, 270, 17280, 540, 270, 17280, 540, 270, 270, 270, 270, 540, 540, 17280, 540, 270, 540, 540, 540, 540, 17280, 540, 270, 540, 270, 17280, 17280, 270, 540, 540, 270, 540, 270, 540, 540, 17280, 17280, 17280, 17280, 540, 540, 270, 540, 17280, 17280, 540, 270, 270, 270, 17280, 540, 540, 540, 540, 17280, 540, 17280, 270, 270, 540, 270, 17280, 17280, 270, 270, 540, 540, 540, 270, 17280, 270, 17280, 540, 270, 17280, 17280, 540, 540, 270, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 270, 17280, 270, 270, 17280, 540, 17280, 17280, 540, 17280, 270, 540, 17280, 270, 17280, 540, 270, 540, 540, 17280, 17280, 270, 270, 17280, 270, 270, 270, 540, 270]
Prompts retrieved: 777600 . Total input tokens: 173082175 . Total output tokens: 152832153
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 6.104571297066286,
    "estimated_duration": 3600.0823391476297,
    "input_throughput": 5460.864543630043,
    "output_throughput": 4738.638006829331,
    "total_throughput": 10199.502550459374,
    "itl": 101.65884465024291,
    "ttft": 1811585.056432951,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1200,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.13547670155763,
    "arrivals": 259027,
    "finished_requests": 79468,
    "scheduler_time": 82.88456529240217
}
#Debug simulation 
Total elapsed time: 6.104637091979384. Arrivals time: 0.48892316967248917 Scheduler time: 5.445755784865469 Scheduler overhead time: 0.05108907469548285 Adapter cache time: 0.040521412855014205 Engine time: 0.05390863283537328 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-16-32/adapters_128_slots_96_rate_1.6-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_8-16-32/adapters_128_slots_96_rate_1.6-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [42 43 43]
Adapter prompts. [17280, 540, 17280, 17280, 270, 270, 17280, 270, 540, 540, 540, 270, 17280, 540, 270, 17280, 540, 270, 270, 270, 270, 540, 540, 17280, 540, 270, 540, 540, 540, 540, 17280, 540, 270, 540, 270, 17280, 17280, 270, 540, 540, 270, 540, 270, 540, 540, 17280, 17280, 17280, 17280, 540, 540, 270, 540, 17280, 17280, 540, 270, 270, 270, 17280, 540, 540, 540, 540, 17280, 540, 17280, 270, 270, 540, 270, 17280, 17280, 270, 270, 540, 540, 540, 270, 17280, 270, 17280, 540, 270, 17280, 17280, 540, 540, 270, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 270, 17280, 270, 270, 17280, 540, 17280, 17280, 540, 17280, 270, 540, 17280, 270, 17280, 540, 270, 540, 540, 17280, 17280, 270, 270, 17280, 270, 270, 270, 540, 270]
Prompts retrieved: 777600 . Total input tokens: 173082175 . Total output tokens: 152832153
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 5.477930977009237,
    "estimated_duration": 3600.0631527440323,
    "input_throughput": 5019.49500142139,
    "output_throughput": 4357.97910601695,
    "total_throughput": 9377.47410743834,
    "itl": 79.06640543480894,
    "ttft": 1887359.641674114,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1091,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.119555476140246,
    "arrivals": 259027,
    "finished_requests": 73027,
    "scheduler_time": 81.23177529233196
}
#Debug simulation 
Total elapsed time: 5.478053416125476. Arrivals time: 0.23960453202016652 Scheduler time: 5.035929023521021 Scheduler overhead time: 0.06262736022472382 Adapter cache time: 0.043119783978909254 Engine time: 0.06657326454296708 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_16-16-16/adapters_128_slots_96_rate_1.6-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_16-16-16/adapters_128_slots_96_rate_1.6-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [42 43 43]
Adapter prompts. [17280, 540, 17280, 17280, 270, 270, 17280, 270, 540, 540, 540, 270, 17280, 540, 270, 17280, 540, 270, 270, 270, 270, 540, 540, 17280, 540, 270, 540, 540, 540, 540, 17280, 540, 270, 540, 270, 17280, 17280, 270, 540, 540, 270, 540, 270, 540, 540, 17280, 17280, 17280, 17280, 540, 540, 270, 540, 17280, 17280, 540, 270, 270, 270, 17280, 540, 540, 540, 540, 17280, 540, 17280, 270, 270, 540, 270, 17280, 17280, 270, 270, 540, 540, 540, 270, 17280, 270, 17280, 540, 270, 17280, 17280, 540, 540, 270, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 270, 17280, 270, 270, 17280, 540, 17280, 17280, 540, 17280, 270, 540, 17280, 270, 17280, 540, 270, 540, 540, 17280, 17280, 270, 270, 17280, 270, 270, 270, 540, 270]
Prompts retrieved: 777600 . Total input tokens: 173082175 . Total output tokens: 152832153
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 5.87968789297156,
    "estimated_duration": 3600.0537092699615,
    "input_throughput": 5461.516851643615,
    "output_throughput": 4739.065407849068,
    "total_throughput": 10200.582259492683,
    "itl": 101.64495352936977,
    "ttft": 1811372.010381501,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1201,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.667089049625171,
    "arrivals": 259027,
    "finished_requests": 79474,
    "scheduler_time": 82.8938088326096
}
#Debug simulation 
Total elapsed time: 5.879784191027284. Arrivals time: 0.2513295665849 Scheduler time: 5.458286934997886 Scheduler overhead time: 0.05094591178931296 Adapter cache time: 0.040570867946371436 Engine time: 0.05420669028535485 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_16-16-32/adapters_128_slots_96_rate_1.6-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.025_size_16-16-32/adapters_128_slots_96_rate_1.6-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [42 43 43]
Adapter prompts. [17280, 540, 17280, 17280, 270, 270, 17280, 270, 540, 540, 540, 270, 17280, 540, 270, 17280, 540, 270, 270, 270, 270, 540, 540, 17280, 540, 270, 540, 540, 540, 540, 17280, 540, 270, 540, 270, 17280, 17280, 270, 540, 540, 270, 540, 270, 540, 540, 17280, 17280, 17280, 17280, 540, 540, 270, 540, 17280, 17280, 540, 270, 270, 270, 17280, 540, 540, 540, 540, 17280, 540, 17280, 270, 270, 540, 270, 17280, 17280, 270, 270, 540, 540, 540, 270, 17280, 270, 17280, 540, 270, 17280, 17280, 540, 540, 270, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 270, 17280, 270, 270, 17280, 540, 17280, 17280, 540, 17280, 270, 540, 17280, 270, 17280, 540, 270, 540, 540, 17280, 17280, 270, 270, 17280, 270, 270, 270, 540, 270]
Prompts retrieved: 777600 . Total input tokens: 173082175 . Total output tokens: 152832153
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 5.498469875194132,
    "estimated_duration": 3600.068897312268,
    "input_throughput": 5019.605878512869,
    "output_throughput": 4358.054650485518,
    "total_throughput": 9377.660528998387,
    "itl": 79.06593494675835,
    "ttft": 1887389.1503854333,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1091,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.053433227818475,
    "arrivals": 259027,
    "finished_requests": 73029,
    "scheduler_time": 81.23262730279275
}
#Debug simulation 
Total elapsed time: 5.498597074998543. Arrivals time: 0.24665996176190674 Scheduler time: 5.049719316884875 Scheduler overhead time: 0.06266473326832056 Adapter cache time: 0.04315669555217028 Engine time: 0.06632492318749428 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-8/adapters_128_slots_96_rate_1.6-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-8/adapters_128_slots_96_rate_1.6-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [42 43 43]
Adapter prompts. [17280, 540, 17280, 17280, 135, 135, 17280, 135, 540, 540, 540, 135, 17280, 540, 135, 17280, 540, 135, 135, 135, 135, 540, 540, 17280, 540, 135, 540, 540, 540, 540, 17280, 540, 135, 540, 135, 17280, 17280, 135, 540, 540, 135, 540, 135, 540, 540, 17280, 17280, 17280, 17280, 540, 540, 135, 540, 17280, 17280, 540, 135, 135, 135, 17280, 540, 540, 540, 540, 17280, 540, 17280, 135, 135, 540, 135, 17280, 17280, 135, 135, 540, 540, 540, 135, 17280, 135, 17280, 540, 135, 17280, 17280, 540, 540, 135, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 135, 17280, 135, 135, 17280, 540, 17280, 17280, 540, 17280, 135, 540, 17280, 135, 17280, 540, 135, 540, 540, 17280, 17280, 135, 135, 17280, 135, 135, 135, 540, 135]
Prompts retrieved: 771930 . Total input tokens: 171797721 . Total output tokens: 151732794
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 6.096657644025981,
    "estimated_duration": 3600.0022752148047,
    "input_throughput": 5657.271980136399,
    "output_throughput": 4938.356045605337,
    "total_throughput": 10595.628025741737,
    "itl": 110.9164675621459,
    "ttft": 1780553.1577441685,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 856,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.660222131349261,
    "arrivals": 257078,
    "finished_requests": 82291,
    "scheduler_time": 84.68833131160393
}
#Debug simulation 
Total elapsed time: 6.096770811127499. Arrivals time: 0.2669855016283691 Scheduler time: 5.673252508742735 Scheduler overhead time: 0.047666252590715885 Adapter cache time: 0.03566762758418918 Engine time: 0.0501227262429893 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-16/adapters_128_slots_96_rate_1.6-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-16/adapters_128_slots_96_rate_1.6-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [42 43 43]
Adapter prompts. [17280, 540, 17280, 17280, 135, 135, 17280, 135, 540, 540, 540, 135, 17280, 540, 135, 17280, 540, 135, 135, 135, 135, 540, 540, 17280, 540, 135, 540, 540, 540, 540, 17280, 540, 135, 540, 135, 17280, 17280, 135, 540, 540, 135, 540, 135, 540, 540, 17280, 17280, 17280, 17280, 540, 540, 135, 540, 17280, 17280, 540, 135, 135, 135, 17280, 540, 540, 540, 540, 17280, 540, 17280, 135, 135, 540, 135, 17280, 17280, 135, 135, 540, 540, 540, 135, 17280, 135, 17280, 540, 135, 17280, 17280, 540, 540, 135, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 135, 17280, 135, 135, 17280, 540, 17280, 17280, 540, 17280, 135, 540, 17280, 135, 17280, 540, 135, 540, 540, 17280, 17280, 135, 135, 17280, 135, 135, 135, 540, 135]
Prompts retrieved: 771930 . Total input tokens: 171797721 . Total output tokens: 151732794
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 5.944634426152334,
    "estimated_duration": 3600.0062373458445,
    "input_throughput": 5503.168798564712,
    "output_throughput": 4810.579720764047,
    "total_throughput": 10313.74851932876,
    "itl": 100.1191999463427,
    "ttft": 1803231.0498111995,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 837,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.111028025499553,
    "arrivals": 257078,
    "finished_requests": 80124,
    "scheduler_time": 84.14158459797063
}
#Debug simulation 
Total elapsed time: 5.944741185056046. Arrivals time: 0.2516590030863881 Scheduler time: 5.523472988046706 Scheduler overhead time: 0.051982139237225056 Adapter cache time: 0.03694723127409816 Engine time: 0.0557075587566942 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-32/adapters_128_slots_96_rate_1.6-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-32/adapters_128_slots_96_rate_1.6-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [42 43 43]
Adapter prompts. [17280, 540, 17280, 17280, 135, 135, 17280, 135, 540, 540, 540, 135, 17280, 540, 135, 17280, 540, 135, 135, 135, 135, 540, 540, 17280, 540, 135, 540, 540, 540, 540, 17280, 540, 135, 540, 135, 17280, 17280, 135, 540, 540, 135, 540, 135, 540, 540, 17280, 17280, 17280, 17280, 540, 540, 135, 540, 17280, 17280, 540, 135, 135, 135, 17280, 540, 540, 540, 540, 17280, 540, 17280, 135, 135, 540, 135, 17280, 17280, 135, 135, 540, 540, 540, 135, 17280, 135, 17280, 540, 135, 17280, 17280, 540, 540, 135, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 135, 17280, 135, 135, 17280, 540, 17280, 17280, 540, 17280, 135, 540, 17280, 135, 17280, 540, 135, 540, 540, 17280, 17280, 135, 135, 17280, 135, 135, 135, 540, 135]
Prompts retrieved: 771930 . Total input tokens: 171797721 . Total output tokens: 151732794
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 5.507688476005569,
    "estimated_duration": 3600.0507552667627,
    "input_throughput": 5030.394633605125,
    "output_throughput": 4396.2874625714085,
    "total_throughput": 9426.682096176533,
    "itl": 78.20149351056337,
    "ttft": 1880934.8658325274,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 790,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.9255554642342245,
    "arrivals": 257078,
    "finished_requests": 73168,
    "scheduler_time": 81.99892738115352
}
#Debug simulation 
Total elapsed time: 5.507783025037497. Arrivals time: 0.24287245189771056 Scheduler time: 5.064249497838318 Scheduler overhead time: 0.06307222926989198 Adapter cache time: 0.03994124918244779 Engine time: 0.06705967336893082 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-16-16/adapters_128_slots_96_rate_1.6-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-16-16/adapters_128_slots_96_rate_1.6-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [42 43 43]
Adapter prompts. [17280, 540, 17280, 17280, 135, 135, 17280, 135, 540, 540, 540, 135, 17280, 540, 135, 17280, 540, 135, 135, 135, 135, 540, 540, 17280, 540, 135, 540, 540, 540, 540, 17280, 540, 135, 540, 135, 17280, 17280, 135, 540, 540, 135, 540, 135, 540, 540, 17280, 17280, 17280, 17280, 540, 540, 135, 540, 17280, 17280, 540, 135, 135, 135, 17280, 540, 540, 540, 540, 17280, 540, 17280, 135, 135, 540, 135, 17280, 17280, 135, 135, 540, 540, 540, 135, 17280, 135, 17280, 540, 135, 17280, 17280, 540, 540, 135, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 135, 17280, 135, 135, 17280, 540, 17280, 17280, 540, 17280, 135, 540, 17280, 135, 17280, 540, 135, 540, 540, 17280, 17280, 135, 135, 17280, 135, 135, 135, 540, 135]
Prompts retrieved: 771930 . Total input tokens: 171797721 . Total output tokens: 151732794
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 5.963081623893231,
    "estimated_duration": 3600.0004734079284,
    "input_throughput": 5503.9873317691,
    "output_throughput": 4811.099089552096,
    "total_throughput": 10315.086421321195,
    "itl": 100.10633279247291,
    "ttft": 1803122.6902112362,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 837,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.702891059345556,
    "arrivals": 257078,
    "finished_requests": 80134,
    "scheduler_time": 84.14963049402711
}
#Debug simulation 
Total elapsed time: 5.963174238102511. Arrivals time: 0.24788922001607716 Scheduler time: 5.545697989407927 Scheduler overhead time: 0.051973748952150345 Adapter cache time: 0.03748561046086252 Engine time: 0.055020205676555634 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-16-32/adapters_128_slots_96_rate_1.6-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_8-16-32/adapters_128_slots_96_rate_1.6-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [42 43 43]
Adapter prompts. [17280, 540, 17280, 17280, 135, 135, 17280, 135, 540, 540, 540, 135, 17280, 540, 135, 17280, 540, 135, 135, 135, 135, 540, 540, 17280, 540, 135, 540, 540, 540, 540, 17280, 540, 135, 540, 135, 17280, 17280, 135, 540, 540, 135, 540, 135, 540, 540, 17280, 17280, 17280, 17280, 540, 540, 135, 540, 17280, 17280, 540, 135, 135, 135, 17280, 540, 540, 540, 540, 17280, 540, 17280, 135, 135, 540, 135, 17280, 17280, 135, 135, 540, 540, 540, 135, 17280, 135, 17280, 540, 135, 17280, 17280, 540, 540, 135, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 135, 17280, 135, 135, 17280, 540, 17280, 17280, 540, 17280, 135, 540, 17280, 135, 17280, 540, 135, 540, 540, 17280, 17280, 135, 135, 17280, 135, 135, 135, 540, 135]
Prompts retrieved: 771930 . Total input tokens: 171797721 . Total output tokens: 151732794
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 5.486938541056588,
    "estimated_duration": 3600.011794241073,
    "input_throughput": 5030.36268630272,
    "output_throughput": 4396.20254170206,
    "total_throughput": 9426.565228004782,
    "itl": 78.19718460952582,
    "ttft": 1880875.7371724413,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 791,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.874758390467637,
    "arrivals": 257078,
    "finished_requests": 73167,
    "scheduler_time": 82.00033605458975
}
#Debug simulation 
Total elapsed time: 5.487031406024471. Arrivals time: 0.23315431852824986 Scheduler time: 5.054072073660791 Scheduler overhead time: 0.06322820344939828 Adapter cache time: 0.03938782797195017 Engine time: 0.06679702899418771 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_16-16-16/adapters_128_slots_96_rate_1.6-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_16-16-16/adapters_128_slots_96_rate_1.6-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [42 43 43]
Adapter prompts. [17280, 540, 17280, 17280, 135, 135, 17280, 135, 540, 540, 540, 135, 17280, 540, 135, 17280, 540, 135, 135, 135, 135, 540, 540, 17280, 540, 135, 540, 540, 540, 540, 17280, 540, 135, 540, 135, 17280, 17280, 135, 540, 540, 135, 540, 135, 540, 540, 17280, 17280, 17280, 17280, 540, 540, 135, 540, 17280, 17280, 540, 135, 135, 135, 17280, 540, 540, 540, 540, 17280, 540, 17280, 135, 135, 540, 135, 17280, 17280, 135, 135, 540, 540, 540, 135, 17280, 135, 17280, 540, 135, 17280, 17280, 540, 540, 135, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 135, 17280, 135, 135, 17280, 540, 17280, 17280, 540, 17280, 135, 540, 17280, 135, 17280, 540, 135, 540, 540, 17280, 17280, 135, 135, 17280, 135, 135, 135, 540, 135]
Prompts retrieved: 771930 . Total input tokens: 171797721 . Total output tokens: 151732794
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 5.924057016847655,
    "estimated_duration": 3600.093302502994,
    "input_throughput": 5505.302039316665,
    "output_throughput": 4811.759736325776,
    "total_throughput": 10317.061775642442,
    "itl": 100.09779768322785,
    "ttft": 1803010.8638347448,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 838,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.349725748198081,
    "arrivals": 257078,
    "finished_requests": 80148,
    "scheduler_time": 84.15913668154069
}
#Debug simulation 
Total elapsed time: 5.924153366824612. Arrivals time: 0.24929694854654372 Scheduler time: 5.5068418816663325 Scheduler overhead time: 0.051728212274610996 Adapter cache time: 0.03649576031602919 Engine time: 0.054670766927301884 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_16-16-32/adapters_128_slots_96_rate_1.6-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.0125_size_16-16-32/adapters_128_slots_96_rate_1.6-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [42 43 43]
Adapter prompts. [17280, 540, 17280, 17280, 135, 135, 17280, 135, 540, 540, 540, 135, 17280, 540, 135, 17280, 540, 135, 135, 135, 135, 540, 540, 17280, 540, 135, 540, 540, 540, 540, 17280, 540, 135, 540, 135, 17280, 17280, 135, 540, 540, 135, 540, 135, 540, 540, 17280, 17280, 17280, 17280, 540, 540, 135, 540, 17280, 17280, 540, 135, 135, 135, 17280, 540, 540, 540, 540, 17280, 540, 17280, 135, 135, 540, 135, 17280, 17280, 135, 135, 540, 540, 540, 135, 17280, 135, 17280, 540, 135, 17280, 17280, 540, 540, 135, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 135, 17280, 135, 135, 17280, 540, 17280, 17280, 540, 17280, 135, 540, 17280, 135, 17280, 540, 135, 540, 540, 17280, 17280, 135, 135, 17280, 135, 135, 135, 540, 135]
Prompts retrieved: 771930 . Total input tokens: 171797721 . Total output tokens: 151732794
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 5.520061643095687,
    "estimated_duration": 3600.062899639981,
    "input_throughput": 5030.606826844918,
    "output_throughput": 4396.965953451256,
    "total_throughput": 9427.572780296174,
    "itl": 78.19642476738386,
    "ttft": 1880787.5343328123,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 789,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.810658796709054,
    "arrivals": 257078,
    "finished_requests": 73175,
    "scheduler_time": 82.00292368688172
}
#Debug simulation 
Total elapsed time: 5.520156238926575. Arrivals time: 0.23550403118133545 Scheduler time: 5.08445166843012 Scheduler overhead time: 0.063257051166147 Adapter cache time: 0.03929956490173936 Engine time: 0.06716032000258565 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-8/adapters_128_slots_96_rate_1.6-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-8/adapters_128_slots_96_rate_1.6-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [42 43 43]
Adapter prompts. [17280, 540, 17280, 17280, 66, 66, 17280, 66, 540, 540, 540, 66, 17280, 540, 66, 17280, 540, 66, 66, 66, 66, 540, 540, 17280, 540, 66, 540, 540, 540, 540, 17280, 540, 66, 540, 66, 17280, 17280, 66, 540, 540, 66, 540, 66, 540, 540, 17280, 17280, 17280, 17280, 540, 540, 66, 540, 17280, 17280, 540, 66, 66, 66, 17280, 540, 540, 540, 540, 17280, 540, 17280, 66, 66, 540, 66, 17280, 17280, 66, 66, 540, 540, 540, 66, 17280, 66, 17280, 540, 66, 17280, 17280, 540, 540, 66, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 66, 17280, 66, 66, 17280, 540, 17280, 17280, 540, 17280, 66, 540, 17280, 66, 17280, 540, 66, 540, 540, 17280, 17280, 66, 66, 17280, 66, 66, 66, 540, 66]
Prompts retrieved: 769032 . Total input tokens: 171138213 . Total output tokens: 151154399
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 6.154964133864269,
    "estimated_duration": 3600.0985247372832,
    "input_throughput": 5761.7017582911,
    "output_throughput": 5010.382598158563,
    "total_throughput": 10772.084356449663,
    "itl": 109.28109597826703,
    "ttft": 1761570.556573723,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 462,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.0549329727609025,
    "arrivals": 256097,
    "finished_requests": 83246,
    "scheduler_time": 85.89454009082164
}
#Debug simulation 
Total elapsed time: 6.155060731805861. Arrivals time: 0.2769134563859552 Scheduler time: 5.7238734441343695 Scheduler overhead time: 0.04815407935529947 Adapter cache time: 0.03217450366355479 Engine time: 0.05075411684811115 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-16/adapters_128_slots_96_rate_1.6-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-16/adapters_128_slots_96_rate_1.6-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [42 43 43]
Adapter prompts. [17280, 540, 17280, 17280, 66, 66, 17280, 66, 540, 540, 540, 66, 17280, 540, 66, 17280, 540, 66, 66, 66, 66, 540, 540, 17280, 540, 66, 540, 540, 540, 540, 17280, 540, 66, 540, 66, 17280, 17280, 66, 540, 540, 66, 540, 66, 540, 540, 17280, 17280, 17280, 17280, 540, 540, 66, 540, 17280, 17280, 540, 66, 66, 66, 17280, 540, 540, 540, 540, 17280, 540, 17280, 66, 66, 540, 66, 17280, 17280, 66, 66, 540, 540, 540, 66, 17280, 66, 17280, 540, 66, 17280, 17280, 540, 540, 66, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 66, 17280, 66, 66, 17280, 540, 17280, 17280, 540, 17280, 66, 540, 17280, 66, 17280, 540, 66, 540, 540, 17280, 17280, 66, 66, 17280, 66, 66, 66, 540, 66]
Prompts retrieved: 769032 . Total input tokens: 171138213 . Total output tokens: 151154399
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 6.02379573485814,
    "estimated_duration": 3600.023067911747,
    "input_throughput": 5602.530489255865,
    "output_throughput": 4875.437092735393,
    "total_throughput": 10477.967581991257,
    "itl": 98.66209070548341,
    "ttft": 1785313.1934906384,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 454,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.318931061932821,
    "arrivals": 256097,
    "finished_requests": 80962,
    "scheduler_time": 85.28936182870385
}
#Debug simulation 
Total elapsed time: 6.023895270889625. Arrivals time: 0.257690787082538 Scheduler time: 5.59882920444943 Scheduler overhead time: 0.0524287864100188 Adapter cache time: 0.03399548796005547 Engine time: 0.05568614648655057 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-32/adapters_128_slots_96_rate_1.6-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-32/adapters_128_slots_96_rate_1.6-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [42 43 43]
Adapter prompts. [17280, 540, 17280, 17280, 66, 66, 17280, 66, 540, 540, 540, 66, 17280, 540, 66, 17280, 540, 66, 66, 66, 66, 540, 540, 17280, 540, 66, 540, 540, 540, 540, 17280, 540, 66, 540, 66, 17280, 17280, 66, 540, 540, 66, 540, 66, 540, 540, 17280, 17280, 17280, 17280, 540, 540, 66, 540, 17280, 17280, 540, 66, 66, 66, 17280, 540, 540, 540, 540, 17280, 540, 17280, 66, 66, 540, 66, 17280, 17280, 66, 66, 540, 540, 540, 66, 17280, 66, 17280, 540, 66, 17280, 17280, 540, 540, 66, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 66, 17280, 66, 66, 17280, 540, 17280, 17280, 540, 17280, 66, 540, 17280, 66, 17280, 540, 66, 540, 540, 17280, 17280, 66, 66, 17280, 66, 66, 66, 540, 66]
Prompts retrieved: 769032 . Total input tokens: 171138213 . Total output tokens: 151154399
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 5.574567982926965,
    "estimated_duration": 3600.025355201381,
    "input_throughput": 5123.414470776204,
    "output_throughput": 4449.291718697908,
    "total_throughput": 9572.706189474113,
    "itl": 77.21236940901088,
    "ttft": 1865716.068680254,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 422,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.1637436492601623,
    "arrivals": 256097,
    "finished_requests": 73951,
    "scheduler_time": 82.95857891344987
}
#Debug simulation 
Total elapsed time: 5.574696396011859. Arrivals time: 0.24121889215894043 Scheduler time: 5.135344376089051 Scheduler overhead time: 0.06350571382790804 Adapter cache time: 0.03622193285264075 Engine time: 0.06767001166008413 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_8-16-16/adapters_128_slots_96_rate_1.6-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_8-16-16/adapters_128_slots_96_rate_1.6-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [42 43 43]
Adapter prompts. [17280, 540, 17280, 17280, 66, 66, 17280, 66, 540, 540, 540, 66, 17280, 540, 66, 17280, 540, 66, 66, 66, 66, 540, 540, 17280, 540, 66, 540, 540, 540, 540, 17280, 540, 66, 540, 66, 17280, 17280, 66, 540, 540, 66, 540, 66, 540, 540, 17280, 17280, 17280, 17280, 540, 540, 66, 540, 17280, 17280, 540, 66, 66, 66, 17280, 540, 540, 540, 540, 17280, 540, 17280, 66, 66, 540, 66, 17280, 17280, 66, 66, 540, 540, 540, 66, 17280, 66, 17280, 540, 66, 17280, 17280, 540, 540, 66, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 66, 17280, 66, 66, 17280, 540, 17280, 17280, 540, 17280, 66, 540, 17280, 66, 17280, 540, 66, 540, 540, 17280, 17280, 66, 66, 17280, 66, 66, 66, 540, 66]
Prompts retrieved: 769032 . Total input tokens: 171138213 . Total output tokens: 151154399
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 6.017973305890337,
    "estimated_duration": 3600.0669788254563,
    "input_throughput": 5602.938256049029,
    "output_throughput": 4875.753729928321,
    "total_throughput": 10478.69198597735,
    "itl": 98.65726647770762,
    "ttft": 1785238.5563774707,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 453,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.0723849126091167,
    "arrivals": 256097,
    "finished_requests": 80967,
    "scheduler_time": 85.29696172007269
}
#Debug simulation 
Total elapsed time: 6.018095283070579. Arrivals time: 0.2718542346265167 Scheduler time: 5.578662040410563 Scheduler overhead time: 0.052532744593918324 Adapter cache time: 0.03402867494150996 Engine time: 0.05579039710573852 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_8-16-32/adapters_128_slots_96_rate_1.6-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_8-16-32/adapters_128_slots_96_rate_1.6-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [42 43 43]
Adapter prompts. [17280, 540, 17280, 17280, 66, 66, 17280, 66, 540, 540, 540, 66, 17280, 540, 66, 17280, 540, 66, 66, 66, 66, 540, 540, 17280, 540, 66, 540, 540, 540, 540, 17280, 540, 66, 540, 66, 17280, 17280, 66, 540, 540, 66, 540, 66, 540, 540, 17280, 17280, 17280, 17280, 540, 540, 66, 540, 17280, 17280, 540, 66, 66, 66, 17280, 540, 540, 540, 540, 17280, 540, 17280, 66, 66, 540, 66, 17280, 17280, 66, 66, 540, 540, 540, 66, 17280, 66, 17280, 540, 66, 17280, 17280, 540, 540, 66, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 66, 17280, 66, 66, 17280, 540, 17280, 17280, 540, 17280, 66, 540, 17280, 66, 17280, 540, 66, 540, 540, 17280, 17280, 66, 66, 17280, 66, 66, 66, 540, 66]
Prompts retrieved: 769032 . Total input tokens: 171138213 . Total output tokens: 151154399
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 5.603921373840421,
    "estimated_duration": 3600.056533898622,
    "input_throughput": 5123.485097059148,
    "output_throughput": 4449.347072517686,
    "total_throughput": 9572.832169576834,
    "itl": 77.21255030844766,
    "ttft": 1865707.2689108,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 421,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.124444751199356,
    "arrivals": 256097,
    "finished_requests": 73952,
    "scheduler_time": 82.9608995445998
}
#Debug simulation 
Total elapsed time: 5.604028620989993. Arrivals time: 0.24664781778119504 Scheduler time: 5.158135863021016 Scheduler overhead time: 0.06393133220262825 Adapter cache time: 0.03631610330194235 Engine time: 0.0681879110634327 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_16-16-16/adapters_128_slots_96_rate_1.6-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_16-16-16/adapters_128_slots_96_rate_1.6-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [42 43 43]
Adapter prompts. [17280, 540, 17280, 17280, 66, 66, 17280, 66, 540, 540, 540, 66, 17280, 540, 66, 17280, 540, 66, 66, 66, 66, 540, 540, 17280, 540, 66, 540, 540, 540, 540, 17280, 540, 66, 540, 66, 17280, 17280, 66, 540, 540, 66, 540, 66, 540, 540, 17280, 17280, 17280, 17280, 540, 540, 66, 540, 17280, 17280, 540, 66, 66, 66, 17280, 540, 540, 540, 540, 17280, 540, 17280, 66, 66, 540, 66, 17280, 17280, 66, 66, 540, 540, 540, 66, 17280, 66, 17280, 540, 66, 17280, 17280, 540, 540, 66, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 66, 17280, 66, 66, 17280, 540, 17280, 17280, 540, 17280, 66, 540, 17280, 66, 17280, 540, 66, 540, 540, 17280, 17280, 66, 66, 17280, 66, 66, 66, 540, 66]
Prompts retrieved: 769032 . Total input tokens: 171138213 . Total output tokens: 151154399
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 6.001531142974272,
    "estimated_duration": 3600.05051746268,
    "input_throughput": 5603.590533562318,
    "output_throughput": 4876.377960488435,
    "total_throughput": 10479.968494050754,
    "itl": 98.64897827911489,
    "ttft": 1785291.2031096406,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 452,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.8855322651378685,
    "arrivals": 256097,
    "finished_requests": 80977,
    "scheduler_time": 85.29904456573544
}
#Debug simulation 
Total elapsed time: 6.00163952098228. Arrivals time: 0.2608233590144664 Scheduler time: 5.57391620031558 Scheduler overhead time: 0.05230063037015498 Adapter cache time: 0.03395438124425709 Engine time: 0.05537962703965604 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_16-16-32/adapters_128_slots_96_rate_1.6-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.00625_size_16-16-32/adapters_128_slots_96_rate_1.6-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [42 43 43]
Adapter prompts. [17280, 540, 17280, 17280, 66, 66, 17280, 66, 540, 540, 540, 66, 17280, 540, 66, 17280, 540, 66, 66, 66, 66, 540, 540, 17280, 540, 66, 540, 540, 540, 540, 17280, 540, 66, 540, 66, 17280, 17280, 66, 540, 540, 66, 540, 66, 540, 540, 17280, 17280, 17280, 17280, 540, 540, 66, 540, 17280, 17280, 540, 66, 66, 66, 17280, 540, 540, 540, 540, 17280, 540, 17280, 66, 66, 540, 66, 17280, 17280, 66, 66, 540, 540, 540, 66, 17280, 66, 17280, 540, 66, 17280, 17280, 540, 540, 66, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 66, 17280, 66, 66, 17280, 540, 17280, 17280, 540, 17280, 66, 540, 17280, 66, 17280, 540, 66, 540, 540, 17280, 17280, 66, 66, 17280, 66, 66, 66, 540, 66]
Prompts retrieved: 769032 . Total input tokens: 171138213 . Total output tokens: 151154399
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 5.574807162862271,
    "estimated_duration": 3600.0463995638793,
    "input_throughput": 5123.56757463862,
    "output_throughput": 4449.463207457688,
    "total_throughput": 9573.030782096308,
    "itl": 77.21318107216682,
    "ttft": 1865711.945111346,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 422,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.1074596462026447,
    "arrivals": 256097,
    "finished_requests": 73953,
    "scheduler_time": 82.96090156420446
}
#Debug simulation 
Total elapsed time: 5.574914286844432. Arrivals time: 0.24340202240273356 Scheduler time: 5.133081335341558 Scheduler overhead time: 0.0636007683351636 Adapter cache time: 0.03648910718038678 Engine time: 0.06762831006199121 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-8/adapters_128_slots_96_rate_1.6-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-8/adapters_128_slots_96_rate_1.6-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [42 43 43]
Adapter prompts. [17280, 540, 17280, 17280, 33, 33, 17280, 33, 540, 540, 540, 33, 17280, 540, 33, 17280, 540, 33, 33, 33, 33, 540, 540, 17280, 540, 33, 540, 540, 540, 540, 17280, 540, 33, 540, 33, 17280, 17280, 33, 540, 540, 33, 540, 33, 540, 540, 17280, 17280, 17280, 17280, 540, 540, 33, 540, 17280, 17280, 540, 33, 33, 33, 17280, 540, 540, 540, 540, 17280, 540, 17280, 33, 33, 540, 33, 17280, 17280, 33, 33, 540, 540, 540, 33, 17280, 33, 17280, 540, 33, 17280, 17280, 540, 540, 33, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 33, 17280, 33, 33, 17280, 540, 17280, 17280, 540, 17280, 33, 540, 17280, 33, 17280, 540, 33, 540, 540, 17280, 17280, 33, 33, 17280, 33, 33, 33, 540, 33]
Prompts retrieved: 767646 . Total input tokens: 170820333 . Total output tokens: 150885841
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 6.173960617976263,
    "estimated_duration": 3600.02099677709,
    "input_throughput": 5778.028800004796,
    "output_throughput": 5055.104683081611,
    "total_throughput": 10833.133483086407,
    "itl": 108.83442981916947,
    "ttft": 1749798.1147124285,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 232,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5340788954123836,
    "arrivals": 255593,
    "finished_requests": 84316,
    "scheduler_time": 86.64106657405873
}
#Debug simulation 
Total elapsed time: 6.1740682339295745. Arrivals time: 0.2659476639237255 Scheduler time: 5.755591039778665 Scheduler overhead time: 0.04823318519629538 Adapter cache time: 0.029293547617271543 Engine time: 0.051786672323942184 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-16/adapters_128_slots_96_rate_1.6-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-16/adapters_128_slots_96_rate_1.6-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [42 43 43]
Adapter prompts. [17280, 540, 17280, 17280, 33, 33, 17280, 33, 540, 540, 540, 33, 17280, 540, 33, 17280, 540, 33, 33, 33, 33, 540, 540, 17280, 540, 33, 540, 540, 540, 540, 17280, 540, 33, 540, 33, 17280, 17280, 33, 540, 540, 33, 540, 33, 540, 540, 17280, 17280, 17280, 17280, 540, 540, 33, 540, 17280, 17280, 540, 33, 33, 33, 17280, 540, 540, 540, 540, 17280, 540, 17280, 33, 33, 540, 33, 17280, 17280, 33, 33, 540, 540, 540, 33, 17280, 33, 17280, 540, 33, 17280, 17280, 540, 540, 33, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 33, 17280, 33, 33, 17280, 540, 17280, 17280, 540, 17280, 33, 540, 17280, 33, 17280, 540, 33, 540, 540, 17280, 17280, 33, 33, 17280, 33, 33, 33, 540, 33]
Prompts retrieved: 767646 . Total input tokens: 170820333 . Total output tokens: 150885841
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 6.063684233929962,
    "estimated_duration": 3600.087215283083,
    "input_throughput": 5613.524559685121,
    "output_throughput": 4916.655053482691,
    "total_throughput": 10530.179613167811,
    "itl": 98.4696567596665,
    "ttft": 1774694.4676178321,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 226,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6440581736993058,
    "arrivals": 255593,
    "finished_requests": 81965,
    "scheduler_time": 85.9179925577157
}
#Debug simulation 
Total elapsed time: 6.063778921961784. Arrivals time: 0.25233373418450356 Scheduler time: 5.647251869784668 Scheduler overhead time: 0.05236895359121263 Adapter cache time: 0.030943676363676786 Engine time: 0.055628988426178694 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-32/adapters_128_slots_96_rate_1.6-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-32/adapters_128_slots_96_rate_1.6-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [42 43 43]
Adapter prompts. [17280, 540, 17280, 17280, 33, 33, 17280, 33, 540, 540, 540, 33, 17280, 540, 33, 17280, 540, 33, 33, 33, 33, 540, 540, 17280, 540, 33, 540, 540, 540, 540, 17280, 540, 33, 540, 33, 17280, 17280, 33, 540, 540, 33, 540, 33, 540, 540, 17280, 17280, 17280, 17280, 540, 540, 33, 540, 17280, 17280, 540, 33, 33, 33, 17280, 540, 540, 540, 540, 17280, 540, 17280, 33, 33, 540, 33, 17280, 17280, 33, 33, 540, 540, 540, 33, 17280, 33, 17280, 540, 33, 17280, 17280, 540, 540, 33, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 33, 17280, 33, 33, 17280, 540, 17280, 17280, 540, 17280, 33, 540, 17280, 33, 17280, 540, 33, 540, 540, 17280, 17280, 33, 33, 17280, 33, 33, 33, 540, 33]
Prompts retrieved: 767646 . Total input tokens: 170820333 . Total output tokens: 150885841
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 5.5620436440221965,
    "estimated_duration": 3600.0523467448056,
    "input_throughput": 5104.333556876082,
    "output_throughput": 4477.3607290945865,
    "total_throughput": 9581.694285970669,
    "itl": 77.10343317817251,
    "ttft": 1854797.908515929,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 206,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.537219441775235,
    "arrivals": 255593,
    "finished_requests": 74550,
    "scheduler_time": 83.3995973973336
}
#Debug simulation 
Total elapsed time: 5.562133521074429. Arrivals time: 0.23800011374987662 Scheduler time: 5.129090452333912 Scheduler overhead time: 0.0636820956133306 Adapter cache time: 0.033099066000431776 Engine time: 0.06765151442959905 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_8-16-16/adapters_128_slots_96_rate_1.6-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_8-16-16/adapters_128_slots_96_rate_1.6-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [42 43 43]
Adapter prompts. [17280, 540, 17280, 17280, 33, 33, 17280, 33, 540, 540, 540, 33, 17280, 540, 33, 17280, 540, 33, 33, 33, 33, 540, 540, 17280, 540, 33, 540, 540, 540, 540, 17280, 540, 33, 540, 33, 17280, 17280, 33, 540, 540, 33, 540, 33, 540, 540, 17280, 17280, 17280, 17280, 540, 540, 33, 540, 17280, 17280, 540, 33, 33, 33, 17280, 540, 540, 540, 540, 17280, 540, 17280, 33, 33, 540, 33, 17280, 17280, 33, 33, 540, 540, 540, 33, 17280, 33, 17280, 540, 33, 17280, 17280, 540, 540, 33, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 33, 17280, 33, 33, 17280, 540, 17280, 17280, 540, 17280, 33, 540, 17280, 33, 17280, 540, 33, 540, 540, 17280, 17280, 33, 33, 17280, 33, 33, 33, 540, 33]
Prompts retrieved: 767646 . Total input tokens: 170820333 . Total output tokens: 150885841
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 6.034959567012265,
    "estimated_duration": 3600.034754940871,
    "input_throughput": 5613.983579536844,
    "output_throughput": 4917.175862178794,
    "total_throughput": 10531.15944171564,
    "itl": 98.46360583250657,
    "ttft": 1774730.6649904202,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 226,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5274476119410216,
    "arrivals": 255593,
    "finished_requests": 81969,
    "scheduler_time": 85.91862432242803
}
#Debug simulation 
Total elapsed time: 6.035053147003055. Arrivals time: 0.2559563755057752 Scheduler time: 5.615353754488751 Scheduler overhead time: 0.05247020907700062 Adapter cache time: 0.03059559315443039 Engine time: 0.05552703025750816 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_8-16-32/adapters_128_slots_96_rate_1.6-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_8-16-32/adapters_128_slots_96_rate_1.6-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [42 43 43]
Adapter prompts. [17280, 540, 17280, 17280, 33, 33, 17280, 33, 540, 540, 540, 33, 17280, 540, 33, 17280, 540, 33, 33, 33, 33, 540, 540, 17280, 540, 33, 540, 540, 540, 540, 17280, 540, 33, 540, 33, 17280, 17280, 33, 540, 540, 33, 540, 33, 540, 540, 17280, 17280, 17280, 17280, 540, 540, 33, 540, 17280, 17280, 540, 33, 33, 33, 17280, 540, 540, 540, 540, 17280, 540, 17280, 33, 33, 540, 33, 17280, 17280, 33, 33, 540, 540, 540, 33, 17280, 33, 17280, 540, 33, 17280, 17280, 540, 540, 33, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 33, 17280, 33, 33, 17280, 540, 17280, 17280, 540, 17280, 33, 540, 17280, 33, 17280, 540, 33, 540, 540, 17280, 17280, 33, 33, 17280, 33, 33, 33, 540, 33]
Prompts retrieved: 767646 . Total input tokens: 170820333 . Total output tokens: 150885841
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 5.60231949808076,
    "estimated_duration": 3600.0017783107164,
    "input_throughput": 5104.843311667342,
    "output_throughput": 4477.865565823244,
    "total_throughput": 9582.708877490586,
    "itl": 77.13401329302836,
    "ttft": 1854689.4518382538,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 206,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5218927707057468,
    "arrivals": 255593,
    "finished_requests": 74556,
    "scheduler_time": 83.40194606097722
}
#Debug simulation 
Total elapsed time: 5.602411261992529. Arrivals time: 0.24307261547073722 Scheduler time: 5.163025178480893 Scheduler overhead time: 0.06386187975294888 Adapter cache time: 0.03397841192781925 Engine time: 0.06767116510309279 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_16-16-16/adapters_128_slots_96_rate_1.6-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_16-16-16/adapters_128_slots_96_rate_1.6-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [42 43 43]
Adapter prompts. [17280, 540, 17280, 17280, 33, 33, 17280, 33, 540, 540, 540, 33, 17280, 540, 33, 17280, 540, 33, 33, 33, 33, 540, 540, 17280, 540, 33, 540, 540, 540, 540, 17280, 540, 33, 540, 33, 17280, 17280, 33, 540, 540, 33, 540, 33, 540, 540, 17280, 17280, 17280, 17280, 540, 540, 33, 540, 17280, 17280, 540, 33, 33, 33, 17280, 540, 540, 540, 540, 17280, 540, 17280, 33, 33, 540, 33, 17280, 17280, 33, 33, 540, 540, 540, 33, 17280, 33, 17280, 540, 33, 17280, 17280, 540, 540, 33, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 33, 17280, 33, 33, 17280, 540, 17280, 17280, 540, 17280, 33, 540, 17280, 33, 17280, 540, 33, 540, 540, 17280, 17280, 33, 33, 17280, 33, 33, 33, 540, 33]
Prompts retrieved: 767646 . Total input tokens: 170820333 . Total output tokens: 150885841
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 5.9831380972173065,
    "estimated_duration": 3600.066502174105,
    "input_throughput": 5585.180714816582,
    "output_throughput": 4894.163202085177,
    "total_throughput": 10479.343916901758,
    "itl": 98.71290027722027,
    "ttft": 1778326.5813270933,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 226,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.442766132568936,
    "arrivals": 255593,
    "finished_requests": 81579,
    "scheduler_time": 85.5425030870469
}
#Debug simulation 
Total elapsed time: 5.983230964047834. Arrivals time: 0.25121301668696105 Scheduler time: 5.569277110043913 Scheduler overhead time: 0.05213868455030024 Adapter cache time: 0.030050910310819745 Engine time: 0.05539858224801719 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_16-16-32/adapters_128_slots_96_rate_1.6-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.05-0.003125_size_16-16-32/adapters_128_slots_96_rate_1.6-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [42 43 43]
Adapter prompts. [17280, 540, 17280, 17280, 33, 33, 17280, 33, 540, 540, 540, 33, 17280, 540, 33, 17280, 540, 33, 33, 33, 33, 540, 540, 17280, 540, 33, 540, 540, 540, 540, 17280, 540, 33, 540, 33, 17280, 17280, 33, 540, 540, 33, 540, 33, 540, 540, 17280, 17280, 17280, 17280, 540, 540, 33, 540, 17280, 17280, 540, 33, 33, 33, 17280, 540, 540, 540, 540, 17280, 540, 17280, 33, 33, 540, 33, 17280, 17280, 33, 33, 540, 540, 540, 33, 17280, 33, 17280, 540, 33, 17280, 17280, 540, 540, 33, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 33, 17280, 33, 33, 17280, 540, 17280, 17280, 540, 17280, 33, 540, 17280, 33, 17280, 540, 33, 540, 540, 17280, 17280, 33, 33, 17280, 33, 33, 33, 540, 33]
Prompts retrieved: 767646 . Total input tokens: 170820333 . Total output tokens: 150885841
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 5.584131942829117,
    "estimated_duration": 3600.0698278286022,
    "input_throughput": 5103.509898051547,
    "output_throughput": 4476.217898728828,
    "total_throughput": 9579.727796780375,
    "itl": 77.07437090107801,
    "ttft": 1854649.1996736694,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 206,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.509879974462094,
    "arrivals": 255593,
    "finished_requests": 74536,
    "scheduler_time": 83.3958790316282
}
#Debug simulation 
Total elapsed time: 5.584248669911176. Arrivals time: 0.24027780443429947 Scheduler time: 5.14732081326656 Scheduler overhead time: 0.06365604256279767 Adapter cache time: 0.033745154505595565 Engine time: 0.06846391153521836 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-8/adapters_128_slots_96_rate_1.6-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-8/adapters_128_slots_96_rate_1.6-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [42 43 43]
Adapter prompts. [17280, 270, 17280, 17280, 135, 135, 17280, 135, 270, 270, 270, 135, 17280, 270, 135, 17280, 270, 135, 135, 135, 135, 270, 270, 17280, 270, 135, 270, 270, 270, 270, 17280, 270, 135, 270, 135, 17280, 17280, 135, 270, 270, 135, 270, 135, 270, 270, 17280, 17280, 17280, 17280, 270, 270, 135, 270, 17280, 17280, 270, 135, 135, 135, 17280, 270, 270, 270, 270, 17280, 270, 17280, 135, 135, 270, 135, 17280, 17280, 135, 135, 270, 270, 270, 135, 17280, 135, 17280, 270, 135, 17280, 17280, 270, 270, 135, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 135, 17280, 135, 135, 17280, 270, 17280, 17280, 270, 17280, 135, 270, 17280, 135, 17280, 270, 135, 270, 270, 17280, 17280, 135, 135, 17280, 135, 135, 135, 270, 135]
Prompts retrieved: 760320 . Total input tokens: 169197739 . Total output tokens: 149442647
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 6.300888215191662,
    "estimated_duration": 3600.097374938018,
    "input_throughput": 5921.467054864599,
    "output_throughput": 5156.035536488671,
    "total_throughput": 11077.50259135327,
    "itl": 106.33743884659324,
    "ttft": 1722302.7864550333,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 700,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.628686322365038,
    "arrivals": 253064,
    "finished_requests": 86380,
    "scheduler_time": 88.29076521909202
}
#Debug simulation 
Total elapsed time: 6.301009721122682. Arrivals time: 0.25834553502500057 Scheduler time: 5.889364900300279 Scheduler overhead time: 0.04936005058698356 Adapter cache time: 0.02791871689260006 Engine time: 0.052310757571831346 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-16/adapters_128_slots_96_rate_1.6-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-16/adapters_128_slots_96_rate_1.6-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [42 43 43]
Adapter prompts. [17280, 270, 17280, 17280, 135, 135, 17280, 135, 270, 270, 270, 135, 17280, 270, 135, 17280, 270, 135, 135, 135, 135, 270, 270, 17280, 270, 135, 270, 270, 270, 270, 17280, 270, 135, 270, 135, 17280, 17280, 135, 270, 270, 135, 270, 135, 270, 270, 17280, 17280, 17280, 17280, 270, 270, 135, 270, 17280, 17280, 270, 135, 135, 135, 17280, 270, 270, 270, 270, 17280, 270, 17280, 135, 135, 270, 135, 17280, 17280, 135, 135, 270, 270, 270, 135, 17280, 135, 17280, 270, 135, 17280, 17280, 270, 270, 135, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 135, 17280, 135, 135, 17280, 270, 17280, 17280, 270, 17280, 135, 270, 17280, 135, 17280, 270, 135, 270, 270, 17280, 17280, 135, 135, 17280, 135, 135, 135, 270, 135]
Prompts retrieved: 760320 . Total input tokens: 169197739 . Total output tokens: 149442647
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 6.172275830991566,
    "estimated_duration": 3600.030401632196,
    "input_throughput": 5742.292340261197,
    "output_throughput": 5009.0996431097265,
    "total_throughput": 10751.391983370924,
    "itl": 96.312338294917,
    "ttft": 1748872.5319851083,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 682,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.982698182379833,
    "arrivals": 253064,
    "finished_requests": 83887,
    "scheduler_time": 87.48641424443181
}
#Debug simulation 
Total elapsed time: 6.172408284852281. Arrivals time: 0.26169912330806255 Scheduler time: 5.746251139324158 Scheduler overhead time: 0.053628004854545 Adapter cache time: 0.028484645066782832 Engine time: 0.05651332484558225 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-32/adapters_128_slots_96_rate_1.6-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-32/adapters_128_slots_96_rate_1.6-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [42 43 43]
Adapter prompts. [17280, 270, 17280, 17280, 135, 135, 17280, 135, 270, 270, 270, 135, 17280, 270, 135, 17280, 270, 135, 135, 135, 135, 270, 270, 17280, 270, 135, 270, 270, 270, 270, 17280, 270, 135, 270, 135, 17280, 17280, 135, 270, 270, 135, 270, 135, 270, 270, 17280, 17280, 17280, 17280, 270, 270, 135, 270, 17280, 17280, 270, 135, 135, 135, 17280, 270, 270, 270, 270, 17280, 270, 17280, 135, 135, 270, 135, 17280, 17280, 135, 135, 270, 270, 270, 135, 17280, 135, 17280, 270, 135, 17280, 17280, 270, 270, 135, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 135, 17280, 135, 135, 17280, 270, 17280, 17280, 270, 17280, 135, 270, 17280, 135, 17280, 270, 135, 270, 270, 17280, 17280, 135, 135, 17280, 135, 135, 135, 270, 135]
Prompts retrieved: 760320 . Total input tokens: 169197739 . Total output tokens: 149442647
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 5.675119305960834,
    "estimated_duration": 3600.0336855236483,
    "input_throughput": 5204.392968693772,
    "output_throughput": 4547.50994854058,
    "total_throughput": 9751.90291723435,
    "itl": 75.8757203620989,
    "ttft": 1833441.489688312,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 626,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.695063782655664,
    "arrivals": 253064,
    "finished_requests": 76126,
    "scheduler_time": 84.61790525311169
}
#Debug simulation 
Total elapsed time: 5.675241700140759. Arrivals time: 0.26088812737725675 Scheduler time: 5.2187913176603615 Scheduler overhead time: 0.06472709658555686 Adapter cache time: 0.030469339340925217 Engine time: 0.06890688324347138 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-16-16/adapters_128_slots_96_rate_1.6-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-16-16/adapters_128_slots_96_rate_1.6-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [42 43 43]
Adapter prompts. [17280, 270, 17280, 17280, 135, 135, 17280, 135, 270, 270, 270, 135, 17280, 270, 135, 17280, 270, 135, 135, 135, 135, 270, 270, 17280, 270, 135, 270, 270, 270, 270, 17280, 270, 135, 270, 135, 17280, 17280, 135, 270, 270, 135, 270, 135, 270, 270, 17280, 17280, 17280, 17280, 270, 270, 135, 270, 17280, 17280, 270, 135, 135, 135, 17280, 270, 270, 270, 270, 17280, 270, 17280, 135, 135, 270, 135, 17280, 17280, 135, 135, 270, 270, 270, 135, 17280, 135, 17280, 270, 135, 17280, 17280, 270, 270, 135, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 135, 17280, 135, 135, 17280, 270, 17280, 17280, 270, 17280, 135, 270, 17280, 135, 17280, 270, 135, 270, 270, 17280, 17280, 135, 135, 17280, 135, 135, 135, 270, 135]
Prompts retrieved: 760320 . Total input tokens: 169197739 . Total output tokens: 149442647
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 6.217004933860153,
    "estimated_duration": 3600.083954492252,
    "input_throughput": 5742.774407858464,
    "output_throughput": 5009.688726146293,
    "total_throughput": 10752.463134004758,
    "itl": 96.30580478950242,
    "ttft": 1748663.0136422885,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 683,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.636473976098923,
    "arrivals": 253064,
    "finished_requests": 83897,
    "scheduler_time": 87.49583208080698
}
#Debug simulation 
Total elapsed time: 6.217116344952956. Arrivals time: 0.28661209740675986 Scheduler time: 5.763918510871008 Scheduler overhead time: 0.05365236266516149 Adapter cache time: 0.02844562754034996 Engine time: 0.0567289877217263 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-16-32/adapters_128_slots_96_rate_1.6-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_8-16-32/adapters_128_slots_96_rate_1.6-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [42 43 43]
Adapter prompts. [17280, 270, 17280, 17280, 135, 135, 17280, 135, 270, 270, 270, 135, 17280, 270, 135, 17280, 270, 135, 135, 135, 135, 270, 270, 17280, 270, 135, 270, 270, 270, 270, 17280, 270, 135, 270, 135, 17280, 17280, 135, 270, 270, 135, 270, 135, 270, 270, 17280, 17280, 17280, 17280, 270, 270, 135, 270, 17280, 17280, 270, 135, 135, 135, 17280, 270, 270, 270, 270, 17280, 270, 17280, 135, 135, 270, 135, 17280, 17280, 135, 135, 270, 270, 270, 135, 17280, 135, 17280, 270, 135, 17280, 17280, 270, 270, 135, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 135, 17280, 135, 135, 17280, 270, 17280, 17280, 270, 17280, 135, 270, 17280, 135, 17280, 270, 135, 270, 270, 17280, 17280, 135, 135, 17280, 135, 135, 135, 270, 135]
Prompts retrieved: 760320 . Total input tokens: 169197739 . Total output tokens: 149442647
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 5.665430827066302,
    "estimated_duration": 3600.0577108968964,
    "input_throughput": 5204.3807362555335,
    "output_throughput": 4547.319880580893,
    "total_throughput": 9751.700616836428,
    "itl": 75.873514846311,
    "ttft": 1833451.5343483253,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 625,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.638315172777543,
    "arrivals": 253064,
    "finished_requests": 76128,
    "scheduler_time": 84.61904510267514
}
#Debug simulation 
Total elapsed time: 5.665524293901399. Arrivals time: 0.24253315711393952 Scheduler time: 5.227916297037154 Scheduler overhead time: 0.064559725811705 Adapter cache time: 0.030496544670313597 Engine time: 0.068810771452263 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_16-16-16/adapters_128_slots_96_rate_1.6-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_16-16-16/adapters_128_slots_96_rate_1.6-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [42 43 43]
Adapter prompts. [17280, 270, 17280, 17280, 135, 135, 17280, 135, 270, 270, 270, 135, 17280, 270, 135, 17280, 270, 135, 135, 135, 135, 270, 270, 17280, 270, 135, 270, 270, 270, 270, 17280, 270, 135, 270, 135, 17280, 17280, 135, 270, 270, 135, 270, 135, 270, 270, 17280, 17280, 17280, 17280, 270, 270, 135, 270, 17280, 17280, 270, 135, 135, 135, 17280, 270, 270, 270, 270, 17280, 270, 17280, 135, 135, 270, 135, 17280, 17280, 135, 135, 270, 270, 270, 135, 17280, 135, 17280, 270, 135, 17280, 17280, 270, 270, 135, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 135, 17280, 135, 135, 17280, 270, 17280, 17280, 270, 17280, 135, 270, 17280, 135, 17280, 270, 135, 270, 270, 17280, 17280, 135, 135, 17280, 135, 135, 135, 270, 135]
Prompts retrieved: 760320 . Total input tokens: 169197739 . Total output tokens: 149442647
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 6.183053346117958,
    "estimated_duration": 3600.080428743481,
    "input_throughput": 5743.520015528331,
    "output_throughput": 5010.268341781324,
    "total_throughput": 10753.788357309655,
    "itl": 96.29832316666123,
    "ttft": 1748661.160088679,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 682,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.353834081469083,
    "arrivals": 253064,
    "finished_requests": 83904,
    "scheduler_time": 87.50157814258489
}
#Debug simulation 
Total elapsed time: 6.183146208990365. Arrivals time: 0.2593017944600433 Scheduler time: 5.758287055650726 Scheduler overhead time: 0.05373617960140109 Adapter cache time: 0.028631569584831595 Engine time: 0.05731995031237602 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_16-16-32/adapters_128_slots_96_rate_1.6-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.0125_size_16-16-32/adapters_128_slots_96_rate_1.6-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [42 43 43]
Adapter prompts. [17280, 270, 17280, 17280, 135, 135, 17280, 135, 270, 270, 270, 135, 17280, 270, 135, 17280, 270, 135, 135, 135, 135, 270, 270, 17280, 270, 135, 270, 270, 270, 270, 17280, 270, 135, 270, 135, 17280, 17280, 135, 270, 270, 135, 270, 135, 270, 270, 17280, 17280, 17280, 17280, 270, 270, 135, 270, 17280, 17280, 270, 135, 135, 135, 17280, 270, 270, 270, 270, 17280, 270, 17280, 135, 135, 270, 135, 17280, 17280, 135, 135, 270, 270, 270, 135, 17280, 135, 17280, 270, 135, 17280, 17280, 270, 270, 135, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 135, 17280, 135, 135, 17280, 270, 17280, 17280, 270, 17280, 135, 270, 17280, 135, 17280, 270, 135, 270, 270, 17280, 17280, 135, 135, 17280, 135, 135, 135, 270, 135]
Prompts retrieved: 760320 . Total input tokens: 169197739 . Total output tokens: 149442647
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 5.6840066879522055,
    "estimated_duration": 3600.0745169525044,
    "input_throughput": 5204.318663898141,
    "output_throughput": 4547.383095241631,
    "total_throughput": 9751.70175913977,
    "itl": 75.87153827311931,
    "ttft": 1833533.1650437,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 625,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.601241198163512,
    "arrivals": 253064,
    "finished_requests": 76128,
    "scheduler_time": 84.62068658289891
}
#Debug simulation 
Total elapsed time: 5.684108240995556. Arrivals time: 0.24106486840173602 Scheduler time: 5.247368253301829 Scheduler overhead time: 0.06472611031495035 Adapter cache time: 0.03039107727818191 Engine time: 0.06906191888265312 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-8/adapters_128_slots_96_rate_1.6-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 268384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-8/adapters_128_slots_96_rate_1.6-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [42 43 43]
Adapter prompts. [17280, 270, 17280, 17280, 66, 66, 17280, 66, 270, 270, 270, 66, 17280, 270, 66, 17280, 270, 66, 66, 66, 66, 270, 270, 17280, 270, 66, 270, 270, 270, 270, 17280, 270, 66, 270, 66, 17280, 17280, 66, 270, 270, 66, 270, 66, 270, 270, 17280, 17280, 17280, 17280, 270, 270, 66, 270, 17280, 17280, 270, 66, 66, 66, 17280, 270, 270, 270, 270, 17280, 270, 17280, 66, 66, 270, 66, 17280, 17280, 66, 66, 270, 270, 270, 66, 17280, 66, 17280, 270, 66, 17280, 17280, 270, 270, 66, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 66, 17280, 66, 66, 17280, 270, 17280, 17280, 270, 17280, 66, 270, 17280, 66, 17280, 270, 66, 270, 270, 17280, 17280, 66, 66, 17280, 66, 66, 66, 270, 66]
Prompts retrieved: 757422 . Total input tokens: 168545654 . Total output tokens: 148880243
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 6.6077661730814725,
    "estimated_duration": 3600.1094825909117,
    "input_throughput": 5956.700790267832,
    "output_throughput": 5212.0967683726985,
    "total_throughput": 11168.79755864053,
    "itl": 104.95909942194717,
    "ttft": 1727334.1056062125,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 451,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.982196473409451,
    "arrivals": 252140,
    "finished_requests": 86978,
    "scheduler_time": 89.34278949778037
}
#Debug simulation 
Total elapsed time: 6.607831340981647. Arrivals time: 0.26715162326581776 Scheduler time: 6.188834987347946 Scheduler overhead time: 0.04981327848508954 Adapter cache time: 0.025467630242928863 Engine time: 0.052661161636933684 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-16/adapters_128_slots_96_rate_1.6-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-16/adapters_128_slots_96_rate_1.6-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [42 43 43]
Adapter prompts. [17280, 270, 17280, 17280, 66, 66, 17280, 66, 270, 270, 270, 66, 17280, 270, 66, 17280, 270, 66, 66, 66, 66, 270, 270, 17280, 270, 66, 270, 270, 270, 270, 17280, 270, 66, 270, 66, 17280, 17280, 66, 270, 270, 66, 270, 66, 270, 270, 17280, 17280, 17280, 17280, 270, 270, 66, 270, 17280, 17280, 270, 66, 66, 66, 17280, 270, 270, 270, 270, 17280, 270, 17280, 66, 66, 270, 66, 17280, 17280, 66, 66, 270, 270, 270, 66, 17280, 66, 17280, 270, 66, 17280, 17280, 270, 270, 66, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 66, 17280, 66, 66, 17280, 270, 17280, 17280, 270, 17280, 66, 270, 17280, 66, 17280, 270, 66, 270, 270, 17280, 17280, 66, 66, 17280, 66, 66, 66, 270, 66]
Prompts retrieved: 757422 . Total input tokens: 168545654 . Total output tokens: 148880243
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 6.174626196967438,
    "estimated_duration": 3600.025554353249,
    "input_throughput": 5772.315414503565,
    "output_throughput": 5059.372697500798,
    "total_throughput": 10831.688112004362,
    "itl": 95.1076956778607,
    "ttft": 1754994.2490848345,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 443,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.2306610589334777,
    "arrivals": 252140,
    "finished_requests": 84330,
    "scheduler_time": 88.42444953131665
}
#Debug simulation 
Total elapsed time: 6.174750232836232. Arrivals time: 0.2573448845651001 Scheduler time: 5.7540547559037805 Scheduler overhead time: 0.05400440818630159 Adapter cache time: 0.026222167070955038 Engine time: 0.05715568480081856 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-32/adapters_128_slots_96_rate_1.6-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-32/adapters_128_slots_96_rate_1.6-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [42 43 43]
Adapter prompts. [17280, 270, 17280, 17280, 66, 66, 17280, 66, 270, 270, 270, 66, 17280, 270, 66, 17280, 270, 66, 66, 66, 66, 270, 270, 17280, 270, 66, 270, 270, 270, 270, 17280, 270, 66, 270, 66, 17280, 17280, 66, 270, 270, 66, 270, 66, 270, 270, 17280, 17280, 17280, 17280, 270, 270, 66, 270, 17280, 17280, 270, 66, 66, 66, 17280, 270, 270, 270, 270, 17280, 270, 17280, 66, 66, 270, 66, 17280, 17280, 66, 66, 270, 270, 270, 66, 17280, 66, 17280, 270, 66, 17280, 17280, 270, 270, 66, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 66, 17280, 66, 66, 17280, 270, 17280, 17280, 270, 17280, 66, 270, 17280, 66, 17280, 270, 66, 270, 270, 17280, 17280, 66, 66, 17280, 66, 66, 66, 270, 66]
Prompts retrieved: 757422 . Total input tokens: 168545654 . Total output tokens: 148880243
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 5.67595828906633,
    "estimated_duration": 3600.0311923537606,
    "input_throughput": 5220.662543124192,
    "output_throughput": 4577.655892260559,
    "total_throughput": 9798.318435384752,
    "itl": 74.98887228448797,
    "ttft": 1843707.4453768292,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 408,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.0575138476072086,
    "arrivals": 252140,
    "finished_requests": 76247,
    "scheduler_time": 85.34496731386224
}
#Debug simulation 
Total elapsed time: 5.676056387135759. Arrivals time: 0.2408185068052262 Scheduler time: 5.24142225086689 Scheduler overhead time: 0.06516379723325372 Adapter cache time: 0.027688303496688604 Engine time: 0.06947171734645963 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-16-16/adapters_128_slots_96_rate_1.6-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-16-16/adapters_128_slots_96_rate_1.6-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [42 43 43]
Adapter prompts. [17280, 270, 17280, 17280, 66, 66, 17280, 66, 270, 270, 270, 66, 17280, 270, 66, 17280, 270, 66, 66, 66, 66, 270, 270, 17280, 270, 66, 270, 270, 270, 270, 17280, 270, 66, 270, 66, 17280, 17280, 66, 270, 270, 66, 270, 66, 270, 270, 17280, 17280, 17280, 17280, 270, 270, 66, 270, 17280, 17280, 270, 66, 66, 66, 17280, 270, 270, 270, 270, 17280, 270, 17280, 66, 66, 270, 66, 17280, 17280, 66, 66, 270, 270, 270, 66, 17280, 66, 17280, 270, 66, 17280, 17280, 270, 270, 66, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 66, 17280, 66, 66, 17280, 270, 17280, 17280, 270, 17280, 66, 270, 17280, 66, 17280, 270, 66, 270, 270, 17280, 17280, 66, 66, 17280, 66, 66, 66, 270, 66]
Prompts retrieved: 757422 . Total input tokens: 168545654 . Total output tokens: 148880243
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 6.181994270067662,
    "estimated_duration": 3600.0668104663655,
    "input_throughput": 5772.772866209052,
    "output_throughput": 5059.843874853052,
    "total_throughput": 10832.616741062104,
    "itl": 95.10141223938655,
    "ttft": 1754894.3589446812,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 443,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.01271036612335,
    "arrivals": 252140,
    "finished_requests": 84337,
    "scheduler_time": 88.42949709565315
}
#Debug simulation 
Total elapsed time: 6.182087276130915. Arrivals time: 0.2602425878867507 Scheduler time: 5.757573728449643 Scheduler overhead time: 0.054104202426970005 Adapter cache time: 0.026579524856060743 Engine time: 0.05752235953696072 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-16-32/adapters_128_slots_96_rate_1.6-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_8-16-32/adapters_128_slots_96_rate_1.6-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [42 43 43]
Adapter prompts. [17280, 270, 17280, 17280, 66, 66, 17280, 66, 270, 270, 270, 66, 17280, 270, 66, 17280, 270, 66, 66, 66, 66, 270, 270, 17280, 270, 66, 270, 270, 270, 270, 17280, 270, 66, 270, 66, 17280, 17280, 66, 270, 270, 66, 270, 66, 270, 270, 17280, 17280, 17280, 17280, 270, 270, 66, 270, 17280, 17280, 270, 66, 66, 66, 17280, 270, 270, 270, 270, 17280, 270, 17280, 66, 66, 270, 66, 17280, 17280, 66, 66, 270, 270, 270, 66, 17280, 66, 17280, 270, 66, 17280, 17280, 270, 270, 66, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 66, 17280, 66, 66, 17280, 270, 17280, 17280, 270, 17280, 66, 270, 17280, 66, 17280, 270, 66, 270, 270, 17280, 17280, 66, 66, 17280, 66, 66, 66, 270, 66]
Prompts retrieved: 757422 . Total input tokens: 168545654 . Total output tokens: 148880243
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 5.668636424001306,
    "estimated_duration": 3600.047103271643,
    "input_throughput": 5220.639747441062,
    "output_throughput": 4577.669549107704,
    "total_throughput": 9798.309296548767,
    "itl": 74.98963430187871,
    "ttft": 1843787.7252309478,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 408,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.0268605054682323,
    "arrivals": 252140,
    "finished_requests": 76248,
    "scheduler_time": 85.34579453675309
}
#Debug simulation 
Total elapsed time: 5.668731902958825. Arrivals time: 0.24472423805855215 Scheduler time: 5.228691701544449 Scheduler overhead time: 0.06499224109575152 Adapter cache time: 0.027884921059012413 Engine time: 0.07099106814712286 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_16-16-16/adapters_128_slots_96_rate_1.6-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 235584,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_16-16-16/adapters_128_slots_96_rate_1.6-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [42 43 43]
Adapter prompts. [17280, 270, 17280, 17280, 66, 66, 17280, 66, 270, 270, 270, 66, 17280, 270, 66, 17280, 270, 66, 66, 66, 66, 270, 270, 17280, 270, 66, 270, 270, 270, 270, 17280, 270, 66, 270, 66, 17280, 17280, 66, 270, 270, 66, 270, 66, 270, 270, 17280, 17280, 17280, 17280, 270, 270, 66, 270, 17280, 17280, 270, 66, 66, 66, 17280, 270, 270, 270, 270, 17280, 270, 17280, 66, 66, 270, 66, 17280, 17280, 66, 66, 270, 270, 270, 66, 17280, 66, 17280, 270, 66, 17280, 17280, 270, 270, 66, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 66, 17280, 66, 66, 17280, 270, 17280, 17280, 270, 17280, 66, 270, 17280, 66, 17280, 270, 66, 270, 270, 17280, 17280, 66, 66, 17280, 66, 66, 66, 270, 66]
Prompts retrieved: 757422 . Total input tokens: 168545654 . Total output tokens: 148880243
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 6.181415221188217,
    "estimated_duration": 3600.0957672486265,
    "input_throughput": 5773.161144511476,
    "output_throughput": 5059.949561820076,
    "total_throughput": 10833.110706331552,
    "itl": 95.0962553209624,
    "ttft": 1754931.1981264937,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 443,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.828076976672734,
    "arrivals": 252140,
    "finished_requests": 84340,
    "scheduler_time": 88.43515794436433
}
#Debug simulation 
Total elapsed time: 6.181516690179706. Arrivals time: 0.2474889513105154 Scheduler time: 5.770469929557294 Scheduler overhead time: 0.05408380855806172 Adapter cache time: 0.026090561412274837 Engine time: 0.057286803144961596 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_16-16-32/adapters_128_slots_96_rate_1.6-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 168064,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_1.6-0.025-0.00625_size_16-16-32/adapters_128_slots_96_rate_1.6-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [42 43 43]
Adapter prompts. [17280, 270, 17280, 17280, 66, 66, 17280, 66, 270, 270, 270, 66, 17280, 270, 66, 17280, 270, 66, 66, 66, 66, 270, 270, 17280, 270, 66, 270, 270, 270, 270, 17280, 270, 66, 270, 66, 17280, 17280, 66, 270, 270, 66, 270, 66, 270, 270, 17280, 17280, 17280, 17280, 270, 270, 66, 270, 17280, 17280, 270, 66, 66, 66, 17280, 270, 270, 270, 270, 17280, 270, 17280, 66, 66, 270, 66, 17280, 17280, 66, 66, 270, 270, 270, 66, 17280, 66, 17280, 270, 66, 17280, 17280, 270, 270, 66, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 66, 17280, 66, 66, 17280, 270, 17280, 17280, 270, 17280, 66, 270, 17280, 66, 17280, 270, 66, 270, 270, 17280, 17280, 66, 66, 17280, 66, 66, 66, 270, 66]
Prompts retrieved: 757422 . Total input tokens: 168545654 . Total output tokens: 148880243
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 5.918616576818749,
    "estimated_duration": 3600.0727201712575,
    "input_throughput": 5220.568988702522,
    "output_throughput": 4577.678364012613,
    "total_throughput": 9798.247352715136,
    "itl": 74.99247332534388,
    "ttft": 1843785.6788079652,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 408,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.001799327097853,
    "arrivals": 252140,
    "finished_requests": 76248,
    "scheduler_time": 85.34705285753165
}
#Debug simulation 
Total elapsed time: 5.918740690918639. Arrivals time: 0.46164656477048993 Scheduler time: 5.2630372499115765 Scheduler overhead time: 0.06528697605244815 Adapter cache time: 0.027753812726587057 Engine time: 0.06935635395348072 
