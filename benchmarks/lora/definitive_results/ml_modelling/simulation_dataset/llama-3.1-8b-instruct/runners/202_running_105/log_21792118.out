INFO 05-31 19:31:05 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 05-31 19:31:05 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_8-8-32/adapters_256_slots_32_rate_0.8-0.4-0.1_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_8-8-32/adapters_256_slots_32_rate_0.8-0.4-0.1_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 1080, 8640, 8640, 1080, 8640, 4320, 8640, 1080, 4320, 1080, 8640, 4320, 4320, 4320, 4320, 8640, 1080, 1080, 1080, 4320, 8640, 1080, 8640, 8640, 4320, 4320, 4320, 1080, 8640, 1080, 4320, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 8640, 4320, 1080, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 1080, 8640, 8640, 4320, 1080, 1080, 8640, 4320, 1080, 4320, 4320, 8640, 4320, 1080, 1080, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 4320, 1080, 4320, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 8640, 8640, 1080, 8640, 1080, 4320, 8640, 8640, 8640, 4320, 1080, 8640, 4320, 1080, 1080, 1080, 1080, 1080, 8640, 4320, 1080, 8640, 1080, 8640, 1080, 1080, 4320, 4320, 8640, 4320, 8640, 1080, 4320, 1080, 8640, 8640, 1080, 8640, 4320, 1080, 8640, 1080, 1080, 8640, 8640, 4320, 8640, 8640, 1080, 8640, 4320, 4320, 1080, 4320, 8640, 8640, 1080, 8640, 4320, 1080, 4320, 8640, 1080, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 1080, 1080, 8640, 1080, 4320, 8640, 8640, 4320, 1080, 8640, 1080, 4320, 4320, 1080, 4320, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 8640, 4320, 8640, 4320, 1080, 4320, 8640, 4320, 8640, 1080, 8640, 1080, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 1080, 8640, 1080, 8640, 4320, 4320, 1080, 4320, 8640, 4320, 4320, 8640, 1080, 8640, 8640, 4320, 1080, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 1080, 8640, 4320, 8640, 8640, 1080, 8640, 4320, 4320, 8640, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 1080, 1080, 1080, 1080]
Prompts retrieved: 1202040 . Total input tokens: 267683845 . Total output tokens: 236075847
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 81.16752699902281,
    "estimated_duration": 3600.068004196597,
    "input_throughput": 6409.389481838225,
    "output_throughput": 5592.081031950588,
    "total_throughput": 12001.470513788812,
    "itl": 90.09472725654778,
    "ttft": 1854456.124761972,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 461,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.465040059676421,
    "arrivals": 401058,
    "finished_requests": 93724,
    "scheduler_time": 247.62064701018258
}
#Debug simulation 
Total elapsed time: 81.16774176387116. Arrivals time: 0.45663061272352934 Scheduler time: 80.4998031114228 Scheduler overhead time: 0.08134071808308363 Adapter cache time: 0.017906160093843937 Engine time: 0.08049853192642331 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_8-16-16/adapters_256_slots_32_rate_0.8-0.4-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_8-16-16/adapters_256_slots_32_rate_0.8-0.4-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 1080, 8640, 8640, 1080, 8640, 4320, 8640, 1080, 4320, 1080, 8640, 4320, 4320, 4320, 4320, 8640, 1080, 1080, 1080, 4320, 8640, 1080, 8640, 8640, 4320, 4320, 4320, 1080, 8640, 1080, 4320, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 8640, 4320, 1080, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 1080, 8640, 8640, 4320, 1080, 1080, 8640, 4320, 1080, 4320, 4320, 8640, 4320, 1080, 1080, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 4320, 1080, 4320, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 8640, 8640, 1080, 8640, 1080, 4320, 8640, 8640, 8640, 4320, 1080, 8640, 4320, 1080, 1080, 1080, 1080, 1080, 8640, 4320, 1080, 8640, 1080, 8640, 1080, 1080, 4320, 4320, 8640, 4320, 8640, 1080, 4320, 1080, 8640, 8640, 1080, 8640, 4320, 1080, 8640, 1080, 1080, 8640, 8640, 4320, 8640, 8640, 1080, 8640, 4320, 4320, 1080, 4320, 8640, 8640, 1080, 8640, 4320, 1080, 4320, 8640, 1080, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 1080, 1080, 8640, 1080, 4320, 8640, 8640, 4320, 1080, 8640, 1080, 4320, 4320, 1080, 4320, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 8640, 4320, 8640, 4320, 1080, 4320, 8640, 4320, 8640, 1080, 8640, 1080, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 1080, 8640, 1080, 8640, 4320, 4320, 1080, 4320, 8640, 4320, 4320, 8640, 1080, 8640, 8640, 4320, 1080, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 1080, 8640, 4320, 8640, 8640, 1080, 8640, 4320, 4320, 8640, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 1080, 1080, 1080, 1080]
Prompts retrieved: 1202040 . Total input tokens: 267683845 . Total output tokens: 236075847
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 87.80099154403433,
    "estimated_duration": 3600.053940729261,
    "input_throughput": 6549.997135660513,
    "output_throughput": 5719.695132075952,
    "total_throughput": 12269.692267736464,
    "itl": 95.0648659714839,
    "ttft": 1841467.4458067883,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 436,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.986069792192426,
    "arrivals": 401058,
    "finished_requests": 95896,
    "scheduler_time": 241.46216852398206
}
#Debug simulation 
Total elapsed time: 87.80119551625103. Arrivals time: 0.46273830626159906 Scheduler time: 87.12982164882123 Scheduler overhead time: 0.0806364850141108 Adapter cache time: 0.01764714252203703 Engine time: 0.07948035188019276 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_8-16-32/adapters_256_slots_32_rate_0.8-0.4-0.1_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_8-16-32/adapters_256_slots_32_rate_0.8-0.4-0.1_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 1080, 8640, 8640, 1080, 8640, 4320, 8640, 1080, 4320, 1080, 8640, 4320, 4320, 4320, 4320, 8640, 1080, 1080, 1080, 4320, 8640, 1080, 8640, 8640, 4320, 4320, 4320, 1080, 8640, 1080, 4320, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 8640, 4320, 1080, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 1080, 8640, 8640, 4320, 1080, 1080, 8640, 4320, 1080, 4320, 4320, 8640, 4320, 1080, 1080, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 4320, 1080, 4320, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 8640, 8640, 1080, 8640, 1080, 4320, 8640, 8640, 8640, 4320, 1080, 8640, 4320, 1080, 1080, 1080, 1080, 1080, 8640, 4320, 1080, 8640, 1080, 8640, 1080, 1080, 4320, 4320, 8640, 4320, 8640, 1080, 4320, 1080, 8640, 8640, 1080, 8640, 4320, 1080, 8640, 1080, 1080, 8640, 8640, 4320, 8640, 8640, 1080, 8640, 4320, 4320, 1080, 4320, 8640, 8640, 1080, 8640, 4320, 1080, 4320, 8640, 1080, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 1080, 1080, 8640, 1080, 4320, 8640, 8640, 4320, 1080, 8640, 1080, 4320, 4320, 1080, 4320, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 8640, 4320, 8640, 4320, 1080, 4320, 8640, 4320, 8640, 1080, 8640, 1080, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 1080, 8640, 1080, 8640, 4320, 4320, 1080, 4320, 8640, 4320, 4320, 8640, 1080, 8640, 8640, 4320, 1080, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 1080, 8640, 4320, 8640, 8640, 1080, 8640, 4320, 4320, 8640, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 1080, 1080, 1080, 1080]
Prompts retrieved: 1202040 . Total input tokens: 267683845 . Total output tokens: 236075847
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 83.04334105690941,
    "estimated_duration": 3600.0783903406887,
    "input_throughput": 6407.341590641611,
    "output_throughput": 5596.517579744515,
    "total_throughput": 12003.859170386126,
    "itl": 90.14128878398903,
    "ttft": 1851706.0243373015,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 439,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.2712638921616843,
    "arrivals": 401058,
    "finished_requests": 93671,
    "scheduler_time": 247.49674803192255
}
#Debug simulation 
Total elapsed time: 83.04351143492386. Arrivals time: 0.46441236697137356 Scheduler time: 82.36811465770006 Scheduler overhead time: 0.0808059899136424 Adapter cache time: 0.017682163044810295 Engine time: 0.08104000985622406 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_16-16-16/adapters_256_slots_32_rate_0.8-0.4-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_16-16-16/adapters_256_slots_32_rate_0.8-0.4-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 1080, 8640, 8640, 1080, 8640, 4320, 8640, 1080, 4320, 1080, 8640, 4320, 4320, 4320, 4320, 8640, 1080, 1080, 1080, 4320, 8640, 1080, 8640, 8640, 4320, 4320, 4320, 1080, 8640, 1080, 4320, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 8640, 4320, 1080, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 1080, 8640, 8640, 4320, 1080, 1080, 8640, 4320, 1080, 4320, 4320, 8640, 4320, 1080, 1080, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 4320, 1080, 4320, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 8640, 8640, 1080, 8640, 1080, 4320, 8640, 8640, 8640, 4320, 1080, 8640, 4320, 1080, 1080, 1080, 1080, 1080, 8640, 4320, 1080, 8640, 1080, 8640, 1080, 1080, 4320, 4320, 8640, 4320, 8640, 1080, 4320, 1080, 8640, 8640, 1080, 8640, 4320, 1080, 8640, 1080, 1080, 8640, 8640, 4320, 8640, 8640, 1080, 8640, 4320, 4320, 1080, 4320, 8640, 8640, 1080, 8640, 4320, 1080, 4320, 8640, 1080, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 1080, 1080, 8640, 1080, 4320, 8640, 8640, 4320, 1080, 8640, 1080, 4320, 4320, 1080, 4320, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 8640, 4320, 8640, 4320, 1080, 4320, 8640, 4320, 8640, 1080, 8640, 1080, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 1080, 8640, 1080, 8640, 4320, 4320, 1080, 4320, 8640, 4320, 4320, 8640, 1080, 8640, 8640, 4320, 1080, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 1080, 8640, 4320, 8640, 8640, 1080, 8640, 4320, 4320, 8640, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 1080, 1080, 1080, 1080]
Prompts retrieved: 1202040 . Total input tokens: 267683845 . Total output tokens: 236075847
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 86.92531087994576,
    "estimated_duration": 3600.1003995897345,
    "input_throughput": 6549.922886230397,
    "output_throughput": 5717.223609193115,
    "total_throughput": 12267.146495423513,
    "itl": 95.03255683048317,
    "ttft": 1840410.463309946,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 460,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.9366036326624325,
    "arrivals": 401058,
    "finished_requests": 95826,
    "scheduler_time": 241.48906388072515
}
#Debug simulation 
Total elapsed time: 86.9254748239182. Arrivals time: 0.47684311820194125 Scheduler time: 86.2428092523478 Scheduler overhead time: 0.07888369169086218 Adapter cache time: 0.017282512970268726 Engine time: 0.07912213169038296 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_16-16-32/adapters_256_slots_32_rate_0.8-0.4-0.1_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.1_size_16-16-32/adapters_256_slots_32_rate_0.8-0.4-0.1_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 1080, 8640, 8640, 1080, 8640, 4320, 8640, 1080, 4320, 1080, 8640, 4320, 4320, 4320, 4320, 8640, 1080, 1080, 1080, 4320, 8640, 1080, 8640, 8640, 4320, 4320, 4320, 1080, 8640, 1080, 4320, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 8640, 4320, 1080, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 1080, 8640, 8640, 4320, 1080, 1080, 8640, 4320, 1080, 4320, 4320, 8640, 4320, 1080, 1080, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 4320, 1080, 4320, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 8640, 8640, 1080, 8640, 1080, 4320, 8640, 8640, 8640, 4320, 1080, 8640, 4320, 1080, 1080, 1080, 1080, 1080, 8640, 4320, 1080, 8640, 1080, 8640, 1080, 1080, 4320, 4320, 8640, 4320, 8640, 1080, 4320, 1080, 8640, 8640, 1080, 8640, 4320, 1080, 8640, 1080, 1080, 8640, 8640, 4320, 8640, 8640, 1080, 8640, 4320, 4320, 1080, 4320, 8640, 8640, 1080, 8640, 4320, 1080, 4320, 8640, 1080, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 1080, 1080, 8640, 1080, 4320, 8640, 8640, 4320, 1080, 8640, 1080, 4320, 4320, 1080, 4320, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 8640, 4320, 8640, 4320, 1080, 4320, 8640, 4320, 8640, 1080, 8640, 1080, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 1080, 8640, 1080, 8640, 4320, 4320, 1080, 4320, 8640, 4320, 4320, 8640, 1080, 8640, 8640, 4320, 1080, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 1080, 8640, 4320, 8640, 8640, 1080, 8640, 4320, 4320, 8640, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 1080, 1080, 1080, 1080]
Prompts retrieved: 1202040 . Total input tokens: 267683845 . Total output tokens: 236075847
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 83.6191716119647,
    "estimated_duration": 3600.026636732819,
    "input_throughput": 6399.826258204965,
    "output_throughput": 5591.255296451818,
    "total_throughput": 11991.081554656783,
    "itl": 89.85044742540215,
    "ttft": 1852553.4785426026,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 454,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.347252730764475,
    "arrivals": 401058,
    "finished_requests": 93547,
    "scheduler_time": 247.84347206620322
}
#Debug simulation 
Total elapsed time: 83.61933881882578. Arrivals time: 0.4664758457802236 Scheduler time: 82.94067838182673 Scheduler overhead time: 0.0820923363789916 Adapter cache time: 0.01774567784741521 Engine time: 0.08031463297083974 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_8-8-8/adapters_256_slots_32_rate_0.8-0.4-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_8-8-8/adapters_256_slots_32_rate_0.8-0.4-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 540, 8640, 8640, 540, 8640, 4320, 8640, 540, 4320, 540, 8640, 4320, 4320, 4320, 4320, 8640, 540, 540, 540, 4320, 8640, 540, 8640, 8640, 4320, 4320, 4320, 540, 8640, 540, 4320, 4320, 540, 4320, 540, 540, 4320, 4320, 8640, 4320, 540, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 540, 8640, 8640, 4320, 540, 540, 8640, 4320, 540, 4320, 4320, 8640, 4320, 540, 540, 8640, 8640, 8640, 8640, 8640, 8640, 540, 4320, 540, 4320, 540, 540, 540, 4320, 4320, 4320, 540, 540, 8640, 8640, 540, 8640, 540, 4320, 8640, 8640, 8640, 4320, 540, 8640, 4320, 540, 540, 540, 540, 540, 8640, 4320, 540, 8640, 540, 8640, 540, 540, 4320, 4320, 8640, 4320, 8640, 540, 4320, 540, 8640, 8640, 540, 8640, 4320, 540, 8640, 540, 540, 8640, 8640, 4320, 8640, 8640, 540, 8640, 4320, 4320, 540, 4320, 8640, 8640, 540, 8640, 4320, 540, 4320, 8640, 540, 540, 540, 540, 540, 540, 8640, 540, 540, 540, 8640, 540, 4320, 8640, 8640, 4320, 540, 8640, 540, 4320, 4320, 540, 4320, 540, 8640, 540, 540, 8640, 540, 8640, 8640, 4320, 8640, 4320, 540, 4320, 8640, 4320, 8640, 540, 8640, 540, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 540, 8640, 540, 8640, 4320, 4320, 540, 4320, 8640, 4320, 4320, 8640, 540, 8640, 8640, 4320, 540, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 540, 8640, 4320, 8640, 8640, 540, 8640, 4320, 4320, 8640, 540, 4320, 540, 540, 540, 540, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 540, 540, 540, 540]
Prompts retrieved: 1156140 . Total input tokens: 257510080 . Total output tokens: 227106040
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 86.50386102870107,
    "estimated_duration": 3600.098262584676,
    "input_throughput": 6594.811104670946,
    "output_throughput": 5753.12963405894,
    "total_throughput": 12347.940738729885,
    "itl": 97.28634457613948,
    "ttft": 1832383.9148670686,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 452,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.988808882441401,
    "arrivals": 385672,
    "finished_requests": 96412,
    "scheduler_time": 238.6957097108502
}
#Debug simulation 
Total elapsed time: 86.50403579697013. Arrivals time: 0.48396974243223667 Scheduler time: 85.81428463384509 Scheduler overhead time: 0.07979875663295388 Adapter cache time: 0.017540051601827145 Engine time: 0.07850332790985703 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_8-8-16/adapters_256_slots_32_rate_0.8-0.4-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_8-8-16/adapters_256_slots_32_rate_0.8-0.4-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 540, 8640, 8640, 540, 8640, 4320, 8640, 540, 4320, 540, 8640, 4320, 4320, 4320, 4320, 8640, 540, 540, 540, 4320, 8640, 540, 8640, 8640, 4320, 4320, 4320, 540, 8640, 540, 4320, 4320, 540, 4320, 540, 540, 4320, 4320, 8640, 4320, 540, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 540, 8640, 8640, 4320, 540, 540, 8640, 4320, 540, 4320, 4320, 8640, 4320, 540, 540, 8640, 8640, 8640, 8640, 8640, 8640, 540, 4320, 540, 4320, 540, 540, 540, 4320, 4320, 4320, 540, 540, 8640, 8640, 540, 8640, 540, 4320, 8640, 8640, 8640, 4320, 540, 8640, 4320, 540, 540, 540, 540, 540, 8640, 4320, 540, 8640, 540, 8640, 540, 540, 4320, 4320, 8640, 4320, 8640, 540, 4320, 540, 8640, 8640, 540, 8640, 4320, 540, 8640, 540, 540, 8640, 8640, 4320, 8640, 8640, 540, 8640, 4320, 4320, 540, 4320, 8640, 8640, 540, 8640, 4320, 540, 4320, 8640, 540, 540, 540, 540, 540, 540, 8640, 540, 540, 540, 8640, 540, 4320, 8640, 8640, 4320, 540, 8640, 540, 4320, 4320, 540, 4320, 540, 8640, 540, 540, 8640, 540, 8640, 8640, 4320, 8640, 4320, 540, 4320, 8640, 4320, 8640, 540, 8640, 540, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 540, 8640, 540, 8640, 4320, 4320, 540, 4320, 8640, 4320, 4320, 8640, 540, 8640, 8640, 4320, 540, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 540, 8640, 4320, 8640, 8640, 540, 8640, 4320, 4320, 8640, 540, 4320, 540, 540, 540, 540, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 540, 540, 540, 540]
Prompts retrieved: 1156140 . Total input tokens: 257510080 . Total output tokens: 227106040
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 81.76484930608422,
    "estimated_duration": 3600.0766057524293,
    "input_throughput": 6523.598126349162,
    "output_throughput": 5694.7763187153305,
    "total_throughput": 12218.374445064492,
    "itl": 94.9137762341281,
    "ttft": 1842001.1525608564,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 482,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.5198923838418015,
    "arrivals": 385672,
    "finished_requests": 95387,
    "scheduler_time": 241.61486320916487
}
#Debug simulation 
Total elapsed time: 81.76502189226449. Arrivals time: 0.4742780514061451 Scheduler time: 81.0864865295589 Scheduler overhead time: 0.07839490100741386 Adapter cache time: 0.017862078733742237 Engine time: 0.07759212097153068 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_8-8-32/adapters_256_slots_32_rate_0.8-0.4-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_8-8-32/adapters_256_slots_32_rate_0.8-0.4-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 540, 8640, 8640, 540, 8640, 4320, 8640, 540, 4320, 540, 8640, 4320, 4320, 4320, 4320, 8640, 540, 540, 540, 4320, 8640, 540, 8640, 8640, 4320, 4320, 4320, 540, 8640, 540, 4320, 4320, 540, 4320, 540, 540, 4320, 4320, 8640, 4320, 540, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 540, 8640, 8640, 4320, 540, 540, 8640, 4320, 540, 4320, 4320, 8640, 4320, 540, 540, 8640, 8640, 8640, 8640, 8640, 8640, 540, 4320, 540, 4320, 540, 540, 540, 4320, 4320, 4320, 540, 540, 8640, 8640, 540, 8640, 540, 4320, 8640, 8640, 8640, 4320, 540, 8640, 4320, 540, 540, 540, 540, 540, 8640, 4320, 540, 8640, 540, 8640, 540, 540, 4320, 4320, 8640, 4320, 8640, 540, 4320, 540, 8640, 8640, 540, 8640, 4320, 540, 8640, 540, 540, 8640, 8640, 4320, 8640, 8640, 540, 8640, 4320, 4320, 540, 4320, 8640, 8640, 540, 8640, 4320, 540, 4320, 8640, 540, 540, 540, 540, 540, 540, 8640, 540, 540, 540, 8640, 540, 4320, 8640, 8640, 4320, 540, 8640, 540, 4320, 4320, 540, 4320, 540, 8640, 540, 540, 8640, 540, 8640, 8640, 4320, 8640, 4320, 540, 4320, 8640, 4320, 8640, 540, 8640, 540, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 540, 8640, 540, 8640, 4320, 4320, 540, 4320, 8640, 4320, 4320, 8640, 540, 8640, 8640, 4320, 540, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 540, 8640, 4320, 8640, 8640, 540, 8640, 4320, 4320, 8640, 540, 4320, 540, 540, 540, 540, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 540, 540, 540, 540]
Prompts retrieved: 1156140 . Total input tokens: 257510080 . Total output tokens: 227106040
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 82.45350761106238,
    "estimated_duration": 3600.0170711536725,
    "input_throughput": 6358.3526265514465,
    "output_throughput": 5550.023959635583,
    "total_throughput": 11908.376586187029,
    "itl": 89.09168142581032,
    "ttft": 1856595.0115432404,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 460,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.455255179908153,
    "arrivals": 385672,
    "finished_requests": 92802,
    "scheduler_time": 248.73768206044932
}
#Debug simulation 
Total elapsed time: 82.45368490088731. Arrivals time: 0.4706505467183888 Scheduler time: 81.76984963798895 Scheduler overhead time: 0.08218940999358892 Adapter cache time: 0.017973764333873987 Engine time: 0.08085526432842016 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_8-16-16/adapters_256_slots_32_rate_0.8-0.4-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_8-16-16/adapters_256_slots_32_rate_0.8-0.4-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 540, 8640, 8640, 540, 8640, 4320, 8640, 540, 4320, 540, 8640, 4320, 4320, 4320, 4320, 8640, 540, 540, 540, 4320, 8640, 540, 8640, 8640, 4320, 4320, 4320, 540, 8640, 540, 4320, 4320, 540, 4320, 540, 540, 4320, 4320, 8640, 4320, 540, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 540, 8640, 8640, 4320, 540, 540, 8640, 4320, 540, 4320, 4320, 8640, 4320, 540, 540, 8640, 8640, 8640, 8640, 8640, 8640, 540, 4320, 540, 4320, 540, 540, 540, 4320, 4320, 4320, 540, 540, 8640, 8640, 540, 8640, 540, 4320, 8640, 8640, 8640, 4320, 540, 8640, 4320, 540, 540, 540, 540, 540, 8640, 4320, 540, 8640, 540, 8640, 540, 540, 4320, 4320, 8640, 4320, 8640, 540, 4320, 540, 8640, 8640, 540, 8640, 4320, 540, 8640, 540, 540, 8640, 8640, 4320, 8640, 8640, 540, 8640, 4320, 4320, 540, 4320, 8640, 8640, 540, 8640, 4320, 540, 4320, 8640, 540, 540, 540, 540, 540, 540, 8640, 540, 540, 540, 8640, 540, 4320, 8640, 8640, 4320, 540, 8640, 540, 4320, 4320, 540, 4320, 540, 8640, 540, 540, 8640, 540, 8640, 8640, 4320, 8640, 4320, 540, 4320, 8640, 4320, 8640, 540, 8640, 540, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 540, 8640, 540, 8640, 4320, 4320, 540, 4320, 8640, 4320, 4320, 8640, 540, 8640, 8640, 4320, 540, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 540, 8640, 4320, 8640, 8640, 540, 8640, 4320, 4320, 8640, 540, 4320, 540, 540, 540, 540, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 540, 540, 540, 540]
Prompts retrieved: 1156140 . Total input tokens: 257510080 . Total output tokens: 227106040
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 82.31364676821977,
    "estimated_duration": 3600.014144098143,
    "input_throughput": 6521.404377949014,
    "output_throughput": 5694.07623956301,
    "total_throughput": 12215.480617512023,
    "itl": 94.92802386564462,
    "ttft": 1841101.8015250508,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 497,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.404641610006797,
    "arrivals": 385672,
    "finished_requests": 95237,
    "scheduler_time": 241.5262729024225
}
#Debug simulation 
Total elapsed time: 82.31381692085415. Arrivals time: 0.47210959577932954 Scheduler time: 81.63728158222511 Scheduler overhead time: 0.07818815344944596 Adapter cache time: 0.01802974008023739 Engine time: 0.07776655489578843 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_8-16-32/adapters_256_slots_32_rate_0.8-0.4-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_8-16-32/adapters_256_slots_32_rate_0.8-0.4-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 540, 8640, 8640, 540, 8640, 4320, 8640, 540, 4320, 540, 8640, 4320, 4320, 4320, 4320, 8640, 540, 540, 540, 4320, 8640, 540, 8640, 8640, 4320, 4320, 4320, 540, 8640, 540, 4320, 4320, 540, 4320, 540, 540, 4320, 4320, 8640, 4320, 540, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 540, 8640, 8640, 4320, 540, 540, 8640, 4320, 540, 4320, 4320, 8640, 4320, 540, 540, 8640, 8640, 8640, 8640, 8640, 8640, 540, 4320, 540, 4320, 540, 540, 540, 4320, 4320, 4320, 540, 540, 8640, 8640, 540, 8640, 540, 4320, 8640, 8640, 8640, 4320, 540, 8640, 4320, 540, 540, 540, 540, 540, 8640, 4320, 540, 8640, 540, 8640, 540, 540, 4320, 4320, 8640, 4320, 8640, 540, 4320, 540, 8640, 8640, 540, 8640, 4320, 540, 8640, 540, 540, 8640, 8640, 4320, 8640, 8640, 540, 8640, 4320, 4320, 540, 4320, 8640, 8640, 540, 8640, 4320, 540, 4320, 8640, 540, 540, 540, 540, 540, 540, 8640, 540, 540, 540, 8640, 540, 4320, 8640, 8640, 4320, 540, 8640, 540, 4320, 4320, 540, 4320, 540, 8640, 540, 540, 8640, 540, 8640, 8640, 4320, 8640, 4320, 540, 4320, 8640, 4320, 8640, 540, 8640, 540, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 540, 8640, 540, 8640, 4320, 4320, 540, 4320, 8640, 4320, 4320, 8640, 540, 8640, 8640, 4320, 540, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 540, 8640, 4320, 8640, 8640, 540, 8640, 4320, 4320, 8640, 540, 4320, 540, 540, 540, 540, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 540, 540, 540, 540]
Prompts retrieved: 1156140 . Total input tokens: 257510080 . Total output tokens: 227106040
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 80.19238018989563,
    "estimated_duration": 3600.0104874391664,
    "input_throughput": 6360.16341615919,
    "output_throughput": 5554.887706514751,
    "total_throughput": 11915.05112267394,
    "itl": 89.27892435401994,
    "ttft": 1856359.4348154622,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 479,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.5517937844200347,
    "arrivals": 385672,
    "finished_requests": 92950,
    "scheduler_time": 248.40913583463936
}
#Debug simulation 
Total elapsed time: 80.1925478130579. Arrivals time: 0.4667733497917652 Scheduler time: 79.51280160015449 Scheduler overhead time: 0.08343621715903282 Adapter cache time: 0.018139789812266827 Engine time: 0.08012941339984536 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_16-16-16/adapters_256_slots_32_rate_0.8-0.4-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_16-16-16/adapters_256_slots_32_rate_0.8-0.4-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 540, 8640, 8640, 540, 8640, 4320, 8640, 540, 4320, 540, 8640, 4320, 4320, 4320, 4320, 8640, 540, 540, 540, 4320, 8640, 540, 8640, 8640, 4320, 4320, 4320, 540, 8640, 540, 4320, 4320, 540, 4320, 540, 540, 4320, 4320, 8640, 4320, 540, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 540, 8640, 8640, 4320, 540, 540, 8640, 4320, 540, 4320, 4320, 8640, 4320, 540, 540, 8640, 8640, 8640, 8640, 8640, 8640, 540, 4320, 540, 4320, 540, 540, 540, 4320, 4320, 4320, 540, 540, 8640, 8640, 540, 8640, 540, 4320, 8640, 8640, 8640, 4320, 540, 8640, 4320, 540, 540, 540, 540, 540, 8640, 4320, 540, 8640, 540, 8640, 540, 540, 4320, 4320, 8640, 4320, 8640, 540, 4320, 540, 8640, 8640, 540, 8640, 4320, 540, 8640, 540, 540, 8640, 8640, 4320, 8640, 8640, 540, 8640, 4320, 4320, 540, 4320, 8640, 8640, 540, 8640, 4320, 540, 4320, 8640, 540, 540, 540, 540, 540, 540, 8640, 540, 540, 540, 8640, 540, 4320, 8640, 8640, 4320, 540, 8640, 540, 4320, 4320, 540, 4320, 540, 8640, 540, 540, 8640, 540, 8640, 8640, 4320, 8640, 4320, 540, 4320, 8640, 4320, 8640, 540, 8640, 540, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 540, 8640, 540, 8640, 4320, 4320, 540, 4320, 8640, 4320, 4320, 8640, 540, 8640, 8640, 4320, 540, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 540, 8640, 4320, 8640, 8640, 540, 8640, 4320, 4320, 8640, 540, 4320, 540, 540, 540, 540, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 540, 540, 540, 540]
Prompts retrieved: 1156140 . Total input tokens: 257510080 . Total output tokens: 227106040
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 82.1678654840216,
    "estimated_duration": 3600.1069012516414,
    "input_throughput": 6523.018244773654,
    "output_throughput": 5689.85992968107,
    "total_throughput": 12212.878174454725,
    "itl": 94.83493571740773,
    "ttft": 1842313.6638007609,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 498,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.1791926284041114,
    "arrivals": 385672,
    "finished_requests": 95206,
    "scheduler_time": 241.79270800886576
}
#Debug simulation 
Total elapsed time: 82.16803349601105. Arrivals time: 0.47022861149162054 Scheduler time: 81.49349484452978 Scheduler overhead time: 0.07810388784855604 Adapter cache time: 0.01801821356639266 Engine time: 0.0780310439877212 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_16-16-32/adapters_256_slots_32_rate_0.8-0.4-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.05_size_16-16-32/adapters_256_slots_32_rate_0.8-0.4-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 540, 8640, 8640, 540, 8640, 4320, 8640, 540, 4320, 540, 8640, 4320, 4320, 4320, 4320, 8640, 540, 540, 540, 4320, 8640, 540, 8640, 8640, 4320, 4320, 4320, 540, 8640, 540, 4320, 4320, 540, 4320, 540, 540, 4320, 4320, 8640, 4320, 540, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 540, 8640, 8640, 4320, 540, 540, 8640, 4320, 540, 4320, 4320, 8640, 4320, 540, 540, 8640, 8640, 8640, 8640, 8640, 8640, 540, 4320, 540, 4320, 540, 540, 540, 4320, 4320, 4320, 540, 540, 8640, 8640, 540, 8640, 540, 4320, 8640, 8640, 8640, 4320, 540, 8640, 4320, 540, 540, 540, 540, 540, 8640, 4320, 540, 8640, 540, 8640, 540, 540, 4320, 4320, 8640, 4320, 8640, 540, 4320, 540, 8640, 8640, 540, 8640, 4320, 540, 8640, 540, 540, 8640, 8640, 4320, 8640, 8640, 540, 8640, 4320, 4320, 540, 4320, 8640, 8640, 540, 8640, 4320, 540, 4320, 8640, 540, 540, 540, 540, 540, 540, 8640, 540, 540, 540, 8640, 540, 4320, 8640, 8640, 4320, 540, 8640, 540, 4320, 4320, 540, 4320, 540, 8640, 540, 540, 8640, 540, 8640, 8640, 4320, 8640, 4320, 540, 4320, 8640, 4320, 8640, 540, 8640, 540, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 540, 8640, 540, 8640, 4320, 4320, 540, 4320, 8640, 4320, 4320, 8640, 540, 8640, 8640, 4320, 540, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 540, 8640, 4320, 8640, 8640, 540, 8640, 4320, 4320, 8640, 540, 4320, 540, 540, 540, 540, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 540, 540, 540, 540]
Prompts retrieved: 1156140 . Total input tokens: 257510080 . Total output tokens: 227106040
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 78.60447629820555,
    "estimated_duration": 3600.081997997894,
    "input_throughput": 6355.171080193097,
    "output_throughput": 5556.262888213165,
    "total_throughput": 11911.433968406262,
    "itl": 89.39677829085444,
    "ttft": 1858484.3544024585,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 505,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.71252895558256,
    "arrivals": 385672,
    "finished_requests": 92941,
    "scheduler_time": 248.22564596963184
}
#Debug simulation 
Total elapsed time: 78.60464232508093. Arrivals time: 0.46550131775438786 Scheduler time: 77.92852336168289 Scheduler overhead time: 0.08105536177754402 Adapter cache time: 0.018061760812997818 Engine time: 0.07962017366662621 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_8-8-8/adapters_256_slots_32_rate_0.8-0.4-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_8-8-8/adapters_256_slots_32_rate_0.8-0.4-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 270, 8640, 8640, 270, 8640, 4320, 8640, 270, 4320, 270, 8640, 4320, 4320, 4320, 4320, 8640, 270, 270, 270, 4320, 8640, 270, 8640, 8640, 4320, 4320, 4320, 270, 8640, 270, 4320, 4320, 270, 4320, 270, 270, 4320, 4320, 8640, 4320, 270, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 270, 8640, 8640, 4320, 270, 270, 8640, 4320, 270, 4320, 4320, 8640, 4320, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 270, 4320, 270, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 270, 8640, 8640, 270, 8640, 270, 4320, 8640, 8640, 8640, 4320, 270, 8640, 4320, 270, 270, 270, 270, 270, 8640, 4320, 270, 8640, 270, 8640, 270, 270, 4320, 4320, 8640, 4320, 8640, 270, 4320, 270, 8640, 8640, 270, 8640, 4320, 270, 8640, 270, 270, 8640, 8640, 4320, 8640, 8640, 270, 8640, 4320, 4320, 270, 4320, 8640, 8640, 270, 8640, 4320, 270, 4320, 8640, 270, 270, 270, 270, 270, 270, 8640, 270, 270, 270, 8640, 270, 4320, 8640, 8640, 4320, 270, 8640, 270, 4320, 4320, 270, 4320, 270, 8640, 270, 270, 8640, 270, 8640, 8640, 4320, 8640, 4320, 270, 4320, 8640, 4320, 8640, 270, 8640, 270, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 270, 8640, 270, 8640, 4320, 4320, 270, 4320, 8640, 4320, 4320, 8640, 270, 8640, 8640, 4320, 270, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 270, 8640, 4320, 8640, 8640, 270, 8640, 4320, 4320, 8640, 270, 4320, 270, 270, 270, 270, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 270, 270, 270, 270]
Prompts retrieved: 1133190 . Total input tokens: 252353794 . Total output tokens: 222596229
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 83.20339619694278,
    "estimated_duration": 3600.000331311398,
    "input_throughput": 6581.114949889335,
    "output_throughput": 5735.9172498959,
    "total_throughput": 12317.032199785233,
    "itl": 97.1529451240184,
    "ttft": 1825455.7554033478,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 485,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.207018380495756,
    "arrivals": 378122,
    "finished_requests": 96142,
    "scheduler_time": 239.58534049572395
}
#Debug simulation 
Total elapsed time: 83.20356843620539. Arrivals time: 0.47274854592978954 Scheduler time: 82.52841558866203 Scheduler overhead time: 0.07812516577541828 Adapter cache time: 0.017264990601688623 Engine time: 0.07678879424929619 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_8-8-16/adapters_256_slots_32_rate_0.8-0.4-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_8-8-16/adapters_256_slots_32_rate_0.8-0.4-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 270, 8640, 8640, 270, 8640, 4320, 8640, 270, 4320, 270, 8640, 4320, 4320, 4320, 4320, 8640, 270, 270, 270, 4320, 8640, 270, 8640, 8640, 4320, 4320, 4320, 270, 8640, 270, 4320, 4320, 270, 4320, 270, 270, 4320, 4320, 8640, 4320, 270, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 270, 8640, 8640, 4320, 270, 270, 8640, 4320, 270, 4320, 4320, 8640, 4320, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 270, 4320, 270, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 270, 8640, 8640, 270, 8640, 270, 4320, 8640, 8640, 8640, 4320, 270, 8640, 4320, 270, 270, 270, 270, 270, 8640, 4320, 270, 8640, 270, 8640, 270, 270, 4320, 4320, 8640, 4320, 8640, 270, 4320, 270, 8640, 8640, 270, 8640, 4320, 270, 8640, 270, 270, 8640, 8640, 4320, 8640, 8640, 270, 8640, 4320, 4320, 270, 4320, 8640, 8640, 270, 8640, 4320, 270, 4320, 8640, 270, 270, 270, 270, 270, 270, 8640, 270, 270, 270, 8640, 270, 4320, 8640, 8640, 4320, 270, 8640, 270, 4320, 4320, 270, 4320, 270, 8640, 270, 270, 8640, 270, 8640, 8640, 4320, 8640, 4320, 270, 4320, 8640, 4320, 8640, 270, 8640, 270, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 270, 8640, 270, 8640, 4320, 4320, 270, 4320, 8640, 4320, 4320, 8640, 270, 8640, 8640, 4320, 270, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 270, 8640, 4320, 8640, 8640, 270, 8640, 4320, 4320, 8640, 270, 4320, 270, 270, 270, 270, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 270, 270, 270, 270]
Prompts retrieved: 1133190 . Total input tokens: 252353794 . Total output tokens: 222596229
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 78.4955391921103,
    "estimated_duration": 3600.110758359454,
    "input_throughput": 6525.682562806952,
    "output_throughput": 5696.221415516925,
    "total_throughput": 12221.903978323877,
    "itl": 95.19185422252268,
    "ttft": 1834588.3849754257,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 501,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.6620101963123357,
    "arrivals": 378122,
    "finished_requests": 95375,
    "scheduler_time": 241.4348445627157
}
#Debug simulation 
Total elapsed time: 78.49570686602965. Arrivals time: 0.46008776407688856 Scheduler time: 77.83119333535433 Scheduler overhead time: 0.07887213351204991 Adapter cache time: 0.01777171529829502 Engine time: 0.07746679522097111 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_8-8-32/adapters_256_slots_32_rate_0.8-0.4-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_8-8-32/adapters_256_slots_32_rate_0.8-0.4-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 270, 8640, 8640, 270, 8640, 4320, 8640, 270, 4320, 270, 8640, 4320, 4320, 4320, 4320, 8640, 270, 270, 270, 4320, 8640, 270, 8640, 8640, 4320, 4320, 4320, 270, 8640, 270, 4320, 4320, 270, 4320, 270, 270, 4320, 4320, 8640, 4320, 270, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 270, 8640, 8640, 4320, 270, 270, 8640, 4320, 270, 4320, 4320, 8640, 4320, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 270, 4320, 270, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 270, 8640, 8640, 270, 8640, 270, 4320, 8640, 8640, 8640, 4320, 270, 8640, 4320, 270, 270, 270, 270, 270, 8640, 4320, 270, 8640, 270, 8640, 270, 270, 4320, 4320, 8640, 4320, 8640, 270, 4320, 270, 8640, 8640, 270, 8640, 4320, 270, 8640, 270, 270, 8640, 8640, 4320, 8640, 8640, 270, 8640, 4320, 4320, 270, 4320, 8640, 8640, 270, 8640, 4320, 270, 4320, 8640, 270, 270, 270, 270, 270, 270, 8640, 270, 270, 270, 8640, 270, 4320, 8640, 8640, 4320, 270, 8640, 270, 4320, 4320, 270, 4320, 270, 8640, 270, 270, 8640, 270, 8640, 8640, 4320, 8640, 4320, 270, 4320, 8640, 4320, 8640, 270, 8640, 270, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 270, 8640, 270, 8640, 4320, 4320, 270, 4320, 8640, 4320, 4320, 8640, 270, 8640, 8640, 4320, 270, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 270, 8640, 4320, 8640, 8640, 270, 8640, 4320, 4320, 8640, 270, 4320, 270, 270, 270, 270, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 270, 270, 270, 270]
Prompts retrieved: 1133190 . Total input tokens: 252353794 . Total output tokens: 222596229
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 80.45115118706599,
    "estimated_duration": 3600.0188355563605,
    "input_throughput": 6382.29132944221,
    "output_throughput": 5560.7314612580985,
    "total_throughput": 11943.022790700308,
    "itl": 89.61769973502557,
    "ttft": 1843580.9993323,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 438,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.301504855211848,
    "arrivals": 378122,
    "finished_requests": 93230,
    "scheduler_time": 248.2501983224393
}
#Debug simulation 
Total elapsed time: 80.45132162282243. Arrivals time: 0.46817954210564494 Scheduler time: 79.77259876718745 Scheduler overhead time: 0.08110702177509665 Adapter cache time: 0.01751838345080614 Engine time: 0.0801257323473692 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_8-16-16/adapters_256_slots_32_rate_0.8-0.4-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_8-16-16/adapters_256_slots_32_rate_0.8-0.4-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 270, 8640, 8640, 270, 8640, 4320, 8640, 270, 4320, 270, 8640, 4320, 4320, 4320, 4320, 8640, 270, 270, 270, 4320, 8640, 270, 8640, 8640, 4320, 4320, 4320, 270, 8640, 270, 4320, 4320, 270, 4320, 270, 270, 4320, 4320, 8640, 4320, 270, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 270, 8640, 8640, 4320, 270, 270, 8640, 4320, 270, 4320, 4320, 8640, 4320, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 270, 4320, 270, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 270, 8640, 8640, 270, 8640, 270, 4320, 8640, 8640, 8640, 4320, 270, 8640, 4320, 270, 270, 270, 270, 270, 8640, 4320, 270, 8640, 270, 8640, 270, 270, 4320, 4320, 8640, 4320, 8640, 270, 4320, 270, 8640, 8640, 270, 8640, 4320, 270, 8640, 270, 270, 8640, 8640, 4320, 8640, 8640, 270, 8640, 4320, 4320, 270, 4320, 8640, 8640, 270, 8640, 4320, 270, 4320, 8640, 270, 270, 270, 270, 270, 270, 8640, 270, 270, 270, 8640, 270, 4320, 8640, 8640, 4320, 270, 8640, 270, 4320, 4320, 270, 4320, 270, 8640, 270, 270, 8640, 270, 8640, 8640, 4320, 8640, 4320, 270, 4320, 8640, 4320, 8640, 270, 8640, 270, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 270, 8640, 270, 8640, 4320, 4320, 270, 4320, 8640, 4320, 4320, 8640, 270, 8640, 8640, 4320, 270, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 270, 8640, 4320, 8640, 8640, 270, 8640, 4320, 4320, 8640, 270, 4320, 270, 270, 270, 270, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 270, 270, 270, 270]
Prompts retrieved: 1133190 . Total input tokens: 252353794 . Total output tokens: 222596229
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 79.37947567598894,
    "estimated_duration": 3600.0782426091023,
    "input_throughput": 6521.084937027875,
    "output_throughput": 5697.794774908522,
    "total_throughput": 12218.879711936397,
    "itl": 94.9984671136632,
    "ttft": 1832550.7258273577,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 497,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.399088726113546,
    "arrivals": 378122,
    "finished_requests": 95388,
    "scheduler_time": 241.4513609960724
}
#Debug simulation 
Total elapsed time: 79.37964946171269. Arrivals time: 0.46743210032582283 Scheduler time: 78.70819553965703 Scheduler overhead time: 0.07882000878453255 Adapter cache time: 0.01758067449554801 Engine time: 0.07697811210528016 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_8-16-32/adapters_256_slots_32_rate_0.8-0.4-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_8-16-32/adapters_256_slots_32_rate_0.8-0.4-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 270, 8640, 8640, 270, 8640, 4320, 8640, 270, 4320, 270, 8640, 4320, 4320, 4320, 4320, 8640, 270, 270, 270, 4320, 8640, 270, 8640, 8640, 4320, 4320, 4320, 270, 8640, 270, 4320, 4320, 270, 4320, 270, 270, 4320, 4320, 8640, 4320, 270, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 270, 8640, 8640, 4320, 270, 270, 8640, 4320, 270, 4320, 4320, 8640, 4320, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 270, 4320, 270, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 270, 8640, 8640, 270, 8640, 270, 4320, 8640, 8640, 8640, 4320, 270, 8640, 4320, 270, 270, 270, 270, 270, 8640, 4320, 270, 8640, 270, 8640, 270, 270, 4320, 4320, 8640, 4320, 8640, 270, 4320, 270, 8640, 8640, 270, 8640, 4320, 270, 8640, 270, 270, 8640, 8640, 4320, 8640, 8640, 270, 8640, 4320, 4320, 270, 4320, 8640, 8640, 270, 8640, 4320, 270, 4320, 8640, 270, 270, 270, 270, 270, 270, 8640, 270, 270, 270, 8640, 270, 4320, 8640, 8640, 4320, 270, 8640, 270, 4320, 4320, 270, 4320, 270, 8640, 270, 270, 8640, 270, 8640, 8640, 4320, 8640, 4320, 270, 4320, 8640, 4320, 8640, 270, 8640, 270, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 270, 8640, 270, 8640, 4320, 4320, 270, 4320, 8640, 4320, 4320, 8640, 270, 8640, 8640, 4320, 270, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 270, 8640, 4320, 8640, 8640, 270, 8640, 4320, 4320, 8640, 270, 4320, 270, 270, 270, 270, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 270, 270, 270, 270]
Prompts retrieved: 1133190 . Total input tokens: 252353794 . Total output tokens: 222596229
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 78.04911952884868,
    "estimated_duration": 3600.0060517365173,
    "input_throughput": 6378.378166593313,
    "output_throughput": 5560.374263911116,
    "total_throughput": 11938.75243050443,
    "itl": 89.65681874365377,
    "ttft": 1847241.8772990964,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 499,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.7140922103682836,
    "arrivals": 378122,
    "finished_requests": 93200,
    "scheduler_time": 248.03803876152486
}
#Debug simulation 
Total elapsed time: 78.04928660392761. Arrivals time: 0.4622389804571867 Scheduler time: 77.37612437130883 Scheduler overhead time: 0.08143407246097922 Adapter cache time: 0.018078788183629513 Engine time: 0.07986960420385003 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_16-16-16/adapters_256_slots_32_rate_0.8-0.4-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_16-16-16/adapters_256_slots_32_rate_0.8-0.4-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 270, 8640, 8640, 270, 8640, 4320, 8640, 270, 4320, 270, 8640, 4320, 4320, 4320, 4320, 8640, 270, 270, 270, 4320, 8640, 270, 8640, 8640, 4320, 4320, 4320, 270, 8640, 270, 4320, 4320, 270, 4320, 270, 270, 4320, 4320, 8640, 4320, 270, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 270, 8640, 8640, 4320, 270, 270, 8640, 4320, 270, 4320, 4320, 8640, 4320, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 270, 4320, 270, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 270, 8640, 8640, 270, 8640, 270, 4320, 8640, 8640, 8640, 4320, 270, 8640, 4320, 270, 270, 270, 270, 270, 8640, 4320, 270, 8640, 270, 8640, 270, 270, 4320, 4320, 8640, 4320, 8640, 270, 4320, 270, 8640, 8640, 270, 8640, 4320, 270, 8640, 270, 270, 8640, 8640, 4320, 8640, 8640, 270, 8640, 4320, 4320, 270, 4320, 8640, 8640, 270, 8640, 4320, 270, 4320, 8640, 270, 270, 270, 270, 270, 270, 8640, 270, 270, 270, 8640, 270, 4320, 8640, 8640, 4320, 270, 8640, 270, 4320, 4320, 270, 4320, 270, 8640, 270, 270, 8640, 270, 8640, 8640, 4320, 8640, 4320, 270, 4320, 8640, 4320, 8640, 270, 8640, 270, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 270, 8640, 270, 8640, 4320, 4320, 270, 4320, 8640, 4320, 4320, 8640, 270, 8640, 8640, 4320, 270, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 270, 8640, 4320, 8640, 8640, 270, 8640, 4320, 4320, 8640, 270, 4320, 270, 270, 270, 270, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 270, 270, 270, 270]
Prompts retrieved: 1133190 . Total input tokens: 252353794 . Total output tokens: 222596229
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 81.91464909585193,
    "estimated_duration": 3600.063399518596,
    "input_throughput": 6512.5144749215115,
    "output_throughput": 5672.42482527689,
    "total_throughput": 12184.939300198403,
    "itl": 94.76572736680322,
    "ttft": 1828413.9287344469,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 486,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.1025855771172655,
    "arrivals": 378122,
    "finished_requests": 95153,
    "scheduler_time": 242.43233343187055
}
#Debug simulation 
Total elapsed time: 81.91481839492917. Arrivals time: 0.46357894456014037 Scheduler time: 81.24586343113333 Scheduler overhead time: 0.07855834579095244 Adapter cache time: 0.017594064585864544 Engine time: 0.078162947203964 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_16-16-32/adapters_256_slots_32_rate_0.8-0.4-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.025_size_16-16-32/adapters_256_slots_32_rate_0.8-0.4-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 270, 8640, 8640, 270, 8640, 4320, 8640, 270, 4320, 270, 8640, 4320, 4320, 4320, 4320, 8640, 270, 270, 270, 4320, 8640, 270, 8640, 8640, 4320, 4320, 4320, 270, 8640, 270, 4320, 4320, 270, 4320, 270, 270, 4320, 4320, 8640, 4320, 270, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 270, 8640, 8640, 4320, 270, 270, 8640, 4320, 270, 4320, 4320, 8640, 4320, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 270, 4320, 270, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 270, 8640, 8640, 270, 8640, 270, 4320, 8640, 8640, 8640, 4320, 270, 8640, 4320, 270, 270, 270, 270, 270, 8640, 4320, 270, 8640, 270, 8640, 270, 270, 4320, 4320, 8640, 4320, 8640, 270, 4320, 270, 8640, 8640, 270, 8640, 4320, 270, 8640, 270, 270, 8640, 8640, 4320, 8640, 8640, 270, 8640, 4320, 4320, 270, 4320, 8640, 8640, 270, 8640, 4320, 270, 4320, 8640, 270, 270, 270, 270, 270, 270, 8640, 270, 270, 270, 8640, 270, 4320, 8640, 8640, 4320, 270, 8640, 270, 4320, 4320, 270, 4320, 270, 8640, 270, 270, 8640, 270, 8640, 8640, 4320, 8640, 4320, 270, 4320, 8640, 4320, 8640, 270, 8640, 270, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 270, 8640, 270, 8640, 4320, 4320, 270, 4320, 8640, 4320, 4320, 8640, 270, 8640, 8640, 4320, 270, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 270, 8640, 4320, 8640, 8640, 270, 8640, 4320, 4320, 8640, 270, 4320, 270, 270, 270, 270, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 270, 270, 270, 270]
Prompts retrieved: 1133190 . Total input tokens: 252353794 . Total output tokens: 222596229
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 78.36545264115557,
    "estimated_duration": 3600.0742358215716,
    "input_throughput": 6382.756436342238,
    "output_throughput": 5561.4878162174455,
    "total_throughput": 11944.244252559683,
    "itl": 89.61324796371814,
    "ttft": 1848255.3426104044,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 502,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.703938979171247,
    "arrivals": 378122,
    "finished_requests": 93278,
    "scheduler_time": 248.07558199801935
}
#Debug simulation 
Total elapsed time: 78.36561167007312. Arrivals time: 0.4719060231000185 Scheduler time: 77.68157880241051 Scheduler overhead time: 0.08105738507583737 Adapter cache time: 0.018011549953371286 Engine time: 0.08148019667714834 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-8/adapters_256_slots_32_rate_0.8-0.4-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-8/adapters_256_slots_32_rate_0.8-0.4-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 135, 8640, 8640, 135, 8640, 4320, 8640, 135, 4320, 135, 8640, 4320, 4320, 4320, 4320, 8640, 135, 135, 135, 4320, 8640, 135, 8640, 8640, 4320, 4320, 4320, 135, 8640, 135, 4320, 4320, 135, 4320, 135, 135, 4320, 4320, 8640, 4320, 135, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 135, 8640, 8640, 4320, 135, 135, 8640, 4320, 135, 4320, 4320, 8640, 4320, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 135, 4320, 135, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 135, 8640, 8640, 135, 8640, 135, 4320, 8640, 8640, 8640, 4320, 135, 8640, 4320, 135, 135, 135, 135, 135, 8640, 4320, 135, 8640, 135, 8640, 135, 135, 4320, 4320, 8640, 4320, 8640, 135, 4320, 135, 8640, 8640, 135, 8640, 4320, 135, 8640, 135, 135, 8640, 8640, 4320, 8640, 8640, 135, 8640, 4320, 4320, 135, 4320, 8640, 8640, 135, 8640, 4320, 135, 4320, 8640, 135, 135, 135, 135, 135, 135, 8640, 135, 135, 135, 8640, 135, 4320, 8640, 8640, 4320, 135, 8640, 135, 4320, 4320, 135, 4320, 135, 8640, 135, 135, 8640, 135, 8640, 8640, 4320, 8640, 4320, 135, 4320, 8640, 4320, 8640, 135, 8640, 135, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 135, 8640, 135, 8640, 4320, 4320, 135, 4320, 8640, 4320, 4320, 8640, 135, 8640, 8640, 4320, 135, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 135, 8640, 4320, 8640, 8640, 135, 8640, 4320, 4320, 8640, 135, 4320, 135, 135, 135, 135, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 135, 135, 135, 135]
Prompts retrieved: 1121715 . Total input tokens: 249759382 . Total output tokens: 220336548
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 81.136598886922,
    "estimated_duration": 3600.0774018712355,
    "input_throughput": 6628.6591470495105,
    "output_throughput": 5763.718021511073,
    "total_throughput": 12392.377168560583,
    "itl": 97.48689329559444,
    "ttft": 1817142.823955341,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 512,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.38555342435841,
    "arrivals": 374287,
    "finished_requests": 96336,
    "scheduler_time": 238.04177739457558
}
#Debug simulation 
Total elapsed time: 81.13678166409954. Arrivals time: 0.47695624828338623 Scheduler time: 80.45628518145531 Scheduler overhead time: 0.07789709838107228 Adapter cache time: 0.017926462925970554 Engine time: 0.07745769247412682 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-16/adapters_256_slots_32_rate_0.8-0.4-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-16/adapters_256_slots_32_rate_0.8-0.4-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 135, 8640, 8640, 135, 8640, 4320, 8640, 135, 4320, 135, 8640, 4320, 4320, 4320, 4320, 8640, 135, 135, 135, 4320, 8640, 135, 8640, 8640, 4320, 4320, 4320, 135, 8640, 135, 4320, 4320, 135, 4320, 135, 135, 4320, 4320, 8640, 4320, 135, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 135, 8640, 8640, 4320, 135, 135, 8640, 4320, 135, 4320, 4320, 8640, 4320, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 135, 4320, 135, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 135, 8640, 8640, 135, 8640, 135, 4320, 8640, 8640, 8640, 4320, 135, 8640, 4320, 135, 135, 135, 135, 135, 8640, 4320, 135, 8640, 135, 8640, 135, 135, 4320, 4320, 8640, 4320, 8640, 135, 4320, 135, 8640, 8640, 135, 8640, 4320, 135, 8640, 135, 135, 8640, 8640, 4320, 8640, 8640, 135, 8640, 4320, 4320, 135, 4320, 8640, 8640, 135, 8640, 4320, 135, 4320, 8640, 135, 135, 135, 135, 135, 135, 8640, 135, 135, 135, 8640, 135, 4320, 8640, 8640, 4320, 135, 8640, 135, 4320, 4320, 135, 4320, 135, 8640, 135, 135, 8640, 135, 8640, 8640, 4320, 8640, 4320, 135, 4320, 8640, 4320, 8640, 135, 8640, 135, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 135, 8640, 135, 8640, 4320, 4320, 135, 4320, 8640, 4320, 4320, 8640, 135, 8640, 8640, 4320, 135, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 135, 8640, 4320, 8640, 8640, 135, 8640, 4320, 4320, 8640, 135, 4320, 135, 135, 135, 135, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 135, 135, 135, 135]
Prompts retrieved: 1121715 . Total input tokens: 249759382 . Total output tokens: 220336548
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 81.97355806315318,
    "estimated_duration": 3600.0588565831545,
    "input_throughput": 6567.032913022576,
    "output_throughput": 5696.038819615989,
    "total_throughput": 12263.071732638566,
    "itl": 94.90732977470108,
    "ttft": 1822319.304042811,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 462,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.381108197243889,
    "arrivals": 374287,
    "finished_requests": 95277,
    "scheduler_time": 241.30761050479109
}
#Debug simulation 
Total elapsed time: 81.97372987121344. Arrivals time: 0.46901592379435897 Scheduler time: 81.29706100793555 Scheduler overhead time: 0.07986870408058167 Adapter cache time: 0.01765793701633811 Engine time: 0.07932853745296597 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-32/adapters_256_slots_32_rate_0.8-0.4-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-32/adapters_256_slots_32_rate_0.8-0.4-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 135, 8640, 8640, 135, 8640, 4320, 8640, 135, 4320, 135, 8640, 4320, 4320, 4320, 4320, 8640, 135, 135, 135, 4320, 8640, 135, 8640, 8640, 4320, 4320, 4320, 135, 8640, 135, 4320, 4320, 135, 4320, 135, 135, 4320, 4320, 8640, 4320, 135, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 135, 8640, 8640, 4320, 135, 135, 8640, 4320, 135, 4320, 4320, 8640, 4320, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 135, 4320, 135, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 135, 8640, 8640, 135, 8640, 135, 4320, 8640, 8640, 8640, 4320, 135, 8640, 4320, 135, 135, 135, 135, 135, 8640, 4320, 135, 8640, 135, 8640, 135, 135, 4320, 4320, 8640, 4320, 8640, 135, 4320, 135, 8640, 8640, 135, 8640, 4320, 135, 8640, 135, 135, 8640, 8640, 4320, 8640, 8640, 135, 8640, 4320, 4320, 135, 4320, 8640, 8640, 135, 8640, 4320, 135, 4320, 8640, 135, 135, 135, 135, 135, 135, 8640, 135, 135, 135, 8640, 135, 4320, 8640, 8640, 4320, 135, 8640, 135, 4320, 4320, 135, 4320, 135, 8640, 135, 135, 8640, 135, 8640, 8640, 4320, 8640, 4320, 135, 4320, 8640, 4320, 8640, 135, 8640, 135, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 135, 8640, 135, 8640, 4320, 4320, 135, 4320, 8640, 4320, 4320, 8640, 135, 8640, 8640, 4320, 135, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 135, 8640, 4320, 8640, 8640, 135, 8640, 4320, 4320, 8640, 135, 4320, 135, 135, 135, 135, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 135, 135, 135, 135]
Prompts retrieved: 1121715 . Total input tokens: 249759382 . Total output tokens: 220336548
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 78.57275014463812,
    "estimated_duration": 3600.001754137371,
    "input_throughput": 6363.736899203135,
    "output_throughput": 5539.262578714584,
    "total_throughput": 11902.99947791772,
    "itl": 89.0918116021148,
    "ttft": 1837396.4100307252,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 509,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.815097840931299,
    "arrivals": 374287,
    "finished_requests": 92486,
    "scheduler_time": 249.01168192899632
}
#Debug simulation 
Total elapsed time: 78.57291626976803. Arrivals time: 0.46454715821892023 Scheduler time: 77.89758122619241 Scheduler overhead time: 0.08091507805511355 Adapter cache time: 0.018596446607261896 Engine time: 0.07973137171939015 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_8-16-16/adapters_256_slots_32_rate_0.8-0.4-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_8-16-16/adapters_256_slots_32_rate_0.8-0.4-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 135, 8640, 8640, 135, 8640, 4320, 8640, 135, 4320, 135, 8640, 4320, 4320, 4320, 4320, 8640, 135, 135, 135, 4320, 8640, 135, 8640, 8640, 4320, 4320, 4320, 135, 8640, 135, 4320, 4320, 135, 4320, 135, 135, 4320, 4320, 8640, 4320, 135, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 135, 8640, 8640, 4320, 135, 135, 8640, 4320, 135, 4320, 4320, 8640, 4320, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 135, 4320, 135, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 135, 8640, 8640, 135, 8640, 135, 4320, 8640, 8640, 8640, 4320, 135, 8640, 4320, 135, 135, 135, 135, 135, 8640, 4320, 135, 8640, 135, 8640, 135, 135, 4320, 4320, 8640, 4320, 8640, 135, 4320, 135, 8640, 8640, 135, 8640, 4320, 135, 8640, 135, 135, 8640, 8640, 4320, 8640, 8640, 135, 8640, 4320, 4320, 135, 4320, 8640, 8640, 135, 8640, 4320, 135, 4320, 8640, 135, 135, 135, 135, 135, 135, 8640, 135, 135, 135, 8640, 135, 4320, 8640, 8640, 4320, 135, 8640, 135, 4320, 4320, 135, 4320, 135, 8640, 135, 135, 8640, 135, 8640, 8640, 4320, 8640, 4320, 135, 4320, 8640, 4320, 8640, 135, 8640, 135, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 135, 8640, 135, 8640, 4320, 4320, 135, 4320, 8640, 4320, 4320, 8640, 135, 8640, 8640, 4320, 135, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 135, 8640, 4320, 8640, 8640, 135, 8640, 4320, 4320, 8640, 135, 4320, 135, 135, 135, 135, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 135, 135, 135, 135]
Prompts retrieved: 1121715 . Total input tokens: 249759382 . Total output tokens: 220336548
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 80.44187739491463,
    "estimated_duration": 3600.0775725714216,
    "input_throughput": 6554.488764292278,
    "output_throughput": 5696.849466871626,
    "total_throughput": 12251.338231163903,
    "itl": 94.83160095007165,
    "ttft": 1825335.1183002638,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 500,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.418240488935257,
    "arrivals": 374287,
    "finished_requests": 95158,
    "scheduler_time": 241.3168551180932
}
#Debug simulation 
Total elapsed time: 80.44205143023282. Arrivals time: 0.4683139971457422 Scheduler time: 79.76626190869138 Scheduler overhead time: 0.0794596429914236 Adapter cache time: 0.018562808632850647 Engine time: 0.07841521967202425 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_8-16-32/adapters_256_slots_32_rate_0.8-0.4-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_8-16-32/adapters_256_slots_32_rate_0.8-0.4-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 135, 8640, 8640, 135, 8640, 4320, 8640, 135, 4320, 135, 8640, 4320, 4320, 4320, 4320, 8640, 135, 135, 135, 4320, 8640, 135, 8640, 8640, 4320, 4320, 4320, 135, 8640, 135, 4320, 4320, 135, 4320, 135, 135, 4320, 4320, 8640, 4320, 135, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 135, 8640, 8640, 4320, 135, 135, 8640, 4320, 135, 4320, 4320, 8640, 4320, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 135, 4320, 135, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 135, 8640, 8640, 135, 8640, 135, 4320, 8640, 8640, 8640, 4320, 135, 8640, 4320, 135, 135, 135, 135, 135, 8640, 4320, 135, 8640, 135, 8640, 135, 135, 4320, 4320, 8640, 4320, 8640, 135, 4320, 135, 8640, 8640, 135, 8640, 4320, 135, 8640, 135, 135, 8640, 8640, 4320, 8640, 8640, 135, 8640, 4320, 4320, 135, 4320, 8640, 8640, 135, 8640, 4320, 135, 4320, 8640, 135, 135, 135, 135, 135, 135, 8640, 135, 135, 135, 8640, 135, 4320, 8640, 8640, 4320, 135, 8640, 135, 4320, 4320, 135, 4320, 135, 8640, 135, 135, 8640, 135, 8640, 8640, 4320, 8640, 4320, 135, 4320, 8640, 4320, 8640, 135, 8640, 135, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 135, 8640, 135, 8640, 4320, 4320, 135, 4320, 8640, 4320, 4320, 8640, 135, 8640, 8640, 4320, 135, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 135, 8640, 4320, 8640, 8640, 135, 8640, 4320, 4320, 8640, 135, 4320, 135, 135, 135, 135, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 135, 135, 135, 135]
Prompts retrieved: 1121715 . Total input tokens: 249759382 . Total output tokens: 220336548
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 79.74419291317463,
    "estimated_duration": 3600.0367569831383,
    "input_throughput": 6371.923552031511,
    "output_throughput": 5538.464284100472,
    "total_throughput": 11910.387836131982,
    "itl": 89.15532905022648,
    "ttft": 1841265.5731837961,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 486,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.620598797937885,
    "arrivals": 374287,
    "finished_requests": 92522,
    "scheduler_time": 249.05128312853356
}
#Debug simulation 
Total elapsed time: 79.74436383321881. Arrivals time: 0.4639610666781664 Scheduler time: 79.06901628058404 Scheduler overhead time: 0.08154434897005558 Adapter cache time: 0.017949935048818588 Engine time: 0.08019081922248006 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_16-16-16/adapters_256_slots_32_rate_0.8-0.4-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_16-16-16/adapters_256_slots_32_rate_0.8-0.4-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 135, 8640, 8640, 135, 8640, 4320, 8640, 135, 4320, 135, 8640, 4320, 4320, 4320, 4320, 8640, 135, 135, 135, 4320, 8640, 135, 8640, 8640, 4320, 4320, 4320, 135, 8640, 135, 4320, 4320, 135, 4320, 135, 135, 4320, 4320, 8640, 4320, 135, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 135, 8640, 8640, 4320, 135, 135, 8640, 4320, 135, 4320, 4320, 8640, 4320, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 135, 4320, 135, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 135, 8640, 8640, 135, 8640, 135, 4320, 8640, 8640, 8640, 4320, 135, 8640, 4320, 135, 135, 135, 135, 135, 8640, 4320, 135, 8640, 135, 8640, 135, 135, 4320, 4320, 8640, 4320, 8640, 135, 4320, 135, 8640, 8640, 135, 8640, 4320, 135, 8640, 135, 135, 8640, 8640, 4320, 8640, 8640, 135, 8640, 4320, 4320, 135, 4320, 8640, 8640, 135, 8640, 4320, 135, 4320, 8640, 135, 135, 135, 135, 135, 135, 8640, 135, 135, 135, 8640, 135, 4320, 8640, 8640, 4320, 135, 8640, 135, 4320, 4320, 135, 4320, 135, 8640, 135, 135, 8640, 135, 8640, 8640, 4320, 8640, 4320, 135, 4320, 8640, 4320, 8640, 135, 8640, 135, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 135, 8640, 135, 8640, 4320, 4320, 135, 4320, 8640, 4320, 4320, 8640, 135, 8640, 8640, 4320, 135, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 135, 8640, 4320, 8640, 8640, 135, 8640, 4320, 4320, 8640, 135, 4320, 135, 135, 135, 135, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 135, 135, 135, 135]
Prompts retrieved: 1121715 . Total input tokens: 249759382 . Total output tokens: 220336548
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 79.84932196093723,
    "estimated_duration": 3600.024727912534,
    "input_throughput": 6543.235888732014,
    "output_throughput": 5692.753675023624,
    "total_throughput": 12235.989563755638,
    "itl": 94.95335091310646,
    "ttft": 1823191.4484088637,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 507,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.236647916869246,
    "arrivals": 374287,
    "finished_requests": 95041,
    "scheduler_time": 241.5110401240738
}
#Debug simulation 
Total elapsed time: 79.84948676126078. Arrivals time: 0.46908313129097223 Scheduler time: 79.1763327755034 Scheduler overhead time: 0.07863618200644851 Adapter cache time: 0.017534319311380386 Engine time: 0.077350661624223 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_16-16-32/adapters_256_slots_32_rate_0.8-0.4-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.0125_size_16-16-32/adapters_256_slots_32_rate_0.8-0.4-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 135, 8640, 8640, 135, 8640, 4320, 8640, 135, 4320, 135, 8640, 4320, 4320, 4320, 4320, 8640, 135, 135, 135, 4320, 8640, 135, 8640, 8640, 4320, 4320, 4320, 135, 8640, 135, 4320, 4320, 135, 4320, 135, 135, 4320, 4320, 8640, 4320, 135, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 135, 8640, 8640, 4320, 135, 135, 8640, 4320, 135, 4320, 4320, 8640, 4320, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 135, 4320, 135, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 135, 8640, 8640, 135, 8640, 135, 4320, 8640, 8640, 8640, 4320, 135, 8640, 4320, 135, 135, 135, 135, 135, 8640, 4320, 135, 8640, 135, 8640, 135, 135, 4320, 4320, 8640, 4320, 8640, 135, 4320, 135, 8640, 8640, 135, 8640, 4320, 135, 8640, 135, 135, 8640, 8640, 4320, 8640, 8640, 135, 8640, 4320, 4320, 135, 4320, 8640, 8640, 135, 8640, 4320, 135, 4320, 8640, 135, 135, 135, 135, 135, 135, 8640, 135, 135, 135, 8640, 135, 4320, 8640, 8640, 4320, 135, 8640, 135, 4320, 4320, 135, 4320, 135, 8640, 135, 135, 8640, 135, 8640, 8640, 4320, 8640, 4320, 135, 4320, 8640, 4320, 8640, 135, 8640, 135, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 135, 8640, 135, 8640, 4320, 4320, 135, 4320, 8640, 4320, 4320, 8640, 135, 8640, 8640, 4320, 135, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 135, 8640, 4320, 8640, 8640, 135, 8640, 4320, 4320, 8640, 135, 4320, 135, 135, 135, 135, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 135, 135, 135, 135]
Prompts retrieved: 1121715 . Total input tokens: 249759382 . Total output tokens: 220336548
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 79.15738238021731,
    "estimated_duration": 3600.0895375964724,
    "input_throughput": 6372.512616815778,
    "output_throughput": 5547.8259058340955,
    "total_throughput": 11920.338522649874,
    "itl": 89.32802240754117,
    "ttft": 1837165.5622281604,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 513,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.7859924296848804,
    "arrivals": 374287,
    "finished_requests": 92631,
    "scheduler_time": 248.53932266222782
}
#Debug simulation 
Total elapsed time: 79.15754938684404. Arrivals time: 0.44732843339443207 Scheduler time: 78.49896954745054 Scheduler overhead time: 0.08044842770323157 Adapter cache time: 0.018537347204983234 Engine time: 0.0802456047385931 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-8/adapters_256_slots_32_rate_0.8-0.4-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-8/adapters_256_slots_32_rate_0.8-0.4-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 66, 8640, 8640, 66, 8640, 4320, 8640, 66, 4320, 66, 8640, 4320, 4320, 4320, 4320, 8640, 66, 66, 66, 4320, 8640, 66, 8640, 8640, 4320, 4320, 4320, 66, 8640, 66, 4320, 4320, 66, 4320, 66, 66, 4320, 4320, 8640, 4320, 66, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 66, 8640, 8640, 4320, 66, 66, 8640, 4320, 66, 4320, 4320, 8640, 4320, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 66, 4320, 66, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 66, 8640, 8640, 66, 8640, 66, 4320, 8640, 8640, 8640, 4320, 66, 8640, 4320, 66, 66, 66, 66, 66, 8640, 4320, 66, 8640, 66, 8640, 66, 66, 4320, 4320, 8640, 4320, 8640, 66, 4320, 66, 8640, 8640, 66, 8640, 4320, 66, 8640, 66, 66, 8640, 8640, 4320, 8640, 8640, 66, 8640, 4320, 4320, 66, 4320, 8640, 8640, 66, 8640, 4320, 66, 4320, 8640, 66, 66, 66, 66, 66, 66, 8640, 66, 66, 66, 8640, 66, 4320, 8640, 8640, 4320, 66, 8640, 66, 4320, 4320, 66, 4320, 66, 8640, 66, 66, 8640, 66, 8640, 8640, 4320, 8640, 4320, 66, 4320, 8640, 4320, 8640, 66, 8640, 66, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 66, 8640, 66, 8640, 4320, 4320, 66, 4320, 8640, 4320, 4320, 8640, 66, 8640, 8640, 4320, 66, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 66, 8640, 4320, 8640, 8640, 66, 8640, 4320, 4320, 8640, 66, 4320, 66, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 66, 66, 66, 66]
Prompts retrieved: 1115850 . Total input tokens: 248489857 . Total output tokens: 219174347
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 84.73107187496498,
    "estimated_duration": 3600.0739871573287,
    "input_throughput": 6555.949984415851,
    "output_throughput": 5756.098367401248,
    "total_throughput": 12312.048351817099,
    "itl": 97.40374056193194,
    "ttft": 1818396.5106590092,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 445,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.94252201921775,
    "arrivals": 372356,
    "finished_requests": 95804,
    "scheduler_time": 238.26437097767496
}
#Debug simulation 
Total elapsed time: 84.73124015610665. Arrivals time: 0.46706221299245954 Scheduler time: 84.06297216145322 Scheduler overhead time: 0.07747143041342497 Adapter cache time: 0.017267365474253893 Engine time: 0.07663396932184696 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-16/adapters_256_slots_32_rate_0.8-0.4-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-16/adapters_256_slots_32_rate_0.8-0.4-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 66, 8640, 8640, 66, 8640, 4320, 8640, 66, 4320, 66, 8640, 4320, 4320, 4320, 4320, 8640, 66, 66, 66, 4320, 8640, 66, 8640, 8640, 4320, 4320, 4320, 66, 8640, 66, 4320, 4320, 66, 4320, 66, 66, 4320, 4320, 8640, 4320, 66, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 66, 8640, 8640, 4320, 66, 66, 8640, 4320, 66, 4320, 4320, 8640, 4320, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 66, 4320, 66, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 66, 8640, 8640, 66, 8640, 66, 4320, 8640, 8640, 8640, 4320, 66, 8640, 4320, 66, 66, 66, 66, 66, 8640, 4320, 66, 8640, 66, 8640, 66, 66, 4320, 4320, 8640, 4320, 8640, 66, 4320, 66, 8640, 8640, 66, 8640, 4320, 66, 8640, 66, 66, 8640, 8640, 4320, 8640, 8640, 66, 8640, 4320, 4320, 66, 4320, 8640, 8640, 66, 8640, 4320, 66, 4320, 8640, 66, 66, 66, 66, 66, 66, 8640, 66, 66, 66, 8640, 66, 4320, 8640, 8640, 4320, 66, 8640, 66, 4320, 4320, 66, 4320, 66, 8640, 66, 66, 8640, 66, 8640, 8640, 4320, 8640, 4320, 66, 4320, 8640, 4320, 8640, 66, 8640, 66, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 66, 8640, 66, 8640, 4320, 4320, 66, 4320, 8640, 4320, 4320, 8640, 66, 8640, 8640, 4320, 66, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 66, 8640, 4320, 8640, 8640, 66, 8640, 4320, 4320, 8640, 66, 4320, 66, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 66, 66, 66, 66]
Prompts retrieved: 1115850 . Total input tokens: 248489857 . Total output tokens: 219174347
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 82.10228261398152,
    "estimated_duration": 3600.0336459568875,
    "input_throughput": 6474.279212966868,
    "output_throughput": 5687.033515087648,
    "total_throughput": 12161.312728054516,
    "itl": 94.5082213586697,
    "ttft": 1831728.788759697,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 438,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.194576791310687,
    "arrivals": 372356,
    "finished_requests": 94709,
    "scheduler_time": 241.7270782940468
}
#Debug simulation 
Total elapsed time: 82.10245176265016. Arrivals time: 0.4618609705939889 Scheduler time: 81.43529251497239 Scheduler overhead time: 0.07860435638576746 Adapter cache time: 0.017044270876795053 Engine time: 0.07889295881614089 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-32/adapters_256_slots_32_rate_0.8-0.4-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-32/adapters_256_slots_32_rate_0.8-0.4-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 66, 8640, 8640, 66, 8640, 4320, 8640, 66, 4320, 66, 8640, 4320, 4320, 4320, 4320, 8640, 66, 66, 66, 4320, 8640, 66, 8640, 8640, 4320, 4320, 4320, 66, 8640, 66, 4320, 4320, 66, 4320, 66, 66, 4320, 4320, 8640, 4320, 66, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 66, 8640, 8640, 4320, 66, 66, 8640, 4320, 66, 4320, 4320, 8640, 4320, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 66, 4320, 66, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 66, 8640, 8640, 66, 8640, 66, 4320, 8640, 8640, 8640, 4320, 66, 8640, 4320, 66, 66, 66, 66, 66, 8640, 4320, 66, 8640, 66, 8640, 66, 66, 4320, 4320, 8640, 4320, 8640, 66, 4320, 66, 8640, 8640, 66, 8640, 4320, 66, 8640, 66, 66, 8640, 8640, 4320, 8640, 8640, 66, 8640, 4320, 4320, 66, 4320, 8640, 8640, 66, 8640, 4320, 66, 4320, 8640, 66, 66, 66, 66, 66, 66, 8640, 66, 66, 66, 8640, 66, 4320, 8640, 8640, 4320, 66, 8640, 66, 4320, 4320, 66, 4320, 66, 8640, 66, 66, 8640, 66, 8640, 8640, 4320, 8640, 4320, 66, 4320, 8640, 4320, 8640, 66, 8640, 66, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 66, 8640, 66, 8640, 4320, 4320, 66, 4320, 8640, 4320, 4320, 8640, 66, 8640, 8640, 4320, 66, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 66, 8640, 4320, 8640, 8640, 66, 8640, 4320, 4320, 8640, 66, 4320, 66, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 66, 66, 66, 66]
Prompts retrieved: 1115850 . Total input tokens: 248489857 . Total output tokens: 219174347
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 79.60833101300523,
    "estimated_duration": 3600.058529979677,
    "input_throughput": 6346.532093779314,
    "output_throughput": 5578.100420526597,
    "total_throughput": 11924.632514305911,
    "itl": 89.83240747376831,
    "ttft": 1836480.227059935,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 526,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.9506822818890543,
    "arrivals": 372356,
    "finished_requests": 92720,
    "scheduler_time": 246.75307603414856
}
#Debug simulation 
Total elapsed time: 79.60850134026259. Arrivals time: 0.4541923222132027 Scheduler time: 78.94348941929638 Scheduler overhead time: 0.08066653925925493 Adapter cache time: 0.018373177386820316 Engine time: 0.07995639089494944 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_8-16-16/adapters_256_slots_32_rate_0.8-0.4-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_8-16-16/adapters_256_slots_32_rate_0.8-0.4-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 66, 8640, 8640, 66, 8640, 4320, 8640, 66, 4320, 66, 8640, 4320, 4320, 4320, 4320, 8640, 66, 66, 66, 4320, 8640, 66, 8640, 8640, 4320, 4320, 4320, 66, 8640, 66, 4320, 4320, 66, 4320, 66, 66, 4320, 4320, 8640, 4320, 66, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 66, 8640, 8640, 4320, 66, 66, 8640, 4320, 66, 4320, 4320, 8640, 4320, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 66, 4320, 66, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 66, 8640, 8640, 66, 8640, 66, 4320, 8640, 8640, 8640, 4320, 66, 8640, 4320, 66, 66, 66, 66, 66, 8640, 4320, 66, 8640, 66, 8640, 66, 66, 4320, 4320, 8640, 4320, 8640, 66, 4320, 66, 8640, 8640, 66, 8640, 4320, 66, 8640, 66, 66, 8640, 8640, 4320, 8640, 8640, 66, 8640, 4320, 4320, 66, 4320, 8640, 8640, 66, 8640, 4320, 66, 4320, 8640, 66, 66, 66, 66, 66, 66, 8640, 66, 66, 66, 8640, 66, 4320, 8640, 8640, 4320, 66, 8640, 66, 4320, 4320, 66, 4320, 66, 8640, 66, 66, 8640, 66, 8640, 8640, 4320, 8640, 4320, 66, 4320, 8640, 4320, 8640, 66, 8640, 66, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 66, 8640, 66, 8640, 4320, 4320, 66, 4320, 8640, 4320, 4320, 8640, 66, 8640, 8640, 4320, 66, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 66, 8640, 4320, 8640, 8640, 66, 8640, 4320, 4320, 8640, 66, 4320, 66, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 66, 66, 66, 66]
Prompts retrieved: 1115850 . Total input tokens: 248489857 . Total output tokens: 219174347
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 85.4096571537666,
    "estimated_duration": 3600.0217524869813,
    "input_throughput": 6208.382208957451,
    "output_throughput": 5462.745047697074,
    "total_throughput": 11671.127256654525,
    "itl": 86.35007070228393,
    "ttft": 1848078.1109086773,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 425,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.8964115682197695,
    "arrivals": 372356,
    "finished_requests": 90657,
    "scheduler_time": 253.0997626475558
}
#Debug simulation 
Total elapsed time: 85.40982438065112. Arrivals time: 0.4483592235483229 Scheduler time: 84.7457335498184 Scheduler overhead time: 0.08248230069875717 Adapter cache time: 0.018145659938454628 Engine time: 0.08259500004351139 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_8-16-32/adapters_256_slots_32_rate_0.8-0.4-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_8-16-32/adapters_256_slots_32_rate_0.8-0.4-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 66, 8640, 8640, 66, 8640, 4320, 8640, 66, 4320, 66, 8640, 4320, 4320, 4320, 4320, 8640, 66, 66, 66, 4320, 8640, 66, 8640, 8640, 4320, 4320, 4320, 66, 8640, 66, 4320, 4320, 66, 4320, 66, 66, 4320, 4320, 8640, 4320, 66, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 66, 8640, 8640, 4320, 66, 66, 8640, 4320, 66, 4320, 4320, 8640, 4320, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 66, 4320, 66, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 66, 8640, 8640, 66, 8640, 66, 4320, 8640, 8640, 8640, 4320, 66, 8640, 4320, 66, 66, 66, 66, 66, 8640, 4320, 66, 8640, 66, 8640, 66, 66, 4320, 4320, 8640, 4320, 8640, 66, 4320, 66, 8640, 8640, 66, 8640, 4320, 66, 8640, 66, 66, 8640, 8640, 4320, 8640, 8640, 66, 8640, 4320, 4320, 66, 4320, 8640, 8640, 66, 8640, 4320, 66, 4320, 8640, 66, 66, 66, 66, 66, 66, 8640, 66, 66, 66, 8640, 66, 4320, 8640, 8640, 4320, 66, 8640, 66, 4320, 4320, 66, 4320, 66, 8640, 66, 66, 8640, 66, 8640, 8640, 4320, 8640, 4320, 66, 4320, 8640, 4320, 8640, 66, 8640, 66, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 66, 8640, 66, 8640, 4320, 4320, 66, 4320, 8640, 4320, 4320, 8640, 66, 8640, 8640, 4320, 66, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 66, 8640, 4320, 8640, 8640, 66, 8640, 4320, 4320, 8640, 66, 4320, 66, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 66, 66, 66, 66]
Prompts retrieved: 1115850 . Total input tokens: 248489857 . Total output tokens: 219174347
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 80.010367766954,
    "estimated_duration": 3600.0026677872675,
    "input_throughput": 5886.235637993198,
    "output_throughput": 5162.138396809142,
    "total_throughput": 11048.37403480234,
    "itl": 77.41004047303677,
    "ttft": 1884393.392068057,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 417,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.0975773732783476,
    "arrivals": 372356,
    "finished_requests": 85859,
    "scheduler_time": 267.099424525061
}
#Debug simulation 
Total elapsed time: 80.0105418250896. Arrivals time: 0.42769878078252077 Scheduler time: 79.35596752446145 Scheduler overhead time: 0.08733524475246668 Adapter cache time: 0.01856487523764372 Engine time: 0.08589805010706186 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_16-16-16/adapters_256_slots_32_rate_0.8-0.4-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_16-16-16/adapters_256_slots_32_rate_0.8-0.4-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 66, 8640, 8640, 66, 8640, 4320, 8640, 66, 4320, 66, 8640, 4320, 4320, 4320, 4320, 8640, 66, 66, 66, 4320, 8640, 66, 8640, 8640, 4320, 4320, 4320, 66, 8640, 66, 4320, 4320, 66, 4320, 66, 66, 4320, 4320, 8640, 4320, 66, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 66, 8640, 8640, 4320, 66, 66, 8640, 4320, 66, 4320, 4320, 8640, 4320, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 66, 4320, 66, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 66, 8640, 8640, 66, 8640, 66, 4320, 8640, 8640, 8640, 4320, 66, 8640, 4320, 66, 66, 66, 66, 66, 8640, 4320, 66, 8640, 66, 8640, 66, 66, 4320, 4320, 8640, 4320, 8640, 66, 4320, 66, 8640, 8640, 66, 8640, 4320, 66, 8640, 66, 66, 8640, 8640, 4320, 8640, 8640, 66, 8640, 4320, 4320, 66, 4320, 8640, 8640, 66, 8640, 4320, 66, 4320, 8640, 66, 66, 66, 66, 66, 66, 8640, 66, 66, 66, 8640, 66, 4320, 8640, 8640, 4320, 66, 8640, 66, 4320, 4320, 66, 4320, 66, 8640, 66, 66, 8640, 66, 8640, 8640, 4320, 8640, 4320, 66, 4320, 8640, 4320, 8640, 66, 8640, 66, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 66, 8640, 66, 8640, 4320, 4320, 66, 4320, 8640, 4320, 4320, 8640, 66, 8640, 8640, 4320, 66, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 66, 8640, 4320, 8640, 8640, 66, 8640, 4320, 4320, 8640, 66, 4320, 66, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 66, 66, 66, 66]
Prompts retrieved: 1115850 . Total input tokens: 248489857 . Total output tokens: 219174347
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 81.16172615485266,
    "estimated_duration": 3600.0634070295814,
    "input_throughput": 6510.624494622243,
    "output_throughput": 5717.1248594708095,
    "total_throughput": 12227.749354093054,
    "itl": 95.30557827303126,
    "ttft": 1826278.1806826568,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 483,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.083433814295554,
    "arrivals": 372356,
    "finished_requests": 95074,
    "scheduler_time": 240.1311006714781
}
#Debug simulation 
Total elapsed time: 81.16190144699067. Arrivals time: 0.4549719407223165 Scheduler time: 80.50066899415106 Scheduler overhead time: 0.07971511874347925 Adapter cache time: 0.017648252192884684 Engine time: 0.07842791685834527 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_16-16-32/adapters_256_slots_32_rate_0.8-0.4-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.00625_size_16-16-32/adapters_256_slots_32_rate_0.8-0.4-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 66, 8640, 8640, 66, 8640, 4320, 8640, 66, 4320, 66, 8640, 4320, 4320, 4320, 4320, 8640, 66, 66, 66, 4320, 8640, 66, 8640, 8640, 4320, 4320, 4320, 66, 8640, 66, 4320, 4320, 66, 4320, 66, 66, 4320, 4320, 8640, 4320, 66, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 66, 8640, 8640, 4320, 66, 66, 8640, 4320, 66, 4320, 4320, 8640, 4320, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 66, 4320, 66, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 66, 8640, 8640, 66, 8640, 66, 4320, 8640, 8640, 8640, 4320, 66, 8640, 4320, 66, 66, 66, 66, 66, 8640, 4320, 66, 8640, 66, 8640, 66, 66, 4320, 4320, 8640, 4320, 8640, 66, 4320, 66, 8640, 8640, 66, 8640, 4320, 66, 8640, 66, 66, 8640, 8640, 4320, 8640, 8640, 66, 8640, 4320, 4320, 66, 4320, 8640, 8640, 66, 8640, 4320, 66, 4320, 8640, 66, 66, 66, 66, 66, 66, 8640, 66, 66, 66, 8640, 66, 4320, 8640, 8640, 4320, 66, 8640, 66, 4320, 4320, 66, 4320, 66, 8640, 66, 66, 8640, 66, 8640, 8640, 4320, 8640, 4320, 66, 4320, 8640, 4320, 8640, 66, 8640, 66, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 66, 8640, 66, 8640, 4320, 4320, 66, 4320, 8640, 4320, 4320, 8640, 66, 8640, 8640, 4320, 66, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 66, 8640, 4320, 8640, 8640, 66, 8640, 4320, 4320, 8640, 66, 4320, 66, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 66, 66, 66, 66]
Prompts retrieved: 1115850 . Total input tokens: 248489857 . Total output tokens: 219174347
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 79.9097449220717,
    "estimated_duration": 3600.015763927347,
    "input_throughput": 5842.11664036048,
    "output_throughput": 5137.385281842128,
    "total_throughput": 10979.50192220261,
    "itl": 76.61659067069769,
    "ttft": 1885181.832133058,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 416,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.063249287456295,
    "arrivals": 372356,
    "finished_requests": 85298,
    "scheduler_time": 268.348094234498
}
#Debug simulation 
Total elapsed time: 79.90991089073941. Arrivals time: 0.43379843700677156 Scheduler time: 79.25020913034678 Scheduler overhead time: 0.08673427859321237 Adapter cache time: 0.018228603526949883 Engine time: 0.08614120446145535 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-8/adapters_256_slots_32_rate_0.8-0.4-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-8/adapters_256_slots_32_rate_0.8-0.4-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 33, 8640, 8640, 33, 8640, 4320, 8640, 33, 4320, 33, 8640, 4320, 4320, 4320, 4320, 8640, 33, 33, 33, 4320, 8640, 33, 8640, 8640, 4320, 4320, 4320, 33, 8640, 33, 4320, 4320, 33, 4320, 33, 33, 4320, 4320, 8640, 4320, 33, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 33, 8640, 8640, 4320, 33, 33, 8640, 4320, 33, 4320, 4320, 8640, 4320, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 4320, 33, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 33, 8640, 8640, 33, 8640, 33, 4320, 8640, 8640, 8640, 4320, 33, 8640, 4320, 33, 33, 33, 33, 33, 8640, 4320, 33, 8640, 33, 8640, 33, 33, 4320, 4320, 8640, 4320, 8640, 33, 4320, 33, 8640, 8640, 33, 8640, 4320, 33, 8640, 33, 33, 8640, 8640, 4320, 8640, 8640, 33, 8640, 4320, 4320, 33, 4320, 8640, 8640, 33, 8640, 4320, 33, 4320, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 4320, 8640, 8640, 4320, 33, 8640, 33, 4320, 4320, 33, 4320, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 4320, 8640, 4320, 33, 4320, 8640, 4320, 8640, 33, 8640, 33, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 33, 8640, 33, 8640, 4320, 4320, 33, 4320, 8640, 4320, 4320, 8640, 33, 8640, 8640, 4320, 33, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 33, 8640, 4320, 8640, 8640, 33, 8640, 4320, 4320, 8640, 33, 4320, 33, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 33, 33, 33, 33]
Prompts retrieved: 1113045 . Total input tokens: 247844840 . Total output tokens: 218638540
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 81.2665377757512,
    "estimated_duration": 3600.10159990848,
    "input_throughput": 6566.972998928978,
    "output_throughput": 5727.2878078008025,
    "total_throughput": 12294.26080672978,
    "itl": 96.87561321462857,
    "ttft": 1823072.9097536406,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 450,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.9755840643775007,
    "arrivals": 371350,
    "finished_requests": 95963,
    "scheduler_time": 239.0186670154379
}
#Debug simulation 
Total elapsed time: 81.26671116612852. Arrivals time: 0.46859320253133774 Scheduler time: 80.59628103720024 Scheduler overhead time: 0.07787586748600006 Adapter cache time: 0.017159983050078154 Engine time: 0.07669583195820451 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-16/adapters_256_slots_32_rate_0.8-0.4-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-16/adapters_256_slots_32_rate_0.8-0.4-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 33, 8640, 8640, 33, 8640, 4320, 8640, 33, 4320, 33, 8640, 4320, 4320, 4320, 4320, 8640, 33, 33, 33, 4320, 8640, 33, 8640, 8640, 4320, 4320, 4320, 33, 8640, 33, 4320, 4320, 33, 4320, 33, 33, 4320, 4320, 8640, 4320, 33, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 33, 8640, 8640, 4320, 33, 33, 8640, 4320, 33, 4320, 4320, 8640, 4320, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 4320, 33, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 33, 8640, 8640, 33, 8640, 33, 4320, 8640, 8640, 8640, 4320, 33, 8640, 4320, 33, 33, 33, 33, 33, 8640, 4320, 33, 8640, 33, 8640, 33, 33, 4320, 4320, 8640, 4320, 8640, 33, 4320, 33, 8640, 8640, 33, 8640, 4320, 33, 8640, 33, 33, 8640, 8640, 4320, 8640, 8640, 33, 8640, 4320, 4320, 33, 4320, 8640, 8640, 33, 8640, 4320, 33, 4320, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 4320, 8640, 8640, 4320, 33, 8640, 33, 4320, 4320, 33, 4320, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 4320, 8640, 4320, 33, 4320, 8640, 4320, 8640, 33, 8640, 33, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 33, 8640, 33, 8640, 4320, 4320, 33, 4320, 8640, 4320, 4320, 8640, 33, 8640, 8640, 4320, 33, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 33, 8640, 4320, 8640, 8640, 33, 8640, 4320, 4320, 8640, 33, 4320, 33, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 33, 33, 33, 33]
Prompts retrieved: 1113045 . Total input tokens: 247844840 . Total output tokens: 218638540
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 81.44457258097827,
    "estimated_duration": 3600.017853676852,
    "input_throughput": 6493.358074912013,
    "output_throughput": 5666.802729648689,
    "total_throughput": 12160.1608045607,
    "itl": 94.59656001780304,
    "ttft": 1826703.059206609,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 473,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.4610488744033545,
    "arrivals": 371350,
    "finished_requests": 94795,
    "scheduler_time": 241.80288744295484
}
#Debug simulation 
Total elapsed time: 81.4447352741845. Arrivals time: 0.46795249031856656 Scheduler time: 80.77072225185111 Scheduler overhead time: 0.07912879250943661 Adapter cache time: 0.017408065032213926 Engine time: 0.07833454292267561 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-32/adapters_256_slots_32_rate_0.8-0.4-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-32/adapters_256_slots_32_rate_0.8-0.4-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 33, 8640, 8640, 33, 8640, 4320, 8640, 33, 4320, 33, 8640, 4320, 4320, 4320, 4320, 8640, 33, 33, 33, 4320, 8640, 33, 8640, 8640, 4320, 4320, 4320, 33, 8640, 33, 4320, 4320, 33, 4320, 33, 33, 4320, 4320, 8640, 4320, 33, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 33, 8640, 8640, 4320, 33, 33, 8640, 4320, 33, 4320, 4320, 8640, 4320, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 4320, 33, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 33, 8640, 8640, 33, 8640, 33, 4320, 8640, 8640, 8640, 4320, 33, 8640, 4320, 33, 33, 33, 33, 33, 8640, 4320, 33, 8640, 33, 8640, 33, 33, 4320, 4320, 8640, 4320, 8640, 33, 4320, 33, 8640, 8640, 33, 8640, 4320, 33, 8640, 33, 33, 8640, 8640, 4320, 8640, 8640, 33, 8640, 4320, 4320, 33, 4320, 8640, 8640, 33, 8640, 4320, 33, 4320, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 4320, 8640, 8640, 4320, 33, 8640, 33, 4320, 4320, 33, 4320, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 4320, 8640, 4320, 33, 4320, 8640, 4320, 8640, 33, 8640, 33, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 33, 8640, 33, 8640, 4320, 4320, 33, 4320, 8640, 4320, 4320, 8640, 33, 8640, 8640, 4320, 33, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 33, 8640, 4320, 8640, 8640, 33, 8640, 4320, 4320, 8640, 33, 4320, 33, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 33, 33, 33, 33]
Prompts retrieved: 1113045 . Total input tokens: 247844840 . Total output tokens: 218638540
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 81.09135938482359,
    "estimated_duration": 3600.0407458444483,
    "input_throughput": 6332.4141612326675,
    "output_throughput": 5533.489870356246,
    "total_throughput": 11865.904031588914,
    "itl": 88.96015661707905,
    "ttft": 1836618.631241933,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 426,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.206300781122432,
    "arrivals": 371350,
    "finished_requests": 92456,
    "scheduler_time": 248.54380145171717
}
#Debug simulation 
Total elapsed time: 81.09153134888038. Arrivals time: 0.4584948872216046 Scheduler time: 80.4180327267386 Scheduler overhead time: 0.08455886924639344 Adapter cache time: 0.01742564234882593 Engine time: 0.08067623432725668 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_8-16-16/adapters_256_slots_32_rate_0.8-0.4-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_8-16-16/adapters_256_slots_32_rate_0.8-0.4-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 33, 8640, 8640, 33, 8640, 4320, 8640, 33, 4320, 33, 8640, 4320, 4320, 4320, 4320, 8640, 33, 33, 33, 4320, 8640, 33, 8640, 8640, 4320, 4320, 4320, 33, 8640, 33, 4320, 4320, 33, 4320, 33, 33, 4320, 4320, 8640, 4320, 33, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 33, 8640, 8640, 4320, 33, 33, 8640, 4320, 33, 4320, 4320, 8640, 4320, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 4320, 33, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 33, 8640, 8640, 33, 8640, 33, 4320, 8640, 8640, 8640, 4320, 33, 8640, 4320, 33, 33, 33, 33, 33, 8640, 4320, 33, 8640, 33, 8640, 33, 33, 4320, 4320, 8640, 4320, 8640, 33, 4320, 33, 8640, 8640, 33, 8640, 4320, 33, 8640, 33, 33, 8640, 8640, 4320, 8640, 8640, 33, 8640, 4320, 4320, 33, 4320, 8640, 8640, 33, 8640, 4320, 33, 4320, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 4320, 8640, 8640, 4320, 33, 8640, 33, 4320, 4320, 33, 4320, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 4320, 8640, 4320, 33, 4320, 8640, 4320, 8640, 33, 8640, 33, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 33, 8640, 33, 8640, 4320, 4320, 33, 4320, 8640, 4320, 4320, 8640, 33, 8640, 8640, 4320, 33, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 33, 8640, 4320, 8640, 8640, 33, 8640, 4320, 4320, 8640, 33, 4320, 33, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 33, 33, 33, 33]
Prompts retrieved: 1113045 . Total input tokens: 247844840 . Total output tokens: 218638540
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 80.87623376073316,
    "estimated_duration": 3600.085822192369,
    "input_throughput": 6523.517815944188,
    "output_throughput": 5691.548483008671,
    "total_throughput": 12215.06629895286,
    "itl": 95.10019046137035,
    "ttft": 1828501.6393688817,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 437,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.9938419341063085,
    "arrivals": 371350,
    "finished_requests": 95271,
    "scheduler_time": 240.81113540337543
}
#Debug simulation 
Total elapsed time: 80.87641344591975. Arrivals time: 0.4559719078242779 Scheduler time: 80.2161439047195 Scheduler overhead time: 0.07783321850001812 Adapter cache time: 0.017257769592106342 Engine time: 0.078709970228374 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_8-16-32/adapters_256_slots_32_rate_0.8-0.4-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_8-16-32/adapters_256_slots_32_rate_0.8-0.4-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 33, 8640, 8640, 33, 8640, 4320, 8640, 33, 4320, 33, 8640, 4320, 4320, 4320, 4320, 8640, 33, 33, 33, 4320, 8640, 33, 8640, 8640, 4320, 4320, 4320, 33, 8640, 33, 4320, 4320, 33, 4320, 33, 33, 4320, 4320, 8640, 4320, 33, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 33, 8640, 8640, 4320, 33, 33, 8640, 4320, 33, 4320, 4320, 8640, 4320, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 4320, 33, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 33, 8640, 8640, 33, 8640, 33, 4320, 8640, 8640, 8640, 4320, 33, 8640, 4320, 33, 33, 33, 33, 33, 8640, 4320, 33, 8640, 33, 8640, 33, 33, 4320, 4320, 8640, 4320, 8640, 33, 4320, 33, 8640, 8640, 33, 8640, 4320, 33, 8640, 33, 33, 8640, 8640, 4320, 8640, 8640, 33, 8640, 4320, 4320, 33, 4320, 8640, 8640, 33, 8640, 4320, 33, 4320, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 4320, 8640, 8640, 4320, 33, 8640, 33, 4320, 4320, 33, 4320, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 4320, 8640, 4320, 33, 4320, 8640, 4320, 8640, 33, 8640, 33, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 33, 8640, 33, 8640, 4320, 4320, 33, 4320, 8640, 4320, 4320, 8640, 33, 8640, 8640, 4320, 33, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 33, 8640, 4320, 8640, 8640, 33, 8640, 4320, 4320, 8640, 33, 4320, 33, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 33, 33, 33, 33]
Prompts retrieved: 1113045 . Total input tokens: 247844840 . Total output tokens: 218638540
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 77.84119418729097,
    "estimated_duration": 3600.0755746149953,
    "input_throughput": 6337.672786894213,
    "output_throughput": 5538.430676453875,
    "total_throughput": 11876.103463348087,
    "itl": 89.32639210627188,
    "ttft": 1843614.8513242446,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 462,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.445518038328764,
    "arrivals": 371350,
    "finished_requests": 92586,
    "scheduler_time": 248.14209521133498
}
#Debug simulation 
Total elapsed time: 77.84135475521907. Arrivals time: 0.45234593376517296 Scheduler time: 77.17926953546703 Scheduler overhead time: 0.08029412338510156 Adapter cache time: 0.0174096142873168 Engine time: 0.08017180627211928 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_16-16-16/adapters_256_slots_32_rate_0.8-0.4-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_16-16-16/adapters_256_slots_32_rate_0.8-0.4-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 33, 8640, 8640, 33, 8640, 4320, 8640, 33, 4320, 33, 8640, 4320, 4320, 4320, 4320, 8640, 33, 33, 33, 4320, 8640, 33, 8640, 8640, 4320, 4320, 4320, 33, 8640, 33, 4320, 4320, 33, 4320, 33, 33, 4320, 4320, 8640, 4320, 33, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 33, 8640, 8640, 4320, 33, 33, 8640, 4320, 33, 4320, 4320, 8640, 4320, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 4320, 33, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 33, 8640, 8640, 33, 8640, 33, 4320, 8640, 8640, 8640, 4320, 33, 8640, 4320, 33, 33, 33, 33, 33, 8640, 4320, 33, 8640, 33, 8640, 33, 33, 4320, 4320, 8640, 4320, 8640, 33, 4320, 33, 8640, 8640, 33, 8640, 4320, 33, 8640, 33, 33, 8640, 8640, 4320, 8640, 8640, 33, 8640, 4320, 4320, 33, 4320, 8640, 8640, 33, 8640, 4320, 33, 4320, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 4320, 8640, 8640, 4320, 33, 8640, 33, 4320, 4320, 33, 4320, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 4320, 8640, 4320, 33, 4320, 8640, 4320, 8640, 33, 8640, 33, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 33, 8640, 33, 8640, 4320, 4320, 33, 4320, 8640, 4320, 4320, 8640, 33, 8640, 8640, 4320, 33, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 33, 8640, 4320, 8640, 8640, 33, 8640, 4320, 4320, 8640, 33, 4320, 33, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 33, 33, 33, 33]
Prompts retrieved: 1113045 . Total input tokens: 247844840 . Total output tokens: 218638540
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 80.26054391590878,
    "estimated_duration": 3600.0743659814907,
    "input_throughput": 6497.2096746182215,
    "output_throughput": 5666.411003273392,
    "total_throughput": 12163.620677891613,
    "itl": 94.54462453480917,
    "ttft": 1827206.3008227933,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 453,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.891916186078439,
    "arrivals": 371350,
    "finished_requests": 94887,
    "scheduler_time": 242.00415448572
}
#Debug simulation 
Total elapsed time: 80.26071028597653. Arrivals time: 0.44915598910301924 Scheduler time: 79.60609588446096 Scheduler overhead time: 0.07881788490340114 Adapter cache time: 0.017423991579562426 Engine time: 0.07782505685463548 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_16-16-32/adapters_256_slots_32_rate_0.8-0.4-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.4-0.003125_size_16-16-32/adapters_256_slots_32_rate_0.8-0.4-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 33, 8640, 8640, 33, 8640, 4320, 8640, 33, 4320, 33, 8640, 4320, 4320, 4320, 4320, 8640, 33, 33, 33, 4320, 8640, 33, 8640, 8640, 4320, 4320, 4320, 33, 8640, 33, 4320, 4320, 33, 4320, 33, 33, 4320, 4320, 8640, 4320, 33, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 33, 8640, 8640, 4320, 33, 33, 8640, 4320, 33, 4320, 4320, 8640, 4320, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 4320, 33, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 33, 8640, 8640, 33, 8640, 33, 4320, 8640, 8640, 8640, 4320, 33, 8640, 4320, 33, 33, 33, 33, 33, 8640, 4320, 33, 8640, 33, 8640, 33, 33, 4320, 4320, 8640, 4320, 8640, 33, 4320, 33, 8640, 8640, 33, 8640, 4320, 33, 8640, 33, 33, 8640, 8640, 4320, 8640, 8640, 33, 8640, 4320, 4320, 33, 4320, 8640, 8640, 33, 8640, 4320, 33, 4320, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 4320, 8640, 8640, 4320, 33, 8640, 33, 4320, 4320, 33, 4320, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 4320, 8640, 4320, 33, 4320, 8640, 4320, 8640, 33, 8640, 33, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 33, 8640, 33, 8640, 4320, 4320, 33, 4320, 8640, 4320, 4320, 8640, 33, 8640, 8640, 4320, 33, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 33, 8640, 4320, 8640, 8640, 33, 8640, 4320, 4320, 8640, 33, 4320, 33, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 33, 33, 33, 33]
Prompts retrieved: 1113045 . Total input tokens: 247844840 . Total output tokens: 218638540
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 78.2130835079588,
    "estimated_duration": 3600.032923357014,
    "input_throughput": 6334.49040203083,
    "output_throughput": 5534.109944034044,
    "total_throughput": 11868.600346064875,
    "itl": 89.24625132482997,
    "ttft": 1843386.0272609584,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 460,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.397469846382764,
    "arrivals": 371350,
    "finished_requests": 92511,
    "scheduler_time": 248.35047244865774
}
#Debug simulation 
Total elapsed time: 78.21324512502179. Arrivals time: 0.4448630250990391 Scheduler time: 77.55885284626856 Scheduler overhead time: 0.08065952779725194 Adapter cache time: 0.017626192420721054 Engine time: 0.07963870745152235 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_8-8-8/adapters_256_slots_32_rate_0.8-0.1-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_8-8-8/adapters_256_slots_32_rate_0.8-0.1-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 540, 8640, 8640, 540, 8640, 1080, 8640, 540, 1080, 540, 8640, 1080, 1080, 1080, 1080, 8640, 540, 540, 540, 1080, 8640, 540, 8640, 8640, 1080, 1080, 1080, 540, 8640, 540, 1080, 1080, 540, 1080, 540, 540, 1080, 1080, 8640, 1080, 540, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 540, 8640, 8640, 1080, 540, 540, 8640, 1080, 540, 1080, 1080, 8640, 1080, 540, 540, 8640, 8640, 8640, 8640, 8640, 8640, 540, 1080, 540, 1080, 540, 540, 540, 1080, 1080, 1080, 540, 540, 8640, 8640, 540, 8640, 540, 1080, 8640, 8640, 8640, 1080, 540, 8640, 1080, 540, 540, 540, 540, 540, 8640, 1080, 540, 8640, 540, 8640, 540, 540, 1080, 1080, 8640, 1080, 8640, 540, 1080, 540, 8640, 8640, 540, 8640, 1080, 540, 8640, 540, 540, 8640, 8640, 1080, 8640, 8640, 540, 8640, 1080, 1080, 540, 1080, 8640, 8640, 540, 8640, 1080, 540, 1080, 8640, 540, 540, 540, 540, 540, 540, 8640, 540, 540, 540, 8640, 540, 1080, 8640, 8640, 1080, 540, 8640, 540, 1080, 1080, 540, 1080, 540, 8640, 540, 540, 8640, 540, 8640, 8640, 1080, 8640, 1080, 540, 1080, 8640, 1080, 8640, 540, 8640, 540, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 540, 8640, 540, 8640, 1080, 1080, 540, 1080, 8640, 1080, 1080, 8640, 540, 8640, 8640, 1080, 540, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 540, 8640, 1080, 8640, 8640, 540, 8640, 1080, 1080, 8640, 540, 1080, 540, 540, 540, 540, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 540, 540, 540, 540]
Prompts retrieved: 880740 . Total input tokens: 196131426 . Total output tokens: 172959159
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 87.4778160462156,
    "estimated_duration": 3600.0401269646304,
    "input_throughput": 6624.386995404816,
    "output_throughput": 5796.602888866917,
    "total_throughput": 12420.989884271734,
    "itl": 97.34620773618393,
    "ttft": 1698524.6752638821,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 424,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.8036614295467968,
    "arrivals": 293562,
    "finished_requests": 96892,
    "scheduler_time": 233.89472950197975
}
#Debug simulation 
Total elapsed time: 87.4779860638082. Arrivals time: 0.46070078760385513 Scheduler time: 86.81350543443114 Scheduler overhead time: 0.07895624823868275 Adapter cache time: 0.017399588134139776 Engine time: 0.0773704550229013 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_8-8-16/adapters_256_slots_32_rate_0.8-0.1-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_8-8-16/adapters_256_slots_32_rate_0.8-0.1-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 540, 8640, 8640, 540, 8640, 1080, 8640, 540, 1080, 540, 8640, 1080, 1080, 1080, 1080, 8640, 540, 540, 540, 1080, 8640, 540, 8640, 8640, 1080, 1080, 1080, 540, 8640, 540, 1080, 1080, 540, 1080, 540, 540, 1080, 1080, 8640, 1080, 540, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 540, 8640, 8640, 1080, 540, 540, 8640, 1080, 540, 1080, 1080, 8640, 1080, 540, 540, 8640, 8640, 8640, 8640, 8640, 8640, 540, 1080, 540, 1080, 540, 540, 540, 1080, 1080, 1080, 540, 540, 8640, 8640, 540, 8640, 540, 1080, 8640, 8640, 8640, 1080, 540, 8640, 1080, 540, 540, 540, 540, 540, 8640, 1080, 540, 8640, 540, 8640, 540, 540, 1080, 1080, 8640, 1080, 8640, 540, 1080, 540, 8640, 8640, 540, 8640, 1080, 540, 8640, 540, 540, 8640, 8640, 1080, 8640, 8640, 540, 8640, 1080, 1080, 540, 1080, 8640, 8640, 540, 8640, 1080, 540, 1080, 8640, 540, 540, 540, 540, 540, 540, 8640, 540, 540, 540, 8640, 540, 1080, 8640, 8640, 1080, 540, 8640, 540, 1080, 1080, 540, 1080, 540, 8640, 540, 540, 8640, 540, 8640, 8640, 1080, 8640, 1080, 540, 1080, 8640, 1080, 8640, 540, 8640, 540, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 540, 8640, 540, 8640, 1080, 1080, 540, 1080, 8640, 1080, 1080, 8640, 540, 8640, 8640, 1080, 540, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 540, 8640, 1080, 8640, 8640, 540, 8640, 1080, 1080, 8640, 540, 1080, 540, 540, 540, 540, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 540, 540, 540, 540]
Prompts retrieved: 880740 . Total input tokens: 196131426 . Total output tokens: 172959159
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 85.9426184380427,
    "estimated_duration": 3600.1032908097777,
    "input_throughput": 6560.827868549068,
    "output_throughput": 5756.900101424088,
    "total_throughput": 12317.727969973155,
    "itl": 95.24229164347105,
    "ttft": 1706834.2313772344,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 426,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.1013110883440853,
    "arrivals": 293562,
    "finished_requests": 96135,
    "scheduler_time": 236.48870371736163
}
#Debug simulation 
Total elapsed time: 85.94278537901118. Arrivals time: 0.4521703110076487 Scheduler time: 85.28387465095147 Scheduler overhead time: 0.0802796445786953 Adapter cache time: 0.017454413697123528 Engine time: 0.07811709214001894 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_8-8-32/adapters_256_slots_32_rate_0.8-0.1-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_8-8-32/adapters_256_slots_32_rate_0.8-0.1-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 540, 8640, 8640, 540, 8640, 1080, 8640, 540, 1080, 540, 8640, 1080, 1080, 1080, 1080, 8640, 540, 540, 540, 1080, 8640, 540, 8640, 8640, 1080, 1080, 1080, 540, 8640, 540, 1080, 1080, 540, 1080, 540, 540, 1080, 1080, 8640, 1080, 540, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 540, 8640, 8640, 1080, 540, 540, 8640, 1080, 540, 1080, 1080, 8640, 1080, 540, 540, 8640, 8640, 8640, 8640, 8640, 8640, 540, 1080, 540, 1080, 540, 540, 540, 1080, 1080, 1080, 540, 540, 8640, 8640, 540, 8640, 540, 1080, 8640, 8640, 8640, 1080, 540, 8640, 1080, 540, 540, 540, 540, 540, 8640, 1080, 540, 8640, 540, 8640, 540, 540, 1080, 1080, 8640, 1080, 8640, 540, 1080, 540, 8640, 8640, 540, 8640, 1080, 540, 8640, 540, 540, 8640, 8640, 1080, 8640, 8640, 540, 8640, 1080, 1080, 540, 1080, 8640, 8640, 540, 8640, 1080, 540, 1080, 8640, 540, 540, 540, 540, 540, 540, 8640, 540, 540, 540, 8640, 540, 1080, 8640, 8640, 1080, 540, 8640, 540, 1080, 1080, 540, 1080, 540, 8640, 540, 540, 8640, 540, 8640, 8640, 1080, 8640, 1080, 540, 1080, 8640, 1080, 8640, 540, 8640, 540, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 540, 8640, 540, 8640, 1080, 1080, 540, 1080, 8640, 1080, 1080, 8640, 540, 8640, 8640, 1080, 540, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 540, 8640, 1080, 8640, 8640, 540, 8640, 1080, 1080, 8640, 540, 1080, 540, 540, 540, 540, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 540, 540, 540, 540]
Prompts retrieved: 880740 . Total input tokens: 196131426 . Total output tokens: 172959159
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 79.09591310610995,
    "estimated_duration": 3600.0517096952385,
    "input_throughput": 6415.634513748481,
    "output_throughput": 5626.495571007989,
    "total_throughput": 12042.13008475647,
    "itl": 90.15347725202878,
    "ttft": 1726400.7200894072,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 431,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.2193402456771834,
    "arrivals": 293562,
    "finished_requests": 93915,
    "scheduler_time": 242.39065221702288
}
#Debug simulation 
Total elapsed time: 79.0960872080177. Arrivals time: 0.44533456210047007 Scheduler time: 78.44208888802677 Scheduler overhead time: 0.08008928876370192 Adapter cache time: 0.017617052886635065 Engine time: 0.07984956540167332 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_8-16-16/adapters_256_slots_32_rate_0.8-0.1-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_8-16-16/adapters_256_slots_32_rate_0.8-0.1-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 540, 8640, 8640, 540, 8640, 1080, 8640, 540, 1080, 540, 8640, 1080, 1080, 1080, 1080, 8640, 540, 540, 540, 1080, 8640, 540, 8640, 8640, 1080, 1080, 1080, 540, 8640, 540, 1080, 1080, 540, 1080, 540, 540, 1080, 1080, 8640, 1080, 540, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 540, 8640, 8640, 1080, 540, 540, 8640, 1080, 540, 1080, 1080, 8640, 1080, 540, 540, 8640, 8640, 8640, 8640, 8640, 8640, 540, 1080, 540, 1080, 540, 540, 540, 1080, 1080, 1080, 540, 540, 8640, 8640, 540, 8640, 540, 1080, 8640, 8640, 8640, 1080, 540, 8640, 1080, 540, 540, 540, 540, 540, 8640, 1080, 540, 8640, 540, 8640, 540, 540, 1080, 1080, 8640, 1080, 8640, 540, 1080, 540, 8640, 8640, 540, 8640, 1080, 540, 8640, 540, 540, 8640, 8640, 1080, 8640, 8640, 540, 8640, 1080, 1080, 540, 1080, 8640, 8640, 540, 8640, 1080, 540, 1080, 8640, 540, 540, 540, 540, 540, 540, 8640, 540, 540, 540, 8640, 540, 1080, 8640, 8640, 1080, 540, 8640, 540, 1080, 1080, 540, 1080, 540, 8640, 540, 540, 8640, 540, 8640, 8640, 1080, 8640, 1080, 540, 1080, 8640, 1080, 8640, 540, 8640, 540, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 540, 8640, 540, 8640, 1080, 1080, 540, 1080, 8640, 1080, 1080, 8640, 540, 8640, 8640, 1080, 540, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 540, 8640, 1080, 8640, 8640, 540, 8640, 1080, 1080, 8640, 540, 1080, 540, 540, 540, 540, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 540, 540, 540, 540]
Prompts retrieved: 880740 . Total input tokens: 196131426 . Total output tokens: 172959159
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 84.11641990672797,
    "estimated_duration": 3600.107234517367,
    "input_throughput": 6548.430772829601,
    "output_throughput": 5732.483133316079,
    "total_throughput": 12280.91390614568,
    "itl": 94.54262950637398,
    "ttft": 1713655.9702801227,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 433,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.9502593776909594,
    "arrivals": 293562,
    "finished_requests": 95872,
    "scheduler_time": 237.04909535809364
}
#Debug simulation 
Total elapsed time: 84.11660041799769. Arrivals time: 0.44786020228639245 Scheduler time: 83.46063978830352 Scheduler overhead time: 0.07983058970421553 Adapter cache time: 0.01792386034503579 Engine time: 0.07925157388672233 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_8-16-32/adapters_256_slots_32_rate_0.8-0.1-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_8-16-32/adapters_256_slots_32_rate_0.8-0.1-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 540, 8640, 8640, 540, 8640, 1080, 8640, 540, 1080, 540, 8640, 1080, 1080, 1080, 1080, 8640, 540, 540, 540, 1080, 8640, 540, 8640, 8640, 1080, 1080, 1080, 540, 8640, 540, 1080, 1080, 540, 1080, 540, 540, 1080, 1080, 8640, 1080, 540, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 540, 8640, 8640, 1080, 540, 540, 8640, 1080, 540, 1080, 1080, 8640, 1080, 540, 540, 8640, 8640, 8640, 8640, 8640, 8640, 540, 1080, 540, 1080, 540, 540, 540, 1080, 1080, 1080, 540, 540, 8640, 8640, 540, 8640, 540, 1080, 8640, 8640, 8640, 1080, 540, 8640, 1080, 540, 540, 540, 540, 540, 8640, 1080, 540, 8640, 540, 8640, 540, 540, 1080, 1080, 8640, 1080, 8640, 540, 1080, 540, 8640, 8640, 540, 8640, 1080, 540, 8640, 540, 540, 8640, 8640, 1080, 8640, 8640, 540, 8640, 1080, 1080, 540, 1080, 8640, 8640, 540, 8640, 1080, 540, 1080, 8640, 540, 540, 540, 540, 540, 540, 8640, 540, 540, 540, 8640, 540, 1080, 8640, 8640, 1080, 540, 8640, 540, 1080, 1080, 540, 1080, 540, 8640, 540, 540, 8640, 540, 8640, 8640, 1080, 8640, 1080, 540, 1080, 8640, 1080, 8640, 540, 8640, 540, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 540, 8640, 540, 8640, 1080, 1080, 540, 1080, 8640, 1080, 1080, 8640, 540, 8640, 8640, 1080, 540, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 540, 8640, 1080, 8640, 8640, 540, 8640, 1080, 1080, 8640, 540, 1080, 540, 540, 540, 540, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 540, 540, 540, 540]
Prompts retrieved: 880740 . Total input tokens: 196131426 . Total output tokens: 172959159
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 78.70462161395699,
    "estimated_duration": 3600.028331993087,
    "input_throughput": 6415.762841292093,
    "output_throughput": 5627.529878017333,
    "total_throughput": 12043.292719309426,
    "itl": 90.06802687395327,
    "ttft": 1727142.9847700286,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 440,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.259455640330005,
    "arrivals": 293562,
    "finished_requests": 93945,
    "scheduler_time": 242.5710641025322
}
#Debug simulation 
Total elapsed time: 78.70479717990384. Arrivals time: 0.4496913026086986 Scheduler time: 78.04523813398555 Scheduler overhead time: 0.08069853810593486 Adapter cache time: 0.01767867337912321 Engine time: 0.07964083924889565 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_16-16-16/adapters_256_slots_32_rate_0.8-0.1-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_16-16-16/adapters_256_slots_32_rate_0.8-0.1-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 540, 8640, 8640, 540, 8640, 1080, 8640, 540, 1080, 540, 8640, 1080, 1080, 1080, 1080, 8640, 540, 540, 540, 1080, 8640, 540, 8640, 8640, 1080, 1080, 1080, 540, 8640, 540, 1080, 1080, 540, 1080, 540, 540, 1080, 1080, 8640, 1080, 540, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 540, 8640, 8640, 1080, 540, 540, 8640, 1080, 540, 1080, 1080, 8640, 1080, 540, 540, 8640, 8640, 8640, 8640, 8640, 8640, 540, 1080, 540, 1080, 540, 540, 540, 1080, 1080, 1080, 540, 540, 8640, 8640, 540, 8640, 540, 1080, 8640, 8640, 8640, 1080, 540, 8640, 1080, 540, 540, 540, 540, 540, 8640, 1080, 540, 8640, 540, 8640, 540, 540, 1080, 1080, 8640, 1080, 8640, 540, 1080, 540, 8640, 8640, 540, 8640, 1080, 540, 8640, 540, 540, 8640, 8640, 1080, 8640, 8640, 540, 8640, 1080, 1080, 540, 1080, 8640, 8640, 540, 8640, 1080, 540, 1080, 8640, 540, 540, 540, 540, 540, 540, 8640, 540, 540, 540, 8640, 540, 1080, 8640, 8640, 1080, 540, 8640, 540, 1080, 1080, 540, 1080, 540, 8640, 540, 540, 8640, 540, 8640, 8640, 1080, 8640, 1080, 540, 1080, 8640, 1080, 8640, 540, 8640, 540, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 540, 8640, 540, 8640, 1080, 1080, 540, 1080, 8640, 1080, 1080, 8640, 540, 8640, 8640, 1080, 540, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 540, 8640, 1080, 8640, 8640, 540, 8640, 1080, 1080, 8640, 540, 1080, 540, 540, 540, 540, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 540, 540, 540, 540]
Prompts retrieved: 880740 . Total input tokens: 196131426 . Total output tokens: 172959159
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 84.9695378257893,
    "estimated_duration": 3600.0110754132047,
    "input_throughput": 6564.128694322883,
    "output_throughput": 5750.0173100506545,
    "total_throughput": 12314.146004373539,
    "itl": 95.02379403520352,
    "ttft": 1712744.2165117676,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 465,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.968523237365285,
    "arrivals": 293562,
    "finished_requests": 96042,
    "scheduler_time": 236.16732373429778
}
#Debug simulation 
Total elapsed time: 84.96970415301621. Arrivals time: 0.4436676986515522 Scheduler time: 84.31970140524209 Scheduler overhead time: 0.07940090773627162 Adapter cache time: 0.01790195144712925 Engine time: 0.07830803608521819 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_16-16-32/adapters_256_slots_32_rate_0.8-0.1-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.05_size_16-16-32/adapters_256_slots_32_rate_0.8-0.1-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 540, 8640, 8640, 540, 8640, 1080, 8640, 540, 1080, 540, 8640, 1080, 1080, 1080, 1080, 8640, 540, 540, 540, 1080, 8640, 540, 8640, 8640, 1080, 1080, 1080, 540, 8640, 540, 1080, 1080, 540, 1080, 540, 540, 1080, 1080, 8640, 1080, 540, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 540, 8640, 8640, 1080, 540, 540, 8640, 1080, 540, 1080, 1080, 8640, 1080, 540, 540, 8640, 8640, 8640, 8640, 8640, 8640, 540, 1080, 540, 1080, 540, 540, 540, 1080, 1080, 1080, 540, 540, 8640, 8640, 540, 8640, 540, 1080, 8640, 8640, 8640, 1080, 540, 8640, 1080, 540, 540, 540, 540, 540, 8640, 1080, 540, 8640, 540, 8640, 540, 540, 1080, 1080, 8640, 1080, 8640, 540, 1080, 540, 8640, 8640, 540, 8640, 1080, 540, 8640, 540, 540, 8640, 8640, 1080, 8640, 8640, 540, 8640, 1080, 1080, 540, 1080, 8640, 8640, 540, 8640, 1080, 540, 1080, 8640, 540, 540, 540, 540, 540, 540, 8640, 540, 540, 540, 8640, 540, 1080, 8640, 8640, 1080, 540, 8640, 540, 1080, 1080, 540, 1080, 540, 8640, 540, 540, 8640, 540, 8640, 8640, 1080, 8640, 1080, 540, 1080, 8640, 1080, 8640, 540, 8640, 540, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 540, 8640, 540, 8640, 1080, 1080, 540, 1080, 8640, 1080, 1080, 8640, 540, 8640, 8640, 1080, 540, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 540, 8640, 1080, 8640, 8640, 540, 8640, 1080, 1080, 8640, 540, 1080, 540, 540, 540, 540, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 540, 540, 540, 540]
Prompts retrieved: 880740 . Total input tokens: 196131426 . Total output tokens: 172959159
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 79.31819979893044,
    "estimated_duration": 3600.1000277276985,
    "input_throughput": 6418.457215641497,
    "output_throughput": 5626.559218907381,
    "total_throughput": 12045.016434548877,
    "itl": 90.04738552936178,
    "ttft": 1726748.007721334,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 431,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.16326335979628,
    "arrivals": 293562,
    "finished_requests": 93919,
    "scheduler_time": 242.5638336267907
}
#Debug simulation 
Total elapsed time: 79.31837442936376. Arrivals time: 0.4460381134413183 Scheduler time: 78.66331332130358 Scheduler overhead time: 0.08050436619669199 Adapter cache time: 0.017567325849086046 Engine time: 0.07998237432911992 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_8-8-8/adapters_256_slots_32_rate_0.8-0.1-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_8-8-8/adapters_256_slots_32_rate_0.8-0.1-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 270, 8640, 8640, 270, 8640, 1080, 8640, 270, 1080, 270, 8640, 1080, 1080, 1080, 1080, 8640, 270, 270, 270, 1080, 8640, 270, 8640, 8640, 1080, 1080, 1080, 270, 8640, 270, 1080, 1080, 270, 1080, 270, 270, 1080, 1080, 8640, 1080, 270, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 270, 8640, 8640, 1080, 270, 270, 8640, 1080, 270, 1080, 1080, 8640, 1080, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 270, 1080, 270, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 270, 8640, 8640, 270, 8640, 270, 1080, 8640, 8640, 8640, 1080, 270, 8640, 1080, 270, 270, 270, 270, 270, 8640, 1080, 270, 8640, 270, 8640, 270, 270, 1080, 1080, 8640, 1080, 8640, 270, 1080, 270, 8640, 8640, 270, 8640, 1080, 270, 8640, 270, 270, 8640, 8640, 1080, 8640, 8640, 270, 8640, 1080, 1080, 270, 1080, 8640, 8640, 270, 8640, 1080, 270, 1080, 8640, 270, 270, 270, 270, 270, 270, 8640, 270, 270, 270, 8640, 270, 1080, 8640, 8640, 1080, 270, 8640, 270, 1080, 1080, 270, 1080, 270, 8640, 270, 270, 8640, 270, 8640, 8640, 1080, 8640, 1080, 270, 1080, 8640, 1080, 8640, 270, 8640, 270, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 270, 8640, 270, 8640, 1080, 1080, 270, 1080, 8640, 1080, 1080, 8640, 270, 8640, 8640, 1080, 270, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 270, 8640, 1080, 8640, 8640, 270, 8640, 1080, 1080, 8640, 270, 1080, 270, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 270, 270, 270, 270]
Prompts retrieved: 857790 . Total input tokens: 191014731 . Total output tokens: 168440396
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 82.39617078797892,
    "estimated_duration": 3600.119924166237,
    "input_throughput": 6587.211953916278,
    "output_throughput": 5732.464038619357,
    "total_throughput": 12319.675992535635,
    "itl": 95.49103053354193,
    "ttft": 1702540.8952181484,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 459,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.035095745665052,
    "arrivals": 285871,
    "finished_requests": 95823,
    "scheduler_time": 236.14682728395638
}
#Debug simulation 
Total elapsed time: 82.39633847307414. Arrivals time: 0.44925176352262497 Scheduler time: 81.74268898041919 Scheduler overhead time: 0.07895898027345538 Adapter cache time: 0.017352488823235035 Engine time: 0.07720658276230097 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_8-8-16/adapters_256_slots_32_rate_0.8-0.1-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_8-8-16/adapters_256_slots_32_rate_0.8-0.1-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 270, 8640, 8640, 270, 8640, 1080, 8640, 270, 1080, 270, 8640, 1080, 1080, 1080, 1080, 8640, 270, 270, 270, 1080, 8640, 270, 8640, 8640, 1080, 1080, 1080, 270, 8640, 270, 1080, 1080, 270, 1080, 270, 270, 1080, 1080, 8640, 1080, 270, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 270, 8640, 8640, 1080, 270, 270, 8640, 1080, 270, 1080, 1080, 8640, 1080, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 270, 1080, 270, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 270, 8640, 8640, 270, 8640, 270, 1080, 8640, 8640, 8640, 1080, 270, 8640, 1080, 270, 270, 270, 270, 270, 8640, 1080, 270, 8640, 270, 8640, 270, 270, 1080, 1080, 8640, 1080, 8640, 270, 1080, 270, 8640, 8640, 270, 8640, 1080, 270, 8640, 270, 270, 8640, 8640, 1080, 8640, 8640, 270, 8640, 1080, 1080, 270, 1080, 8640, 8640, 270, 8640, 1080, 270, 1080, 8640, 270, 270, 270, 270, 270, 270, 8640, 270, 270, 270, 8640, 270, 1080, 8640, 8640, 1080, 270, 8640, 270, 1080, 1080, 270, 1080, 270, 8640, 270, 270, 8640, 270, 8640, 8640, 1080, 8640, 1080, 270, 1080, 8640, 1080, 8640, 270, 8640, 270, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 270, 8640, 270, 8640, 1080, 1080, 270, 1080, 8640, 1080, 1080, 8640, 270, 8640, 8640, 1080, 270, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 270, 8640, 1080, 8640, 8640, 270, 8640, 1080, 1080, 8640, 270, 1080, 270, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 270, 270, 270, 270]
Prompts retrieved: 857790 . Total input tokens: 191014731 . Total output tokens: 168440396
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 83.3891004351899,
    "estimated_duration": 3600.00178016127,
    "input_throughput": 6489.201513381887,
    "output_throughput": 5664.61275446549,
    "total_throughput": 12153.814267847378,
    "itl": 92.89229582598624,
    "ttft": 1707025.0183571558,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 433,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.166821849527773,
    "arrivals": 285871,
    "finished_requests": 94477,
    "scheduler_time": 239.74213073951034
}
#Debug simulation 
Total elapsed time: 83.38926777103916. Arrivals time: 0.45297963405027986 Scheduler time: 82.730192292016 Scheduler overhead time: 0.07965320348739624 Adapter cache time: 0.017350303009152412 Engine time: 0.07853520847856998 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_8-8-32/adapters_256_slots_32_rate_0.8-0.1-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_8-8-32/adapters_256_slots_32_rate_0.8-0.1-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 270, 8640, 8640, 270, 8640, 1080, 8640, 270, 1080, 270, 8640, 1080, 1080, 1080, 1080, 8640, 270, 270, 270, 1080, 8640, 270, 8640, 8640, 1080, 1080, 1080, 270, 8640, 270, 1080, 1080, 270, 1080, 270, 270, 1080, 1080, 8640, 1080, 270, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 270, 8640, 8640, 1080, 270, 270, 8640, 1080, 270, 1080, 1080, 8640, 1080, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 270, 1080, 270, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 270, 8640, 8640, 270, 8640, 270, 1080, 8640, 8640, 8640, 1080, 270, 8640, 1080, 270, 270, 270, 270, 270, 8640, 1080, 270, 8640, 270, 8640, 270, 270, 1080, 1080, 8640, 1080, 8640, 270, 1080, 270, 8640, 8640, 270, 8640, 1080, 270, 8640, 270, 270, 8640, 8640, 1080, 8640, 8640, 270, 8640, 1080, 1080, 270, 1080, 8640, 8640, 270, 8640, 1080, 270, 1080, 8640, 270, 270, 270, 270, 270, 270, 8640, 270, 270, 270, 8640, 270, 1080, 8640, 8640, 1080, 270, 8640, 270, 1080, 1080, 270, 1080, 270, 8640, 270, 270, 8640, 270, 8640, 8640, 1080, 8640, 1080, 270, 1080, 8640, 1080, 8640, 270, 8640, 270, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 270, 8640, 270, 8640, 1080, 1080, 270, 1080, 8640, 1080, 1080, 8640, 270, 8640, 8640, 1080, 270, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 270, 8640, 1080, 8640, 8640, 270, 8640, 1080, 1080, 8640, 270, 1080, 270, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 270, 270, 270, 270]
Prompts retrieved: 857790 . Total input tokens: 191014731 . Total output tokens: 168440396
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 80.21257435483858,
    "estimated_duration": 3600.011388264584,
    "input_throughput": 6379.023987218624,
    "output_throughput": 5550.422441755744,
    "total_throughput": 11929.446428974368,
    "itl": 88.2637848470818,
    "ttft": 1721368.4656402739,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 420,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.157844340880424,
    "arrivals": 285871,
    "finished_requests": 92779,
    "scheduler_time": 244.82000450162386
}
#Debug simulation 
Total elapsed time: 80.2127458518371. Arrivals time: 0.43594683427363634 Scheduler time: 79.56657174555585 Scheduler overhead time: 0.08113322779536247 Adapter cache time: 0.017570822034031153 Engine time: 0.07969016954302788 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_8-16-16/adapters_256_slots_32_rate_0.8-0.1-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_8-16-16/adapters_256_slots_32_rate_0.8-0.1-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 270, 8640, 8640, 270, 8640, 1080, 8640, 270, 1080, 270, 8640, 1080, 1080, 1080, 1080, 8640, 270, 270, 270, 1080, 8640, 270, 8640, 8640, 1080, 1080, 1080, 270, 8640, 270, 1080, 1080, 270, 1080, 270, 270, 1080, 1080, 8640, 1080, 270, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 270, 8640, 8640, 1080, 270, 270, 8640, 1080, 270, 1080, 1080, 8640, 1080, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 270, 1080, 270, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 270, 8640, 8640, 270, 8640, 270, 1080, 8640, 8640, 8640, 1080, 270, 8640, 1080, 270, 270, 270, 270, 270, 8640, 1080, 270, 8640, 270, 8640, 270, 270, 1080, 1080, 8640, 1080, 8640, 270, 1080, 270, 8640, 8640, 270, 8640, 1080, 270, 8640, 270, 270, 8640, 8640, 1080, 8640, 8640, 270, 8640, 1080, 1080, 270, 1080, 8640, 8640, 270, 8640, 1080, 270, 1080, 8640, 270, 270, 270, 270, 270, 270, 8640, 270, 270, 270, 8640, 270, 1080, 8640, 8640, 1080, 270, 8640, 270, 1080, 1080, 270, 1080, 270, 8640, 270, 270, 8640, 270, 8640, 8640, 1080, 8640, 1080, 270, 1080, 8640, 1080, 8640, 270, 8640, 270, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 270, 8640, 270, 8640, 1080, 1080, 270, 1080, 8640, 1080, 1080, 8640, 270, 8640, 8640, 1080, 270, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 270, 8640, 1080, 8640, 8640, 270, 8640, 1080, 1080, 8640, 270, 1080, 270, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 270, 270, 270, 270]
Prompts retrieved: 857790 . Total input tokens: 191014731 . Total output tokens: 168440396
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 81.1444127340801,
    "estimated_duration": 3600.0937440669595,
    "input_throughput": 6531.809911548413,
    "output_throughput": 5682.532860071963,
    "total_throughput": 12214.342771620375,
    "itl": 93.35329566515196,
    "ttft": 1709967.8783914854,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 410,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.814534963844341,
    "arrivals": 285871,
    "finished_requests": 94992,
    "scheduler_time": 238.5783059516161
}
#Debug simulation 
Total elapsed time: 81.14458454214036. Arrivals time: 0.45399228669703007 Scheduler time: 80.48473625676706 Scheduler overhead time: 0.0791500173509121 Adapter cache time: 0.017271392047405243 Engine time: 0.07823483273386955 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_8-16-32/adapters_256_slots_32_rate_0.8-0.1-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_8-16-32/adapters_256_slots_32_rate_0.8-0.1-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 270, 8640, 8640, 270, 8640, 1080, 8640, 270, 1080, 270, 8640, 1080, 1080, 1080, 1080, 8640, 270, 270, 270, 1080, 8640, 270, 8640, 8640, 1080, 1080, 1080, 270, 8640, 270, 1080, 1080, 270, 1080, 270, 270, 1080, 1080, 8640, 1080, 270, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 270, 8640, 8640, 1080, 270, 270, 8640, 1080, 270, 1080, 1080, 8640, 1080, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 270, 1080, 270, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 270, 8640, 8640, 270, 8640, 270, 1080, 8640, 8640, 8640, 1080, 270, 8640, 1080, 270, 270, 270, 270, 270, 8640, 1080, 270, 8640, 270, 8640, 270, 270, 1080, 1080, 8640, 1080, 8640, 270, 1080, 270, 8640, 8640, 270, 8640, 1080, 270, 8640, 270, 270, 8640, 8640, 1080, 8640, 8640, 270, 8640, 1080, 1080, 270, 1080, 8640, 8640, 270, 8640, 1080, 270, 1080, 8640, 270, 270, 270, 270, 270, 270, 8640, 270, 270, 270, 8640, 270, 1080, 8640, 8640, 1080, 270, 8640, 270, 1080, 1080, 270, 1080, 270, 8640, 270, 270, 8640, 270, 8640, 8640, 1080, 8640, 1080, 270, 1080, 8640, 1080, 8640, 270, 8640, 270, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 270, 8640, 270, 8640, 1080, 1080, 270, 1080, 8640, 1080, 1080, 8640, 270, 8640, 8640, 1080, 270, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 270, 8640, 1080, 8640, 8640, 270, 8640, 1080, 1080, 8640, 270, 1080, 270, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 270, 270, 270, 270]
Prompts retrieved: 857790 . Total input tokens: 191014731 . Total output tokens: 168440396
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 79.8273508856073,
    "estimated_duration": 3600.042411243285,
    "input_throughput": 6364.930015390173,
    "output_throughput": 5541.398883995497,
    "total_throughput": 11906.328899385671,
    "itl": 88.05767738137816,
    "ttft": 1727681.1467253752,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 438,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.2593041026639074,
    "arrivals": 285871,
    "finished_requests": 92589,
    "scheduler_time": 245.29649824335536
}
#Debug simulation 
Total elapsed time: 79.82751294691116. Arrivals time: 0.4381857728585601 Scheduler time: 79.17900856398046 Scheduler overhead time: 0.08093606308102608 Adapter cache time: 0.0178661048412323 Engine time: 0.07976812683045864 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_16-16-16/adapters_256_slots_32_rate_0.8-0.1-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_16-16-16/adapters_256_slots_32_rate_0.8-0.1-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 270, 8640, 8640, 270, 8640, 1080, 8640, 270, 1080, 270, 8640, 1080, 1080, 1080, 1080, 8640, 270, 270, 270, 1080, 8640, 270, 8640, 8640, 1080, 1080, 1080, 270, 8640, 270, 1080, 1080, 270, 1080, 270, 270, 1080, 1080, 8640, 1080, 270, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 270, 8640, 8640, 1080, 270, 270, 8640, 1080, 270, 1080, 1080, 8640, 1080, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 270, 1080, 270, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 270, 8640, 8640, 270, 8640, 270, 1080, 8640, 8640, 8640, 1080, 270, 8640, 1080, 270, 270, 270, 270, 270, 8640, 1080, 270, 8640, 270, 8640, 270, 270, 1080, 1080, 8640, 1080, 8640, 270, 1080, 270, 8640, 8640, 270, 8640, 1080, 270, 8640, 270, 270, 8640, 8640, 1080, 8640, 8640, 270, 8640, 1080, 1080, 270, 1080, 8640, 8640, 270, 8640, 1080, 270, 1080, 8640, 270, 270, 270, 270, 270, 270, 8640, 270, 270, 270, 8640, 270, 1080, 8640, 8640, 1080, 270, 8640, 270, 1080, 1080, 270, 1080, 270, 8640, 270, 270, 8640, 270, 8640, 8640, 1080, 8640, 1080, 270, 1080, 8640, 1080, 8640, 270, 8640, 270, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 270, 8640, 270, 8640, 1080, 1080, 270, 1080, 8640, 1080, 1080, 8640, 270, 8640, 8640, 1080, 270, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 270, 8640, 1080, 8640, 8640, 270, 8640, 1080, 1080, 8640, 270, 1080, 270, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 270, 270, 270, 270]
Prompts retrieved: 857790 . Total input tokens: 191014731 . Total output tokens: 168440396
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 80.69908122997731,
    "estimated_duration": 3600.0759915505455,
    "input_throughput": 6534.56817445341,
    "output_throughput": 5685.2786019066,
    "total_throughput": 12219.84677636001,
    "itl": 93.42411326941216,
    "ttft": 1710295.0044500665,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 428,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.7323181625641766,
    "arrivals": 285871,
    "finished_requests": 95059,
    "scheduler_time": 238.3759626776679
}
#Debug simulation 
Total elapsed time: 80.69924914184958. Arrivals time: 0.44701736560091376 Scheduler time: 80.04875941714272 Scheduler overhead time: 0.07857406744733453 Adapter cache time: 0.017187264282256365 Engine time: 0.07711388124153018 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_16-16-32/adapters_256_slots_32_rate_0.8-0.1-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.025_size_16-16-32/adapters_256_slots_32_rate_0.8-0.1-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 270, 8640, 8640, 270, 8640, 1080, 8640, 270, 1080, 270, 8640, 1080, 1080, 1080, 1080, 8640, 270, 270, 270, 1080, 8640, 270, 8640, 8640, 1080, 1080, 1080, 270, 8640, 270, 1080, 1080, 270, 1080, 270, 270, 1080, 1080, 8640, 1080, 270, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 270, 8640, 8640, 1080, 270, 270, 8640, 1080, 270, 1080, 1080, 8640, 1080, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 270, 1080, 270, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 270, 8640, 8640, 270, 8640, 270, 1080, 8640, 8640, 8640, 1080, 270, 8640, 1080, 270, 270, 270, 270, 270, 8640, 1080, 270, 8640, 270, 8640, 270, 270, 1080, 1080, 8640, 1080, 8640, 270, 1080, 270, 8640, 8640, 270, 8640, 1080, 270, 8640, 270, 270, 8640, 8640, 1080, 8640, 8640, 270, 8640, 1080, 1080, 270, 1080, 8640, 8640, 270, 8640, 1080, 270, 1080, 8640, 270, 270, 270, 270, 270, 270, 8640, 270, 270, 270, 8640, 270, 1080, 8640, 8640, 1080, 270, 8640, 270, 1080, 1080, 270, 1080, 270, 8640, 270, 270, 8640, 270, 8640, 8640, 1080, 8640, 1080, 270, 1080, 8640, 1080, 8640, 270, 8640, 270, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 270, 8640, 270, 8640, 1080, 1080, 270, 1080, 8640, 1080, 1080, 8640, 270, 8640, 8640, 1080, 270, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 270, 8640, 1080, 8640, 8640, 270, 8640, 1080, 1080, 8640, 270, 1080, 270, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 270, 270, 270, 270]
Prompts retrieved: 857790 . Total input tokens: 191014731 . Total output tokens: 168440396
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 80.26576222898439,
    "estimated_duration": 3600.041299275187,
    "input_throughput": 6394.072758174887,
    "output_throughput": 5563.1881234341035,
    "total_throughput": 11957.26088160899,
    "itl": 88.4228339506484,
    "ttft": 1720524.6162652995,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 379,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.796124935653079,
    "arrivals": 285871,
    "finished_requests": 93009,
    "scheduler_time": 244.32273663600623
}
#Debug simulation 
Total elapsed time: 80.26592053286731. Arrivals time: 0.4275653655640781 Scheduler time: 79.62794799124822 Scheduler overhead time: 0.08165505900979042 Adapter cache time: 0.017123304307460785 Engine time: 0.08028397429734468 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-8/adapters_256_slots_32_rate_0.8-0.1-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-8/adapters_256_slots_32_rate_0.8-0.1-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 135, 8640, 8640, 135, 8640, 1080, 8640, 135, 1080, 135, 8640, 1080, 1080, 1080, 1080, 8640, 135, 135, 135, 1080, 8640, 135, 8640, 8640, 1080, 1080, 1080, 135, 8640, 135, 1080, 1080, 135, 1080, 135, 135, 1080, 1080, 8640, 1080, 135, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 135, 8640, 8640, 1080, 135, 135, 8640, 1080, 135, 1080, 1080, 8640, 1080, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 135, 1080, 135, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 135, 8640, 8640, 135, 8640, 135, 1080, 8640, 8640, 8640, 1080, 135, 8640, 1080, 135, 135, 135, 135, 135, 8640, 1080, 135, 8640, 135, 8640, 135, 135, 1080, 1080, 8640, 1080, 8640, 135, 1080, 135, 8640, 8640, 135, 8640, 1080, 135, 8640, 135, 135, 8640, 8640, 1080, 8640, 8640, 135, 8640, 1080, 1080, 135, 1080, 8640, 8640, 135, 8640, 1080, 135, 1080, 8640, 135, 135, 135, 135, 135, 135, 8640, 135, 135, 135, 8640, 135, 1080, 8640, 8640, 1080, 135, 8640, 135, 1080, 1080, 135, 1080, 135, 8640, 135, 135, 8640, 135, 8640, 8640, 1080, 8640, 1080, 135, 1080, 8640, 1080, 8640, 135, 8640, 135, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 135, 8640, 135, 8640, 1080, 1080, 135, 1080, 8640, 1080, 1080, 8640, 135, 8640, 8640, 1080, 135, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 135, 8640, 1080, 8640, 8640, 135, 8640, 1080, 1080, 8640, 135, 1080, 135, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 135, 135, 135, 135]
Prompts retrieved: 846315 . Total input tokens: 188481277 . Total output tokens: 166186996
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 91.33563561318442,
    "estimated_duration": 3600.1063341877198,
    "input_throughput": 6573.191401397668,
    "output_throughput": 5762.158412657132,
    "total_throughput": 12335.349814054802,
    "itl": 96.54258087791557,
    "ttft": 1682757.723583391,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 413,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.730924930195345,
    "arrivals": 281942,
    "finished_requests": 95958,
    "scheduler_time": 235.14800558178763
}
#Debug simulation 
Total elapsed time: 91.33579478599131. Arrivals time: 0.44677315559238195 Scheduler time: 90.68182961456478 Scheduler overhead time: 0.08003879012539983 Adapter cache time: 0.01733257807791233 Engine time: 0.07925727870315313 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-16/adapters_256_slots_32_rate_0.8-0.1-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-16/adapters_256_slots_32_rate_0.8-0.1-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 135, 8640, 8640, 135, 8640, 1080, 8640, 135, 1080, 135, 8640, 1080, 1080, 1080, 1080, 8640, 135, 135, 135, 1080, 8640, 135, 8640, 8640, 1080, 1080, 1080, 135, 8640, 135, 1080, 1080, 135, 1080, 135, 135, 1080, 1080, 8640, 1080, 135, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 135, 8640, 8640, 1080, 135, 135, 8640, 1080, 135, 1080, 1080, 8640, 1080, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 135, 1080, 135, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 135, 8640, 8640, 135, 8640, 135, 1080, 8640, 8640, 8640, 1080, 135, 8640, 1080, 135, 135, 135, 135, 135, 8640, 1080, 135, 8640, 135, 8640, 135, 135, 1080, 1080, 8640, 1080, 8640, 135, 1080, 135, 8640, 8640, 135, 8640, 1080, 135, 8640, 135, 135, 8640, 8640, 1080, 8640, 8640, 135, 8640, 1080, 1080, 135, 1080, 8640, 8640, 135, 8640, 1080, 135, 1080, 8640, 135, 135, 135, 135, 135, 135, 8640, 135, 135, 135, 8640, 135, 1080, 8640, 8640, 1080, 135, 8640, 135, 1080, 1080, 135, 1080, 135, 8640, 135, 135, 8640, 135, 8640, 8640, 1080, 8640, 1080, 135, 1080, 8640, 1080, 8640, 135, 8640, 135, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 135, 8640, 135, 8640, 1080, 1080, 135, 1080, 8640, 1080, 1080, 8640, 135, 8640, 8640, 1080, 135, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 135, 8640, 1080, 8640, 8640, 135, 8640, 1080, 1080, 8640, 135, 1080, 135, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 135, 135, 135, 135]
Prompts retrieved: 846315 . Total input tokens: 188481277 . Total output tokens: 166186996
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 90.75668837316334,
    "estimated_duration": 3600.036965332096,
    "input_throughput": 6515.79615039762,
    "output_throughput": 5708.457218050883,
    "total_throughput": 12224.253368448502,
    "itl": 94.10676492208195,
    "ttft": 1688502.7817897068,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 398,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.9017379874084175,
    "arrivals": 281942,
    "finished_requests": 95077,
    "scheduler_time": 238.12116404266564
}
#Debug simulation 
Total elapsed time: 90.75685611180961. Arrivals time: 0.45418600272387266 Scheduler time: 90.0916344979778 Scheduler overhead time: 0.08085576491430402 Adapter cache time: 0.017390959430485964 Engine time: 0.08105728356167674 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-32/adapters_256_slots_32_rate_0.8-0.1-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-32/adapters_256_slots_32_rate_0.8-0.1-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 135, 8640, 8640, 135, 8640, 1080, 8640, 135, 1080, 135, 8640, 1080, 1080, 1080, 1080, 8640, 135, 135, 135, 1080, 8640, 135, 8640, 8640, 1080, 1080, 1080, 135, 8640, 135, 1080, 1080, 135, 1080, 135, 135, 1080, 1080, 8640, 1080, 135, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 135, 8640, 8640, 1080, 135, 135, 8640, 1080, 135, 1080, 1080, 8640, 1080, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 135, 1080, 135, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 135, 8640, 8640, 135, 8640, 135, 1080, 8640, 8640, 8640, 1080, 135, 8640, 1080, 135, 135, 135, 135, 135, 8640, 1080, 135, 8640, 135, 8640, 135, 135, 1080, 1080, 8640, 1080, 8640, 135, 1080, 135, 8640, 8640, 135, 8640, 1080, 135, 8640, 135, 135, 8640, 8640, 1080, 8640, 8640, 135, 8640, 1080, 1080, 135, 1080, 8640, 8640, 135, 8640, 1080, 135, 1080, 8640, 135, 135, 135, 135, 135, 135, 8640, 135, 135, 135, 8640, 135, 1080, 8640, 8640, 1080, 135, 8640, 135, 1080, 1080, 135, 1080, 135, 8640, 135, 135, 8640, 135, 8640, 8640, 1080, 8640, 1080, 135, 1080, 8640, 1080, 8640, 135, 8640, 135, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 135, 8640, 135, 8640, 1080, 1080, 135, 1080, 8640, 1080, 1080, 8640, 135, 8640, 8640, 1080, 135, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 135, 8640, 1080, 8640, 8640, 135, 8640, 1080, 1080, 8640, 135, 1080, 135, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 135, 135, 135, 135]
Prompts retrieved: 846315 . Total input tokens: 188481277 . Total output tokens: 166186996
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 80.92830750206485,
    "estimated_duration": 3600.075623383316,
    "input_throughput": 6389.887437525824,
    "output_throughput": 5597.806576368763,
    "total_throughput": 11987.694013894587,
    "itl": 89.52020545692278,
    "ttft": 1708306.1203948685,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 421,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.1556675758864965,
    "arrivals": 281942,
    "finished_requests": 93262,
    "scheduler_time": 243.25466180849256
}
#Debug simulation 
Total elapsed time: 80.92848721984774. Arrivals time: 0.43862170027568936 Scheduler time: 80.2793035316281 Scheduler overhead time: 0.08083797013387084 Adapter cache time: 0.017579175531864166 Engine time: 0.08011658722534776 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_8-16-16/adapters_256_slots_32_rate_0.8-0.1-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_8-16-16/adapters_256_slots_32_rate_0.8-0.1-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 135, 8640, 8640, 135, 8640, 1080, 8640, 135, 1080, 135, 8640, 1080, 1080, 1080, 1080, 8640, 135, 135, 135, 1080, 8640, 135, 8640, 8640, 1080, 1080, 1080, 135, 8640, 135, 1080, 1080, 135, 1080, 135, 135, 1080, 1080, 8640, 1080, 135, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 135, 8640, 8640, 1080, 135, 135, 8640, 1080, 135, 1080, 1080, 8640, 1080, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 135, 1080, 135, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 135, 8640, 8640, 135, 8640, 135, 1080, 8640, 8640, 8640, 1080, 135, 8640, 1080, 135, 135, 135, 135, 135, 8640, 1080, 135, 8640, 135, 8640, 135, 135, 1080, 1080, 8640, 1080, 8640, 135, 1080, 135, 8640, 8640, 135, 8640, 1080, 135, 8640, 135, 135, 8640, 8640, 1080, 8640, 8640, 135, 8640, 1080, 1080, 135, 1080, 8640, 8640, 135, 8640, 1080, 135, 1080, 8640, 135, 135, 135, 135, 135, 135, 8640, 135, 135, 135, 8640, 135, 1080, 8640, 8640, 1080, 135, 8640, 135, 1080, 1080, 135, 1080, 135, 8640, 135, 135, 8640, 135, 8640, 8640, 1080, 8640, 1080, 135, 1080, 8640, 1080, 8640, 135, 8640, 135, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 135, 8640, 135, 8640, 1080, 1080, 135, 1080, 8640, 1080, 1080, 8640, 135, 8640, 8640, 1080, 135, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 135, 8640, 1080, 8640, 8640, 135, 8640, 1080, 1080, 8640, 135, 1080, 135, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 135, 135, 135, 135]
Prompts retrieved: 846315 . Total input tokens: 188481277 . Total output tokens: 166186996
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 91.51989585906267,
    "estimated_duration": 3600.1060698054484,
    "input_throughput": 6512.963936439547,
    "output_throughput": 5713.793594173637,
    "total_throughput": 12226.757530613184,
    "itl": 94.33047574024881,
    "ttft": 1686992.2097905902,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 412,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.818973479885604,
    "arrivals": 281942,
    "finished_requests": 95114,
    "scheduler_time": 237.75431552801405
}
#Debug simulation 
Total elapsed time: 91.52006532019004. Arrivals time: 0.4649653919041157 Scheduler time: 90.84605036396533 Scheduler overhead time: 0.08098892262205482 Adapter cache time: 0.017457312904298306 Engine time: 0.0793209346011281 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_8-16-32/adapters_256_slots_32_rate_0.8-0.1-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_8-16-32/adapters_256_slots_32_rate_0.8-0.1-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 135, 8640, 8640, 135, 8640, 1080, 8640, 135, 1080, 135, 8640, 1080, 1080, 1080, 1080, 8640, 135, 135, 135, 1080, 8640, 135, 8640, 8640, 1080, 1080, 1080, 135, 8640, 135, 1080, 1080, 135, 1080, 135, 135, 1080, 1080, 8640, 1080, 135, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 135, 8640, 8640, 1080, 135, 135, 8640, 1080, 135, 1080, 1080, 8640, 1080, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 135, 1080, 135, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 135, 8640, 8640, 135, 8640, 135, 1080, 8640, 8640, 8640, 1080, 135, 8640, 1080, 135, 135, 135, 135, 135, 8640, 1080, 135, 8640, 135, 8640, 135, 135, 1080, 1080, 8640, 1080, 8640, 135, 1080, 135, 8640, 8640, 135, 8640, 1080, 135, 8640, 135, 135, 8640, 8640, 1080, 8640, 8640, 135, 8640, 1080, 1080, 135, 1080, 8640, 8640, 135, 8640, 1080, 135, 1080, 8640, 135, 135, 135, 135, 135, 135, 8640, 135, 135, 135, 8640, 135, 1080, 8640, 8640, 1080, 135, 8640, 135, 1080, 1080, 135, 1080, 135, 8640, 135, 135, 8640, 135, 8640, 8640, 1080, 8640, 1080, 135, 1080, 8640, 1080, 8640, 135, 8640, 135, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 135, 8640, 135, 8640, 1080, 1080, 135, 1080, 8640, 1080, 1080, 8640, 135, 8640, 8640, 1080, 135, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 135, 8640, 1080, 8640, 8640, 135, 8640, 1080, 1080, 8640, 135, 1080, 135, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 135, 135, 135, 135]
Prompts retrieved: 846315 . Total input tokens: 188481277 . Total output tokens: 166186996
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 79.1223115758039,
    "estimated_duration": 3600.0772095360085,
    "input_throughput": 6387.949385942185,
    "output_throughput": 5596.814964587072,
    "total_throughput": 11984.764350529256,
    "itl": 89.48973293807194,
    "ttft": 1713228.0353882278,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 463,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.437127399286283,
    "arrivals": 281942,
    "finished_requests": 93186,
    "scheduler_time": 243.33345959121021
}
#Debug simulation 
Total elapsed time: 79.12248331867158. Arrivals time: 0.4550140956416726 Scheduler time: 78.45614291448146 Scheduler overhead time: 0.08116689417511225 Adapter cache time: 0.017902526538819075 Engine time: 0.08032828290015459 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_16-16-16/adapters_256_slots_32_rate_0.8-0.1-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_16-16-16/adapters_256_slots_32_rate_0.8-0.1-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 135, 8640, 8640, 135, 8640, 1080, 8640, 135, 1080, 135, 8640, 1080, 1080, 1080, 1080, 8640, 135, 135, 135, 1080, 8640, 135, 8640, 8640, 1080, 1080, 1080, 135, 8640, 135, 1080, 1080, 135, 1080, 135, 135, 1080, 1080, 8640, 1080, 135, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 135, 8640, 8640, 1080, 135, 135, 8640, 1080, 135, 1080, 1080, 8640, 1080, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 135, 1080, 135, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 135, 8640, 8640, 135, 8640, 135, 1080, 8640, 8640, 8640, 1080, 135, 8640, 1080, 135, 135, 135, 135, 135, 8640, 1080, 135, 8640, 135, 8640, 135, 135, 1080, 1080, 8640, 1080, 8640, 135, 1080, 135, 8640, 8640, 135, 8640, 1080, 135, 8640, 135, 135, 8640, 8640, 1080, 8640, 8640, 135, 8640, 1080, 1080, 135, 1080, 8640, 8640, 135, 8640, 1080, 135, 1080, 8640, 135, 135, 135, 135, 135, 135, 8640, 135, 135, 135, 8640, 135, 1080, 8640, 8640, 1080, 135, 8640, 135, 1080, 1080, 135, 1080, 135, 8640, 135, 135, 8640, 135, 8640, 8640, 1080, 8640, 1080, 135, 1080, 8640, 1080, 8640, 135, 8640, 135, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 135, 8640, 135, 8640, 1080, 1080, 135, 1080, 8640, 1080, 1080, 8640, 135, 8640, 8640, 1080, 135, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 135, 8640, 1080, 8640, 8640, 135, 8640, 1080, 1080, 8640, 135, 1080, 135, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 135, 135, 135, 135]
Prompts retrieved: 846315 . Total input tokens: 188481277 . Total output tokens: 166186996
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 89.79954312415794,
    "estimated_duration": 3600.0873141110865,
    "input_throughput": 6545.666241936282,
    "output_throughput": 5732.714014769913,
    "total_throughput": 12278.380256706196,
    "itl": 94.73369738347401,
    "ttft": 1682647.027767935,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 407,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.598255822812196,
    "arrivals": 281942,
    "finished_requests": 95456,
    "scheduler_time": 236.83138128533307
}
#Debug simulation 
Total elapsed time: 89.7997119743377. Arrivals time: 0.4537788718007505 Scheduler time: 89.13910095067695 Scheduler overhead time: 0.07957007177174091 Adapter cache time: 0.017117363400757313 Engine time: 0.07866773242130876 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_16-16-32/adapters_256_slots_32_rate_0.8-0.1-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.0125_size_16-16-32/adapters_256_slots_32_rate_0.8-0.1-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 135, 8640, 8640, 135, 8640, 1080, 8640, 135, 1080, 135, 8640, 1080, 1080, 1080, 1080, 8640, 135, 135, 135, 1080, 8640, 135, 8640, 8640, 1080, 1080, 1080, 135, 8640, 135, 1080, 1080, 135, 1080, 135, 135, 1080, 1080, 8640, 1080, 135, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 135, 8640, 8640, 1080, 135, 135, 8640, 1080, 135, 1080, 1080, 8640, 1080, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 135, 1080, 135, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 135, 8640, 8640, 135, 8640, 135, 1080, 8640, 8640, 8640, 1080, 135, 8640, 1080, 135, 135, 135, 135, 135, 8640, 1080, 135, 8640, 135, 8640, 135, 135, 1080, 1080, 8640, 1080, 8640, 135, 1080, 135, 8640, 8640, 135, 8640, 1080, 135, 8640, 135, 135, 8640, 8640, 1080, 8640, 8640, 135, 8640, 1080, 1080, 135, 1080, 8640, 8640, 135, 8640, 1080, 135, 1080, 8640, 135, 135, 135, 135, 135, 135, 8640, 135, 135, 135, 8640, 135, 1080, 8640, 8640, 1080, 135, 8640, 135, 1080, 1080, 135, 1080, 135, 8640, 135, 135, 8640, 135, 8640, 8640, 1080, 8640, 1080, 135, 1080, 8640, 1080, 8640, 135, 8640, 135, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 135, 8640, 135, 8640, 1080, 1080, 135, 1080, 8640, 1080, 1080, 8640, 135, 8640, 8640, 1080, 135, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 135, 8640, 1080, 8640, 8640, 135, 8640, 1080, 1080, 8640, 135, 1080, 135, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 135, 135, 135, 135]
Prompts retrieved: 846315 . Total input tokens: 188481277 . Total output tokens: 166186996
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 79.26778122689575,
    "estimated_duration": 3600.0562617494556,
    "input_throughput": 6384.360223534631,
    "output_throughput": 5597.495020871544,
    "total_throughput": 11981.855244406173,
    "itl": 89.55695221780836,
    "ttft": 1710652.6923430343,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 425,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.125059757921868,
    "arrivals": 281942,
    "finished_requests": 93284,
    "scheduler_time": 243.17992253114107
}
#Debug simulation 
Total elapsed time: 79.26796030905098. Arrivals time: 0.4555277982726693 Scheduler time: 78.60314934328198 Scheduler overhead time: 0.08072061697021127 Adapter cache time: 0.017427823040634394 Engine time: 0.07973210979253054 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-8/adapters_256_slots_32_rate_0.8-0.1-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-8/adapters_256_slots_32_rate_0.8-0.1-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 66, 8640, 8640, 66, 8640, 1080, 8640, 66, 1080, 66, 8640, 1080, 1080, 1080, 1080, 8640, 66, 66, 66, 1080, 8640, 66, 8640, 8640, 1080, 1080, 1080, 66, 8640, 66, 1080, 1080, 66, 1080, 66, 66, 1080, 1080, 8640, 1080, 66, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 66, 8640, 8640, 1080, 66, 66, 8640, 1080, 66, 1080, 1080, 8640, 1080, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 66, 1080, 66, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 66, 8640, 8640, 66, 8640, 66, 1080, 8640, 8640, 8640, 1080, 66, 8640, 1080, 66, 66, 66, 66, 66, 8640, 1080, 66, 8640, 66, 8640, 66, 66, 1080, 1080, 8640, 1080, 8640, 66, 1080, 66, 8640, 8640, 66, 8640, 1080, 66, 8640, 66, 66, 8640, 8640, 1080, 8640, 8640, 66, 8640, 1080, 1080, 66, 1080, 8640, 8640, 66, 8640, 1080, 66, 1080, 8640, 66, 66, 66, 66, 66, 66, 8640, 66, 66, 66, 8640, 66, 1080, 8640, 8640, 1080, 66, 8640, 66, 1080, 1080, 66, 1080, 66, 8640, 66, 66, 8640, 66, 8640, 8640, 1080, 8640, 1080, 66, 1080, 8640, 1080, 8640, 66, 8640, 66, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 66, 8640, 66, 8640, 1080, 1080, 66, 1080, 8640, 1080, 1080, 8640, 66, 8640, 8640, 1080, 66, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 66, 8640, 1080, 8640, 8640, 66, 8640, 1080, 1080, 8640, 66, 1080, 66, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 66, 66, 66, 66]
Prompts retrieved: 840450 . Total input tokens: 187162021 . Total output tokens: 165050758
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 90.54662419110537,
    "estimated_duration": 3600.051198269839,
    "input_throughput": 6653.312600529487,
    "output_throughput": 5758.466993459169,
    "total_throughput": 12411.779593988656,
    "itl": 96.46315822246125,
    "ttft": 1682631.7389375267,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 429,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.8367234747065475,
    "arrivals": 279961,
    "finished_requests": 96482,
    "scheduler_time": 234.79561515824548
}
#Debug simulation 
Total elapsed time: 90.54679817892611. Arrivals time: 0.46909960033372045 Scheduler time: 89.8712197728455 Scheduler overhead time: 0.07918112445622683 Adapter cache time: 0.017236953135579824 Engine time: 0.07929084077477455 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-16/adapters_256_slots_32_rate_0.8-0.1-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-16/adapters_256_slots_32_rate_0.8-0.1-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 66, 8640, 8640, 66, 8640, 1080, 8640, 66, 1080, 66, 8640, 1080, 1080, 1080, 1080, 8640, 66, 66, 66, 1080, 8640, 66, 8640, 8640, 1080, 1080, 1080, 66, 8640, 66, 1080, 1080, 66, 1080, 66, 66, 1080, 1080, 8640, 1080, 66, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 66, 8640, 8640, 1080, 66, 66, 8640, 1080, 66, 1080, 1080, 8640, 1080, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 66, 1080, 66, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 66, 8640, 8640, 66, 8640, 66, 1080, 8640, 8640, 8640, 1080, 66, 8640, 1080, 66, 66, 66, 66, 66, 8640, 1080, 66, 8640, 66, 8640, 66, 66, 1080, 1080, 8640, 1080, 8640, 66, 1080, 66, 8640, 8640, 66, 8640, 1080, 66, 8640, 66, 66, 8640, 8640, 1080, 8640, 8640, 66, 8640, 1080, 1080, 66, 1080, 8640, 8640, 66, 8640, 1080, 66, 1080, 8640, 66, 66, 66, 66, 66, 66, 8640, 66, 66, 66, 8640, 66, 1080, 8640, 8640, 1080, 66, 8640, 66, 1080, 1080, 66, 1080, 66, 8640, 66, 66, 8640, 66, 8640, 8640, 1080, 8640, 1080, 66, 1080, 8640, 1080, 8640, 66, 8640, 66, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 66, 8640, 66, 8640, 1080, 1080, 66, 1080, 8640, 1080, 1080, 8640, 66, 8640, 8640, 1080, 66, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 66, 8640, 1080, 8640, 8640, 66, 8640, 1080, 1080, 8640, 66, 1080, 66, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 66, 66, 66, 66]
Prompts retrieved: 840450 . Total input tokens: 187162021 . Total output tokens: 165050758
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 90.8324971711263,
    "estimated_duration": 3600.07612121709,
    "input_throughput": 6578.24368224572,
    "output_throughput": 5710.41231012913,
    "total_throughput": 12288.65599237485,
    "itl": 94.38826590313509,
    "ttft": 1683276.442911719,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 435,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.183754354328853,
    "arrivals": 279961,
    "finished_requests": 95397,
    "scheduler_time": 237.17269626842045
}
#Debug simulation 
Total elapsed time: 90.83266586996615. Arrivals time: 0.470374196767807 Scheduler time: 90.15171006787568 Scheduler overhead time: 0.08105137897655368 Adapter cache time: 0.01781028090044856 Engine time: 0.07997087761759758 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-32/adapters_256_slots_32_rate_0.8-0.1-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-32/adapters_256_slots_32_rate_0.8-0.1-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 66, 8640, 8640, 66, 8640, 1080, 8640, 66, 1080, 66, 8640, 1080, 1080, 1080, 1080, 8640, 66, 66, 66, 1080, 8640, 66, 8640, 8640, 1080, 1080, 1080, 66, 8640, 66, 1080, 1080, 66, 1080, 66, 66, 1080, 1080, 8640, 1080, 66, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 66, 8640, 8640, 1080, 66, 66, 8640, 1080, 66, 1080, 1080, 8640, 1080, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 66, 1080, 66, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 66, 8640, 8640, 66, 8640, 66, 1080, 8640, 8640, 8640, 1080, 66, 8640, 1080, 66, 66, 66, 66, 66, 8640, 1080, 66, 8640, 66, 8640, 66, 66, 1080, 1080, 8640, 1080, 8640, 66, 1080, 66, 8640, 8640, 66, 8640, 1080, 66, 8640, 66, 66, 8640, 8640, 1080, 8640, 8640, 66, 8640, 1080, 1080, 66, 1080, 8640, 8640, 66, 8640, 1080, 66, 1080, 8640, 66, 66, 66, 66, 66, 66, 8640, 66, 66, 66, 8640, 66, 1080, 8640, 8640, 1080, 66, 8640, 66, 1080, 1080, 66, 1080, 66, 8640, 66, 66, 8640, 66, 8640, 8640, 1080, 8640, 1080, 66, 1080, 8640, 1080, 8640, 66, 8640, 66, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 66, 8640, 66, 8640, 1080, 1080, 66, 1080, 8640, 1080, 1080, 8640, 66, 8640, 8640, 1080, 66, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 66, 8640, 1080, 8640, 8640, 66, 8640, 1080, 1080, 8640, 66, 1080, 66, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 66, 66, 66, 66]
Prompts retrieved: 840450 . Total input tokens: 187162021 . Total output tokens: 165050758
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 79.43690375285223,
    "estimated_duration": 3600.07015809335,
    "input_throughput": 6450.138186278613,
    "output_throughput": 5593.775986483934,
    "total_throughput": 12043.914172762547,
    "itl": 89.59778970510997,
    "ttft": 1707750.0004260535,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 471,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.5440919870185,
    "arrivals": 279961,
    "finished_requests": 93611,
    "scheduler_time": 242.81428889827495
}
#Debug simulation 
Total elapsed time: 79.4370751939714. Arrivals time: 0.439499378670007 Scheduler time: 78.78751478670165 Scheduler overhead time: 0.08043625066056848 Adapter cache time: 0.01791915250942111 Engine time: 0.0801886091940105 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_8-16-16/adapters_256_slots_32_rate_0.8-0.1-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_8-16-16/adapters_256_slots_32_rate_0.8-0.1-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 66, 8640, 8640, 66, 8640, 1080, 8640, 66, 1080, 66, 8640, 1080, 1080, 1080, 1080, 8640, 66, 66, 66, 1080, 8640, 66, 8640, 8640, 1080, 1080, 1080, 66, 8640, 66, 1080, 1080, 66, 1080, 66, 66, 1080, 1080, 8640, 1080, 66, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 66, 8640, 8640, 1080, 66, 66, 8640, 1080, 66, 1080, 1080, 8640, 1080, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 66, 1080, 66, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 66, 8640, 8640, 66, 8640, 66, 1080, 8640, 8640, 8640, 1080, 66, 8640, 1080, 66, 66, 66, 66, 66, 8640, 1080, 66, 8640, 66, 8640, 66, 66, 1080, 1080, 8640, 1080, 8640, 66, 1080, 66, 8640, 8640, 66, 8640, 1080, 66, 8640, 66, 66, 8640, 8640, 1080, 8640, 8640, 66, 8640, 1080, 1080, 66, 1080, 8640, 8640, 66, 8640, 1080, 66, 1080, 8640, 66, 66, 66, 66, 66, 66, 8640, 66, 66, 66, 8640, 66, 1080, 8640, 8640, 1080, 66, 8640, 66, 1080, 1080, 66, 1080, 66, 8640, 66, 66, 8640, 66, 8640, 8640, 1080, 8640, 1080, 66, 1080, 8640, 1080, 8640, 66, 8640, 66, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 66, 8640, 66, 8640, 1080, 1080, 66, 1080, 8640, 1080, 1080, 8640, 66, 8640, 8640, 1080, 66, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 66, 8640, 1080, 8640, 8640, 66, 8640, 1080, 1080, 8640, 66, 1080, 66, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 66, 66, 66, 66]
Prompts retrieved: 840450 . Total input tokens: 187162021 . Total output tokens: 165050758
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 82.57927294494584,
    "estimated_duration": 3600.019513140656,
    "input_throughput": 6583.69431429078,
    "output_throughput": 5703.329641701805,
    "total_throughput": 12287.023955992585,
    "itl": 94.51658294147843,
    "ttft": 1696436.4146867015,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 447,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.0562929225387014,
    "arrivals": 279961,
    "finished_requests": 95523,
    "scheduler_time": 237.4432361115684
}
#Debug simulation 
Total elapsed time: 82.57944477768615. Arrivals time: 0.4632730851881206 Scheduler time: 81.90957342414185 Scheduler overhead time: 0.07953871879726648 Adapter cache time: 0.01715035503730178 Engine time: 0.07869579689577222 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_8-16-32/adapters_256_slots_32_rate_0.8-0.1-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_8-16-32/adapters_256_slots_32_rate_0.8-0.1-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 66, 8640, 8640, 66, 8640, 1080, 8640, 66, 1080, 66, 8640, 1080, 1080, 1080, 1080, 8640, 66, 66, 66, 1080, 8640, 66, 8640, 8640, 1080, 1080, 1080, 66, 8640, 66, 1080, 1080, 66, 1080, 66, 66, 1080, 1080, 8640, 1080, 66, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 66, 8640, 8640, 1080, 66, 66, 8640, 1080, 66, 1080, 1080, 8640, 1080, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 66, 1080, 66, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 66, 8640, 8640, 66, 8640, 66, 1080, 8640, 8640, 8640, 1080, 66, 8640, 1080, 66, 66, 66, 66, 66, 8640, 1080, 66, 8640, 66, 8640, 66, 66, 1080, 1080, 8640, 1080, 8640, 66, 1080, 66, 8640, 8640, 66, 8640, 1080, 66, 8640, 66, 66, 8640, 8640, 1080, 8640, 8640, 66, 8640, 1080, 1080, 66, 1080, 8640, 8640, 66, 8640, 1080, 66, 1080, 8640, 66, 66, 66, 66, 66, 66, 8640, 66, 66, 66, 8640, 66, 1080, 8640, 8640, 1080, 66, 8640, 66, 1080, 1080, 66, 1080, 66, 8640, 66, 66, 8640, 66, 8640, 8640, 1080, 8640, 1080, 66, 1080, 8640, 1080, 8640, 66, 8640, 66, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 66, 8640, 66, 8640, 1080, 1080, 66, 1080, 8640, 1080, 1080, 8640, 66, 8640, 8640, 1080, 66, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 66, 8640, 1080, 8640, 8640, 66, 8640, 1080, 1080, 8640, 66, 1080, 66, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 66, 66, 66, 66]
Prompts retrieved: 840450 . Total input tokens: 187162021 . Total output tokens: 165050758
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 78.85612931195647,
    "estimated_duration": 3600.0489924361714,
    "input_throughput": 6443.623142001251,
    "output_throughput": 5592.107230289849,
    "total_throughput": 12035.7303722911,
    "itl": 89.43605353011394,
    "ttft": 1711490.094875751,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 473,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.5201149117341526,
    "arrivals": 279961,
    "finished_requests": 93521,
    "scheduler_time": 242.8691129235318
}
#Debug simulation 
Total elapsed time: 78.85629524802789. Arrivals time: 0.4395220410078764 Scheduler time: 78.20772142848 Scheduler overhead time: 0.07992694154381752 Adapter cache time: 0.017839923035353422 Engine time: 0.08006073348224163 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_16-16-16/adapters_256_slots_32_rate_0.8-0.1-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_16-16-16/adapters_256_slots_32_rate_0.8-0.1-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 66, 8640, 8640, 66, 8640, 1080, 8640, 66, 1080, 66, 8640, 1080, 1080, 1080, 1080, 8640, 66, 66, 66, 1080, 8640, 66, 8640, 8640, 1080, 1080, 1080, 66, 8640, 66, 1080, 1080, 66, 1080, 66, 66, 1080, 1080, 8640, 1080, 66, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 66, 8640, 8640, 1080, 66, 66, 8640, 1080, 66, 1080, 1080, 8640, 1080, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 66, 1080, 66, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 66, 8640, 8640, 66, 8640, 66, 1080, 8640, 8640, 8640, 1080, 66, 8640, 1080, 66, 66, 66, 66, 66, 8640, 1080, 66, 8640, 66, 8640, 66, 66, 1080, 1080, 8640, 1080, 8640, 66, 1080, 66, 8640, 8640, 66, 8640, 1080, 66, 8640, 66, 66, 8640, 8640, 1080, 8640, 8640, 66, 8640, 1080, 1080, 66, 1080, 8640, 8640, 66, 8640, 1080, 66, 1080, 8640, 66, 66, 66, 66, 66, 66, 8640, 66, 66, 66, 8640, 66, 1080, 8640, 8640, 1080, 66, 8640, 66, 1080, 1080, 66, 1080, 66, 8640, 66, 66, 8640, 66, 8640, 8640, 1080, 8640, 1080, 66, 1080, 8640, 1080, 8640, 66, 8640, 66, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 66, 8640, 66, 8640, 1080, 1080, 66, 1080, 8640, 1080, 1080, 8640, 66, 8640, 8640, 1080, 66, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 66, 8640, 1080, 8640, 8640, 66, 8640, 1080, 1080, 8640, 66, 1080, 66, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 66, 66, 66, 66]
Prompts retrieved: 840450 . Total input tokens: 187162021 . Total output tokens: 165050758
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 88.82202298613265,
    "estimated_duration": 3600.0033983839653,
    "input_throughput": 6586.518782355606,
    "output_throughput": 5717.612102599642,
    "total_throughput": 12304.130884955248,
    "itl": 94.2712125419476,
    "ttft": 1680852.3857359437,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 433,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.764237767267029,
    "arrivals": 279961,
    "finished_requests": 95595,
    "scheduler_time": 237.12596917369004
}
#Debug simulation 
Total elapsed time: 88.82220203895122. Arrivals time: 0.4655196154490113 Scheduler time: 88.14952802890912 Scheduler overhead time: 0.08005124563351274 Adapter cache time: 0.017424076795578003 Engine time: 0.07853683549910784 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_16-16-32/adapters_256_slots_32_rate_0.8-0.1-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.00625_size_16-16-32/adapters_256_slots_32_rate_0.8-0.1-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 66, 8640, 8640, 66, 8640, 1080, 8640, 66, 1080, 66, 8640, 1080, 1080, 1080, 1080, 8640, 66, 66, 66, 1080, 8640, 66, 8640, 8640, 1080, 1080, 1080, 66, 8640, 66, 1080, 1080, 66, 1080, 66, 66, 1080, 1080, 8640, 1080, 66, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 66, 8640, 8640, 1080, 66, 66, 8640, 1080, 66, 1080, 1080, 8640, 1080, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 66, 1080, 66, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 66, 8640, 8640, 66, 8640, 66, 1080, 8640, 8640, 8640, 1080, 66, 8640, 1080, 66, 66, 66, 66, 66, 8640, 1080, 66, 8640, 66, 8640, 66, 66, 1080, 1080, 8640, 1080, 8640, 66, 1080, 66, 8640, 8640, 66, 8640, 1080, 66, 8640, 66, 66, 8640, 8640, 1080, 8640, 8640, 66, 8640, 1080, 1080, 66, 1080, 8640, 8640, 66, 8640, 1080, 66, 1080, 8640, 66, 66, 66, 66, 66, 66, 8640, 66, 66, 66, 8640, 66, 1080, 8640, 8640, 1080, 66, 8640, 66, 1080, 1080, 66, 1080, 66, 8640, 66, 66, 8640, 66, 8640, 8640, 1080, 8640, 1080, 66, 1080, 8640, 1080, 8640, 66, 8640, 66, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 66, 8640, 66, 8640, 1080, 1080, 66, 1080, 8640, 1080, 1080, 8640, 66, 8640, 8640, 1080, 66, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 66, 8640, 1080, 8640, 8640, 66, 8640, 1080, 1080, 8640, 66, 1080, 66, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 66, 66, 66, 66]
Prompts retrieved: 840450 . Total input tokens: 187162021 . Total output tokens: 165050758
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 81.80904991691932,
    "estimated_duration": 3600.0126555522324,
    "input_throughput": 6452.299261830464,
    "output_throughput": 5590.829512490301,
    "total_throughput": 12043.128774320765,
    "itl": 89.34094603202509,
    "ttft": 1708231.7298432312,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 443,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.2667009694688245,
    "arrivals": 279961,
    "finished_requests": 93641,
    "scheduler_time": 243.1768399185404
}
#Debug simulation 
Total elapsed time: 81.80922407796606. Arrivals time: 0.44910156773403287 Scheduler time: 81.14949300978333 Scheduler overhead time: 0.080608069896698 Adapter cache time: 0.01782606588676572 Engine time: 0.08027354255318642 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-8/adapters_256_slots_32_rate_0.8-0.1-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-8/adapters_256_slots_32_rate_0.8-0.1-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 33, 8640, 8640, 33, 8640, 1080, 8640, 33, 1080, 33, 8640, 1080, 1080, 1080, 1080, 8640, 33, 33, 33, 1080, 8640, 33, 8640, 8640, 1080, 1080, 1080, 33, 8640, 33, 1080, 1080, 33, 1080, 33, 33, 1080, 1080, 8640, 1080, 33, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 33, 8640, 8640, 1080, 33, 33, 8640, 1080, 33, 1080, 1080, 8640, 1080, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 1080, 33, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 33, 8640, 8640, 33, 8640, 33, 1080, 8640, 8640, 8640, 1080, 33, 8640, 1080, 33, 33, 33, 33, 33, 8640, 1080, 33, 8640, 33, 8640, 33, 33, 1080, 1080, 8640, 1080, 8640, 33, 1080, 33, 8640, 8640, 33, 8640, 1080, 33, 8640, 33, 33, 8640, 8640, 1080, 8640, 8640, 33, 8640, 1080, 1080, 33, 1080, 8640, 8640, 33, 8640, 1080, 33, 1080, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 1080, 8640, 8640, 1080, 33, 8640, 33, 1080, 1080, 33, 1080, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 1080, 8640, 1080, 33, 1080, 8640, 1080, 8640, 33, 8640, 33, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 33, 8640, 33, 8640, 1080, 1080, 33, 1080, 8640, 1080, 1080, 8640, 33, 8640, 8640, 1080, 33, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 33, 8640, 1080, 8640, 8640, 33, 8640, 1080, 1080, 8640, 33, 1080, 33, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 33, 33, 33, 33]
Prompts retrieved: 837645 . Total input tokens: 186540932 . Total output tokens: 164512523
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 85.95546081103384,
    "estimated_duration": 3600.0321884303303,
    "input_throughput": 6651.57636005493,
    "output_throughput": 5799.866475389454,
    "total_throughput": 12451.442835444383,
    "itl": 97.34457875505043,
    "ttft": 1686929.521715671,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 420,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.777211793418996,
    "arrivals": 278999,
    "finished_requests": 96662,
    "scheduler_time": 232.71791636806074
}
#Debug simulation 
Total elapsed time: 85.95562816783786. Arrivals time: 0.46791334077715874 Scheduler time: 85.28367979638278 Scheduler overhead time: 0.07870652480050921 Adapter cache time: 0.017121135722845793 Engine time: 0.07752621779218316 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-16/adapters_256_slots_32_rate_0.8-0.1-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-16/adapters_256_slots_32_rate_0.8-0.1-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 33, 8640, 8640, 33, 8640, 1080, 8640, 33, 1080, 33, 8640, 1080, 1080, 1080, 1080, 8640, 33, 33, 33, 1080, 8640, 33, 8640, 8640, 1080, 1080, 1080, 33, 8640, 33, 1080, 1080, 33, 1080, 33, 33, 1080, 1080, 8640, 1080, 33, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 33, 8640, 8640, 1080, 33, 33, 8640, 1080, 33, 1080, 1080, 8640, 1080, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 1080, 33, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 33, 8640, 8640, 33, 8640, 33, 1080, 8640, 8640, 8640, 1080, 33, 8640, 1080, 33, 33, 33, 33, 33, 8640, 1080, 33, 8640, 33, 8640, 33, 33, 1080, 1080, 8640, 1080, 8640, 33, 1080, 33, 8640, 8640, 33, 8640, 1080, 33, 8640, 33, 33, 8640, 8640, 1080, 8640, 8640, 33, 8640, 1080, 1080, 33, 1080, 8640, 8640, 33, 8640, 1080, 33, 1080, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 1080, 8640, 8640, 1080, 33, 8640, 33, 1080, 1080, 33, 1080, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 1080, 8640, 1080, 33, 1080, 8640, 1080, 8640, 33, 8640, 33, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 33, 8640, 33, 8640, 1080, 1080, 33, 1080, 8640, 1080, 1080, 8640, 33, 8640, 8640, 1080, 33, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 33, 8640, 1080, 8640, 8640, 33, 8640, 1080, 1080, 8640, 33, 1080, 33, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 33, 33, 33, 33]
Prompts retrieved: 837645 . Total input tokens: 186540932 . Total output tokens: 164512523
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 83.5577794527635,
    "estimated_duration": 3600.063135035294,
    "input_throughput": 6578.446297100237,
    "output_throughput": 5738.606859125947,
    "total_throughput": 12317.053156226184,
    "itl": 95.16002678791372,
    "ttft": 1682727.4058154926,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 486,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.5690278241504036,
    "arrivals": 278999,
    "finished_requests": 95658,
    "scheduler_time": 235.66503427102666
}
#Debug simulation 
Total elapsed time: 83.55793862976134. Arrivals time: 0.46415502578020096 Scheduler time: 82.88745447807014 Scheduler overhead time: 0.07881274586543441 Adapter cache time: 0.017711411230266094 Engine time: 0.0791877955198288 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-32/adapters_256_slots_32_rate_0.8-0.1-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-32/adapters_256_slots_32_rate_0.8-0.1-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 33, 8640, 8640, 33, 8640, 1080, 8640, 33, 1080, 33, 8640, 1080, 1080, 1080, 1080, 8640, 33, 33, 33, 1080, 8640, 33, 8640, 8640, 1080, 1080, 1080, 33, 8640, 33, 1080, 1080, 33, 1080, 33, 33, 1080, 1080, 8640, 1080, 33, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 33, 8640, 8640, 1080, 33, 33, 8640, 1080, 33, 1080, 1080, 8640, 1080, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 1080, 33, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 33, 8640, 8640, 33, 8640, 33, 1080, 8640, 8640, 8640, 1080, 33, 8640, 1080, 33, 33, 33, 33, 33, 8640, 1080, 33, 8640, 33, 8640, 33, 33, 1080, 1080, 8640, 1080, 8640, 33, 1080, 33, 8640, 8640, 33, 8640, 1080, 33, 8640, 33, 33, 8640, 8640, 1080, 8640, 8640, 33, 8640, 1080, 1080, 33, 1080, 8640, 8640, 33, 8640, 1080, 33, 1080, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 1080, 8640, 8640, 1080, 33, 8640, 33, 1080, 1080, 33, 1080, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 1080, 8640, 1080, 33, 1080, 8640, 1080, 8640, 33, 8640, 33, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 33, 8640, 33, 8640, 1080, 1080, 33, 1080, 8640, 1080, 1080, 8640, 33, 8640, 8640, 1080, 33, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 33, 8640, 1080, 8640, 8640, 33, 8640, 1080, 1080, 8640, 33, 1080, 33, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 33, 33, 33, 33]
Prompts retrieved: 837645 . Total input tokens: 186540932 . Total output tokens: 164512523
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 76.29729655012488,
    "estimated_duration": 3600.0756487277954,
    "input_throughput": 6443.245993510477,
    "output_throughput": 5622.129636957073,
    "total_throughput": 12065.37563046755,
    "itl": 90.08880255509452,
    "ttft": 1710632.2743722706,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 493,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.7046775372932035,
    "arrivals": 278999,
    "finished_requests": 93708,
    "scheduler_time": 241.3477652258321
}
#Debug simulation 
Total elapsed time: 76.29746592603624. Arrivals time: 0.44200391974300146 Scheduler time: 75.64576257066801 Scheduler overhead time: 0.0805864967405796 Adapter cache time: 0.017872849479317665 Engine time: 0.07970791030675173 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_8-16-16/adapters_256_slots_32_rate_0.8-0.1-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_8-16-16/adapters_256_slots_32_rate_0.8-0.1-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 33, 8640, 8640, 33, 8640, 1080, 8640, 33, 1080, 33, 8640, 1080, 1080, 1080, 1080, 8640, 33, 33, 33, 1080, 8640, 33, 8640, 8640, 1080, 1080, 1080, 33, 8640, 33, 1080, 1080, 33, 1080, 33, 33, 1080, 1080, 8640, 1080, 33, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 33, 8640, 8640, 1080, 33, 33, 8640, 1080, 33, 1080, 1080, 8640, 1080, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 1080, 33, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 33, 8640, 8640, 33, 8640, 33, 1080, 8640, 8640, 8640, 1080, 33, 8640, 1080, 33, 33, 33, 33, 33, 8640, 1080, 33, 8640, 33, 8640, 33, 33, 1080, 1080, 8640, 1080, 8640, 33, 1080, 33, 8640, 8640, 33, 8640, 1080, 33, 8640, 33, 33, 8640, 8640, 1080, 8640, 8640, 33, 8640, 1080, 1080, 33, 1080, 8640, 8640, 33, 8640, 1080, 33, 1080, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 1080, 8640, 8640, 1080, 33, 8640, 33, 1080, 1080, 33, 1080, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 1080, 8640, 1080, 33, 1080, 8640, 1080, 8640, 33, 8640, 33, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 33, 8640, 33, 8640, 1080, 1080, 33, 1080, 8640, 1080, 1080, 8640, 33, 8640, 8640, 1080, 33, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 33, 8640, 1080, 8640, 8640, 33, 8640, 1080, 1080, 8640, 33, 1080, 33, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 33, 33, 33, 33]
Prompts retrieved: 837645 . Total input tokens: 186540932 . Total output tokens: 164512523
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 79.29975626897067,
    "estimated_duration": 3600.0079973867555,
    "input_throughput": 6578.771218617275,
    "output_throughput": 5757.411932152797,
    "total_throughput": 12336.183150770072,
    "itl": 95.50072426446079,
    "ttft": 1692061.1709161354,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 456,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.1304068626835906,
    "arrivals": 278999,
    "finished_requests": 95799,
    "scheduler_time": 234.76295433956022
}
#Debug simulation 
Total elapsed time: 79.29993213713169. Arrivals time: 0.46135782776400447 Scheduler time: 78.6334356800653 Scheduler overhead time: 0.07847300451248884 Adapter cache time: 0.017719721421599388 Engine time: 0.07798381708562374 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_8-16-32/adapters_256_slots_32_rate_0.8-0.1-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_8-16-32/adapters_256_slots_32_rate_0.8-0.1-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 33, 8640, 8640, 33, 8640, 1080, 8640, 33, 1080, 33, 8640, 1080, 1080, 1080, 1080, 8640, 33, 33, 33, 1080, 8640, 33, 8640, 8640, 1080, 1080, 1080, 33, 8640, 33, 1080, 1080, 33, 1080, 33, 33, 1080, 1080, 8640, 1080, 33, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 33, 8640, 8640, 1080, 33, 33, 8640, 1080, 33, 1080, 1080, 8640, 1080, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 1080, 33, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 33, 8640, 8640, 33, 8640, 33, 1080, 8640, 8640, 8640, 1080, 33, 8640, 1080, 33, 33, 33, 33, 33, 8640, 1080, 33, 8640, 33, 8640, 33, 33, 1080, 1080, 8640, 1080, 8640, 33, 1080, 33, 8640, 8640, 33, 8640, 1080, 33, 8640, 33, 33, 8640, 8640, 1080, 8640, 8640, 33, 8640, 1080, 1080, 33, 1080, 8640, 8640, 33, 8640, 1080, 33, 1080, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 1080, 8640, 8640, 1080, 33, 8640, 33, 1080, 1080, 33, 1080, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 1080, 8640, 1080, 33, 1080, 8640, 1080, 8640, 33, 8640, 33, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 33, 8640, 33, 8640, 1080, 1080, 33, 1080, 8640, 1080, 1080, 8640, 33, 8640, 8640, 1080, 33, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 33, 8640, 1080, 8640, 8640, 33, 8640, 1080, 1080, 8640, 33, 1080, 33, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 33, 33, 33, 33]
Prompts retrieved: 837645 . Total input tokens: 186540932 . Total output tokens: 164512523
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 84.22101656580344,
    "estimated_duration": 3600.0048144719813,
    "input_throughput": 6425.1330739935665,
    "output_throughput": 5619.990261865097,
    "total_throughput": 12045.123335858663,
    "itl": 89.92889110464445,
    "ttft": 1693821.7970017074,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 415,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.0938529746281196,
    "arrivals": 278999,
    "finished_requests": 93493,
    "scheduler_time": 241.61315593483917
}
#Debug simulation 
Total elapsed time: 84.22118582762778. Arrivals time: 0.45609163818880916 Scheduler time: 83.55397076671943 Scheduler overhead time: 0.0814367551356554 Adapter cache time: 0.017845313530415297 Engine time: 0.0800820030272007 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_16-16-16/adapters_256_slots_32_rate_0.8-0.1-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_16-16-16/adapters_256_slots_32_rate_0.8-0.1-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 33, 8640, 8640, 33, 8640, 1080, 8640, 33, 1080, 33, 8640, 1080, 1080, 1080, 1080, 8640, 33, 33, 33, 1080, 8640, 33, 8640, 8640, 1080, 1080, 1080, 33, 8640, 33, 1080, 1080, 33, 1080, 33, 33, 1080, 1080, 8640, 1080, 33, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 33, 8640, 8640, 1080, 33, 33, 8640, 1080, 33, 1080, 1080, 8640, 1080, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 1080, 33, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 33, 8640, 8640, 33, 8640, 33, 1080, 8640, 8640, 8640, 1080, 33, 8640, 1080, 33, 33, 33, 33, 33, 8640, 1080, 33, 8640, 33, 8640, 33, 33, 1080, 1080, 8640, 1080, 8640, 33, 1080, 33, 8640, 8640, 33, 8640, 1080, 33, 8640, 33, 33, 8640, 8640, 1080, 8640, 8640, 33, 8640, 1080, 1080, 33, 1080, 8640, 8640, 33, 8640, 1080, 33, 1080, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 1080, 8640, 8640, 1080, 33, 8640, 33, 1080, 1080, 33, 1080, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 1080, 8640, 1080, 33, 1080, 8640, 1080, 8640, 33, 8640, 33, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 33, 8640, 33, 8640, 1080, 1080, 33, 1080, 8640, 1080, 1080, 8640, 33, 8640, 8640, 1080, 33, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 33, 8640, 1080, 8640, 8640, 33, 8640, 1080, 1080, 8640, 33, 1080, 33, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 33, 33, 33, 33]
Prompts retrieved: 837645 . Total input tokens: 186540932 . Total output tokens: 164512523
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 89.72067563422024,
    "estimated_duration": 3600.0613781750853,
    "input_throughput": 6587.425187739852,
    "output_throughput": 5749.226978594417,
    "total_throughput": 12336.652166334268,
    "itl": 94.92057033493519,
    "ttft": 1678172.4369643298,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 395,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.52164877152535,
    "arrivals": 278999,
    "finished_requests": 95585,
    "scheduler_time": 236.32793193996596
}
#Debug simulation 
Total elapsed time: 89.72083734488115. Arrivals time: 0.4686576724052429 Scheduler time: 89.04359932569787 Scheduler overhead time: 0.08037045272067189 Adapter cache time: 0.01723724789917469 Engine time: 0.07966533862054348 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_16-16-32/adapters_256_slots_32_rate_0.8-0.1-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.1-0.003125_size_16-16-32/adapters_256_slots_32_rate_0.8-0.1-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 33, 8640, 8640, 33, 8640, 1080, 8640, 33, 1080, 33, 8640, 1080, 1080, 1080, 1080, 8640, 33, 33, 33, 1080, 8640, 33, 8640, 8640, 1080, 1080, 1080, 33, 8640, 33, 1080, 1080, 33, 1080, 33, 33, 1080, 1080, 8640, 1080, 33, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 33, 8640, 8640, 1080, 33, 33, 8640, 1080, 33, 1080, 1080, 8640, 1080, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 1080, 33, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 33, 8640, 8640, 33, 8640, 33, 1080, 8640, 8640, 8640, 1080, 33, 8640, 1080, 33, 33, 33, 33, 33, 8640, 1080, 33, 8640, 33, 8640, 33, 33, 1080, 1080, 8640, 1080, 8640, 33, 1080, 33, 8640, 8640, 33, 8640, 1080, 33, 8640, 33, 33, 8640, 8640, 1080, 8640, 8640, 33, 8640, 1080, 1080, 33, 1080, 8640, 8640, 33, 8640, 1080, 33, 1080, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 1080, 8640, 8640, 1080, 33, 8640, 33, 1080, 1080, 33, 1080, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 1080, 8640, 1080, 33, 1080, 8640, 1080, 8640, 33, 8640, 33, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 33, 8640, 33, 8640, 1080, 1080, 33, 1080, 8640, 1080, 1080, 8640, 33, 8640, 8640, 1080, 33, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 33, 8640, 1080, 8640, 8640, 33, 8640, 1080, 1080, 8640, 33, 1080, 33, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 33, 33, 33, 33]
Prompts retrieved: 837645 . Total input tokens: 186540932 . Total output tokens: 164512523
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 79.31088662100956,
    "estimated_duration": 3600.101402150632,
    "input_throughput": 6402.360218584643,
    "output_throughput": 5603.432444416449,
    "total_throughput": 12005.792663001092,
    "itl": 89.6839377895074,
    "ttft": 1704068.5041989218,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 508,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.740640891827674,
    "arrivals": 278999,
    "finished_requests": 93304,
    "scheduler_time": 242.3246936043765
}
#Debug simulation 
Total elapsed time: 79.31105182832107. Arrivals time: 0.44276083866134286 Scheduler time: 78.65680142911151 Scheduler overhead time: 0.08083541179075837 Adapter cache time: 0.018440309446305037 Engine time: 0.08057714998722076 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.025_size_8-8-8/adapters_256_slots_32_rate_0.8-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.025_size_8-8-8/adapters_256_slots_32_rate_0.8-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 8640, 270, 8640, 8640, 270, 8640, 540, 8640, 270, 540, 270, 8640, 540, 540, 540, 540, 8640, 270, 270, 270, 540, 8640, 270, 8640, 8640, 540, 540, 540, 270, 8640, 270, 540, 540, 270, 540, 270, 270, 540, 540, 8640, 540, 270, 540, 8640, 540, 540, 8640, 540, 8640, 270, 8640, 8640, 540, 270, 270, 8640, 540, 270, 540, 540, 8640, 540, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 8640, 8640, 270, 8640, 270, 540, 8640, 8640, 8640, 540, 270, 8640, 540, 270, 270, 270, 270, 270, 8640, 540, 270, 8640, 270, 8640, 270, 270, 540, 540, 8640, 540, 8640, 270, 540, 270, 8640, 8640, 270, 8640, 540, 270, 8640, 270, 270, 8640, 8640, 540, 8640, 8640, 270, 8640, 540, 540, 270, 540, 8640, 8640, 270, 8640, 540, 270, 540, 8640, 270, 270, 270, 270, 270, 270, 8640, 270, 270, 270, 8640, 270, 540, 8640, 8640, 540, 270, 8640, 270, 540, 540, 270, 540, 270, 8640, 270, 270, 8640, 270, 8640, 8640, 540, 8640, 540, 270, 540, 8640, 540, 8640, 270, 8640, 270, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 540, 270, 8640, 270, 8640, 540, 540, 270, 540, 8640, 540, 540, 8640, 270, 8640, 8640, 540, 270, 8640, 8640, 540, 540, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 8640, 270, 8640, 540, 8640, 8640, 270, 8640, 540, 540, 8640, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 8640, 540, 270, 270, 270, 270]
Prompts retrieved: 811890 . Total input tokens: 180825203 . Total output tokens: 159433071
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 83.87255601305515,
    "estimated_duration": 3600.06022923056,
    "input_throughput": 6542.245545995731,
    "output_throughput": 5732.873531510639,
    "total_throughput": 12275.11907750637,
    "itl": 95.8487442286083,
    "ttft": 1682155.9270731404,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 417,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.7573745663231457,
    "arrivals": 270522,
    "finished_requests": 95415,
    "scheduler_time": 235.80286111780904
}
#Debug simulation 
Total elapsed time: 83.8727249451913. Arrivals time: 0.4530458450317383 Scheduler time: 83.21544037992135 Scheduler overhead time: 0.07860293099656701 Adapter cache time: 0.017419546376913786 Engine time: 0.07761963550001383 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.025_size_8-8-16/adapters_256_slots_32_rate_0.8-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.025_size_8-8-16/adapters_256_slots_32_rate_0.8-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 8640, 270, 8640, 8640, 270, 8640, 540, 8640, 270, 540, 270, 8640, 540, 540, 540, 540, 8640, 270, 270, 270, 540, 8640, 270, 8640, 8640, 540, 540, 540, 270, 8640, 270, 540, 540, 270, 540, 270, 270, 540, 540, 8640, 540, 270, 540, 8640, 540, 540, 8640, 540, 8640, 270, 8640, 8640, 540, 270, 270, 8640, 540, 270, 540, 540, 8640, 540, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 8640, 8640, 270, 8640, 270, 540, 8640, 8640, 8640, 540, 270, 8640, 540, 270, 270, 270, 270, 270, 8640, 540, 270, 8640, 270, 8640, 270, 270, 540, 540, 8640, 540, 8640, 270, 540, 270, 8640, 8640, 270, 8640, 540, 270, 8640, 270, 270, 8640, 8640, 540, 8640, 8640, 270, 8640, 540, 540, 270, 540, 8640, 8640, 270, 8640, 540, 270, 540, 8640, 270, 270, 270, 270, 270, 270, 8640, 270, 270, 270, 8640, 270, 540, 8640, 8640, 540, 270, 8640, 270, 540, 540, 270, 540, 270, 8640, 270, 270, 8640, 270, 8640, 8640, 540, 8640, 540, 270, 540, 8640, 540, 8640, 270, 8640, 270, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 540, 270, 8640, 270, 8640, 540, 540, 270, 540, 8640, 540, 540, 8640, 270, 8640, 8640, 540, 270, 8640, 8640, 540, 540, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 8640, 270, 8640, 540, 8640, 8640, 270, 8640, 540, 540, 8640, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 8640, 540, 270, 270, 270, 270]
Prompts retrieved: 811890 . Total input tokens: 180825203 . Total output tokens: 159433071
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 83.95494064688683,
    "estimated_duration": 3600.101400584901,
    "input_throughput": 6466.2925872637525,
    "output_throughput": 5664.242122926587,
    "total_throughput": 12130.53471019034,
    "itl": 93.14659526802372,
    "ttft": 1687776.1971959893,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 438,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.2112354429904415,
    "arrivals": 270522,
    "finished_requests": 94302,
    "scheduler_time": 239.14864205998296
}
#Debug simulation 
Total elapsed time: 83.95510725397617. Arrivals time: 0.438871378544718 Scheduler time: 83.30566012253985 Scheduler overhead time: 0.08257101802155375 Adapter cache time: 0.017106811981648207 Engine time: 0.07892114389687777 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.025_size_8-8-32/adapters_256_slots_32_rate_0.8-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.025_size_8-8-32/adapters_256_slots_32_rate_0.8-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 8640, 270, 8640, 8640, 270, 8640, 540, 8640, 270, 540, 270, 8640, 540, 540, 540, 540, 8640, 270, 270, 270, 540, 8640, 270, 8640, 8640, 540, 540, 540, 270, 8640, 270, 540, 540, 270, 540, 270, 270, 540, 540, 8640, 540, 270, 540, 8640, 540, 540, 8640, 540, 8640, 270, 8640, 8640, 540, 270, 270, 8640, 540, 270, 540, 540, 8640, 540, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 8640, 8640, 270, 8640, 270, 540, 8640, 8640, 8640, 540, 270, 8640, 540, 270, 270, 270, 270, 270, 8640, 540, 270, 8640, 270, 8640, 270, 270, 540, 540, 8640, 540, 8640, 270, 540, 270, 8640, 8640, 270, 8640, 540, 270, 8640, 270, 270, 8640, 8640, 540, 8640, 8640, 270, 8640, 540, 540, 270, 540, 8640, 8640, 270, 8640, 540, 270, 540, 8640, 270, 270, 270, 270, 270, 270, 8640, 270, 270, 270, 8640, 270, 540, 8640, 8640, 540, 270, 8640, 270, 540, 540, 270, 540, 270, 8640, 270, 270, 8640, 270, 8640, 8640, 540, 8640, 540, 270, 540, 8640, 540, 8640, 270, 8640, 270, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 540, 270, 8640, 270, 8640, 540, 540, 270, 540, 8640, 540, 540, 8640, 270, 8640, 8640, 540, 270, 8640, 8640, 540, 540, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 8640, 270, 8640, 540, 8640, 8640, 270, 8640, 540, 540, 8640, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 8640, 540, 270, 270, 270, 270]
Prompts retrieved: 811890 . Total input tokens: 180825203 . Total output tokens: 159433071
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 80.8127028606832,
    "estimated_duration": 3600.0402812385382,
    "input_throughput": 6359.534952793215,
    "output_throughput": 5573.6251354101105,
    "total_throughput": 11933.160088203325,
    "itl": 88.79311072889189,
    "ttft": 1700838.094147734,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 434,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.274326980900975,
    "arrivals": 270522,
    "finished_requests": 92744,
    "scheduler_time": 243.65751152839377
}
#Debug simulation 
Total elapsed time: 80.81287291180342. Arrivals time: 0.4331910265609622 Scheduler time: 80.16672038007528 Scheduler overhead time: 0.08216896886005998 Adapter cache time: 0.017781068570911884 Engine time: 0.08063070522621274 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.025_size_8-16-16/adapters_256_slots_32_rate_0.8-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.025_size_8-16-16/adapters_256_slots_32_rate_0.8-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 8640, 270, 8640, 8640, 270, 8640, 540, 8640, 270, 540, 270, 8640, 540, 540, 540, 540, 8640, 270, 270, 270, 540, 8640, 270, 8640, 8640, 540, 540, 540, 270, 8640, 270, 540, 540, 270, 540, 270, 270, 540, 540, 8640, 540, 270, 540, 8640, 540, 540, 8640, 540, 8640, 270, 8640, 8640, 540, 270, 270, 8640, 540, 270, 540, 540, 8640, 540, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 8640, 8640, 270, 8640, 270, 540, 8640, 8640, 8640, 540, 270, 8640, 540, 270, 270, 270, 270, 270, 8640, 540, 270, 8640, 270, 8640, 270, 270, 540, 540, 8640, 540, 8640, 270, 540, 270, 8640, 8640, 270, 8640, 540, 270, 8640, 270, 270, 8640, 8640, 540, 8640, 8640, 270, 8640, 540, 540, 270, 540, 8640, 8640, 270, 8640, 540, 270, 540, 8640, 270, 270, 270, 270, 270, 270, 8640, 270, 270, 270, 8640, 270, 540, 8640, 8640, 540, 270, 8640, 270, 540, 540, 270, 540, 270, 8640, 270, 270, 8640, 270, 8640, 8640, 540, 8640, 540, 270, 540, 8640, 540, 8640, 270, 8640, 270, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 540, 270, 8640, 270, 8640, 540, 540, 270, 540, 8640, 540, 540, 8640, 270, 8640, 8640, 540, 270, 8640, 8640, 540, 540, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 8640, 270, 8640, 540, 8640, 8640, 270, 8640, 540, 540, 8640, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 8640, 540, 270, 270, 270, 270]
Prompts retrieved: 811890 . Total input tokens: 180825203 . Total output tokens: 159433071
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 84.05601846566424,
    "estimated_duration": 3600.0262910744277,
    "input_throughput": 6475.6910408680205,
    "output_throughput": 5677.287427226029,
    "total_throughput": 12152.978468094048,
    "itl": 93.35444800271502,
    "ttft": 1687209.1782427235,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 418,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.872547436235469,
    "arrivals": 270522,
    "finished_requests": 94421,
    "scheduler_time": 238.5580574204471
}
#Debug simulation 
Total elapsed time: 84.05619060480967. Arrivals time: 0.4298014617525041 Scheduler time: 83.41912026703358 Scheduler overhead time: 0.07949527027085423 Adapter cache time: 0.01758859446272254 Engine time: 0.07895291596651077 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.025_size_8-16-32/adapters_256_slots_32_rate_0.8-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.025_size_8-16-32/adapters_256_slots_32_rate_0.8-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 8640, 270, 8640, 8640, 270, 8640, 540, 8640, 270, 540, 270, 8640, 540, 540, 540, 540, 8640, 270, 270, 270, 540, 8640, 270, 8640, 8640, 540, 540, 540, 270, 8640, 270, 540, 540, 270, 540, 270, 270, 540, 540, 8640, 540, 270, 540, 8640, 540, 540, 8640, 540, 8640, 270, 8640, 8640, 540, 270, 270, 8640, 540, 270, 540, 540, 8640, 540, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 8640, 8640, 270, 8640, 270, 540, 8640, 8640, 8640, 540, 270, 8640, 540, 270, 270, 270, 270, 270, 8640, 540, 270, 8640, 270, 8640, 270, 270, 540, 540, 8640, 540, 8640, 270, 540, 270, 8640, 8640, 270, 8640, 540, 270, 8640, 270, 270, 8640, 8640, 540, 8640, 8640, 270, 8640, 540, 540, 270, 540, 8640, 8640, 270, 8640, 540, 270, 540, 8640, 270, 270, 270, 270, 270, 270, 8640, 270, 270, 270, 8640, 270, 540, 8640, 8640, 540, 270, 8640, 270, 540, 540, 270, 540, 270, 8640, 270, 270, 8640, 270, 8640, 8640, 540, 8640, 540, 270, 540, 8640, 540, 8640, 270, 8640, 270, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 540, 270, 8640, 270, 8640, 540, 540, 270, 540, 8640, 540, 540, 8640, 270, 8640, 8640, 540, 270, 8640, 8640, 540, 540, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 8640, 270, 8640, 540, 8640, 8640, 270, 8640, 540, 540, 8640, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 8640, 540, 270, 270, 270, 270]
Prompts retrieved: 811890 . Total input tokens: 180825203 . Total output tokens: 159433071
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 82.23396769119427,
    "estimated_duration": 3600.073745705582,
    "input_throughput": 6337.259903971368,
    "output_throughput": 5553.190687787361,
    "total_throughput": 11890.450591758728,
    "itl": 88.30879950069264,
    "ttft": 1704925.1471844602,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 466,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.485952129443204,
    "arrivals": 270522,
    "finished_requests": 92450,
    "scheduler_time": 244.6271175312527
}
#Debug simulation 
Total elapsed time: 82.2341317688115. Arrivals time: 0.4353380911052227 Scheduler time: 81.58655244251713 Scheduler overhead time: 0.08112309873104095 Adapter cache time: 0.01825697487220168 Engine time: 0.08034764463081956 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.025_size_16-16-16/adapters_256_slots_32_rate_0.8-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.025_size_16-16-16/adapters_256_slots_32_rate_0.8-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 8640, 270, 8640, 8640, 270, 8640, 540, 8640, 270, 540, 270, 8640, 540, 540, 540, 540, 8640, 270, 270, 270, 540, 8640, 270, 8640, 8640, 540, 540, 540, 270, 8640, 270, 540, 540, 270, 540, 270, 270, 540, 540, 8640, 540, 270, 540, 8640, 540, 540, 8640, 540, 8640, 270, 8640, 8640, 540, 270, 270, 8640, 540, 270, 540, 540, 8640, 540, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 8640, 8640, 270, 8640, 270, 540, 8640, 8640, 8640, 540, 270, 8640, 540, 270, 270, 270, 270, 270, 8640, 540, 270, 8640, 270, 8640, 270, 270, 540, 540, 8640, 540, 8640, 270, 540, 270, 8640, 8640, 270, 8640, 540, 270, 8640, 270, 270, 8640, 8640, 540, 8640, 8640, 270, 8640, 540, 540, 270, 540, 8640, 8640, 270, 8640, 540, 270, 540, 8640, 270, 270, 270, 270, 270, 270, 8640, 270, 270, 270, 8640, 270, 540, 8640, 8640, 540, 270, 8640, 270, 540, 540, 270, 540, 270, 8640, 270, 270, 8640, 270, 8640, 8640, 540, 8640, 540, 270, 540, 8640, 540, 8640, 270, 8640, 270, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 540, 270, 8640, 270, 8640, 540, 540, 270, 540, 8640, 540, 540, 8640, 270, 8640, 8640, 540, 270, 8640, 8640, 540, 540, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 8640, 270, 8640, 540, 8640, 8640, 270, 8640, 540, 540, 8640, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 8640, 540, 270, 270, 270, 270]
Prompts retrieved: 811890 . Total input tokens: 180825203 . Total output tokens: 159433071
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 83.75548367388546,
    "estimated_duration": 3600.012794397192,
    "input_throughput": 6489.793879722058,
    "output_throughput": 5692.764490141664,
    "total_throughput": 12182.558369863722,
    "itl": 93.78765544092795,
    "ttft": 1683480.205310191,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 413,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.636559348455619,
    "arrivals": 270522,
    "finished_requests": 94614,
    "scheduler_time": 237.83397372974213
}
#Debug simulation 
Total elapsed time: 83.75565570173785. Arrivals time: 0.44046990806236863 Scheduler time: 83.10765275917947 Scheduler overhead time: 0.08017744589596987 Adapter cache time: 0.017191807739436626 Engine time: 0.0788021800108254 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.025_size_16-16-32/adapters_256_slots_32_rate_0.8-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.025_size_16-16-32/adapters_256_slots_32_rate_0.8-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 8640, 270, 8640, 8640, 270, 8640, 540, 8640, 270, 540, 270, 8640, 540, 540, 540, 540, 8640, 270, 270, 270, 540, 8640, 270, 8640, 8640, 540, 540, 540, 270, 8640, 270, 540, 540, 270, 540, 270, 270, 540, 540, 8640, 540, 270, 540, 8640, 540, 540, 8640, 540, 8640, 270, 8640, 8640, 540, 270, 270, 8640, 540, 270, 540, 540, 8640, 540, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 8640, 8640, 270, 8640, 270, 540, 8640, 8640, 8640, 540, 270, 8640, 540, 270, 270, 270, 270, 270, 8640, 540, 270, 8640, 270, 8640, 270, 270, 540, 540, 8640, 540, 8640, 270, 540, 270, 8640, 8640, 270, 8640, 540, 270, 8640, 270, 270, 8640, 8640, 540, 8640, 8640, 270, 8640, 540, 540, 270, 540, 8640, 8640, 270, 8640, 540, 270, 540, 8640, 270, 270, 270, 270, 270, 270, 8640, 270, 270, 270, 8640, 270, 540, 8640, 8640, 540, 270, 8640, 270, 540, 540, 270, 540, 270, 8640, 270, 270, 8640, 270, 8640, 8640, 540, 8640, 540, 270, 540, 8640, 540, 8640, 270, 8640, 270, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 540, 270, 8640, 270, 8640, 540, 540, 270, 540, 8640, 540, 540, 8640, 270, 8640, 8640, 540, 270, 8640, 8640, 540, 540, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 8640, 270, 8640, 540, 8640, 8640, 270, 8640, 540, 540, 8640, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 8640, 540, 270, 270, 270, 270]
Prompts retrieved: 811890 . Total input tokens: 180825203 . Total output tokens: 159433071
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 80.88145661726594,
    "estimated_duration": 3600.085111638267,
    "input_throughput": 6359.696309952272,
    "output_throughput": 5573.91738743322,
    "total_throughput": 11933.613697385492,
    "itl": 88.79229673936318,
    "ttft": 1700923.6820648785,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 435,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.2187662120722473,
    "arrivals": 270522,
    "finished_requests": 92748,
    "scheduler_time": 243.66446912227428
}
#Debug simulation 
Total elapsed time: 80.8816113290377. Arrivals time: 0.431742403190583 Scheduler time: 80.23855337779969 Scheduler overhead time: 0.08144321199506521 Adapter cache time: 0.01769527606666088 Engine time: 0.08017897652462125 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-8/adapters_256_slots_32_rate_0.8-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-8/adapters_256_slots_32_rate_0.8-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 8640, 135, 8640, 8640, 135, 8640, 540, 8640, 135, 540, 135, 8640, 540, 540, 540, 540, 8640, 135, 135, 135, 540, 8640, 135, 8640, 8640, 540, 540, 540, 135, 8640, 135, 540, 540, 135, 540, 135, 135, 540, 540, 8640, 540, 135, 540, 8640, 540, 540, 8640, 540, 8640, 135, 8640, 8640, 540, 135, 135, 8640, 540, 135, 540, 540, 8640, 540, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 8640, 8640, 135, 8640, 135, 540, 8640, 8640, 8640, 540, 135, 8640, 540, 135, 135, 135, 135, 135, 8640, 540, 135, 8640, 135, 8640, 135, 135, 540, 540, 8640, 540, 8640, 135, 540, 135, 8640, 8640, 135, 8640, 540, 135, 8640, 135, 135, 8640, 8640, 540, 8640, 8640, 135, 8640, 540, 540, 135, 540, 8640, 8640, 135, 8640, 540, 135, 540, 8640, 135, 135, 135, 135, 135, 135, 8640, 135, 135, 135, 8640, 135, 540, 8640, 8640, 540, 135, 8640, 135, 540, 540, 135, 540, 135, 8640, 135, 135, 8640, 135, 8640, 8640, 540, 8640, 540, 135, 540, 8640, 540, 8640, 135, 8640, 135, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 540, 135, 8640, 135, 8640, 540, 540, 135, 540, 8640, 540, 540, 8640, 135, 8640, 8640, 540, 135, 8640, 8640, 540, 540, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 8640, 135, 8640, 540, 8640, 8640, 135, 8640, 540, 540, 8640, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 8640, 540, 135, 135, 135, 135]
Prompts retrieved: 800415 . Total input tokens: 178214941 . Total output tokens: 157218537
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 81.93578458204865,
    "estimated_duration": 3600.1052134544952,
    "input_throughput": 6585.4844773412815,
    "output_throughput": 5752.630762734727,
    "total_throughput": 12338.11524007601,
    "itl": 96.53674491478547,
    "ttft": 1673293.920167463,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 472,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.121057063080404,
    "arrivals": 266663,
    "finished_requests": 95765,
    "scheduler_time": 234.27663494854968
}
#Debug simulation 
Total elapsed time: 81.93595223687589. Arrivals time: 0.4233080968260765 Scheduler time: 81.30999987060204 Scheduler overhead time: 0.07739530224353075 Adapter cache time: 0.01730285631492734 Engine time: 0.07762655196711421 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-16/adapters_256_slots_32_rate_0.8-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-16/adapters_256_slots_32_rate_0.8-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 8640, 135, 8640, 8640, 135, 8640, 540, 8640, 135, 540, 135, 8640, 540, 540, 540, 540, 8640, 135, 135, 135, 540, 8640, 135, 8640, 8640, 540, 540, 540, 135, 8640, 135, 540, 540, 135, 540, 135, 135, 540, 540, 8640, 540, 135, 540, 8640, 540, 540, 8640, 540, 8640, 135, 8640, 8640, 540, 135, 135, 8640, 540, 135, 540, 540, 8640, 540, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 8640, 8640, 135, 8640, 135, 540, 8640, 8640, 8640, 540, 135, 8640, 540, 135, 135, 135, 135, 135, 8640, 540, 135, 8640, 135, 8640, 135, 135, 540, 540, 8640, 540, 8640, 135, 540, 135, 8640, 8640, 135, 8640, 540, 135, 8640, 135, 135, 8640, 8640, 540, 8640, 8640, 135, 8640, 540, 540, 135, 540, 8640, 8640, 135, 8640, 540, 135, 540, 8640, 135, 135, 135, 135, 135, 135, 8640, 135, 135, 135, 8640, 135, 540, 8640, 8640, 540, 135, 8640, 135, 540, 540, 135, 540, 135, 8640, 135, 135, 8640, 135, 8640, 8640, 540, 8640, 540, 135, 540, 8640, 540, 8640, 135, 8640, 135, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 540, 135, 8640, 135, 8640, 540, 540, 135, 540, 8640, 540, 540, 8640, 135, 8640, 8640, 540, 135, 8640, 8640, 540, 540, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 8640, 135, 8640, 540, 8640, 8640, 135, 8640, 540, 540, 8640, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 8640, 540, 135, 135, 135, 135]
Prompts retrieved: 800415 . Total input tokens: 178214941 . Total output tokens: 157218537
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 82.51308347517624,
    "estimated_duration": 3600.024433799661,
    "input_throughput": 6539.489226508432,
    "output_throughput": 5710.502630756321,
    "total_throughput": 12249.991857264753,
    "itl": 94.36771113227125,
    "ttft": 1678634.9783765601,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 424,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.0954843513295094,
    "arrivals": 266663,
    "finished_requests": 95062,
    "scheduler_time": 236.51494945521665
}
#Debug simulation 
Total elapsed time: 82.51325667928904. Arrivals time: 0.43605592800304294 Scheduler time: 81.87220241269097 Scheduler overhead time: 0.07906387001276016 Adapter cache time: 0.01742509286850691 Engine time: 0.07760574063286185 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-32/adapters_256_slots_32_rate_0.8-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-32/adapters_256_slots_32_rate_0.8-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 8640, 135, 8640, 8640, 135, 8640, 540, 8640, 135, 540, 135, 8640, 540, 540, 540, 540, 8640, 135, 135, 135, 540, 8640, 135, 8640, 8640, 540, 540, 540, 135, 8640, 135, 540, 540, 135, 540, 135, 135, 540, 540, 8640, 540, 135, 540, 8640, 540, 540, 8640, 540, 8640, 135, 8640, 8640, 540, 135, 135, 8640, 540, 135, 540, 540, 8640, 540, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 8640, 8640, 135, 8640, 135, 540, 8640, 8640, 8640, 540, 135, 8640, 540, 135, 135, 135, 135, 135, 8640, 540, 135, 8640, 135, 8640, 135, 135, 540, 540, 8640, 540, 8640, 135, 540, 135, 8640, 8640, 135, 8640, 540, 135, 8640, 135, 135, 8640, 8640, 540, 8640, 8640, 135, 8640, 540, 540, 135, 540, 8640, 8640, 135, 8640, 540, 135, 540, 8640, 135, 135, 135, 135, 135, 135, 8640, 135, 135, 135, 8640, 135, 540, 8640, 8640, 540, 135, 8640, 135, 540, 540, 135, 540, 135, 8640, 135, 135, 8640, 135, 8640, 8640, 540, 8640, 540, 135, 540, 8640, 540, 8640, 135, 8640, 135, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 540, 135, 8640, 135, 8640, 540, 540, 135, 540, 8640, 540, 540, 8640, 135, 8640, 8640, 540, 135, 8640, 8640, 540, 540, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 8640, 135, 8640, 540, 8640, 8640, 135, 8640, 540, 540, 8640, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 8640, 540, 135, 135, 135, 135]
Prompts retrieved: 800415 . Total input tokens: 178214941 . Total output tokens: 157218537
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 79.73513892805204,
    "estimated_duration": 3600.014178078606,
    "input_throughput": 6393.593430869378,
    "output_throughput": 5586.044944615466,
    "total_throughput": 11979.638375484845,
    "itl": 89.30211290129996,
    "ttft": 1692621.974176812,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 426,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.192630329965637,
    "arrivals": 266663,
    "finished_requests": 92951,
    "scheduler_time": 242.44483866705298
}
#Debug simulation 
Total elapsed time: 79.73531301831827. Arrivals time: 0.43283495865762234 Scheduler time: 79.0927835740149 Scheduler overhead time: 0.08087055198848248 Adapter cache time: 0.017713710200041533 Engine time: 0.07935163285583258 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.0125_size_8-16-16/adapters_256_slots_32_rate_0.8-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.0125_size_8-16-16/adapters_256_slots_32_rate_0.8-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 8640, 135, 8640, 8640, 135, 8640, 540, 8640, 135, 540, 135, 8640, 540, 540, 540, 540, 8640, 135, 135, 135, 540, 8640, 135, 8640, 8640, 540, 540, 540, 135, 8640, 135, 540, 540, 135, 540, 135, 135, 540, 540, 8640, 540, 135, 540, 8640, 540, 540, 8640, 540, 8640, 135, 8640, 8640, 540, 135, 135, 8640, 540, 135, 540, 540, 8640, 540, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 8640, 8640, 135, 8640, 135, 540, 8640, 8640, 8640, 540, 135, 8640, 540, 135, 135, 135, 135, 135, 8640, 540, 135, 8640, 135, 8640, 135, 135, 540, 540, 8640, 540, 8640, 135, 540, 135, 8640, 8640, 135, 8640, 540, 135, 8640, 135, 135, 8640, 8640, 540, 8640, 8640, 135, 8640, 540, 540, 135, 540, 8640, 8640, 135, 8640, 540, 135, 540, 8640, 135, 135, 135, 135, 135, 135, 8640, 135, 135, 135, 8640, 135, 540, 8640, 8640, 540, 135, 8640, 135, 540, 540, 135, 540, 135, 8640, 135, 135, 8640, 135, 8640, 8640, 540, 8640, 540, 135, 540, 8640, 540, 8640, 135, 8640, 135, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 540, 135, 8640, 135, 8640, 540, 540, 135, 540, 8640, 540, 540, 8640, 135, 8640, 8640, 540, 135, 8640, 8640, 540, 540, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 8640, 135, 8640, 540, 8640, 8640, 135, 8640, 540, 540, 8640, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 8640, 540, 135, 135, 135, 135]
Prompts retrieved: 800415 . Total input tokens: 178214941 . Total output tokens: 157218537
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 81.36335575720295,
    "estimated_duration": 3600.0412219147984,
    "input_throughput": 6545.985878313292,
    "output_throughput": 5713.551521240554,
    "total_throughput": 12259.537399553847,
    "itl": 94.49915782996578,
    "ttft": 1677195.2988978252,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 455,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.1059760690899525,
    "arrivals": 266663,
    "finished_requests": 95108,
    "scheduler_time": 236.29619832175456
}
#Debug simulation 
Total elapsed time: 81.36353333108127. Arrivals time: 0.4515216131694615 Scheduler time: 80.7063458301127 Scheduler overhead time: 0.07920660497620702 Adapter cache time: 0.0175922648049891 Engine time: 0.07809499884024262 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.0125_size_8-16-32/adapters_256_slots_32_rate_0.8-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.0125_size_8-16-32/adapters_256_slots_32_rate_0.8-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 8640, 135, 8640, 8640, 135, 8640, 540, 8640, 135, 540, 135, 8640, 540, 540, 540, 540, 8640, 135, 135, 135, 540, 8640, 135, 8640, 8640, 540, 540, 540, 135, 8640, 135, 540, 540, 135, 540, 135, 135, 540, 540, 8640, 540, 135, 540, 8640, 540, 540, 8640, 540, 8640, 135, 8640, 8640, 540, 135, 135, 8640, 540, 135, 540, 540, 8640, 540, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 8640, 8640, 135, 8640, 135, 540, 8640, 8640, 8640, 540, 135, 8640, 540, 135, 135, 135, 135, 135, 8640, 540, 135, 8640, 135, 8640, 135, 135, 540, 540, 8640, 540, 8640, 135, 540, 135, 8640, 8640, 135, 8640, 540, 135, 8640, 135, 135, 8640, 8640, 540, 8640, 8640, 135, 8640, 540, 540, 135, 540, 8640, 8640, 135, 8640, 540, 135, 540, 8640, 135, 135, 135, 135, 135, 135, 8640, 135, 135, 135, 8640, 135, 540, 8640, 8640, 540, 135, 8640, 135, 540, 540, 135, 540, 135, 8640, 135, 135, 8640, 135, 8640, 8640, 540, 8640, 540, 135, 540, 8640, 540, 8640, 135, 8640, 135, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 540, 135, 8640, 135, 8640, 540, 540, 135, 540, 8640, 540, 540, 8640, 135, 8640, 8640, 540, 135, 8640, 8640, 540, 540, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 8640, 135, 8640, 540, 8640, 8640, 135, 8640, 540, 540, 8640, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 8640, 540, 135, 135, 135, 135]
Prompts retrieved: 800415 . Total input tokens: 178214941 . Total output tokens: 157218537
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 79.7243857467547,
    "estimated_duration": 3600.0507645575753,
    "input_throughput": 6398.144778058622,
    "output_throughput": 5587.806760406109,
    "total_throughput": 11985.951538464731,
    "itl": 89.3836559978884,
    "ttft": 1694265.67662512,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 472,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.498937869751854,
    "arrivals": 266663,
    "finished_requests": 93015,
    "scheduler_time": 242.3020861090076
}
#Debug simulation 
Total elapsed time: 79.72454821597785. Arrivals time: 0.4422361319884658 Scheduler time: 79.07253530016169 Scheduler overhead time: 0.07999872788786888 Adapter cache time: 0.018059473484754562 Engine time: 0.08003735216334462 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.0125_size_16-16-16/adapters_256_slots_32_rate_0.8-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.0125_size_16-16-16/adapters_256_slots_32_rate_0.8-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 8640, 135, 8640, 8640, 135, 8640, 540, 8640, 135, 540, 135, 8640, 540, 540, 540, 540, 8640, 135, 135, 135, 540, 8640, 135, 8640, 8640, 540, 540, 540, 135, 8640, 135, 540, 540, 135, 540, 135, 135, 540, 540, 8640, 540, 135, 540, 8640, 540, 540, 8640, 540, 8640, 135, 8640, 8640, 540, 135, 135, 8640, 540, 135, 540, 540, 8640, 540, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 8640, 8640, 135, 8640, 135, 540, 8640, 8640, 8640, 540, 135, 8640, 540, 135, 135, 135, 135, 135, 8640, 540, 135, 8640, 135, 8640, 135, 135, 540, 540, 8640, 540, 8640, 135, 540, 135, 8640, 8640, 135, 8640, 540, 135, 8640, 135, 135, 8640, 8640, 540, 8640, 8640, 135, 8640, 540, 540, 135, 540, 8640, 8640, 135, 8640, 540, 135, 540, 8640, 135, 135, 135, 135, 135, 135, 8640, 135, 135, 135, 8640, 135, 540, 8640, 8640, 540, 135, 8640, 135, 540, 540, 135, 540, 135, 8640, 135, 135, 8640, 135, 8640, 8640, 540, 8640, 540, 135, 540, 8640, 540, 8640, 135, 8640, 135, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 540, 135, 8640, 135, 8640, 540, 540, 135, 540, 8640, 540, 540, 8640, 135, 8640, 8640, 540, 135, 8640, 8640, 540, 540, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 8640, 135, 8640, 540, 8640, 8640, 135, 8640, 540, 540, 8640, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 8640, 540, 135, 135, 135, 135]
Prompts retrieved: 800415 . Total input tokens: 178214941 . Total output tokens: 157218537
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 81.30945502500981,
    "estimated_duration": 3600.0141905648006,
    "input_throughput": 6544.931978810733,
    "output_throughput": 5718.46273660666,
    "total_throughput": 12263.394715417393,
    "itl": 94.60586256923482,
    "ttft": 1675656.7829933972,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 467,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.981291079246426,
    "arrivals": 266663,
    "finished_requests": 95154,
    "scheduler_time": 236.05696477809565
}
#Debug simulation 
Total elapsed time: 81.30961570004001. Arrivals time: 0.4449446965008974 Scheduler time: 80.66135575110093 Scheduler overhead time: 0.07856849348172545 Adapter cache time: 0.017480222042649984 Engine time: 0.07684751786291599 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.0125_size_16-16-32/adapters_256_slots_32_rate_0.8-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.0125_size_16-16-32/adapters_256_slots_32_rate_0.8-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 8640, 135, 8640, 8640, 135, 8640, 540, 8640, 135, 540, 135, 8640, 540, 540, 540, 540, 8640, 135, 135, 135, 540, 8640, 135, 8640, 8640, 540, 540, 540, 135, 8640, 135, 540, 540, 135, 540, 135, 135, 540, 540, 8640, 540, 135, 540, 8640, 540, 540, 8640, 540, 8640, 135, 8640, 8640, 540, 135, 135, 8640, 540, 135, 540, 540, 8640, 540, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 8640, 8640, 135, 8640, 135, 540, 8640, 8640, 8640, 540, 135, 8640, 540, 135, 135, 135, 135, 135, 8640, 540, 135, 8640, 135, 8640, 135, 135, 540, 540, 8640, 540, 8640, 135, 540, 135, 8640, 8640, 135, 8640, 540, 135, 8640, 135, 135, 8640, 8640, 540, 8640, 8640, 135, 8640, 540, 540, 135, 540, 8640, 8640, 135, 8640, 540, 135, 540, 8640, 135, 135, 135, 135, 135, 135, 8640, 135, 135, 135, 8640, 135, 540, 8640, 8640, 540, 135, 8640, 135, 540, 540, 135, 540, 135, 8640, 135, 135, 8640, 135, 8640, 8640, 540, 8640, 540, 135, 540, 8640, 540, 8640, 135, 8640, 135, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 540, 135, 8640, 135, 8640, 540, 540, 135, 540, 8640, 540, 540, 8640, 135, 8640, 8640, 540, 135, 8640, 8640, 540, 540, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 8640, 135, 8640, 540, 8640, 8640, 135, 8640, 540, 540, 8640, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 8640, 540, 135, 135, 135, 135]
Prompts retrieved: 800415 . Total input tokens: 178214941 . Total output tokens: 157218537
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 80.196623114869,
    "estimated_duration": 3600.027225776406,
    "input_throughput": 6361.591055762314,
    "output_throughput": 5559.93017405118,
    "total_throughput": 11921.521229813494,
    "itl": 89.01096101075902,
    "ttft": 1692436.4779876114,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 414,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.0460096858442043,
    "arrivals": 266663,
    "finished_requests": 92444,
    "scheduler_time": 243.81626055183074
}
#Debug simulation 
Total elapsed time: 80.19677951699123. Arrivals time: 0.43054645135998726 Scheduler time: 79.55754604190588 Scheduler overhead time: 0.08060935698449612 Adapter cache time: 0.016934768296778202 Engine time: 0.07925221044570208 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-8/adapters_256_slots_32_rate_0.8-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-8/adapters_256_slots_32_rate_0.8-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 8640, 66, 8640, 8640, 66, 8640, 540, 8640, 66, 540, 66, 8640, 540, 540, 540, 540, 8640, 66, 66, 66, 540, 8640, 66, 8640, 8640, 540, 540, 540, 66, 8640, 66, 540, 540, 66, 540, 66, 66, 540, 540, 8640, 540, 66, 540, 8640, 540, 540, 8640, 540, 8640, 66, 8640, 8640, 540, 66, 66, 8640, 540, 66, 540, 540, 8640, 540, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 8640, 8640, 66, 8640, 66, 540, 8640, 8640, 8640, 540, 66, 8640, 540, 66, 66, 66, 66, 66, 8640, 540, 66, 8640, 66, 8640, 66, 66, 540, 540, 8640, 540, 8640, 66, 540, 66, 8640, 8640, 66, 8640, 540, 66, 8640, 66, 66, 8640, 8640, 540, 8640, 8640, 66, 8640, 540, 540, 66, 540, 8640, 8640, 66, 8640, 540, 66, 540, 8640, 66, 66, 66, 66, 66, 66, 8640, 66, 66, 66, 8640, 66, 540, 8640, 8640, 540, 66, 8640, 66, 540, 540, 66, 540, 66, 8640, 66, 66, 8640, 66, 8640, 8640, 540, 8640, 540, 66, 540, 8640, 540, 8640, 66, 8640, 66, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 540, 66, 8640, 66, 8640, 540, 540, 66, 540, 8640, 540, 540, 8640, 66, 8640, 8640, 540, 66, 8640, 8640, 540, 540, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 8640, 66, 8640, 540, 8640, 8640, 66, 8640, 540, 540, 8640, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 8640, 540, 66, 66, 66, 66]
Prompts retrieved: 794550 . Total input tokens: 176917091 . Total output tokens: 156115593
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 81.51365240616724,
    "estimated_duration": 3600.0827396784885,
    "input_throughput": 6626.549644836916,
    "output_throughput": 5778.829128204415,
    "total_throughput": 12405.378773041331,
    "itl": 97.01666410096989,
    "ttft": 1656615.476835082,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 438,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.896235155994099,
    "arrivals": 264754,
    "finished_requests": 96476,
    "scheduler_time": 233.4227511093453
}
#Debug simulation 
Total elapsed time: 81.51382442843169. Arrivals time: 0.44740294478833675 Scheduler time: 80.864734263625 Scheduler overhead time: 0.07765535963699222 Adapter cache time: 0.016910940408706665 Engine time: 0.07664025155827403 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-16/adapters_256_slots_32_rate_0.8-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-16/adapters_256_slots_32_rate_0.8-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 8640, 66, 8640, 8640, 66, 8640, 540, 8640, 66, 540, 66, 8640, 540, 540, 540, 540, 8640, 66, 66, 66, 540, 8640, 66, 8640, 8640, 540, 540, 540, 66, 8640, 66, 540, 540, 66, 540, 66, 66, 540, 540, 8640, 540, 66, 540, 8640, 540, 540, 8640, 540, 8640, 66, 8640, 8640, 540, 66, 66, 8640, 540, 66, 540, 540, 8640, 540, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 8640, 8640, 66, 8640, 66, 540, 8640, 8640, 8640, 540, 66, 8640, 540, 66, 66, 66, 66, 66, 8640, 540, 66, 8640, 66, 8640, 66, 66, 540, 540, 8640, 540, 8640, 66, 540, 66, 8640, 8640, 66, 8640, 540, 66, 8640, 66, 66, 8640, 8640, 540, 8640, 8640, 66, 8640, 540, 540, 66, 540, 8640, 8640, 66, 8640, 540, 66, 540, 8640, 66, 66, 66, 66, 66, 66, 8640, 66, 66, 66, 8640, 66, 540, 8640, 8640, 540, 66, 8640, 66, 540, 540, 66, 540, 66, 8640, 66, 66, 8640, 66, 8640, 8640, 540, 8640, 540, 66, 540, 8640, 540, 8640, 66, 8640, 66, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 540, 66, 8640, 66, 8640, 540, 540, 66, 540, 8640, 540, 540, 8640, 66, 8640, 8640, 540, 66, 8640, 8640, 540, 540, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 8640, 66, 8640, 540, 8640, 8640, 66, 8640, 540, 540, 8640, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 8640, 540, 66, 66, 66, 66]
Prompts retrieved: 794550 . Total input tokens: 176917091 . Total output tokens: 156115593
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 81.87271666200832,
    "estimated_duration": 3600.0832218164287,
    "input_throughput": 6559.274479239829,
    "output_throughput": 5722.884647540117,
    "total_throughput": 12282.159126779945,
    "itl": 94.86135419405883,
    "ttft": 1666110.5112287216,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 441,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.2248343219189013,
    "arrivals": 264754,
    "finished_requests": 95549,
    "scheduler_time": 236.10552619485227
}
#Debug simulation 
Total elapsed time: 81.87289279326797. Arrivals time: 0.43517194874584675 Scheduler time: 81.23638864373788 Scheduler overhead time: 0.07744974875822663 Adapter cache time: 0.01690252497792244 Engine time: 0.07669290341436863 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-32/adapters_256_slots_32_rate_0.8-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-32/adapters_256_slots_32_rate_0.8-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 8640, 66, 8640, 8640, 66, 8640, 540, 8640, 66, 540, 66, 8640, 540, 540, 540, 540, 8640, 66, 66, 66, 540, 8640, 66, 8640, 8640, 540, 540, 540, 66, 8640, 66, 540, 540, 66, 540, 66, 66, 540, 540, 8640, 540, 66, 540, 8640, 540, 540, 8640, 540, 8640, 66, 8640, 8640, 540, 66, 66, 8640, 540, 66, 540, 540, 8640, 540, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 8640, 8640, 66, 8640, 66, 540, 8640, 8640, 8640, 540, 66, 8640, 540, 66, 66, 66, 66, 66, 8640, 540, 66, 8640, 66, 8640, 66, 66, 540, 540, 8640, 540, 8640, 66, 540, 66, 8640, 8640, 66, 8640, 540, 66, 8640, 66, 66, 8640, 8640, 540, 8640, 8640, 66, 8640, 540, 540, 66, 540, 8640, 8640, 66, 8640, 540, 66, 540, 8640, 66, 66, 66, 66, 66, 66, 8640, 66, 66, 66, 8640, 66, 540, 8640, 8640, 540, 66, 8640, 66, 540, 540, 66, 540, 66, 8640, 66, 66, 8640, 66, 8640, 8640, 540, 8640, 540, 66, 540, 8640, 540, 8640, 66, 8640, 66, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 540, 66, 8640, 66, 8640, 540, 540, 66, 540, 8640, 540, 540, 8640, 66, 8640, 8640, 540, 66, 8640, 8640, 540, 540, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 8640, 66, 8640, 540, 8640, 8640, 66, 8640, 540, 540, 8640, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 8640, 540, 66, 66, 66, 66]
Prompts retrieved: 794550 . Total input tokens: 176917091 . Total output tokens: 156115593
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 77.27875320101157,
    "estimated_duration": 3600.0259229698045,
    "input_throughput": 6397.547265715391,
    "output_throughput": 5589.725582697918,
    "total_throughput": 11987.27284841331,
    "itl": 89.69356161934974,
    "ttft": 1680718.9976437753,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 457,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.432735766181749,
    "arrivals": 264754,
    "finished_requests": 93326,
    "scheduler_time": 242.5677773858934
}
#Debug simulation 
Total elapsed time: 77.2789125898853. Arrivals time: 0.3741293754428625 Scheduler time: 76.70721410447732 Scheduler overhead time: 0.07621716195717454 Adapter cache time: 0.016438677441328764 Engine time: 0.0741580268368125 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.00625_size_8-16-16/adapters_256_slots_32_rate_0.8-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.00625_size_8-16-16/adapters_256_slots_32_rate_0.8-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 8640, 66, 8640, 8640, 66, 8640, 540, 8640, 66, 540, 66, 8640, 540, 540, 540, 540, 8640, 66, 66, 66, 540, 8640, 66, 8640, 8640, 540, 540, 540, 66, 8640, 66, 540, 540, 66, 540, 66, 66, 540, 540, 8640, 540, 66, 540, 8640, 540, 540, 8640, 540, 8640, 66, 8640, 8640, 540, 66, 66, 8640, 540, 66, 540, 540, 8640, 540, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 8640, 8640, 66, 8640, 66, 540, 8640, 8640, 8640, 540, 66, 8640, 540, 66, 66, 66, 66, 66, 8640, 540, 66, 8640, 66, 8640, 66, 66, 540, 540, 8640, 540, 8640, 66, 540, 66, 8640, 8640, 66, 8640, 540, 66, 8640, 66, 66, 8640, 8640, 540, 8640, 8640, 66, 8640, 540, 540, 66, 540, 8640, 8640, 66, 8640, 540, 66, 540, 8640, 66, 66, 66, 66, 66, 66, 8640, 66, 66, 66, 8640, 66, 540, 8640, 8640, 540, 66, 8640, 66, 540, 540, 66, 540, 66, 8640, 66, 66, 8640, 66, 8640, 8640, 540, 8640, 540, 66, 540, 8640, 540, 8640, 66, 8640, 66, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 540, 66, 8640, 66, 8640, 540, 540, 66, 540, 8640, 540, 540, 8640, 66, 8640, 8640, 540, 66, 8640, 8640, 540, 540, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 8640, 66, 8640, 540, 8640, 8640, 66, 8640, 540, 540, 8640, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 8640, 540, 66, 66, 66, 66]
Prompts retrieved: 794550 . Total input tokens: 176917091 . Total output tokens: 156115593
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 78.97213479690254,
    "estimated_duration": 3600.0441431939066,
    "input_throughput": 6582.066790708153,
    "output_throughput": 5742.560418067207,
    "total_throughput": 12324.62720877536,
    "itl": 95.23955930023587,
    "ttft": 1657160.7390209313,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 537,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.668327773469495,
    "arrivals": 264754,
    "finished_requests": 95907,
    "scheduler_time": 235.07985314584897
}
#Debug simulation 
Total elapsed time: 78.9722906970419. Arrivals time: 0.39725919254124165 Scheduler time: 78.38044430268928 Scheduler overhead time: 0.07439866242930293 Adapter cache time: 0.017393844667822123 Engine time: 0.07320982357487082 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.00625_size_8-16-32/adapters_256_slots_32_rate_0.8-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.00625_size_8-16-32/adapters_256_slots_32_rate_0.8-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 8640, 66, 8640, 8640, 66, 8640, 540, 8640, 66, 540, 66, 8640, 540, 540, 540, 540, 8640, 66, 66, 66, 540, 8640, 66, 8640, 8640, 540, 540, 540, 66, 8640, 66, 540, 540, 66, 540, 66, 66, 540, 540, 8640, 540, 66, 540, 8640, 540, 540, 8640, 540, 8640, 66, 8640, 8640, 540, 66, 66, 8640, 540, 66, 540, 540, 8640, 540, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 8640, 8640, 66, 8640, 66, 540, 8640, 8640, 8640, 540, 66, 8640, 540, 66, 66, 66, 66, 66, 8640, 540, 66, 8640, 66, 8640, 66, 66, 540, 540, 8640, 540, 8640, 66, 540, 66, 8640, 8640, 66, 8640, 540, 66, 8640, 66, 66, 8640, 8640, 540, 8640, 8640, 66, 8640, 540, 540, 66, 540, 8640, 8640, 66, 8640, 540, 66, 540, 8640, 66, 66, 66, 66, 66, 66, 8640, 66, 66, 66, 8640, 66, 540, 8640, 8640, 540, 66, 8640, 66, 540, 540, 66, 540, 66, 8640, 66, 66, 8640, 66, 8640, 8640, 540, 8640, 540, 66, 540, 8640, 540, 8640, 66, 8640, 66, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 540, 66, 8640, 66, 8640, 540, 540, 66, 540, 8640, 540, 540, 8640, 66, 8640, 8640, 540, 66, 8640, 8640, 540, 540, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 8640, 66, 8640, 540, 8640, 8640, 66, 8640, 540, 540, 8640, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 8640, 540, 66, 66, 66, 66]
Prompts retrieved: 794550 . Total input tokens: 176917091 . Total output tokens: 156115593
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 78.57017670571804,
    "estimated_duration": 3600.0469993812526,
    "input_throughput": 6430.319938594897,
    "output_throughput": 5614.332813842112,
    "total_throughput": 12044.652752437009,
    "itl": 89.9503147246222,
    "ttft": 1683113.5150124433,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 466,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.46756949345584,
    "arrivals": 264754,
    "finished_requests": 93706,
    "scheduler_time": 241.3761696202997
}
#Debug simulation 
Total elapsed time: 78.57033978309482. Arrivals time: 0.392794590909034 Scheduler time: 77.9766932670027 Scheduler overhead time: 0.07770300703123212 Adapter cache time: 0.016916709020733833 Engine time: 0.0756646953523159 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.00625_size_16-16-16/adapters_256_slots_32_rate_0.8-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.00625_size_16-16-16/adapters_256_slots_32_rate_0.8-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 8640, 66, 8640, 8640, 66, 8640, 540, 8640, 66, 540, 66, 8640, 540, 540, 540, 540, 8640, 66, 66, 66, 540, 8640, 66, 8640, 8640, 540, 540, 540, 66, 8640, 66, 540, 540, 66, 540, 66, 66, 540, 540, 8640, 540, 66, 540, 8640, 540, 540, 8640, 540, 8640, 66, 8640, 8640, 540, 66, 66, 8640, 540, 66, 540, 540, 8640, 540, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 8640, 8640, 66, 8640, 66, 540, 8640, 8640, 8640, 540, 66, 8640, 540, 66, 66, 66, 66, 66, 8640, 540, 66, 8640, 66, 8640, 66, 66, 540, 540, 8640, 540, 8640, 66, 540, 66, 8640, 8640, 66, 8640, 540, 66, 8640, 66, 66, 8640, 8640, 540, 8640, 8640, 66, 8640, 540, 540, 66, 540, 8640, 8640, 66, 8640, 540, 66, 540, 8640, 66, 66, 66, 66, 66, 66, 8640, 66, 66, 66, 8640, 66, 540, 8640, 8640, 540, 66, 8640, 66, 540, 540, 66, 540, 66, 8640, 66, 66, 8640, 66, 8640, 8640, 540, 8640, 540, 66, 540, 8640, 540, 8640, 66, 8640, 66, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 540, 66, 8640, 66, 8640, 540, 540, 66, 540, 8640, 540, 540, 8640, 66, 8640, 8640, 540, 66, 8640, 8640, 540, 540, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 8640, 66, 8640, 540, 8640, 8640, 66, 8640, 540, 540, 8640, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 8640, 540, 66, 66, 66, 66]
Prompts retrieved: 794550 . Total input tokens: 176917091 . Total output tokens: 156115593
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 82.00222449889407,
    "estimated_duration": 3600.0628722808115,
    "input_throughput": 6560.402647922912,
    "output_throughput": 5718.272633099237,
    "total_throughput": 12278.67528102215,
    "itl": 94.75396202274798,
    "ttft": 1661265.417219126,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 414,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.6429432693961896,
    "arrivals": 264754,
    "finished_requests": 95455,
    "scheduler_time": 236.34457109270278
}
#Debug simulation 
Total elapsed time: 82.00239006709307. Arrivals time: 0.40278995083644986 Scheduler time: 81.4002478918992 Scheduler overhead time: 0.07775518530979753 Adapter cache time: 0.016420974861830473 Engine time: 0.07523223664611578 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.00625_size_16-16-32/adapters_256_slots_32_rate_0.8-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.00625_size_16-16-32/adapters_256_slots_32_rate_0.8-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 8640, 66, 8640, 8640, 66, 8640, 540, 8640, 66, 540, 66, 8640, 540, 540, 540, 540, 8640, 66, 66, 66, 540, 8640, 66, 8640, 8640, 540, 540, 540, 66, 8640, 66, 540, 540, 66, 540, 66, 66, 540, 540, 8640, 540, 66, 540, 8640, 540, 540, 8640, 540, 8640, 66, 8640, 8640, 540, 66, 66, 8640, 540, 66, 540, 540, 8640, 540, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 8640, 8640, 66, 8640, 66, 540, 8640, 8640, 8640, 540, 66, 8640, 540, 66, 66, 66, 66, 66, 8640, 540, 66, 8640, 66, 8640, 66, 66, 540, 540, 8640, 540, 8640, 66, 540, 66, 8640, 8640, 66, 8640, 540, 66, 8640, 66, 66, 8640, 8640, 540, 8640, 8640, 66, 8640, 540, 540, 66, 540, 8640, 8640, 66, 8640, 540, 66, 540, 8640, 66, 66, 66, 66, 66, 66, 8640, 66, 66, 66, 8640, 66, 540, 8640, 8640, 540, 66, 8640, 66, 540, 540, 66, 540, 66, 8640, 66, 66, 8640, 66, 8640, 8640, 540, 8640, 540, 66, 540, 8640, 540, 8640, 66, 8640, 66, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 540, 66, 8640, 66, 8640, 540, 540, 66, 540, 8640, 540, 540, 8640, 66, 8640, 8640, 540, 66, 8640, 8640, 540, 540, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 8640, 66, 8640, 540, 8640, 8640, 66, 8640, 540, 540, 8640, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 8640, 540, 66, 66, 66, 66]
Prompts retrieved: 794550 . Total input tokens: 176917091 . Total output tokens: 156115593
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 76.717730327975,
    "estimated_duration": 3600.0027365784963,
    "input_throughput": 6401.423467222831,
    "output_throughput": 5596.251579282853,
    "total_throughput": 11997.675046505685,
    "itl": 89.78046784110995,
    "ttft": 1684196.14516152,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 410,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.023543996363899,
    "arrivals": 264754,
    "finished_requests": 93355,
    "scheduler_time": 242.29630675028682
}
#Debug simulation 
Total elapsed time: 76.71789381885901. Arrivals time: 0.3909069309011102 Scheduler time: 76.12702708784491 Scheduler overhead time: 0.0775115517899394 Adapter cache time: 0.016359233763068914 Engine time: 0.07547063520178199 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-8/adapters_256_slots_32_rate_0.8-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-8/adapters_256_slots_32_rate_0.8-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 8640, 33, 8640, 8640, 33, 8640, 540, 8640, 33, 540, 33, 8640, 540, 540, 540, 540, 8640, 33, 33, 33, 540, 8640, 33, 8640, 8640, 540, 540, 540, 33, 8640, 33, 540, 540, 33, 540, 33, 33, 540, 540, 8640, 540, 33, 540, 8640, 540, 540, 8640, 540, 8640, 33, 8640, 8640, 540, 33, 33, 8640, 540, 33, 540, 540, 8640, 540, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 8640, 8640, 33, 8640, 33, 540, 8640, 8640, 8640, 540, 33, 8640, 540, 33, 33, 33, 33, 33, 8640, 540, 33, 8640, 33, 8640, 33, 33, 540, 540, 8640, 540, 8640, 33, 540, 33, 8640, 8640, 33, 8640, 540, 33, 8640, 33, 33, 8640, 8640, 540, 8640, 8640, 33, 8640, 540, 540, 33, 540, 8640, 8640, 33, 8640, 540, 33, 540, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 540, 8640, 8640, 540, 33, 8640, 33, 540, 540, 33, 540, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 540, 8640, 540, 33, 540, 8640, 540, 8640, 33, 8640, 33, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 540, 33, 8640, 33, 8640, 540, 540, 33, 540, 8640, 540, 540, 8640, 33, 8640, 8640, 540, 33, 8640, 8640, 540, 540, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 8640, 33, 8640, 540, 8640, 8640, 33, 8640, 540, 540, 8640, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 8640, 540, 33, 33, 33, 33]
Prompts retrieved: 791745 . Total input tokens: 176275360 . Total output tokens: 155563613
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 84.97634421102703,
    "estimated_duration": 3600.042850739917,
    "input_throughput": 6617.359844787321,
    "output_throughput": 5720.72468408734,
    "total_throughput": 12338.08452887466,
    "itl": 95.99116523529462,
    "ttft": 1657389.101792833,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 424,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.8036614295467968,
    "arrivals": 263766,
    "finished_requests": 96019,
    "scheduler_time": 235.48580727392854
}
#Debug simulation 
Total elapsed time: 84.97649541404098. Arrivals time: 0.3883198956027627 Scheduler time: 84.38993052113801 Scheduler overhead time: 0.07765012700110674 Adapter cache time: 0.015835142228752375 Engine time: 0.07440236629918218 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-16/adapters_256_slots_32_rate_0.8-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-16/adapters_256_slots_32_rate_0.8-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 8640, 33, 8640, 8640, 33, 8640, 540, 8640, 33, 540, 33, 8640, 540, 540, 540, 540, 8640, 33, 33, 33, 540, 8640, 33, 8640, 8640, 540, 540, 540, 33, 8640, 33, 540, 540, 33, 540, 33, 33, 540, 540, 8640, 540, 33, 540, 8640, 540, 540, 8640, 540, 8640, 33, 8640, 8640, 540, 33, 33, 8640, 540, 33, 540, 540, 8640, 540, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 8640, 8640, 33, 8640, 33, 540, 8640, 8640, 8640, 540, 33, 8640, 540, 33, 33, 33, 33, 33, 8640, 540, 33, 8640, 33, 8640, 33, 33, 540, 540, 8640, 540, 8640, 33, 540, 33, 8640, 8640, 33, 8640, 540, 33, 8640, 33, 33, 8640, 8640, 540, 8640, 8640, 33, 8640, 540, 540, 33, 540, 8640, 8640, 33, 8640, 540, 33, 540, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 540, 8640, 8640, 540, 33, 8640, 33, 540, 540, 33, 540, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 540, 8640, 540, 33, 540, 8640, 540, 8640, 33, 8640, 33, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 540, 33, 8640, 33, 8640, 540, 540, 33, 540, 8640, 540, 540, 8640, 33, 8640, 8640, 540, 33, 8640, 8640, 540, 540, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 8640, 33, 8640, 540, 8640, 8640, 33, 8640, 540, 540, 8640, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 8640, 540, 33, 33, 33, 33]
Prompts retrieved: 791745 . Total input tokens: 176275360 . Total output tokens: 155563613
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 83.74951467802748,
    "estimated_duration": 3600.002759142581,
    "input_throughput": 6602.561606275313,
    "output_throughput": 5709.93645707533,
    "total_throughput": 12312.498063350644,
    "itl": 94.2831269163972,
    "ttft": 1661151.0013659985,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 425,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.099091830323454,
    "arrivals": 263766,
    "finished_requests": 95739,
    "scheduler_time": 236.12500562070025
}
#Debug simulation 
Total elapsed time: 83.74966231128201. Arrivals time: 0.3908429676666856 Scheduler time: 83.15876399539411 Scheduler overhead time: 0.07760301465168595 Adapter cache time: 0.016206503845751286 Engine time: 0.07582424767315388 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-32/adapters_256_slots_32_rate_0.8-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-32/adapters_256_slots_32_rate_0.8-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 8640, 33, 8640, 8640, 33, 8640, 540, 8640, 33, 540, 33, 8640, 540, 540, 540, 540, 8640, 33, 33, 33, 540, 8640, 33, 8640, 8640, 540, 540, 540, 33, 8640, 33, 540, 540, 33, 540, 33, 33, 540, 540, 8640, 540, 33, 540, 8640, 540, 540, 8640, 540, 8640, 33, 8640, 8640, 540, 33, 33, 8640, 540, 33, 540, 540, 8640, 540, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 8640, 8640, 33, 8640, 33, 540, 8640, 8640, 8640, 540, 33, 8640, 540, 33, 33, 33, 33, 33, 8640, 540, 33, 8640, 33, 8640, 33, 33, 540, 540, 8640, 540, 8640, 33, 540, 33, 8640, 8640, 33, 8640, 540, 33, 8640, 33, 33, 8640, 8640, 540, 8640, 8640, 33, 8640, 540, 540, 33, 540, 8640, 8640, 33, 8640, 540, 33, 540, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 540, 8640, 8640, 540, 33, 8640, 33, 540, 540, 33, 540, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 540, 8640, 540, 33, 540, 8640, 540, 8640, 33, 8640, 33, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 540, 33, 8640, 33, 8640, 540, 540, 33, 540, 8640, 540, 540, 8640, 33, 8640, 8640, 540, 33, 8640, 8640, 540, 540, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 8640, 33, 8640, 540, 8640, 8640, 33, 8640, 540, 540, 8640, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 8640, 540, 33, 33, 33, 33]
Prompts retrieved: 791745 . Total input tokens: 176275360 . Total output tokens: 155563613
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 78.29883179301396,
    "estimated_duration": 3600.0468717233316,
    "input_throughput": 6454.123190034303,
    "output_throughput": 5583.403415627738,
    "total_throughput": 12037.52660566204,
    "itl": 89.12216065380319,
    "ttft": 1678029.7312344797,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 478,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.573283598320588,
    "arrivals": 263766,
    "finished_requests": 93643,
    "scheduler_time": 242.2855011000937
}
#Debug simulation 
Total elapsed time: 78.2989771538414. Arrivals time: 0.40627133660018444 Scheduler time: 77.68937317840755 Scheduler overhead time: 0.07856886787340045 Adapter cache time: 0.016785610932856798 Engine time: 0.0767437843605876 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.003125_size_8-16-16/adapters_256_slots_32_rate_0.8-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.003125_size_8-16-16/adapters_256_slots_32_rate_0.8-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 8640, 33, 8640, 8640, 33, 8640, 540, 8640, 33, 540, 33, 8640, 540, 540, 540, 540, 8640, 33, 33, 33, 540, 8640, 33, 8640, 8640, 540, 540, 540, 33, 8640, 33, 540, 540, 33, 540, 33, 33, 540, 540, 8640, 540, 33, 540, 8640, 540, 540, 8640, 540, 8640, 33, 8640, 8640, 540, 33, 33, 8640, 540, 33, 540, 540, 8640, 540, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 8640, 8640, 33, 8640, 33, 540, 8640, 8640, 8640, 540, 33, 8640, 540, 33, 33, 33, 33, 33, 8640, 540, 33, 8640, 33, 8640, 33, 33, 540, 540, 8640, 540, 8640, 33, 540, 33, 8640, 8640, 33, 8640, 540, 33, 8640, 33, 33, 8640, 8640, 540, 8640, 8640, 33, 8640, 540, 540, 33, 540, 8640, 8640, 33, 8640, 540, 33, 540, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 540, 8640, 8640, 540, 33, 8640, 33, 540, 540, 33, 540, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 540, 8640, 540, 33, 540, 8640, 540, 8640, 33, 8640, 33, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 540, 33, 8640, 33, 8640, 540, 540, 33, 540, 8640, 540, 540, 8640, 33, 8640, 8640, 540, 33, 8640, 8640, 540, 540, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 8640, 33, 8640, 540, 8640, 8640, 33, 8640, 540, 540, 8640, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 8640, 540, 33, 33, 33, 33]
Prompts retrieved: 791745 . Total input tokens: 176275360 . Total output tokens: 155563613
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 81.53536272095516,
    "estimated_duration": 3600.0029349697948,
    "input_throughput": 6596.538788710529,
    "output_throughput": 5708.462568287441,
    "total_throughput": 12305.001356997971,
    "itl": 94.33778520985184,
    "ttft": 1664126.7535255516,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 416,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.847285605594512,
    "arrivals": 263766,
    "finished_requests": 95717,
    "scheduler_time": 236.13407136280514
}
#Debug simulation 
Total elapsed time: 81.53550594160333. Arrivals time: 0.4009031713940203 Scheduler time: 80.93409068556502 Scheduler overhead time: 0.07860670099034905 Adapter cache time: 0.016114368103444576 Engine time: 0.07536627864465117 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.003125_size_8-16-32/adapters_256_slots_32_rate_0.8-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.003125_size_8-16-32/adapters_256_slots_32_rate_0.8-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 8640, 33, 8640, 8640, 33, 8640, 540, 8640, 33, 540, 33, 8640, 540, 540, 540, 540, 8640, 33, 33, 33, 540, 8640, 33, 8640, 8640, 540, 540, 540, 33, 8640, 33, 540, 540, 33, 540, 33, 33, 540, 540, 8640, 540, 33, 540, 8640, 540, 540, 8640, 540, 8640, 33, 8640, 8640, 540, 33, 33, 8640, 540, 33, 540, 540, 8640, 540, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 8640, 8640, 33, 8640, 33, 540, 8640, 8640, 8640, 540, 33, 8640, 540, 33, 33, 33, 33, 33, 8640, 540, 33, 8640, 33, 8640, 33, 33, 540, 540, 8640, 540, 8640, 33, 540, 33, 8640, 8640, 33, 8640, 540, 33, 8640, 33, 33, 8640, 8640, 540, 8640, 8640, 33, 8640, 540, 540, 33, 540, 8640, 8640, 33, 8640, 540, 33, 540, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 540, 8640, 8640, 540, 33, 8640, 33, 540, 540, 33, 540, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 540, 8640, 540, 33, 540, 8640, 540, 8640, 33, 8640, 33, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 540, 33, 8640, 33, 8640, 540, 540, 33, 540, 8640, 540, 540, 8640, 33, 8640, 8640, 540, 33, 8640, 8640, 540, 540, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 8640, 33, 8640, 540, 8640, 8640, 33, 8640, 540, 540, 8640, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 8640, 540, 33, 33, 33, 33]
Prompts retrieved: 791745 . Total input tokens: 176275360 . Total output tokens: 155563613
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 79.5669890679419,
    "estimated_duration": 3600.072979085729,
    "input_throughput": 6482.933300404137,
    "output_throughput": 5598.159569842453,
    "total_throughput": 12081.09287024659,
    "itl": 89.27388702897757,
    "ttft": 1676903.0278152835,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 461,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.4177647569263625,
    "arrivals": 263766,
    "finished_requests": 93944,
    "scheduler_time": 241.45920249974745
}
#Debug simulation 
Total elapsed time: 79.56713406881317. Arrivals time: 0.3934577815234661 Scheduler time: 78.96727585233748 Scheduler overhead time: 0.08040621131658554 Adapter cache time: 0.016997838858515024 Engine time: 0.07757066609337926 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.003125_size_16-16-16/adapters_256_slots_32_rate_0.8-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.003125_size_16-16-16/adapters_256_slots_32_rate_0.8-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 8640, 33, 8640, 8640, 33, 8640, 540, 8640, 33, 540, 33, 8640, 540, 540, 540, 540, 8640, 33, 33, 33, 540, 8640, 33, 8640, 8640, 540, 540, 540, 33, 8640, 33, 540, 540, 33, 540, 33, 33, 540, 540, 8640, 540, 33, 540, 8640, 540, 540, 8640, 540, 8640, 33, 8640, 8640, 540, 33, 33, 8640, 540, 33, 540, 540, 8640, 540, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 8640, 8640, 33, 8640, 33, 540, 8640, 8640, 8640, 540, 33, 8640, 540, 33, 33, 33, 33, 33, 8640, 540, 33, 8640, 33, 8640, 33, 33, 540, 540, 8640, 540, 8640, 33, 540, 33, 8640, 8640, 33, 8640, 540, 33, 8640, 33, 33, 8640, 8640, 540, 8640, 8640, 33, 8640, 540, 540, 33, 540, 8640, 8640, 33, 8640, 540, 33, 540, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 540, 8640, 8640, 540, 33, 8640, 33, 540, 540, 33, 540, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 540, 8640, 540, 33, 540, 8640, 540, 8640, 33, 8640, 33, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 540, 33, 8640, 33, 8640, 540, 540, 33, 540, 8640, 540, 540, 8640, 33, 8640, 8640, 540, 33, 8640, 8640, 540, 540, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 8640, 33, 8640, 540, 8640, 8640, 33, 8640, 540, 540, 8640, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 8640, 540, 33, 33, 33, 33]
Prompts retrieved: 791745 . Total input tokens: 176275360 . Total output tokens: 155563613
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 83.36674834834412,
    "estimated_duration": 3600.0159650293604,
    "input_throughput": 6592.848818048626,
    "output_throughput": 5701.38027147127,
    "total_throughput": 12294.229089519895,
    "itl": 94.10999443986127,
    "ttft": 1662844.2993547213,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 431,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.751469925385888,
    "arrivals": 263766,
    "finished_requests": 95623,
    "scheduler_time": 236.582992285746
}
#Debug simulation 
Total elapsed time: 83.36687722895294. Arrivals time: 0.41885641403496265 Scheduler time: 82.75081393308938 Scheduler overhead time: 0.07667461410164833 Adapter cache time: 0.016051161102950573 Engine time: 0.07412987621501088 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.003125_size_16-16-32/adapters_256_slots_32_rate_0.8-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 258176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.05-0.003125_size_16-16-32/adapters_256_slots_32_rate_0.8-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 8640, 33, 8640, 8640, 33, 8640, 540, 8640, 33, 540, 33, 8640, 540, 540, 540, 540, 8640, 33, 33, 33, 540, 8640, 33, 8640, 8640, 540, 540, 540, 33, 8640, 33, 540, 540, 33, 540, 33, 33, 540, 540, 8640, 540, 33, 540, 8640, 540, 540, 8640, 540, 8640, 33, 8640, 8640, 540, 33, 33, 8640, 540, 33, 540, 540, 8640, 540, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 8640, 8640, 33, 8640, 33, 540, 8640, 8640, 8640, 540, 33, 8640, 540, 33, 33, 33, 33, 33, 8640, 540, 33, 8640, 33, 8640, 33, 33, 540, 540, 8640, 540, 8640, 33, 540, 33, 8640, 8640, 33, 8640, 540, 33, 8640, 33, 33, 8640, 8640, 540, 8640, 8640, 33, 8640, 540, 540, 33, 540, 8640, 8640, 33, 8640, 540, 33, 540, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 540, 8640, 8640, 540, 33, 8640, 33, 540, 540, 33, 540, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 540, 8640, 540, 33, 540, 8640, 540, 8640, 33, 8640, 33, 540, 8640, 540, 8640, 540, 8640, 540, 8640, 540, 33, 8640, 33, 8640, 540, 540, 33, 540, 8640, 540, 540, 8640, 33, 8640, 8640, 540, 33, 8640, 8640, 540, 540, 8640, 8640, 540, 540, 540, 540, 8640, 8640, 540, 540, 8640, 33, 8640, 540, 8640, 8640, 33, 8640, 540, 540, 8640, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 8640, 540, 33, 33, 33, 33]
Prompts retrieved: 791745 . Total input tokens: 176275360 . Total output tokens: 155563613
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 79.01473791757599,
    "estimated_duration": 3600.04323861033,
    "input_throughput": 6446.999511305648,
    "output_throughput": 5578.630496602717,
    "total_throughput": 12025.630007908367,
    "itl": 89.00446951740636,
    "ttft": 1678978.210221738,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 477,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.5027100065909615,
    "arrivals": 263766,
    "finished_requests": 93584,
    "scheduler_time": 242.49404009647756
}
#Debug simulation 
Total elapsed time: 79.01486759493127. Arrivals time: 0.39661304373294115 Scheduler time: 78.41274921735749 Scheduler overhead time: 0.07957608485594392 Adapter cache time: 0.017046458087861538 Engine time: 0.07771023223176599 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-8/adapters_256_slots_32_rate_0.8-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 295232,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-8/adapters_256_slots_32_rate_0.8-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 8640, 135, 8640, 8640, 135, 8640, 270, 8640, 135, 270, 135, 8640, 270, 270, 270, 270, 8640, 135, 135, 135, 270, 8640, 135, 8640, 8640, 270, 270, 270, 135, 8640, 135, 270, 270, 135, 270, 135, 135, 270, 270, 8640, 270, 135, 270, 8640, 270, 270, 8640, 270, 8640, 135, 8640, 8640, 270, 135, 135, 8640, 270, 135, 270, 270, 8640, 270, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 8640, 8640, 135, 8640, 135, 270, 8640, 8640, 8640, 270, 135, 8640, 270, 135, 135, 135, 135, 135, 8640, 270, 135, 8640, 135, 8640, 135, 135, 270, 270, 8640, 270, 8640, 135, 270, 135, 8640, 8640, 135, 8640, 270, 135, 8640, 135, 135, 8640, 8640, 270, 8640, 8640, 135, 8640, 270, 270, 135, 270, 8640, 8640, 135, 8640, 270, 135, 270, 8640, 135, 135, 135, 135, 135, 135, 8640, 135, 135, 135, 8640, 135, 270, 8640, 8640, 270, 135, 8640, 135, 270, 270, 135, 270, 135, 8640, 135, 135, 8640, 135, 8640, 8640, 270, 8640, 270, 135, 270, 8640, 270, 8640, 135, 8640, 135, 270, 8640, 270, 8640, 270, 8640, 270, 8640, 270, 135, 8640, 135, 8640, 270, 270, 135, 270, 8640, 270, 270, 8640, 135, 8640, 8640, 270, 135, 8640, 8640, 270, 270, 8640, 8640, 270, 270, 270, 270, 8640, 8640, 270, 270, 8640, 135, 8640, 270, 8640, 8640, 135, 8640, 270, 270, 8640, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 8640, 270, 135, 135, 135, 135]
Prompts retrieved: 777465 . Total input tokens: 173094731 . Total output tokens: 152764019
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 85.7619071919471,
    "estimated_duration": 3600.021567074415,
    "input_throughput": 6565.539000147724,
    "output_throughput": 5713.099106990672,
    "total_throughput": 12278.638107138397,
    "itl": 96.01832404092752,
    "ttft": 1655357.625857425,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 412,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.724312521163395,
    "arrivals": 258949,
    "finished_requests": 95539,
    "scheduler_time": 235.99858010076528
}
#Debug simulation 
Total elapsed time: 85.76204279111698. Arrivals time: 0.39684848906472325 Scheduler time: 85.16593340178952 Scheduler overhead time: 0.07804018771275878 Adapter cache time: 0.01633997680619359 Engine time: 0.07482752855867147 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-16/adapters_256_slots_32_rate_0.8-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/llama/llama-3.1-8b-instruct",
    "adapter_slots": 32,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 284176,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/llama-3.1-8b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-16/adapters_256_slots_32_rate_0.8-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 8640, 135, 8640, 8640, 135, 8640, 270, 8640, 135, 270, 135, 8640, 270, 270, 270, 270, 8640, 135, 135, 135, 270, 8640, 135, 8640, 8640, 270, 270, 270, 135, 8640, 135, 270, 270, 135, 270, 135, 135, 270, 270, 8640, 270, 135, 270, 8640, 270, 270, 8640, 270, 8640, 135, 8640, 8640, 270, 135, 135, 8640, 270, 135, 270, 270, 8640, 270, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 8640, 8640, 135, 8640, 135, 270, 8640, 8640, 8640, 270, 135, 8640, 270, 135, 135, 135, 135, 135, 8640, 270, 135, 8640, 135, 8640, 135, 135, 270, 270, 8640, 270, 8640, 135, 270, 135, 8640, 8640, 135, 8640, 270, 135, 8640, 135, 135, 8640, 8640, 270, 8640, 8640, 135, 8640, 270, 270, 135, 270, 8640, 8640, 135, 8640, 270, 135, 270, 8640, 135, 135, 135, 135, 135, 135, 8640, 135, 135, 135, 8640, 135, 270, 8640, 8640, 270, 135, 8640, 135, 270, 270, 135, 270, 135, 8640, 135, 135, 8640, 135, 8640, 8640, 270, 8640, 270, 135, 270, 8640, 270, 8640, 135, 8640, 135, 270, 8640, 270, 8640, 270, 8640, 270, 8640, 270, 135, 8640, 135, 8640, 270, 270, 135, 270, 8640, 270, 270, 8640, 135, 8640, 8640, 270, 135, 8640, 8640, 270, 270, 8640, 8640, 270, 270, 270, 270, 8640, 8640, 270, 270, 8640, 135, 8640, 270, 8640, 8640, 135, 8640, 270, 270, 8640, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 8640, 270, 135, 135, 135, 135]
Prompts retrieved: 777465 . Total input tokens: 173094731 . Total output tokens: 152764019
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 83.37702976120636,
    "estimated_duration": 3600.0240126356175,
    "input_throughput": 6539.643879420682,
    "output_throughput": 5692.585362783879,
    "total_throughput": 12232.229242204561,
    "itl": 94.26428436377512,
    "ttft": 1662028.0965263646,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 447,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.2686907314555764,
    "arrivals": 258949,
    "finished_requests": 95129,
    "scheduler_time": 236.9687857576961
}
#Debug simulation 
Total elapsed time: 83.37716097012162. Arrivals time: 0.3950231997296214 Scheduler time: 82.78308696532622 Scheduler overhead time: 0.07736014062538743 Adapter cache time: 0.01651970762759447 Engine time: 0.07490599667653441 
