INFO 06-01 00:47:20 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 06-01 00:47:20 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_16-16-32/adapters_384_slots_64_rate_0.4-0.1-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_16-16-32/adapters_384_slots_64_rate_0.4-0.1-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 4320, 1080, 270, 4320, 4320, 270, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 270, 4320, 270, 4320, 1080, 1080, 1080, 270, 270, 1080, 270, 4320, 270, 4320, 1080, 4320, 1080, 270, 1080, 4320, 1080, 4320, 270, 4320, 4320, 4320, 4320, 270, 1080, 1080, 1080, 4320, 1080, 270, 1080, 270, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 270, 270, 4320, 1080, 1080, 270, 270, 270, 1080, 270, 1080, 270, 4320, 270, 1080, 4320, 270, 4320, 1080, 270, 4320, 4320, 4320, 4320, 1080, 270, 1080, 4320, 4320, 1080, 270, 270, 4320, 1080, 1080, 270, 270, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 270, 1080, 1080, 1080, 1080, 270, 270, 4320, 270, 4320, 270, 270, 270, 1080, 1080, 4320, 270, 270, 4320, 270, 4320, 1080, 270, 4320, 1080, 1080, 270, 4320, 4320, 4320, 270, 1080, 4320, 270, 4320, 1080, 1080, 4320, 4320, 270, 1080, 4320, 270, 1080, 1080, 270, 1080, 270, 1080, 4320, 4320, 1080, 270, 4320, 270, 4320, 1080, 1080, 1080, 1080, 1080, 270, 270, 4320, 270, 4320, 270, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 270, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 270, 270, 270, 270, 270, 1080, 270, 270, 1080, 4320, 4320, 270, 270, 4320, 270, 270, 270, 1080, 270, 1080, 4320, 4320, 1080, 1080, 270, 4320, 1080, 4320, 270, 1080, 1080, 270, 270, 1080, 270, 4320, 4320, 270, 4320, 4320, 270, 1080, 4320, 270, 270, 1080, 1080, 270, 270, 4320, 4320, 4320, 4320, 1080, 270, 1080, 1080, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 4320, 1080, 1080, 1080, 4320, 270, 1080, 1080, 4320, 4320, 270, 4320, 4320, 270, 4320, 270, 270, 1080, 270, 4320, 4320, 4320, 1080, 270, 4320, 4320, 1080, 1080, 4320, 4320, 270, 4320, 4320, 1080, 270, 4320, 1080, 1080, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 270, 4320, 270, 1080, 4320, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 4320, 270, 270, 270, 1080, 270, 1080, 1080, 270, 4320, 1080, 4320, 270, 4320, 270, 1080, 1080, 1080, 1080, 270, 1080, 4320, 4320, 270, 4320, 4320, 270, 4320, 1080, 4320, 1080, 1080, 1080, 270, 1080, 270, 270, 4320, 270, 1080, 270, 270, 1080, 4320, 1080, 4320, 270, 4320, 4320, 1080, 4320, 1080, 270, 4320, 270, 4320, 4320, 270, 270, 270]
Prompts retrieved: 725760 . Total input tokens: 161737649 . Total output tokens: 145027066
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 87.00625067809597,
    "estimated_duration": 3600.0023784864347,
    "input_throughput": 6138.855944115115,
    "output_throughput": 5420.083641223496,
    "total_throughput": 11558.93958533861,
    "itl": 148.44329405948383,
    "ttft": 1661374.9934939558,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 595,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9933162197098089,
    "arrivals": 241330,
    "finished_requests": 89167,
    "scheduler_time": 168.39842874507917
}
#Debug simulation 
Total elapsed time: 87.00649146502838. Arrivals time: 0.4125252431258559 Scheduler time: 86.4326957645826 Scheduler overhead time: 0.05983548425137997 Adapter cache time: 0.018653963692486286 Engine time: 0.06056374404579401 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-8/adapters_384_slots_64_rate_0.4-0.1-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-8/adapters_384_slots_64_rate_0.4-0.1-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 4320, 1080, 135, 4320, 4320, 135, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 135, 4320, 135, 4320, 1080, 1080, 1080, 135, 135, 1080, 135, 4320, 135, 4320, 1080, 4320, 1080, 135, 1080, 4320, 1080, 4320, 135, 4320, 4320, 4320, 4320, 135, 1080, 1080, 1080, 4320, 1080, 135, 1080, 135, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 135, 135, 4320, 1080, 1080, 135, 135, 135, 1080, 135, 1080, 135, 4320, 135, 1080, 4320, 135, 4320, 1080, 135, 4320, 4320, 4320, 4320, 1080, 135, 1080, 4320, 4320, 1080, 135, 135, 4320, 1080, 1080, 135, 135, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 135, 1080, 1080, 1080, 1080, 135, 135, 4320, 135, 4320, 135, 135, 135, 1080, 1080, 4320, 135, 135, 4320, 135, 4320, 1080, 135, 4320, 1080, 1080, 135, 4320, 4320, 4320, 135, 1080, 4320, 135, 4320, 1080, 1080, 4320, 4320, 135, 1080, 4320, 135, 1080, 1080, 135, 1080, 135, 1080, 4320, 4320, 1080, 135, 4320, 135, 4320, 1080, 1080, 1080, 1080, 1080, 135, 135, 4320, 135, 4320, 135, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 135, 135, 135, 135, 135, 1080, 135, 135, 1080, 4320, 4320, 135, 135, 4320, 135, 135, 135, 1080, 135, 1080, 4320, 4320, 1080, 1080, 135, 4320, 1080, 4320, 135, 1080, 1080, 135, 135, 1080, 135, 4320, 4320, 135, 4320, 4320, 135, 1080, 4320, 135, 135, 1080, 1080, 135, 135, 4320, 4320, 4320, 4320, 1080, 135, 1080, 1080, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 4320, 1080, 1080, 1080, 4320, 135, 1080, 1080, 4320, 4320, 135, 4320, 4320, 135, 4320, 135, 135, 1080, 135, 4320, 4320, 4320, 1080, 135, 4320, 4320, 1080, 1080, 4320, 4320, 135, 4320, 4320, 1080, 135, 4320, 1080, 1080, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 4320, 135, 1080, 4320, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 4320, 135, 135, 135, 1080, 135, 1080, 1080, 135, 4320, 1080, 4320, 135, 4320, 135, 1080, 1080, 1080, 1080, 135, 1080, 4320, 4320, 135, 4320, 4320, 135, 4320, 1080, 4320, 1080, 1080, 1080, 135, 1080, 135, 135, 4320, 135, 1080, 135, 135, 1080, 4320, 1080, 4320, 135, 4320, 4320, 1080, 4320, 1080, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 708480 . Total input tokens: 157845104 . Total output tokens: 141621177
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 84.32392667466775,
    "estimated_duration": 3600.1746001334386,
    "input_throughput": 6125.821508540886,
    "output_throughput": 5422.763662428038,
    "total_throughput": 11548.585170968923,
    "itl": 148.43304414044442,
    "ttft": 1664592.3871624526,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 619,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8944419134944044,
    "arrivals": 235580,
    "finished_requests": 89031,
    "scheduler_time": 168.38354762299028
}
#Debug simulation 
Total elapsed time: 84.32420484395698. Arrivals time: 0.4115441171452403 Scheduler time: 83.75548458425328 Scheduler overhead time: 0.05826618475839496 Adapter cache time: 0.018414413556456566 Engine time: 0.058859437704086304 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-16/adapters_384_slots_64_rate_0.4-0.1-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-16/adapters_384_slots_64_rate_0.4-0.1-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 4320, 1080, 135, 4320, 4320, 135, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 135, 4320, 135, 4320, 1080, 1080, 1080, 135, 135, 1080, 135, 4320, 135, 4320, 1080, 4320, 1080, 135, 1080, 4320, 1080, 4320, 135, 4320, 4320, 4320, 4320, 135, 1080, 1080, 1080, 4320, 1080, 135, 1080, 135, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 135, 135, 4320, 1080, 1080, 135, 135, 135, 1080, 135, 1080, 135, 4320, 135, 1080, 4320, 135, 4320, 1080, 135, 4320, 4320, 4320, 4320, 1080, 135, 1080, 4320, 4320, 1080, 135, 135, 4320, 1080, 1080, 135, 135, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 135, 1080, 1080, 1080, 1080, 135, 135, 4320, 135, 4320, 135, 135, 135, 1080, 1080, 4320, 135, 135, 4320, 135, 4320, 1080, 135, 4320, 1080, 1080, 135, 4320, 4320, 4320, 135, 1080, 4320, 135, 4320, 1080, 1080, 4320, 4320, 135, 1080, 4320, 135, 1080, 1080, 135, 1080, 135, 1080, 4320, 4320, 1080, 135, 4320, 135, 4320, 1080, 1080, 1080, 1080, 1080, 135, 135, 4320, 135, 4320, 135, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 135, 135, 135, 135, 135, 1080, 135, 135, 1080, 4320, 4320, 135, 135, 4320, 135, 135, 135, 1080, 135, 1080, 4320, 4320, 1080, 1080, 135, 4320, 1080, 4320, 135, 1080, 1080, 135, 135, 1080, 135, 4320, 4320, 135, 4320, 4320, 135, 1080, 4320, 135, 135, 1080, 1080, 135, 135, 4320, 4320, 4320, 4320, 1080, 135, 1080, 1080, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 4320, 1080, 1080, 1080, 4320, 135, 1080, 1080, 4320, 4320, 135, 4320, 4320, 135, 4320, 135, 135, 1080, 135, 4320, 4320, 4320, 1080, 135, 4320, 4320, 1080, 1080, 4320, 4320, 135, 4320, 4320, 1080, 135, 4320, 1080, 1080, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 4320, 135, 1080, 4320, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 4320, 135, 135, 135, 1080, 135, 1080, 1080, 135, 4320, 1080, 4320, 135, 4320, 135, 1080, 1080, 1080, 1080, 135, 1080, 4320, 4320, 135, 4320, 4320, 135, 4320, 1080, 4320, 1080, 1080, 1080, 135, 1080, 135, 135, 4320, 135, 1080, 135, 135, 1080, 4320, 1080, 4320, 135, 4320, 4320, 1080, 4320, 1080, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 708480 . Total input tokens: 157845104 . Total output tokens: 141621177
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 84.53229848016053,
    "estimated_duration": 3600.067554587901,
    "input_throughput": 6126.626977288702,
    "output_throughput": 5423.141289423628,
    "total_throughput": 11549.76826671233,
    "itl": 148.4474448221261,
    "ttft": 1664545.2382206065,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 619,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.017139427149673,
    "arrivals": 235580,
    "finished_requests": 89032,
    "scheduler_time": 168.36101041628467
}
#Debug simulation 
Total elapsed time: 84.53248864924535. Arrivals time: 0.41621819138526917 Scheduler time: 83.9575715106912 Scheduler overhead time: 0.058966594748198986 Adapter cache time: 0.018625921569764614 Engine time: 0.05927798757329583 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-32/adapters_384_slots_64_rate_0.4-0.1-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-32/adapters_384_slots_64_rate_0.4-0.1-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 4320, 1080, 135, 4320, 4320, 135, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 135, 4320, 135, 4320, 1080, 1080, 1080, 135, 135, 1080, 135, 4320, 135, 4320, 1080, 4320, 1080, 135, 1080, 4320, 1080, 4320, 135, 4320, 4320, 4320, 4320, 135, 1080, 1080, 1080, 4320, 1080, 135, 1080, 135, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 135, 135, 4320, 1080, 1080, 135, 135, 135, 1080, 135, 1080, 135, 4320, 135, 1080, 4320, 135, 4320, 1080, 135, 4320, 4320, 4320, 4320, 1080, 135, 1080, 4320, 4320, 1080, 135, 135, 4320, 1080, 1080, 135, 135, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 135, 1080, 1080, 1080, 1080, 135, 135, 4320, 135, 4320, 135, 135, 135, 1080, 1080, 4320, 135, 135, 4320, 135, 4320, 1080, 135, 4320, 1080, 1080, 135, 4320, 4320, 4320, 135, 1080, 4320, 135, 4320, 1080, 1080, 4320, 4320, 135, 1080, 4320, 135, 1080, 1080, 135, 1080, 135, 1080, 4320, 4320, 1080, 135, 4320, 135, 4320, 1080, 1080, 1080, 1080, 1080, 135, 135, 4320, 135, 4320, 135, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 135, 135, 135, 135, 135, 1080, 135, 135, 1080, 4320, 4320, 135, 135, 4320, 135, 135, 135, 1080, 135, 1080, 4320, 4320, 1080, 1080, 135, 4320, 1080, 4320, 135, 1080, 1080, 135, 135, 1080, 135, 4320, 4320, 135, 4320, 4320, 135, 1080, 4320, 135, 135, 1080, 1080, 135, 135, 4320, 4320, 4320, 4320, 1080, 135, 1080, 1080, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 4320, 1080, 1080, 1080, 4320, 135, 1080, 1080, 4320, 4320, 135, 4320, 4320, 135, 4320, 135, 135, 1080, 135, 4320, 4320, 4320, 1080, 135, 4320, 4320, 1080, 1080, 4320, 4320, 135, 4320, 4320, 1080, 135, 4320, 1080, 1080, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 4320, 135, 1080, 4320, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 4320, 135, 135, 135, 1080, 135, 1080, 1080, 135, 4320, 1080, 4320, 135, 4320, 135, 1080, 1080, 1080, 1080, 135, 1080, 4320, 4320, 135, 4320, 4320, 135, 4320, 1080, 4320, 1080, 1080, 1080, 135, 1080, 135, 135, 4320, 135, 1080, 135, 135, 1080, 4320, 1080, 4320, 135, 4320, 4320, 1080, 4320, 1080, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 708480 . Total input tokens: 157845104 . Total output tokens: 141621177
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 84.8700061198324,
    "estimated_duration": 3600.0717260911233,
    "input_throughput": 6126.61987819565,
    "output_throughput": 5423.135005479006,
    "total_throughput": 11549.754883674656,
    "itl": 148.44752230763135,
    "ttft": 1664547.0080950023,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 619,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.021197897661489,
    "arrivals": 235580,
    "finished_requests": 89032,
    "scheduler_time": 168.36108227743082
}
#Debug simulation 
Total elapsed time: 84.87018756056204. Arrivals time: 0.41875030053779483 Scheduler time: 84.29301099665463 Scheduler overhead time: 0.058647419791668653 Adapter cache time: 0.01834485586732626 Engine time: 0.0595318702980876 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-16-16/adapters_384_slots_64_rate_0.4-0.1-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-16-16/adapters_384_slots_64_rate_0.4-0.1-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 4320, 1080, 135, 4320, 4320, 135, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 135, 4320, 135, 4320, 1080, 1080, 1080, 135, 135, 1080, 135, 4320, 135, 4320, 1080, 4320, 1080, 135, 1080, 4320, 1080, 4320, 135, 4320, 4320, 4320, 4320, 135, 1080, 1080, 1080, 4320, 1080, 135, 1080, 135, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 135, 135, 4320, 1080, 1080, 135, 135, 135, 1080, 135, 1080, 135, 4320, 135, 1080, 4320, 135, 4320, 1080, 135, 4320, 4320, 4320, 4320, 1080, 135, 1080, 4320, 4320, 1080, 135, 135, 4320, 1080, 1080, 135, 135, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 135, 1080, 1080, 1080, 1080, 135, 135, 4320, 135, 4320, 135, 135, 135, 1080, 1080, 4320, 135, 135, 4320, 135, 4320, 1080, 135, 4320, 1080, 1080, 135, 4320, 4320, 4320, 135, 1080, 4320, 135, 4320, 1080, 1080, 4320, 4320, 135, 1080, 4320, 135, 1080, 1080, 135, 1080, 135, 1080, 4320, 4320, 1080, 135, 4320, 135, 4320, 1080, 1080, 1080, 1080, 1080, 135, 135, 4320, 135, 4320, 135, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 135, 135, 135, 135, 135, 1080, 135, 135, 1080, 4320, 4320, 135, 135, 4320, 135, 135, 135, 1080, 135, 1080, 4320, 4320, 1080, 1080, 135, 4320, 1080, 4320, 135, 1080, 1080, 135, 135, 1080, 135, 4320, 4320, 135, 4320, 4320, 135, 1080, 4320, 135, 135, 1080, 1080, 135, 135, 4320, 4320, 4320, 4320, 1080, 135, 1080, 1080, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 4320, 1080, 1080, 1080, 4320, 135, 1080, 1080, 4320, 4320, 135, 4320, 4320, 135, 4320, 135, 135, 1080, 135, 4320, 4320, 4320, 1080, 135, 4320, 4320, 1080, 1080, 4320, 4320, 135, 4320, 4320, 1080, 135, 4320, 1080, 1080, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 4320, 135, 1080, 4320, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 4320, 135, 135, 135, 1080, 135, 1080, 1080, 135, 4320, 1080, 4320, 135, 4320, 135, 1080, 1080, 1080, 1080, 135, 1080, 4320, 4320, 135, 4320, 4320, 135, 4320, 1080, 4320, 1080, 1080, 1080, 135, 1080, 135, 135, 4320, 135, 1080, 135, 135, 1080, 4320, 1080, 4320, 135, 4320, 4320, 1080, 4320, 1080, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 708480 . Total input tokens: 157845104 . Total output tokens: 141621177
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 89.5169746009633,
    "estimated_duration": 3600.0881650936785,
    "input_throughput": 6114.434700081077,
    "output_throughput": 5412.869659399836,
    "total_throughput": 11527.304359480913,
    "itl": 147.87193427162245,
    "ttft": 1661136.6497726098,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 599,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.873576380971342,
    "arrivals": 235580,
    "finished_requests": 88816,
    "scheduler_time": 168.85034897877267
}
#Debug simulation 
Total elapsed time: 89.51715215714648. Arrivals time: 0.4244095361791551 Scheduler time: 88.93416149588302 Scheduler overhead time: 0.0585809201002121 Adapter cache time: 0.01854108925908804 Engine time: 0.05992244742810726 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-16-32/adapters_384_slots_64_rate_0.4-0.1-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-16-32/adapters_384_slots_64_rate_0.4-0.1-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 4320, 1080, 135, 4320, 4320, 135, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 135, 4320, 135, 4320, 1080, 1080, 1080, 135, 135, 1080, 135, 4320, 135, 4320, 1080, 4320, 1080, 135, 1080, 4320, 1080, 4320, 135, 4320, 4320, 4320, 4320, 135, 1080, 1080, 1080, 4320, 1080, 135, 1080, 135, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 135, 135, 4320, 1080, 1080, 135, 135, 135, 1080, 135, 1080, 135, 4320, 135, 1080, 4320, 135, 4320, 1080, 135, 4320, 4320, 4320, 4320, 1080, 135, 1080, 4320, 4320, 1080, 135, 135, 4320, 1080, 1080, 135, 135, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 135, 1080, 1080, 1080, 1080, 135, 135, 4320, 135, 4320, 135, 135, 135, 1080, 1080, 4320, 135, 135, 4320, 135, 4320, 1080, 135, 4320, 1080, 1080, 135, 4320, 4320, 4320, 135, 1080, 4320, 135, 4320, 1080, 1080, 4320, 4320, 135, 1080, 4320, 135, 1080, 1080, 135, 1080, 135, 1080, 4320, 4320, 1080, 135, 4320, 135, 4320, 1080, 1080, 1080, 1080, 1080, 135, 135, 4320, 135, 4320, 135, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 135, 135, 135, 135, 135, 1080, 135, 135, 1080, 4320, 4320, 135, 135, 4320, 135, 135, 135, 1080, 135, 1080, 4320, 4320, 1080, 1080, 135, 4320, 1080, 4320, 135, 1080, 1080, 135, 135, 1080, 135, 4320, 4320, 135, 4320, 4320, 135, 1080, 4320, 135, 135, 1080, 1080, 135, 135, 4320, 4320, 4320, 4320, 1080, 135, 1080, 1080, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 4320, 1080, 1080, 1080, 4320, 135, 1080, 1080, 4320, 4320, 135, 4320, 4320, 135, 4320, 135, 135, 1080, 135, 4320, 4320, 4320, 1080, 135, 4320, 4320, 1080, 1080, 4320, 4320, 135, 4320, 4320, 1080, 135, 4320, 1080, 1080, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 4320, 135, 1080, 4320, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 4320, 135, 135, 135, 1080, 135, 1080, 1080, 135, 4320, 1080, 4320, 135, 4320, 135, 1080, 1080, 1080, 1080, 135, 1080, 4320, 4320, 135, 4320, 4320, 135, 4320, 1080, 4320, 1080, 1080, 1080, 135, 1080, 135, 135, 4320, 135, 1080, 135, 135, 1080, 4320, 1080, 4320, 135, 4320, 4320, 1080, 4320, 1080, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 708480 . Total input tokens: 157845104 . Total output tokens: 141621177
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 85.01148061081767,
    "estimated_duration": 3600.125404352477,
    "input_throughput": 6125.500509881934,
    "output_throughput": 5422.3022276945,
    "total_throughput": 11547.802737576434,
    "itl": 148.4399308579911,
    "ttft": 1664590.249755255,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 619,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0458456397987947,
    "arrivals": 235580,
    "finished_requests": 89022,
    "scheduler_time": 168.3749932314437
}
#Debug simulation 
Total elapsed time: 85.011652066838. Arrivals time: 0.4190191407687962 Scheduler time: 84.43239927338436 Scheduler overhead time: 0.059817389119416475 Adapter cache time: 0.01885393774136901 Engine time: 0.05960025452077389 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_16-16-16/adapters_384_slots_64_rate_0.4-0.1-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_16-16-16/adapters_384_slots_64_rate_0.4-0.1-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 4320, 1080, 135, 4320, 4320, 135, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 135, 4320, 135, 4320, 1080, 1080, 1080, 135, 135, 1080, 135, 4320, 135, 4320, 1080, 4320, 1080, 135, 1080, 4320, 1080, 4320, 135, 4320, 4320, 4320, 4320, 135, 1080, 1080, 1080, 4320, 1080, 135, 1080, 135, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 135, 135, 4320, 1080, 1080, 135, 135, 135, 1080, 135, 1080, 135, 4320, 135, 1080, 4320, 135, 4320, 1080, 135, 4320, 4320, 4320, 4320, 1080, 135, 1080, 4320, 4320, 1080, 135, 135, 4320, 1080, 1080, 135, 135, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 135, 1080, 1080, 1080, 1080, 135, 135, 4320, 135, 4320, 135, 135, 135, 1080, 1080, 4320, 135, 135, 4320, 135, 4320, 1080, 135, 4320, 1080, 1080, 135, 4320, 4320, 4320, 135, 1080, 4320, 135, 4320, 1080, 1080, 4320, 4320, 135, 1080, 4320, 135, 1080, 1080, 135, 1080, 135, 1080, 4320, 4320, 1080, 135, 4320, 135, 4320, 1080, 1080, 1080, 1080, 1080, 135, 135, 4320, 135, 4320, 135, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 135, 135, 135, 135, 135, 1080, 135, 135, 1080, 4320, 4320, 135, 135, 4320, 135, 135, 135, 1080, 135, 1080, 4320, 4320, 1080, 1080, 135, 4320, 1080, 4320, 135, 1080, 1080, 135, 135, 1080, 135, 4320, 4320, 135, 4320, 4320, 135, 1080, 4320, 135, 135, 1080, 1080, 135, 135, 4320, 4320, 4320, 4320, 1080, 135, 1080, 1080, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 4320, 1080, 1080, 1080, 4320, 135, 1080, 1080, 4320, 4320, 135, 4320, 4320, 135, 4320, 135, 135, 1080, 135, 4320, 4320, 4320, 1080, 135, 4320, 4320, 1080, 1080, 4320, 4320, 135, 4320, 4320, 1080, 135, 4320, 1080, 1080, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 4320, 135, 1080, 4320, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 4320, 135, 135, 135, 1080, 135, 1080, 1080, 135, 4320, 1080, 4320, 135, 4320, 135, 1080, 1080, 1080, 1080, 135, 1080, 4320, 4320, 135, 4320, 4320, 135, 4320, 1080, 4320, 1080, 1080, 1080, 135, 1080, 135, 135, 4320, 135, 1080, 135, 135, 1080, 4320, 1080, 4320, 135, 4320, 4320, 1080, 4320, 1080, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 708480 . Total input tokens: 157845104 . Total output tokens: 141621177
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 84.77703301189467,
    "estimated_duration": 3600.105352949212,
    "input_throughput": 6126.562930146327,
    "output_throughput": 5423.144348819125,
    "total_throughput": 11549.707278965452,
    "itl": 148.44122469908413,
    "ttft": 1664589.6445891033,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 619,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8508411325444178,
    "arrivals": 235580,
    "finished_requests": 89033,
    "scheduler_time": 168.36941169285697
}
#Debug simulation 
Total elapsed time: 84.77721238089725. Arrivals time: 0.42604015907272696 Scheduler time: 84.19214656483382 Scheduler overhead time: 0.059116097167134285 Adapter cache time: 0.01836649887263775 Engine time: 0.05963679263368249 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_16-16-32/adapters_384_slots_64_rate_0.4-0.1-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_16-16-32/adapters_384_slots_64_rate_0.4-0.1-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 4320, 1080, 135, 4320, 4320, 135, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 135, 4320, 135, 4320, 1080, 1080, 1080, 135, 135, 1080, 135, 4320, 135, 4320, 1080, 4320, 1080, 135, 1080, 4320, 1080, 4320, 135, 4320, 4320, 4320, 4320, 135, 1080, 1080, 1080, 4320, 1080, 135, 1080, 135, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 135, 135, 4320, 1080, 1080, 135, 135, 135, 1080, 135, 1080, 135, 4320, 135, 1080, 4320, 135, 4320, 1080, 135, 4320, 4320, 4320, 4320, 1080, 135, 1080, 4320, 4320, 1080, 135, 135, 4320, 1080, 1080, 135, 135, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 135, 1080, 1080, 1080, 1080, 135, 135, 4320, 135, 4320, 135, 135, 135, 1080, 1080, 4320, 135, 135, 4320, 135, 4320, 1080, 135, 4320, 1080, 1080, 135, 4320, 4320, 4320, 135, 1080, 4320, 135, 4320, 1080, 1080, 4320, 4320, 135, 1080, 4320, 135, 1080, 1080, 135, 1080, 135, 1080, 4320, 4320, 1080, 135, 4320, 135, 4320, 1080, 1080, 1080, 1080, 1080, 135, 135, 4320, 135, 4320, 135, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 135, 135, 135, 135, 135, 1080, 135, 135, 1080, 4320, 4320, 135, 135, 4320, 135, 135, 135, 1080, 135, 1080, 4320, 4320, 1080, 1080, 135, 4320, 1080, 4320, 135, 1080, 1080, 135, 135, 1080, 135, 4320, 4320, 135, 4320, 4320, 135, 1080, 4320, 135, 135, 1080, 1080, 135, 135, 4320, 4320, 4320, 4320, 1080, 135, 1080, 1080, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 4320, 1080, 1080, 1080, 4320, 135, 1080, 1080, 4320, 4320, 135, 4320, 4320, 135, 4320, 135, 135, 1080, 135, 4320, 4320, 4320, 1080, 135, 4320, 4320, 1080, 1080, 4320, 4320, 135, 4320, 4320, 1080, 135, 4320, 1080, 1080, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 4320, 135, 1080, 4320, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 4320, 135, 135, 135, 1080, 135, 1080, 1080, 135, 4320, 1080, 4320, 135, 4320, 135, 1080, 1080, 1080, 1080, 135, 1080, 4320, 4320, 135, 4320, 4320, 135, 4320, 1080, 4320, 1080, 1080, 1080, 135, 1080, 135, 135, 4320, 135, 1080, 135, 135, 1080, 4320, 1080, 4320, 135, 4320, 4320, 1080, 4320, 1080, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 708480 . Total input tokens: 157845104 . Total output tokens: 141621177
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 85.87436206685379,
    "estimated_duration": 3600.1085727467816,
    "input_throughput": 6108.321611873437,
    "output_throughput": 5413.338405272245,
    "total_throughput": 11521.660017145681,
    "itl": 148.06321818050597,
    "ttft": 1663018.887955773,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 627,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0985798446461548,
    "arrivals": 235580,
    "finished_requests": 88816,
    "scheduler_time": 168.74708927859302
}
#Debug simulation 
Total elapsed time: 85.87453984795138. Arrivals time: 0.4209890365600586 Scheduler time: 85.29512638831511 Scheduler overhead time: 0.05878165923058987 Adapter cache time: 0.018631329759955406 Engine time: 0.05938299745321274 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-8/adapters_384_slots_64_rate_0.4-0.1-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-8/adapters_384_slots_64_rate_0.4-0.1-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 1080, 66, 4320, 4320, 66, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 66, 4320, 66, 4320, 1080, 1080, 1080, 66, 66, 1080, 66, 4320, 66, 4320, 1080, 4320, 1080, 66, 1080, 4320, 1080, 4320, 66, 4320, 4320, 4320, 4320, 66, 1080, 1080, 1080, 4320, 1080, 66, 1080, 66, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 66, 66, 4320, 1080, 1080, 66, 66, 66, 1080, 66, 1080, 66, 4320, 66, 1080, 4320, 66, 4320, 1080, 66, 4320, 4320, 4320, 4320, 1080, 66, 1080, 4320, 4320, 1080, 66, 66, 4320, 1080, 1080, 66, 66, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 66, 1080, 1080, 1080, 1080, 66, 66, 4320, 66, 4320, 66, 66, 66, 1080, 1080, 4320, 66, 66, 4320, 66, 4320, 1080, 66, 4320, 1080, 1080, 66, 4320, 4320, 4320, 66, 1080, 4320, 66, 4320, 1080, 1080, 4320, 4320, 66, 1080, 4320, 66, 1080, 1080, 66, 1080, 66, 1080, 4320, 4320, 1080, 66, 4320, 66, 4320, 1080, 1080, 1080, 1080, 1080, 66, 66, 4320, 66, 4320, 66, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 66, 66, 66, 66, 66, 1080, 66, 66, 1080, 4320, 4320, 66, 66, 4320, 66, 66, 66, 1080, 66, 1080, 4320, 4320, 1080, 1080, 66, 4320, 1080, 4320, 66, 1080, 1080, 66, 66, 1080, 66, 4320, 4320, 66, 4320, 4320, 66, 1080, 4320, 66, 66, 1080, 1080, 66, 66, 4320, 4320, 4320, 4320, 1080, 66, 1080, 1080, 66, 66, 66, 66, 66, 66, 66, 66, 1080, 4320, 1080, 1080, 1080, 4320, 66, 1080, 1080, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 1080, 66, 4320, 4320, 4320, 1080, 66, 4320, 4320, 1080, 1080, 4320, 4320, 66, 4320, 4320, 1080, 66, 4320, 1080, 1080, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 1080, 4320, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 4320, 66, 66, 66, 1080, 66, 1080, 1080, 66, 4320, 1080, 4320, 66, 4320, 66, 1080, 1080, 1080, 1080, 66, 1080, 4320, 4320, 66, 4320, 4320, 66, 4320, 1080, 4320, 1080, 1080, 1080, 66, 1080, 66, 66, 4320, 66, 1080, 66, 66, 1080, 4320, 1080, 4320, 66, 4320, 4320, 1080, 4320, 1080, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 699648 . Total input tokens: 155898747 . Total output tokens: 139865162
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 79.3659598059021,
    "estimated_duration": 3600.0698422489027,
    "input_throughput": 6142.889990763412,
    "output_throughput": 5435.20288700198,
    "total_throughput": 11578.092877765392,
    "itl": 149.5808962057455,
    "ttft": 1649664.8231973357,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 610,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8668975237990086,
    "arrivals": 232701,
    "finished_requests": 89612,
    "scheduler_time": 167.18437172445758
}
#Debug simulation 
Total elapsed time: 79.36612970335409. Arrivals time: 0.4151422427967191 Scheduler time: 78.79200395382941 Scheduler overhead time: 0.058703601360321045 Adapter cache time: 0.018717133905738592 Engine time: 0.05953519977629185 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-16/adapters_384_slots_64_rate_0.4-0.1-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-16/adapters_384_slots_64_rate_0.4-0.1-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 1080, 66, 4320, 4320, 66, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 66, 4320, 66, 4320, 1080, 1080, 1080, 66, 66, 1080, 66, 4320, 66, 4320, 1080, 4320, 1080, 66, 1080, 4320, 1080, 4320, 66, 4320, 4320, 4320, 4320, 66, 1080, 1080, 1080, 4320, 1080, 66, 1080, 66, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 66, 66, 4320, 1080, 1080, 66, 66, 66, 1080, 66, 1080, 66, 4320, 66, 1080, 4320, 66, 4320, 1080, 66, 4320, 4320, 4320, 4320, 1080, 66, 1080, 4320, 4320, 1080, 66, 66, 4320, 1080, 1080, 66, 66, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 66, 1080, 1080, 1080, 1080, 66, 66, 4320, 66, 4320, 66, 66, 66, 1080, 1080, 4320, 66, 66, 4320, 66, 4320, 1080, 66, 4320, 1080, 1080, 66, 4320, 4320, 4320, 66, 1080, 4320, 66, 4320, 1080, 1080, 4320, 4320, 66, 1080, 4320, 66, 1080, 1080, 66, 1080, 66, 1080, 4320, 4320, 1080, 66, 4320, 66, 4320, 1080, 1080, 1080, 1080, 1080, 66, 66, 4320, 66, 4320, 66, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 66, 66, 66, 66, 66, 1080, 66, 66, 1080, 4320, 4320, 66, 66, 4320, 66, 66, 66, 1080, 66, 1080, 4320, 4320, 1080, 1080, 66, 4320, 1080, 4320, 66, 1080, 1080, 66, 66, 1080, 66, 4320, 4320, 66, 4320, 4320, 66, 1080, 4320, 66, 66, 1080, 1080, 66, 66, 4320, 4320, 4320, 4320, 1080, 66, 1080, 1080, 66, 66, 66, 66, 66, 66, 66, 66, 1080, 4320, 1080, 1080, 1080, 4320, 66, 1080, 1080, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 1080, 66, 4320, 4320, 4320, 1080, 66, 4320, 4320, 1080, 1080, 4320, 4320, 66, 4320, 4320, 1080, 66, 4320, 1080, 1080, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 1080, 4320, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 4320, 66, 66, 66, 1080, 66, 1080, 1080, 66, 4320, 1080, 4320, 66, 4320, 66, 1080, 1080, 1080, 1080, 66, 1080, 4320, 4320, 66, 4320, 4320, 66, 4320, 1080, 4320, 1080, 1080, 1080, 66, 1080, 66, 66, 4320, 66, 1080, 66, 66, 1080, 4320, 1080, 4320, 66, 4320, 4320, 1080, 4320, 1080, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 699648 . Total input tokens: 155898747 . Total output tokens: 139865162
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 79.8193119992502,
    "estimated_duration": 3600.0039157527467,
    "input_throughput": 6142.699429641066,
    "output_throughput": 5435.007143848847,
    "total_throughput": 11577.706573489912,
    "itl": 149.585782883351,
    "ttft": 1649706.7701481883,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 610,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9922719510877558,
    "arrivals": 232701,
    "finished_requests": 89608,
    "scheduler_time": 167.176221503924
}
#Debug simulation 
Total elapsed time: 79.81946957996115. Arrivals time: 0.4200760736130178 Scheduler time: 79.24056460196152 Scheduler overhead time: 0.05956572946161032 Adapter cache time: 0.01873947400599718 Engine time: 0.05868943827226758 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-32/adapters_384_slots_64_rate_0.4-0.1-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-32/adapters_384_slots_64_rate_0.4-0.1-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 1080, 66, 4320, 4320, 66, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 66, 4320, 66, 4320, 1080, 1080, 1080, 66, 66, 1080, 66, 4320, 66, 4320, 1080, 4320, 1080, 66, 1080, 4320, 1080, 4320, 66, 4320, 4320, 4320, 4320, 66, 1080, 1080, 1080, 4320, 1080, 66, 1080, 66, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 66, 66, 4320, 1080, 1080, 66, 66, 66, 1080, 66, 1080, 66, 4320, 66, 1080, 4320, 66, 4320, 1080, 66, 4320, 4320, 4320, 4320, 1080, 66, 1080, 4320, 4320, 1080, 66, 66, 4320, 1080, 1080, 66, 66, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 66, 1080, 1080, 1080, 1080, 66, 66, 4320, 66, 4320, 66, 66, 66, 1080, 1080, 4320, 66, 66, 4320, 66, 4320, 1080, 66, 4320, 1080, 1080, 66, 4320, 4320, 4320, 66, 1080, 4320, 66, 4320, 1080, 1080, 4320, 4320, 66, 1080, 4320, 66, 1080, 1080, 66, 1080, 66, 1080, 4320, 4320, 1080, 66, 4320, 66, 4320, 1080, 1080, 1080, 1080, 1080, 66, 66, 4320, 66, 4320, 66, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 66, 66, 66, 66, 66, 1080, 66, 66, 1080, 4320, 4320, 66, 66, 4320, 66, 66, 66, 1080, 66, 1080, 4320, 4320, 1080, 1080, 66, 4320, 1080, 4320, 66, 1080, 1080, 66, 66, 1080, 66, 4320, 4320, 66, 4320, 4320, 66, 1080, 4320, 66, 66, 1080, 1080, 66, 66, 4320, 4320, 4320, 4320, 1080, 66, 1080, 1080, 66, 66, 66, 66, 66, 66, 66, 66, 1080, 4320, 1080, 1080, 1080, 4320, 66, 1080, 1080, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 1080, 66, 4320, 4320, 4320, 1080, 66, 4320, 4320, 1080, 1080, 4320, 4320, 66, 4320, 4320, 1080, 66, 4320, 1080, 1080, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 1080, 4320, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 4320, 66, 66, 66, 1080, 66, 1080, 1080, 66, 4320, 1080, 4320, 66, 4320, 66, 1080, 1080, 1080, 1080, 66, 1080, 4320, 4320, 66, 4320, 4320, 66, 4320, 1080, 4320, 1080, 1080, 1080, 66, 1080, 66, 66, 4320, 66, 1080, 66, 66, 1080, 4320, 1080, 4320, 66, 4320, 4320, 1080, 4320, 1080, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 699648 . Total input tokens: 155898747 . Total output tokens: 139865162
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 79.96823126683012,
    "estimated_duration": 3600.007023467949,
    "input_throughput": 6142.694126940189,
    "output_throughput": 5435.002452065132,
    "total_throughput": 11577.696579005322,
    "itl": 149.58586342074256,
    "ttft": 1649707.9586310845,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 610,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9954924654960757,
    "arrivals": 232701,
    "finished_requests": 89608,
    "scheduler_time": 167.1762479426258
}
#Debug simulation 
Total elapsed time: 79.96839753165841. Arrivals time: 0.4169066590256989 Scheduler time: 79.39169172476977 Scheduler overhead time: 0.05930664576590061 Adapter cache time: 0.01875025499612093 Engine time: 0.05924599431455135 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-16-16/adapters_384_slots_64_rate_0.4-0.1-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-16-16/adapters_384_slots_64_rate_0.4-0.1-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 1080, 66, 4320, 4320, 66, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 66, 4320, 66, 4320, 1080, 1080, 1080, 66, 66, 1080, 66, 4320, 66, 4320, 1080, 4320, 1080, 66, 1080, 4320, 1080, 4320, 66, 4320, 4320, 4320, 4320, 66, 1080, 1080, 1080, 4320, 1080, 66, 1080, 66, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 66, 66, 4320, 1080, 1080, 66, 66, 66, 1080, 66, 1080, 66, 4320, 66, 1080, 4320, 66, 4320, 1080, 66, 4320, 4320, 4320, 4320, 1080, 66, 1080, 4320, 4320, 1080, 66, 66, 4320, 1080, 1080, 66, 66, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 66, 1080, 1080, 1080, 1080, 66, 66, 4320, 66, 4320, 66, 66, 66, 1080, 1080, 4320, 66, 66, 4320, 66, 4320, 1080, 66, 4320, 1080, 1080, 66, 4320, 4320, 4320, 66, 1080, 4320, 66, 4320, 1080, 1080, 4320, 4320, 66, 1080, 4320, 66, 1080, 1080, 66, 1080, 66, 1080, 4320, 4320, 1080, 66, 4320, 66, 4320, 1080, 1080, 1080, 1080, 1080, 66, 66, 4320, 66, 4320, 66, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 66, 66, 66, 66, 66, 1080, 66, 66, 1080, 4320, 4320, 66, 66, 4320, 66, 66, 66, 1080, 66, 1080, 4320, 4320, 1080, 1080, 66, 4320, 1080, 4320, 66, 1080, 1080, 66, 66, 1080, 66, 4320, 4320, 66, 4320, 4320, 66, 1080, 4320, 66, 66, 1080, 1080, 66, 66, 4320, 4320, 4320, 4320, 1080, 66, 1080, 1080, 66, 66, 66, 66, 66, 66, 66, 66, 1080, 4320, 1080, 1080, 1080, 4320, 66, 1080, 1080, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 1080, 66, 4320, 4320, 4320, 1080, 66, 4320, 4320, 1080, 1080, 4320, 4320, 66, 4320, 4320, 1080, 66, 4320, 1080, 1080, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 1080, 4320, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 4320, 66, 66, 66, 1080, 66, 1080, 1080, 66, 4320, 1080, 4320, 66, 4320, 66, 1080, 1080, 1080, 1080, 66, 1080, 4320, 4320, 66, 4320, 4320, 66, 4320, 1080, 4320, 1080, 1080, 1080, 66, 1080, 66, 66, 4320, 66, 1080, 66, 66, 1080, 4320, 1080, 4320, 66, 4320, 4320, 1080, 4320, 1080, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 699648 . Total input tokens: 155898747 . Total output tokens: 139865162
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 82.7376718558371,
    "estimated_duration": 3600.142043683396,
    "input_throughput": 6117.758614175643,
    "output_throughput": 5420.442794538841,
    "total_throughput": 11538.201408714483,
    "itl": 149.03643285723285,
    "ttft": 1646515.029356555,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 626,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9616624546656258,
    "arrivals": 232701,
    "finished_requests": 89291,
    "scheduler_time": 167.76034044563028
}
#Debug simulation 
Total elapsed time: 82.73783300071955. Arrivals time: 0.4223048724234104 Scheduler time: 82.15856090188026 Scheduler overhead time: 0.05831995327025652 Adapter cache time: 0.018680231645703316 Engine time: 0.057904785964637995 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-16-32/adapters_384_slots_64_rate_0.4-0.1-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-16-32/adapters_384_slots_64_rate_0.4-0.1-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 1080, 66, 4320, 4320, 66, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 66, 4320, 66, 4320, 1080, 1080, 1080, 66, 66, 1080, 66, 4320, 66, 4320, 1080, 4320, 1080, 66, 1080, 4320, 1080, 4320, 66, 4320, 4320, 4320, 4320, 66, 1080, 1080, 1080, 4320, 1080, 66, 1080, 66, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 66, 66, 4320, 1080, 1080, 66, 66, 66, 1080, 66, 1080, 66, 4320, 66, 1080, 4320, 66, 4320, 1080, 66, 4320, 4320, 4320, 4320, 1080, 66, 1080, 4320, 4320, 1080, 66, 66, 4320, 1080, 1080, 66, 66, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 66, 1080, 1080, 1080, 1080, 66, 66, 4320, 66, 4320, 66, 66, 66, 1080, 1080, 4320, 66, 66, 4320, 66, 4320, 1080, 66, 4320, 1080, 1080, 66, 4320, 4320, 4320, 66, 1080, 4320, 66, 4320, 1080, 1080, 4320, 4320, 66, 1080, 4320, 66, 1080, 1080, 66, 1080, 66, 1080, 4320, 4320, 1080, 66, 4320, 66, 4320, 1080, 1080, 1080, 1080, 1080, 66, 66, 4320, 66, 4320, 66, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 66, 66, 66, 66, 66, 1080, 66, 66, 1080, 4320, 4320, 66, 66, 4320, 66, 66, 66, 1080, 66, 1080, 4320, 4320, 1080, 1080, 66, 4320, 1080, 4320, 66, 1080, 1080, 66, 66, 1080, 66, 4320, 4320, 66, 4320, 4320, 66, 1080, 4320, 66, 66, 1080, 1080, 66, 66, 4320, 4320, 4320, 4320, 1080, 66, 1080, 1080, 66, 66, 66, 66, 66, 66, 66, 66, 1080, 4320, 1080, 1080, 1080, 4320, 66, 1080, 1080, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 1080, 66, 4320, 4320, 4320, 1080, 66, 4320, 4320, 1080, 1080, 4320, 4320, 66, 4320, 4320, 1080, 66, 4320, 1080, 1080, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 1080, 4320, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 4320, 66, 66, 66, 1080, 66, 1080, 1080, 66, 4320, 1080, 4320, 66, 4320, 66, 1080, 1080, 1080, 1080, 66, 1080, 4320, 4320, 66, 4320, 4320, 66, 4320, 1080, 4320, 1080, 1080, 1080, 66, 1080, 66, 66, 4320, 66, 1080, 66, 66, 1080, 4320, 1080, 4320, 66, 4320, 4320, 1080, 4320, 1080, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 699648 . Total input tokens: 155898747 . Total output tokens: 139865162
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 80.41461957013234,
    "estimated_duration": 3600.027195314991,
    "input_throughput": 6141.343051178127,
    "output_throughput": 5439.639740912169,
    "total_throughput": 11580.982792090295,
    "itl": 149.52467080845884,
    "ttft": 1645918.3024604146,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 602,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9941058193706018,
    "arrivals": 232701,
    "finished_requests": 89714,
    "scheduler_time": 167.26950911189303
}
#Debug simulation 
Total elapsed time: 80.41479076631367. Arrivals time: 0.43282688735052943 Scheduler time: 79.82366944011301 Scheduler overhead time: 0.058778753969818354 Adapter cache time: 0.018932870589196682 Engine time: 0.05891674058511853 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_16-16-16/adapters_384_slots_64_rate_0.4-0.1-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_16-16-16/adapters_384_slots_64_rate_0.4-0.1-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 1080, 66, 4320, 4320, 66, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 66, 4320, 66, 4320, 1080, 1080, 1080, 66, 66, 1080, 66, 4320, 66, 4320, 1080, 4320, 1080, 66, 1080, 4320, 1080, 4320, 66, 4320, 4320, 4320, 4320, 66, 1080, 1080, 1080, 4320, 1080, 66, 1080, 66, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 66, 66, 4320, 1080, 1080, 66, 66, 66, 1080, 66, 1080, 66, 4320, 66, 1080, 4320, 66, 4320, 1080, 66, 4320, 4320, 4320, 4320, 1080, 66, 1080, 4320, 4320, 1080, 66, 66, 4320, 1080, 1080, 66, 66, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 66, 1080, 1080, 1080, 1080, 66, 66, 4320, 66, 4320, 66, 66, 66, 1080, 1080, 4320, 66, 66, 4320, 66, 4320, 1080, 66, 4320, 1080, 1080, 66, 4320, 4320, 4320, 66, 1080, 4320, 66, 4320, 1080, 1080, 4320, 4320, 66, 1080, 4320, 66, 1080, 1080, 66, 1080, 66, 1080, 4320, 4320, 1080, 66, 4320, 66, 4320, 1080, 1080, 1080, 1080, 1080, 66, 66, 4320, 66, 4320, 66, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 66, 66, 66, 66, 66, 1080, 66, 66, 1080, 4320, 4320, 66, 66, 4320, 66, 66, 66, 1080, 66, 1080, 4320, 4320, 1080, 1080, 66, 4320, 1080, 4320, 66, 1080, 1080, 66, 66, 1080, 66, 4320, 4320, 66, 4320, 4320, 66, 1080, 4320, 66, 66, 1080, 1080, 66, 66, 4320, 4320, 4320, 4320, 1080, 66, 1080, 1080, 66, 66, 66, 66, 66, 66, 66, 66, 1080, 4320, 1080, 1080, 1080, 4320, 66, 1080, 1080, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 1080, 66, 4320, 4320, 4320, 1080, 66, 4320, 4320, 1080, 1080, 4320, 4320, 66, 4320, 4320, 1080, 66, 4320, 1080, 1080, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 1080, 4320, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 4320, 66, 66, 66, 1080, 66, 1080, 1080, 66, 4320, 1080, 4320, 66, 4320, 66, 1080, 1080, 1080, 1080, 66, 1080, 4320, 4320, 66, 4320, 4320, 66, 4320, 1080, 4320, 1080, 1080, 1080, 66, 1080, 66, 66, 4320, 66, 1080, 66, 66, 1080, 4320, 1080, 4320, 66, 4320, 4320, 1080, 4320, 1080, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 699648 . Total input tokens: 155898747 . Total output tokens: 139865162
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 81.01308431709185,
    "estimated_duration": 3600.097052200878,
    "input_throughput": 6113.843510564299,
    "output_throughput": 5416.875077875503,
    "total_throughput": 11530.718588439802,
    "itl": 148.97368758875663,
    "ttft": 1647012.1230805903,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 642,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9196122893271654,
    "arrivals": 232701,
    "finished_requests": 89243,
    "scheduler_time": 167.87221891376416
}
#Debug simulation 
Total elapsed time: 81.01324134413153. Arrivals time: 0.42161201732233167 Scheduler time: 80.43569507822394 Scheduler overhead time: 0.05740619823336601 Adapter cache time: 0.01866252813488245 Engine time: 0.05817573703825474 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_16-16-32/adapters_384_slots_64_rate_0.4-0.1-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_16-16-32/adapters_384_slots_64_rate_0.4-0.1-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 1080, 66, 4320, 4320, 66, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 66, 4320, 66, 4320, 1080, 1080, 1080, 66, 66, 1080, 66, 4320, 66, 4320, 1080, 4320, 1080, 66, 1080, 4320, 1080, 4320, 66, 4320, 4320, 4320, 4320, 66, 1080, 1080, 1080, 4320, 1080, 66, 1080, 66, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 66, 66, 4320, 1080, 1080, 66, 66, 66, 1080, 66, 1080, 66, 4320, 66, 1080, 4320, 66, 4320, 1080, 66, 4320, 4320, 4320, 4320, 1080, 66, 1080, 4320, 4320, 1080, 66, 66, 4320, 1080, 1080, 66, 66, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 66, 1080, 1080, 1080, 1080, 66, 66, 4320, 66, 4320, 66, 66, 66, 1080, 1080, 4320, 66, 66, 4320, 66, 4320, 1080, 66, 4320, 1080, 1080, 66, 4320, 4320, 4320, 66, 1080, 4320, 66, 4320, 1080, 1080, 4320, 4320, 66, 1080, 4320, 66, 1080, 1080, 66, 1080, 66, 1080, 4320, 4320, 1080, 66, 4320, 66, 4320, 1080, 1080, 1080, 1080, 1080, 66, 66, 4320, 66, 4320, 66, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 66, 66, 66, 66, 66, 1080, 66, 66, 1080, 4320, 4320, 66, 66, 4320, 66, 66, 66, 1080, 66, 1080, 4320, 4320, 1080, 1080, 66, 4320, 1080, 4320, 66, 1080, 1080, 66, 66, 1080, 66, 4320, 4320, 66, 4320, 4320, 66, 1080, 4320, 66, 66, 1080, 1080, 66, 66, 4320, 4320, 4320, 4320, 1080, 66, 1080, 1080, 66, 66, 66, 66, 66, 66, 66, 66, 1080, 4320, 1080, 1080, 1080, 4320, 66, 1080, 1080, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 1080, 66, 4320, 4320, 4320, 1080, 66, 4320, 4320, 1080, 1080, 4320, 4320, 66, 4320, 4320, 1080, 66, 4320, 1080, 1080, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 1080, 4320, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 4320, 66, 66, 66, 1080, 66, 1080, 1080, 66, 4320, 1080, 4320, 66, 4320, 66, 1080, 1080, 1080, 1080, 66, 1080, 4320, 4320, 66, 4320, 4320, 66, 4320, 1080, 4320, 1080, 1080, 1080, 66, 1080, 66, 66, 4320, 66, 1080, 66, 66, 1080, 4320, 1080, 4320, 66, 4320, 4320, 1080, 4320, 1080, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 699648 . Total input tokens: 155898747 . Total output tokens: 139865162
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 82.47716370224953,
    "estimated_duration": 3600.0441957229273,
    "input_throughput": 6110.666926293785,
    "output_throughput": 5418.710143385522,
    "total_throughput": 11529.377069679307,
    "itl": 148.97452388602923,
    "ttft": 1645221.2814405165,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 631,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1172359379753463,
    "arrivals": 232701,
    "finished_requests": 89197,
    "scheduler_time": 167.91376601192704
}
#Debug simulation 
Total elapsed time: 82.47733327001333. Arrivals time: 0.4248865661211312 Scheduler time: 81.8941321731545 Scheduler overhead time: 0.05851559806615114 Adapter cache time: 0.018882795702666044 Engine time: 0.05866878107190132 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-8/adapters_384_slots_64_rate_0.4-0.1-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-8/adapters_384_slots_64_rate_0.4-0.1-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 1080, 33, 4320, 4320, 33, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 33, 4320, 33, 4320, 1080, 1080, 1080, 33, 33, 1080, 33, 4320, 33, 4320, 1080, 4320, 1080, 33, 1080, 4320, 1080, 4320, 33, 4320, 4320, 4320, 4320, 33, 1080, 1080, 1080, 4320, 1080, 33, 1080, 33, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 33, 33, 4320, 1080, 1080, 33, 33, 33, 1080, 33, 1080, 33, 4320, 33, 1080, 4320, 33, 4320, 1080, 33, 4320, 4320, 4320, 4320, 1080, 33, 1080, 4320, 4320, 1080, 33, 33, 4320, 1080, 1080, 33, 33, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 33, 1080, 1080, 1080, 1080, 33, 33, 4320, 33, 4320, 33, 33, 33, 1080, 1080, 4320, 33, 33, 4320, 33, 4320, 1080, 33, 4320, 1080, 1080, 33, 4320, 4320, 4320, 33, 1080, 4320, 33, 4320, 1080, 1080, 4320, 4320, 33, 1080, 4320, 33, 1080, 1080, 33, 1080, 33, 1080, 4320, 4320, 1080, 33, 4320, 33, 4320, 1080, 1080, 1080, 1080, 1080, 33, 33, 4320, 33, 4320, 33, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 33, 33, 33, 33, 33, 1080, 33, 33, 1080, 4320, 4320, 33, 33, 4320, 33, 33, 33, 1080, 33, 1080, 4320, 4320, 1080, 1080, 33, 4320, 1080, 4320, 33, 1080, 1080, 33, 33, 1080, 33, 4320, 4320, 33, 4320, 4320, 33, 1080, 4320, 33, 33, 1080, 1080, 33, 33, 4320, 4320, 4320, 4320, 1080, 33, 1080, 1080, 33, 33, 33, 33, 33, 33, 33, 33, 1080, 4320, 1080, 1080, 1080, 4320, 33, 1080, 1080, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 1080, 33, 4320, 4320, 4320, 1080, 33, 4320, 4320, 1080, 1080, 4320, 4320, 33, 4320, 4320, 1080, 33, 4320, 1080, 1080, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 1080, 4320, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 4320, 33, 33, 33, 1080, 33, 1080, 1080, 33, 4320, 1080, 4320, 33, 4320, 33, 1080, 1080, 1080, 1080, 33, 1080, 4320, 4320, 33, 4320, 4320, 33, 4320, 1080, 4320, 1080, 1080, 1080, 33, 1080, 33, 33, 4320, 33, 1080, 33, 33, 1080, 4320, 1080, 4320, 33, 4320, 4320, 1080, 4320, 1080, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 695424 . Total input tokens: 154965070 . Total output tokens: 139036309
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 78.02956137573346,
    "estimated_duration": 3600.042794364585,
    "input_throughput": 6089.625110656341,
    "output_throughput": 5441.784200639701,
    "total_throughput": 11531.409311296042,
    "itl": 150.21627720088352,
    "ttft": 1650057.2222169384,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 622,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.903623376726203,
    "arrivals": 231176,
    "finished_requests": 89246,
    "scheduler_time": 166.70046135632174
}
#Debug simulation 
Total elapsed time: 78.02972852485254. Arrivals time: 0.4212553622201085 Scheduler time: 77.45219545811415 Scheduler overhead time: 0.05798221053555608 Adapter cache time: 0.018269119318574667 Engine time: 0.05853554280474782 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-16/adapters_384_slots_64_rate_0.4-0.1-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-16/adapters_384_slots_64_rate_0.4-0.1-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 1080, 33, 4320, 4320, 33, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 33, 4320, 33, 4320, 1080, 1080, 1080, 33, 33, 1080, 33, 4320, 33, 4320, 1080, 4320, 1080, 33, 1080, 4320, 1080, 4320, 33, 4320, 4320, 4320, 4320, 33, 1080, 1080, 1080, 4320, 1080, 33, 1080, 33, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 33, 33, 4320, 1080, 1080, 33, 33, 33, 1080, 33, 1080, 33, 4320, 33, 1080, 4320, 33, 4320, 1080, 33, 4320, 4320, 4320, 4320, 1080, 33, 1080, 4320, 4320, 1080, 33, 33, 4320, 1080, 1080, 33, 33, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 33, 1080, 1080, 1080, 1080, 33, 33, 4320, 33, 4320, 33, 33, 33, 1080, 1080, 4320, 33, 33, 4320, 33, 4320, 1080, 33, 4320, 1080, 1080, 33, 4320, 4320, 4320, 33, 1080, 4320, 33, 4320, 1080, 1080, 4320, 4320, 33, 1080, 4320, 33, 1080, 1080, 33, 1080, 33, 1080, 4320, 4320, 1080, 33, 4320, 33, 4320, 1080, 1080, 1080, 1080, 1080, 33, 33, 4320, 33, 4320, 33, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 33, 33, 33, 33, 33, 1080, 33, 33, 1080, 4320, 4320, 33, 33, 4320, 33, 33, 33, 1080, 33, 1080, 4320, 4320, 1080, 1080, 33, 4320, 1080, 4320, 33, 1080, 1080, 33, 33, 1080, 33, 4320, 4320, 33, 4320, 4320, 33, 1080, 4320, 33, 33, 1080, 1080, 33, 33, 4320, 4320, 4320, 4320, 1080, 33, 1080, 1080, 33, 33, 33, 33, 33, 33, 33, 33, 1080, 4320, 1080, 1080, 1080, 4320, 33, 1080, 1080, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 1080, 33, 4320, 4320, 4320, 1080, 33, 4320, 4320, 1080, 1080, 4320, 4320, 33, 4320, 4320, 1080, 33, 4320, 1080, 1080, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 1080, 4320, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 4320, 33, 33, 33, 1080, 33, 1080, 1080, 33, 4320, 1080, 4320, 33, 4320, 33, 1080, 1080, 1080, 1080, 33, 1080, 4320, 4320, 33, 4320, 4320, 33, 4320, 1080, 4320, 1080, 1080, 1080, 33, 1080, 33, 33, 4320, 33, 1080, 33, 33, 1080, 4320, 1080, 4320, 33, 4320, 4320, 1080, 4320, 1080, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 695424 . Total input tokens: 154965070 . Total output tokens: 139036309
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 85.49227816006169,
    "estimated_duration": 3600.1162153808336,
    "input_throughput": 6103.722126002395,
    "output_throughput": 5443.63176840581,
    "total_throughput": 11547.353894408207,
    "itl": 150.39639649034365,
    "ttft": 1633327.3405119942,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 620,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0283013838133845,
    "arrivals": 231176,
    "finished_requests": 89311,
    "scheduler_time": 166.55665493394469
}
#Debug simulation 
Total elapsed time: 85.49243238475174. Arrivals time: 0.41940459376201034 Scheduler time: 84.91592493560165 Scheduler overhead time: 0.05858060251921415 Adapter cache time: 0.018361219204962254 Engine time: 0.05882266815751791 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-32/adapters_384_slots_64_rate_0.4-0.1-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-32/adapters_384_slots_64_rate_0.4-0.1-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 1080, 33, 4320, 4320, 33, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 33, 4320, 33, 4320, 1080, 1080, 1080, 33, 33, 1080, 33, 4320, 33, 4320, 1080, 4320, 1080, 33, 1080, 4320, 1080, 4320, 33, 4320, 4320, 4320, 4320, 33, 1080, 1080, 1080, 4320, 1080, 33, 1080, 33, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 33, 33, 4320, 1080, 1080, 33, 33, 33, 1080, 33, 1080, 33, 4320, 33, 1080, 4320, 33, 4320, 1080, 33, 4320, 4320, 4320, 4320, 1080, 33, 1080, 4320, 4320, 1080, 33, 33, 4320, 1080, 1080, 33, 33, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 33, 1080, 1080, 1080, 1080, 33, 33, 4320, 33, 4320, 33, 33, 33, 1080, 1080, 4320, 33, 33, 4320, 33, 4320, 1080, 33, 4320, 1080, 1080, 33, 4320, 4320, 4320, 33, 1080, 4320, 33, 4320, 1080, 1080, 4320, 4320, 33, 1080, 4320, 33, 1080, 1080, 33, 1080, 33, 1080, 4320, 4320, 1080, 33, 4320, 33, 4320, 1080, 1080, 1080, 1080, 1080, 33, 33, 4320, 33, 4320, 33, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 33, 33, 33, 33, 33, 1080, 33, 33, 1080, 4320, 4320, 33, 33, 4320, 33, 33, 33, 1080, 33, 1080, 4320, 4320, 1080, 1080, 33, 4320, 1080, 4320, 33, 1080, 1080, 33, 33, 1080, 33, 4320, 4320, 33, 4320, 4320, 33, 1080, 4320, 33, 33, 1080, 1080, 33, 33, 4320, 4320, 4320, 4320, 1080, 33, 1080, 1080, 33, 33, 33, 33, 33, 33, 33, 33, 1080, 4320, 1080, 1080, 1080, 4320, 33, 1080, 1080, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 1080, 33, 4320, 4320, 4320, 1080, 33, 4320, 4320, 1080, 1080, 4320, 4320, 33, 4320, 4320, 1080, 33, 4320, 1080, 1080, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 1080, 4320, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 4320, 33, 33, 33, 1080, 33, 1080, 1080, 33, 4320, 1080, 4320, 33, 4320, 33, 1080, 1080, 1080, 1080, 33, 1080, 4320, 4320, 33, 4320, 4320, 33, 4320, 1080, 4320, 1080, 1080, 1080, 33, 1080, 33, 33, 4320, 33, 1080, 33, 33, 1080, 4320, 1080, 4320, 33, 4320, 4320, 1080, 4320, 1080, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 695424 . Total input tokens: 154965070 . Total output tokens: 139036309
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 85.32635221304372,
    "estimated_duration": 3600.1180423098426,
    "input_throughput": 6103.719028585343,
    "output_throughput": 5443.6290059606135,
    "total_throughput": 11547.348034545957,
    "itl": 150.39639517956851,
    "ttft": 1633327.6605596875,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 620,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0309863664023693,
    "arrivals": 231176,
    "finished_requests": 89311,
    "scheduler_time": 166.55663230792032
}
#Debug simulation 
Total elapsed time: 85.32650663610548. Arrivals time: 0.4182286877185106 Scheduler time: 84.75280022015795 Scheduler overhead time: 0.057383906096220016 Adapter cache time: 0.01775953359901905 Engine time: 0.05863560037687421 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-16-16/adapters_384_slots_64_rate_0.4-0.1-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-16-16/adapters_384_slots_64_rate_0.4-0.1-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 1080, 33, 4320, 4320, 33, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 33, 4320, 33, 4320, 1080, 1080, 1080, 33, 33, 1080, 33, 4320, 33, 4320, 1080, 4320, 1080, 33, 1080, 4320, 1080, 4320, 33, 4320, 4320, 4320, 4320, 33, 1080, 1080, 1080, 4320, 1080, 33, 1080, 33, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 33, 33, 4320, 1080, 1080, 33, 33, 33, 1080, 33, 1080, 33, 4320, 33, 1080, 4320, 33, 4320, 1080, 33, 4320, 4320, 4320, 4320, 1080, 33, 1080, 4320, 4320, 1080, 33, 33, 4320, 1080, 1080, 33, 33, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 33, 1080, 1080, 1080, 1080, 33, 33, 4320, 33, 4320, 33, 33, 33, 1080, 1080, 4320, 33, 33, 4320, 33, 4320, 1080, 33, 4320, 1080, 1080, 33, 4320, 4320, 4320, 33, 1080, 4320, 33, 4320, 1080, 1080, 4320, 4320, 33, 1080, 4320, 33, 1080, 1080, 33, 1080, 33, 1080, 4320, 4320, 1080, 33, 4320, 33, 4320, 1080, 1080, 1080, 1080, 1080, 33, 33, 4320, 33, 4320, 33, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 33, 33, 33, 33, 33, 1080, 33, 33, 1080, 4320, 4320, 33, 33, 4320, 33, 33, 33, 1080, 33, 1080, 4320, 4320, 1080, 1080, 33, 4320, 1080, 4320, 33, 1080, 1080, 33, 33, 1080, 33, 4320, 4320, 33, 4320, 4320, 33, 1080, 4320, 33, 33, 1080, 1080, 33, 33, 4320, 4320, 4320, 4320, 1080, 33, 1080, 1080, 33, 33, 33, 33, 33, 33, 33, 33, 1080, 4320, 1080, 1080, 1080, 4320, 33, 1080, 1080, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 1080, 33, 4320, 4320, 4320, 1080, 33, 4320, 4320, 1080, 1080, 4320, 4320, 33, 4320, 4320, 1080, 33, 4320, 1080, 1080, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 1080, 4320, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 4320, 33, 33, 33, 1080, 33, 1080, 1080, 33, 4320, 1080, 4320, 33, 4320, 33, 1080, 1080, 1080, 1080, 33, 1080, 4320, 4320, 33, 4320, 4320, 33, 4320, 1080, 4320, 1080, 1080, 1080, 33, 1080, 33, 33, 4320, 33, 1080, 33, 33, 1080, 4320, 1080, 4320, 33, 4320, 4320, 1080, 4320, 1080, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 695424 . Total input tokens: 154965070 . Total output tokens: 139036309
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 77.476574618835,
    "estimated_duration": 3600.072726704812,
    "input_throughput": 6089.5744792540045,
    "output_throughput": 5441.738955627031,
    "total_throughput": 11531.313434881036,
    "itl": 150.21689080407785,
    "ttft": 1650045.2804525965,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 622,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.949702253486018,
    "arrivals": 231176,
    "finished_requests": 89246,
    "scheduler_time": 166.70112687348995
}
#Debug simulation 
Total elapsed time: 77.47673627082258. Arrivals time: 0.42491041496396065 Scheduler time: 76.89567451365292 Scheduler overhead time: 0.05832875706255436 Adapter cache time: 0.01774162147194147 Engine time: 0.0584311387501657 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-16-32/adapters_384_slots_64_rate_0.4-0.1-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-16-32/adapters_384_slots_64_rate_0.4-0.1-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 1080, 33, 4320, 4320, 33, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 33, 4320, 33, 4320, 1080, 1080, 1080, 33, 33, 1080, 33, 4320, 33, 4320, 1080, 4320, 1080, 33, 1080, 4320, 1080, 4320, 33, 4320, 4320, 4320, 4320, 33, 1080, 1080, 1080, 4320, 1080, 33, 1080, 33, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 33, 33, 4320, 1080, 1080, 33, 33, 33, 1080, 33, 1080, 33, 4320, 33, 1080, 4320, 33, 4320, 1080, 33, 4320, 4320, 4320, 4320, 1080, 33, 1080, 4320, 4320, 1080, 33, 33, 4320, 1080, 1080, 33, 33, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 33, 1080, 1080, 1080, 1080, 33, 33, 4320, 33, 4320, 33, 33, 33, 1080, 1080, 4320, 33, 33, 4320, 33, 4320, 1080, 33, 4320, 1080, 1080, 33, 4320, 4320, 4320, 33, 1080, 4320, 33, 4320, 1080, 1080, 4320, 4320, 33, 1080, 4320, 33, 1080, 1080, 33, 1080, 33, 1080, 4320, 4320, 1080, 33, 4320, 33, 4320, 1080, 1080, 1080, 1080, 1080, 33, 33, 4320, 33, 4320, 33, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 33, 33, 33, 33, 33, 1080, 33, 33, 1080, 4320, 4320, 33, 33, 4320, 33, 33, 33, 1080, 33, 1080, 4320, 4320, 1080, 1080, 33, 4320, 1080, 4320, 33, 1080, 1080, 33, 33, 1080, 33, 4320, 4320, 33, 4320, 4320, 33, 1080, 4320, 33, 33, 1080, 1080, 33, 33, 4320, 4320, 4320, 4320, 1080, 33, 1080, 1080, 33, 33, 33, 33, 33, 33, 33, 33, 1080, 4320, 1080, 1080, 1080, 4320, 33, 1080, 1080, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 1080, 33, 4320, 4320, 4320, 1080, 33, 4320, 4320, 1080, 1080, 4320, 4320, 33, 4320, 4320, 1080, 33, 4320, 1080, 1080, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 1080, 4320, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 4320, 33, 33, 33, 1080, 33, 1080, 1080, 33, 4320, 1080, 4320, 33, 4320, 33, 1080, 1080, 1080, 1080, 33, 1080, 4320, 4320, 33, 4320, 4320, 33, 4320, 1080, 4320, 1080, 1080, 1080, 33, 1080, 33, 33, 4320, 33, 1080, 33, 33, 1080, 4320, 1080, 4320, 33, 4320, 4320, 1080, 4320, 1080, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 695424 . Total input tokens: 154965070 . Total output tokens: 139036309
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 85.03797351615503,
    "estimated_duration": 3600.14434930101,
    "input_throughput": 6103.6744274618895,
    "output_throughput": 5443.589228249976,
    "total_throughput": 11547.263655711866,
    "itl": 150.39717437144873,
    "ttft": 1633337.3212601321,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 620,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.057394661549481,
    "arrivals": 231176,
    "finished_requests": 89311,
    "scheduler_time": 166.55715812392532
}
#Debug simulation 
Total elapsed time: 85.03812484396622. Arrivals time: 0.4229220310226083 Scheduler time: 84.45907226018608 Scheduler overhead time: 0.05827132239937782 Adapter cache time: 0.017899753525853157 Engine time: 0.05843230476602912 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_16-16-16/adapters_384_slots_64_rate_0.4-0.1-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_16-16-16/adapters_384_slots_64_rate_0.4-0.1-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 1080, 33, 4320, 4320, 33, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 33, 4320, 33, 4320, 1080, 1080, 1080, 33, 33, 1080, 33, 4320, 33, 4320, 1080, 4320, 1080, 33, 1080, 4320, 1080, 4320, 33, 4320, 4320, 4320, 4320, 33, 1080, 1080, 1080, 4320, 1080, 33, 1080, 33, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 33, 33, 4320, 1080, 1080, 33, 33, 33, 1080, 33, 1080, 33, 4320, 33, 1080, 4320, 33, 4320, 1080, 33, 4320, 4320, 4320, 4320, 1080, 33, 1080, 4320, 4320, 1080, 33, 33, 4320, 1080, 1080, 33, 33, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 33, 1080, 1080, 1080, 1080, 33, 33, 4320, 33, 4320, 33, 33, 33, 1080, 1080, 4320, 33, 33, 4320, 33, 4320, 1080, 33, 4320, 1080, 1080, 33, 4320, 4320, 4320, 33, 1080, 4320, 33, 4320, 1080, 1080, 4320, 4320, 33, 1080, 4320, 33, 1080, 1080, 33, 1080, 33, 1080, 4320, 4320, 1080, 33, 4320, 33, 4320, 1080, 1080, 1080, 1080, 1080, 33, 33, 4320, 33, 4320, 33, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 33, 33, 33, 33, 33, 1080, 33, 33, 1080, 4320, 4320, 33, 33, 4320, 33, 33, 33, 1080, 33, 1080, 4320, 4320, 1080, 1080, 33, 4320, 1080, 4320, 33, 1080, 1080, 33, 33, 1080, 33, 4320, 4320, 33, 4320, 4320, 33, 1080, 4320, 33, 33, 1080, 1080, 33, 33, 4320, 4320, 4320, 4320, 1080, 33, 1080, 1080, 33, 33, 33, 33, 33, 33, 33, 33, 1080, 4320, 1080, 1080, 1080, 4320, 33, 1080, 1080, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 1080, 33, 4320, 4320, 4320, 1080, 33, 4320, 4320, 1080, 1080, 4320, 4320, 33, 4320, 4320, 1080, 33, 4320, 1080, 1080, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 1080, 4320, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 4320, 33, 33, 33, 1080, 33, 1080, 1080, 33, 4320, 1080, 4320, 33, 4320, 33, 1080, 1080, 1080, 1080, 33, 1080, 4320, 4320, 33, 4320, 4320, 33, 4320, 1080, 4320, 1080, 1080, 1080, 33, 1080, 33, 33, 4320, 33, 1080, 33, 33, 1080, 4320, 1080, 4320, 33, 4320, 4320, 1080, 4320, 1080, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 695424 . Total input tokens: 154965070 . Total output tokens: 139036309
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 81.29769857320935,
    "estimated_duration": 3600.107662578859,
    "input_throughput": 6092.237803879725,
    "output_throughput": 5435.596052697591,
    "total_throughput": 11527.833856577317,
    "itl": 150.2129094513066,
    "ttft": 1638251.789371767,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 615,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8388809313648096,
    "arrivals": 231176,
    "finished_requests": 89198,
    "scheduler_time": 166.86600068631512
}
#Debug simulation 
Total elapsed time: 81.2978546670638. Arrivals time: 0.36051874328404665 Scheduler time: 80.79406822612509 Scheduler overhead time: 0.05362242180854082 Adapter cache time: 0.01598368352279067 Engine time: 0.052856049966067076 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_16-16-32/adapters_384_slots_64_rate_0.4-0.1-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_16-16-32/adapters_384_slots_64_rate_0.4-0.1-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 1080, 33, 4320, 4320, 33, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 33, 4320, 33, 4320, 1080, 1080, 1080, 33, 33, 1080, 33, 4320, 33, 4320, 1080, 4320, 1080, 33, 1080, 4320, 1080, 4320, 33, 4320, 4320, 4320, 4320, 33, 1080, 1080, 1080, 4320, 1080, 33, 1080, 33, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 33, 33, 4320, 1080, 1080, 33, 33, 33, 1080, 33, 1080, 33, 4320, 33, 1080, 4320, 33, 4320, 1080, 33, 4320, 4320, 4320, 4320, 1080, 33, 1080, 4320, 4320, 1080, 33, 33, 4320, 1080, 1080, 33, 33, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 33, 1080, 1080, 1080, 1080, 33, 33, 4320, 33, 4320, 33, 33, 33, 1080, 1080, 4320, 33, 33, 4320, 33, 4320, 1080, 33, 4320, 1080, 1080, 33, 4320, 4320, 4320, 33, 1080, 4320, 33, 4320, 1080, 1080, 4320, 4320, 33, 1080, 4320, 33, 1080, 1080, 33, 1080, 33, 1080, 4320, 4320, 1080, 33, 4320, 33, 4320, 1080, 1080, 1080, 1080, 1080, 33, 33, 4320, 33, 4320, 33, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 33, 33, 33, 33, 33, 1080, 33, 33, 1080, 4320, 4320, 33, 33, 4320, 33, 33, 33, 1080, 33, 1080, 4320, 4320, 1080, 1080, 33, 4320, 1080, 4320, 33, 1080, 1080, 33, 33, 1080, 33, 4320, 4320, 33, 4320, 4320, 33, 1080, 4320, 33, 33, 1080, 1080, 33, 33, 4320, 4320, 4320, 4320, 1080, 33, 1080, 1080, 33, 33, 33, 33, 33, 33, 33, 33, 1080, 4320, 1080, 1080, 1080, 4320, 33, 1080, 1080, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 1080, 33, 4320, 4320, 4320, 1080, 33, 4320, 4320, 1080, 1080, 4320, 4320, 33, 4320, 4320, 1080, 33, 4320, 1080, 1080, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 1080, 4320, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 4320, 33, 33, 33, 1080, 33, 1080, 1080, 33, 4320, 1080, 4320, 33, 4320, 33, 1080, 1080, 1080, 1080, 33, 1080, 4320, 4320, 33, 4320, 4320, 33, 4320, 1080, 4320, 1080, 1080, 1080, 33, 1080, 33, 33, 4320, 33, 1080, 33, 33, 1080, 4320, 1080, 4320, 33, 4320, 4320, 1080, 4320, 1080, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 695424 . Total input tokens: 154965070 . Total output tokens: 139036309
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 83.48682208871469,
    "estimated_duration": 3600.1699157341245,
    "input_throughput": 6103.631082512164,
    "output_throughput": 5443.550570863475,
    "total_throughput": 11547.181653375637,
    "itl": 150.398113955357,
    "ttft": 1633345.7610336957,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 619,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.08117671307176,
    "arrivals": 231176,
    "finished_requests": 89311,
    "scheduler_time": 166.5573408630264
}
#Debug simulation 
Total elapsed time: 83.48697038274258. Arrivals time: 0.36591648450121284 Scheduler time: 82.97601988399401 Scheduler overhead time: 0.05410371161997318 Adapter cache time: 0.016460103914141655 Engine time: 0.05413791723549366 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-8/adapters_384_slots_64_rate_0.4-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-8/adapters_384_slots_64_rate_0.4-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 4320, 540, 270, 4320, 4320, 270, 540, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 270, 4320, 270, 4320, 540, 540, 540, 270, 270, 540, 270, 4320, 270, 4320, 540, 4320, 540, 270, 540, 4320, 540, 4320, 270, 4320, 4320, 4320, 4320, 270, 540, 540, 540, 4320, 540, 270, 540, 270, 4320, 540, 4320, 4320, 540, 4320, 4320, 270, 270, 4320, 540, 540, 270, 270, 270, 540, 270, 540, 270, 4320, 270, 540, 4320, 270, 4320, 540, 270, 4320, 4320, 4320, 4320, 540, 270, 540, 4320, 4320, 540, 270, 270, 4320, 540, 540, 270, 270, 4320, 540, 4320, 540, 4320, 4320, 540, 4320, 4320, 270, 540, 540, 540, 540, 270, 270, 4320, 270, 4320, 270, 270, 270, 540, 540, 4320, 270, 270, 4320, 270, 4320, 540, 270, 4320, 540, 540, 270, 4320, 4320, 4320, 270, 540, 4320, 270, 4320, 540, 540, 4320, 4320, 270, 540, 4320, 270, 540, 540, 270, 540, 270, 540, 4320, 4320, 540, 270, 4320, 270, 4320, 540, 540, 540, 540, 540, 270, 270, 4320, 270, 4320, 270, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 270, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 270, 270, 270, 270, 270, 540, 270, 270, 540, 4320, 4320, 270, 270, 4320, 270, 270, 270, 540, 270, 540, 4320, 4320, 540, 540, 270, 4320, 540, 4320, 270, 540, 540, 270, 270, 540, 270, 4320, 4320, 270, 4320, 4320, 270, 540, 4320, 270, 270, 540, 540, 270, 270, 4320, 4320, 4320, 4320, 540, 270, 540, 540, 270, 270, 270, 270, 270, 270, 270, 270, 540, 4320, 540, 540, 540, 4320, 270, 540, 540, 4320, 4320, 270, 4320, 4320, 270, 4320, 270, 270, 540, 270, 4320, 4320, 4320, 540, 270, 4320, 4320, 540, 540, 4320, 4320, 270, 4320, 4320, 540, 270, 4320, 540, 540, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 270, 4320, 270, 540, 4320, 270, 540, 540, 540, 540, 270, 540, 270, 540, 540, 270, 4320, 270, 270, 270, 540, 270, 540, 540, 270, 4320, 540, 4320, 270, 4320, 270, 540, 540, 540, 540, 270, 540, 4320, 4320, 270, 4320, 4320, 270, 4320, 540, 4320, 540, 540, 540, 270, 540, 270, 270, 4320, 270, 540, 270, 270, 540, 4320, 540, 4320, 270, 4320, 4320, 540, 4320, 540, 270, 4320, 270, 4320, 4320, 270, 270, 270]
Prompts retrieved: 656640 . Total input tokens: 146385497 . Total output tokens: 131206172
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 80.3920984622091,
    "estimated_duration": 3600.1722337386573,
    "input_throughput": 6177.189466545495,
    "output_throughput": 5433.614485628533,
    "total_throughput": 11610.803952174028,
    "itl": 149.42311987477456,
    "ttft": 1603463.7767043377,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 567,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7352965508098956,
    "arrivals": 218283,
    "finished_requests": 89579,
    "scheduler_time": 167.06553508887058
}
#Debug simulation 
Total elapsed time: 80.39225968997926. Arrivals time: 0.38732947781682014 Scheduler time: 79.85910980775952 Scheduler overhead time: 0.05451647564768791 Adapter cache time: 0.016172192059457302 Engine time: 0.05422814702615142 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-16/adapters_384_slots_64_rate_0.4-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-16/adapters_384_slots_64_rate_0.4-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 4320, 540, 270, 4320, 4320, 270, 540, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 270, 4320, 270, 4320, 540, 540, 540, 270, 270, 540, 270, 4320, 270, 4320, 540, 4320, 540, 270, 540, 4320, 540, 4320, 270, 4320, 4320, 4320, 4320, 270, 540, 540, 540, 4320, 540, 270, 540, 270, 4320, 540, 4320, 4320, 540, 4320, 4320, 270, 270, 4320, 540, 540, 270, 270, 270, 540, 270, 540, 270, 4320, 270, 540, 4320, 270, 4320, 540, 270, 4320, 4320, 4320, 4320, 540, 270, 540, 4320, 4320, 540, 270, 270, 4320, 540, 540, 270, 270, 4320, 540, 4320, 540, 4320, 4320, 540, 4320, 4320, 270, 540, 540, 540, 540, 270, 270, 4320, 270, 4320, 270, 270, 270, 540, 540, 4320, 270, 270, 4320, 270, 4320, 540, 270, 4320, 540, 540, 270, 4320, 4320, 4320, 270, 540, 4320, 270, 4320, 540, 540, 4320, 4320, 270, 540, 4320, 270, 540, 540, 270, 540, 270, 540, 4320, 4320, 540, 270, 4320, 270, 4320, 540, 540, 540, 540, 540, 270, 270, 4320, 270, 4320, 270, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 270, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 270, 270, 270, 270, 270, 540, 270, 270, 540, 4320, 4320, 270, 270, 4320, 270, 270, 270, 540, 270, 540, 4320, 4320, 540, 540, 270, 4320, 540, 4320, 270, 540, 540, 270, 270, 540, 270, 4320, 4320, 270, 4320, 4320, 270, 540, 4320, 270, 270, 540, 540, 270, 270, 4320, 4320, 4320, 4320, 540, 270, 540, 540, 270, 270, 270, 270, 270, 270, 270, 270, 540, 4320, 540, 540, 540, 4320, 270, 540, 540, 4320, 4320, 270, 4320, 4320, 270, 4320, 270, 270, 540, 270, 4320, 4320, 4320, 540, 270, 4320, 4320, 540, 540, 4320, 4320, 270, 4320, 4320, 540, 270, 4320, 540, 540, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 270, 4320, 270, 540, 4320, 270, 540, 540, 540, 540, 270, 540, 270, 540, 540, 270, 4320, 270, 270, 270, 540, 270, 540, 540, 270, 4320, 540, 4320, 270, 4320, 270, 540, 540, 540, 540, 270, 540, 4320, 4320, 270, 4320, 4320, 270, 4320, 540, 4320, 540, 540, 540, 270, 540, 270, 270, 4320, 270, 540, 270, 270, 540, 4320, 540, 4320, 270, 4320, 4320, 540, 4320, 540, 270, 4320, 270, 4320, 4320, 270, 270, 270]
Prompts retrieved: 656640 . Total input tokens: 146385497 . Total output tokens: 131206172
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 81.66453220276162,
    "estimated_duration": 3600.00994060206,
    "input_throughput": 6166.496305920588,
    "output_throughput": 5430.190005733901,
    "total_throughput": 11596.68631165449,
    "itl": 149.25347596957397,
    "ttft": 1602529.9529242031,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 573,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8697908259416047,
    "arrivals": 218283,
    "finished_requests": 89486,
    "scheduler_time": 167.17645716177756
}
#Debug simulation 
Total elapsed time: 81.66469714278355. Arrivals time: 0.38127994211390615 Scheduler time: 81.13393146684393 Scheduler overhead time: 0.05596465989947319 Adapter cache time: 0.01684589171782136 Engine time: 0.0559024759568274 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-32/adapters_384_slots_64_rate_0.4-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-32/adapters_384_slots_64_rate_0.4-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 4320, 540, 270, 4320, 4320, 270, 540, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 270, 4320, 270, 4320, 540, 540, 540, 270, 270, 540, 270, 4320, 270, 4320, 540, 4320, 540, 270, 540, 4320, 540, 4320, 270, 4320, 4320, 4320, 4320, 270, 540, 540, 540, 4320, 540, 270, 540, 270, 4320, 540, 4320, 4320, 540, 4320, 4320, 270, 270, 4320, 540, 540, 270, 270, 270, 540, 270, 540, 270, 4320, 270, 540, 4320, 270, 4320, 540, 270, 4320, 4320, 4320, 4320, 540, 270, 540, 4320, 4320, 540, 270, 270, 4320, 540, 540, 270, 270, 4320, 540, 4320, 540, 4320, 4320, 540, 4320, 4320, 270, 540, 540, 540, 540, 270, 270, 4320, 270, 4320, 270, 270, 270, 540, 540, 4320, 270, 270, 4320, 270, 4320, 540, 270, 4320, 540, 540, 270, 4320, 4320, 4320, 270, 540, 4320, 270, 4320, 540, 540, 4320, 4320, 270, 540, 4320, 270, 540, 540, 270, 540, 270, 540, 4320, 4320, 540, 270, 4320, 270, 4320, 540, 540, 540, 540, 540, 270, 270, 4320, 270, 4320, 270, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 270, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 270, 270, 270, 270, 270, 540, 270, 270, 540, 4320, 4320, 270, 270, 4320, 270, 270, 270, 540, 270, 540, 4320, 4320, 540, 540, 270, 4320, 540, 4320, 270, 540, 540, 270, 270, 540, 270, 4320, 4320, 270, 4320, 4320, 270, 540, 4320, 270, 270, 540, 540, 270, 270, 4320, 4320, 4320, 4320, 540, 270, 540, 540, 270, 270, 270, 270, 270, 270, 270, 270, 540, 4320, 540, 540, 540, 4320, 270, 540, 540, 4320, 4320, 270, 4320, 4320, 270, 4320, 270, 270, 540, 270, 4320, 4320, 4320, 540, 270, 4320, 4320, 540, 540, 4320, 4320, 270, 4320, 4320, 540, 270, 4320, 540, 540, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 270, 4320, 270, 540, 4320, 270, 540, 540, 540, 540, 270, 540, 270, 540, 540, 270, 4320, 270, 270, 270, 540, 270, 540, 540, 270, 4320, 540, 4320, 270, 4320, 270, 540, 540, 540, 540, 270, 540, 4320, 4320, 270, 4320, 4320, 270, 4320, 540, 4320, 540, 540, 540, 270, 540, 270, 270, 4320, 270, 540, 270, 270, 540, 4320, 540, 4320, 270, 4320, 4320, 540, 4320, 540, 270, 4320, 270, 4320, 4320, 270, 270, 270]
Prompts retrieved: 656640 . Total input tokens: 146385497 . Total output tokens: 131206172
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 81.85575809143484,
    "estimated_duration": 3600.0132681126047,
    "input_throughput": 6166.4906061967395,
    "output_throughput": 5430.184986581704,
    "total_throughput": 11596.675592778443,
    "itl": 149.2535913390077,
    "ttft": 1602531.2475638739,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 573,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8731020907499012,
    "arrivals": 218283,
    "finished_requests": 89486,
    "scheduler_time": 167.17647340748036
}
#Debug simulation 
Total elapsed time: 81.85591620206833. Arrivals time: 0.37636093655601144 Scheduler time: 81.32978408690542 Scheduler overhead time: 0.05569107411429286 Adapter cache time: 0.0169969005510211 Engine time: 0.05572208343073726 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-16-16/adapters_384_slots_64_rate_0.4-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-16-16/adapters_384_slots_64_rate_0.4-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 4320, 540, 270, 4320, 4320, 270, 540, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 270, 4320, 270, 4320, 540, 540, 540, 270, 270, 540, 270, 4320, 270, 4320, 540, 4320, 540, 270, 540, 4320, 540, 4320, 270, 4320, 4320, 4320, 4320, 270, 540, 540, 540, 4320, 540, 270, 540, 270, 4320, 540, 4320, 4320, 540, 4320, 4320, 270, 270, 4320, 540, 540, 270, 270, 270, 540, 270, 540, 270, 4320, 270, 540, 4320, 270, 4320, 540, 270, 4320, 4320, 4320, 4320, 540, 270, 540, 4320, 4320, 540, 270, 270, 4320, 540, 540, 270, 270, 4320, 540, 4320, 540, 4320, 4320, 540, 4320, 4320, 270, 540, 540, 540, 540, 270, 270, 4320, 270, 4320, 270, 270, 270, 540, 540, 4320, 270, 270, 4320, 270, 4320, 540, 270, 4320, 540, 540, 270, 4320, 4320, 4320, 270, 540, 4320, 270, 4320, 540, 540, 4320, 4320, 270, 540, 4320, 270, 540, 540, 270, 540, 270, 540, 4320, 4320, 540, 270, 4320, 270, 4320, 540, 540, 540, 540, 540, 270, 270, 4320, 270, 4320, 270, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 270, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 270, 270, 270, 270, 270, 540, 270, 270, 540, 4320, 4320, 270, 270, 4320, 270, 270, 270, 540, 270, 540, 4320, 4320, 540, 540, 270, 4320, 540, 4320, 270, 540, 540, 270, 270, 540, 270, 4320, 4320, 270, 4320, 4320, 270, 540, 4320, 270, 270, 540, 540, 270, 270, 4320, 4320, 4320, 4320, 540, 270, 540, 540, 270, 270, 270, 270, 270, 270, 270, 270, 540, 4320, 540, 540, 540, 4320, 270, 540, 540, 4320, 4320, 270, 4320, 4320, 270, 4320, 270, 270, 540, 270, 4320, 4320, 4320, 540, 270, 4320, 4320, 540, 540, 4320, 4320, 270, 4320, 4320, 540, 270, 4320, 540, 540, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 270, 4320, 270, 540, 4320, 270, 540, 540, 540, 540, 270, 540, 270, 540, 540, 270, 4320, 270, 270, 270, 540, 270, 540, 540, 270, 4320, 540, 4320, 270, 4320, 270, 540, 540, 540, 540, 270, 540, 4320, 4320, 270, 4320, 4320, 270, 4320, 540, 4320, 540, 540, 540, 270, 540, 270, 270, 4320, 270, 540, 270, 270, 540, 4320, 540, 4320, 270, 4320, 4320, 540, 4320, 540, 270, 4320, 270, 4320, 4320, 270, 270, 270]
Prompts retrieved: 656640 . Total input tokens: 146385497 . Total output tokens: 131206172
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 80.57817091792822,
    "estimated_duration": 3600.0985412057316,
    "input_throughput": 6176.932032686049,
    "output_throughput": 5435.653156717777,
    "total_throughput": 11612.585189403826,
    "itl": 149.4860250198308,
    "ttft": 1604168.2319783673,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 571,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7878119961218806,
    "arrivals": 218283,
    "finished_requests": 89567,
    "scheduler_time": 167.04944258116484
}
#Debug simulation 
Total elapsed time: 80.57832687487826. Arrivals time: 0.37046545511111617 Scheduler time: 80.06052885577083 Scheduler overhead time: 0.05483009805902839 Adapter cache time: 0.016596709843724966 Engine time: 0.055269470904022455 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-16-32/adapters_384_slots_64_rate_0.4-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-16-32/adapters_384_slots_64_rate_0.4-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 4320, 540, 270, 4320, 4320, 270, 540, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 270, 4320, 270, 4320, 540, 540, 540, 270, 270, 540, 270, 4320, 270, 4320, 540, 4320, 540, 270, 540, 4320, 540, 4320, 270, 4320, 4320, 4320, 4320, 270, 540, 540, 540, 4320, 540, 270, 540, 270, 4320, 540, 4320, 4320, 540, 4320, 4320, 270, 270, 4320, 540, 540, 270, 270, 270, 540, 270, 540, 270, 4320, 270, 540, 4320, 270, 4320, 540, 270, 4320, 4320, 4320, 4320, 540, 270, 540, 4320, 4320, 540, 270, 270, 4320, 540, 540, 270, 270, 4320, 540, 4320, 540, 4320, 4320, 540, 4320, 4320, 270, 540, 540, 540, 540, 270, 270, 4320, 270, 4320, 270, 270, 270, 540, 540, 4320, 270, 270, 4320, 270, 4320, 540, 270, 4320, 540, 540, 270, 4320, 4320, 4320, 270, 540, 4320, 270, 4320, 540, 540, 4320, 4320, 270, 540, 4320, 270, 540, 540, 270, 540, 270, 540, 4320, 4320, 540, 270, 4320, 270, 4320, 540, 540, 540, 540, 540, 270, 270, 4320, 270, 4320, 270, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 270, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 270, 270, 270, 270, 270, 540, 270, 270, 540, 4320, 4320, 270, 270, 4320, 270, 270, 270, 540, 270, 540, 4320, 4320, 540, 540, 270, 4320, 540, 4320, 270, 540, 540, 270, 270, 540, 270, 4320, 4320, 270, 4320, 4320, 270, 540, 4320, 270, 270, 540, 540, 270, 270, 4320, 4320, 4320, 4320, 540, 270, 540, 540, 270, 270, 270, 270, 270, 270, 270, 270, 540, 4320, 540, 540, 540, 4320, 270, 540, 540, 4320, 4320, 270, 4320, 4320, 270, 4320, 270, 270, 540, 270, 4320, 4320, 4320, 540, 270, 4320, 4320, 540, 540, 4320, 4320, 270, 4320, 4320, 540, 270, 4320, 540, 540, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 270, 4320, 270, 540, 4320, 270, 540, 540, 540, 540, 270, 540, 270, 540, 540, 270, 4320, 270, 270, 270, 540, 270, 540, 540, 270, 4320, 540, 4320, 270, 4320, 270, 540, 540, 540, 540, 270, 540, 4320, 4320, 270, 4320, 4320, 270, 4320, 540, 4320, 540, 540, 540, 270, 540, 270, 270, 4320, 270, 540, 270, 270, 540, 4320, 540, 4320, 270, 4320, 4320, 540, 4320, 540, 270, 4320, 270, 4320, 4320, 270, 270, 270]
Prompts retrieved: 656640 . Total input tokens: 146385497 . Total output tokens: 131206172
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 81.84592019300908,
    "estimated_duration": 3600.040802200544,
    "input_throughput": 6166.443443204997,
    "output_throughput": 5430.143455054935,
    "total_throughput": 11596.586898259931,
    "itl": 149.25389155345158,
    "ttft": 1602543.132567287,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 573,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8964922950230578,
    "arrivals": 218283,
    "finished_requests": 89486,
    "scheduler_time": 167.17731423840888
}
#Debug simulation 
Total elapsed time: 81.84606053680182. Arrivals time: 0.3769385004416108 Scheduler time: 81.31962411850691 Scheduler overhead time: 0.056146848015487194 Adapter cache time: 0.016871129628270864 Engine time: 0.05505042849108577 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_16-16-16/adapters_384_slots_64_rate_0.4-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_16-16-16/adapters_384_slots_64_rate_0.4-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 4320, 540, 270, 4320, 4320, 270, 540, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 270, 4320, 270, 4320, 540, 540, 540, 270, 270, 540, 270, 4320, 270, 4320, 540, 4320, 540, 270, 540, 4320, 540, 4320, 270, 4320, 4320, 4320, 4320, 270, 540, 540, 540, 4320, 540, 270, 540, 270, 4320, 540, 4320, 4320, 540, 4320, 4320, 270, 270, 4320, 540, 540, 270, 270, 270, 540, 270, 540, 270, 4320, 270, 540, 4320, 270, 4320, 540, 270, 4320, 4320, 4320, 4320, 540, 270, 540, 4320, 4320, 540, 270, 270, 4320, 540, 540, 270, 270, 4320, 540, 4320, 540, 4320, 4320, 540, 4320, 4320, 270, 540, 540, 540, 540, 270, 270, 4320, 270, 4320, 270, 270, 270, 540, 540, 4320, 270, 270, 4320, 270, 4320, 540, 270, 4320, 540, 540, 270, 4320, 4320, 4320, 270, 540, 4320, 270, 4320, 540, 540, 4320, 4320, 270, 540, 4320, 270, 540, 540, 270, 540, 270, 540, 4320, 4320, 540, 270, 4320, 270, 4320, 540, 540, 540, 540, 540, 270, 270, 4320, 270, 4320, 270, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 270, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 270, 270, 270, 270, 270, 540, 270, 270, 540, 4320, 4320, 270, 270, 4320, 270, 270, 270, 540, 270, 540, 4320, 4320, 540, 540, 270, 4320, 540, 4320, 270, 540, 540, 270, 270, 540, 270, 4320, 4320, 270, 4320, 4320, 270, 540, 4320, 270, 270, 540, 540, 270, 270, 4320, 4320, 4320, 4320, 540, 270, 540, 540, 270, 270, 270, 270, 270, 270, 270, 270, 540, 4320, 540, 540, 540, 4320, 270, 540, 540, 4320, 4320, 270, 4320, 4320, 270, 4320, 270, 270, 540, 270, 4320, 4320, 4320, 540, 270, 4320, 4320, 540, 540, 4320, 4320, 270, 4320, 4320, 540, 270, 4320, 540, 540, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 270, 4320, 270, 540, 4320, 270, 540, 540, 540, 540, 270, 540, 270, 540, 540, 270, 4320, 270, 270, 270, 540, 270, 540, 540, 270, 4320, 540, 4320, 270, 4320, 270, 540, 540, 540, 540, 270, 540, 4320, 4320, 270, 4320, 4320, 270, 4320, 540, 4320, 540, 540, 540, 270, 540, 270, 270, 4320, 270, 540, 270, 270, 540, 4320, 540, 4320, 270, 4320, 4320, 540, 4320, 540, 270, 4320, 270, 4320, 4320, 270, 270, 270]
Prompts retrieved: 656640 . Total input tokens: 146385497 . Total output tokens: 131206172
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 80.96667729783803,
    "estimated_duration": 3600.0468155904805,
    "input_throughput": 6179.098533848195,
    "output_throughput": 5438.6103856231675,
    "total_throughput": 11617.708919471363,
    "itl": 149.5988867721523,
    "ttft": 1602377.832284899,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 579,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.731239120748335,
    "arrivals": 218283,
    "finished_requests": 89672,
    "scheduler_time": 166.90739088496105
}
#Debug simulation 
Total elapsed time: 80.96681462880224. Arrivals time: 0.38063716795295477 Scheduler time: 80.4361625071615 Scheduler overhead time: 0.05637820018455386 Adapter cache time: 0.017006754875183105 Engine time: 0.05547226266935468 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_16-16-32/adapters_384_slots_64_rate_0.4-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_16-16-32/adapters_384_slots_64_rate_0.4-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 4320, 540, 270, 4320, 4320, 270, 540, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 270, 4320, 270, 4320, 540, 540, 540, 270, 270, 540, 270, 4320, 270, 4320, 540, 4320, 540, 270, 540, 4320, 540, 4320, 270, 4320, 4320, 4320, 4320, 270, 540, 540, 540, 4320, 540, 270, 540, 270, 4320, 540, 4320, 4320, 540, 4320, 4320, 270, 270, 4320, 540, 540, 270, 270, 270, 540, 270, 540, 270, 4320, 270, 540, 4320, 270, 4320, 540, 270, 4320, 4320, 4320, 4320, 540, 270, 540, 4320, 4320, 540, 270, 270, 4320, 540, 540, 270, 270, 4320, 540, 4320, 540, 4320, 4320, 540, 4320, 4320, 270, 540, 540, 540, 540, 270, 270, 4320, 270, 4320, 270, 270, 270, 540, 540, 4320, 270, 270, 4320, 270, 4320, 540, 270, 4320, 540, 540, 270, 4320, 4320, 4320, 270, 540, 4320, 270, 4320, 540, 540, 4320, 4320, 270, 540, 4320, 270, 540, 540, 270, 540, 270, 540, 4320, 4320, 540, 270, 4320, 270, 4320, 540, 540, 540, 540, 540, 270, 270, 4320, 270, 4320, 270, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 270, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 270, 270, 270, 270, 270, 540, 270, 270, 540, 4320, 4320, 270, 270, 4320, 270, 270, 270, 540, 270, 540, 4320, 4320, 540, 540, 270, 4320, 540, 4320, 270, 540, 540, 270, 270, 540, 270, 4320, 4320, 270, 4320, 4320, 270, 540, 4320, 270, 270, 540, 540, 270, 270, 4320, 4320, 4320, 4320, 540, 270, 540, 540, 270, 270, 270, 270, 270, 270, 270, 270, 540, 4320, 540, 540, 540, 4320, 270, 540, 540, 4320, 4320, 270, 4320, 4320, 270, 4320, 270, 270, 540, 270, 4320, 4320, 4320, 540, 270, 4320, 4320, 540, 540, 4320, 4320, 270, 4320, 4320, 540, 270, 4320, 540, 540, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 270, 4320, 270, 540, 4320, 270, 540, 540, 540, 540, 270, 540, 270, 540, 540, 270, 4320, 270, 270, 270, 540, 270, 540, 540, 270, 4320, 540, 4320, 270, 4320, 270, 540, 540, 540, 540, 270, 540, 4320, 4320, 270, 4320, 4320, 270, 4320, 540, 4320, 540, 540, 540, 270, 540, 270, 270, 4320, 270, 540, 270, 270, 540, 4320, 540, 4320, 270, 4320, 4320, 540, 4320, 540, 270, 4320, 270, 4320, 4320, 270, 270, 270]
Prompts retrieved: 656640 . Total input tokens: 146385497 . Total output tokens: 131206172
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 82.31150934891775,
    "estimated_duration": 3600.138082994759,
    "input_throughput": 6167.097341313928,
    "output_throughput": 5430.898912559423,
    "total_throughput": 11597.99625387335,
    "itl": 149.2525059854904,
    "ttft": 1602304.3678027457,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 573,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9208027896657547,
    "arrivals": 218283,
    "finished_requests": 89494,
    "scheduler_time": 167.16305609647543
}
#Debug simulation 
Total elapsed time: 82.31165449414402. Arrivals time: 0.3926021228544414 Scheduler time: 81.77038223296404 Scheduler overhead time: 0.05587147921323776 Adapter cache time: 0.016849287319928408 Engine time: 0.05448249960318208 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-8/adapters_384_slots_64_rate_0.4-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-8/adapters_384_slots_64_rate_0.4-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 4320, 540, 135, 4320, 4320, 135, 540, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 135, 4320, 135, 4320, 540, 540, 540, 135, 135, 540, 135, 4320, 135, 4320, 540, 4320, 540, 135, 540, 4320, 540, 4320, 135, 4320, 4320, 4320, 4320, 135, 540, 540, 540, 4320, 540, 135, 540, 135, 4320, 540, 4320, 4320, 540, 4320, 4320, 135, 135, 4320, 540, 540, 135, 135, 135, 540, 135, 540, 135, 4320, 135, 540, 4320, 135, 4320, 540, 135, 4320, 4320, 4320, 4320, 540, 135, 540, 4320, 4320, 540, 135, 135, 4320, 540, 540, 135, 135, 4320, 540, 4320, 540, 4320, 4320, 540, 4320, 4320, 135, 540, 540, 540, 540, 135, 135, 4320, 135, 4320, 135, 135, 135, 540, 540, 4320, 135, 135, 4320, 135, 4320, 540, 135, 4320, 540, 540, 135, 4320, 4320, 4320, 135, 540, 4320, 135, 4320, 540, 540, 4320, 4320, 135, 540, 4320, 135, 540, 540, 135, 540, 135, 540, 4320, 4320, 540, 135, 4320, 135, 4320, 540, 540, 540, 540, 540, 135, 135, 4320, 135, 4320, 135, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 135, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 135, 135, 135, 135, 135, 540, 135, 135, 540, 4320, 4320, 135, 135, 4320, 135, 135, 135, 540, 135, 540, 4320, 4320, 540, 540, 135, 4320, 540, 4320, 135, 540, 540, 135, 135, 540, 135, 4320, 4320, 135, 4320, 4320, 135, 540, 4320, 135, 135, 540, 540, 135, 135, 4320, 4320, 4320, 4320, 540, 135, 540, 540, 135, 135, 135, 135, 135, 135, 135, 135, 540, 4320, 540, 540, 540, 4320, 135, 540, 540, 4320, 4320, 135, 4320, 4320, 135, 4320, 135, 135, 540, 135, 4320, 4320, 4320, 540, 135, 4320, 4320, 540, 540, 4320, 4320, 135, 4320, 4320, 540, 135, 4320, 540, 540, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 4320, 135, 540, 4320, 135, 540, 540, 540, 540, 135, 540, 135, 540, 540, 135, 4320, 135, 135, 135, 540, 135, 540, 540, 135, 4320, 540, 4320, 135, 4320, 135, 540, 540, 540, 540, 135, 540, 4320, 4320, 135, 4320, 4320, 135, 4320, 540, 4320, 540, 540, 540, 135, 540, 135, 135, 4320, 135, 540, 135, 135, 540, 4320, 540, 4320, 135, 4320, 4320, 540, 4320, 540, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 639360 . Total input tokens: 142592364 . Total output tokens: 127777710
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 78.10960519080982,
    "estimated_duration": 3600.141892411395,
    "input_throughput": 6081.34252879002,
    "output_throughput": 5399.022477689296,
    "total_throughput": 11480.365006479315,
    "itl": 146.93952942083453,
    "ttft": 1605197.8977924136,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 536,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.640421430747977,
    "arrivals": 212473,
    "finished_requests": 88463,
    "scheduler_time": 168.70786948437132
}
#Debug simulation 
Total elapsed time: 78.10974860796705. Arrivals time: 0.3895212155766785 Scheduler time: 77.57304086815566 Scheduler overhead time: 0.05506609007716179 Adapter cache time: 0.016830422449856997 Engine time: 0.054269767832010984 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-16/adapters_384_slots_64_rate_0.4-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-16/adapters_384_slots_64_rate_0.4-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 4320, 540, 135, 4320, 4320, 135, 540, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 135, 4320, 135, 4320, 540, 540, 540, 135, 135, 540, 135, 4320, 135, 4320, 540, 4320, 540, 135, 540, 4320, 540, 4320, 135, 4320, 4320, 4320, 4320, 135, 540, 540, 540, 4320, 540, 135, 540, 135, 4320, 540, 4320, 4320, 540, 4320, 4320, 135, 135, 4320, 540, 540, 135, 135, 135, 540, 135, 540, 135, 4320, 135, 540, 4320, 135, 4320, 540, 135, 4320, 4320, 4320, 4320, 540, 135, 540, 4320, 4320, 540, 135, 135, 4320, 540, 540, 135, 135, 4320, 540, 4320, 540, 4320, 4320, 540, 4320, 4320, 135, 540, 540, 540, 540, 135, 135, 4320, 135, 4320, 135, 135, 135, 540, 540, 4320, 135, 135, 4320, 135, 4320, 540, 135, 4320, 540, 540, 135, 4320, 4320, 4320, 135, 540, 4320, 135, 4320, 540, 540, 4320, 4320, 135, 540, 4320, 135, 540, 540, 135, 540, 135, 540, 4320, 4320, 540, 135, 4320, 135, 4320, 540, 540, 540, 540, 540, 135, 135, 4320, 135, 4320, 135, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 135, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 135, 135, 135, 135, 135, 540, 135, 135, 540, 4320, 4320, 135, 135, 4320, 135, 135, 135, 540, 135, 540, 4320, 4320, 540, 540, 135, 4320, 540, 4320, 135, 540, 540, 135, 135, 540, 135, 4320, 4320, 135, 4320, 4320, 135, 540, 4320, 135, 135, 540, 540, 135, 135, 4320, 4320, 4320, 4320, 540, 135, 540, 540, 135, 135, 135, 135, 135, 135, 135, 135, 540, 4320, 540, 540, 540, 4320, 135, 540, 540, 4320, 4320, 135, 4320, 4320, 135, 4320, 135, 135, 540, 135, 4320, 4320, 4320, 540, 135, 4320, 4320, 540, 540, 4320, 4320, 135, 4320, 4320, 540, 135, 4320, 540, 540, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 4320, 135, 540, 4320, 135, 540, 540, 540, 540, 135, 540, 135, 540, 540, 135, 4320, 135, 135, 135, 540, 135, 540, 540, 135, 4320, 540, 4320, 135, 4320, 135, 540, 540, 540, 540, 135, 540, 4320, 4320, 135, 4320, 4320, 135, 4320, 540, 4320, 540, 540, 540, 135, 540, 135, 135, 4320, 135, 540, 135, 135, 540, 4320, 540, 4320, 135, 4320, 4320, 540, 4320, 540, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 639360 . Total input tokens: 142592364 . Total output tokens: 127777710
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 76.84170226799324,
    "estimated_duration": 3600.0933287471444,
    "input_throughput": 6087.2071912720085,
    "output_throughput": 5407.788971619571,
    "total_throughput": 11494.99616289158,
    "itl": 147.50753754894123,
    "ttft": 1604806.070115449,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 519,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6928014879161546,
    "arrivals": 212473,
    "finished_requests": 88556,
    "scheduler_time": 168.2015837147513
}
#Debug simulation 
Total elapsed time: 76.84184886654839. Arrivals time: 0.39702544873580337 Scheduler time: 76.29782053967938 Scheduler overhead time: 0.05554777942597866 Adapter cache time: 0.01615291927009821 Engine time: 0.053995887748897076 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-32/adapters_384_slots_64_rate_0.4-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-32/adapters_384_slots_64_rate_0.4-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 4320, 540, 135, 4320, 4320, 135, 540, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 135, 4320, 135, 4320, 540, 540, 540, 135, 135, 540, 135, 4320, 135, 4320, 540, 4320, 540, 135, 540, 4320, 540, 4320, 135, 4320, 4320, 4320, 4320, 135, 540, 540, 540, 4320, 540, 135, 540, 135, 4320, 540, 4320, 4320, 540, 4320, 4320, 135, 135, 4320, 540, 540, 135, 135, 135, 540, 135, 540, 135, 4320, 135, 540, 4320, 135, 4320, 540, 135, 4320, 4320, 4320, 4320, 540, 135, 540, 4320, 4320, 540, 135, 135, 4320, 540, 540, 135, 135, 4320, 540, 4320, 540, 4320, 4320, 540, 4320, 4320, 135, 540, 540, 540, 540, 135, 135, 4320, 135, 4320, 135, 135, 135, 540, 540, 4320, 135, 135, 4320, 135, 4320, 540, 135, 4320, 540, 540, 135, 4320, 4320, 4320, 135, 540, 4320, 135, 4320, 540, 540, 4320, 4320, 135, 540, 4320, 135, 540, 540, 135, 540, 135, 540, 4320, 4320, 540, 135, 4320, 135, 4320, 540, 540, 540, 540, 540, 135, 135, 4320, 135, 4320, 135, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 135, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 135, 135, 135, 135, 135, 540, 135, 135, 540, 4320, 4320, 135, 135, 4320, 135, 135, 135, 540, 135, 540, 4320, 4320, 540, 540, 135, 4320, 540, 4320, 135, 540, 540, 135, 135, 540, 135, 4320, 4320, 135, 4320, 4320, 135, 540, 4320, 135, 135, 540, 540, 135, 135, 4320, 4320, 4320, 4320, 540, 135, 540, 540, 135, 135, 135, 135, 135, 135, 135, 135, 540, 4320, 540, 540, 540, 4320, 135, 540, 540, 4320, 4320, 135, 4320, 4320, 135, 4320, 135, 135, 540, 135, 4320, 4320, 4320, 540, 135, 4320, 4320, 540, 540, 4320, 4320, 135, 4320, 4320, 540, 135, 4320, 540, 540, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 4320, 135, 540, 4320, 135, 540, 540, 540, 540, 135, 540, 135, 540, 540, 135, 4320, 135, 135, 135, 540, 135, 540, 540, 135, 4320, 540, 4320, 135, 4320, 135, 540, 540, 540, 540, 135, 540, 4320, 4320, 135, 4320, 4320, 135, 4320, 540, 4320, 540, 540, 540, 135, 540, 135, 135, 4320, 135, 540, 135, 135, 540, 4320, 540, 4320, 135, 4320, 4320, 540, 4320, 540, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 639360 . Total input tokens: 142592364 . Total output tokens: 127777710
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 77.02599675580859,
    "estimated_duration": 3600.097046036663,
    "input_throughput": 6087.200905910475,
    "output_throughput": 5407.783387793079,
    "total_throughput": 11494.984293703554,
    "itl": 147.50737419597587,
    "ttft": 1604807.5849099373,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 519,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6959366681240602,
    "arrivals": 212473,
    "finished_requests": 88556,
    "scheduler_time": 168.2016677393379
}
#Debug simulation 
Total elapsed time: 77.02613755688071. Arrivals time: 0.3740728427655995 Scheduler time: 76.50437194807455 Scheduler overhead time: 0.055759500712156296 Adapter cache time: 0.016510289162397385 Engine time: 0.054453165270388126 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-16/adapters_384_slots_64_rate_0.4-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-16/adapters_384_slots_64_rate_0.4-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 4320, 540, 135, 4320, 4320, 135, 540, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 135, 4320, 135, 4320, 540, 540, 540, 135, 135, 540, 135, 4320, 135, 4320, 540, 4320, 540, 135, 540, 4320, 540, 4320, 135, 4320, 4320, 4320, 4320, 135, 540, 540, 540, 4320, 540, 135, 540, 135, 4320, 540, 4320, 4320, 540, 4320, 4320, 135, 135, 4320, 540, 540, 135, 135, 135, 540, 135, 540, 135, 4320, 135, 540, 4320, 135, 4320, 540, 135, 4320, 4320, 4320, 4320, 540, 135, 540, 4320, 4320, 540, 135, 135, 4320, 540, 540, 135, 135, 4320, 540, 4320, 540, 4320, 4320, 540, 4320, 4320, 135, 540, 540, 540, 540, 135, 135, 4320, 135, 4320, 135, 135, 135, 540, 540, 4320, 135, 135, 4320, 135, 4320, 540, 135, 4320, 540, 540, 135, 4320, 4320, 4320, 135, 540, 4320, 135, 4320, 540, 540, 4320, 4320, 135, 540, 4320, 135, 540, 540, 135, 540, 135, 540, 4320, 4320, 540, 135, 4320, 135, 4320, 540, 540, 540, 540, 540, 135, 135, 4320, 135, 4320, 135, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 135, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 135, 135, 135, 135, 135, 540, 135, 135, 540, 4320, 4320, 135, 135, 4320, 135, 135, 135, 540, 135, 540, 4320, 4320, 540, 540, 135, 4320, 540, 4320, 135, 540, 540, 135, 135, 540, 135, 4320, 4320, 135, 4320, 4320, 135, 540, 4320, 135, 135, 540, 540, 135, 135, 4320, 4320, 4320, 4320, 540, 135, 540, 540, 135, 135, 135, 135, 135, 135, 135, 135, 540, 4320, 540, 540, 540, 4320, 135, 540, 540, 4320, 4320, 135, 4320, 4320, 135, 4320, 135, 135, 540, 135, 4320, 4320, 4320, 540, 135, 4320, 4320, 540, 540, 4320, 4320, 135, 4320, 4320, 540, 135, 4320, 540, 540, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 4320, 135, 540, 4320, 135, 540, 540, 540, 540, 135, 540, 135, 540, 540, 135, 4320, 135, 135, 135, 540, 135, 540, 540, 135, 4320, 540, 4320, 135, 4320, 135, 540, 540, 540, 540, 135, 540, 4320, 4320, 135, 4320, 4320, 135, 4320, 540, 4320, 540, 540, 540, 135, 540, 135, 135, 4320, 135, 540, 135, 135, 540, 4320, 540, 4320, 135, 4320, 4320, 540, 4320, 540, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 639360 . Total input tokens: 142592364 . Total output tokens: 127777710
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 77.8684562696144,
    "estimated_duration": 3600.0031942919195,
    "input_throughput": 6081.130715303693,
    "output_throughput": 5398.694931942334,
    "total_throughput": 11479.825647246027,
    "itl": 146.93936231607995,
    "ttft": 1605175.454895653,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 536,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6766227107052614,
    "arrivals": 212473,
    "finished_requests": 88454,
    "scheduler_time": 168.70033438789926
}
#Debug simulation 
Total elapsed time: 77.86860731989145. Arrivals time: 0.36738000763580203 Scheduler time: 77.35356111312285 Scheduler overhead time: 0.055342288222163916 Adapter cache time: 0.0163395288400352 Engine time: 0.054388261400163174 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-32/adapters_384_slots_64_rate_0.4-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-32/adapters_384_slots_64_rate_0.4-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 4320, 540, 135, 4320, 4320, 135, 540, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 135, 4320, 135, 4320, 540, 540, 540, 135, 135, 540, 135, 4320, 135, 4320, 540, 4320, 540, 135, 540, 4320, 540, 4320, 135, 4320, 4320, 4320, 4320, 135, 540, 540, 540, 4320, 540, 135, 540, 135, 4320, 540, 4320, 4320, 540, 4320, 4320, 135, 135, 4320, 540, 540, 135, 135, 135, 540, 135, 540, 135, 4320, 135, 540, 4320, 135, 4320, 540, 135, 4320, 4320, 4320, 4320, 540, 135, 540, 4320, 4320, 540, 135, 135, 4320, 540, 540, 135, 135, 4320, 540, 4320, 540, 4320, 4320, 540, 4320, 4320, 135, 540, 540, 540, 540, 135, 135, 4320, 135, 4320, 135, 135, 135, 540, 540, 4320, 135, 135, 4320, 135, 4320, 540, 135, 4320, 540, 540, 135, 4320, 4320, 4320, 135, 540, 4320, 135, 4320, 540, 540, 4320, 4320, 135, 540, 4320, 135, 540, 540, 135, 540, 135, 540, 4320, 4320, 540, 135, 4320, 135, 4320, 540, 540, 540, 540, 540, 135, 135, 4320, 135, 4320, 135, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 135, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 135, 135, 135, 135, 135, 540, 135, 135, 540, 4320, 4320, 135, 135, 4320, 135, 135, 135, 540, 135, 540, 4320, 4320, 540, 540, 135, 4320, 540, 4320, 135, 540, 540, 135, 135, 540, 135, 4320, 4320, 135, 4320, 4320, 135, 540, 4320, 135, 135, 540, 540, 135, 135, 4320, 4320, 4320, 4320, 540, 135, 540, 540, 135, 135, 135, 135, 135, 135, 135, 135, 540, 4320, 540, 540, 540, 4320, 135, 540, 540, 4320, 4320, 135, 4320, 4320, 135, 4320, 135, 135, 540, 135, 4320, 4320, 4320, 540, 135, 4320, 4320, 540, 540, 4320, 4320, 135, 4320, 4320, 540, 135, 4320, 540, 540, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 4320, 135, 540, 4320, 135, 540, 540, 540, 540, 135, 540, 135, 540, 540, 135, 4320, 135, 135, 135, 540, 135, 540, 540, 135, 4320, 540, 4320, 135, 4320, 135, 540, 540, 540, 540, 135, 540, 4320, 4320, 135, 4320, 4320, 135, 4320, 540, 4320, 540, 540, 540, 135, 540, 135, 135, 4320, 135, 540, 135, 135, 540, 4320, 540, 4320, 135, 4320, 4320, 540, 4320, 540, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 639360 . Total input tokens: 142592364 . Total output tokens: 127777710
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 76.91580460174009,
    "estimated_duration": 3600.0170001682673,
    "input_throughput": 6139.502952060205,
    "output_throughput": 5453.105637857382,
    "total_throughput": 11592.608589917587,
    "itl": 150.71899859951338,
    "ttft": 1594447.9287414593,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 523,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7308778910525187,
    "arrivals": 212473,
    "finished_requests": 89372,
    "scheduler_time": 165.87424572445747
}
#Debug simulation 
Total elapsed time: 76.9159429166466. Arrivals time: 0.3733178284019232 Scheduler time: 76.39551571756601 Scheduler overhead time: 0.05554789397865534 Adapter cache time: 0.016244670376181602 Engine time: 0.05429109977558255 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-16/adapters_384_slots_64_rate_0.4-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-16/adapters_384_slots_64_rate_0.4-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 4320, 540, 135, 4320, 4320, 135, 540, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 135, 4320, 135, 4320, 540, 540, 540, 135, 135, 540, 135, 4320, 135, 4320, 540, 4320, 540, 135, 540, 4320, 540, 4320, 135, 4320, 4320, 4320, 4320, 135, 540, 540, 540, 4320, 540, 135, 540, 135, 4320, 540, 4320, 4320, 540, 4320, 4320, 135, 135, 4320, 540, 540, 135, 135, 135, 540, 135, 540, 135, 4320, 135, 540, 4320, 135, 4320, 540, 135, 4320, 4320, 4320, 4320, 540, 135, 540, 4320, 4320, 540, 135, 135, 4320, 540, 540, 135, 135, 4320, 540, 4320, 540, 4320, 4320, 540, 4320, 4320, 135, 540, 540, 540, 540, 135, 135, 4320, 135, 4320, 135, 135, 135, 540, 540, 4320, 135, 135, 4320, 135, 4320, 540, 135, 4320, 540, 540, 135, 4320, 4320, 4320, 135, 540, 4320, 135, 4320, 540, 540, 4320, 4320, 135, 540, 4320, 135, 540, 540, 135, 540, 135, 540, 4320, 4320, 540, 135, 4320, 135, 4320, 540, 540, 540, 540, 540, 135, 135, 4320, 135, 4320, 135, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 135, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 135, 135, 135, 135, 135, 540, 135, 135, 540, 4320, 4320, 135, 135, 4320, 135, 135, 135, 540, 135, 540, 4320, 4320, 540, 540, 135, 4320, 540, 4320, 135, 540, 540, 135, 135, 540, 135, 4320, 4320, 135, 4320, 4320, 135, 540, 4320, 135, 135, 540, 540, 135, 135, 4320, 4320, 4320, 4320, 540, 135, 540, 540, 135, 135, 135, 135, 135, 135, 135, 135, 540, 4320, 540, 540, 540, 4320, 135, 540, 540, 4320, 4320, 135, 4320, 4320, 135, 4320, 135, 135, 540, 135, 4320, 4320, 4320, 540, 135, 4320, 4320, 540, 540, 4320, 4320, 135, 4320, 4320, 540, 135, 4320, 540, 540, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 4320, 135, 540, 4320, 135, 540, 540, 540, 540, 135, 540, 135, 540, 540, 135, 4320, 135, 135, 135, 540, 135, 540, 540, 135, 4320, 540, 4320, 135, 4320, 135, 540, 540, 540, 540, 135, 540, 4320, 4320, 135, 4320, 4320, 135, 4320, 540, 4320, 540, 540, 540, 135, 540, 135, 135, 4320, 135, 540, 135, 135, 540, 4320, 540, 4320, 135, 4320, 4320, 540, 4320, 540, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 639360 . Total input tokens: 142592364 . Total output tokens: 127777710
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 78.22016618866473,
    "estimated_duration": 3600.0691171629232,
    "input_throughput": 6082.526275844558,
    "output_throughput": 5405.342332798146,
    "total_throughput": 11487.868608642704,
    "itl": 147.3716444217747,
    "ttft": 1603689.1160943632,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 522,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5608062539389171,
    "arrivals": 212473,
    "finished_requests": 88510,
    "scheduler_time": 168.3736044174873
}
#Debug simulation 
Total elapsed time: 78.22030084766448. Arrivals time: 0.3835415062494576 Scheduler time: 77.68970442283899 Scheduler overhead time: 0.055909641552716494 Adapter cache time: 0.016597692854702473 Engine time: 0.05354012502357364 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-32/adapters_384_slots_64_rate_0.4-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-32/adapters_384_slots_64_rate_0.4-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 4320, 540, 135, 4320, 4320, 135, 540, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 135, 4320, 135, 4320, 540, 540, 540, 135, 135, 540, 135, 4320, 135, 4320, 540, 4320, 540, 135, 540, 4320, 540, 4320, 135, 4320, 4320, 4320, 4320, 135, 540, 540, 540, 4320, 540, 135, 540, 135, 4320, 540, 4320, 4320, 540, 4320, 4320, 135, 135, 4320, 540, 540, 135, 135, 135, 540, 135, 540, 135, 4320, 135, 540, 4320, 135, 4320, 540, 135, 4320, 4320, 4320, 4320, 540, 135, 540, 4320, 4320, 540, 135, 135, 4320, 540, 540, 135, 135, 4320, 540, 4320, 540, 4320, 4320, 540, 4320, 4320, 135, 540, 540, 540, 540, 135, 135, 4320, 135, 4320, 135, 135, 135, 540, 540, 4320, 135, 135, 4320, 135, 4320, 540, 135, 4320, 540, 540, 135, 4320, 4320, 4320, 135, 540, 4320, 135, 4320, 540, 540, 4320, 4320, 135, 540, 4320, 135, 540, 540, 135, 540, 135, 540, 4320, 4320, 540, 135, 4320, 135, 4320, 540, 540, 540, 540, 540, 135, 135, 4320, 135, 4320, 135, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 135, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 135, 135, 135, 135, 135, 540, 135, 135, 540, 4320, 4320, 135, 135, 4320, 135, 135, 135, 540, 135, 540, 4320, 4320, 540, 540, 135, 4320, 540, 4320, 135, 540, 540, 135, 135, 540, 135, 4320, 4320, 135, 4320, 4320, 135, 540, 4320, 135, 135, 540, 540, 135, 135, 4320, 4320, 4320, 4320, 540, 135, 540, 540, 135, 135, 135, 135, 135, 135, 135, 135, 540, 4320, 540, 540, 540, 4320, 135, 540, 540, 4320, 4320, 135, 4320, 4320, 135, 4320, 135, 135, 540, 135, 4320, 4320, 4320, 540, 135, 4320, 4320, 540, 540, 4320, 4320, 135, 4320, 4320, 540, 135, 4320, 540, 540, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 4320, 135, 540, 4320, 135, 540, 540, 540, 540, 135, 540, 135, 540, 540, 135, 4320, 135, 135, 135, 540, 135, 540, 540, 135, 4320, 540, 4320, 135, 4320, 135, 540, 540, 540, 540, 135, 540, 4320, 4320, 135, 4320, 4320, 135, 4320, 540, 4320, 540, 540, 540, 135, 540, 135, 135, 4320, 135, 540, 135, 135, 540, 4320, 540, 4320, 135, 4320, 4320, 540, 4320, 540, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 639360 . Total input tokens: 142592364 . Total output tokens: 127777710
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 76.8518716278486,
    "estimated_duration": 3600.0392377062985,
    "input_throughput": 6139.465028187332,
    "output_throughput": 5453.071953878958,
    "total_throughput": 11592.536982066289,
    "itl": 150.71927053578239,
    "ttft": 1594457.269911635,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 523,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7528848036751128,
    "arrivals": 212473,
    "finished_requests": 89372,
    "scheduler_time": 165.87452786706046
}
#Debug simulation 
Total elapsed time: 76.85200693411753. Arrivals time: 0.38957610772922635 Scheduler time: 76.31542864441872 Scheduler overhead time: 0.055933854542672634 Adapter cache time: 0.015620436519384384 Engine time: 0.054552935529500246 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-8/adapters_384_slots_64_rate_0.4-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-8/adapters_384_slots_64_rate_0.4-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 540, 66, 4320, 4320, 66, 540, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 66, 4320, 66, 4320, 540, 540, 540, 66, 66, 540, 66, 4320, 66, 4320, 540, 4320, 540, 66, 540, 4320, 540, 4320, 66, 4320, 4320, 4320, 4320, 66, 540, 540, 540, 4320, 540, 66, 540, 66, 4320, 540, 4320, 4320, 540, 4320, 4320, 66, 66, 4320, 540, 540, 66, 66, 66, 540, 66, 540, 66, 4320, 66, 540, 4320, 66, 4320, 540, 66, 4320, 4320, 4320, 4320, 540, 66, 540, 4320, 4320, 540, 66, 66, 4320, 540, 540, 66, 66, 4320, 540, 4320, 540, 4320, 4320, 540, 4320, 4320, 66, 540, 540, 540, 540, 66, 66, 4320, 66, 4320, 66, 66, 66, 540, 540, 4320, 66, 66, 4320, 66, 4320, 540, 66, 4320, 540, 540, 66, 4320, 4320, 4320, 66, 540, 4320, 66, 4320, 540, 540, 4320, 4320, 66, 540, 4320, 66, 540, 540, 66, 540, 66, 540, 4320, 4320, 540, 66, 4320, 66, 4320, 540, 540, 540, 540, 540, 66, 66, 4320, 66, 4320, 66, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 66, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 66, 66, 66, 66, 66, 540, 66, 66, 540, 4320, 4320, 66, 66, 4320, 66, 66, 66, 540, 66, 540, 4320, 4320, 540, 540, 66, 4320, 540, 4320, 66, 540, 540, 66, 66, 540, 66, 4320, 4320, 66, 4320, 4320, 66, 540, 4320, 66, 66, 540, 540, 66, 66, 4320, 4320, 4320, 4320, 540, 66, 540, 540, 66, 66, 66, 66, 66, 66, 66, 66, 540, 4320, 540, 540, 540, 4320, 66, 540, 540, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 540, 66, 4320, 4320, 4320, 540, 66, 4320, 4320, 540, 540, 4320, 4320, 66, 4320, 4320, 540, 66, 4320, 540, 540, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 540, 4320, 66, 540, 540, 540, 540, 66, 540, 66, 540, 540, 66, 4320, 66, 66, 66, 540, 66, 540, 540, 66, 4320, 540, 4320, 66, 4320, 66, 540, 540, 540, 540, 66, 540, 4320, 4320, 66, 4320, 4320, 66, 4320, 540, 4320, 540, 540, 540, 66, 540, 66, 66, 4320, 66, 540, 66, 66, 540, 4320, 540, 4320, 66, 4320, 4320, 540, 4320, 540, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 630528 . Total input tokens: 140630688 . Total output tokens: 125979895
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 77.45729556679726,
    "estimated_duration": 3600.0207868792972,
    "input_throughput": 6198.3983762891985,
    "output_throughput": 5426.937830805099,
    "total_throughput": 11625.336207094299,
    "itl": 148.75371613092787,
    "ttft": 1582740.471103553,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 554,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6955102101387685,
    "arrivals": 209565,
    "finished_requests": 89546,
    "scheduler_time": 166.66732250022562
}
#Debug simulation 
Total elapsed time: 77.45744251692668. Arrivals time: 0.3895363095216453 Scheduler time: 76.92064711172134 Scheduler overhead time: 0.055271020624786615 Adapter cache time: 0.01684847055003047 Engine time: 0.0543824378401041 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-16/adapters_384_slots_64_rate_0.4-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-16/adapters_384_slots_64_rate_0.4-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 540, 66, 4320, 4320, 66, 540, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 66, 4320, 66, 4320, 540, 540, 540, 66, 66, 540, 66, 4320, 66, 4320, 540, 4320, 540, 66, 540, 4320, 540, 4320, 66, 4320, 4320, 4320, 4320, 66, 540, 540, 540, 4320, 540, 66, 540, 66, 4320, 540, 4320, 4320, 540, 4320, 4320, 66, 66, 4320, 540, 540, 66, 66, 66, 540, 66, 540, 66, 4320, 66, 540, 4320, 66, 4320, 540, 66, 4320, 4320, 4320, 4320, 540, 66, 540, 4320, 4320, 540, 66, 66, 4320, 540, 540, 66, 66, 4320, 540, 4320, 540, 4320, 4320, 540, 4320, 4320, 66, 540, 540, 540, 540, 66, 66, 4320, 66, 4320, 66, 66, 66, 540, 540, 4320, 66, 66, 4320, 66, 4320, 540, 66, 4320, 540, 540, 66, 4320, 4320, 4320, 66, 540, 4320, 66, 4320, 540, 540, 4320, 4320, 66, 540, 4320, 66, 540, 540, 66, 540, 66, 540, 4320, 4320, 540, 66, 4320, 66, 4320, 540, 540, 540, 540, 540, 66, 66, 4320, 66, 4320, 66, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 66, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 66, 66, 66, 66, 66, 540, 66, 66, 540, 4320, 4320, 66, 66, 4320, 66, 66, 66, 540, 66, 540, 4320, 4320, 540, 540, 66, 4320, 540, 4320, 66, 540, 540, 66, 66, 540, 66, 4320, 4320, 66, 4320, 4320, 66, 540, 4320, 66, 66, 540, 540, 66, 66, 4320, 4320, 4320, 4320, 540, 66, 540, 540, 66, 66, 66, 66, 66, 66, 66, 66, 540, 4320, 540, 540, 540, 4320, 66, 540, 540, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 540, 66, 4320, 4320, 4320, 540, 66, 4320, 4320, 540, 540, 4320, 4320, 66, 4320, 4320, 540, 66, 4320, 540, 540, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 540, 4320, 66, 540, 540, 540, 540, 66, 540, 66, 540, 540, 66, 4320, 66, 66, 66, 540, 66, 540, 540, 66, 4320, 540, 4320, 66, 4320, 66, 540, 540, 540, 540, 66, 540, 4320, 4320, 66, 4320, 4320, 66, 4320, 540, 4320, 540, 540, 540, 66, 540, 66, 66, 4320, 66, 540, 66, 66, 540, 4320, 540, 4320, 66, 4320, 4320, 540, 4320, 540, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 630528 . Total input tokens: 140630688 . Total output tokens: 125979895
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 78.75227685505524,
    "estimated_duration": 3600.1204141567987,
    "input_throughput": 6205.194390763796,
    "output_throughput": 5428.91618934298,
    "total_throughput": 11634.110580106775,
    "itl": 148.70924850250054,
    "ttft": 1581857.0195567333,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 565,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8417844703979835,
    "arrivals": 209565,
    "finished_requests": 89635,
    "scheduler_time": 166.68760033137093
}
#Debug simulation 
Total elapsed time: 78.75241586612538. Arrivals time: 0.38375776959583163 Scheduler time: 78.2206936487928 Scheduler overhead time: 0.05505059426650405 Adapter cache time: 0.016702069900929928 Engine time: 0.05488460278138518 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-32/adapters_384_slots_64_rate_0.4-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-32/adapters_384_slots_64_rate_0.4-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 540, 66, 4320, 4320, 66, 540, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 66, 4320, 66, 4320, 540, 540, 540, 66, 66, 540, 66, 4320, 66, 4320, 540, 4320, 540, 66, 540, 4320, 540, 4320, 66, 4320, 4320, 4320, 4320, 66, 540, 540, 540, 4320, 540, 66, 540, 66, 4320, 540, 4320, 4320, 540, 4320, 4320, 66, 66, 4320, 540, 540, 66, 66, 66, 540, 66, 540, 66, 4320, 66, 540, 4320, 66, 4320, 540, 66, 4320, 4320, 4320, 4320, 540, 66, 540, 4320, 4320, 540, 66, 66, 4320, 540, 540, 66, 66, 4320, 540, 4320, 540, 4320, 4320, 540, 4320, 4320, 66, 540, 540, 540, 540, 66, 66, 4320, 66, 4320, 66, 66, 66, 540, 540, 4320, 66, 66, 4320, 66, 4320, 540, 66, 4320, 540, 540, 66, 4320, 4320, 4320, 66, 540, 4320, 66, 4320, 540, 540, 4320, 4320, 66, 540, 4320, 66, 540, 540, 66, 540, 66, 540, 4320, 4320, 540, 66, 4320, 66, 4320, 540, 540, 540, 540, 540, 66, 66, 4320, 66, 4320, 66, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 66, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 66, 66, 66, 66, 66, 540, 66, 66, 540, 4320, 4320, 66, 66, 4320, 66, 66, 66, 540, 66, 540, 4320, 4320, 540, 540, 66, 4320, 540, 4320, 66, 540, 540, 66, 66, 540, 66, 4320, 4320, 66, 4320, 4320, 66, 540, 4320, 66, 66, 540, 540, 66, 66, 4320, 4320, 4320, 4320, 540, 66, 540, 540, 66, 66, 66, 66, 66, 66, 66, 66, 540, 4320, 540, 540, 540, 4320, 66, 540, 540, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 540, 66, 4320, 4320, 4320, 540, 66, 4320, 4320, 540, 540, 4320, 4320, 66, 4320, 4320, 540, 66, 4320, 540, 540, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 540, 4320, 66, 540, 540, 540, 540, 66, 540, 66, 540, 540, 66, 4320, 66, 66, 66, 540, 66, 540, 540, 66, 4320, 540, 4320, 66, 4320, 66, 540, 540, 540, 540, 66, 540, 4320, 4320, 66, 4320, 4320, 66, 4320, 540, 4320, 540, 540, 540, 66, 540, 66, 66, 4320, 66, 540, 66, 66, 540, 4320, 540, 4320, 66, 4320, 4320, 540, 4320, 540, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 630528 . Total input tokens: 140630688 . Total output tokens: 125979895
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 78.37626398913562,
    "estimated_duration": 3600.127579616355,
    "input_throughput": 6205.1820403488555,
    "output_throughput": 5428.905383981634,
    "total_throughput": 11634.08742433049,
    "itl": 148.70905638622003,
    "ttft": 1581860.7967365484,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 565,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8453814650140816,
    "arrivals": 209565,
    "finished_requests": 89635,
    "scheduler_time": 166.6880506223365
}
#Debug simulation 
Total elapsed time: 78.37640891922638. Arrivals time: 0.38176021026447415 Scheduler time: 77.84607505099848 Scheduler overhead time: 0.05663019558414817 Adapter cache time: 0.01667229225859046 Engine time: 0.05386887490749359 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-16/adapters_384_slots_64_rate_0.4-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-16/adapters_384_slots_64_rate_0.4-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 540, 66, 4320, 4320, 66, 540, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 66, 4320, 66, 4320, 540, 540, 540, 66, 66, 540, 66, 4320, 66, 4320, 540, 4320, 540, 66, 540, 4320, 540, 4320, 66, 4320, 4320, 4320, 4320, 66, 540, 540, 540, 4320, 540, 66, 540, 66, 4320, 540, 4320, 4320, 540, 4320, 4320, 66, 66, 4320, 540, 540, 66, 66, 66, 540, 66, 540, 66, 4320, 66, 540, 4320, 66, 4320, 540, 66, 4320, 4320, 4320, 4320, 540, 66, 540, 4320, 4320, 540, 66, 66, 4320, 540, 540, 66, 66, 4320, 540, 4320, 540, 4320, 4320, 540, 4320, 4320, 66, 540, 540, 540, 540, 66, 66, 4320, 66, 4320, 66, 66, 66, 540, 540, 4320, 66, 66, 4320, 66, 4320, 540, 66, 4320, 540, 540, 66, 4320, 4320, 4320, 66, 540, 4320, 66, 4320, 540, 540, 4320, 4320, 66, 540, 4320, 66, 540, 540, 66, 540, 66, 540, 4320, 4320, 540, 66, 4320, 66, 4320, 540, 540, 540, 540, 540, 66, 66, 4320, 66, 4320, 66, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 66, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 66, 66, 66, 66, 66, 540, 66, 66, 540, 4320, 4320, 66, 66, 4320, 66, 66, 66, 540, 66, 540, 4320, 4320, 540, 540, 66, 4320, 540, 4320, 66, 540, 540, 66, 66, 540, 66, 4320, 4320, 66, 4320, 4320, 66, 540, 4320, 66, 66, 540, 540, 66, 66, 4320, 4320, 4320, 4320, 540, 66, 540, 540, 66, 66, 66, 66, 66, 66, 66, 66, 540, 4320, 540, 540, 540, 4320, 66, 540, 540, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 540, 66, 4320, 4320, 4320, 540, 66, 4320, 4320, 540, 540, 4320, 4320, 66, 4320, 4320, 540, 66, 4320, 540, 540, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 540, 4320, 66, 540, 540, 540, 540, 66, 540, 66, 540, 540, 66, 4320, 66, 66, 66, 540, 66, 540, 540, 66, 4320, 540, 4320, 66, 4320, 66, 540, 540, 540, 540, 66, 540, 4320, 4320, 66, 4320, 4320, 66, 4320, 540, 4320, 540, 540, 540, 66, 540, 66, 66, 4320, 66, 540, 66, 66, 540, 4320, 540, 4320, 66, 4320, 4320, 540, 4320, 540, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 630528 . Total input tokens: 140630688 . Total output tokens: 125979895
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 77.5304090520367,
    "estimated_duration": 3600.059276501328,
    "input_throughput": 6198.332106821844,
    "output_throughput": 5426.8798093199375,
    "total_throughput": 11625.211916141781,
    "itl": 148.754245138689,
    "ttft": 1582756.099399224,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 554,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.730852211331939,
    "arrivals": 209565,
    "finished_requests": 89546,
    "scheduler_time": 166.66818869151598
}
#Debug simulation 
Total elapsed time: 77.53056143177673. Arrivals time: 0.363052885979414 Scheduler time: 77.01690215757117 Scheduler overhead time: 0.05707078194245696 Adapter cache time: 0.016703328117728233 Engine time: 0.054970461409538984 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-32/adapters_384_slots_64_rate_0.4-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-32/adapters_384_slots_64_rate_0.4-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 540, 66, 4320, 4320, 66, 540, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 66, 4320, 66, 4320, 540, 540, 540, 66, 66, 540, 66, 4320, 66, 4320, 540, 4320, 540, 66, 540, 4320, 540, 4320, 66, 4320, 4320, 4320, 4320, 66, 540, 540, 540, 4320, 540, 66, 540, 66, 4320, 540, 4320, 4320, 540, 4320, 4320, 66, 66, 4320, 540, 540, 66, 66, 66, 540, 66, 540, 66, 4320, 66, 540, 4320, 66, 4320, 540, 66, 4320, 4320, 4320, 4320, 540, 66, 540, 4320, 4320, 540, 66, 66, 4320, 540, 540, 66, 66, 4320, 540, 4320, 540, 4320, 4320, 540, 4320, 4320, 66, 540, 540, 540, 540, 66, 66, 4320, 66, 4320, 66, 66, 66, 540, 540, 4320, 66, 66, 4320, 66, 4320, 540, 66, 4320, 540, 540, 66, 4320, 4320, 4320, 66, 540, 4320, 66, 4320, 540, 540, 4320, 4320, 66, 540, 4320, 66, 540, 540, 66, 540, 66, 540, 4320, 4320, 540, 66, 4320, 66, 4320, 540, 540, 540, 540, 540, 66, 66, 4320, 66, 4320, 66, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 66, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 66, 66, 66, 66, 66, 540, 66, 66, 540, 4320, 4320, 66, 66, 4320, 66, 66, 66, 540, 66, 540, 4320, 4320, 540, 540, 66, 4320, 540, 4320, 66, 540, 540, 66, 66, 540, 66, 4320, 4320, 66, 4320, 4320, 66, 540, 4320, 66, 66, 540, 540, 66, 66, 4320, 4320, 4320, 4320, 540, 66, 540, 540, 66, 66, 66, 66, 66, 66, 66, 66, 540, 4320, 540, 540, 540, 4320, 66, 540, 540, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 540, 66, 4320, 4320, 4320, 540, 66, 4320, 4320, 540, 540, 4320, 4320, 66, 4320, 4320, 540, 66, 4320, 540, 540, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 540, 4320, 66, 540, 540, 540, 540, 66, 540, 66, 540, 540, 66, 4320, 66, 66, 66, 540, 66, 540, 540, 66, 4320, 540, 4320, 66, 4320, 66, 540, 540, 540, 540, 66, 540, 4320, 4320, 66, 4320, 4320, 66, 4320, 540, 4320, 540, 540, 540, 66, 540, 66, 66, 4320, 66, 540, 66, 66, 540, 4320, 540, 4320, 66, 4320, 4320, 540, 4320, 540, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 630528 . Total input tokens: 140630688 . Total output tokens: 125979895
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 77.37498445669189,
    "estimated_duration": 3600.0577476638364,
    "input_throughput": 6205.677121289923,
    "output_throughput": 5429.731234918312,
    "total_throughput": 11635.408356208236,
    "itl": 148.7051297577661,
    "ttft": 1582655.2111721863,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 568,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8781537334062197,
    "arrivals": 209565,
    "finished_requests": 89638,
    "scheduler_time": 166.67987700775996
}
#Debug simulation 
Total elapsed time: 77.37511835293844. Arrivals time: 0.3764026267454028 Scheduler time: 76.8518524011597 Scheduler overhead time: 0.055441899225115776 Adapter cache time: 0.016889692284166813 Engine time: 0.05374725488945842 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-16/adapters_384_slots_64_rate_0.4-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-16/adapters_384_slots_64_rate_0.4-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 540, 66, 4320, 4320, 66, 540, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 66, 4320, 66, 4320, 540, 540, 540, 66, 66, 540, 66, 4320, 66, 4320, 540, 4320, 540, 66, 540, 4320, 540, 4320, 66, 4320, 4320, 4320, 4320, 66, 540, 540, 540, 4320, 540, 66, 540, 66, 4320, 540, 4320, 4320, 540, 4320, 4320, 66, 66, 4320, 540, 540, 66, 66, 66, 540, 66, 540, 66, 4320, 66, 540, 4320, 66, 4320, 540, 66, 4320, 4320, 4320, 4320, 540, 66, 540, 4320, 4320, 540, 66, 66, 4320, 540, 540, 66, 66, 4320, 540, 4320, 540, 4320, 4320, 540, 4320, 4320, 66, 540, 540, 540, 540, 66, 66, 4320, 66, 4320, 66, 66, 66, 540, 540, 4320, 66, 66, 4320, 66, 4320, 540, 66, 4320, 540, 540, 66, 4320, 4320, 4320, 66, 540, 4320, 66, 4320, 540, 540, 4320, 4320, 66, 540, 4320, 66, 540, 540, 66, 540, 66, 540, 4320, 4320, 540, 66, 4320, 66, 4320, 540, 540, 540, 540, 540, 66, 66, 4320, 66, 4320, 66, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 66, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 66, 66, 66, 66, 66, 540, 66, 66, 540, 4320, 4320, 66, 66, 4320, 66, 66, 66, 540, 66, 540, 4320, 4320, 540, 540, 66, 4320, 540, 4320, 66, 540, 540, 66, 66, 540, 66, 4320, 4320, 66, 4320, 4320, 66, 540, 4320, 66, 66, 540, 540, 66, 66, 4320, 4320, 4320, 4320, 540, 66, 540, 540, 66, 66, 66, 66, 66, 66, 66, 66, 540, 4320, 540, 540, 540, 4320, 66, 540, 540, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 540, 66, 4320, 4320, 4320, 540, 66, 4320, 4320, 540, 540, 4320, 4320, 66, 4320, 4320, 540, 66, 4320, 540, 540, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 540, 4320, 66, 540, 540, 540, 540, 66, 540, 66, 540, 540, 66, 4320, 66, 66, 66, 540, 66, 540, 540, 66, 4320, 540, 4320, 66, 4320, 66, 540, 540, 540, 540, 66, 540, 4320, 4320, 66, 4320, 4320, 66, 4320, 540, 4320, 540, 540, 540, 66, 540, 66, 66, 4320, 66, 540, 66, 66, 540, 4320, 540, 4320, 66, 4320, 4320, 540, 4320, 540, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 630528 . Total input tokens: 140630688 . Total output tokens: 125979895
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 77.84496928099543,
    "estimated_duration": 3600.1098278268378,
    "input_throughput": 6202.4563326944235,
    "output_throughput": 5430.333499520207,
    "total_throughput": 11632.78983221463,
    "itl": 148.74551593629027,
    "ttft": 1581259.6483030173,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 543,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6235973101318606,
    "arrivals": 209565,
    "finished_requests": 89602,
    "scheduler_time": 166.53837545089925
}
#Debug simulation 
Total elapsed time: 77.84511028416455. Arrivals time: 0.3902357742190361 Scheduler time: 77.30635901959613 Scheduler overhead time: 0.055815698113292456 Adapter cache time: 0.016491652466356754 Engine time: 0.05517307668924332 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-32/adapters_384_slots_64_rate_0.4-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-32/adapters_384_slots_64_rate_0.4-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 540, 66, 4320, 4320, 66, 540, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 66, 4320, 66, 4320, 540, 540, 540, 66, 66, 540, 66, 4320, 66, 4320, 540, 4320, 540, 66, 540, 4320, 540, 4320, 66, 4320, 4320, 4320, 4320, 66, 540, 540, 540, 4320, 540, 66, 540, 66, 4320, 540, 4320, 4320, 540, 4320, 4320, 66, 66, 4320, 540, 540, 66, 66, 66, 540, 66, 540, 66, 4320, 66, 540, 4320, 66, 4320, 540, 66, 4320, 4320, 4320, 4320, 540, 66, 540, 4320, 4320, 540, 66, 66, 4320, 540, 540, 66, 66, 4320, 540, 4320, 540, 4320, 4320, 540, 4320, 4320, 66, 540, 540, 540, 540, 66, 66, 4320, 66, 4320, 66, 66, 66, 540, 540, 4320, 66, 66, 4320, 66, 4320, 540, 66, 4320, 540, 540, 66, 4320, 4320, 4320, 66, 540, 4320, 66, 4320, 540, 540, 4320, 4320, 66, 540, 4320, 66, 540, 540, 66, 540, 66, 540, 4320, 4320, 540, 66, 4320, 66, 4320, 540, 540, 540, 540, 540, 66, 66, 4320, 66, 4320, 66, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 66, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 66, 66, 66, 66, 66, 540, 66, 66, 540, 4320, 4320, 66, 66, 4320, 66, 66, 66, 540, 66, 540, 4320, 4320, 540, 540, 66, 4320, 540, 4320, 66, 540, 540, 66, 66, 540, 66, 4320, 4320, 66, 4320, 4320, 66, 540, 4320, 66, 66, 540, 540, 66, 66, 4320, 4320, 4320, 4320, 540, 66, 540, 540, 66, 66, 66, 66, 66, 66, 66, 66, 540, 4320, 540, 540, 540, 4320, 66, 540, 540, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 540, 66, 4320, 4320, 4320, 540, 66, 4320, 4320, 540, 540, 4320, 4320, 66, 4320, 4320, 540, 66, 4320, 540, 540, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 540, 4320, 66, 540, 540, 540, 540, 66, 540, 66, 540, 540, 66, 4320, 66, 66, 66, 540, 66, 540, 540, 66, 4320, 540, 4320, 66, 4320, 66, 540, 540, 540, 540, 66, 540, 4320, 4320, 66, 4320, 4320, 66, 4320, 540, 4320, 540, 540, 540, 66, 540, 66, 66, 4320, 66, 540, 66, 66, 540, 4320, 540, 4320, 66, 4320, 4320, 540, 4320, 540, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 630528 . Total input tokens: 140630688 . Total output tokens: 125979895
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 77.51668571587652,
    "estimated_duration": 3600.0817408486055,
    "input_throughput": 6205.635762796282,
    "output_throughput": 5429.695047810867,
    "total_throughput": 11635.330810607149,
    "itl": 148.7058073530032,
    "ttft": 1582664.1614069988,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 568,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9014181838929616,
    "arrivals": 209565,
    "finished_requests": 89638,
    "scheduler_time": 166.68041376748627
}
#Debug simulation 
Total elapsed time: 77.516833930742. Arrivals time: 0.39323773281648755 Scheduler time: 76.97388811782002 Scheduler overhead time: 0.05712520610541105 Adapter cache time: 0.016654144041240215 Engine time: 0.05454127723351121 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-8/adapters_384_slots_64_rate_0.4-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-8/adapters_384_slots_64_rate_0.4-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 540, 33, 4320, 4320, 33, 540, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 33, 4320, 33, 4320, 540, 540, 540, 33, 33, 540, 33, 4320, 33, 4320, 540, 4320, 540, 33, 540, 4320, 540, 4320, 33, 4320, 4320, 4320, 4320, 33, 540, 540, 540, 4320, 540, 33, 540, 33, 4320, 540, 4320, 4320, 540, 4320, 4320, 33, 33, 4320, 540, 540, 33, 33, 33, 540, 33, 540, 33, 4320, 33, 540, 4320, 33, 4320, 540, 33, 4320, 4320, 4320, 4320, 540, 33, 540, 4320, 4320, 540, 33, 33, 4320, 540, 540, 33, 33, 4320, 540, 4320, 540, 4320, 4320, 540, 4320, 4320, 33, 540, 540, 540, 540, 33, 33, 4320, 33, 4320, 33, 33, 33, 540, 540, 4320, 33, 33, 4320, 33, 4320, 540, 33, 4320, 540, 540, 33, 4320, 4320, 4320, 33, 540, 4320, 33, 4320, 540, 540, 4320, 4320, 33, 540, 4320, 33, 540, 540, 33, 540, 33, 540, 4320, 4320, 540, 33, 4320, 33, 4320, 540, 540, 540, 540, 540, 33, 33, 4320, 33, 4320, 33, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 33, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 33, 33, 33, 33, 33, 540, 33, 33, 540, 4320, 4320, 33, 33, 4320, 33, 33, 33, 540, 33, 540, 4320, 4320, 540, 540, 33, 4320, 540, 4320, 33, 540, 540, 33, 33, 540, 33, 4320, 4320, 33, 4320, 4320, 33, 540, 4320, 33, 33, 540, 540, 33, 33, 4320, 4320, 4320, 4320, 540, 33, 540, 540, 33, 33, 33, 33, 33, 33, 33, 33, 540, 4320, 540, 540, 540, 4320, 33, 540, 540, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 540, 33, 4320, 4320, 4320, 540, 33, 4320, 4320, 540, 540, 4320, 4320, 33, 4320, 4320, 540, 33, 4320, 540, 540, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 540, 4320, 33, 540, 540, 540, 540, 33, 540, 33, 540, 540, 33, 4320, 33, 33, 33, 540, 33, 540, 540, 33, 4320, 540, 4320, 33, 4320, 33, 540, 540, 540, 540, 33, 540, 4320, 4320, 33, 4320, 4320, 33, 4320, 540, 4320, 540, 540, 540, 33, 540, 33, 33, 4320, 33, 540, 33, 33, 540, 4320, 540, 4320, 33, 4320, 4320, 540, 4320, 540, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 626304 . Total input tokens: 139684315 . Total output tokens: 125137764
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 74.26402177568525,
    "estimated_duration": 3600.0931435506145,
    "input_throughput": 6167.706254983406,
    "output_throughput": 5457.021587120444,
    "total_throughput": 11624.72784210385,
    "itl": 150.6486071319538,
    "ttft": 1584713.3967141581,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 527,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6128770410525812,
    "arrivals": 208142,
    "finished_requests": 89652,
    "scheduler_time": 165.07557349612856
}
#Debug simulation 
Total elapsed time: 74.2641594959423. Arrivals time: 0.38876329036429524 Scheduler time: 73.73072060244158 Scheduler overhead time: 0.05404604505747557 Adapter cache time: 0.015865979250520468 Engine time: 0.053788512479513884 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-16/adapters_384_slots_64_rate_0.4-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-16/adapters_384_slots_64_rate_0.4-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 540, 33, 4320, 4320, 33, 540, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 33, 4320, 33, 4320, 540, 540, 540, 33, 33, 540, 33, 4320, 33, 4320, 540, 4320, 540, 33, 540, 4320, 540, 4320, 33, 4320, 4320, 4320, 4320, 33, 540, 540, 540, 4320, 540, 33, 540, 33, 4320, 540, 4320, 4320, 540, 4320, 4320, 33, 33, 4320, 540, 540, 33, 33, 33, 540, 33, 540, 33, 4320, 33, 540, 4320, 33, 4320, 540, 33, 4320, 4320, 4320, 4320, 540, 33, 540, 4320, 4320, 540, 33, 33, 4320, 540, 540, 33, 33, 4320, 540, 4320, 540, 4320, 4320, 540, 4320, 4320, 33, 540, 540, 540, 540, 33, 33, 4320, 33, 4320, 33, 33, 33, 540, 540, 4320, 33, 33, 4320, 33, 4320, 540, 33, 4320, 540, 540, 33, 4320, 4320, 4320, 33, 540, 4320, 33, 4320, 540, 540, 4320, 4320, 33, 540, 4320, 33, 540, 540, 33, 540, 33, 540, 4320, 4320, 540, 33, 4320, 33, 4320, 540, 540, 540, 540, 540, 33, 33, 4320, 33, 4320, 33, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 33, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 33, 33, 33, 33, 33, 540, 33, 33, 540, 4320, 4320, 33, 33, 4320, 33, 33, 33, 540, 33, 540, 4320, 4320, 540, 540, 33, 4320, 540, 4320, 33, 540, 540, 33, 33, 540, 33, 4320, 4320, 33, 4320, 4320, 33, 540, 4320, 33, 33, 540, 540, 33, 33, 4320, 4320, 4320, 4320, 540, 33, 540, 540, 33, 33, 33, 33, 33, 33, 33, 33, 540, 4320, 540, 540, 540, 4320, 33, 540, 540, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 540, 33, 4320, 4320, 4320, 540, 33, 4320, 4320, 540, 540, 4320, 4320, 33, 4320, 4320, 540, 33, 4320, 540, 540, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 540, 4320, 33, 540, 540, 540, 540, 33, 540, 33, 540, 540, 33, 4320, 33, 33, 33, 540, 33, 540, 540, 33, 4320, 540, 4320, 33, 4320, 33, 540, 540, 540, 540, 33, 540, 4320, 4320, 33, 4320, 4320, 33, 4320, 540, 4320, 540, 540, 540, 33, 540, 33, 33, 4320, 33, 540, 33, 33, 540, 4320, 540, 4320, 33, 4320, 4320, 540, 4320, 540, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 626304 . Total input tokens: 139684315 . Total output tokens: 125137764
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 80.73529113270342,
    "estimated_duration": 3600.0905266754394,
    "input_throughput": 6156.482131705615,
    "output_throughput": 5449.72740397113,
    "total_throughput": 11606.209535676746,
    "itl": 150.46751902654708,
    "ttft": 1576617.3462249637,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 515,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6808412867365454,
    "arrivals": 208142,
    "finished_requests": 89508,
    "scheduler_time": 165.48030745363252
}
#Debug simulation 
Total elapsed time: 80.73543227789924. Arrivals time: 0.3891701907850802 Scheduler time: 80.19631439866498 Scheduler overhead time: 0.056207265704870224 Adapter cache time: 0.017012429423630238 Engine time: 0.05541630042716861 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-32/adapters_384_slots_64_rate_0.4-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-32/adapters_384_slots_64_rate_0.4-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 540, 33, 4320, 4320, 33, 540, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 33, 4320, 33, 4320, 540, 540, 540, 33, 33, 540, 33, 4320, 33, 4320, 540, 4320, 540, 33, 540, 4320, 540, 4320, 33, 4320, 4320, 4320, 4320, 33, 540, 540, 540, 4320, 540, 33, 540, 33, 4320, 540, 4320, 4320, 540, 4320, 4320, 33, 33, 4320, 540, 540, 33, 33, 33, 540, 33, 540, 33, 4320, 33, 540, 4320, 33, 4320, 540, 33, 4320, 4320, 4320, 4320, 540, 33, 540, 4320, 4320, 540, 33, 33, 4320, 540, 540, 33, 33, 4320, 540, 4320, 540, 4320, 4320, 540, 4320, 4320, 33, 540, 540, 540, 540, 33, 33, 4320, 33, 4320, 33, 33, 33, 540, 540, 4320, 33, 33, 4320, 33, 4320, 540, 33, 4320, 540, 540, 33, 4320, 4320, 4320, 33, 540, 4320, 33, 4320, 540, 540, 4320, 4320, 33, 540, 4320, 33, 540, 540, 33, 540, 33, 540, 4320, 4320, 540, 33, 4320, 33, 4320, 540, 540, 540, 540, 540, 33, 33, 4320, 33, 4320, 33, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 33, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 33, 33, 33, 33, 33, 540, 33, 33, 540, 4320, 4320, 33, 33, 4320, 33, 33, 33, 540, 33, 540, 4320, 4320, 540, 540, 33, 4320, 540, 4320, 33, 540, 540, 33, 33, 540, 33, 4320, 4320, 33, 4320, 4320, 33, 540, 4320, 33, 33, 540, 540, 33, 33, 4320, 4320, 4320, 4320, 540, 33, 540, 540, 33, 33, 33, 33, 33, 33, 33, 33, 540, 4320, 540, 540, 540, 4320, 33, 540, 540, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 540, 33, 4320, 4320, 4320, 540, 33, 4320, 4320, 540, 540, 4320, 4320, 33, 4320, 4320, 540, 33, 4320, 540, 540, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 540, 4320, 33, 540, 540, 540, 540, 33, 540, 33, 540, 540, 33, 4320, 33, 33, 33, 540, 33, 540, 540, 33, 4320, 540, 4320, 33, 4320, 33, 540, 540, 540, 540, 33, 540, 4320, 4320, 33, 4320, 4320, 33, 4320, 540, 4320, 540, 540, 540, 33, 540, 33, 33, 4320, 33, 540, 33, 33, 540, 4320, 540, 4320, 33, 4320, 4320, 540, 4320, 540, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 626304 . Total input tokens: 139684315 . Total output tokens: 125137764
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 81.4171543107368,
    "estimated_duration": 3600.0937825539127,
    "input_throughput": 6156.476563862427,
    "output_throughput": 5449.72247530782,
    "total_throughput": 11606.199039170247,
    "itl": 150.4676242935929,
    "ttft": 1576618.5244136432,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 515,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6837625927291913,
    "arrivals": 208142,
    "finished_requests": 89508,
    "scheduler_time": 165.48036355021313
}
#Debug simulation 
Total elapsed time: 81.41729385079816. Arrivals time: 0.3779084454290569 Scheduler time: 80.89031350053847 Scheduler overhead time: 0.056452891789376736 Adapter cache time: 0.016017832793295383 Engine time: 0.055218849796801805 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-16/adapters_384_slots_64_rate_0.4-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-16/adapters_384_slots_64_rate_0.4-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 540, 33, 4320, 4320, 33, 540, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 33, 4320, 33, 4320, 540, 540, 540, 33, 33, 540, 33, 4320, 33, 4320, 540, 4320, 540, 33, 540, 4320, 540, 4320, 33, 4320, 4320, 4320, 4320, 33, 540, 540, 540, 4320, 540, 33, 540, 33, 4320, 540, 4320, 4320, 540, 4320, 4320, 33, 33, 4320, 540, 540, 33, 33, 33, 540, 33, 540, 33, 4320, 33, 540, 4320, 33, 4320, 540, 33, 4320, 4320, 4320, 4320, 540, 33, 540, 4320, 4320, 540, 33, 33, 4320, 540, 540, 33, 33, 4320, 540, 4320, 540, 4320, 4320, 540, 4320, 4320, 33, 540, 540, 540, 540, 33, 33, 4320, 33, 4320, 33, 33, 33, 540, 540, 4320, 33, 33, 4320, 33, 4320, 540, 33, 4320, 540, 540, 33, 4320, 4320, 4320, 33, 540, 4320, 33, 4320, 540, 540, 4320, 4320, 33, 540, 4320, 33, 540, 540, 33, 540, 33, 540, 4320, 4320, 540, 33, 4320, 33, 4320, 540, 540, 540, 540, 540, 33, 33, 4320, 33, 4320, 33, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 33, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 33, 33, 33, 33, 33, 540, 33, 33, 540, 4320, 4320, 33, 33, 4320, 33, 33, 33, 540, 33, 540, 4320, 4320, 540, 540, 33, 4320, 540, 4320, 33, 540, 540, 33, 33, 540, 33, 4320, 4320, 33, 4320, 4320, 33, 540, 4320, 33, 33, 540, 540, 33, 33, 4320, 4320, 4320, 4320, 540, 33, 540, 540, 33, 33, 33, 33, 33, 33, 33, 33, 540, 4320, 540, 540, 540, 4320, 33, 540, 540, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 540, 33, 4320, 4320, 4320, 540, 33, 4320, 4320, 540, 540, 4320, 4320, 33, 4320, 4320, 540, 33, 4320, 540, 540, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 540, 4320, 33, 540, 540, 540, 540, 33, 540, 33, 540, 540, 33, 4320, 33, 33, 33, 540, 33, 540, 540, 33, 4320, 540, 4320, 33, 4320, 33, 540, 540, 540, 540, 33, 540, 4320, 4320, 33, 4320, 4320, 33, 4320, 540, 4320, 540, 540, 540, 33, 540, 33, 33, 4320, 33, 540, 33, 33, 540, 4320, 540, 4320, 33, 4320, 4320, 540, 4320, 540, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 626304 . Total input tokens: 139684315 . Total output tokens: 125137764
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 75.99964307388291,
    "estimated_duration": 3600.125471090091,
    "input_throughput": 6150.070095555826,
    "output_throughput": 5437.850474159237,
    "total_throughput": 11587.920569715063,
    "itl": 149.67205083597153,
    "ttft": 1588232.2470494881,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 507,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5870510849240165,
    "arrivals": 208142,
    "finished_requests": 89355,
    "scheduler_time": 165.93118380393
}
#Debug simulation 
Total elapsed time: 75.99977290723473. Arrivals time: 0.3545998907648027 Scheduler time: 75.4984698034823 Scheduler overhead time: 0.0555291217751801 Adapter cache time: 0.01589962560683489 Engine time: 0.05432650074362755 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-32/adapters_384_slots_64_rate_0.4-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-32/adapters_384_slots_64_rate_0.4-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 540, 33, 4320, 4320, 33, 540, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 33, 4320, 33, 4320, 540, 540, 540, 33, 33, 540, 33, 4320, 33, 4320, 540, 4320, 540, 33, 540, 4320, 540, 4320, 33, 4320, 4320, 4320, 4320, 33, 540, 540, 540, 4320, 540, 33, 540, 33, 4320, 540, 4320, 4320, 540, 4320, 4320, 33, 33, 4320, 540, 540, 33, 33, 33, 540, 33, 540, 33, 4320, 33, 540, 4320, 33, 4320, 540, 33, 4320, 4320, 4320, 4320, 540, 33, 540, 4320, 4320, 540, 33, 33, 4320, 540, 540, 33, 33, 4320, 540, 4320, 540, 4320, 4320, 540, 4320, 4320, 33, 540, 540, 540, 540, 33, 33, 4320, 33, 4320, 33, 33, 33, 540, 540, 4320, 33, 33, 4320, 33, 4320, 540, 33, 4320, 540, 540, 33, 4320, 4320, 4320, 33, 540, 4320, 33, 4320, 540, 540, 4320, 4320, 33, 540, 4320, 33, 540, 540, 33, 540, 33, 540, 4320, 4320, 540, 33, 4320, 33, 4320, 540, 540, 540, 540, 540, 33, 33, 4320, 33, 4320, 33, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 33, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 33, 33, 33, 33, 33, 540, 33, 33, 540, 4320, 4320, 33, 33, 4320, 33, 33, 33, 540, 33, 540, 4320, 4320, 540, 540, 33, 4320, 540, 4320, 33, 540, 540, 33, 33, 540, 33, 4320, 4320, 33, 4320, 4320, 33, 540, 4320, 33, 33, 540, 540, 33, 33, 4320, 4320, 4320, 4320, 540, 33, 540, 540, 33, 33, 33, 33, 33, 33, 33, 33, 540, 4320, 540, 540, 540, 4320, 33, 540, 540, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 540, 33, 4320, 4320, 4320, 540, 33, 4320, 4320, 540, 540, 4320, 4320, 33, 4320, 4320, 540, 33, 4320, 540, 540, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 540, 4320, 33, 540, 540, 540, 540, 33, 540, 33, 540, 540, 33, 4320, 33, 33, 33, 540, 33, 540, 540, 33, 4320, 540, 4320, 33, 4320, 33, 540, 540, 540, 540, 33, 540, 4320, 4320, 33, 4320, 4320, 33, 4320, 540, 4320, 540, 540, 540, 33, 540, 33, 33, 4320, 33, 540, 33, 33, 540, 4320, 540, 4320, 33, 4320, 4320, 540, 4320, 540, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 626304 . Total input tokens: 139684315 . Total output tokens: 125137764
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 74.31296805525199,
    "estimated_duration": 3600.0257183445674,
    "input_throughput": 6167.551216886852,
    "output_throughput": 5456.841294187596,
    "total_throughput": 11624.392511074448,
    "itl": 150.65380878571946,
    "ttft": 1584702.0949951878,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 527,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.746087193898861,
    "arrivals": 208142,
    "finished_requests": 89647,
    "scheduler_time": 165.06694908550585
}
#Debug simulation 
Total elapsed time: 74.31309619825333. Arrivals time: 0.37722749914973974 Scheduler time: 73.79236378101632 Scheduler overhead time: 0.05392149183899164 Adapter cache time: 0.015714802779257298 Engine time: 0.05295639391988516 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-16/adapters_384_slots_64_rate_0.4-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-16/adapters_384_slots_64_rate_0.4-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 540, 33, 4320, 4320, 33, 540, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 33, 4320, 33, 4320, 540, 540, 540, 33, 33, 540, 33, 4320, 33, 4320, 540, 4320, 540, 33, 540, 4320, 540, 4320, 33, 4320, 4320, 4320, 4320, 33, 540, 540, 540, 4320, 540, 33, 540, 33, 4320, 540, 4320, 4320, 540, 4320, 4320, 33, 33, 4320, 540, 540, 33, 33, 33, 540, 33, 540, 33, 4320, 33, 540, 4320, 33, 4320, 540, 33, 4320, 4320, 4320, 4320, 540, 33, 540, 4320, 4320, 540, 33, 33, 4320, 540, 540, 33, 33, 4320, 540, 4320, 540, 4320, 4320, 540, 4320, 4320, 33, 540, 540, 540, 540, 33, 33, 4320, 33, 4320, 33, 33, 33, 540, 540, 4320, 33, 33, 4320, 33, 4320, 540, 33, 4320, 540, 540, 33, 4320, 4320, 4320, 33, 540, 4320, 33, 4320, 540, 540, 4320, 4320, 33, 540, 4320, 33, 540, 540, 33, 540, 33, 540, 4320, 4320, 540, 33, 4320, 33, 4320, 540, 540, 540, 540, 540, 33, 33, 4320, 33, 4320, 33, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 33, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 33, 33, 33, 33, 33, 540, 33, 33, 540, 4320, 4320, 33, 33, 4320, 33, 33, 33, 540, 33, 540, 4320, 4320, 540, 540, 33, 4320, 540, 4320, 33, 540, 540, 33, 33, 540, 33, 4320, 4320, 33, 4320, 4320, 33, 540, 4320, 33, 33, 540, 540, 33, 33, 4320, 4320, 4320, 4320, 540, 33, 540, 540, 33, 33, 33, 33, 33, 33, 33, 33, 540, 4320, 540, 540, 540, 4320, 33, 540, 540, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 540, 33, 4320, 4320, 4320, 540, 33, 4320, 4320, 540, 540, 4320, 4320, 33, 4320, 4320, 540, 33, 4320, 540, 540, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 540, 4320, 33, 540, 540, 540, 540, 33, 540, 33, 540, 540, 33, 4320, 33, 33, 33, 540, 33, 540, 540, 33, 4320, 540, 4320, 33, 4320, 33, 540, 540, 540, 540, 33, 540, 4320, 4320, 33, 4320, 4320, 33, 4320, 540, 4320, 540, 540, 540, 33, 540, 33, 33, 4320, 33, 540, 33, 33, 540, 4320, 540, 4320, 33, 4320, 4320, 540, 4320, 540, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 626304 . Total input tokens: 139684315 . Total output tokens: 125137764
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 80.35291994502768,
    "estimated_duration": 3600.145563443313,
    "input_throughput": 6156.502732850955,
    "output_throughput": 5449.864916360329,
    "total_throughput": 11606.367649211285,
    "itl": 150.4631376013548,
    "ttft": 1576635.554156528,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 515,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5398759018746027,
    "arrivals": 208142,
    "finished_requests": 89511,
    "scheduler_time": 165.4883419997304
}
#Debug simulation 
Total elapsed time: 80.35305447783321. Arrivals time: 0.39124691020697355 Scheduler time: 79.81458629248664 Scheduler overhead time: 0.05564420251175761 Adapter cache time: 0.016226171515882015 Engine time: 0.05450343945994973 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-32/adapters_384_slots_64_rate_0.4-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-32/adapters_384_slots_64_rate_0.4-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 540, 33, 4320, 4320, 33, 540, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 33, 4320, 33, 4320, 540, 540, 540, 33, 33, 540, 33, 4320, 33, 4320, 540, 4320, 540, 33, 540, 4320, 540, 4320, 33, 4320, 4320, 4320, 4320, 33, 540, 540, 540, 4320, 540, 33, 540, 33, 4320, 540, 4320, 4320, 540, 4320, 4320, 33, 33, 4320, 540, 540, 33, 33, 33, 540, 33, 540, 33, 4320, 33, 540, 4320, 33, 4320, 540, 33, 4320, 4320, 4320, 4320, 540, 33, 540, 4320, 4320, 540, 33, 33, 4320, 540, 540, 33, 33, 4320, 540, 4320, 540, 4320, 4320, 540, 4320, 4320, 33, 540, 540, 540, 540, 33, 33, 4320, 33, 4320, 33, 33, 33, 540, 540, 4320, 33, 33, 4320, 33, 4320, 540, 33, 4320, 540, 540, 33, 4320, 4320, 4320, 33, 540, 4320, 33, 4320, 540, 540, 4320, 4320, 33, 540, 4320, 33, 540, 540, 33, 540, 33, 540, 4320, 4320, 540, 33, 4320, 33, 4320, 540, 540, 540, 540, 540, 33, 33, 4320, 33, 4320, 33, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 33, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 33, 33, 33, 33, 33, 540, 33, 33, 540, 4320, 4320, 33, 33, 4320, 33, 33, 33, 540, 33, 540, 4320, 4320, 540, 540, 33, 4320, 540, 4320, 33, 540, 540, 33, 33, 540, 33, 4320, 4320, 33, 4320, 4320, 33, 540, 4320, 33, 33, 540, 540, 33, 33, 4320, 4320, 4320, 4320, 540, 33, 540, 540, 33, 33, 33, 33, 33, 33, 33, 33, 540, 4320, 540, 540, 540, 4320, 33, 540, 540, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 540, 33, 4320, 4320, 4320, 540, 33, 4320, 4320, 540, 540, 4320, 4320, 33, 4320, 4320, 540, 33, 4320, 540, 540, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 540, 4320, 33, 540, 540, 540, 540, 33, 540, 33, 540, 540, 33, 4320, 33, 33, 33, 540, 33, 540, 540, 33, 4320, 540, 4320, 33, 4320, 33, 540, 540, 540, 540, 33, 540, 4320, 4320, 33, 4320, 4320, 33, 4320, 540, 4320, 540, 540, 540, 33, 540, 33, 33, 4320, 33, 540, 33, 33, 540, 4320, 540, 4320, 33, 4320, 4320, 540, 4320, 540, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 626304 . Total input tokens: 139684315 . Total output tokens: 125137764
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 74.31101257912815,
    "estimated_duration": 3600.0491578604724,
    "input_throughput": 6167.511060653283,
    "output_throughput": 5456.805765306545,
    "total_throughput": 11624.316825959828,
    "itl": 150.65391647975233,
    "ttft": 1584712.1742176863,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 527,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7692258905991887,
    "arrivals": 208142,
    "finished_requests": 89647,
    "scheduler_time": 165.0675139557741
}
#Debug simulation 
Total elapsed time: 74.31115080416203. Arrivals time: 0.38779952516779304 Scheduler time: 73.77906999457628 Scheduler overhead time: 0.0538900806568563 Adapter cache time: 0.016037691850215197 Engine time: 0.05362922418862581 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-8/adapters_384_slots_64_rate_0.4-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-8/adapters_384_slots_64_rate_0.4-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 4320, 270, 135, 4320, 4320, 135, 270, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 135, 4320, 135, 4320, 270, 270, 270, 135, 135, 270, 135, 4320, 135, 4320, 270, 4320, 270, 135, 270, 4320, 270, 4320, 135, 4320, 4320, 4320, 4320, 135, 270, 270, 270, 4320, 270, 135, 270, 135, 4320, 270, 4320, 4320, 270, 4320, 4320, 135, 135, 4320, 270, 270, 135, 135, 135, 270, 135, 270, 135, 4320, 135, 270, 4320, 135, 4320, 270, 135, 4320, 4320, 4320, 4320, 270, 135, 270, 4320, 4320, 270, 135, 135, 4320, 270, 270, 135, 135, 4320, 270, 4320, 270, 4320, 4320, 270, 4320, 4320, 135, 270, 270, 270, 270, 135, 135, 4320, 135, 4320, 135, 135, 135, 270, 270, 4320, 135, 135, 4320, 135, 4320, 270, 135, 4320, 270, 270, 135, 4320, 4320, 4320, 135, 270, 4320, 135, 4320, 270, 270, 4320, 4320, 135, 270, 4320, 135, 270, 270, 135, 270, 135, 270, 4320, 4320, 270, 135, 4320, 135, 4320, 270, 270, 270, 270, 270, 135, 135, 4320, 135, 4320, 135, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 135, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 135, 135, 135, 135, 135, 270, 135, 135, 270, 4320, 4320, 135, 135, 4320, 135, 135, 135, 270, 135, 270, 4320, 4320, 270, 270, 135, 4320, 270, 4320, 135, 270, 270, 135, 135, 270, 135, 4320, 4320, 135, 4320, 4320, 135, 270, 4320, 135, 135, 270, 270, 135, 135, 4320, 4320, 4320, 4320, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 4320, 270, 270, 270, 4320, 135, 270, 270, 4320, 4320, 135, 4320, 4320, 135, 4320, 135, 135, 270, 135, 4320, 4320, 4320, 270, 135, 4320, 4320, 270, 270, 4320, 4320, 135, 4320, 4320, 270, 135, 4320, 270, 270, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 4320, 135, 270, 4320, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 4320, 135, 135, 135, 270, 135, 270, 270, 135, 4320, 270, 4320, 135, 4320, 135, 270, 270, 270, 270, 135, 270, 4320, 4320, 135, 4320, 4320, 135, 4320, 270, 4320, 270, 270, 270, 135, 270, 135, 135, 4320, 135, 270, 135, 135, 270, 4320, 270, 4320, 135, 4320, 4320, 270, 4320, 270, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 604800 . Total input tokens: 134855028 . Total output tokens: 120795858
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 71.85461746994406,
    "estimated_duration": 3600.0227673777713,
    "input_throughput": 6122.575168060615,
    "output_throughput": 5414.563534607372,
    "total_throughput": 11537.138702667988,
    "itl": 148.634033225327,
    "ttft": 1573554.8938504038,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 575,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7597804527613585,
    "arrivals": 200966,
    "finished_requests": 88757,
    "scheduler_time": 166.47750387705705
}
#Debug simulation 
Total elapsed time: 71.85476062493399. Arrivals time: 0.3823602246120572 Scheduler time: 71.3294655685313 Scheduler overhead time: 0.05363392736762762 Adapter cache time: 0.016696710605174303 Engine time: 0.051796986255794764 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-16/adapters_384_slots_64_rate_0.4-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-16/adapters_384_slots_64_rate_0.4-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 4320, 270, 135, 4320, 4320, 135, 270, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 135, 4320, 135, 4320, 270, 270, 270, 135, 135, 270, 135, 4320, 135, 4320, 270, 4320, 270, 135, 270, 4320, 270, 4320, 135, 4320, 4320, 4320, 4320, 135, 270, 270, 270, 4320, 270, 135, 270, 135, 4320, 270, 4320, 4320, 270, 4320, 4320, 135, 135, 4320, 270, 270, 135, 135, 135, 270, 135, 270, 135, 4320, 135, 270, 4320, 135, 4320, 270, 135, 4320, 4320, 4320, 4320, 270, 135, 270, 4320, 4320, 270, 135, 135, 4320, 270, 270, 135, 135, 4320, 270, 4320, 270, 4320, 4320, 270, 4320, 4320, 135, 270, 270, 270, 270, 135, 135, 4320, 135, 4320, 135, 135, 135, 270, 270, 4320, 135, 135, 4320, 135, 4320, 270, 135, 4320, 270, 270, 135, 4320, 4320, 4320, 135, 270, 4320, 135, 4320, 270, 270, 4320, 4320, 135, 270, 4320, 135, 270, 270, 135, 270, 135, 270, 4320, 4320, 270, 135, 4320, 135, 4320, 270, 270, 270, 270, 270, 135, 135, 4320, 135, 4320, 135, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 135, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 135, 135, 135, 135, 135, 270, 135, 135, 270, 4320, 4320, 135, 135, 4320, 135, 135, 135, 270, 135, 270, 4320, 4320, 270, 270, 135, 4320, 270, 4320, 135, 270, 270, 135, 135, 270, 135, 4320, 4320, 135, 4320, 4320, 135, 270, 4320, 135, 135, 270, 270, 135, 135, 4320, 4320, 4320, 4320, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 4320, 270, 270, 270, 4320, 135, 270, 270, 4320, 4320, 135, 4320, 4320, 135, 4320, 135, 135, 270, 135, 4320, 4320, 4320, 270, 135, 4320, 4320, 270, 270, 4320, 4320, 135, 4320, 4320, 270, 135, 4320, 270, 270, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 4320, 135, 270, 4320, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 4320, 135, 135, 135, 270, 135, 270, 270, 135, 4320, 270, 4320, 135, 4320, 135, 270, 270, 270, 270, 135, 270, 4320, 4320, 135, 4320, 4320, 135, 4320, 270, 4320, 270, 270, 270, 135, 270, 135, 135, 4320, 135, 270, 135, 135, 270, 4320, 270, 4320, 135, 4320, 4320, 270, 4320, 270, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 604800 . Total input tokens: 134855028 . Total output tokens: 120795858
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 72.28172494098544,
    "estimated_duration": 3600.1519798669806,
    "input_throughput": 6124.845874094105,
    "output_throughput": 5414.371145720414,
    "total_throughput": 11539.21701981452,
    "itl": 148.47687495931063,
    "ttft": 1574714.7531054227,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 579,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8852795558003743,
    "arrivals": 200966,
    "finished_requests": 88767,
    "scheduler_time": 166.50292582403458
}
#Debug simulation 
Total elapsed time: 72.2818707623519. Arrivals time: 0.37064804416149855 Scheduler time: 71.76559443864971 Scheduler overhead time: 0.054831359069794416 Adapter cache time: 0.016738705337047577 Engine time: 0.05314487498253584 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-32/adapters_384_slots_64_rate_0.4-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-32/adapters_384_slots_64_rate_0.4-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 4320, 270, 135, 4320, 4320, 135, 270, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 135, 4320, 135, 4320, 270, 270, 270, 135, 135, 270, 135, 4320, 135, 4320, 270, 4320, 270, 135, 270, 4320, 270, 4320, 135, 4320, 4320, 4320, 4320, 135, 270, 270, 270, 4320, 270, 135, 270, 135, 4320, 270, 4320, 4320, 270, 4320, 4320, 135, 135, 4320, 270, 270, 135, 135, 135, 270, 135, 270, 135, 4320, 135, 270, 4320, 135, 4320, 270, 135, 4320, 4320, 4320, 4320, 270, 135, 270, 4320, 4320, 270, 135, 135, 4320, 270, 270, 135, 135, 4320, 270, 4320, 270, 4320, 4320, 270, 4320, 4320, 135, 270, 270, 270, 270, 135, 135, 4320, 135, 4320, 135, 135, 135, 270, 270, 4320, 135, 135, 4320, 135, 4320, 270, 135, 4320, 270, 270, 135, 4320, 4320, 4320, 135, 270, 4320, 135, 4320, 270, 270, 4320, 4320, 135, 270, 4320, 135, 270, 270, 135, 270, 135, 270, 4320, 4320, 270, 135, 4320, 135, 4320, 270, 270, 270, 270, 270, 135, 135, 4320, 135, 4320, 135, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 135, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 135, 135, 135, 135, 135, 270, 135, 135, 270, 4320, 4320, 135, 135, 4320, 135, 135, 135, 270, 135, 270, 4320, 4320, 270, 270, 135, 4320, 270, 4320, 135, 270, 270, 135, 135, 270, 135, 4320, 4320, 135, 4320, 4320, 135, 270, 4320, 135, 135, 270, 270, 135, 135, 4320, 4320, 4320, 4320, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 4320, 270, 270, 270, 4320, 135, 270, 270, 4320, 4320, 135, 4320, 4320, 135, 4320, 135, 135, 270, 135, 4320, 4320, 4320, 270, 135, 4320, 4320, 270, 270, 4320, 4320, 135, 4320, 4320, 270, 135, 4320, 270, 270, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 4320, 135, 270, 4320, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 4320, 135, 135, 135, 270, 135, 270, 270, 135, 4320, 270, 4320, 135, 4320, 135, 270, 270, 270, 270, 135, 270, 4320, 4320, 135, 4320, 4320, 135, 4320, 270, 4320, 270, 270, 270, 135, 270, 135, 135, 4320, 135, 270, 135, 135, 270, 4320, 270, 4320, 135, 4320, 4320, 270, 4320, 270, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 604800 . Total input tokens: 134855028 . Total output tokens: 120795858
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 72.24577170191333,
    "estimated_duration": 3600.1563286114747,
    "input_throughput": 6124.838475695997,
    "output_throughput": 5414.364605527556,
    "total_throughput": 11539.203081223552,
    "itl": 148.4768306823252,
    "ttft": 1574716.4004968237,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 579,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8893397188745555,
    "arrivals": 200966,
    "finished_requests": 88767,
    "scheduler_time": 166.50307516748813
}
#Debug simulation 
Total elapsed time: 72.24592075217515. Arrivals time: 0.3573153023608029 Scheduler time: 71.7436482612975 Scheduler overhead time: 0.05424801493063569 Adapter cache time: 0.01717613311484456 Engine time: 0.052471624221652746 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-16/adapters_384_slots_64_rate_0.4-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-16/adapters_384_slots_64_rate_0.4-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 4320, 270, 135, 4320, 4320, 135, 270, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 135, 4320, 135, 4320, 270, 270, 270, 135, 135, 270, 135, 4320, 135, 4320, 270, 4320, 270, 135, 270, 4320, 270, 4320, 135, 4320, 4320, 4320, 4320, 135, 270, 270, 270, 4320, 270, 135, 270, 135, 4320, 270, 4320, 4320, 270, 4320, 4320, 135, 135, 4320, 270, 270, 135, 135, 135, 270, 135, 270, 135, 4320, 135, 270, 4320, 135, 4320, 270, 135, 4320, 4320, 4320, 4320, 270, 135, 270, 4320, 4320, 270, 135, 135, 4320, 270, 270, 135, 135, 4320, 270, 4320, 270, 4320, 4320, 270, 4320, 4320, 135, 270, 270, 270, 270, 135, 135, 4320, 135, 4320, 135, 135, 135, 270, 270, 4320, 135, 135, 4320, 135, 4320, 270, 135, 4320, 270, 270, 135, 4320, 4320, 4320, 135, 270, 4320, 135, 4320, 270, 270, 4320, 4320, 135, 270, 4320, 135, 270, 270, 135, 270, 135, 270, 4320, 4320, 270, 135, 4320, 135, 4320, 270, 270, 270, 270, 270, 135, 135, 4320, 135, 4320, 135, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 135, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 135, 135, 135, 135, 135, 270, 135, 135, 270, 4320, 4320, 135, 135, 4320, 135, 135, 135, 270, 135, 270, 4320, 4320, 270, 270, 135, 4320, 270, 4320, 135, 270, 270, 135, 135, 270, 135, 4320, 4320, 135, 4320, 4320, 135, 270, 4320, 135, 135, 270, 270, 135, 135, 4320, 4320, 4320, 4320, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 4320, 270, 270, 270, 4320, 135, 270, 270, 4320, 4320, 135, 4320, 4320, 135, 4320, 135, 135, 270, 135, 4320, 4320, 4320, 270, 135, 4320, 4320, 270, 270, 4320, 4320, 135, 4320, 4320, 270, 135, 4320, 270, 270, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 4320, 135, 270, 4320, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 4320, 135, 135, 135, 270, 135, 270, 270, 135, 4320, 270, 4320, 135, 4320, 135, 270, 270, 270, 270, 135, 270, 4320, 4320, 135, 4320, 4320, 135, 4320, 270, 4320, 270, 270, 270, 135, 270, 135, 135, 4320, 135, 270, 135, 135, 270, 4320, 270, 4320, 135, 4320, 4320, 270, 4320, 270, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 604800 . Total input tokens: 134855028 . Total output tokens: 120795858
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 72.35809312481433,
    "estimated_duration": 3600.1007699052793,
    "input_throughput": 6123.721642541701,
    "output_throughput": 5413.885956451382,
    "total_throughput": 11537.607598993083,
    "itl": 148.65262678910713,
    "ttft": 1573552.9144398281,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 580,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8151310440944397,
    "arrivals": 200966,
    "finished_requests": 88739,
    "scheduler_time": 166.45189549221251
}
#Debug simulation 
Total elapsed time: 72.3582312068902. Arrivals time: 0.3643197393976152 Scheduler time: 71.84845465933904 Scheduler overhead time: 0.05434190109372139 Adapter cache time: 0.016929018311202526 Engine time: 0.053012619726359844 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-32/adapters_384_slots_64_rate_0.4-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-32/adapters_384_slots_64_rate_0.4-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 4320, 270, 135, 4320, 4320, 135, 270, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 135, 4320, 135, 4320, 270, 270, 270, 135, 135, 270, 135, 4320, 135, 4320, 270, 4320, 270, 135, 270, 4320, 270, 4320, 135, 4320, 4320, 4320, 4320, 135, 270, 270, 270, 4320, 270, 135, 270, 135, 4320, 270, 4320, 4320, 270, 4320, 4320, 135, 135, 4320, 270, 270, 135, 135, 135, 270, 135, 270, 135, 4320, 135, 270, 4320, 135, 4320, 270, 135, 4320, 4320, 4320, 4320, 270, 135, 270, 4320, 4320, 270, 135, 135, 4320, 270, 270, 135, 135, 4320, 270, 4320, 270, 4320, 4320, 270, 4320, 4320, 135, 270, 270, 270, 270, 135, 135, 4320, 135, 4320, 135, 135, 135, 270, 270, 4320, 135, 135, 4320, 135, 4320, 270, 135, 4320, 270, 270, 135, 4320, 4320, 4320, 135, 270, 4320, 135, 4320, 270, 270, 4320, 4320, 135, 270, 4320, 135, 270, 270, 135, 270, 135, 270, 4320, 4320, 270, 135, 4320, 135, 4320, 270, 270, 270, 270, 270, 135, 135, 4320, 135, 4320, 135, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 135, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 135, 135, 135, 135, 135, 270, 135, 135, 270, 4320, 4320, 135, 135, 4320, 135, 135, 135, 270, 135, 270, 4320, 4320, 270, 270, 135, 4320, 270, 4320, 135, 270, 270, 135, 135, 270, 135, 4320, 4320, 135, 4320, 4320, 135, 270, 4320, 135, 135, 270, 270, 135, 135, 4320, 4320, 4320, 4320, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 4320, 270, 270, 270, 4320, 135, 270, 270, 4320, 4320, 135, 4320, 4320, 135, 4320, 135, 135, 270, 135, 4320, 4320, 4320, 270, 135, 4320, 4320, 270, 270, 4320, 4320, 135, 4320, 4320, 270, 135, 4320, 270, 270, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 4320, 135, 270, 4320, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 4320, 135, 135, 135, 270, 135, 270, 270, 135, 4320, 270, 4320, 135, 4320, 135, 270, 270, 270, 270, 135, 270, 4320, 4320, 135, 4320, 4320, 135, 4320, 270, 4320, 270, 270, 270, 135, 270, 135, 135, 4320, 135, 270, 135, 135, 270, 4320, 270, 4320, 135, 4320, 4320, 270, 4320, 270, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 604800 . Total input tokens: 134855028 . Total output tokens: 120795858
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 72.656676792074,
    "estimated_duration": 3600.0088082152665,
    "input_throughput": 6124.9072362496045,
    "output_throughput": 5414.2500861443705,
    "total_throughput": 11539.157322393976,
    "itl": 148.47604730742867,
    "ttft": 1574677.7760831984,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 579,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9123526617884674,
    "arrivals": 200966,
    "finished_requests": 88763,
    "scheduler_time": 166.4951678875436
}
#Debug simulation 
Total elapsed time: 72.65681252488866. Arrivals time: 0.3821906396187842 Scheduler time: 72.12993497401476 Scheduler overhead time: 0.05406195996329188 Adapter cache time: 0.017243182752281427 Engine time: 0.05247754557058215 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-16/adapters_384_slots_64_rate_0.4-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-16/adapters_384_slots_64_rate_0.4-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 4320, 270, 135, 4320, 4320, 135, 270, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 135, 4320, 135, 4320, 270, 270, 270, 135, 135, 270, 135, 4320, 135, 4320, 270, 4320, 270, 135, 270, 4320, 270, 4320, 135, 4320, 4320, 4320, 4320, 135, 270, 270, 270, 4320, 270, 135, 270, 135, 4320, 270, 4320, 4320, 270, 4320, 4320, 135, 135, 4320, 270, 270, 135, 135, 135, 270, 135, 270, 135, 4320, 135, 270, 4320, 135, 4320, 270, 135, 4320, 4320, 4320, 4320, 270, 135, 270, 4320, 4320, 270, 135, 135, 4320, 270, 270, 135, 135, 4320, 270, 4320, 270, 4320, 4320, 270, 4320, 4320, 135, 270, 270, 270, 270, 135, 135, 4320, 135, 4320, 135, 135, 135, 270, 270, 4320, 135, 135, 4320, 135, 4320, 270, 135, 4320, 270, 270, 135, 4320, 4320, 4320, 135, 270, 4320, 135, 4320, 270, 270, 4320, 4320, 135, 270, 4320, 135, 270, 270, 135, 270, 135, 270, 4320, 4320, 270, 135, 4320, 135, 4320, 270, 270, 270, 270, 270, 135, 135, 4320, 135, 4320, 135, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 135, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 135, 135, 135, 135, 135, 270, 135, 135, 270, 4320, 4320, 135, 135, 4320, 135, 135, 135, 270, 135, 270, 4320, 4320, 270, 270, 135, 4320, 270, 4320, 135, 270, 270, 135, 135, 270, 135, 4320, 4320, 135, 4320, 4320, 135, 270, 4320, 135, 135, 270, 270, 135, 135, 4320, 4320, 4320, 4320, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 4320, 270, 270, 270, 4320, 135, 270, 270, 4320, 4320, 135, 4320, 4320, 135, 4320, 135, 135, 270, 135, 4320, 4320, 4320, 270, 135, 4320, 4320, 270, 270, 4320, 4320, 135, 4320, 4320, 270, 135, 4320, 270, 270, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 4320, 135, 270, 4320, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 4320, 135, 135, 135, 270, 135, 270, 270, 135, 4320, 270, 4320, 135, 4320, 135, 270, 270, 270, 270, 135, 270, 4320, 4320, 135, 4320, 4320, 135, 4320, 270, 4320, 270, 270, 270, 135, 270, 135, 135, 4320, 135, 270, 135, 135, 270, 4320, 270, 4320, 135, 4320, 4320, 270, 4320, 270, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 604800 . Total input tokens: 134855028 . Total output tokens: 120795858
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 71.52877036016434,
    "estimated_duration": 3600.021636720132,
    "input_throughput": 6119.904329261887,
    "output_throughput": 5412.0677501679875,
    "total_throughput": 11531.972079429874,
    "itl": 148.56319222177467,
    "ttft": 1574761.3598505363,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 586,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7521694728126496,
    "arrivals": 200966,
    "finished_requests": 88730,
    "scheduler_time": 166.57769846231136
}
#Debug simulation 
Total elapsed time: 71.5289146960713. Arrivals time: 0.3827806767076254 Scheduler time: 71.00267441477627 Scheduler overhead time: 0.05302682938054204 Adapter cache time: 0.016997414175421 Engine time: 0.05279336357489228 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-32/adapters_384_slots_64_rate_0.4-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-32/adapters_384_slots_64_rate_0.4-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 4320, 270, 135, 4320, 4320, 135, 270, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 135, 4320, 135, 4320, 270, 270, 270, 135, 135, 270, 135, 4320, 135, 4320, 270, 4320, 270, 135, 270, 4320, 270, 4320, 135, 4320, 4320, 4320, 4320, 135, 270, 270, 270, 4320, 270, 135, 270, 135, 4320, 270, 4320, 4320, 270, 4320, 4320, 135, 135, 4320, 270, 270, 135, 135, 135, 270, 135, 270, 135, 4320, 135, 270, 4320, 135, 4320, 270, 135, 4320, 4320, 4320, 4320, 270, 135, 270, 4320, 4320, 270, 135, 135, 4320, 270, 270, 135, 135, 4320, 270, 4320, 270, 4320, 4320, 270, 4320, 4320, 135, 270, 270, 270, 270, 135, 135, 4320, 135, 4320, 135, 135, 135, 270, 270, 4320, 135, 135, 4320, 135, 4320, 270, 135, 4320, 270, 270, 135, 4320, 4320, 4320, 135, 270, 4320, 135, 4320, 270, 270, 4320, 4320, 135, 270, 4320, 135, 270, 270, 135, 270, 135, 270, 4320, 4320, 270, 135, 4320, 135, 4320, 270, 270, 270, 270, 270, 135, 135, 4320, 135, 4320, 135, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 135, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 135, 135, 135, 135, 135, 270, 135, 135, 270, 4320, 4320, 135, 135, 4320, 135, 135, 135, 270, 135, 270, 4320, 4320, 270, 270, 135, 4320, 270, 4320, 135, 270, 270, 135, 135, 270, 135, 4320, 4320, 135, 4320, 4320, 135, 270, 4320, 135, 135, 270, 270, 135, 135, 4320, 4320, 4320, 4320, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 4320, 270, 270, 270, 4320, 135, 270, 270, 4320, 4320, 135, 4320, 4320, 135, 4320, 135, 135, 270, 135, 4320, 4320, 4320, 270, 135, 4320, 4320, 270, 270, 4320, 4320, 135, 4320, 4320, 270, 135, 4320, 270, 270, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 4320, 135, 270, 4320, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 4320, 135, 135, 135, 270, 135, 270, 270, 135, 4320, 270, 4320, 135, 4320, 135, 270, 270, 270, 270, 135, 270, 4320, 4320, 135, 4320, 4320, 135, 4320, 270, 4320, 270, 270, 270, 135, 270, 135, 135, 4320, 135, 270, 135, 135, 270, 4320, 270, 4320, 135, 4320, 4320, 270, 4320, 270, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 604800 . Total input tokens: 134855028 . Total output tokens: 120795858
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 72.269546110183,
    "estimated_duration": 3600.0355479976606,
    "input_throughput": 6124.861742619195,
    "output_throughput": 5414.20987102227,
    "total_throughput": 11539.071613641465,
    "itl": 148.47624988349727,
    "ttft": 1574688.8677289481,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 579,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9367488963529438,
    "arrivals": 200966,
    "finished_requests": 88763,
    "scheduler_time": 166.49579641697915
}
#Debug simulation 
Total elapsed time: 72.2696905080229. Arrivals time: 0.3867704630829394 Scheduler time: 71.73794941883534 Scheduler overhead time: 0.05387032311409712 Adapter cache time: 0.017097192350775003 Engine time: 0.0527277197688818 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-8/adapters_384_slots_64_rate_0.4-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-8/adapters_384_slots_64_rate_0.4-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 270, 66, 4320, 4320, 66, 270, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 66, 4320, 66, 4320, 270, 270, 270, 66, 66, 270, 66, 4320, 66, 4320, 270, 4320, 270, 66, 270, 4320, 270, 4320, 66, 4320, 4320, 4320, 4320, 66, 270, 270, 270, 4320, 270, 66, 270, 66, 4320, 270, 4320, 4320, 270, 4320, 4320, 66, 66, 4320, 270, 270, 66, 66, 66, 270, 66, 270, 66, 4320, 66, 270, 4320, 66, 4320, 270, 66, 4320, 4320, 4320, 4320, 270, 66, 270, 4320, 4320, 270, 66, 66, 4320, 270, 270, 66, 66, 4320, 270, 4320, 270, 4320, 4320, 270, 4320, 4320, 66, 270, 270, 270, 270, 66, 66, 4320, 66, 4320, 66, 66, 66, 270, 270, 4320, 66, 66, 4320, 66, 4320, 270, 66, 4320, 270, 270, 66, 4320, 4320, 4320, 66, 270, 4320, 66, 4320, 270, 270, 4320, 4320, 66, 270, 4320, 66, 270, 270, 66, 270, 66, 270, 4320, 4320, 270, 66, 4320, 66, 4320, 270, 270, 270, 270, 270, 66, 66, 4320, 66, 4320, 66, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 66, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 66, 66, 66, 66, 66, 270, 66, 66, 270, 4320, 4320, 66, 66, 4320, 66, 66, 66, 270, 66, 270, 4320, 4320, 270, 270, 66, 4320, 270, 4320, 66, 270, 270, 66, 66, 270, 66, 4320, 4320, 66, 4320, 4320, 66, 270, 4320, 66, 66, 270, 270, 66, 66, 4320, 4320, 4320, 4320, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 4320, 270, 270, 270, 4320, 66, 270, 270, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 270, 66, 4320, 4320, 4320, 270, 66, 4320, 4320, 270, 270, 4320, 4320, 66, 4320, 4320, 270, 66, 4320, 270, 270, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 270, 4320, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 4320, 66, 66, 66, 270, 66, 270, 270, 66, 4320, 270, 4320, 66, 4320, 66, 270, 270, 270, 270, 66, 270, 4320, 4320, 66, 4320, 4320, 66, 4320, 270, 4320, 270, 270, 270, 66, 270, 66, 66, 4320, 66, 270, 66, 66, 270, 4320, 270, 4320, 66, 4320, 4320, 270, 4320, 270, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 595968 . Total input tokens: 132907362 . Total output tokens: 119020776
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 69.8015755400993,
    "estimated_duration": 3600.0585736942803,
    "input_throughput": 6134.306580833809,
    "output_throughput": 5419.542377050463,
    "total_throughput": 11553.848957884273,
    "itl": 148.6900240898957,
    "ttft": 1566512.5692711323,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 596,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8240506953839486,
    "arrivals": 198105,
    "finished_requests": 89190,
    "scheduler_time": 166.16316146421218
}
#Debug simulation 
Total elapsed time: 69.80171989509836. Arrivals time: 0.3564310632646084 Scheduler time: 69.3007776523009 Scheduler overhead time: 0.053857837338000536 Adapter cache time: 0.01697898656129837 Engine time: 0.05343972286209464 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-16/adapters_384_slots_64_rate_0.4-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-16/adapters_384_slots_64_rate_0.4-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 270, 66, 4320, 4320, 66, 270, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 66, 4320, 66, 4320, 270, 270, 270, 66, 66, 270, 66, 4320, 66, 4320, 270, 4320, 270, 66, 270, 4320, 270, 4320, 66, 4320, 4320, 4320, 4320, 66, 270, 270, 270, 4320, 270, 66, 270, 66, 4320, 270, 4320, 4320, 270, 4320, 4320, 66, 66, 4320, 270, 270, 66, 66, 66, 270, 66, 270, 66, 4320, 66, 270, 4320, 66, 4320, 270, 66, 4320, 4320, 4320, 4320, 270, 66, 270, 4320, 4320, 270, 66, 66, 4320, 270, 270, 66, 66, 4320, 270, 4320, 270, 4320, 4320, 270, 4320, 4320, 66, 270, 270, 270, 270, 66, 66, 4320, 66, 4320, 66, 66, 66, 270, 270, 4320, 66, 66, 4320, 66, 4320, 270, 66, 4320, 270, 270, 66, 4320, 4320, 4320, 66, 270, 4320, 66, 4320, 270, 270, 4320, 4320, 66, 270, 4320, 66, 270, 270, 66, 270, 66, 270, 4320, 4320, 270, 66, 4320, 66, 4320, 270, 270, 270, 270, 270, 66, 66, 4320, 66, 4320, 66, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 66, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 66, 66, 66, 66, 66, 270, 66, 66, 270, 4320, 4320, 66, 66, 4320, 66, 66, 66, 270, 66, 270, 4320, 4320, 270, 270, 66, 4320, 270, 4320, 66, 270, 270, 66, 66, 270, 66, 4320, 4320, 66, 4320, 4320, 66, 270, 4320, 66, 66, 270, 270, 66, 66, 4320, 4320, 4320, 4320, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 4320, 270, 270, 270, 4320, 66, 270, 270, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 270, 66, 4320, 4320, 4320, 270, 66, 4320, 4320, 270, 270, 4320, 4320, 66, 4320, 4320, 270, 66, 4320, 270, 270, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 270, 4320, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 4320, 66, 66, 66, 270, 66, 270, 270, 66, 4320, 270, 4320, 66, 4320, 66, 270, 270, 270, 270, 66, 270, 4320, 4320, 66, 4320, 4320, 66, 4320, 270, 4320, 270, 270, 270, 66, 270, 66, 66, 4320, 66, 270, 66, 66, 270, 4320, 270, 4320, 66, 4320, 4320, 270, 4320, 270, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 595968 . Total input tokens: 132907362 . Total output tokens: 119020776
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 70.89044202119112,
    "estimated_duration": 3600.058006820923,
    "input_throughput": 6126.135456210456,
    "output_throughput": 5410.063660946122,
    "total_throughput": 11536.199117156579,
    "itl": 148.39697629534945,
    "ttft": 1568834.8913753396,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 590,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.925116229457786,
    "arrivals": 198105,
    "finished_requests": 89047,
    "scheduler_time": 166.40422542154954
}
#Debug simulation 
Total elapsed time: 70.89057804830372. Arrivals time: 0.34851985052227974 Scheduler time: 70.39840997057036 Scheduler overhead time: 0.0535069671459496 Adapter cache time: 0.016813875641673803 Engine time: 0.05276331910863519 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-32/adapters_384_slots_64_rate_0.4-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-32/adapters_384_slots_64_rate_0.4-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 270, 66, 4320, 4320, 66, 270, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 66, 4320, 66, 4320, 270, 270, 270, 66, 66, 270, 66, 4320, 66, 4320, 270, 4320, 270, 66, 270, 4320, 270, 4320, 66, 4320, 4320, 4320, 4320, 66, 270, 270, 270, 4320, 270, 66, 270, 66, 4320, 270, 4320, 4320, 270, 4320, 4320, 66, 66, 4320, 270, 270, 66, 66, 66, 270, 66, 270, 66, 4320, 66, 270, 4320, 66, 4320, 270, 66, 4320, 4320, 4320, 4320, 270, 66, 270, 4320, 4320, 270, 66, 66, 4320, 270, 270, 66, 66, 4320, 270, 4320, 270, 4320, 4320, 270, 4320, 4320, 66, 270, 270, 270, 270, 66, 66, 4320, 66, 4320, 66, 66, 66, 270, 270, 4320, 66, 66, 4320, 66, 4320, 270, 66, 4320, 270, 270, 66, 4320, 4320, 4320, 66, 270, 4320, 66, 4320, 270, 270, 4320, 4320, 66, 270, 4320, 66, 270, 270, 66, 270, 66, 270, 4320, 4320, 270, 66, 4320, 66, 4320, 270, 270, 270, 270, 270, 66, 66, 4320, 66, 4320, 66, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 66, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 66, 66, 66, 66, 66, 270, 66, 66, 270, 4320, 4320, 66, 66, 4320, 66, 66, 66, 270, 66, 270, 4320, 4320, 270, 270, 66, 4320, 270, 4320, 66, 270, 270, 66, 66, 270, 66, 4320, 4320, 66, 4320, 4320, 66, 270, 4320, 66, 66, 270, 270, 66, 66, 4320, 4320, 4320, 4320, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 4320, 270, 270, 270, 4320, 66, 270, 270, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 270, 66, 4320, 4320, 4320, 270, 66, 4320, 4320, 270, 270, 4320, 4320, 66, 4320, 4320, 270, 66, 4320, 270, 270, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 270, 4320, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 4320, 66, 66, 66, 270, 66, 270, 270, 66, 4320, 270, 4320, 66, 4320, 66, 270, 270, 270, 270, 66, 270, 4320, 4320, 66, 4320, 4320, 66, 4320, 270, 4320, 270, 270, 270, 66, 270, 66, 66, 4320, 66, 270, 66, 66, 270, 4320, 270, 4320, 66, 4320, 4320, 270, 4320, 270, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 595968 . Total input tokens: 132907362 . Total output tokens: 119020776
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 70.8563786461018,
    "estimated_duration": 3600.062177100344,
    "input_throughput": 6126.128359750627,
    "output_throughput": 5410.057393977375,
    "total_throughput": 11536.185753728001,
    "itl": 148.39708329418676,
    "ttft": 1568836.5397739643,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 590,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.928551633618784,
    "arrivals": 198105,
    "finished_requests": 89047,
    "scheduler_time": 166.40430582443273
}
#Debug simulation 
Total elapsed time: 70.8565115951933. Arrivals time: 0.3689825697802007 Scheduler time: 70.34440055117011 Scheduler overhead time: 0.053387561812996864 Adapter cache time: 0.016541455406695604 Engine time: 0.05273309722542763 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-16/adapters_384_slots_64_rate_0.4-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-16/adapters_384_slots_64_rate_0.4-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 270, 66, 4320, 4320, 66, 270, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 66, 4320, 66, 4320, 270, 270, 270, 66, 66, 270, 66, 4320, 66, 4320, 270, 4320, 270, 66, 270, 4320, 270, 4320, 66, 4320, 4320, 4320, 4320, 66, 270, 270, 270, 4320, 270, 66, 270, 66, 4320, 270, 4320, 4320, 270, 4320, 4320, 66, 66, 4320, 270, 270, 66, 66, 66, 270, 66, 270, 66, 4320, 66, 270, 4320, 66, 4320, 270, 66, 4320, 4320, 4320, 4320, 270, 66, 270, 4320, 4320, 270, 66, 66, 4320, 270, 270, 66, 66, 4320, 270, 4320, 270, 4320, 4320, 270, 4320, 4320, 66, 270, 270, 270, 270, 66, 66, 4320, 66, 4320, 66, 66, 66, 270, 270, 4320, 66, 66, 4320, 66, 4320, 270, 66, 4320, 270, 270, 66, 4320, 4320, 4320, 66, 270, 4320, 66, 4320, 270, 270, 4320, 4320, 66, 270, 4320, 66, 270, 270, 66, 270, 66, 270, 4320, 4320, 270, 66, 4320, 66, 4320, 270, 270, 270, 270, 270, 66, 66, 4320, 66, 4320, 66, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 66, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 66, 66, 66, 66, 66, 270, 66, 66, 270, 4320, 4320, 66, 66, 4320, 66, 66, 66, 270, 66, 270, 4320, 4320, 270, 270, 66, 4320, 270, 4320, 66, 270, 270, 66, 66, 270, 66, 4320, 4320, 66, 4320, 4320, 66, 270, 4320, 66, 66, 270, 270, 66, 66, 4320, 4320, 4320, 4320, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 4320, 270, 270, 270, 4320, 66, 270, 270, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 270, 66, 4320, 4320, 4320, 270, 66, 4320, 4320, 270, 270, 4320, 4320, 66, 4320, 4320, 270, 66, 4320, 270, 270, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 270, 4320, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 4320, 66, 66, 66, 270, 66, 270, 270, 66, 4320, 270, 4320, 66, 4320, 66, 270, 270, 270, 270, 66, 270, 4320, 4320, 66, 4320, 4320, 66, 4320, 270, 4320, 270, 270, 270, 66, 270, 66, 66, 4320, 66, 270, 66, 66, 270, 4320, 270, 4320, 66, 4320, 4320, 270, 4320, 270, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 595968 . Total input tokens: 132907362 . Total output tokens: 119020776
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 70.69826888712123,
    "estimated_duration": 3600.0934681734475,
    "input_throughput": 6132.521056793943,
    "output_throughput": 5423.781958057556,
    "total_throughput": 11556.303014851499,
    "itl": 148.79501965249486,
    "ttft": 1565382.830151306,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 601,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.878739290924266,
    "arrivals": 198105,
    "finished_requests": 89190,
    "scheduler_time": 166.09754487168956
}
#Debug simulation 
Total elapsed time: 70.69841444212943. Arrivals time: 0.3788106110878289 Scheduler time: 70.17422437109053 Scheduler overhead time: 0.054252322763204575 Adapter cache time: 0.01708111958578229 Engine time: 0.05313641345128417 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-32/adapters_384_slots_64_rate_0.4-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-32/adapters_384_slots_64_rate_0.4-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 270, 66, 4320, 4320, 66, 270, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 66, 4320, 66, 4320, 270, 270, 270, 66, 66, 270, 66, 4320, 66, 4320, 270, 4320, 270, 66, 270, 4320, 270, 4320, 66, 4320, 4320, 4320, 4320, 66, 270, 270, 270, 4320, 270, 66, 270, 66, 4320, 270, 4320, 4320, 270, 4320, 4320, 66, 66, 4320, 270, 270, 66, 66, 66, 270, 66, 270, 66, 4320, 66, 270, 4320, 66, 4320, 270, 66, 4320, 4320, 4320, 4320, 270, 66, 270, 4320, 4320, 270, 66, 66, 4320, 270, 270, 66, 66, 4320, 270, 4320, 270, 4320, 4320, 270, 4320, 4320, 66, 270, 270, 270, 270, 66, 66, 4320, 66, 4320, 66, 66, 66, 270, 270, 4320, 66, 66, 4320, 66, 4320, 270, 66, 4320, 270, 270, 66, 4320, 4320, 4320, 66, 270, 4320, 66, 4320, 270, 270, 4320, 4320, 66, 270, 4320, 66, 270, 270, 66, 270, 66, 270, 4320, 4320, 270, 66, 4320, 66, 4320, 270, 270, 270, 270, 270, 66, 66, 4320, 66, 4320, 66, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 66, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 66, 66, 66, 66, 66, 270, 66, 66, 270, 4320, 4320, 66, 66, 4320, 66, 66, 66, 270, 66, 270, 4320, 4320, 270, 270, 66, 4320, 270, 4320, 66, 270, 270, 66, 66, 270, 66, 4320, 4320, 66, 4320, 4320, 66, 270, 4320, 66, 66, 270, 270, 66, 66, 4320, 4320, 4320, 4320, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 4320, 270, 270, 270, 4320, 66, 270, 270, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 270, 66, 4320, 4320, 4320, 270, 66, 4320, 4320, 270, 270, 4320, 4320, 66, 4320, 4320, 270, 66, 4320, 270, 270, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 270, 4320, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 4320, 66, 66, 66, 270, 66, 270, 270, 66, 4320, 270, 4320, 66, 4320, 66, 270, 270, 270, 270, 66, 270, 4320, 4320, 66, 4320, 4320, 66, 4320, 270, 4320, 270, 270, 270, 66, 270, 66, 66, 4320, 66, 270, 66, 66, 270, 4320, 270, 4320, 66, 4320, 4320, 270, 4320, 270, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 595968 . Total input tokens: 132907362 . Total output tokens: 119020776
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 70.96928421827033,
    "estimated_duration": 3600.083607006181,
    "input_throughput": 6126.091893277004,
    "output_throughput": 5410.025189997361,
    "total_throughput": 11536.117083274365,
    "itl": 148.39735089956747,
    "ttft": 1568843.7734857977,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 590,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9533251295425036,
    "arrivals": 198105,
    "finished_requests": 89047,
    "scheduler_time": 166.40468627161925
}
#Debug simulation 
Total elapsed time: 70.96941945515573. Arrivals time: 0.382574959192425 Scheduler time: 70.44352013804018 Scheduler overhead time: 0.05318279704079032 Adapter cache time: 0.01685114298015833 Engine time: 0.05269753420725465 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-16/adapters_384_slots_64_rate_0.4-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-16/adapters_384_slots_64_rate_0.4-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 270, 66, 4320, 4320, 66, 270, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 66, 4320, 66, 4320, 270, 270, 270, 66, 66, 270, 66, 4320, 66, 4320, 270, 4320, 270, 66, 270, 4320, 270, 4320, 66, 4320, 4320, 4320, 4320, 66, 270, 270, 270, 4320, 270, 66, 270, 66, 4320, 270, 4320, 4320, 270, 4320, 4320, 66, 66, 4320, 270, 270, 66, 66, 66, 270, 66, 270, 66, 4320, 66, 270, 4320, 66, 4320, 270, 66, 4320, 4320, 4320, 4320, 270, 66, 270, 4320, 4320, 270, 66, 66, 4320, 270, 270, 66, 66, 4320, 270, 4320, 270, 4320, 4320, 270, 4320, 4320, 66, 270, 270, 270, 270, 66, 66, 4320, 66, 4320, 66, 66, 66, 270, 270, 4320, 66, 66, 4320, 66, 4320, 270, 66, 4320, 270, 270, 66, 4320, 4320, 4320, 66, 270, 4320, 66, 4320, 270, 270, 4320, 4320, 66, 270, 4320, 66, 270, 270, 66, 270, 66, 270, 4320, 4320, 270, 66, 4320, 66, 4320, 270, 270, 270, 270, 270, 66, 66, 4320, 66, 4320, 66, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 66, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 66, 66, 66, 66, 66, 270, 66, 66, 270, 4320, 4320, 66, 66, 4320, 66, 66, 66, 270, 66, 270, 4320, 4320, 270, 270, 66, 4320, 270, 4320, 66, 270, 270, 66, 66, 270, 66, 4320, 4320, 66, 4320, 4320, 66, 270, 4320, 66, 66, 270, 270, 66, 66, 4320, 4320, 4320, 4320, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 4320, 270, 270, 270, 4320, 66, 270, 270, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 270, 66, 4320, 4320, 4320, 270, 66, 4320, 4320, 270, 270, 4320, 4320, 66, 4320, 4320, 270, 66, 4320, 270, 270, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 270, 4320, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 4320, 66, 66, 66, 270, 66, 270, 270, 66, 4320, 270, 4320, 66, 4320, 66, 270, 270, 270, 270, 66, 270, 4320, 4320, 66, 4320, 4320, 66, 4320, 270, 4320, 270, 270, 270, 66, 270, 66, 66, 4320, 66, 270, 66, 66, 270, 4320, 270, 4320, 66, 4320, 4320, 270, 4320, 270, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 595968 . Total input tokens: 132907362 . Total output tokens: 119020776
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 69.57187646720558,
    "estimated_duration": 3600.0169547378086,
    "input_throughput": 6134.377498121639,
    "output_throughput": 5419.60503111602,
    "total_throughput": 11553.982529237659,
    "itl": 148.68989098425527,
    "ttft": 1566496.9174410221,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 596,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7820699757616703,
    "arrivals": 198105,
    "finished_requests": 89190,
    "scheduler_time": 166.16253834808813
}
#Debug simulation 
Total elapsed time: 69.57202135585248. Arrivals time: 0.3665550737641752 Scheduler time: 69.0629303236492 Scheduler overhead time: 0.05306651769205928 Adapter cache time: 0.016614808700978756 Engine time: 0.05230511957779527 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-32/adapters_384_slots_64_rate_0.4-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-32/adapters_384_slots_64_rate_0.4-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 270, 66, 4320, 4320, 66, 270, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 66, 4320, 66, 4320, 270, 270, 270, 66, 66, 270, 66, 4320, 66, 4320, 270, 4320, 270, 66, 270, 4320, 270, 4320, 66, 4320, 4320, 4320, 4320, 66, 270, 270, 270, 4320, 270, 66, 270, 66, 4320, 270, 4320, 4320, 270, 4320, 4320, 66, 66, 4320, 270, 270, 66, 66, 66, 270, 66, 270, 66, 4320, 66, 270, 4320, 66, 4320, 270, 66, 4320, 4320, 4320, 4320, 270, 66, 270, 4320, 4320, 270, 66, 66, 4320, 270, 270, 66, 66, 4320, 270, 4320, 270, 4320, 4320, 270, 4320, 4320, 66, 270, 270, 270, 270, 66, 66, 4320, 66, 4320, 66, 66, 66, 270, 270, 4320, 66, 66, 4320, 66, 4320, 270, 66, 4320, 270, 270, 66, 4320, 4320, 4320, 66, 270, 4320, 66, 4320, 270, 270, 4320, 4320, 66, 270, 4320, 66, 270, 270, 66, 270, 66, 270, 4320, 4320, 270, 66, 4320, 66, 4320, 270, 270, 270, 270, 270, 66, 66, 4320, 66, 4320, 66, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 66, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 66, 66, 66, 66, 66, 270, 66, 66, 270, 4320, 4320, 66, 66, 4320, 66, 66, 66, 270, 66, 270, 4320, 4320, 270, 270, 66, 4320, 270, 4320, 66, 270, 270, 66, 66, 270, 66, 4320, 4320, 66, 4320, 4320, 66, 270, 4320, 66, 66, 270, 270, 66, 66, 4320, 4320, 4320, 4320, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 4320, 270, 270, 270, 4320, 66, 270, 270, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 270, 66, 4320, 4320, 4320, 270, 66, 4320, 4320, 270, 270, 4320, 4320, 66, 4320, 4320, 270, 66, 4320, 270, 270, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 270, 4320, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 4320, 66, 66, 66, 270, 66, 270, 270, 66, 4320, 270, 4320, 66, 4320, 66, 270, 270, 270, 270, 66, 270, 4320, 4320, 66, 4320, 4320, 66, 4320, 270, 4320, 270, 270, 270, 66, 270, 66, 66, 4320, 66, 270, 66, 66, 270, 4320, 270, 4320, 66, 4320, 4320, 270, 4320, 270, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 595968 . Total input tokens: 132907362 . Total output tokens: 119020776
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 71.26014576014131,
    "estimated_duration": 3600.145624712303,
    "input_throughput": 6130.445071027845,
    "output_throughput": 5416.780884122817,
    "total_throughput": 11547.225955150663,
    "itl": 148.45703645092735,
    "ttft": 1565914.383413747,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 596,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.997748742401595,
    "arrivals": 198105,
    "finished_requests": 89116,
    "scheduler_time": 166.40258830139513
}
#Debug simulation 
Total elapsed time: 71.260290666949. Arrivals time: 0.36148198414593935 Scheduler time: 70.7532059638761 Scheduler overhead time: 0.05417559528723359 Adapter cache time: 0.017075583338737488 Engine time: 0.05356340715661645 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-8/adapters_384_slots_64_rate_0.4-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-8/adapters_384_slots_64_rate_0.4-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 270, 33, 4320, 4320, 33, 270, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 33, 4320, 33, 4320, 270, 270, 270, 33, 33, 270, 33, 4320, 33, 4320, 270, 4320, 270, 33, 270, 4320, 270, 4320, 33, 4320, 4320, 4320, 4320, 33, 270, 270, 270, 4320, 270, 33, 270, 33, 4320, 270, 4320, 4320, 270, 4320, 4320, 33, 33, 4320, 270, 270, 33, 33, 33, 270, 33, 270, 33, 4320, 33, 270, 4320, 33, 4320, 270, 33, 4320, 4320, 4320, 4320, 270, 33, 270, 4320, 4320, 270, 33, 33, 4320, 270, 270, 33, 33, 4320, 270, 4320, 270, 4320, 4320, 270, 4320, 4320, 33, 270, 270, 270, 270, 33, 33, 4320, 33, 4320, 33, 33, 33, 270, 270, 4320, 33, 33, 4320, 33, 4320, 270, 33, 4320, 270, 270, 33, 4320, 4320, 4320, 33, 270, 4320, 33, 4320, 270, 270, 4320, 4320, 33, 270, 4320, 33, 270, 270, 33, 270, 33, 270, 4320, 4320, 270, 33, 4320, 33, 4320, 270, 270, 270, 270, 270, 33, 33, 4320, 33, 4320, 33, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 33, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 33, 33, 33, 33, 33, 270, 33, 33, 270, 4320, 4320, 33, 33, 4320, 33, 33, 33, 270, 33, 270, 4320, 4320, 270, 270, 33, 4320, 270, 4320, 33, 270, 270, 33, 33, 270, 33, 4320, 4320, 33, 4320, 4320, 33, 270, 4320, 33, 33, 270, 270, 33, 33, 4320, 4320, 4320, 4320, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 4320, 270, 270, 270, 4320, 33, 270, 270, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 270, 33, 4320, 4320, 4320, 270, 33, 4320, 4320, 270, 270, 4320, 4320, 33, 4320, 4320, 270, 33, 4320, 270, 270, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 270, 4320, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 4320, 33, 33, 33, 270, 33, 270, 270, 33, 4320, 270, 4320, 33, 4320, 33, 270, 270, 270, 270, 33, 270, 4320, 4320, 33, 4320, 4320, 33, 4320, 270, 4320, 270, 270, 270, 33, 270, 33, 33, 4320, 33, 270, 33, 33, 270, 4320, 270, 4320, 33, 4320, 4320, 270, 4320, 270, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 591744 . Total input tokens: 131952871 . Total output tokens: 118169411
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 74.05741974385455,
    "estimated_duration": 3600.1207587238073,
    "input_throughput": 6118.112551260056,
    "output_throughput": 5375.187194237277,
    "total_throughput": 11493.299745497334,
    "itl": 146.19434513196242,
    "ttft": 1554235.0432840486,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 528,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.615937528796514,
    "arrivals": 196756,
    "finished_requests": 88931,
    "scheduler_time": 168.06945957276065
}
#Debug simulation 
Total elapsed time: 74.05754844285548. Arrivals time: 0.36327326856553555 Scheduler time: 73.55176371522248 Scheduler overhead time: 0.052961194422096014 Adapter cache time: 0.015778894536197186 Engine time: 0.05258283903822303 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-16/adapters_384_slots_64_rate_0.4-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-16/adapters_384_slots_64_rate_0.4-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 270, 33, 4320, 4320, 33, 270, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 33, 4320, 33, 4320, 270, 270, 270, 33, 33, 270, 33, 4320, 33, 4320, 270, 4320, 270, 33, 270, 4320, 270, 4320, 33, 4320, 4320, 4320, 4320, 33, 270, 270, 270, 4320, 270, 33, 270, 33, 4320, 270, 4320, 4320, 270, 4320, 4320, 33, 33, 4320, 270, 270, 33, 33, 33, 270, 33, 270, 33, 4320, 33, 270, 4320, 33, 4320, 270, 33, 4320, 4320, 4320, 4320, 270, 33, 270, 4320, 4320, 270, 33, 33, 4320, 270, 270, 33, 33, 4320, 270, 4320, 270, 4320, 4320, 270, 4320, 4320, 33, 270, 270, 270, 270, 33, 33, 4320, 33, 4320, 33, 33, 33, 270, 270, 4320, 33, 33, 4320, 33, 4320, 270, 33, 4320, 270, 270, 33, 4320, 4320, 4320, 33, 270, 4320, 33, 4320, 270, 270, 4320, 4320, 33, 270, 4320, 33, 270, 270, 33, 270, 33, 270, 4320, 4320, 270, 33, 4320, 33, 4320, 270, 270, 270, 270, 270, 33, 33, 4320, 33, 4320, 33, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 33, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 33, 33, 33, 33, 33, 270, 33, 33, 270, 4320, 4320, 33, 33, 4320, 33, 33, 33, 270, 33, 270, 4320, 4320, 270, 270, 33, 4320, 270, 4320, 33, 270, 270, 33, 33, 270, 33, 4320, 4320, 33, 4320, 4320, 33, 270, 4320, 33, 33, 270, 270, 33, 33, 4320, 4320, 4320, 4320, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 4320, 270, 270, 270, 4320, 33, 270, 270, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 270, 33, 4320, 4320, 4320, 270, 33, 4320, 4320, 270, 270, 4320, 4320, 33, 4320, 4320, 270, 33, 4320, 270, 270, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 270, 4320, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 4320, 33, 33, 33, 270, 33, 270, 270, 33, 4320, 270, 4320, 33, 4320, 33, 270, 270, 270, 270, 33, 270, 4320, 4320, 33, 4320, 4320, 33, 4320, 270, 4320, 270, 270, 270, 33, 270, 33, 33, 4320, 33, 270, 33, 33, 270, 4320, 270, 4320, 33, 4320, 4320, 270, 4320, 270, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 591744 . Total input tokens: 131952871 . Total output tokens: 118169411
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 73.89255951205269,
    "estimated_duration": 3600.0321955459576,
    "input_throughput": 6117.961674689926,
    "output_throughput": 5375.006652423972,
    "total_throughput": 11492.968327113898,
    "itl": 146.19835404267377,
    "ttft": 1554236.8546467805,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 528,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.726658060983761,
    "arrivals": 196756,
    "finished_requests": 88927,
    "scheduler_time": 168.06055441343517
}
#Debug simulation 
Total elapsed time: 73.89269064739347. Arrivals time: 0.37166286166757345 Scheduler time: 73.374392548576 Scheduler overhead time: 0.0550796645693481 Adapter cache time: 0.016534026712179184 Engine time: 0.05352457286790013 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-32/adapters_384_slots_64_rate_0.4-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-32/adapters_384_slots_64_rate_0.4-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 270, 33, 4320, 4320, 33, 270, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 33, 4320, 33, 4320, 270, 270, 270, 33, 33, 270, 33, 4320, 33, 4320, 270, 4320, 270, 33, 270, 4320, 270, 4320, 33, 4320, 4320, 4320, 4320, 33, 270, 270, 270, 4320, 270, 33, 270, 33, 4320, 270, 4320, 4320, 270, 4320, 4320, 33, 33, 4320, 270, 270, 33, 33, 33, 270, 33, 270, 33, 4320, 33, 270, 4320, 33, 4320, 270, 33, 4320, 4320, 4320, 4320, 270, 33, 270, 4320, 4320, 270, 33, 33, 4320, 270, 270, 33, 33, 4320, 270, 4320, 270, 4320, 4320, 270, 4320, 4320, 33, 270, 270, 270, 270, 33, 33, 4320, 33, 4320, 33, 33, 33, 270, 270, 4320, 33, 33, 4320, 33, 4320, 270, 33, 4320, 270, 270, 33, 4320, 4320, 4320, 33, 270, 4320, 33, 4320, 270, 270, 4320, 4320, 33, 270, 4320, 33, 270, 270, 33, 270, 33, 270, 4320, 4320, 270, 33, 4320, 33, 4320, 270, 270, 270, 270, 270, 33, 33, 4320, 33, 4320, 33, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 33, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 33, 33, 33, 33, 33, 270, 33, 33, 270, 4320, 4320, 33, 33, 4320, 33, 33, 33, 270, 33, 270, 4320, 4320, 270, 270, 33, 4320, 270, 4320, 33, 270, 270, 33, 33, 270, 33, 4320, 4320, 33, 4320, 4320, 33, 270, 4320, 33, 33, 270, 270, 33, 33, 4320, 4320, 4320, 4320, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 4320, 270, 270, 270, 4320, 33, 270, 270, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 270, 33, 4320, 4320, 4320, 270, 33, 4320, 4320, 270, 270, 4320, 4320, 33, 4320, 4320, 270, 33, 4320, 270, 270, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 270, 4320, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 4320, 33, 33, 33, 270, 33, 270, 270, 33, 4320, 270, 4320, 33, 4320, 33, 270, 270, 270, 270, 33, 270, 4320, 4320, 33, 4320, 4320, 33, 4320, 270, 4320, 270, 270, 270, 33, 270, 33, 33, 4320, 33, 270, 33, 33, 270, 4320, 270, 4320, 33, 4320, 4320, 270, 4320, 270, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 591744 . Total input tokens: 131952871 . Total output tokens: 118169411
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 73.80322847189382,
    "estimated_duration": 3600.034323234324,
    "input_throughput": 6117.958058858879,
    "output_throughput": 5375.003475693392,
    "total_throughput": 11492.96153455227,
    "itl": 146.19835840852653,
    "ttft": 1554237.4270255119,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 528,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7290615451708542,
    "arrivals": 196756,
    "finished_requests": 88927,
    "scheduler_time": 168.06055709344233
}
#Debug simulation 
Total elapsed time: 73.80336217489094. Arrivals time: 0.37644023913890123 Scheduler time: 73.279672795441 Scheduler overhead time: 0.056412019301205873 Adapter cache time: 0.01630760356783867 Engine time: 0.05324301403015852 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-16/adapters_384_slots_64_rate_0.4-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-16/adapters_384_slots_64_rate_0.4-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 270, 33, 4320, 4320, 33, 270, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 33, 4320, 33, 4320, 270, 270, 270, 33, 33, 270, 33, 4320, 33, 4320, 270, 4320, 270, 33, 270, 4320, 270, 4320, 33, 4320, 4320, 4320, 4320, 33, 270, 270, 270, 4320, 270, 33, 270, 33, 4320, 270, 4320, 4320, 270, 4320, 4320, 33, 33, 4320, 270, 270, 33, 33, 33, 270, 33, 270, 33, 4320, 33, 270, 4320, 33, 4320, 270, 33, 4320, 4320, 4320, 4320, 270, 33, 270, 4320, 4320, 270, 33, 33, 4320, 270, 270, 33, 33, 4320, 270, 4320, 270, 4320, 4320, 270, 4320, 4320, 33, 270, 270, 270, 270, 33, 33, 4320, 33, 4320, 33, 33, 33, 270, 270, 4320, 33, 33, 4320, 33, 4320, 270, 33, 4320, 270, 270, 33, 4320, 4320, 4320, 33, 270, 4320, 33, 4320, 270, 270, 4320, 4320, 33, 270, 4320, 33, 270, 270, 33, 270, 33, 270, 4320, 4320, 270, 33, 4320, 33, 4320, 270, 270, 270, 270, 270, 33, 33, 4320, 33, 4320, 33, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 33, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 33, 33, 33, 33, 33, 270, 33, 33, 270, 4320, 4320, 33, 33, 4320, 33, 33, 33, 270, 33, 270, 4320, 4320, 270, 270, 33, 4320, 270, 4320, 33, 270, 270, 33, 33, 270, 33, 4320, 4320, 33, 4320, 4320, 33, 270, 4320, 33, 33, 270, 270, 33, 33, 4320, 4320, 4320, 4320, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 4320, 270, 270, 270, 4320, 33, 270, 270, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 270, 33, 4320, 4320, 4320, 270, 33, 4320, 4320, 270, 270, 4320, 4320, 33, 4320, 4320, 270, 33, 4320, 270, 270, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 270, 4320, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 4320, 33, 33, 33, 270, 33, 270, 270, 33, 4320, 270, 4320, 33, 4320, 33, 270, 270, 270, 270, 33, 270, 4320, 4320, 33, 4320, 4320, 33, 4320, 270, 4320, 270, 270, 270, 33, 270, 33, 33, 4320, 33, 270, 33, 33, 270, 4320, 270, 4320, 33, 4320, 4320, 270, 4320, 270, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 591744 . Total input tokens: 131952871 . Total output tokens: 118169411
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 70.26231687981635,
    "estimated_duration": 3600.1396023490597,
    "input_throughput": 6182.809962557066,
    "output_throughput": 5428.780313754353,
    "total_throughput": 11611.590276311419,
    "itl": 148.73580459831538,
    "ttft": 1552416.0625422124,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 519,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6266090463288063,
    "arrivals": 196756,
    "finished_requests": 89900,
    "scheduler_time": 165.29506713336644
}
#Debug simulation 
Total elapsed time: 70.26245101680979. Arrivals time: 0.377361589577049 Scheduler time: 69.7397988899611 Scheduler overhead time: 0.055978278163820505 Adapter cache time: 0.01554371789097786 Engine time: 0.05249409098178148 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-32/adapters_384_slots_64_rate_0.4-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-32/adapters_384_slots_64_rate_0.4-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 270, 33, 4320, 4320, 33, 270, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 33, 4320, 33, 4320, 270, 270, 270, 33, 33, 270, 33, 4320, 33, 4320, 270, 4320, 270, 33, 270, 4320, 270, 4320, 33, 4320, 4320, 4320, 4320, 33, 270, 270, 270, 4320, 270, 33, 270, 33, 4320, 270, 4320, 4320, 270, 4320, 4320, 33, 33, 4320, 270, 270, 33, 33, 33, 270, 33, 270, 33, 4320, 33, 270, 4320, 33, 4320, 270, 33, 4320, 4320, 4320, 4320, 270, 33, 270, 4320, 4320, 270, 33, 33, 4320, 270, 270, 33, 33, 4320, 270, 4320, 270, 4320, 4320, 270, 4320, 4320, 33, 270, 270, 270, 270, 33, 33, 4320, 33, 4320, 33, 33, 33, 270, 270, 4320, 33, 33, 4320, 33, 4320, 270, 33, 4320, 270, 270, 33, 4320, 4320, 4320, 33, 270, 4320, 33, 4320, 270, 270, 4320, 4320, 33, 270, 4320, 33, 270, 270, 33, 270, 33, 270, 4320, 4320, 270, 33, 4320, 33, 4320, 270, 270, 270, 270, 270, 33, 33, 4320, 33, 4320, 33, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 33, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 33, 33, 33, 33, 33, 270, 33, 33, 270, 4320, 4320, 33, 33, 4320, 33, 33, 33, 270, 33, 270, 4320, 4320, 270, 270, 33, 4320, 270, 4320, 33, 270, 270, 33, 33, 270, 33, 4320, 4320, 33, 4320, 4320, 33, 270, 4320, 33, 33, 270, 270, 33, 33, 4320, 4320, 4320, 4320, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 4320, 270, 270, 270, 4320, 33, 270, 270, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 270, 33, 4320, 4320, 4320, 270, 33, 4320, 4320, 270, 270, 4320, 4320, 33, 4320, 4320, 270, 33, 4320, 270, 270, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 270, 4320, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 4320, 33, 33, 33, 270, 33, 270, 270, 33, 4320, 270, 4320, 33, 4320, 33, 270, 270, 270, 270, 33, 270, 4320, 4320, 33, 4320, 4320, 33, 4320, 270, 4320, 270, 270, 270, 33, 270, 33, 33, 4320, 33, 270, 33, 33, 270, 4320, 270, 4320, 33, 4320, 4320, 270, 4320, 270, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 591744 . Total input tokens: 131952871 . Total output tokens: 118169411
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 73.89776198938489,
    "estimated_duration": 3600.058262624571,
    "input_throughput": 6117.917376132433,
    "output_throughput": 5374.96773340913,
    "total_throughput": 11492.885109541563,
    "itl": 146.19833969282683,
    "ttft": 1554246.0231408877,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 528,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7511942115798638,
    "arrivals": 196756,
    "finished_requests": 88927,
    "scheduler_time": 168.06116192221566
}
#Debug simulation 
Total elapsed time: 73.8978936583735. Arrivals time: 0.3582058376632631 Scheduler time: 73.39220780739561 Scheduler overhead time: 0.05633065849542618 Adapter cache time: 0.01598617574200034 Engine time: 0.05343705369159579 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-16/adapters_384_slots_64_rate_0.4-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-16/adapters_384_slots_64_rate_0.4-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 270, 33, 4320, 4320, 33, 270, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 33, 4320, 33, 4320, 270, 270, 270, 33, 33, 270, 33, 4320, 33, 4320, 270, 4320, 270, 33, 270, 4320, 270, 4320, 33, 4320, 4320, 4320, 4320, 33, 270, 270, 270, 4320, 270, 33, 270, 33, 4320, 270, 4320, 4320, 270, 4320, 4320, 33, 33, 4320, 270, 270, 33, 33, 33, 270, 33, 270, 33, 4320, 33, 270, 4320, 33, 4320, 270, 33, 4320, 4320, 4320, 4320, 270, 33, 270, 4320, 4320, 270, 33, 33, 4320, 270, 270, 33, 33, 4320, 270, 4320, 270, 4320, 4320, 270, 4320, 4320, 33, 270, 270, 270, 270, 33, 33, 4320, 33, 4320, 33, 33, 33, 270, 270, 4320, 33, 33, 4320, 33, 4320, 270, 33, 4320, 270, 270, 33, 4320, 4320, 4320, 33, 270, 4320, 33, 4320, 270, 270, 4320, 4320, 33, 270, 4320, 33, 270, 270, 33, 270, 33, 270, 4320, 4320, 270, 33, 4320, 33, 4320, 270, 270, 270, 270, 270, 33, 33, 4320, 33, 4320, 33, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 33, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 33, 33, 33, 33, 33, 270, 33, 33, 270, 4320, 4320, 33, 33, 4320, 33, 33, 33, 270, 33, 270, 4320, 4320, 270, 270, 33, 4320, 270, 4320, 33, 270, 270, 33, 33, 270, 33, 4320, 4320, 33, 4320, 4320, 33, 270, 4320, 33, 33, 270, 270, 33, 33, 4320, 4320, 4320, 4320, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 4320, 270, 270, 270, 4320, 33, 270, 270, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 270, 33, 4320, 4320, 4320, 270, 33, 4320, 4320, 270, 270, 4320, 4320, 33, 4320, 4320, 270, 33, 4320, 270, 270, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 270, 4320, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 4320, 33, 33, 33, 270, 33, 270, 270, 33, 4320, 270, 4320, 33, 4320, 33, 270, 270, 270, 270, 33, 270, 4320, 4320, 33, 4320, 4320, 33, 4320, 270, 4320, 270, 270, 270, 33, 270, 33, 33, 4320, 33, 270, 33, 33, 270, 4320, 270, 4320, 33, 4320, 4320, 270, 4320, 270, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 591744 . Total input tokens: 131952871 . Total output tokens: 118169411
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 70.5475201481022,
    "estimated_duration": 3600.091983081147,
    "input_throughput": 6182.078153723202,
    "output_throughput": 5428.808511518376,
    "total_throughput": 11610.886665241578,
    "itl": 148.72569501207164,
    "ttft": 1552268.6320076198,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 512,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5309057509898965,
    "arrivals": 196756,
    "finished_requests": 89890,
    "scheduler_time": 165.31093680209415
}
#Debug simulation 
Total elapsed time: 70.5476482170634. Arrivals time: 0.34217415237799287 Scheduler time: 70.06231342256069 Scheduler overhead time: 0.05441717058420181 Adapter cache time: 0.015403852332383394 Engine time: 0.05200277687981725 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-32/adapters_384_slots_64_rate_0.4-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-32/adapters_384_slots_64_rate_0.4-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 270, 33, 4320, 4320, 33, 270, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 33, 4320, 33, 4320, 270, 270, 270, 33, 33, 270, 33, 4320, 33, 4320, 270, 4320, 270, 33, 270, 4320, 270, 4320, 33, 4320, 4320, 4320, 4320, 33, 270, 270, 270, 4320, 270, 33, 270, 33, 4320, 270, 4320, 4320, 270, 4320, 4320, 33, 33, 4320, 270, 270, 33, 33, 33, 270, 33, 270, 33, 4320, 33, 270, 4320, 33, 4320, 270, 33, 4320, 4320, 4320, 4320, 270, 33, 270, 4320, 4320, 270, 33, 33, 4320, 270, 270, 33, 33, 4320, 270, 4320, 270, 4320, 4320, 270, 4320, 4320, 33, 270, 270, 270, 270, 33, 33, 4320, 33, 4320, 33, 33, 33, 270, 270, 4320, 33, 33, 4320, 33, 4320, 270, 33, 4320, 270, 270, 33, 4320, 4320, 4320, 33, 270, 4320, 33, 4320, 270, 270, 4320, 4320, 33, 270, 4320, 33, 270, 270, 33, 270, 33, 270, 4320, 4320, 270, 33, 4320, 33, 4320, 270, 270, 270, 270, 270, 33, 33, 4320, 33, 4320, 33, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 33, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 33, 33, 33, 33, 33, 270, 33, 33, 270, 4320, 4320, 33, 33, 4320, 33, 33, 33, 270, 33, 270, 4320, 4320, 270, 270, 33, 4320, 270, 4320, 33, 270, 270, 33, 33, 270, 33, 4320, 4320, 33, 4320, 4320, 33, 270, 4320, 33, 33, 270, 270, 33, 33, 4320, 4320, 4320, 4320, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 4320, 270, 270, 270, 4320, 33, 270, 270, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 270, 33, 4320, 4320, 4320, 270, 33, 4320, 4320, 270, 270, 4320, 4320, 33, 4320, 4320, 270, 33, 4320, 270, 270, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 270, 4320, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 4320, 33, 33, 33, 270, 33, 270, 270, 33, 4320, 270, 4320, 33, 4320, 33, 270, 270, 270, 270, 33, 270, 4320, 4320, 33, 4320, 4320, 33, 4320, 270, 4320, 270, 270, 270, 33, 270, 33, 33, 4320, 33, 270, 33, 33, 270, 4320, 270, 4320, 33, 4320, 4320, 270, 4320, 270, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 591744 . Total input tokens: 131952871 . Total output tokens: 118169411
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 73.3282033498399,
    "estimated_duration": 3600.1592919608133,
    "input_throughput": 6128.479106262877,
    "output_throughput": 5385.786968731452,
    "total_throughput": 11514.26607499433,
    "itl": 146.54567131591762,
    "ttft": 1553836.328987981,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 525,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7640648554638,
    "arrivals": 196756,
    "finished_requests": 89128,
    "scheduler_time": 167.59484477483545
}
#Debug simulation 
Total elapsed time: 73.3283261610195. Arrivals time: 0.36709514120593667 Scheduler time: 72.81454344233498 Scheduler overhead time: 0.05634301295503974 Adapter cache time: 0.01599664380773902 Engine time: 0.05302537465468049 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-8/adapters_384_slots_64_rate_0.4-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-8/adapters_384_slots_64_rate_0.4-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 135, 66, 4320, 4320, 66, 135, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 66, 4320, 66, 4320, 135, 135, 135, 66, 66, 135, 66, 4320, 66, 4320, 135, 4320, 135, 66, 135, 4320, 135, 4320, 66, 4320, 4320, 4320, 4320, 66, 135, 135, 135, 4320, 135, 66, 135, 66, 4320, 135, 4320, 4320, 135, 4320, 4320, 66, 66, 4320, 135, 135, 66, 66, 66, 135, 66, 135, 66, 4320, 66, 135, 4320, 66, 4320, 135, 66, 4320, 4320, 4320, 4320, 135, 66, 135, 4320, 4320, 135, 66, 66, 4320, 135, 135, 66, 66, 4320, 135, 4320, 135, 4320, 4320, 135, 4320, 4320, 66, 135, 135, 135, 135, 66, 66, 4320, 66, 4320, 66, 66, 66, 135, 135, 4320, 66, 66, 4320, 66, 4320, 135, 66, 4320, 135, 135, 66, 4320, 4320, 4320, 66, 135, 4320, 66, 4320, 135, 135, 4320, 4320, 66, 135, 4320, 66, 135, 135, 66, 135, 66, 135, 4320, 4320, 135, 66, 4320, 66, 4320, 135, 135, 135, 135, 135, 66, 66, 4320, 66, 4320, 66, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 66, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 66, 66, 66, 66, 66, 135, 66, 66, 135, 4320, 4320, 66, 66, 4320, 66, 66, 66, 135, 66, 135, 4320, 4320, 135, 135, 66, 4320, 135, 4320, 66, 135, 135, 66, 66, 135, 66, 4320, 4320, 66, 4320, 4320, 66, 135, 4320, 66, 66, 135, 135, 66, 66, 4320, 4320, 4320, 4320, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 4320, 135, 135, 135, 4320, 66, 135, 135, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 135, 66, 4320, 4320, 4320, 135, 66, 4320, 4320, 135, 135, 4320, 4320, 66, 4320, 4320, 135, 66, 4320, 135, 135, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 135, 4320, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 4320, 66, 66, 66, 135, 66, 135, 135, 66, 4320, 135, 4320, 66, 4320, 66, 135, 135, 135, 135, 66, 135, 4320, 4320, 66, 4320, 4320, 66, 4320, 135, 4320, 135, 135, 135, 66, 135, 66, 66, 4320, 66, 135, 66, 66, 135, 4320, 135, 4320, 66, 4320, 4320, 135, 4320, 135, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 578688 . Total input tokens: 129047464 . Total output tokens: 115563730
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 75.5992121687159,
    "estimated_duration": 3600.161963924176,
    "input_throughput": 6048.393716227433,
    "output_throughput": 5355.205180542831,
    "total_throughput": 11403.598896770265,
    "itl": 146.55502298940357,
    "ttft": 1539763.469931975,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 503,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5394253351981926,
    "arrivals": 192504,
    "finished_requests": 87985,
    "scheduler_time": 168.53641322795463
}
#Debug simulation 
Total elapsed time: 75.5993443466723. Arrivals time: 0.3638856364414096 Scheduler time: 75.08636427437887 Scheduler overhead time: 0.05662451917305589 Adapter cache time: 0.01601650333032012 Engine time: 0.05427149869501591 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-16/adapters_384_slots_64_rate_0.4-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-16/adapters_384_slots_64_rate_0.4-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 135, 66, 4320, 4320, 66, 135, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 66, 4320, 66, 4320, 135, 135, 135, 66, 66, 135, 66, 4320, 66, 4320, 135, 4320, 135, 66, 135, 4320, 135, 4320, 66, 4320, 4320, 4320, 4320, 66, 135, 135, 135, 4320, 135, 66, 135, 66, 4320, 135, 4320, 4320, 135, 4320, 4320, 66, 66, 4320, 135, 135, 66, 66, 66, 135, 66, 135, 66, 4320, 66, 135, 4320, 66, 4320, 135, 66, 4320, 4320, 4320, 4320, 135, 66, 135, 4320, 4320, 135, 66, 66, 4320, 135, 135, 66, 66, 4320, 135, 4320, 135, 4320, 4320, 135, 4320, 4320, 66, 135, 135, 135, 135, 66, 66, 4320, 66, 4320, 66, 66, 66, 135, 135, 4320, 66, 66, 4320, 66, 4320, 135, 66, 4320, 135, 135, 66, 4320, 4320, 4320, 66, 135, 4320, 66, 4320, 135, 135, 4320, 4320, 66, 135, 4320, 66, 135, 135, 66, 135, 66, 135, 4320, 4320, 135, 66, 4320, 66, 4320, 135, 135, 135, 135, 135, 66, 66, 4320, 66, 4320, 66, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 66, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 66, 66, 66, 66, 66, 135, 66, 66, 135, 4320, 4320, 66, 66, 4320, 66, 66, 66, 135, 66, 135, 4320, 4320, 135, 135, 66, 4320, 135, 4320, 66, 135, 135, 66, 66, 135, 66, 4320, 4320, 66, 4320, 4320, 66, 135, 4320, 66, 66, 135, 135, 66, 66, 4320, 4320, 4320, 4320, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 4320, 135, 135, 135, 4320, 66, 135, 135, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 135, 66, 4320, 4320, 4320, 135, 66, 4320, 4320, 135, 135, 4320, 4320, 66, 4320, 4320, 135, 66, 4320, 135, 135, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 135, 4320, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 4320, 66, 66, 66, 135, 66, 135, 135, 66, 4320, 135, 4320, 66, 4320, 66, 135, 135, 135, 135, 66, 135, 4320, 4320, 66, 4320, 4320, 66, 4320, 135, 4320, 135, 135, 135, 66, 135, 66, 66, 4320, 66, 135, 66, 66, 135, 4320, 135, 4320, 66, 4320, 4320, 135, 4320, 135, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 578688 . Total input tokens: 129047464 . Total output tokens: 115563730
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 73.20742241619155,
    "estimated_duration": 3600.1229833075413,
    "input_throughput": 6074.029721037446,
    "output_throughput": 5376.122729623601,
    "total_throughput": 11450.152450661046,
    "itl": 147.21740299519308,
    "ttft": 1543538.9474121847,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 533,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7411997171398315,
    "arrivals": 192504,
    "finished_requests": 88390,
    "scheduler_time": 167.46123159021292
}
#Debug simulation 
Total elapsed time: 73.2075562402606. Arrivals time: 0.3720370759256184 Scheduler time: 72.68902663560584 Scheduler overhead time: 0.055498153902590275 Adapter cache time: 0.016193446703255177 Engine time: 0.05321054207161069 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-32/adapters_384_slots_64_rate_0.4-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-32/adapters_384_slots_64_rate_0.4-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 135, 66, 4320, 4320, 66, 135, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 66, 4320, 66, 4320, 135, 135, 135, 66, 66, 135, 66, 4320, 66, 4320, 135, 4320, 135, 66, 135, 4320, 135, 4320, 66, 4320, 4320, 4320, 4320, 66, 135, 135, 135, 4320, 135, 66, 135, 66, 4320, 135, 4320, 4320, 135, 4320, 4320, 66, 66, 4320, 135, 135, 66, 66, 66, 135, 66, 135, 66, 4320, 66, 135, 4320, 66, 4320, 135, 66, 4320, 4320, 4320, 4320, 135, 66, 135, 4320, 4320, 135, 66, 66, 4320, 135, 135, 66, 66, 4320, 135, 4320, 135, 4320, 4320, 135, 4320, 4320, 66, 135, 135, 135, 135, 66, 66, 4320, 66, 4320, 66, 66, 66, 135, 135, 4320, 66, 66, 4320, 66, 4320, 135, 66, 4320, 135, 135, 66, 4320, 4320, 4320, 66, 135, 4320, 66, 4320, 135, 135, 4320, 4320, 66, 135, 4320, 66, 135, 135, 66, 135, 66, 135, 4320, 4320, 135, 66, 4320, 66, 4320, 135, 135, 135, 135, 135, 66, 66, 4320, 66, 4320, 66, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 66, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 66, 66, 66, 66, 66, 135, 66, 66, 135, 4320, 4320, 66, 66, 4320, 66, 66, 66, 135, 66, 135, 4320, 4320, 135, 135, 66, 4320, 135, 4320, 66, 135, 135, 66, 66, 135, 66, 4320, 4320, 66, 4320, 4320, 66, 135, 4320, 66, 66, 135, 135, 66, 66, 4320, 4320, 4320, 4320, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 4320, 135, 135, 135, 4320, 66, 135, 135, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 135, 66, 4320, 4320, 4320, 135, 66, 4320, 4320, 135, 135, 4320, 4320, 66, 4320, 4320, 135, 66, 4320, 135, 135, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 135, 4320, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 4320, 66, 66, 66, 135, 66, 135, 135, 66, 4320, 135, 4320, 66, 4320, 66, 135, 135, 135, 135, 66, 135, 4320, 4320, 66, 4320, 4320, 66, 4320, 135, 4320, 135, 135, 135, 66, 135, 66, 66, 4320, 66, 135, 66, 66, 135, 4320, 135, 4320, 66, 4320, 4320, 135, 4320, 135, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 578688 . Total input tokens: 129047464 . Total output tokens: 115563730
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 73.24958638614044,
    "estimated_duration": 3600.1267921467183,
    "input_throughput": 6074.02329487423,
    "output_throughput": 5376.1170418275715,
    "total_throughput": 11450.140336701801,
    "itl": 147.2174639512972,
    "ttft": 1543540.3835371886,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 533,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7439418919198322,
    "arrivals": 192504,
    "finished_requests": 88390,
    "scheduler_time": 167.46133583883974
}
#Debug simulation 
Total elapsed time: 73.24971914896742. Arrivals time: 0.37399852043017745 Scheduler time: 72.72855895757675 Scheduler overhead time: 0.056475994642823935 Adapter cache time: 0.016306322067975998 Engine time: 0.052820015233010054 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-16/adapters_384_slots_64_rate_0.4-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-16/adapters_384_slots_64_rate_0.4-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 135, 66, 4320, 4320, 66, 135, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 66, 4320, 66, 4320, 135, 135, 135, 66, 66, 135, 66, 4320, 66, 4320, 135, 4320, 135, 66, 135, 4320, 135, 4320, 66, 4320, 4320, 4320, 4320, 66, 135, 135, 135, 4320, 135, 66, 135, 66, 4320, 135, 4320, 4320, 135, 4320, 4320, 66, 66, 4320, 135, 135, 66, 66, 66, 135, 66, 135, 66, 4320, 66, 135, 4320, 66, 4320, 135, 66, 4320, 4320, 4320, 4320, 135, 66, 135, 4320, 4320, 135, 66, 66, 4320, 135, 135, 66, 66, 4320, 135, 4320, 135, 4320, 4320, 135, 4320, 4320, 66, 135, 135, 135, 135, 66, 66, 4320, 66, 4320, 66, 66, 66, 135, 135, 4320, 66, 66, 4320, 66, 4320, 135, 66, 4320, 135, 135, 66, 4320, 4320, 4320, 66, 135, 4320, 66, 4320, 135, 135, 4320, 4320, 66, 135, 4320, 66, 135, 135, 66, 135, 66, 135, 4320, 4320, 135, 66, 4320, 66, 4320, 135, 135, 135, 135, 135, 66, 66, 4320, 66, 4320, 66, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 66, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 66, 66, 66, 66, 66, 135, 66, 66, 135, 4320, 4320, 66, 66, 4320, 66, 66, 66, 135, 66, 135, 4320, 4320, 135, 135, 66, 4320, 135, 4320, 66, 135, 135, 66, 66, 135, 66, 4320, 4320, 66, 4320, 4320, 66, 135, 4320, 66, 66, 135, 135, 66, 66, 4320, 4320, 4320, 4320, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 4320, 135, 135, 135, 4320, 66, 135, 135, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 135, 66, 4320, 4320, 4320, 135, 66, 4320, 4320, 135, 135, 4320, 4320, 66, 4320, 4320, 135, 66, 4320, 135, 135, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 135, 4320, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 4320, 66, 66, 66, 135, 66, 135, 135, 66, 4320, 135, 4320, 66, 4320, 66, 135, 135, 135, 135, 66, 135, 4320, 4320, 66, 4320, 4320, 66, 4320, 135, 4320, 135, 135, 135, 66, 135, 66, 66, 4320, 66, 135, 66, 66, 135, 4320, 135, 4320, 66, 4320, 4320, 135, 4320, 135, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 578688 . Total input tokens: 129047464 . Total output tokens: 115563730
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 78.36973643815145,
    "estimated_duration": 3600.0494337646346,
    "input_throughput": 6089.087775963346,
    "output_throughput": 5389.646269304128,
    "total_throughput": 11478.734045267473,
    "itl": 147.5223953123443,
    "ttft": 1539612.142427881,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 494,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5465460498165278,
    "arrivals": 192504,
    "finished_requests": 88629,
    "scheduler_time": 166.7635533900429
}
#Debug simulation 
Total elapsed time: 78.36988124903291. Arrivals time: 0.3690078961662948 Scheduler time: 77.85292703146115 Scheduler overhead time: 0.056467482820153236 Adapter cache time: 0.01604936784133315 Engine time: 0.05387026537209749 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-32/adapters_384_slots_64_rate_0.4-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-32/adapters_384_slots_64_rate_0.4-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 135, 66, 4320, 4320, 66, 135, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 66, 4320, 66, 4320, 135, 135, 135, 66, 66, 135, 66, 4320, 66, 4320, 135, 4320, 135, 66, 135, 4320, 135, 4320, 66, 4320, 4320, 4320, 4320, 66, 135, 135, 135, 4320, 135, 66, 135, 66, 4320, 135, 4320, 4320, 135, 4320, 4320, 66, 66, 4320, 135, 135, 66, 66, 66, 135, 66, 135, 66, 4320, 66, 135, 4320, 66, 4320, 135, 66, 4320, 4320, 4320, 4320, 135, 66, 135, 4320, 4320, 135, 66, 66, 4320, 135, 135, 66, 66, 4320, 135, 4320, 135, 4320, 4320, 135, 4320, 4320, 66, 135, 135, 135, 135, 66, 66, 4320, 66, 4320, 66, 66, 66, 135, 135, 4320, 66, 66, 4320, 66, 4320, 135, 66, 4320, 135, 135, 66, 4320, 4320, 4320, 66, 135, 4320, 66, 4320, 135, 135, 4320, 4320, 66, 135, 4320, 66, 135, 135, 66, 135, 66, 135, 4320, 4320, 135, 66, 4320, 66, 4320, 135, 135, 135, 135, 135, 66, 66, 4320, 66, 4320, 66, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 66, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 66, 66, 66, 66, 66, 135, 66, 66, 135, 4320, 4320, 66, 66, 4320, 66, 66, 66, 135, 66, 135, 4320, 4320, 135, 135, 66, 4320, 135, 4320, 66, 135, 135, 66, 66, 135, 66, 4320, 4320, 66, 4320, 4320, 66, 135, 4320, 66, 66, 135, 135, 66, 66, 4320, 4320, 4320, 4320, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 4320, 135, 135, 135, 4320, 66, 135, 135, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 135, 66, 4320, 4320, 4320, 135, 66, 4320, 4320, 135, 135, 4320, 4320, 66, 4320, 4320, 135, 66, 4320, 135, 135, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 135, 4320, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 4320, 66, 66, 66, 135, 66, 135, 135, 66, 4320, 135, 4320, 66, 4320, 66, 135, 135, 135, 135, 66, 135, 4320, 4320, 66, 4320, 4320, 66, 4320, 135, 4320, 135, 135, 135, 66, 135, 66, 66, 4320, 66, 135, 66, 66, 135, 4320, 135, 4320, 66, 4320, 4320, 135, 4320, 135, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 578688 . Total input tokens: 129047464 . Total output tokens: 115563730
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 72.65771764004603,
    "estimated_duration": 3600.1516202884904,
    "input_throughput": 6071.565952060767,
    "output_throughput": 5371.462660356062,
    "total_throughput": 11443.028612416829,
    "itl": 147.16228556290523,
    "ttft": 1543092.4899841535,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 545,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.805374792199585,
    "arrivals": 192504,
    "finished_requests": 88339,
    "scheduler_time": 167.67522490667653
}
#Debug simulation 
Total elapsed time: 72.65785471582785. Arrivals time: 0.34883377328515053 Scheduler time: 72.16166881658137 Scheduler overhead time: 0.05606047250330448 Adapter cache time: 0.016587203834205866 Engine time: 0.05316146556288004 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-16/adapters_384_slots_64_rate_0.4-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-16/adapters_384_slots_64_rate_0.4-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 135, 66, 4320, 4320, 66, 135, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 66, 4320, 66, 4320, 135, 135, 135, 66, 66, 135, 66, 4320, 66, 4320, 135, 4320, 135, 66, 135, 4320, 135, 4320, 66, 4320, 4320, 4320, 4320, 66, 135, 135, 135, 4320, 135, 66, 135, 66, 4320, 135, 4320, 4320, 135, 4320, 4320, 66, 66, 4320, 135, 135, 66, 66, 66, 135, 66, 135, 66, 4320, 66, 135, 4320, 66, 4320, 135, 66, 4320, 4320, 4320, 4320, 135, 66, 135, 4320, 4320, 135, 66, 66, 4320, 135, 135, 66, 66, 4320, 135, 4320, 135, 4320, 4320, 135, 4320, 4320, 66, 135, 135, 135, 135, 66, 66, 4320, 66, 4320, 66, 66, 66, 135, 135, 4320, 66, 66, 4320, 66, 4320, 135, 66, 4320, 135, 135, 66, 4320, 4320, 4320, 66, 135, 4320, 66, 4320, 135, 135, 4320, 4320, 66, 135, 4320, 66, 135, 135, 66, 135, 66, 135, 4320, 4320, 135, 66, 4320, 66, 4320, 135, 135, 135, 135, 135, 66, 66, 4320, 66, 4320, 66, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 66, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 66, 66, 66, 66, 66, 135, 66, 66, 135, 4320, 4320, 66, 66, 4320, 66, 66, 66, 135, 66, 135, 4320, 4320, 135, 135, 66, 4320, 135, 4320, 66, 135, 135, 66, 66, 135, 66, 4320, 4320, 66, 4320, 4320, 66, 135, 4320, 66, 66, 135, 135, 66, 66, 4320, 4320, 4320, 4320, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 4320, 135, 135, 135, 4320, 66, 135, 135, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 135, 66, 4320, 4320, 4320, 135, 66, 4320, 4320, 135, 135, 4320, 4320, 66, 4320, 4320, 135, 66, 4320, 135, 135, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 135, 4320, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 4320, 66, 66, 66, 135, 66, 135, 135, 66, 4320, 135, 4320, 66, 4320, 66, 135, 135, 135, 135, 66, 135, 4320, 4320, 66, 4320, 4320, 66, 4320, 135, 4320, 135, 135, 135, 66, 135, 66, 66, 4320, 66, 135, 66, 66, 135, 4320, 135, 4320, 66, 4320, 4320, 135, 4320, 135, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 578688 . Total input tokens: 129047464 . Total output tokens: 115563730
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 76.9488048190251,
    "estimated_duration": 3600.046975097096,
    "input_throughput": 6068.606646281542,
    "output_throughput": 5373.292385852347,
    "total_throughput": 11441.89903213389,
    "itl": 147.00346817316816,
    "ttft": 1540473.9931720686,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 501,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4980151977459737,
    "arrivals": 192504,
    "finished_requests": 88315,
    "scheduler_time": 167.52387338720408
}
#Debug simulation 
Total elapsed time: 76.94894888717681. Arrivals time: 0.3546505612321198 Scheduler time: 76.44799402728677 Scheduler overhead time: 0.055868727155029774 Adapter cache time: 0.015957074239850044 Engine time: 0.05327631812542677 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-32/adapters_384_slots_64_rate_0.4-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-32/adapters_384_slots_64_rate_0.4-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 135, 66, 4320, 4320, 66, 135, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 66, 4320, 66, 4320, 135, 135, 135, 66, 66, 135, 66, 4320, 66, 4320, 135, 4320, 135, 66, 135, 4320, 135, 4320, 66, 4320, 4320, 4320, 4320, 66, 135, 135, 135, 4320, 135, 66, 135, 66, 4320, 135, 4320, 4320, 135, 4320, 4320, 66, 66, 4320, 135, 135, 66, 66, 66, 135, 66, 135, 66, 4320, 66, 135, 4320, 66, 4320, 135, 66, 4320, 4320, 4320, 4320, 135, 66, 135, 4320, 4320, 135, 66, 66, 4320, 135, 135, 66, 66, 4320, 135, 4320, 135, 4320, 4320, 135, 4320, 4320, 66, 135, 135, 135, 135, 66, 66, 4320, 66, 4320, 66, 66, 66, 135, 135, 4320, 66, 66, 4320, 66, 4320, 135, 66, 4320, 135, 135, 66, 4320, 4320, 4320, 66, 135, 4320, 66, 4320, 135, 135, 4320, 4320, 66, 135, 4320, 66, 135, 135, 66, 135, 66, 135, 4320, 4320, 135, 66, 4320, 66, 4320, 135, 135, 135, 135, 135, 66, 66, 4320, 66, 4320, 66, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 66, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 66, 66, 66, 66, 66, 135, 66, 66, 135, 4320, 4320, 66, 66, 4320, 66, 66, 66, 135, 66, 135, 4320, 4320, 135, 135, 66, 4320, 135, 4320, 66, 135, 135, 66, 66, 135, 66, 4320, 4320, 66, 4320, 4320, 66, 135, 4320, 66, 66, 135, 135, 66, 66, 4320, 4320, 4320, 4320, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 4320, 135, 135, 135, 4320, 66, 135, 135, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 135, 66, 4320, 4320, 4320, 135, 66, 4320, 4320, 135, 135, 4320, 4320, 66, 4320, 4320, 135, 66, 4320, 135, 135, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 135, 4320, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 4320, 66, 66, 66, 135, 66, 135, 135, 66, 4320, 135, 4320, 66, 4320, 66, 135, 135, 135, 135, 66, 135, 4320, 4320, 66, 4320, 4320, 66, 4320, 135, 4320, 135, 135, 135, 66, 135, 66, 66, 4320, 66, 135, 66, 66, 135, 4320, 135, 4320, 66, 4320, 4320, 135, 4320, 135, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 578688 . Total input tokens: 129047464 . Total output tokens: 115563730
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 73.19742028880864,
    "estimated_duration": 3600.004485909796,
    "input_throughput": 6071.4327122501445,
    "output_throughput": 5371.497473318574,
    "total_throughput": 11442.930185568717,
    "itl": 147.16199460160982,
    "ttft": 1543104.6408826672,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 545,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8286392426863272,
    "arrivals": 192504,
    "finished_requests": 88335,
    "scheduler_time": 167.66746860457144
}
#Debug simulation 
Total elapsed time: 73.19755155779421. Arrivals time: 0.34252715669572353 Scheduler time: 72.70947955129668 Scheduler overhead time: 0.05504892626777291 Adapter cache time: 0.01642597420141101 Engine time: 0.05248067621141672 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-8/adapters_384_slots_64_rate_0.4-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-8/adapters_384_slots_64_rate_0.4-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 135, 33, 4320, 4320, 33, 135, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 33, 4320, 33, 4320, 135, 135, 135, 33, 33, 135, 33, 4320, 33, 4320, 135, 4320, 135, 33, 135, 4320, 135, 4320, 33, 4320, 4320, 4320, 4320, 33, 135, 135, 135, 4320, 135, 33, 135, 33, 4320, 135, 4320, 4320, 135, 4320, 4320, 33, 33, 4320, 135, 135, 33, 33, 33, 135, 33, 135, 33, 4320, 33, 135, 4320, 33, 4320, 135, 33, 4320, 4320, 4320, 4320, 135, 33, 135, 4320, 4320, 135, 33, 33, 4320, 135, 135, 33, 33, 4320, 135, 4320, 135, 4320, 4320, 135, 4320, 4320, 33, 135, 135, 135, 135, 33, 33, 4320, 33, 4320, 33, 33, 33, 135, 135, 4320, 33, 33, 4320, 33, 4320, 135, 33, 4320, 135, 135, 33, 4320, 4320, 4320, 33, 135, 4320, 33, 4320, 135, 135, 4320, 4320, 33, 135, 4320, 33, 135, 135, 33, 135, 33, 135, 4320, 4320, 135, 33, 4320, 33, 4320, 135, 135, 135, 135, 135, 33, 33, 4320, 33, 4320, 33, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 33, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 33, 33, 33, 33, 33, 135, 33, 33, 135, 4320, 4320, 33, 33, 4320, 33, 33, 33, 135, 33, 135, 4320, 4320, 135, 135, 33, 4320, 135, 4320, 33, 135, 135, 33, 33, 135, 33, 4320, 4320, 33, 4320, 4320, 33, 135, 4320, 33, 33, 135, 135, 33, 33, 4320, 4320, 4320, 4320, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 4320, 135, 135, 135, 4320, 33, 135, 135, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 135, 33, 4320, 4320, 4320, 135, 33, 4320, 4320, 135, 135, 4320, 4320, 33, 4320, 4320, 135, 33, 4320, 135, 135, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 135, 4320, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 4320, 33, 33, 33, 135, 33, 135, 135, 33, 4320, 135, 4320, 33, 4320, 33, 135, 135, 135, 135, 33, 135, 4320, 4320, 33, 4320, 4320, 33, 4320, 135, 4320, 135, 135, 135, 33, 135, 33, 33, 4320, 33, 135, 33, 33, 135, 4320, 135, 4320, 33, 4320, 4320, 135, 4320, 135, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 574464 . Total input tokens: 128075419 . Total output tokens: 114736704
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 71.66466970322654,
    "estimated_duration": 3600.016239124197,
    "input_throughput": 6105.954679067674,
    "output_throughput": 5406.506723073848,
    "total_throughput": 11512.461402141522,
    "itl": 148.30700832947875,
    "ttft": 1542791.1211196382,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 554,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6955102101387685,
    "arrivals": 191087,
    "finished_requests": 88941,
    "scheduler_time": 165.34004129439495
}
#Debug simulation 
Total elapsed time: 71.66479827696458. Arrivals time: 0.3596727824769914 Scheduler time: 71.16028448846191 Scheduler overhead time: 0.05478126183152199 Adapter cache time: 0.01625216845422983 Engine time: 0.0527315647341311 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-16/adapters_384_slots_64_rate_0.4-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-16/adapters_384_slots_64_rate_0.4-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 135, 33, 4320, 4320, 33, 135, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 33, 4320, 33, 4320, 135, 135, 135, 33, 33, 135, 33, 4320, 33, 4320, 135, 4320, 135, 33, 135, 4320, 135, 4320, 33, 4320, 4320, 4320, 4320, 33, 135, 135, 135, 4320, 135, 33, 135, 33, 4320, 135, 4320, 4320, 135, 4320, 4320, 33, 33, 4320, 135, 135, 33, 33, 33, 135, 33, 135, 33, 4320, 33, 135, 4320, 33, 4320, 135, 33, 4320, 4320, 4320, 4320, 135, 33, 135, 4320, 4320, 135, 33, 33, 4320, 135, 135, 33, 33, 4320, 135, 4320, 135, 4320, 4320, 135, 4320, 4320, 33, 135, 135, 135, 135, 33, 33, 4320, 33, 4320, 33, 33, 33, 135, 135, 4320, 33, 33, 4320, 33, 4320, 135, 33, 4320, 135, 135, 33, 4320, 4320, 4320, 33, 135, 4320, 33, 4320, 135, 135, 4320, 4320, 33, 135, 4320, 33, 135, 135, 33, 135, 33, 135, 4320, 4320, 135, 33, 4320, 33, 4320, 135, 135, 135, 135, 135, 33, 33, 4320, 33, 4320, 33, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 33, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 33, 33, 33, 33, 33, 135, 33, 33, 135, 4320, 4320, 33, 33, 4320, 33, 33, 33, 135, 33, 135, 4320, 4320, 135, 135, 33, 4320, 135, 4320, 33, 135, 135, 33, 33, 135, 33, 4320, 4320, 33, 4320, 4320, 33, 135, 4320, 33, 33, 135, 135, 33, 33, 4320, 4320, 4320, 4320, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 4320, 135, 135, 135, 4320, 33, 135, 135, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 135, 33, 4320, 4320, 4320, 135, 33, 4320, 4320, 135, 135, 4320, 4320, 33, 4320, 4320, 135, 33, 4320, 135, 135, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 135, 4320, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 4320, 33, 33, 33, 135, 33, 135, 135, 33, 4320, 135, 4320, 33, 4320, 33, 135, 135, 135, 135, 33, 135, 4320, 4320, 33, 4320, 4320, 33, 4320, 135, 4320, 135, 135, 135, 33, 135, 33, 33, 4320, 33, 135, 33, 33, 135, 4320, 135, 4320, 33, 4320, 4320, 135, 4320, 135, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 574464 . Total input tokens: 128075419 . Total output tokens: 114736704
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 71.00393531098962,
    "estimated_duration": 3600.1717495039347,
    "input_throughput": 6109.056325724041,
    "output_throughput": 5411.709317113708,
    "total_throughput": 11520.765642837749,
    "itl": 148.41386619901476,
    "ttft": 1544118.1639384353,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 561,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8335016270843396,
    "arrivals": 191087,
    "finished_requests": 88983,
    "scheduler_time": 165.22597321211322
}
#Debug simulation 
Total elapsed time: 71.00406049983576. Arrivals time: 0.36347626987844706 Scheduler time: 70.49546390166506 Scheduler overhead time: 0.055118024349212646 Adapter cache time: 0.01643470861017704 Engine time: 0.05261343438178301 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-32/adapters_384_slots_64_rate_0.4-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-32/adapters_384_slots_64_rate_0.4-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 135, 33, 4320, 4320, 33, 135, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 33, 4320, 33, 4320, 135, 135, 135, 33, 33, 135, 33, 4320, 33, 4320, 135, 4320, 135, 33, 135, 4320, 135, 4320, 33, 4320, 4320, 4320, 4320, 33, 135, 135, 135, 4320, 135, 33, 135, 33, 4320, 135, 4320, 4320, 135, 4320, 4320, 33, 33, 4320, 135, 135, 33, 33, 33, 135, 33, 135, 33, 4320, 33, 135, 4320, 33, 4320, 135, 33, 4320, 4320, 4320, 4320, 135, 33, 135, 4320, 4320, 135, 33, 33, 4320, 135, 135, 33, 33, 4320, 135, 4320, 135, 4320, 4320, 135, 4320, 4320, 33, 135, 135, 135, 135, 33, 33, 4320, 33, 4320, 33, 33, 33, 135, 135, 4320, 33, 33, 4320, 33, 4320, 135, 33, 4320, 135, 135, 33, 4320, 4320, 4320, 33, 135, 4320, 33, 4320, 135, 135, 4320, 4320, 33, 135, 4320, 33, 135, 135, 33, 135, 33, 135, 4320, 4320, 135, 33, 4320, 33, 4320, 135, 135, 135, 135, 135, 33, 33, 4320, 33, 4320, 33, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 33, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 33, 33, 33, 33, 33, 135, 33, 33, 135, 4320, 4320, 33, 33, 4320, 33, 33, 33, 135, 33, 135, 4320, 4320, 135, 135, 33, 4320, 135, 4320, 33, 135, 135, 33, 33, 135, 33, 4320, 4320, 33, 4320, 4320, 33, 135, 4320, 33, 33, 135, 135, 33, 33, 4320, 4320, 4320, 4320, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 4320, 135, 135, 135, 4320, 33, 135, 135, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 135, 33, 4320, 4320, 4320, 135, 33, 4320, 4320, 135, 135, 4320, 4320, 33, 4320, 4320, 135, 33, 4320, 135, 135, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 135, 4320, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 4320, 33, 33, 33, 135, 33, 135, 135, 33, 4320, 135, 4320, 33, 4320, 33, 135, 135, 135, 135, 33, 135, 4320, 4320, 33, 4320, 4320, 33, 4320, 135, 4320, 135, 135, 135, 33, 135, 33, 33, 4320, 33, 135, 33, 33, 135, 4320, 135, 4320, 33, 4320, 4320, 135, 4320, 135, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 574464 . Total input tokens: 128075419 . Total output tokens: 114736704
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 70.86178999207914,
    "estimated_duration": 3600.174351227008,
    "input_throughput": 6109.051910917632,
    "output_throughput": 5411.70540625617,
    "total_throughput": 11520.757317173802,
    "itl": 148.41392030884157,
    "ttft": 1544118.9330880488,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 561,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8362426170706863,
    "arrivals": 191087,
    "finished_requests": 88983,
    "scheduler_time": 165.2259731830969
}
#Debug simulation 
Total elapsed time: 70.8619175311178. Arrivals time: 0.37110381899401546 Scheduler time: 70.34652786655352 Scheduler overhead time: 0.05498194321990013 Adapter cache time: 0.016176431439816952 Engine time: 0.05188413243740797 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-16/adapters_384_slots_64_rate_0.4-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-16/adapters_384_slots_64_rate_0.4-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 135, 33, 4320, 4320, 33, 135, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 33, 4320, 33, 4320, 135, 135, 135, 33, 33, 135, 33, 4320, 33, 4320, 135, 4320, 135, 33, 135, 4320, 135, 4320, 33, 4320, 4320, 4320, 4320, 33, 135, 135, 135, 4320, 135, 33, 135, 33, 4320, 135, 4320, 4320, 135, 4320, 4320, 33, 33, 4320, 135, 135, 33, 33, 33, 135, 33, 135, 33, 4320, 33, 135, 4320, 33, 4320, 135, 33, 4320, 4320, 4320, 4320, 135, 33, 135, 4320, 4320, 135, 33, 33, 4320, 135, 135, 33, 33, 4320, 135, 4320, 135, 4320, 4320, 135, 4320, 4320, 33, 135, 135, 135, 135, 33, 33, 4320, 33, 4320, 33, 33, 33, 135, 135, 4320, 33, 33, 4320, 33, 4320, 135, 33, 4320, 135, 135, 33, 4320, 4320, 4320, 33, 135, 4320, 33, 4320, 135, 135, 4320, 4320, 33, 135, 4320, 33, 135, 135, 33, 135, 33, 135, 4320, 4320, 135, 33, 4320, 33, 4320, 135, 135, 135, 135, 135, 33, 33, 4320, 33, 4320, 33, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 33, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 33, 33, 33, 33, 33, 135, 33, 33, 135, 4320, 4320, 33, 33, 4320, 33, 33, 33, 135, 33, 135, 4320, 4320, 135, 135, 33, 4320, 135, 4320, 33, 135, 135, 33, 33, 135, 33, 4320, 4320, 33, 4320, 4320, 33, 135, 4320, 33, 33, 135, 135, 33, 33, 4320, 4320, 4320, 4320, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 4320, 135, 135, 135, 4320, 33, 135, 135, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 135, 33, 4320, 4320, 4320, 135, 33, 4320, 4320, 135, 135, 4320, 4320, 33, 4320, 4320, 135, 33, 4320, 135, 135, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 135, 4320, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 4320, 33, 33, 33, 135, 33, 135, 135, 33, 4320, 135, 4320, 33, 4320, 33, 135, 135, 135, 135, 33, 135, 4320, 4320, 33, 4320, 4320, 33, 4320, 135, 4320, 135, 135, 135, 33, 135, 33, 33, 4320, 33, 135, 33, 33, 135, 4320, 135, 4320, 33, 4320, 4320, 135, 4320, 135, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 574464 . Total input tokens: 128075419 . Total output tokens: 114736704
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 71.85464582592249,
    "estimated_duration": 3600.0987293380877,
    "input_throughput": 6100.563804270457,
    "output_throughput": 5408.238068954231,
    "total_throughput": 11508.801873224687,
    "itl": 148.43580289470498,
    "ttft": 1541899.9012253361,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 555,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7387454054481266,
    "arrivals": 191087,
    "finished_requests": 88929,
    "scheduler_time": 165.27621682615506
}
#Debug simulation 
Total elapsed time: 71.85477988375351. Arrivals time: 0.36975341755896807 Scheduler time: 71.33901674533263 Scheduler overhead time: 0.05552512314170599 Adapter cache time: 0.01631296332925558 Engine time: 0.05313609028235078 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-32/adapters_384_slots_64_rate_0.4-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-32/adapters_384_slots_64_rate_0.4-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 135, 33, 4320, 4320, 33, 135, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 33, 4320, 33, 4320, 135, 135, 135, 33, 33, 135, 33, 4320, 33, 4320, 135, 4320, 135, 33, 135, 4320, 135, 4320, 33, 4320, 4320, 4320, 4320, 33, 135, 135, 135, 4320, 135, 33, 135, 33, 4320, 135, 4320, 4320, 135, 4320, 4320, 33, 33, 4320, 135, 135, 33, 33, 33, 135, 33, 135, 33, 4320, 33, 135, 4320, 33, 4320, 135, 33, 4320, 4320, 4320, 4320, 135, 33, 135, 4320, 4320, 135, 33, 33, 4320, 135, 135, 33, 33, 4320, 135, 4320, 135, 4320, 4320, 135, 4320, 4320, 33, 135, 135, 135, 135, 33, 33, 4320, 33, 4320, 33, 33, 33, 135, 135, 4320, 33, 33, 4320, 33, 4320, 135, 33, 4320, 135, 135, 33, 4320, 4320, 4320, 33, 135, 4320, 33, 4320, 135, 135, 4320, 4320, 33, 135, 4320, 33, 135, 135, 33, 135, 33, 135, 4320, 4320, 135, 33, 4320, 33, 4320, 135, 135, 135, 135, 135, 33, 33, 4320, 33, 4320, 33, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 33, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 33, 33, 33, 33, 33, 135, 33, 33, 135, 4320, 4320, 33, 33, 4320, 33, 33, 33, 135, 33, 135, 4320, 4320, 135, 135, 33, 4320, 135, 4320, 33, 135, 135, 33, 33, 135, 33, 4320, 4320, 33, 4320, 4320, 33, 135, 4320, 33, 33, 135, 135, 33, 33, 4320, 4320, 4320, 4320, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 4320, 135, 135, 135, 4320, 33, 135, 135, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 135, 33, 4320, 4320, 4320, 135, 33, 4320, 4320, 135, 135, 4320, 4320, 33, 4320, 4320, 135, 33, 4320, 135, 135, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 135, 4320, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 4320, 33, 33, 33, 135, 33, 135, 135, 33, 4320, 135, 4320, 33, 4320, 33, 135, 135, 135, 135, 33, 135, 4320, 4320, 33, 4320, 4320, 33, 4320, 135, 4320, 135, 135, 135, 33, 135, 33, 33, 4320, 33, 135, 33, 33, 135, 4320, 135, 4320, 33, 4320, 4320, 135, 4320, 135, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 574464 . Total input tokens: 128075419 . Total output tokens: 114736704
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 71.58481721580029,
    "estimated_duration": 3600.1009506260375,
    "input_throughput": 6107.414847957674,
    "output_throughput": 5409.754411640399,
    "total_throughput": 11517.169259598073,
    "itl": 148.1579067992518,
    "ttft": 1542777.5338391596,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 547,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8144113174267156,
    "arrivals": 191087,
    "finished_requests": 88934,
    "scheduler_time": 165.40942138780758
}
#Debug simulation 
Total elapsed time: 71.5849547428079. Arrivals time: 0.37635270366445184 Scheduler time: 71.06405136082321 Scheduler overhead time: 0.054530082270503044 Adapter cache time: 0.01628143945708871 Engine time: 0.052648202516138554 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-16/adapters_384_slots_64_rate_0.4-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-16/adapters_384_slots_64_rate_0.4-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 135, 33, 4320, 4320, 33, 135, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 33, 4320, 33, 4320, 135, 135, 135, 33, 33, 135, 33, 4320, 33, 4320, 135, 4320, 135, 33, 135, 4320, 135, 4320, 33, 4320, 4320, 4320, 4320, 33, 135, 135, 135, 4320, 135, 33, 135, 33, 4320, 135, 4320, 4320, 135, 4320, 4320, 33, 33, 4320, 135, 135, 33, 33, 33, 135, 33, 135, 33, 4320, 33, 135, 4320, 33, 4320, 135, 33, 4320, 4320, 4320, 4320, 135, 33, 135, 4320, 4320, 135, 33, 33, 4320, 135, 135, 33, 33, 4320, 135, 4320, 135, 4320, 4320, 135, 4320, 4320, 33, 135, 135, 135, 135, 33, 33, 4320, 33, 4320, 33, 33, 33, 135, 135, 4320, 33, 33, 4320, 33, 4320, 135, 33, 4320, 135, 135, 33, 4320, 4320, 4320, 33, 135, 4320, 33, 4320, 135, 135, 4320, 4320, 33, 135, 4320, 33, 135, 135, 33, 135, 33, 135, 4320, 4320, 135, 33, 4320, 33, 4320, 135, 135, 135, 135, 135, 33, 33, 4320, 33, 4320, 33, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 33, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 33, 33, 33, 33, 33, 135, 33, 33, 135, 4320, 4320, 33, 33, 4320, 33, 33, 33, 135, 33, 135, 4320, 4320, 135, 135, 33, 4320, 135, 4320, 33, 135, 135, 33, 33, 135, 33, 4320, 4320, 33, 4320, 4320, 33, 135, 4320, 33, 33, 135, 135, 33, 33, 4320, 4320, 4320, 4320, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 4320, 135, 135, 135, 4320, 33, 135, 135, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 135, 33, 4320, 4320, 4320, 135, 33, 4320, 4320, 135, 135, 4320, 4320, 33, 4320, 4320, 135, 33, 4320, 135, 135, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 135, 4320, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 4320, 33, 33, 33, 135, 33, 135, 135, 33, 4320, 135, 4320, 33, 4320, 33, 135, 135, 135, 135, 33, 135, 4320, 4320, 33, 4320, 4320, 33, 4320, 135, 4320, 135, 135, 135, 33, 135, 33, 33, 4320, 33, 135, 33, 33, 135, 4320, 135, 4320, 33, 4320, 4320, 135, 4320, 135, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 574464 . Total input tokens: 128075419 . Total output tokens: 114736704
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 74.02813779003918,
    "estimated_duration": 3600.118548168052,
    "input_throughput": 6074.321083434278,
    "output_throughput": 5384.53963130303,
    "total_throughput": 11458.860714737308,
    "itl": 146.9847131858907,
    "ttft": 1539253.432235346,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 535,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.599676907772644,
    "arrivals": 191087,
    "finished_requests": 88481,
    "scheduler_time": 166.74661199748573
}
#Debug simulation 
Total elapsed time: 74.02826965972781. Arrivals time: 0.37165366765111685 Scheduler time: 73.50847656838596 Scheduler overhead time: 0.0567635390907526 Adapter cache time: 0.01628477079793811 Engine time: 0.053683673962950706 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-32/adapters_384_slots_64_rate_0.4-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-32/adapters_384_slots_64_rate_0.4-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 135, 33, 4320, 4320, 33, 135, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 33, 4320, 33, 4320, 135, 135, 135, 33, 33, 135, 33, 4320, 33, 4320, 135, 4320, 135, 33, 135, 4320, 135, 4320, 33, 4320, 4320, 4320, 4320, 33, 135, 135, 135, 4320, 135, 33, 135, 33, 4320, 135, 4320, 4320, 135, 4320, 4320, 33, 33, 4320, 135, 135, 33, 33, 33, 135, 33, 135, 33, 4320, 33, 135, 4320, 33, 4320, 135, 33, 4320, 4320, 4320, 4320, 135, 33, 135, 4320, 4320, 135, 33, 33, 4320, 135, 135, 33, 33, 4320, 135, 4320, 135, 4320, 4320, 135, 4320, 4320, 33, 135, 135, 135, 135, 33, 33, 4320, 33, 4320, 33, 33, 33, 135, 135, 4320, 33, 33, 4320, 33, 4320, 135, 33, 4320, 135, 135, 33, 4320, 4320, 4320, 33, 135, 4320, 33, 4320, 135, 135, 4320, 4320, 33, 135, 4320, 33, 135, 135, 33, 135, 33, 135, 4320, 4320, 135, 33, 4320, 33, 4320, 135, 135, 135, 135, 135, 33, 33, 4320, 33, 4320, 33, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 33, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 33, 33, 33, 33, 33, 135, 33, 33, 135, 4320, 4320, 33, 33, 4320, 33, 33, 33, 135, 33, 135, 4320, 4320, 135, 135, 33, 4320, 135, 4320, 33, 135, 135, 33, 33, 135, 33, 4320, 4320, 33, 4320, 4320, 33, 135, 4320, 33, 33, 135, 135, 33, 33, 4320, 4320, 4320, 4320, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 4320, 135, 135, 135, 4320, 33, 135, 135, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 135, 33, 4320, 4320, 4320, 135, 33, 4320, 4320, 135, 135, 4320, 4320, 33, 4320, 4320, 135, 33, 4320, 135, 135, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 135, 4320, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 4320, 33, 33, 33, 135, 33, 135, 135, 33, 4320, 135, 4320, 33, 4320, 33, 135, 135, 135, 135, 33, 135, 4320, 4320, 33, 4320, 4320, 33, 4320, 135, 4320, 135, 135, 135, 33, 135, 33, 33, 4320, 33, 135, 33, 33, 135, 4320, 135, 4320, 33, 4320, 4320, 135, 4320, 135, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 574464 . Total input tokens: 128075419 . Total output tokens: 114736704
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 71.8464366174303,
    "estimated_duration": 3600.128068846586,
    "input_throughput": 6103.100939695016,
    "output_throughput": 5408.87646984144,
    "total_throughput": 11511.977409536456,
    "itl": 148.17286966688258,
    "ttft": 1542559.2006999527,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 534,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7956235366314617,
    "arrivals": 191087,
    "finished_requests": 88923,
    "scheduler_time": 165.42867775062268
}
#Debug simulation 
Total elapsed time: 71.84657208435237. Arrivals time: 0.35803394857794046 Scheduler time: 71.34320481820032 Scheduler overhead time: 0.05480260541662574 Adapter cache time: 0.016269261948764324 Engine time: 0.05268263118341565 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-8/adapters_384_slots_64_rate_0.4-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-8/adapters_384_slots_64_rate_0.4-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 66, 33, 4320, 4320, 33, 66, 4320, 4320, 4320, 4320, 66, 66, 66, 66, 4320, 4320, 66, 66, 33, 4320, 33, 4320, 66, 66, 66, 33, 33, 66, 33, 4320, 33, 4320, 66, 4320, 66, 33, 66, 4320, 66, 4320, 33, 4320, 4320, 4320, 4320, 33, 66, 66, 66, 4320, 66, 33, 66, 33, 4320, 66, 4320, 4320, 66, 4320, 4320, 33, 33, 4320, 66, 66, 33, 33, 33, 66, 33, 66, 33, 4320, 33, 66, 4320, 33, 4320, 66, 33, 4320, 4320, 4320, 4320, 66, 33, 66, 4320, 4320, 66, 33, 33, 4320, 66, 66, 33, 33, 4320, 66, 4320, 66, 4320, 4320, 66, 4320, 4320, 33, 66, 66, 66, 66, 33, 33, 4320, 33, 4320, 33, 33, 33, 66, 66, 4320, 33, 33, 4320, 33, 4320, 66, 33, 4320, 66, 66, 33, 4320, 4320, 4320, 33, 66, 4320, 33, 4320, 66, 66, 4320, 4320, 33, 66, 4320, 33, 66, 66, 33, 66, 33, 66, 4320, 4320, 66, 33, 4320, 33, 4320, 66, 66, 66, 66, 66, 33, 33, 4320, 33, 4320, 33, 66, 4320, 66, 4320, 66, 4320, 66, 4320, 33, 66, 66, 66, 66, 66, 66, 66, 66, 4320, 33, 33, 33, 33, 33, 66, 33, 33, 66, 4320, 4320, 33, 33, 4320, 33, 33, 33, 66, 33, 66, 4320, 4320, 66, 66, 33, 4320, 66, 4320, 33, 66, 66, 33, 33, 66, 33, 4320, 4320, 33, 4320, 4320, 33, 66, 4320, 33, 33, 66, 66, 33, 33, 4320, 4320, 4320, 4320, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 4320, 66, 66, 66, 4320, 33, 66, 66, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 66, 33, 4320, 4320, 4320, 66, 33, 4320, 4320, 66, 66, 4320, 4320, 33, 4320, 4320, 66, 33, 4320, 66, 66, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 66, 4320, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 4320, 33, 33, 33, 66, 33, 66, 66, 33, 4320, 66, 4320, 33, 4320, 33, 66, 66, 66, 66, 33, 66, 4320, 4320, 33, 4320, 4320, 33, 4320, 66, 4320, 66, 66, 66, 33, 66, 33, 33, 4320, 33, 66, 33, 33, 66, 4320, 66, 4320, 33, 4320, 4320, 66, 4320, 66, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 565632 . Total input tokens: 126102881 . Total output tokens: 112978603
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 74.62829296011478,
    "estimated_duration": 3600.104330805492,
    "input_throughput": 6119.828753704626,
    "output_throughput": 5419.196558571646,
    "total_throughput": 11539.025312276272,
    "itl": 148.6181588043745,
    "ttft": 1524893.0331468433,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 533,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6312399675161784,
    "arrivals": 188115,
    "finished_requests": 89174,
    "scheduler_time": 164.7081702189053
}
#Debug simulation 
Total elapsed time: 74.62842440698296. Arrivals time: 0.3497262569144368 Scheduler time: 74.13305165898055 Scheduler overhead time: 0.0555540700443089 Adapter cache time: 0.015897033736109734 Engine time: 0.052747069392353296 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-16/adapters_384_slots_64_rate_0.4-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-16/adapters_384_slots_64_rate_0.4-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 66, 33, 4320, 4320, 33, 66, 4320, 4320, 4320, 4320, 66, 66, 66, 66, 4320, 4320, 66, 66, 33, 4320, 33, 4320, 66, 66, 66, 33, 33, 66, 33, 4320, 33, 4320, 66, 4320, 66, 33, 66, 4320, 66, 4320, 33, 4320, 4320, 4320, 4320, 33, 66, 66, 66, 4320, 66, 33, 66, 33, 4320, 66, 4320, 4320, 66, 4320, 4320, 33, 33, 4320, 66, 66, 33, 33, 33, 66, 33, 66, 33, 4320, 33, 66, 4320, 33, 4320, 66, 33, 4320, 4320, 4320, 4320, 66, 33, 66, 4320, 4320, 66, 33, 33, 4320, 66, 66, 33, 33, 4320, 66, 4320, 66, 4320, 4320, 66, 4320, 4320, 33, 66, 66, 66, 66, 33, 33, 4320, 33, 4320, 33, 33, 33, 66, 66, 4320, 33, 33, 4320, 33, 4320, 66, 33, 4320, 66, 66, 33, 4320, 4320, 4320, 33, 66, 4320, 33, 4320, 66, 66, 4320, 4320, 33, 66, 4320, 33, 66, 66, 33, 66, 33, 66, 4320, 4320, 66, 33, 4320, 33, 4320, 66, 66, 66, 66, 66, 33, 33, 4320, 33, 4320, 33, 66, 4320, 66, 4320, 66, 4320, 66, 4320, 33, 66, 66, 66, 66, 66, 66, 66, 66, 4320, 33, 33, 33, 33, 33, 66, 33, 33, 66, 4320, 4320, 33, 33, 4320, 33, 33, 33, 66, 33, 66, 4320, 4320, 66, 66, 33, 4320, 66, 4320, 33, 66, 66, 33, 33, 66, 33, 4320, 4320, 33, 4320, 4320, 33, 66, 4320, 33, 33, 66, 66, 33, 33, 4320, 4320, 4320, 4320, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 4320, 66, 66, 66, 4320, 33, 66, 66, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 66, 33, 4320, 4320, 4320, 66, 33, 4320, 4320, 66, 66, 4320, 4320, 33, 4320, 4320, 66, 33, 4320, 66, 66, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 66, 4320, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 4320, 33, 33, 33, 66, 33, 66, 66, 33, 4320, 66, 4320, 33, 4320, 33, 66, 66, 66, 66, 33, 66, 4320, 4320, 33, 4320, 4320, 33, 4320, 66, 4320, 66, 66, 66, 33, 66, 33, 33, 4320, 33, 66, 33, 33, 66, 4320, 66, 4320, 33, 4320, 4320, 66, 4320, 66, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 565632 . Total input tokens: 126102881 . Total output tokens: 112978603
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 73.72342923702672,
    "estimated_duration": 3600.103410307821,
    "input_throughput": 6109.367841219708,
    "output_throughput": 5416.683571967904,
    "total_throughput": 11526.051413187612,
    "itl": 148.57860488291695,
    "ttft": 1523342.8978122654,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 510,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6646652493067138,
    "arrivals": 188115,
    "finished_requests": 89089,
    "scheduler_time": 164.82176901113894
}
#Debug simulation 
Total elapsed time: 73.72356717288494. Arrivals time: 0.34733050456270576 Scheduler time: 73.23086734535173 Scheduler overhead time: 0.05553325451910496 Adapter cache time: 0.016055268701165915 Engine time: 0.052439823281019926 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-32/adapters_384_slots_64_rate_0.4-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-32/adapters_384_slots_64_rate_0.4-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 66, 33, 4320, 4320, 33, 66, 4320, 4320, 4320, 4320, 66, 66, 66, 66, 4320, 4320, 66, 66, 33, 4320, 33, 4320, 66, 66, 66, 33, 33, 66, 33, 4320, 33, 4320, 66, 4320, 66, 33, 66, 4320, 66, 4320, 33, 4320, 4320, 4320, 4320, 33, 66, 66, 66, 4320, 66, 33, 66, 33, 4320, 66, 4320, 4320, 66, 4320, 4320, 33, 33, 4320, 66, 66, 33, 33, 33, 66, 33, 66, 33, 4320, 33, 66, 4320, 33, 4320, 66, 33, 4320, 4320, 4320, 4320, 66, 33, 66, 4320, 4320, 66, 33, 33, 4320, 66, 66, 33, 33, 4320, 66, 4320, 66, 4320, 4320, 66, 4320, 4320, 33, 66, 66, 66, 66, 33, 33, 4320, 33, 4320, 33, 33, 33, 66, 66, 4320, 33, 33, 4320, 33, 4320, 66, 33, 4320, 66, 66, 33, 4320, 4320, 4320, 33, 66, 4320, 33, 4320, 66, 66, 4320, 4320, 33, 66, 4320, 33, 66, 66, 33, 66, 33, 66, 4320, 4320, 66, 33, 4320, 33, 4320, 66, 66, 66, 66, 66, 33, 33, 4320, 33, 4320, 33, 66, 4320, 66, 4320, 66, 4320, 66, 4320, 33, 66, 66, 66, 66, 66, 66, 66, 66, 4320, 33, 33, 33, 33, 33, 66, 33, 33, 66, 4320, 4320, 33, 33, 4320, 33, 33, 33, 66, 33, 66, 4320, 4320, 66, 66, 33, 4320, 66, 4320, 33, 66, 66, 33, 33, 66, 33, 4320, 4320, 33, 4320, 4320, 33, 66, 4320, 33, 33, 66, 66, 33, 33, 4320, 4320, 4320, 4320, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 4320, 66, 66, 66, 4320, 33, 66, 66, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 66, 33, 4320, 4320, 4320, 66, 33, 4320, 4320, 66, 66, 4320, 4320, 33, 4320, 4320, 66, 33, 4320, 66, 66, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 66, 4320, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 4320, 33, 33, 33, 66, 33, 66, 66, 33, 4320, 66, 4320, 33, 4320, 33, 66, 66, 66, 66, 33, 66, 4320, 4320, 33, 4320, 4320, 33, 4320, 66, 4320, 66, 66, 66, 33, 66, 33, 33, 4320, 33, 66, 33, 33, 66, 4320, 66, 4320, 33, 4320, 4320, 66, 4320, 66, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 565632 . Total input tokens: 126102881 . Total output tokens: 112978603
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 73.66803723806515,
    "estimated_duration": 3600.1062856159865,
    "input_throughput": 6109.362961831755,
    "output_throughput": 5416.679245808266,
    "total_throughput": 11526.042207640021,
    "itl": 148.57868677834898,
    "ttft": 1523343.7471352955,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 510,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6675332560017806,
    "arrivals": 188115,
    "finished_requests": 89089,
    "scheduler_time": 164.82177631257844
}
#Debug simulation 
Total elapsed time: 73.66817661514506. Arrivals time: 0.3400513557717204 Scheduler time: 73.18394741695374 Scheduler overhead time: 0.0548950731754303 Adapter cache time: 0.01544551644474268 Engine time: 0.052413600496947765 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-16/adapters_384_slots_64_rate_0.4-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-16/adapters_384_slots_64_rate_0.4-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 66, 33, 4320, 4320, 33, 66, 4320, 4320, 4320, 4320, 66, 66, 66, 66, 4320, 4320, 66, 66, 33, 4320, 33, 4320, 66, 66, 66, 33, 33, 66, 33, 4320, 33, 4320, 66, 4320, 66, 33, 66, 4320, 66, 4320, 33, 4320, 4320, 4320, 4320, 33, 66, 66, 66, 4320, 66, 33, 66, 33, 4320, 66, 4320, 4320, 66, 4320, 4320, 33, 33, 4320, 66, 66, 33, 33, 33, 66, 33, 66, 33, 4320, 33, 66, 4320, 33, 4320, 66, 33, 4320, 4320, 4320, 4320, 66, 33, 66, 4320, 4320, 66, 33, 33, 4320, 66, 66, 33, 33, 4320, 66, 4320, 66, 4320, 4320, 66, 4320, 4320, 33, 66, 66, 66, 66, 33, 33, 4320, 33, 4320, 33, 33, 33, 66, 66, 4320, 33, 33, 4320, 33, 4320, 66, 33, 4320, 66, 66, 33, 4320, 4320, 4320, 33, 66, 4320, 33, 4320, 66, 66, 4320, 4320, 33, 66, 4320, 33, 66, 66, 33, 66, 33, 66, 4320, 4320, 66, 33, 4320, 33, 4320, 66, 66, 66, 66, 66, 33, 33, 4320, 33, 4320, 33, 66, 4320, 66, 4320, 66, 4320, 66, 4320, 33, 66, 66, 66, 66, 66, 66, 66, 66, 4320, 33, 33, 33, 33, 33, 66, 33, 33, 66, 4320, 4320, 33, 33, 4320, 33, 33, 33, 66, 33, 66, 4320, 4320, 66, 66, 33, 4320, 66, 4320, 33, 66, 66, 33, 33, 66, 33, 4320, 4320, 33, 4320, 4320, 33, 66, 4320, 33, 33, 66, 66, 33, 33, 4320, 4320, 4320, 4320, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 4320, 66, 66, 66, 4320, 33, 66, 66, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 66, 33, 4320, 4320, 4320, 66, 33, 4320, 4320, 66, 66, 4320, 4320, 33, 4320, 4320, 66, 33, 4320, 66, 66, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 66, 4320, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 4320, 33, 33, 33, 66, 33, 66, 66, 33, 4320, 66, 4320, 33, 4320, 33, 66, 66, 66, 66, 33, 66, 4320, 4320, 33, 4320, 4320, 33, 4320, 66, 4320, 66, 66, 66, 33, 66, 33, 33, 4320, 33, 66, 33, 33, 66, 4320, 66, 4320, 33, 4320, 4320, 66, 4320, 66, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 565632 . Total input tokens: 126102881 . Total output tokens: 112978603
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 74.10954055609182,
    "estimated_duration": 3600.159795785298,
    "input_throughput": 6100.924471661947,
    "output_throughput": 5406.951108889302,
    "total_throughput": 11507.875580551248,
    "itl": 148.00231947463476,
    "ttft": 1523566.8222095596,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 518,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6232104007154644,
    "arrivals": 188115,
    "finished_requests": 88925,
    "scheduler_time": 165.30509133211206
}
#Debug simulation 
Total elapsed time: 74.10966939106584. Arrivals time: 0.3467841921374202 Scheduler time: 73.61881722509861 Scheduler overhead time: 0.05477168504148722 Adapter cache time: 0.015842105727642775 Engine time: 0.051800310611724854 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-32/adapters_384_slots_64_rate_0.4-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-32/adapters_384_slots_64_rate_0.4-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 66, 33, 4320, 4320, 33, 66, 4320, 4320, 4320, 4320, 66, 66, 66, 66, 4320, 4320, 66, 66, 33, 4320, 33, 4320, 66, 66, 66, 33, 33, 66, 33, 4320, 33, 4320, 66, 4320, 66, 33, 66, 4320, 66, 4320, 33, 4320, 4320, 4320, 4320, 33, 66, 66, 66, 4320, 66, 33, 66, 33, 4320, 66, 4320, 4320, 66, 4320, 4320, 33, 33, 4320, 66, 66, 33, 33, 33, 66, 33, 66, 33, 4320, 33, 66, 4320, 33, 4320, 66, 33, 4320, 4320, 4320, 4320, 66, 33, 66, 4320, 4320, 66, 33, 33, 4320, 66, 66, 33, 33, 4320, 66, 4320, 66, 4320, 4320, 66, 4320, 4320, 33, 66, 66, 66, 66, 33, 33, 4320, 33, 4320, 33, 33, 33, 66, 66, 4320, 33, 33, 4320, 33, 4320, 66, 33, 4320, 66, 66, 33, 4320, 4320, 4320, 33, 66, 4320, 33, 4320, 66, 66, 4320, 4320, 33, 66, 4320, 33, 66, 66, 33, 66, 33, 66, 4320, 4320, 66, 33, 4320, 33, 4320, 66, 66, 66, 66, 66, 33, 33, 4320, 33, 4320, 33, 66, 4320, 66, 4320, 66, 4320, 66, 4320, 33, 66, 66, 66, 66, 66, 66, 66, 66, 4320, 33, 33, 33, 33, 33, 66, 33, 33, 66, 4320, 4320, 33, 33, 4320, 33, 33, 33, 66, 33, 66, 4320, 4320, 66, 66, 33, 4320, 66, 4320, 33, 66, 66, 33, 33, 66, 33, 4320, 4320, 33, 4320, 4320, 33, 66, 4320, 33, 33, 66, 66, 33, 33, 4320, 4320, 4320, 4320, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 4320, 66, 66, 66, 4320, 33, 66, 66, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 66, 33, 4320, 4320, 4320, 66, 33, 4320, 4320, 66, 66, 4320, 4320, 33, 4320, 4320, 66, 33, 4320, 66, 66, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 66, 4320, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 4320, 33, 33, 33, 66, 33, 66, 66, 33, 4320, 66, 4320, 33, 4320, 33, 66, 66, 66, 66, 33, 66, 4320, 4320, 33, 4320, 4320, 33, 4320, 66, 4320, 66, 66, 66, 33, 66, 33, 33, 4320, 33, 66, 33, 33, 66, 4320, 66, 4320, 33, 4320, 4320, 66, 4320, 66, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 565632 . Total input tokens: 126102881 . Total output tokens: 112978603
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 74.71152678132057,
    "estimated_duration": 3600.150797664912,
    "input_throughput": 6085.907572041463,
    "output_throughput": 5392.559392954346,
    "total_throughput": 11478.466964995809,
    "itl": 147.9247922610037,
    "ttft": 1521991.4468229692,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 499,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6538779208622918,
    "arrivals": 188115,
    "finished_requests": 88686,
    "scheduler_time": 166.0327462063276
}
#Debug simulation 
Total elapsed time: 74.71165603306144. Arrivals time: 0.35001790057867765 Scheduler time: 74.21763633005321 Scheduler overhead time: 0.054845372680574656 Adapter cache time: 0.015262854751199484 Engine time: 0.052860891446471214 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-16/adapters_384_slots_64_rate_0.4-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-16/adapters_384_slots_64_rate_0.4-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 66, 33, 4320, 4320, 33, 66, 4320, 4320, 4320, 4320, 66, 66, 66, 66, 4320, 4320, 66, 66, 33, 4320, 33, 4320, 66, 66, 66, 33, 33, 66, 33, 4320, 33, 4320, 66, 4320, 66, 33, 66, 4320, 66, 4320, 33, 4320, 4320, 4320, 4320, 33, 66, 66, 66, 4320, 66, 33, 66, 33, 4320, 66, 4320, 4320, 66, 4320, 4320, 33, 33, 4320, 66, 66, 33, 33, 33, 66, 33, 66, 33, 4320, 33, 66, 4320, 33, 4320, 66, 33, 4320, 4320, 4320, 4320, 66, 33, 66, 4320, 4320, 66, 33, 33, 4320, 66, 66, 33, 33, 4320, 66, 4320, 66, 4320, 4320, 66, 4320, 4320, 33, 66, 66, 66, 66, 33, 33, 4320, 33, 4320, 33, 33, 33, 66, 66, 4320, 33, 33, 4320, 33, 4320, 66, 33, 4320, 66, 66, 33, 4320, 4320, 4320, 33, 66, 4320, 33, 4320, 66, 66, 4320, 4320, 33, 66, 4320, 33, 66, 66, 33, 66, 33, 66, 4320, 4320, 66, 33, 4320, 33, 4320, 66, 66, 66, 66, 66, 33, 33, 4320, 33, 4320, 33, 66, 4320, 66, 4320, 66, 4320, 66, 4320, 33, 66, 66, 66, 66, 66, 66, 66, 66, 4320, 33, 33, 33, 33, 33, 66, 33, 33, 66, 4320, 4320, 33, 33, 4320, 33, 33, 33, 66, 33, 66, 4320, 4320, 66, 66, 33, 4320, 66, 4320, 33, 66, 66, 33, 33, 66, 33, 4320, 4320, 33, 4320, 4320, 33, 66, 4320, 33, 33, 66, 66, 33, 33, 4320, 4320, 4320, 4320, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 4320, 66, 66, 66, 4320, 33, 66, 66, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 66, 33, 4320, 4320, 4320, 66, 33, 4320, 4320, 66, 66, 4320, 4320, 33, 4320, 4320, 66, 33, 4320, 66, 66, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 66, 4320, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 4320, 33, 33, 33, 66, 33, 66, 66, 33, 4320, 66, 4320, 33, 4320, 33, 66, 66, 66, 66, 33, 66, 4320, 4320, 33, 4320, 4320, 33, 4320, 66, 4320, 66, 66, 66, 33, 66, 33, 33, 4320, 33, 66, 33, 33, 66, 4320, 66, 4320, 33, 4320, 4320, 66, 4320, 66, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 565632 . Total input tokens: 126102881 . Total output tokens: 112978603
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 71.80503704119474,
    "estimated_duration": 3600.028404186656,
    "input_throughput": 6144.095967208698,
    "output_throughput": 5443.400384622064,
    "total_throughput": 11587.496351830763,
    "itl": 149.0598036058348,
    "ttft": 1526235.9144379871,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 551,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6475177124910771,
    "arrivals": 188115,
    "finished_requests": 89541,
    "scheduler_time": 163.43557582022225
}
#Debug simulation 
Total elapsed time: 71.80516336904839. Arrivals time: 0.3572954530827701 Scheduler time: 71.30606675473973 Scheduler overhead time: 0.05408395593985915 Adapter cache time: 0.015665387734770775 Engine time: 0.051517951767891645 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-32/adapters_384_slots_64_rate_0.4-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-32/adapters_384_slots_64_rate_0.4-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 66, 33, 4320, 4320, 33, 66, 4320, 4320, 4320, 4320, 66, 66, 66, 66, 4320, 4320, 66, 66, 33, 4320, 33, 4320, 66, 66, 66, 33, 33, 66, 33, 4320, 33, 4320, 66, 4320, 66, 33, 66, 4320, 66, 4320, 33, 4320, 4320, 4320, 4320, 33, 66, 66, 66, 4320, 66, 33, 66, 33, 4320, 66, 4320, 4320, 66, 4320, 4320, 33, 33, 4320, 66, 66, 33, 33, 33, 66, 33, 66, 33, 4320, 33, 66, 4320, 33, 4320, 66, 33, 4320, 4320, 4320, 4320, 66, 33, 66, 4320, 4320, 66, 33, 33, 4320, 66, 66, 33, 33, 4320, 66, 4320, 66, 4320, 4320, 66, 4320, 4320, 33, 66, 66, 66, 66, 33, 33, 4320, 33, 4320, 33, 33, 33, 66, 66, 4320, 33, 33, 4320, 33, 4320, 66, 33, 4320, 66, 66, 33, 4320, 4320, 4320, 33, 66, 4320, 33, 4320, 66, 66, 4320, 4320, 33, 66, 4320, 33, 66, 66, 33, 66, 33, 66, 4320, 4320, 66, 33, 4320, 33, 4320, 66, 66, 66, 66, 66, 33, 33, 4320, 33, 4320, 33, 66, 4320, 66, 4320, 66, 4320, 66, 4320, 33, 66, 66, 66, 66, 66, 66, 66, 66, 4320, 33, 33, 33, 33, 33, 66, 33, 33, 66, 4320, 4320, 33, 33, 4320, 33, 33, 33, 66, 33, 66, 4320, 4320, 66, 66, 33, 4320, 66, 4320, 33, 66, 66, 33, 33, 66, 33, 4320, 4320, 33, 4320, 4320, 33, 66, 4320, 33, 33, 66, 66, 33, 33, 4320, 4320, 4320, 4320, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 4320, 66, 66, 66, 4320, 33, 66, 66, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 66, 33, 4320, 4320, 4320, 66, 33, 4320, 4320, 66, 66, 4320, 4320, 33, 4320, 4320, 66, 33, 4320, 66, 66, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 66, 4320, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 4320, 33, 33, 33, 66, 33, 66, 66, 33, 4320, 66, 4320, 33, 4320, 33, 66, 66, 66, 66, 33, 66, 4320, 4320, 33, 4320, 4320, 33, 4320, 66, 4320, 66, 66, 66, 33, 66, 33, 33, 4320, 33, 66, 33, 33, 66, 4320, 66, 4320, 33, 4320, 4320, 66, 4320, 66, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 565632 . Total input tokens: 126102881 . Total output tokens: 112978603
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 74.71593530569226,
    "estimated_duration": 3600.0000023970088,
    "input_throughput": 6085.499162614724,
    "output_throughput": 5392.379440854005,
    "total_throughput": 11477.87860346873,
    "itl": 147.92333182185132,
    "ttft": 1522014.1489001715,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 499,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6761363410577155,
    "arrivals": 188115,
    "finished_requests": 88681,
    "scheduler_time": 166.02499179226774
}
#Debug simulation 
Total elapsed time: 74.71610158262774. Arrivals time: 0.3613932179287076 Scheduler time: 74.20904851285741 Scheduler overhead time: 0.05555429123342037 Adapter cache time: 0.015456065069884062 Engine time: 0.053478451911360025 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-8/adapters_384_slots_64_rate_0.1-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-8/adapters_384_slots_64_rate_0.1-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 1080, 540, 270, 1080, 1080, 270, 540, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 270, 1080, 270, 1080, 540, 540, 540, 270, 270, 540, 270, 1080, 270, 1080, 540, 1080, 540, 270, 540, 1080, 540, 1080, 270, 1080, 1080, 1080, 1080, 270, 540, 540, 540, 1080, 540, 270, 540, 270, 1080, 540, 1080, 1080, 540, 1080, 1080, 270, 270, 1080, 540, 540, 270, 270, 270, 540, 270, 540, 270, 1080, 270, 540, 1080, 270, 1080, 540, 270, 1080, 1080, 1080, 1080, 540, 270, 540, 1080, 1080, 540, 270, 270, 1080, 540, 540, 270, 270, 1080, 540, 1080, 540, 1080, 1080, 540, 1080, 1080, 270, 540, 540, 540, 540, 270, 270, 1080, 270, 1080, 270, 270, 270, 540, 540, 1080, 270, 270, 1080, 270, 1080, 540, 270, 1080, 540, 540, 270, 1080, 1080, 1080, 270, 540, 1080, 270, 1080, 540, 540, 1080, 1080, 270, 540, 1080, 270, 540, 540, 270, 540, 270, 540, 1080, 1080, 540, 270, 1080, 270, 1080, 540, 540, 540, 540, 540, 270, 270, 1080, 270, 1080, 270, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 270, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 270, 270, 270, 270, 270, 540, 270, 270, 540, 1080, 1080, 270, 270, 1080, 270, 270, 270, 540, 270, 540, 1080, 1080, 540, 540, 270, 1080, 540, 1080, 270, 540, 540, 270, 270, 540, 270, 1080, 1080, 270, 1080, 1080, 270, 540, 1080, 270, 270, 540, 540, 270, 270, 1080, 1080, 1080, 1080, 540, 270, 540, 540, 270, 270, 270, 270, 270, 270, 270, 270, 540, 1080, 540, 540, 540, 1080, 270, 540, 540, 1080, 1080, 270, 1080, 1080, 270, 1080, 270, 270, 540, 270, 1080, 1080, 1080, 540, 270, 1080, 1080, 540, 540, 1080, 1080, 270, 1080, 1080, 540, 270, 1080, 540, 540, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 270, 1080, 270, 540, 1080, 270, 540, 540, 540, 540, 270, 540, 270, 540, 540, 270, 1080, 270, 270, 270, 540, 270, 540, 540, 270, 1080, 540, 1080, 270, 1080, 270, 540, 540, 540, 540, 270, 540, 1080, 1080, 270, 1080, 1080, 270, 1080, 540, 1080, 540, 540, 540, 270, 540, 270, 270, 1080, 270, 540, 270, 270, 540, 1080, 540, 1080, 270, 1080, 1080, 540, 1080, 540, 270, 1080, 270, 1080, 1080, 270, 270, 270]
Prompts retrieved: 241920 . Total input tokens: 53925975 . Total output tokens: 48373036
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 26.79312085919082,
    "estimated_duration": 3600.069729278188,
    "input_throughput": 5207.707186204692,
    "output_throughput": 4603.056675605709,
    "total_throughput": 9810.763861810401,
    "itl": 87.95712496029812,
    "ttft": 407283.50509037287,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2815,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.615272999170786,
    "arrivals": 80883,
    "finished_requests": 75451,
    "scheduler_time": 86.7978300132628
}
#Debug simulation 
Total elapsed time: 26.79322474822402. Arrivals time: 0.23108957754448056 Scheduler time: 26.359299899078906 Scheduler overhead time: 0.06689643207937479 Adapter cache time: 0.04348153807222843 Engine time: 0.06404889281839132 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-16/adapters_384_slots_64_rate_0.1-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-16/adapters_384_slots_64_rate_0.1-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 1080, 540, 270, 1080, 1080, 270, 540, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 270, 1080, 270, 1080, 540, 540, 540, 270, 270, 540, 270, 1080, 270, 1080, 540, 1080, 540, 270, 540, 1080, 540, 1080, 270, 1080, 1080, 1080, 1080, 270, 540, 540, 540, 1080, 540, 270, 540, 270, 1080, 540, 1080, 1080, 540, 1080, 1080, 270, 270, 1080, 540, 540, 270, 270, 270, 540, 270, 540, 270, 1080, 270, 540, 1080, 270, 1080, 540, 270, 1080, 1080, 1080, 1080, 540, 270, 540, 1080, 1080, 540, 270, 270, 1080, 540, 540, 270, 270, 1080, 540, 1080, 540, 1080, 1080, 540, 1080, 1080, 270, 540, 540, 540, 540, 270, 270, 1080, 270, 1080, 270, 270, 270, 540, 540, 1080, 270, 270, 1080, 270, 1080, 540, 270, 1080, 540, 540, 270, 1080, 1080, 1080, 270, 540, 1080, 270, 1080, 540, 540, 1080, 1080, 270, 540, 1080, 270, 540, 540, 270, 540, 270, 540, 1080, 1080, 540, 270, 1080, 270, 1080, 540, 540, 540, 540, 540, 270, 270, 1080, 270, 1080, 270, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 270, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 270, 270, 270, 270, 270, 540, 270, 270, 540, 1080, 1080, 270, 270, 1080, 270, 270, 270, 540, 270, 540, 1080, 1080, 540, 540, 270, 1080, 540, 1080, 270, 540, 540, 270, 270, 540, 270, 1080, 1080, 270, 1080, 1080, 270, 540, 1080, 270, 270, 540, 540, 270, 270, 1080, 1080, 1080, 1080, 540, 270, 540, 540, 270, 270, 270, 270, 270, 270, 270, 270, 540, 1080, 540, 540, 540, 1080, 270, 540, 540, 1080, 1080, 270, 1080, 1080, 270, 1080, 270, 270, 540, 270, 1080, 1080, 1080, 540, 270, 1080, 1080, 540, 540, 1080, 1080, 270, 1080, 1080, 540, 270, 1080, 540, 540, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 270, 1080, 270, 540, 1080, 270, 540, 540, 540, 540, 270, 540, 270, 540, 540, 270, 1080, 270, 270, 270, 540, 270, 540, 540, 270, 1080, 540, 1080, 270, 1080, 270, 540, 540, 540, 540, 270, 540, 1080, 1080, 270, 1080, 1080, 270, 1080, 540, 1080, 540, 540, 540, 270, 540, 270, 270, 1080, 270, 540, 270, 270, 540, 1080, 540, 1080, 270, 1080, 1080, 540, 1080, 540, 270, 1080, 270, 1080, 1080, 270, 270, 270]
Prompts retrieved: 241920 . Total input tokens: 53925975 . Total output tokens: 48373036
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 26.858163297642022,
    "estimated_duration": 3600.0514347794838,
    "input_throughput": 5213.8638405730835,
    "output_throughput": 4610.444684109541,
    "total_throughput": 9824.308524682625,
    "itl": 88.43737282906051,
    "ttft": 403010.29065742216,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2811,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.171147601045524,
    "arrivals": 80883,
    "finished_requests": 75537,
    "scheduler_time": 86.70802784151333
}
#Debug simulation 
Total elapsed time: 26.858292376622558. Arrivals time: 0.2363723050802946 Scheduler time: 26.415669843554497 Scheduler overhead time: 0.06842668866738677 Adapter cache time: 0.044253963977098465 Engine time: 0.06402970850467682 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-32/adapters_384_slots_64_rate_0.1-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-32/adapters_384_slots_64_rate_0.1-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 1080, 540, 270, 1080, 1080, 270, 540, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 270, 1080, 270, 1080, 540, 540, 540, 270, 270, 540, 270, 1080, 270, 1080, 540, 1080, 540, 270, 540, 1080, 540, 1080, 270, 1080, 1080, 1080, 1080, 270, 540, 540, 540, 1080, 540, 270, 540, 270, 1080, 540, 1080, 1080, 540, 1080, 1080, 270, 270, 1080, 540, 540, 270, 270, 270, 540, 270, 540, 270, 1080, 270, 540, 1080, 270, 1080, 540, 270, 1080, 1080, 1080, 1080, 540, 270, 540, 1080, 1080, 540, 270, 270, 1080, 540, 540, 270, 270, 1080, 540, 1080, 540, 1080, 1080, 540, 1080, 1080, 270, 540, 540, 540, 540, 270, 270, 1080, 270, 1080, 270, 270, 270, 540, 540, 1080, 270, 270, 1080, 270, 1080, 540, 270, 1080, 540, 540, 270, 1080, 1080, 1080, 270, 540, 1080, 270, 1080, 540, 540, 1080, 1080, 270, 540, 1080, 270, 540, 540, 270, 540, 270, 540, 1080, 1080, 540, 270, 1080, 270, 1080, 540, 540, 540, 540, 540, 270, 270, 1080, 270, 1080, 270, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 270, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 270, 270, 270, 270, 270, 540, 270, 270, 540, 1080, 1080, 270, 270, 1080, 270, 270, 270, 540, 270, 540, 1080, 1080, 540, 540, 270, 1080, 540, 1080, 270, 540, 540, 270, 270, 540, 270, 1080, 1080, 270, 1080, 1080, 270, 540, 1080, 270, 270, 540, 540, 270, 270, 1080, 1080, 1080, 1080, 540, 270, 540, 540, 270, 270, 270, 270, 270, 270, 270, 270, 540, 1080, 540, 540, 540, 1080, 270, 540, 540, 1080, 1080, 270, 1080, 1080, 270, 1080, 270, 270, 540, 270, 1080, 1080, 1080, 540, 270, 1080, 1080, 540, 540, 1080, 1080, 270, 1080, 1080, 540, 270, 1080, 540, 540, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 270, 1080, 270, 540, 1080, 270, 540, 540, 540, 540, 270, 540, 270, 540, 540, 270, 1080, 270, 270, 270, 540, 270, 540, 540, 270, 1080, 540, 1080, 270, 1080, 270, 540, 540, 540, 540, 270, 540, 1080, 1080, 270, 1080, 1080, 270, 1080, 540, 1080, 540, 540, 540, 270, 540, 270, 270, 1080, 270, 540, 270, 270, 540, 1080, 540, 1080, 270, 1080, 1080, 540, 1080, 540, 270, 1080, 270, 1080, 1080, 270, 270, 270]
Prompts retrieved: 241920 . Total input tokens: 53925975 . Total output tokens: 48373036
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 26.84492387669161,
    "estimated_duration": 3600.0392456973213,
    "input_throughput": 5209.02293562848,
    "output_throughput": 4604.9372988957175,
    "total_throughput": 9813.960234524198,
    "itl": 88.20028795036266,
    "ttft": 405695.6410145425,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2799,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.14777583500347,
    "arrivals": 80883,
    "finished_requests": 75495,
    "scheduler_time": 86.84463291305016
}
#Debug simulation 
Total elapsed time: 26.844991473015398. Arrivals time: 0.22389992512762547 Scheduler time: 26.418122889939696 Scheduler overhead time: 0.06687637744471431 Adapter cache time: 0.04318808298557997 Engine time: 0.06422188226133585 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-16-16/adapters_384_slots_64_rate_0.1-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-16-16/adapters_384_slots_64_rate_0.1-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 1080, 540, 270, 1080, 1080, 270, 540, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 270, 1080, 270, 1080, 540, 540, 540, 270, 270, 540, 270, 1080, 270, 1080, 540, 1080, 540, 270, 540, 1080, 540, 1080, 270, 1080, 1080, 1080, 1080, 270, 540, 540, 540, 1080, 540, 270, 540, 270, 1080, 540, 1080, 1080, 540, 1080, 1080, 270, 270, 1080, 540, 540, 270, 270, 270, 540, 270, 540, 270, 1080, 270, 540, 1080, 270, 1080, 540, 270, 1080, 1080, 1080, 1080, 540, 270, 540, 1080, 1080, 540, 270, 270, 1080, 540, 540, 270, 270, 1080, 540, 1080, 540, 1080, 1080, 540, 1080, 1080, 270, 540, 540, 540, 540, 270, 270, 1080, 270, 1080, 270, 270, 270, 540, 540, 1080, 270, 270, 1080, 270, 1080, 540, 270, 1080, 540, 540, 270, 1080, 1080, 1080, 270, 540, 1080, 270, 1080, 540, 540, 1080, 1080, 270, 540, 1080, 270, 540, 540, 270, 540, 270, 540, 1080, 1080, 540, 270, 1080, 270, 1080, 540, 540, 540, 540, 540, 270, 270, 1080, 270, 1080, 270, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 270, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 270, 270, 270, 270, 270, 540, 270, 270, 540, 1080, 1080, 270, 270, 1080, 270, 270, 270, 540, 270, 540, 1080, 1080, 540, 540, 270, 1080, 540, 1080, 270, 540, 540, 270, 270, 540, 270, 1080, 1080, 270, 1080, 1080, 270, 540, 1080, 270, 270, 540, 540, 270, 270, 1080, 1080, 1080, 1080, 540, 270, 540, 540, 270, 270, 270, 270, 270, 270, 270, 270, 540, 1080, 540, 540, 540, 1080, 270, 540, 540, 1080, 1080, 270, 1080, 1080, 270, 1080, 270, 270, 540, 270, 1080, 1080, 1080, 540, 270, 1080, 1080, 540, 540, 1080, 1080, 270, 1080, 1080, 540, 270, 1080, 540, 540, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 270, 1080, 270, 540, 1080, 270, 540, 540, 540, 540, 270, 540, 270, 540, 540, 270, 1080, 270, 270, 270, 540, 270, 540, 540, 270, 1080, 540, 1080, 270, 1080, 270, 540, 540, 540, 540, 270, 540, 1080, 1080, 270, 1080, 1080, 270, 1080, 540, 1080, 540, 540, 540, 270, 540, 270, 270, 1080, 270, 540, 270, 270, 540, 1080, 540, 1080, 270, 1080, 1080, 540, 1080, 540, 270, 1080, 270, 1080, 1080, 270, 270, 270]
Prompts retrieved: 241920 . Total input tokens: 53925975 . Total output tokens: 48373036
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 26.872693835757673,
    "estimated_duration": 3600.0795947562438,
    "input_throughput": 5203.0057966727445,
    "output_throughput": 4604.910409244015,
    "total_throughput": 9807.91620591676,
    "itl": 88.00134451442979,
    "ttft": 407104.96310809726,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2798,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.754326277654478,
    "arrivals": 80883,
    "finished_requests": 75447,
    "scheduler_time": 86.76770933035829
}
#Debug simulation 
Total elapsed time: 26.872858830727637. Arrivals time: 0.2347591812722385 Scheduler time: 26.431973543018103 Scheduler overhead time: 0.06774498987942934 Adapter cache time: 0.04363960353657603 Engine time: 0.06567052146419883 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-16-32/adapters_384_slots_64_rate_0.1-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-16-32/adapters_384_slots_64_rate_0.1-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 1080, 540, 270, 1080, 1080, 270, 540, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 270, 1080, 270, 1080, 540, 540, 540, 270, 270, 540, 270, 1080, 270, 1080, 540, 1080, 540, 270, 540, 1080, 540, 1080, 270, 1080, 1080, 1080, 1080, 270, 540, 540, 540, 1080, 540, 270, 540, 270, 1080, 540, 1080, 1080, 540, 1080, 1080, 270, 270, 1080, 540, 540, 270, 270, 270, 540, 270, 540, 270, 1080, 270, 540, 1080, 270, 1080, 540, 270, 1080, 1080, 1080, 1080, 540, 270, 540, 1080, 1080, 540, 270, 270, 1080, 540, 540, 270, 270, 1080, 540, 1080, 540, 1080, 1080, 540, 1080, 1080, 270, 540, 540, 540, 540, 270, 270, 1080, 270, 1080, 270, 270, 270, 540, 540, 1080, 270, 270, 1080, 270, 1080, 540, 270, 1080, 540, 540, 270, 1080, 1080, 1080, 270, 540, 1080, 270, 1080, 540, 540, 1080, 1080, 270, 540, 1080, 270, 540, 540, 270, 540, 270, 540, 1080, 1080, 540, 270, 1080, 270, 1080, 540, 540, 540, 540, 540, 270, 270, 1080, 270, 1080, 270, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 270, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 270, 270, 270, 270, 270, 540, 270, 270, 540, 1080, 1080, 270, 270, 1080, 270, 270, 270, 540, 270, 540, 1080, 1080, 540, 540, 270, 1080, 540, 1080, 270, 540, 540, 270, 270, 540, 270, 1080, 1080, 270, 1080, 1080, 270, 540, 1080, 270, 270, 540, 540, 270, 270, 1080, 1080, 1080, 1080, 540, 270, 540, 540, 270, 270, 270, 270, 270, 270, 270, 270, 540, 1080, 540, 540, 540, 1080, 270, 540, 540, 1080, 1080, 270, 1080, 1080, 270, 1080, 270, 270, 540, 270, 1080, 1080, 1080, 540, 270, 1080, 1080, 540, 540, 1080, 1080, 270, 1080, 1080, 540, 270, 1080, 540, 540, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 270, 1080, 270, 540, 1080, 270, 540, 540, 540, 540, 270, 540, 270, 540, 540, 270, 1080, 270, 270, 270, 540, 270, 540, 540, 270, 1080, 540, 1080, 270, 1080, 270, 540, 540, 540, 540, 270, 540, 1080, 1080, 270, 1080, 1080, 270, 1080, 540, 1080, 540, 540, 540, 270, 540, 270, 270, 1080, 270, 540, 270, 270, 540, 1080, 540, 1080, 270, 1080, 1080, 540, 1080, 540, 270, 1080, 270, 1080, 1080, 270, 270, 270]
Prompts retrieved: 241920 . Total input tokens: 53925975 . Total output tokens: 48373036
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 26.81383206229657,
    "estimated_duration": 3600.0932395108975,
    "input_throughput": 5208.756482803656,
    "output_throughput": 4604.972398507185,
    "total_throughput": 9813.72888131084,
    "itl": 88.21545144705028,
    "ttft": 405182.81774277834,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2805,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.282827914002922,
    "arrivals": 80883,
    "finished_requests": 75499,
    "scheduler_time": 86.78670654276041
}
#Debug simulation 
Total elapsed time: 26.81391176721081. Arrivals time: 0.23784626787528396 Scheduler time: 26.37082683062181 Scheduler overhead time: 0.06741954712197185 Adapter cache time: 0.04377775313332677 Engine time: 0.06497466331347823 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_16-16-16/adapters_384_slots_64_rate_0.1-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_16-16-16/adapters_384_slots_64_rate_0.1-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 1080, 540, 270, 1080, 1080, 270, 540, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 270, 1080, 270, 1080, 540, 540, 540, 270, 270, 540, 270, 1080, 270, 1080, 540, 1080, 540, 270, 540, 1080, 540, 1080, 270, 1080, 1080, 1080, 1080, 270, 540, 540, 540, 1080, 540, 270, 540, 270, 1080, 540, 1080, 1080, 540, 1080, 1080, 270, 270, 1080, 540, 540, 270, 270, 270, 540, 270, 540, 270, 1080, 270, 540, 1080, 270, 1080, 540, 270, 1080, 1080, 1080, 1080, 540, 270, 540, 1080, 1080, 540, 270, 270, 1080, 540, 540, 270, 270, 1080, 540, 1080, 540, 1080, 1080, 540, 1080, 1080, 270, 540, 540, 540, 540, 270, 270, 1080, 270, 1080, 270, 270, 270, 540, 540, 1080, 270, 270, 1080, 270, 1080, 540, 270, 1080, 540, 540, 270, 1080, 1080, 1080, 270, 540, 1080, 270, 1080, 540, 540, 1080, 1080, 270, 540, 1080, 270, 540, 540, 270, 540, 270, 540, 1080, 1080, 540, 270, 1080, 270, 1080, 540, 540, 540, 540, 540, 270, 270, 1080, 270, 1080, 270, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 270, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 270, 270, 270, 270, 270, 540, 270, 270, 540, 1080, 1080, 270, 270, 1080, 270, 270, 270, 540, 270, 540, 1080, 1080, 540, 540, 270, 1080, 540, 1080, 270, 540, 540, 270, 270, 540, 270, 1080, 1080, 270, 1080, 1080, 270, 540, 1080, 270, 270, 540, 540, 270, 270, 1080, 1080, 1080, 1080, 540, 270, 540, 540, 270, 270, 270, 270, 270, 270, 270, 270, 540, 1080, 540, 540, 540, 1080, 270, 540, 540, 1080, 1080, 270, 1080, 1080, 270, 1080, 270, 270, 540, 270, 1080, 1080, 1080, 540, 270, 1080, 1080, 540, 540, 1080, 1080, 270, 1080, 1080, 540, 270, 1080, 540, 540, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 270, 1080, 270, 540, 1080, 270, 540, 540, 540, 540, 270, 540, 270, 540, 540, 270, 1080, 270, 270, 270, 540, 270, 540, 540, 270, 1080, 540, 1080, 270, 1080, 270, 540, 540, 540, 540, 270, 540, 1080, 1080, 270, 1080, 1080, 270, 1080, 540, 1080, 540, 540, 540, 270, 540, 270, 270, 1080, 270, 540, 270, 270, 540, 1080, 540, 1080, 270, 1080, 1080, 540, 1080, 540, 270, 1080, 270, 1080, 1080, 270, 270, 270]
Prompts retrieved: 241920 . Total input tokens: 53925975 . Total output tokens: 48373036
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 27.069266052916646,
    "estimated_duration": 3600.0628913113965,
    "input_throughput": 5206.717372976762,
    "output_throughput": 4603.217082678063,
    "total_throughput": 9809.934455654826,
    "itl": 88.05069489386092,
    "ttft": 407741.11402800004,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2790,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.342240322776911,
    "arrivals": 80883,
    "finished_requests": 75450,
    "scheduler_time": 86.87111778331803
}
#Debug simulation 
Total elapsed time: 27.069417983293533. Arrivals time: 0.2220281334593892 Scheduler time: 26.64197450131178 Scheduler overhead time: 0.06808468420058489 Adapter cache time: 0.04341621836647391 Engine time: 0.0649032131768763 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_16-16-32/adapters_384_slots_64_rate_0.1-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_16-16-32/adapters_384_slots_64_rate_0.1-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 1080, 540, 270, 1080, 1080, 270, 540, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 270, 1080, 270, 1080, 540, 540, 540, 270, 270, 540, 270, 1080, 270, 1080, 540, 1080, 540, 270, 540, 1080, 540, 1080, 270, 1080, 1080, 1080, 1080, 270, 540, 540, 540, 1080, 540, 270, 540, 270, 1080, 540, 1080, 1080, 540, 1080, 1080, 270, 270, 1080, 540, 540, 270, 270, 270, 540, 270, 540, 270, 1080, 270, 540, 1080, 270, 1080, 540, 270, 1080, 1080, 1080, 1080, 540, 270, 540, 1080, 1080, 540, 270, 270, 1080, 540, 540, 270, 270, 1080, 540, 1080, 540, 1080, 1080, 540, 1080, 1080, 270, 540, 540, 540, 540, 270, 270, 1080, 270, 1080, 270, 270, 270, 540, 540, 1080, 270, 270, 1080, 270, 1080, 540, 270, 1080, 540, 540, 270, 1080, 1080, 1080, 270, 540, 1080, 270, 1080, 540, 540, 1080, 1080, 270, 540, 1080, 270, 540, 540, 270, 540, 270, 540, 1080, 1080, 540, 270, 1080, 270, 1080, 540, 540, 540, 540, 540, 270, 270, 1080, 270, 1080, 270, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 270, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 270, 270, 270, 270, 270, 540, 270, 270, 540, 1080, 1080, 270, 270, 1080, 270, 270, 270, 540, 270, 540, 1080, 1080, 540, 540, 270, 1080, 540, 1080, 270, 540, 540, 270, 270, 540, 270, 1080, 1080, 270, 1080, 1080, 270, 540, 1080, 270, 270, 540, 540, 270, 270, 1080, 1080, 1080, 1080, 540, 270, 540, 540, 270, 270, 270, 270, 270, 270, 270, 270, 540, 1080, 540, 540, 540, 1080, 270, 540, 540, 1080, 1080, 270, 1080, 1080, 270, 1080, 270, 270, 540, 270, 1080, 1080, 1080, 540, 270, 1080, 1080, 540, 540, 1080, 1080, 270, 1080, 1080, 540, 270, 1080, 540, 540, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 270, 1080, 270, 540, 1080, 270, 540, 540, 540, 540, 270, 540, 270, 540, 540, 270, 1080, 270, 270, 270, 540, 270, 540, 540, 270, 1080, 540, 1080, 270, 1080, 270, 540, 540, 540, 540, 270, 540, 1080, 1080, 270, 1080, 1080, 270, 1080, 540, 1080, 540, 540, 540, 270, 540, 270, 270, 1080, 270, 540, 270, 270, 540, 1080, 540, 1080, 270, 1080, 1080, 540, 1080, 540, 270, 1080, 270, 1080, 1080, 270, 270, 270]
Prompts retrieved: 241920 . Total input tokens: 53925975 . Total output tokens: 48373036
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 26.918215731158853,
    "estimated_duration": 3600.0597572990946,
    "input_throughput": 5208.63270727151,
    "output_throughput": 4603.662749318933,
    "total_throughput": 9812.295456590444,
    "itl": 88.11608320808645,
    "ttft": 406256.30528370413,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2799,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.382306646666951,
    "arrivals": 80883,
    "finished_requests": 75487,
    "scheduler_time": 86.86131611797155
}
#Debug simulation 
Total elapsed time: 26.918296419084072. Arrivals time: 0.23843185976147652 Scheduler time: 26.475178775843233 Scheduler overhead time: 0.06723648821935058 Adapter cache time: 0.04333717608824372 Engine time: 0.06525370292365551 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-8/adapters_384_slots_64_rate_0.1-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-8/adapters_384_slots_64_rate_0.1-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 1080, 540, 135, 1080, 1080, 135, 540, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 135, 1080, 135, 1080, 540, 540, 540, 135, 135, 540, 135, 1080, 135, 1080, 540, 1080, 540, 135, 540, 1080, 540, 1080, 135, 1080, 1080, 1080, 1080, 135, 540, 540, 540, 1080, 540, 135, 540, 135, 1080, 540, 1080, 1080, 540, 1080, 1080, 135, 135, 1080, 540, 540, 135, 135, 135, 540, 135, 540, 135, 1080, 135, 540, 1080, 135, 1080, 540, 135, 1080, 1080, 1080, 1080, 540, 135, 540, 1080, 1080, 540, 135, 135, 1080, 540, 540, 135, 135, 1080, 540, 1080, 540, 1080, 1080, 540, 1080, 1080, 135, 540, 540, 540, 540, 135, 135, 1080, 135, 1080, 135, 135, 135, 540, 540, 1080, 135, 135, 1080, 135, 1080, 540, 135, 1080, 540, 540, 135, 1080, 1080, 1080, 135, 540, 1080, 135, 1080, 540, 540, 1080, 1080, 135, 540, 1080, 135, 540, 540, 135, 540, 135, 540, 1080, 1080, 540, 135, 1080, 135, 1080, 540, 540, 540, 540, 540, 135, 135, 1080, 135, 1080, 135, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 135, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 135, 135, 135, 135, 135, 540, 135, 135, 540, 1080, 1080, 135, 135, 1080, 135, 135, 135, 540, 135, 540, 1080, 1080, 540, 540, 135, 1080, 540, 1080, 135, 540, 540, 135, 135, 540, 135, 1080, 1080, 135, 1080, 1080, 135, 540, 1080, 135, 135, 540, 540, 135, 135, 1080, 1080, 1080, 1080, 540, 135, 540, 540, 135, 135, 135, 135, 135, 135, 135, 135, 540, 1080, 540, 540, 540, 1080, 135, 540, 540, 1080, 1080, 135, 1080, 1080, 135, 1080, 135, 135, 540, 135, 1080, 1080, 1080, 540, 135, 1080, 1080, 540, 540, 1080, 1080, 135, 1080, 1080, 540, 135, 1080, 540, 540, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 135, 1080, 135, 540, 1080, 135, 540, 540, 540, 540, 135, 540, 135, 540, 540, 135, 1080, 135, 135, 135, 540, 135, 540, 540, 135, 1080, 540, 1080, 135, 1080, 135, 540, 540, 540, 540, 135, 540, 1080, 1080, 135, 1080, 1080, 135, 1080, 540, 1080, 540, 540, 540, 135, 540, 135, 135, 1080, 135, 540, 135, 135, 540, 1080, 540, 1080, 135, 1080, 1080, 540, 1080, 540, 135, 1080, 135, 1080, 1080, 135, 135, 135]
Prompts retrieved: 224640 . Total input tokens: 50059495 . Total output tokens: 44930825
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 20.931948335841298,
    "estimated_duration": 3600.0818377296196,
    "input_throughput": 4962.387469298895,
    "output_throughput": 4355.0679419798025,
    "total_throughput": 9317.455411278697,
    "itl": 78.06633830670282,
    "ttft": 301639.3765903467,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3419,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.463807596505697,
    "arrivals": 75147,
    "finished_requests": 71586,
    "scheduler_time": 76.98326601834643
}
#Debug simulation 
Total elapsed time: 20.932149070780724. Arrivals time: 0.2069551576860249 Scheduler time: 20.510606481693685 Scheduler overhead time: 0.06932725384831429 Adapter cache time: 0.04827337060123682 Engine time: 0.06635362235829234 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-16/adapters_384_slots_64_rate_0.1-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-16/adapters_384_slots_64_rate_0.1-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 1080, 540, 135, 1080, 1080, 135, 540, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 135, 1080, 135, 1080, 540, 540, 540, 135, 135, 540, 135, 1080, 135, 1080, 540, 1080, 540, 135, 540, 1080, 540, 1080, 135, 1080, 1080, 1080, 1080, 135, 540, 540, 540, 1080, 540, 135, 540, 135, 1080, 540, 1080, 1080, 540, 1080, 1080, 135, 135, 1080, 540, 540, 135, 135, 135, 540, 135, 540, 135, 1080, 135, 540, 1080, 135, 1080, 540, 135, 1080, 1080, 1080, 1080, 540, 135, 540, 1080, 1080, 540, 135, 135, 1080, 540, 540, 135, 135, 1080, 540, 1080, 540, 1080, 1080, 540, 1080, 1080, 135, 540, 540, 540, 540, 135, 135, 1080, 135, 1080, 135, 135, 135, 540, 540, 1080, 135, 135, 1080, 135, 1080, 540, 135, 1080, 540, 540, 135, 1080, 1080, 1080, 135, 540, 1080, 135, 1080, 540, 540, 1080, 1080, 135, 540, 1080, 135, 540, 540, 135, 540, 135, 540, 1080, 1080, 540, 135, 1080, 135, 1080, 540, 540, 540, 540, 540, 135, 135, 1080, 135, 1080, 135, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 135, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 135, 135, 135, 135, 135, 540, 135, 135, 540, 1080, 1080, 135, 135, 1080, 135, 135, 135, 540, 135, 540, 1080, 1080, 540, 540, 135, 1080, 540, 1080, 135, 540, 540, 135, 135, 540, 135, 1080, 1080, 135, 1080, 1080, 135, 540, 1080, 135, 135, 540, 540, 135, 135, 1080, 1080, 1080, 1080, 540, 135, 540, 540, 135, 135, 135, 135, 135, 135, 135, 135, 540, 1080, 540, 540, 540, 1080, 135, 540, 540, 1080, 1080, 135, 1080, 1080, 135, 1080, 135, 135, 540, 135, 1080, 1080, 1080, 540, 135, 1080, 1080, 540, 540, 1080, 1080, 135, 1080, 1080, 540, 135, 1080, 540, 540, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 135, 1080, 135, 540, 1080, 135, 540, 540, 540, 540, 135, 540, 135, 540, 540, 135, 1080, 135, 135, 135, 540, 135, 540, 540, 135, 1080, 540, 1080, 135, 1080, 135, 540, 540, 540, 540, 135, 540, 1080, 1080, 135, 1080, 1080, 135, 1080, 540, 1080, 540, 540, 540, 135, 540, 135, 135, 1080, 135, 540, 135, 135, 540, 1080, 540, 1080, 135, 1080, 1080, 540, 1080, 540, 135, 1080, 135, 1080, 1080, 135, 135, 135]
Prompts retrieved: 224640 . Total input tokens: 50059495 . Total output tokens: 44930825
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 20.264457635115832,
    "estimated_duration": 3600.0725516644266,
    "input_throughput": 4973.557544478341,
    "output_throughput": 4368.380574088473,
    "total_throughput": 9341.938118566814,
    "itl": 78.2459214698528,
    "ttft": 288212.0087445178,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3524,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.499587809481003,
    "arrivals": 75147,
    "finished_requests": 71784,
    "scheduler_time": 76.37918775243932
}
#Debug simulation 
Total elapsed time: 20.264539720956236. Arrivals time: 0.19464949565008283 Scheduler time: 19.85428437544033 Scheduler overhead time: 0.06982115842401981 Adapter cache time: 0.04905695468187332 Engine time: 0.06618951028212905 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-32/adapters_384_slots_64_rate_0.1-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-32/adapters_384_slots_64_rate_0.1-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 1080, 540, 135, 1080, 1080, 135, 540, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 135, 1080, 135, 1080, 540, 540, 540, 135, 135, 540, 135, 1080, 135, 1080, 540, 1080, 540, 135, 540, 1080, 540, 1080, 135, 1080, 1080, 1080, 1080, 135, 540, 540, 540, 1080, 540, 135, 540, 135, 1080, 540, 1080, 1080, 540, 1080, 1080, 135, 135, 1080, 540, 540, 135, 135, 135, 540, 135, 540, 135, 1080, 135, 540, 1080, 135, 1080, 540, 135, 1080, 1080, 1080, 1080, 540, 135, 540, 1080, 1080, 540, 135, 135, 1080, 540, 540, 135, 135, 1080, 540, 1080, 540, 1080, 1080, 540, 1080, 1080, 135, 540, 540, 540, 540, 135, 135, 1080, 135, 1080, 135, 135, 135, 540, 540, 1080, 135, 135, 1080, 135, 1080, 540, 135, 1080, 540, 540, 135, 1080, 1080, 1080, 135, 540, 1080, 135, 1080, 540, 540, 1080, 1080, 135, 540, 1080, 135, 540, 540, 135, 540, 135, 540, 1080, 1080, 540, 135, 1080, 135, 1080, 540, 540, 540, 540, 540, 135, 135, 1080, 135, 1080, 135, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 135, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 135, 135, 135, 135, 135, 540, 135, 135, 540, 1080, 1080, 135, 135, 1080, 135, 135, 135, 540, 135, 540, 1080, 1080, 540, 540, 135, 1080, 540, 1080, 135, 540, 540, 135, 135, 540, 135, 1080, 1080, 135, 1080, 1080, 135, 540, 1080, 135, 135, 540, 540, 135, 135, 1080, 1080, 1080, 1080, 540, 135, 540, 540, 135, 135, 135, 135, 135, 135, 135, 135, 540, 1080, 540, 540, 540, 1080, 135, 540, 540, 1080, 1080, 135, 1080, 1080, 135, 1080, 135, 135, 540, 135, 1080, 1080, 1080, 540, 135, 1080, 1080, 540, 540, 1080, 1080, 135, 1080, 1080, 540, 135, 1080, 540, 540, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 135, 1080, 135, 540, 1080, 135, 540, 540, 540, 540, 135, 540, 135, 540, 540, 135, 1080, 135, 135, 135, 540, 135, 540, 540, 135, 1080, 540, 1080, 135, 1080, 135, 540, 540, 540, 540, 135, 540, 1080, 1080, 135, 1080, 1080, 135, 1080, 540, 1080, 540, 540, 540, 135, 540, 135, 135, 1080, 135, 540, 135, 135, 540, 1080, 540, 1080, 135, 1080, 1080, 540, 1080, 540, 135, 1080, 135, 1080, 1080, 135, 135, 135]
Prompts retrieved: 224640 . Total input tokens: 50059495 . Total output tokens: 44930825
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 20.301422462798655,
    "estimated_duration": 3600.0442924176396,
    "input_throughput": 4969.244694482955,
    "output_throughput": 4366.707107773631,
    "total_throughput": 9335.951802256586,
    "itl": 78.1605299045589,
    "ttft": 290337.50877991563,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3513,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.48340158538829,
    "arrivals": 75147,
    "finished_requests": 71741,
    "scheduler_time": 76.40028331138794
}
#Debug simulation 
Total elapsed time: 20.30154609400779. Arrivals time: 0.20660977438092232 Scheduler time: 19.877741294912994 Scheduler overhead time: 0.06983273616060615 Adapter cache time: 0.04965913016349077 Engine time: 0.06704248953610659 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-16/adapters_384_slots_64_rate_0.1-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-16/adapters_384_slots_64_rate_0.1-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 1080, 540, 135, 1080, 1080, 135, 540, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 135, 1080, 135, 1080, 540, 540, 540, 135, 135, 540, 135, 1080, 135, 1080, 540, 1080, 540, 135, 540, 1080, 540, 1080, 135, 1080, 1080, 1080, 1080, 135, 540, 540, 540, 1080, 540, 135, 540, 135, 1080, 540, 1080, 1080, 540, 1080, 1080, 135, 135, 1080, 540, 540, 135, 135, 135, 540, 135, 540, 135, 1080, 135, 540, 1080, 135, 1080, 540, 135, 1080, 1080, 1080, 1080, 540, 135, 540, 1080, 1080, 540, 135, 135, 1080, 540, 540, 135, 135, 1080, 540, 1080, 540, 1080, 1080, 540, 1080, 1080, 135, 540, 540, 540, 540, 135, 135, 1080, 135, 1080, 135, 135, 135, 540, 540, 1080, 135, 135, 1080, 135, 1080, 540, 135, 1080, 540, 540, 135, 1080, 1080, 1080, 135, 540, 1080, 135, 1080, 540, 540, 1080, 1080, 135, 540, 1080, 135, 540, 540, 135, 540, 135, 540, 1080, 1080, 540, 135, 1080, 135, 1080, 540, 540, 540, 540, 540, 135, 135, 1080, 135, 1080, 135, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 135, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 135, 135, 135, 135, 135, 540, 135, 135, 540, 1080, 1080, 135, 135, 1080, 135, 135, 135, 540, 135, 540, 1080, 1080, 540, 540, 135, 1080, 540, 1080, 135, 540, 540, 135, 135, 540, 135, 1080, 1080, 135, 1080, 1080, 135, 540, 1080, 135, 135, 540, 540, 135, 135, 1080, 1080, 1080, 1080, 540, 135, 540, 540, 135, 135, 135, 135, 135, 135, 135, 135, 540, 1080, 540, 540, 540, 1080, 135, 540, 540, 1080, 1080, 135, 1080, 1080, 135, 1080, 135, 135, 540, 135, 1080, 1080, 1080, 540, 135, 1080, 1080, 540, 540, 1080, 1080, 135, 1080, 1080, 540, 135, 1080, 540, 540, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 135, 1080, 135, 540, 1080, 135, 540, 540, 540, 540, 135, 540, 135, 540, 540, 135, 1080, 135, 135, 135, 540, 135, 540, 540, 135, 1080, 540, 1080, 135, 1080, 135, 540, 540, 540, 540, 135, 540, 1080, 1080, 135, 1080, 1080, 135, 1080, 540, 1080, 540, 540, 540, 135, 540, 135, 135, 1080, 135, 540, 135, 135, 540, 1080, 540, 1080, 135, 1080, 1080, 540, 1080, 540, 135, 1080, 135, 1080, 1080, 135, 135, 135]
Prompts retrieved: 224640 . Total input tokens: 50059495 . Total output tokens: 44930825
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 20.373190764337778,
    "estimated_duration": 3600.083803753675,
    "input_throughput": 4969.251543907685,
    "output_throughput": 4366.802234883656,
    "total_throughput": 9336.05377879134,
    "itl": 78.17665682514739,
    "ttft": 288314.9283771451,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3513,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.984963375795981,
    "arrivals": 75147,
    "finished_requests": 71791,
    "scheduler_time": 76.42239379658848
}
#Debug simulation 
Total elapsed time: 20.373313819989562. Arrivals time: 0.2017310569062829 Scheduler time: 19.955762280151248 Scheduler overhead time: 0.06962809711694717 Adapter cache time: 0.048972324933856726 Engine time: 0.06663157511502504 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-32/adapters_384_slots_64_rate_0.1-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-32/adapters_384_slots_64_rate_0.1-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 1080, 540, 135, 1080, 1080, 135, 540, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 135, 1080, 135, 1080, 540, 540, 540, 135, 135, 540, 135, 1080, 135, 1080, 540, 1080, 540, 135, 540, 1080, 540, 1080, 135, 1080, 1080, 1080, 1080, 135, 540, 540, 540, 1080, 540, 135, 540, 135, 1080, 540, 1080, 1080, 540, 1080, 1080, 135, 135, 1080, 540, 540, 135, 135, 135, 540, 135, 540, 135, 1080, 135, 540, 1080, 135, 1080, 540, 135, 1080, 1080, 1080, 1080, 540, 135, 540, 1080, 1080, 540, 135, 135, 1080, 540, 540, 135, 135, 1080, 540, 1080, 540, 1080, 1080, 540, 1080, 1080, 135, 540, 540, 540, 540, 135, 135, 1080, 135, 1080, 135, 135, 135, 540, 540, 1080, 135, 135, 1080, 135, 1080, 540, 135, 1080, 540, 540, 135, 1080, 1080, 1080, 135, 540, 1080, 135, 1080, 540, 540, 1080, 1080, 135, 540, 1080, 135, 540, 540, 135, 540, 135, 540, 1080, 1080, 540, 135, 1080, 135, 1080, 540, 540, 540, 540, 540, 135, 135, 1080, 135, 1080, 135, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 135, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 135, 135, 135, 135, 135, 540, 135, 135, 540, 1080, 1080, 135, 135, 1080, 135, 135, 135, 540, 135, 540, 1080, 1080, 540, 540, 135, 1080, 540, 1080, 135, 540, 540, 135, 135, 540, 135, 1080, 1080, 135, 1080, 1080, 135, 540, 1080, 135, 135, 540, 540, 135, 135, 1080, 1080, 1080, 1080, 540, 135, 540, 540, 135, 135, 135, 135, 135, 135, 135, 135, 540, 1080, 540, 540, 540, 1080, 135, 540, 540, 1080, 1080, 135, 1080, 1080, 135, 1080, 135, 135, 540, 135, 1080, 1080, 1080, 540, 135, 1080, 1080, 540, 540, 1080, 1080, 135, 1080, 1080, 540, 135, 1080, 540, 540, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 135, 1080, 135, 540, 1080, 135, 540, 540, 540, 540, 135, 540, 135, 540, 540, 135, 1080, 135, 135, 135, 540, 135, 540, 540, 135, 1080, 540, 1080, 135, 1080, 135, 540, 540, 540, 540, 135, 540, 1080, 1080, 135, 1080, 1080, 135, 1080, 540, 1080, 540, 540, 540, 135, 540, 135, 135, 1080, 135, 540, 135, 135, 540, 1080, 540, 1080, 135, 1080, 1080, 540, 1080, 540, 135, 1080, 135, 1080, 1080, 135, 135, 135]
Prompts retrieved: 224640 . Total input tokens: 50059495 . Total output tokens: 44930825
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 20.541723250877112,
    "estimated_duration": 3600.0358108712144,
    "input_throughput": 4972.504980629035,
    "output_throughput": 4366.5618415600675,
    "total_throughput": 9339.066822189103,
    "itl": 78.35997405806589,
    "ttft": 290502.46710748895,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3466,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.475695891677681,
    "arrivals": 75147,
    "finished_requests": 71776,
    "scheduler_time": 76.66527065404254
}
#Debug simulation 
Total elapsed time: 20.541823979932815. Arrivals time: 0.19512937776744366 Scheduler time: 20.13071395503357 Scheduler overhead time: 0.06986231869086623 Adapter cache time: 0.048589928075671196 Engine time: 0.06677215825766325 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-16/adapters_384_slots_64_rate_0.1-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-16/adapters_384_slots_64_rate_0.1-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 1080, 540, 135, 1080, 1080, 135, 540, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 135, 1080, 135, 1080, 540, 540, 540, 135, 135, 540, 135, 1080, 135, 1080, 540, 1080, 540, 135, 540, 1080, 540, 1080, 135, 1080, 1080, 1080, 1080, 135, 540, 540, 540, 1080, 540, 135, 540, 135, 1080, 540, 1080, 1080, 540, 1080, 1080, 135, 135, 1080, 540, 540, 135, 135, 135, 540, 135, 540, 135, 1080, 135, 540, 1080, 135, 1080, 540, 135, 1080, 1080, 1080, 1080, 540, 135, 540, 1080, 1080, 540, 135, 135, 1080, 540, 540, 135, 135, 1080, 540, 1080, 540, 1080, 1080, 540, 1080, 1080, 135, 540, 540, 540, 540, 135, 135, 1080, 135, 1080, 135, 135, 135, 540, 540, 1080, 135, 135, 1080, 135, 1080, 540, 135, 1080, 540, 540, 135, 1080, 1080, 1080, 135, 540, 1080, 135, 1080, 540, 540, 1080, 1080, 135, 540, 1080, 135, 540, 540, 135, 540, 135, 540, 1080, 1080, 540, 135, 1080, 135, 1080, 540, 540, 540, 540, 540, 135, 135, 1080, 135, 1080, 135, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 135, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 135, 135, 135, 135, 135, 540, 135, 135, 540, 1080, 1080, 135, 135, 1080, 135, 135, 135, 540, 135, 540, 1080, 1080, 540, 540, 135, 1080, 540, 1080, 135, 540, 540, 135, 135, 540, 135, 1080, 1080, 135, 1080, 1080, 135, 540, 1080, 135, 135, 540, 540, 135, 135, 1080, 1080, 1080, 1080, 540, 135, 540, 540, 135, 135, 135, 135, 135, 135, 135, 135, 540, 1080, 540, 540, 540, 1080, 135, 540, 540, 1080, 1080, 135, 1080, 1080, 135, 1080, 135, 135, 540, 135, 1080, 1080, 1080, 540, 135, 1080, 1080, 540, 540, 1080, 1080, 135, 1080, 1080, 540, 135, 1080, 540, 540, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 135, 1080, 135, 540, 1080, 135, 540, 540, 540, 540, 135, 540, 135, 540, 540, 135, 1080, 135, 135, 135, 540, 135, 540, 540, 135, 1080, 540, 1080, 135, 1080, 135, 540, 540, 540, 540, 135, 540, 1080, 1080, 135, 1080, 1080, 135, 1080, 540, 1080, 540, 540, 540, 135, 540, 135, 135, 1080, 135, 540, 135, 135, 540, 1080, 540, 1080, 135, 1080, 1080, 540, 1080, 540, 135, 1080, 135, 1080, 1080, 135, 135, 135]
Prompts retrieved: 224640 . Total input tokens: 50059495 . Total output tokens: 44930825
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 20.558992467820644,
    "estimated_duration": 3600.0130561975216,
    "input_throughput": 4964.174774098227,
    "output_throughput": 4355.638092202426,
    "total_throughput": 9319.812866300654,
    "itl": 78.05544785470124,
    "ttft": 296627.2755354199,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3445,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.300723265938348,
    "arrivals": 75147,
    "finished_requests": 71651,
    "scheduler_time": 76.71943578994082
}
#Debug simulation 
Total elapsed time: 20.559104120824486. Arrivals time: 0.20535929687321186 Scheduler time: 20.136732621584088 Scheduler overhead time: 0.06984638329595327 Adapter cache time: 0.049102431163191795 Engine time: 0.0673159770667553 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-32/adapters_384_slots_64_rate_0.1-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-32/adapters_384_slots_64_rate_0.1-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 1080, 540, 135, 1080, 1080, 135, 540, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 135, 1080, 135, 1080, 540, 540, 540, 135, 135, 540, 135, 1080, 135, 1080, 540, 1080, 540, 135, 540, 1080, 540, 1080, 135, 1080, 1080, 1080, 1080, 135, 540, 540, 540, 1080, 540, 135, 540, 135, 1080, 540, 1080, 1080, 540, 1080, 1080, 135, 135, 1080, 540, 540, 135, 135, 135, 540, 135, 540, 135, 1080, 135, 540, 1080, 135, 1080, 540, 135, 1080, 1080, 1080, 1080, 540, 135, 540, 1080, 1080, 540, 135, 135, 1080, 540, 540, 135, 135, 1080, 540, 1080, 540, 1080, 1080, 540, 1080, 1080, 135, 540, 540, 540, 540, 135, 135, 1080, 135, 1080, 135, 135, 135, 540, 540, 1080, 135, 135, 1080, 135, 1080, 540, 135, 1080, 540, 540, 135, 1080, 1080, 1080, 135, 540, 1080, 135, 1080, 540, 540, 1080, 1080, 135, 540, 1080, 135, 540, 540, 135, 540, 135, 540, 1080, 1080, 540, 135, 1080, 135, 1080, 540, 540, 540, 540, 540, 135, 135, 1080, 135, 1080, 135, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 135, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 135, 135, 135, 135, 135, 540, 135, 135, 540, 1080, 1080, 135, 135, 1080, 135, 135, 135, 540, 135, 540, 1080, 1080, 540, 540, 135, 1080, 540, 1080, 135, 540, 540, 135, 135, 540, 135, 1080, 1080, 135, 1080, 1080, 135, 540, 1080, 135, 135, 540, 540, 135, 135, 1080, 1080, 1080, 1080, 540, 135, 540, 540, 135, 135, 135, 135, 135, 135, 135, 135, 540, 1080, 540, 540, 540, 1080, 135, 540, 540, 1080, 1080, 135, 1080, 1080, 135, 1080, 135, 135, 540, 135, 1080, 1080, 1080, 540, 135, 1080, 1080, 540, 540, 1080, 1080, 135, 1080, 1080, 540, 135, 1080, 540, 540, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 135, 1080, 135, 540, 1080, 135, 540, 540, 540, 540, 135, 540, 135, 540, 540, 135, 1080, 135, 135, 135, 540, 135, 540, 540, 135, 1080, 540, 1080, 135, 1080, 135, 540, 540, 540, 540, 135, 540, 1080, 1080, 135, 1080, 1080, 135, 1080, 540, 1080, 540, 540, 540, 135, 540, 135, 135, 1080, 135, 540, 135, 135, 540, 1080, 540, 1080, 135, 1080, 1080, 540, 1080, 540, 135, 1080, 135, 1080, 1080, 135, 135, 135]
Prompts retrieved: 224640 . Total input tokens: 50059495 . Total output tokens: 44930825
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 20.448730467818677,
    "estimated_duration": 3600.0414918404017,
    "input_throughput": 4967.883298160849,
    "output_throughput": 4358.666708582378,
    "total_throughput": 9326.550006743228,
    "itl": 78.11144860111206,
    "ttft": 295027.05975137773,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3459,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.597990659437386,
    "arrivals": 75147,
    "finished_requests": 71670,
    "scheduler_time": 76.58960413931263
}
#Debug simulation 
Total elapsed time: 20.44886968098581. Arrivals time: 0.1997218281030655 Scheduler time: 20.034814373590052 Scheduler overhead time: 0.06885742768645287 Adapter cache time: 0.048359040170907974 Engine time: 0.06644246866926551 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-8/adapters_384_slots_64_rate_0.1-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-8/adapters_384_slots_64_rate_0.1-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 1080, 540, 66, 1080, 1080, 66, 540, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 66, 1080, 66, 1080, 540, 540, 540, 66, 66, 540, 66, 1080, 66, 1080, 540, 1080, 540, 66, 540, 1080, 540, 1080, 66, 1080, 1080, 1080, 1080, 66, 540, 540, 540, 1080, 540, 66, 540, 66, 1080, 540, 1080, 1080, 540, 1080, 1080, 66, 66, 1080, 540, 540, 66, 66, 66, 540, 66, 540, 66, 1080, 66, 540, 1080, 66, 1080, 540, 66, 1080, 1080, 1080, 1080, 540, 66, 540, 1080, 1080, 540, 66, 66, 1080, 540, 540, 66, 66, 1080, 540, 1080, 540, 1080, 1080, 540, 1080, 1080, 66, 540, 540, 540, 540, 66, 66, 1080, 66, 1080, 66, 66, 66, 540, 540, 1080, 66, 66, 1080, 66, 1080, 540, 66, 1080, 540, 540, 66, 1080, 1080, 1080, 66, 540, 1080, 66, 1080, 540, 540, 1080, 1080, 66, 540, 1080, 66, 540, 540, 66, 540, 66, 540, 1080, 1080, 540, 66, 1080, 66, 1080, 540, 540, 540, 540, 540, 66, 66, 1080, 66, 1080, 66, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 66, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 66, 66, 66, 66, 66, 540, 66, 66, 540, 1080, 1080, 66, 66, 1080, 66, 66, 66, 540, 66, 540, 1080, 1080, 540, 540, 66, 1080, 540, 1080, 66, 540, 540, 66, 66, 540, 66, 1080, 1080, 66, 1080, 1080, 66, 540, 1080, 66, 66, 540, 540, 66, 66, 1080, 1080, 1080, 1080, 540, 66, 540, 540, 66, 66, 66, 66, 66, 66, 66, 66, 540, 1080, 540, 540, 540, 1080, 66, 540, 540, 1080, 1080, 66, 1080, 1080, 66, 1080, 66, 66, 540, 66, 1080, 1080, 1080, 540, 66, 1080, 1080, 540, 540, 1080, 1080, 66, 1080, 1080, 540, 66, 1080, 540, 540, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 66, 1080, 66, 540, 1080, 66, 540, 540, 540, 540, 66, 540, 66, 540, 540, 66, 1080, 66, 66, 66, 540, 66, 540, 540, 66, 1080, 540, 1080, 66, 1080, 66, 540, 540, 540, 540, 66, 540, 1080, 1080, 66, 1080, 1080, 66, 1080, 540, 1080, 540, 540, 540, 66, 540, 66, 66, 1080, 66, 540, 66, 66, 540, 1080, 540, 1080, 66, 1080, 1080, 540, 1080, 540, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 215808 . Total input tokens: 48083984 . Total output tokens: 43180710
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 16.971414742060006,
    "estimated_duration": 3599.9366035644416,
    "input_throughput": 4757.17432997107,
    "output_throughput": 4235.941262104792,
    "total_throughput": 8993.115592075861,
    "itl": 73.57186800656969,
    "ttft": 244018.4151027679,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3887,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.89611586066586,
    "arrivals": 72240,
    "finished_requests": 69366,
    "scheduler_time": 70.06660822840246
}
#Debug simulation 
Total elapsed time: 16.97148137819022. Arrivals time: 0.1821807217784226 Scheduler time: 16.565349174197763 Scheduler overhead time: 0.07161857141181827 Adapter cache time: 0.05176534503698349 Engine time: 0.0687800464220345 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-16/adapters_384_slots_64_rate_0.1-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-16/adapters_384_slots_64_rate_0.1-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 1080, 540, 66, 1080, 1080, 66, 540, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 66, 1080, 66, 1080, 540, 540, 540, 66, 66, 540, 66, 1080, 66, 1080, 540, 1080, 540, 66, 540, 1080, 540, 1080, 66, 1080, 1080, 1080, 1080, 66, 540, 540, 540, 1080, 540, 66, 540, 66, 1080, 540, 1080, 1080, 540, 1080, 1080, 66, 66, 1080, 540, 540, 66, 66, 66, 540, 66, 540, 66, 1080, 66, 540, 1080, 66, 1080, 540, 66, 1080, 1080, 1080, 1080, 540, 66, 540, 1080, 1080, 540, 66, 66, 1080, 540, 540, 66, 66, 1080, 540, 1080, 540, 1080, 1080, 540, 1080, 1080, 66, 540, 540, 540, 540, 66, 66, 1080, 66, 1080, 66, 66, 66, 540, 540, 1080, 66, 66, 1080, 66, 1080, 540, 66, 1080, 540, 540, 66, 1080, 1080, 1080, 66, 540, 1080, 66, 1080, 540, 540, 1080, 1080, 66, 540, 1080, 66, 540, 540, 66, 540, 66, 540, 1080, 1080, 540, 66, 1080, 66, 1080, 540, 540, 540, 540, 540, 66, 66, 1080, 66, 1080, 66, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 66, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 66, 66, 66, 66, 66, 540, 66, 66, 540, 1080, 1080, 66, 66, 1080, 66, 66, 66, 540, 66, 540, 1080, 1080, 540, 540, 66, 1080, 540, 1080, 66, 540, 540, 66, 66, 540, 66, 1080, 1080, 66, 1080, 1080, 66, 540, 1080, 66, 66, 540, 540, 66, 66, 1080, 1080, 1080, 1080, 540, 66, 540, 540, 66, 66, 66, 66, 66, 66, 66, 66, 540, 1080, 540, 540, 540, 1080, 66, 540, 540, 1080, 1080, 66, 1080, 1080, 66, 1080, 66, 66, 540, 66, 1080, 1080, 1080, 540, 66, 1080, 1080, 540, 540, 1080, 1080, 66, 1080, 1080, 540, 66, 1080, 540, 540, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 66, 1080, 66, 540, 1080, 66, 540, 540, 540, 540, 66, 540, 66, 540, 540, 66, 1080, 66, 66, 66, 540, 66, 540, 540, 66, 1080, 540, 1080, 66, 1080, 66, 540, 540, 540, 540, 66, 540, 1080, 1080, 66, 1080, 1080, 66, 1080, 540, 1080, 540, 540, 540, 66, 540, 66, 66, 1080, 66, 540, 66, 66, 540, 1080, 540, 1080, 66, 1080, 1080, 540, 1080, 540, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 215808 . Total input tokens: 48083984 . Total output tokens: 43180710
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 16.986565518658608,
    "estimated_duration": 3599.9417605778763,
    "input_throughput": 4759.7289455175705,
    "output_throughput": 4234.7243410829105,
    "total_throughput": 8994.453286600481,
    "itl": 73.6551464463668,
    "ttft": 243518.27775236787,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3876,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.647288222483379,
    "arrivals": 72240,
    "finished_requests": 69386,
    "scheduler_time": 70.13152931830587
}
#Debug simulation 
Total elapsed time: 16.986705775838345. Arrivals time: 0.18772589787840843 Scheduler time: 16.574637598823756 Scheduler overhead time: 0.07170550059527159 Adapter cache time: 0.05241448199376464 Engine time: 0.06853625737130642 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-32/adapters_384_slots_64_rate_0.1-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-32/adapters_384_slots_64_rate_0.1-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 1080, 540, 66, 1080, 1080, 66, 540, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 66, 1080, 66, 1080, 540, 540, 540, 66, 66, 540, 66, 1080, 66, 1080, 540, 1080, 540, 66, 540, 1080, 540, 1080, 66, 1080, 1080, 1080, 1080, 66, 540, 540, 540, 1080, 540, 66, 540, 66, 1080, 540, 1080, 1080, 540, 1080, 1080, 66, 66, 1080, 540, 540, 66, 66, 66, 540, 66, 540, 66, 1080, 66, 540, 1080, 66, 1080, 540, 66, 1080, 1080, 1080, 1080, 540, 66, 540, 1080, 1080, 540, 66, 66, 1080, 540, 540, 66, 66, 1080, 540, 1080, 540, 1080, 1080, 540, 1080, 1080, 66, 540, 540, 540, 540, 66, 66, 1080, 66, 1080, 66, 66, 66, 540, 540, 1080, 66, 66, 1080, 66, 1080, 540, 66, 1080, 540, 540, 66, 1080, 1080, 1080, 66, 540, 1080, 66, 1080, 540, 540, 1080, 1080, 66, 540, 1080, 66, 540, 540, 66, 540, 66, 540, 1080, 1080, 540, 66, 1080, 66, 1080, 540, 540, 540, 540, 540, 66, 66, 1080, 66, 1080, 66, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 66, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 66, 66, 66, 66, 66, 540, 66, 66, 540, 1080, 1080, 66, 66, 1080, 66, 66, 66, 540, 66, 540, 1080, 1080, 540, 540, 66, 1080, 540, 1080, 66, 540, 540, 66, 66, 540, 66, 1080, 1080, 66, 1080, 1080, 66, 540, 1080, 66, 66, 540, 540, 66, 66, 1080, 1080, 1080, 1080, 540, 66, 540, 540, 66, 66, 66, 66, 66, 66, 66, 66, 540, 1080, 540, 540, 540, 1080, 66, 540, 540, 1080, 1080, 66, 1080, 1080, 66, 1080, 66, 66, 540, 66, 1080, 1080, 1080, 540, 66, 1080, 1080, 540, 540, 1080, 1080, 66, 1080, 1080, 540, 66, 1080, 540, 540, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 66, 1080, 66, 540, 1080, 66, 540, 540, 540, 540, 66, 540, 66, 540, 540, 66, 1080, 66, 66, 66, 540, 66, 540, 540, 66, 1080, 540, 1080, 66, 1080, 66, 540, 540, 540, 540, 66, 540, 1080, 1080, 66, 1080, 1080, 66, 1080, 540, 1080, 540, 540, 540, 66, 540, 66, 66, 1080, 66, 540, 66, 66, 540, 1080, 540, 1080, 66, 1080, 1080, 540, 1080, 540, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 215808 . Total input tokens: 48083984 . Total output tokens: 43180710
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 17.042364770080894,
    "estimated_duration": 3599.9309955851472,
    "input_throughput": 4760.25513295,
    "output_throughput": 4236.070918776396,
    "total_throughput": 8996.326051726395,
    "itl": 73.56445310455494,
    "ttft": 243936.80708743245,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3884,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.69449821945195,
    "arrivals": 72240,
    "finished_requests": 69373,
    "scheduler_time": 70.09272030467994
}
#Debug simulation 
Total elapsed time: 17.042468613944948. Arrivals time: 0.19639294687658548 Scheduler time: 16.6196661144495 Scheduler overhead time: 0.0721044335514307 Adapter cache time: 0.0528925065882504 Engine time: 0.0695256283506751 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-16/adapters_384_slots_64_rate_0.1-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-16/adapters_384_slots_64_rate_0.1-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 1080, 540, 66, 1080, 1080, 66, 540, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 66, 1080, 66, 1080, 540, 540, 540, 66, 66, 540, 66, 1080, 66, 1080, 540, 1080, 540, 66, 540, 1080, 540, 1080, 66, 1080, 1080, 1080, 1080, 66, 540, 540, 540, 1080, 540, 66, 540, 66, 1080, 540, 1080, 1080, 540, 1080, 1080, 66, 66, 1080, 540, 540, 66, 66, 66, 540, 66, 540, 66, 1080, 66, 540, 1080, 66, 1080, 540, 66, 1080, 1080, 1080, 1080, 540, 66, 540, 1080, 1080, 540, 66, 66, 1080, 540, 540, 66, 66, 1080, 540, 1080, 540, 1080, 1080, 540, 1080, 1080, 66, 540, 540, 540, 540, 66, 66, 1080, 66, 1080, 66, 66, 66, 540, 540, 1080, 66, 66, 1080, 66, 1080, 540, 66, 1080, 540, 540, 66, 1080, 1080, 1080, 66, 540, 1080, 66, 1080, 540, 540, 1080, 1080, 66, 540, 1080, 66, 540, 540, 66, 540, 66, 540, 1080, 1080, 540, 66, 1080, 66, 1080, 540, 540, 540, 540, 540, 66, 66, 1080, 66, 1080, 66, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 66, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 66, 66, 66, 66, 66, 540, 66, 66, 540, 1080, 1080, 66, 66, 1080, 66, 66, 66, 540, 66, 540, 1080, 1080, 540, 540, 66, 1080, 540, 1080, 66, 540, 540, 66, 66, 540, 66, 1080, 1080, 66, 1080, 1080, 66, 540, 1080, 66, 66, 540, 540, 66, 66, 1080, 1080, 1080, 1080, 540, 66, 540, 540, 66, 66, 66, 66, 66, 66, 66, 66, 540, 1080, 540, 540, 540, 1080, 66, 540, 540, 1080, 1080, 66, 1080, 1080, 66, 1080, 66, 66, 540, 66, 1080, 1080, 1080, 540, 66, 1080, 1080, 540, 540, 1080, 1080, 66, 1080, 1080, 540, 66, 1080, 540, 540, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 66, 1080, 66, 540, 1080, 66, 540, 540, 540, 540, 66, 540, 66, 540, 540, 66, 1080, 66, 66, 66, 540, 66, 540, 540, 66, 1080, 540, 1080, 66, 1080, 66, 540, 540, 540, 540, 66, 540, 1080, 1080, 66, 1080, 1080, 66, 1080, 540, 1080, 540, 540, 540, 66, 540, 66, 66, 1080, 66, 540, 66, 66, 540, 1080, 540, 1080, 66, 1080, 1080, 540, 1080, 540, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 215808 . Total input tokens: 48083984 . Total output tokens: 43180710
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 16.902580260764807,
    "estimated_duration": 3599.9135968290775,
    "input_throughput": 4761.85678875723,
    "output_throughput": 4236.159449335821,
    "total_throughput": 8998.01623809305,
    "itl": 73.55281215810331,
    "ttft": 243376.44500483005,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3890,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.16818989560069,
    "arrivals": 72240,
    "finished_requests": 69391,
    "scheduler_time": 70.14110065354863
}
#Debug simulation 
Total elapsed time: 16.902678805869073. Arrivals time: 0.18195913778617978 Scheduler time: 16.497848716564476 Scheduler overhead time: 0.07111797342076898 Adapter cache time: 0.05266416538506746 Engine time: 0.06763578532263637 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-32/adapters_384_slots_64_rate_0.1-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-32/adapters_384_slots_64_rate_0.1-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 1080, 540, 66, 1080, 1080, 66, 540, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 66, 1080, 66, 1080, 540, 540, 540, 66, 66, 540, 66, 1080, 66, 1080, 540, 1080, 540, 66, 540, 1080, 540, 1080, 66, 1080, 1080, 1080, 1080, 66, 540, 540, 540, 1080, 540, 66, 540, 66, 1080, 540, 1080, 1080, 540, 1080, 1080, 66, 66, 1080, 540, 540, 66, 66, 66, 540, 66, 540, 66, 1080, 66, 540, 1080, 66, 1080, 540, 66, 1080, 1080, 1080, 1080, 540, 66, 540, 1080, 1080, 540, 66, 66, 1080, 540, 540, 66, 66, 1080, 540, 1080, 540, 1080, 1080, 540, 1080, 1080, 66, 540, 540, 540, 540, 66, 66, 1080, 66, 1080, 66, 66, 66, 540, 540, 1080, 66, 66, 1080, 66, 1080, 540, 66, 1080, 540, 540, 66, 1080, 1080, 1080, 66, 540, 1080, 66, 1080, 540, 540, 1080, 1080, 66, 540, 1080, 66, 540, 540, 66, 540, 66, 540, 1080, 1080, 540, 66, 1080, 66, 1080, 540, 540, 540, 540, 540, 66, 66, 1080, 66, 1080, 66, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 66, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 66, 66, 66, 66, 66, 540, 66, 66, 540, 1080, 1080, 66, 66, 1080, 66, 66, 66, 540, 66, 540, 1080, 1080, 540, 540, 66, 1080, 540, 1080, 66, 540, 540, 66, 66, 540, 66, 1080, 1080, 66, 1080, 1080, 66, 540, 1080, 66, 66, 540, 540, 66, 66, 1080, 1080, 1080, 1080, 540, 66, 540, 540, 66, 66, 66, 66, 66, 66, 66, 66, 540, 1080, 540, 540, 540, 1080, 66, 540, 540, 1080, 1080, 66, 1080, 1080, 66, 1080, 66, 66, 540, 66, 1080, 1080, 1080, 540, 66, 1080, 1080, 540, 540, 1080, 1080, 66, 1080, 1080, 540, 66, 1080, 540, 540, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 66, 1080, 66, 540, 1080, 66, 540, 540, 540, 540, 66, 540, 66, 540, 540, 66, 1080, 66, 66, 66, 540, 66, 540, 540, 66, 1080, 540, 1080, 66, 1080, 66, 540, 540, 540, 540, 66, 540, 1080, 1080, 66, 1080, 1080, 66, 1080, 540, 1080, 540, 540, 540, 66, 540, 66, 66, 1080, 66, 540, 66, 66, 540, 1080, 540, 1080, 66, 1080, 1080, 540, 1080, 540, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 215808 . Total input tokens: 48083984 . Total output tokens: 43180710
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 17.040818099863827,
    "estimated_duration": 3599.9379781999014,
    "input_throughput": 4760.413958178584,
    "output_throughput": 4236.012145860702,
    "total_throughput": 8996.426104039285,
    "itl": 73.63661085343129,
    "ttft": 243524.3284275319,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3878,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.837287692892454,
    "arrivals": 72240,
    "finished_requests": 69388,
    "scheduler_time": 70.13066887490794
}
#Debug simulation 
Total elapsed time: 17.04089767113328. Arrivals time: 0.1884302874095738 Scheduler time: 16.62910114042461 Scheduler overhead time: 0.07151128724217415 Adapter cache time: 0.051621547900140285 Engine time: 0.06856394791975617 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-16/adapters_384_slots_64_rate_0.1-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-16/adapters_384_slots_64_rate_0.1-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 1080, 540, 66, 1080, 1080, 66, 540, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 66, 1080, 66, 1080, 540, 540, 540, 66, 66, 540, 66, 1080, 66, 1080, 540, 1080, 540, 66, 540, 1080, 540, 1080, 66, 1080, 1080, 1080, 1080, 66, 540, 540, 540, 1080, 540, 66, 540, 66, 1080, 540, 1080, 1080, 540, 1080, 1080, 66, 66, 1080, 540, 540, 66, 66, 66, 540, 66, 540, 66, 1080, 66, 540, 1080, 66, 1080, 540, 66, 1080, 1080, 1080, 1080, 540, 66, 540, 1080, 1080, 540, 66, 66, 1080, 540, 540, 66, 66, 1080, 540, 1080, 540, 1080, 1080, 540, 1080, 1080, 66, 540, 540, 540, 540, 66, 66, 1080, 66, 1080, 66, 66, 66, 540, 540, 1080, 66, 66, 1080, 66, 1080, 540, 66, 1080, 540, 540, 66, 1080, 1080, 1080, 66, 540, 1080, 66, 1080, 540, 540, 1080, 1080, 66, 540, 1080, 66, 540, 540, 66, 540, 66, 540, 1080, 1080, 540, 66, 1080, 66, 1080, 540, 540, 540, 540, 540, 66, 66, 1080, 66, 1080, 66, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 66, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 66, 66, 66, 66, 66, 540, 66, 66, 540, 1080, 1080, 66, 66, 1080, 66, 66, 66, 540, 66, 540, 1080, 1080, 540, 540, 66, 1080, 540, 1080, 66, 540, 540, 66, 66, 540, 66, 1080, 1080, 66, 1080, 1080, 66, 540, 1080, 66, 66, 540, 540, 66, 66, 1080, 1080, 1080, 1080, 540, 66, 540, 540, 66, 66, 66, 66, 66, 66, 66, 66, 540, 1080, 540, 540, 540, 1080, 66, 540, 540, 1080, 1080, 66, 1080, 1080, 66, 1080, 66, 66, 540, 66, 1080, 1080, 1080, 540, 66, 1080, 1080, 540, 540, 1080, 1080, 66, 1080, 1080, 540, 66, 1080, 540, 540, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 66, 1080, 66, 540, 1080, 66, 540, 540, 540, 540, 66, 540, 66, 540, 540, 66, 1080, 66, 66, 66, 540, 66, 540, 540, 66, 1080, 540, 1080, 66, 1080, 66, 540, 540, 540, 540, 66, 540, 1080, 1080, 66, 1080, 1080, 66, 1080, 540, 1080, 540, 540, 540, 66, 540, 66, 66, 1080, 66, 540, 66, 66, 540, 1080, 540, 1080, 66, 1080, 1080, 540, 1080, 540, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 215808 . Total input tokens: 48083984 . Total output tokens: 43180710
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 16.957899416796863,
    "estimated_duration": 3599.953483929589,
    "input_throughput": 4756.080065043107,
    "output_throughput": 4234.554437453437,
    "total_throughput": 8990.634502496545,
    "itl": 73.60108187432138,
    "ttft": 245523.89089761372,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3880,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.601395144221135,
    "arrivals": 72240,
    "finished_requests": 69346,
    "scheduler_time": 70.15777783467972
}
#Debug simulation 
Total elapsed time: 16.958044136874378. Arrivals time: 0.18742656614631414 Scheduler time: 16.54698302783072 Scheduler overhead time: 0.07114212773740292 Adapter cache time: 0.05222925543785095 Engine time: 0.06858597509562969 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-32/adapters_384_slots_64_rate_0.1-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-32/adapters_384_slots_64_rate_0.1-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 1080, 540, 66, 1080, 1080, 66, 540, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 66, 1080, 66, 1080, 540, 540, 540, 66, 66, 540, 66, 1080, 66, 1080, 540, 1080, 540, 66, 540, 1080, 540, 1080, 66, 1080, 1080, 1080, 1080, 66, 540, 540, 540, 1080, 540, 66, 540, 66, 1080, 540, 1080, 1080, 540, 1080, 1080, 66, 66, 1080, 540, 540, 66, 66, 66, 540, 66, 540, 66, 1080, 66, 540, 1080, 66, 1080, 540, 66, 1080, 1080, 1080, 1080, 540, 66, 540, 1080, 1080, 540, 66, 66, 1080, 540, 540, 66, 66, 1080, 540, 1080, 540, 1080, 1080, 540, 1080, 1080, 66, 540, 540, 540, 540, 66, 66, 1080, 66, 1080, 66, 66, 66, 540, 540, 1080, 66, 66, 1080, 66, 1080, 540, 66, 1080, 540, 540, 66, 1080, 1080, 1080, 66, 540, 1080, 66, 1080, 540, 540, 1080, 1080, 66, 540, 1080, 66, 540, 540, 66, 540, 66, 540, 1080, 1080, 540, 66, 1080, 66, 1080, 540, 540, 540, 540, 540, 66, 66, 1080, 66, 1080, 66, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 66, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 66, 66, 66, 66, 66, 540, 66, 66, 540, 1080, 1080, 66, 66, 1080, 66, 66, 66, 540, 66, 540, 1080, 1080, 540, 540, 66, 1080, 540, 1080, 66, 540, 540, 66, 66, 540, 66, 1080, 1080, 66, 1080, 1080, 66, 540, 1080, 66, 66, 540, 540, 66, 66, 1080, 1080, 1080, 1080, 540, 66, 540, 540, 66, 66, 66, 66, 66, 66, 66, 66, 540, 1080, 540, 540, 540, 1080, 66, 540, 540, 1080, 1080, 66, 1080, 1080, 66, 1080, 66, 66, 540, 66, 1080, 1080, 1080, 540, 66, 1080, 1080, 540, 540, 1080, 1080, 66, 1080, 1080, 540, 66, 1080, 540, 540, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 66, 1080, 66, 540, 1080, 66, 540, 540, 540, 540, 66, 540, 66, 540, 540, 66, 1080, 66, 66, 66, 540, 66, 540, 540, 66, 1080, 540, 1080, 66, 1080, 66, 540, 540, 540, 540, 66, 540, 1080, 1080, 66, 1080, 1080, 66, 1080, 540, 1080, 540, 540, 540, 66, 540, 66, 66, 1080, 66, 540, 66, 66, 540, 1080, 540, 1080, 66, 1080, 1080, 540, 1080, 540, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 215808 . Total input tokens: 48083984 . Total output tokens: 43180710
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 17.014821223914623,
    "estimated_duration": 3599.909968651711,
    "input_throughput": 4761.469911543326,
    "output_throughput": 4235.9051011798565,
    "total_throughput": 8997.375012723181,
    "itl": 73.64907044258943,
    "ttft": 243439.65601098398,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3884,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.023441535233621,
    "arrivals": 72240,
    "finished_requests": 69383,
    "scheduler_time": 70.08492115528468
}
#Debug simulation 
Total elapsed time: 17.014919436071068. Arrivals time: 0.18734008632600307 Scheduler time: 16.602294818963856 Scheduler overhead time: 0.07155471062287688 Adapter cache time: 0.052876506466418505 Engine time: 0.06897716224193573 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-8/adapters_384_slots_64_rate_0.1-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-8/adapters_384_slots_64_rate_0.1-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 1080, 540, 33, 1080, 1080, 33, 540, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 33, 1080, 33, 1080, 540, 540, 540, 33, 33, 540, 33, 1080, 33, 1080, 540, 1080, 540, 33, 540, 1080, 540, 1080, 33, 1080, 1080, 1080, 1080, 33, 540, 540, 540, 1080, 540, 33, 540, 33, 1080, 540, 1080, 1080, 540, 1080, 1080, 33, 33, 1080, 540, 540, 33, 33, 33, 540, 33, 540, 33, 1080, 33, 540, 1080, 33, 1080, 540, 33, 1080, 1080, 1080, 1080, 540, 33, 540, 1080, 1080, 540, 33, 33, 1080, 540, 540, 33, 33, 1080, 540, 1080, 540, 1080, 1080, 540, 1080, 1080, 33, 540, 540, 540, 540, 33, 33, 1080, 33, 1080, 33, 33, 33, 540, 540, 1080, 33, 33, 1080, 33, 1080, 540, 33, 1080, 540, 540, 33, 1080, 1080, 1080, 33, 540, 1080, 33, 1080, 540, 540, 1080, 1080, 33, 540, 1080, 33, 540, 540, 33, 540, 33, 540, 1080, 1080, 540, 33, 1080, 33, 1080, 540, 540, 540, 540, 540, 33, 33, 1080, 33, 1080, 33, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 33, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 33, 33, 33, 33, 33, 540, 33, 33, 540, 1080, 1080, 33, 33, 1080, 33, 33, 33, 540, 33, 540, 1080, 1080, 540, 540, 33, 1080, 540, 1080, 33, 540, 540, 33, 33, 540, 33, 1080, 1080, 33, 1080, 1080, 33, 540, 1080, 33, 33, 540, 540, 33, 33, 1080, 1080, 1080, 1080, 540, 33, 540, 540, 33, 33, 33, 33, 33, 33, 33, 33, 540, 1080, 540, 540, 540, 1080, 33, 540, 540, 1080, 1080, 33, 1080, 1080, 33, 1080, 33, 33, 540, 33, 1080, 1080, 1080, 540, 33, 1080, 1080, 540, 540, 1080, 1080, 33, 1080, 1080, 540, 33, 1080, 540, 540, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 33, 1080, 33, 540, 1080, 33, 540, 540, 540, 540, 33, 540, 33, 540, 540, 33, 1080, 33, 33, 33, 540, 33, 540, 540, 33, 1080, 540, 1080, 33, 1080, 33, 540, 540, 540, 540, 33, 540, 1080, 1080, 33, 1080, 1080, 33, 1080, 540, 1080, 540, 540, 540, 33, 540, 33, 33, 1080, 33, 540, 33, 33, 540, 1080, 540, 1080, 33, 1080, 1080, 540, 1080, 540, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 211584 . Total input tokens: 47166834 . Total output tokens: 42349164
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 15.960328111890703,
    "estimated_duration": 3600.0582948912484,
    "input_throughput": 4700.821101706972,
    "output_throughput": 4189.071610701673,
    "total_throughput": 8889.892712408644,
    "itl": 71.89109100561227,
    "ttft": 218198.0684951994,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3824,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.703305132798146,
    "arrivals": 70816,
    "finished_requests": 68334,
    "scheduler_time": 67.63495208101635
}
#Debug simulation 
Total elapsed time: 15.960442118812352. Arrivals time: 0.1840803581289947 Scheduler time: 15.552567216567695 Scheduler overhead time: 0.07190272491425276 Adapter cache time: 0.05141136236488819 Engine time: 0.06851411145180464 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-16/adapters_384_slots_64_rate_0.1-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-16/adapters_384_slots_64_rate_0.1-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 1080, 540, 33, 1080, 1080, 33, 540, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 33, 1080, 33, 1080, 540, 540, 540, 33, 33, 540, 33, 1080, 33, 1080, 540, 1080, 540, 33, 540, 1080, 540, 1080, 33, 1080, 1080, 1080, 1080, 33, 540, 540, 540, 1080, 540, 33, 540, 33, 1080, 540, 1080, 1080, 540, 1080, 1080, 33, 33, 1080, 540, 540, 33, 33, 33, 540, 33, 540, 33, 1080, 33, 540, 1080, 33, 1080, 540, 33, 1080, 1080, 1080, 1080, 540, 33, 540, 1080, 1080, 540, 33, 33, 1080, 540, 540, 33, 33, 1080, 540, 1080, 540, 1080, 1080, 540, 1080, 1080, 33, 540, 540, 540, 540, 33, 33, 1080, 33, 1080, 33, 33, 33, 540, 540, 1080, 33, 33, 1080, 33, 1080, 540, 33, 1080, 540, 540, 33, 1080, 1080, 1080, 33, 540, 1080, 33, 1080, 540, 540, 1080, 1080, 33, 540, 1080, 33, 540, 540, 33, 540, 33, 540, 1080, 1080, 540, 33, 1080, 33, 1080, 540, 540, 540, 540, 540, 33, 33, 1080, 33, 1080, 33, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 33, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 33, 33, 33, 33, 33, 540, 33, 33, 540, 1080, 1080, 33, 33, 1080, 33, 33, 33, 540, 33, 540, 1080, 1080, 540, 540, 33, 1080, 540, 1080, 33, 540, 540, 33, 33, 540, 33, 1080, 1080, 33, 1080, 1080, 33, 540, 1080, 33, 33, 540, 540, 33, 33, 1080, 1080, 1080, 1080, 540, 33, 540, 540, 33, 33, 33, 33, 33, 33, 33, 33, 540, 1080, 540, 540, 540, 1080, 33, 540, 540, 1080, 1080, 33, 1080, 1080, 33, 1080, 33, 33, 540, 33, 1080, 1080, 1080, 540, 33, 1080, 1080, 540, 540, 1080, 1080, 33, 1080, 1080, 540, 33, 1080, 540, 540, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 33, 1080, 33, 540, 1080, 33, 540, 540, 540, 540, 33, 540, 33, 540, 540, 33, 1080, 33, 33, 33, 540, 33, 540, 540, 33, 1080, 540, 1080, 33, 1080, 33, 540, 540, 540, 540, 33, 540, 1080, 1080, 33, 1080, 1080, 33, 1080, 540, 1080, 540, 540, 540, 33, 540, 33, 33, 1080, 33, 540, 33, 33, 540, 1080, 540, 1080, 33, 1080, 1080, 540, 1080, 540, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 211584 . Total input tokens: 47166834 . Total output tokens: 42349164
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 15.865582180209458,
    "estimated_duration": 3600.0306092675487,
    "input_throughput": 4702.043353860266,
    "output_throughput": 4190.348260141384,
    "total_throughput": 8892.39161400165,
    "itl": 71.92447894522839,
    "ttft": 216661.9970809061,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3820,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.468404737052495,
    "arrivals": 70816,
    "finished_requests": 68366,
    "scheduler_time": 67.65711968656352
}
#Debug simulation 
Total elapsed time: 15.865654755849391. Arrivals time: 0.17775405757129192 Scheduler time: 15.463574071414769 Scheduler overhead time: 0.07220334187150002 Adapter cache time: 0.050635109189897776 Engine time: 0.0692631071433425 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-32/adapters_384_slots_64_rate_0.1-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-32/adapters_384_slots_64_rate_0.1-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 1080, 540, 33, 1080, 1080, 33, 540, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 33, 1080, 33, 1080, 540, 540, 540, 33, 33, 540, 33, 1080, 33, 1080, 540, 1080, 540, 33, 540, 1080, 540, 1080, 33, 1080, 1080, 1080, 1080, 33, 540, 540, 540, 1080, 540, 33, 540, 33, 1080, 540, 1080, 1080, 540, 1080, 1080, 33, 33, 1080, 540, 540, 33, 33, 33, 540, 33, 540, 33, 1080, 33, 540, 1080, 33, 1080, 540, 33, 1080, 1080, 1080, 1080, 540, 33, 540, 1080, 1080, 540, 33, 33, 1080, 540, 540, 33, 33, 1080, 540, 1080, 540, 1080, 1080, 540, 1080, 1080, 33, 540, 540, 540, 540, 33, 33, 1080, 33, 1080, 33, 33, 33, 540, 540, 1080, 33, 33, 1080, 33, 1080, 540, 33, 1080, 540, 540, 33, 1080, 1080, 1080, 33, 540, 1080, 33, 1080, 540, 540, 1080, 1080, 33, 540, 1080, 33, 540, 540, 33, 540, 33, 540, 1080, 1080, 540, 33, 1080, 33, 1080, 540, 540, 540, 540, 540, 33, 33, 1080, 33, 1080, 33, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 33, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 33, 33, 33, 33, 33, 540, 33, 33, 540, 1080, 1080, 33, 33, 1080, 33, 33, 33, 540, 33, 540, 1080, 1080, 540, 540, 33, 1080, 540, 1080, 33, 540, 540, 33, 33, 540, 33, 1080, 1080, 33, 1080, 1080, 33, 540, 1080, 33, 33, 540, 540, 33, 33, 1080, 1080, 1080, 1080, 540, 33, 540, 540, 33, 33, 33, 33, 33, 33, 33, 33, 540, 1080, 540, 540, 540, 1080, 33, 540, 540, 1080, 1080, 33, 1080, 1080, 33, 1080, 33, 33, 540, 33, 1080, 1080, 1080, 540, 33, 1080, 1080, 540, 540, 1080, 1080, 33, 1080, 1080, 540, 33, 1080, 540, 540, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 33, 1080, 33, 540, 1080, 33, 540, 540, 540, 540, 33, 540, 33, 540, 540, 33, 1080, 33, 33, 33, 540, 33, 540, 540, 33, 1080, 540, 1080, 33, 1080, 33, 540, 540, 540, 540, 33, 540, 1080, 1080, 33, 1080, 1080, 33, 1080, 540, 1080, 540, 540, 540, 33, 540, 33, 33, 1080, 33, 540, 33, 33, 540, 1080, 540, 1080, 33, 1080, 1080, 540, 1080, 540, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 211584 . Total input tokens: 47166834 . Total output tokens: 42349164
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 15.907641947735101,
    "estimated_duration": 3600.021230431517,
    "input_throughput": 4702.659211254352,
    "output_throughput": 4190.03056773416,
    "total_throughput": 8892.689778988513,
    "itl": 71.98268608656267,
    "ttft": 216257.0530334719,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3826,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.510891928839605,
    "arrivals": 70816,
    "finished_requests": 68377,
    "scheduler_time": 67.67162181208853
}
#Debug simulation 
Total elapsed time: 15.907759017776698. Arrivals time: 0.18713213643059134 Scheduler time: 15.494853225536644 Scheduler overhead time: 0.07298379763960838 Adapter cache time: 0.05104473326355219 Engine time: 0.06959500024095178 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-16/adapters_384_slots_64_rate_0.1-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-16/adapters_384_slots_64_rate_0.1-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 1080, 540, 33, 1080, 1080, 33, 540, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 33, 1080, 33, 1080, 540, 540, 540, 33, 33, 540, 33, 1080, 33, 1080, 540, 1080, 540, 33, 540, 1080, 540, 1080, 33, 1080, 1080, 1080, 1080, 33, 540, 540, 540, 1080, 540, 33, 540, 33, 1080, 540, 1080, 1080, 540, 1080, 1080, 33, 33, 1080, 540, 540, 33, 33, 33, 540, 33, 540, 33, 1080, 33, 540, 1080, 33, 1080, 540, 33, 1080, 1080, 1080, 1080, 540, 33, 540, 1080, 1080, 540, 33, 33, 1080, 540, 540, 33, 33, 1080, 540, 1080, 540, 1080, 1080, 540, 1080, 1080, 33, 540, 540, 540, 540, 33, 33, 1080, 33, 1080, 33, 33, 33, 540, 540, 1080, 33, 33, 1080, 33, 1080, 540, 33, 1080, 540, 540, 33, 1080, 1080, 1080, 33, 540, 1080, 33, 1080, 540, 540, 1080, 1080, 33, 540, 1080, 33, 540, 540, 33, 540, 33, 540, 1080, 1080, 540, 33, 1080, 33, 1080, 540, 540, 540, 540, 540, 33, 33, 1080, 33, 1080, 33, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 33, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 33, 33, 33, 33, 33, 540, 33, 33, 540, 1080, 1080, 33, 33, 1080, 33, 33, 33, 540, 33, 540, 1080, 1080, 540, 540, 33, 1080, 540, 1080, 33, 540, 540, 33, 33, 540, 33, 1080, 1080, 33, 1080, 1080, 33, 540, 1080, 33, 33, 540, 540, 33, 33, 1080, 1080, 1080, 1080, 540, 33, 540, 540, 33, 33, 33, 33, 33, 33, 33, 33, 540, 1080, 540, 540, 540, 1080, 33, 540, 540, 1080, 1080, 33, 1080, 1080, 33, 1080, 33, 33, 540, 33, 1080, 1080, 1080, 540, 33, 1080, 1080, 540, 540, 1080, 1080, 33, 1080, 1080, 540, 33, 1080, 540, 540, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 33, 1080, 33, 540, 1080, 33, 540, 540, 540, 540, 33, 540, 33, 540, 540, 33, 1080, 33, 33, 33, 540, 33, 540, 540, 33, 1080, 540, 1080, 33, 1080, 33, 540, 540, 540, 540, 33, 540, 1080, 1080, 33, 1080, 1080, 33, 1080, 540, 1080, 540, 540, 540, 33, 540, 33, 33, 1080, 33, 540, 33, 33, 540, 1080, 540, 1080, 33, 1080, 1080, 540, 1080, 540, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 211584 . Total input tokens: 47166834 . Total output tokens: 42349164
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 15.887077721301466,
    "estimated_duration": 3600.0436349892548,
    "input_throughput": 4705.1526918646805,
    "output_throughput": 4191.146977596297,
    "total_throughput": 8896.299669460977,
    "itl": 71.97581454634249,
    "ttft": 215163.24681548768,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3825,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.96934207792916,
    "arrivals": 70816,
    "finished_requests": 68396,
    "scheduler_time": 67.66234302879563
}
#Debug simulation 
Total elapsed time: 15.887167497072369. Arrivals time: 0.18536030407994986 Scheduler time: 15.47610180452466 Scheduler overhead time: 0.07233155518770218 Adapter cache time: 0.05168879544362426 Engine time: 0.06966074323281646 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-32/adapters_384_slots_64_rate_0.1-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-32/adapters_384_slots_64_rate_0.1-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 1080, 540, 33, 1080, 1080, 33, 540, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 33, 1080, 33, 1080, 540, 540, 540, 33, 33, 540, 33, 1080, 33, 1080, 540, 1080, 540, 33, 540, 1080, 540, 1080, 33, 1080, 1080, 1080, 1080, 33, 540, 540, 540, 1080, 540, 33, 540, 33, 1080, 540, 1080, 1080, 540, 1080, 1080, 33, 33, 1080, 540, 540, 33, 33, 33, 540, 33, 540, 33, 1080, 33, 540, 1080, 33, 1080, 540, 33, 1080, 1080, 1080, 1080, 540, 33, 540, 1080, 1080, 540, 33, 33, 1080, 540, 540, 33, 33, 1080, 540, 1080, 540, 1080, 1080, 540, 1080, 1080, 33, 540, 540, 540, 540, 33, 33, 1080, 33, 1080, 33, 33, 33, 540, 540, 1080, 33, 33, 1080, 33, 1080, 540, 33, 1080, 540, 540, 33, 1080, 1080, 1080, 33, 540, 1080, 33, 1080, 540, 540, 1080, 1080, 33, 540, 1080, 33, 540, 540, 33, 540, 33, 540, 1080, 1080, 540, 33, 1080, 33, 1080, 540, 540, 540, 540, 540, 33, 33, 1080, 33, 1080, 33, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 33, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 33, 33, 33, 33, 33, 540, 33, 33, 540, 1080, 1080, 33, 33, 1080, 33, 33, 33, 540, 33, 540, 1080, 1080, 540, 540, 33, 1080, 540, 1080, 33, 540, 540, 33, 33, 540, 33, 1080, 1080, 33, 1080, 1080, 33, 540, 1080, 33, 33, 540, 540, 33, 33, 1080, 1080, 1080, 1080, 540, 33, 540, 540, 33, 33, 33, 33, 33, 33, 33, 33, 540, 1080, 540, 540, 540, 1080, 33, 540, 540, 1080, 1080, 33, 1080, 1080, 33, 1080, 33, 33, 540, 33, 1080, 1080, 1080, 540, 33, 1080, 1080, 540, 540, 1080, 1080, 33, 1080, 1080, 540, 33, 1080, 540, 540, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 33, 1080, 33, 540, 1080, 33, 540, 540, 540, 540, 33, 540, 33, 540, 540, 33, 1080, 33, 33, 33, 540, 33, 540, 540, 33, 1080, 540, 1080, 33, 1080, 33, 540, 540, 540, 540, 33, 540, 1080, 1080, 33, 1080, 1080, 33, 1080, 540, 1080, 540, 540, 540, 33, 540, 33, 33, 1080, 33, 540, 33, 33, 540, 1080, 540, 1080, 33, 1080, 1080, 540, 1080, 540, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 211584 . Total input tokens: 47166834 . Total output tokens: 42349164
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 15.75338823813945,
    "estimated_duration": 3600.01696287704,
    "input_throughput": 4705.7300492443865,
    "output_throughput": 4191.140529499595,
    "total_throughput": 8896.870578743981,
    "itl": 71.95188788704769,
    "ttft": 215411.7069371484,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3847,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.739234598334045,
    "arrivals": 70816,
    "finished_requests": 68385,
    "scheduler_time": 67.59877032817919
}
#Debug simulation 
Total elapsed time: 15.753496803808957. Arrivals time: 0.17581753060221672 Scheduler time: 15.355380011256784 Scheduler overhead time: 0.07138017890974879 Adapter cache time: 0.050726049579679966 Engine time: 0.06840897584334016 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-16/adapters_384_slots_64_rate_0.1-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-16/adapters_384_slots_64_rate_0.1-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 1080, 540, 33, 1080, 1080, 33, 540, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 33, 1080, 33, 1080, 540, 540, 540, 33, 33, 540, 33, 1080, 33, 1080, 540, 1080, 540, 33, 540, 1080, 540, 1080, 33, 1080, 1080, 1080, 1080, 33, 540, 540, 540, 1080, 540, 33, 540, 33, 1080, 540, 1080, 1080, 540, 1080, 1080, 33, 33, 1080, 540, 540, 33, 33, 33, 540, 33, 540, 33, 1080, 33, 540, 1080, 33, 1080, 540, 33, 1080, 1080, 1080, 1080, 540, 33, 540, 1080, 1080, 540, 33, 33, 1080, 540, 540, 33, 33, 1080, 540, 1080, 540, 1080, 1080, 540, 1080, 1080, 33, 540, 540, 540, 540, 33, 33, 1080, 33, 1080, 33, 33, 33, 540, 540, 1080, 33, 33, 1080, 33, 1080, 540, 33, 1080, 540, 540, 33, 1080, 1080, 1080, 33, 540, 1080, 33, 1080, 540, 540, 1080, 1080, 33, 540, 1080, 33, 540, 540, 33, 540, 33, 540, 1080, 1080, 540, 33, 1080, 33, 1080, 540, 540, 540, 540, 540, 33, 33, 1080, 33, 1080, 33, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 33, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 33, 33, 33, 33, 33, 540, 33, 33, 540, 1080, 1080, 33, 33, 1080, 33, 33, 33, 540, 33, 540, 1080, 1080, 540, 540, 33, 1080, 540, 1080, 33, 540, 540, 33, 33, 540, 33, 1080, 1080, 33, 1080, 1080, 33, 540, 1080, 33, 33, 540, 540, 33, 33, 1080, 1080, 1080, 1080, 540, 33, 540, 540, 33, 33, 33, 33, 33, 33, 33, 33, 540, 1080, 540, 540, 540, 1080, 33, 540, 540, 1080, 1080, 33, 1080, 1080, 33, 1080, 33, 33, 540, 33, 1080, 1080, 1080, 540, 33, 1080, 1080, 540, 540, 1080, 1080, 33, 1080, 1080, 540, 33, 1080, 540, 540, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 33, 1080, 33, 540, 1080, 33, 540, 540, 540, 540, 33, 540, 33, 540, 540, 33, 1080, 33, 33, 33, 540, 33, 540, 540, 33, 1080, 540, 1080, 33, 1080, 33, 540, 540, 540, 540, 33, 540, 1080, 1080, 33, 1080, 1080, 33, 1080, 540, 1080, 540, 540, 540, 33, 540, 33, 33, 1080, 33, 540, 33, 33, 540, 1080, 540, 1080, 33, 1080, 1080, 540, 1080, 540, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 211584 . Total input tokens: 47166834 . Total output tokens: 42349164
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 15.886036788113415,
    "estimated_duration": 3600.0089418992447,
    "input_throughput": 4702.290820163686,
    "output_throughput": 4190.001814840538,
    "total_throughput": 8892.292635004223,
    "itl": 71.92289095646996,
    "ttft": 216112.7055734754,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3835,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.466842880950502,
    "arrivals": 70816,
    "finished_requests": 68375,
    "scheduler_time": 67.65104828372066
}
#Debug simulation 
Total elapsed time: 15.886162518057972. Arrivals time: 0.18092629732564092 Scheduler time: 15.4810232212767 Scheduler overhead time: 0.07204831717535853 Adapter cache time: 0.050728516187518835 Engine time: 0.06934215454384685 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-32/adapters_384_slots_64_rate_0.1-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-32/adapters_384_slots_64_rate_0.1-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 1080, 540, 33, 1080, 1080, 33, 540, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 33, 1080, 33, 1080, 540, 540, 540, 33, 33, 540, 33, 1080, 33, 1080, 540, 1080, 540, 33, 540, 1080, 540, 1080, 33, 1080, 1080, 1080, 1080, 33, 540, 540, 540, 1080, 540, 33, 540, 33, 1080, 540, 1080, 1080, 540, 1080, 1080, 33, 33, 1080, 540, 540, 33, 33, 33, 540, 33, 540, 33, 1080, 33, 540, 1080, 33, 1080, 540, 33, 1080, 1080, 1080, 1080, 540, 33, 540, 1080, 1080, 540, 33, 33, 1080, 540, 540, 33, 33, 1080, 540, 1080, 540, 1080, 1080, 540, 1080, 1080, 33, 540, 540, 540, 540, 33, 33, 1080, 33, 1080, 33, 33, 33, 540, 540, 1080, 33, 33, 1080, 33, 1080, 540, 33, 1080, 540, 540, 33, 1080, 1080, 1080, 33, 540, 1080, 33, 1080, 540, 540, 1080, 1080, 33, 540, 1080, 33, 540, 540, 33, 540, 33, 540, 1080, 1080, 540, 33, 1080, 33, 1080, 540, 540, 540, 540, 540, 33, 33, 1080, 33, 1080, 33, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 33, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 33, 33, 33, 33, 33, 540, 33, 33, 540, 1080, 1080, 33, 33, 1080, 33, 33, 33, 540, 33, 540, 1080, 1080, 540, 540, 33, 1080, 540, 1080, 33, 540, 540, 33, 33, 540, 33, 1080, 1080, 33, 1080, 1080, 33, 540, 1080, 33, 33, 540, 540, 33, 33, 1080, 1080, 1080, 1080, 540, 33, 540, 540, 33, 33, 33, 33, 33, 33, 33, 33, 540, 1080, 540, 540, 540, 1080, 33, 540, 540, 1080, 1080, 33, 1080, 1080, 33, 1080, 33, 33, 540, 33, 1080, 1080, 1080, 540, 33, 1080, 1080, 540, 540, 1080, 1080, 33, 1080, 1080, 540, 33, 1080, 540, 540, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 33, 1080, 33, 540, 1080, 33, 540, 540, 540, 540, 33, 540, 33, 540, 540, 33, 1080, 33, 33, 33, 540, 33, 540, 540, 33, 1080, 540, 1080, 33, 1080, 33, 540, 540, 540, 540, 33, 540, 1080, 1080, 33, 1080, 1080, 33, 1080, 540, 1080, 540, 540, 540, 33, 540, 33, 33, 1080, 33, 540, 33, 33, 540, 1080, 540, 1080, 33, 1080, 1080, 540, 1080, 540, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 211584 . Total input tokens: 47166834 . Total output tokens: 42349164
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 15.823895697947592,
    "estimated_duration": 3600.0031337650107,
    "input_throughput": 4704.622293560908,
    "output_throughput": 4190.174130271923,
    "total_throughput": 8894.79642383283,
    "itl": 71.96730232699018,
    "ttft": 216218.4534356656,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3845,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.897799280918319,
    "arrivals": 70816,
    "finished_requests": 68371,
    "scheduler_time": 67.61120522649746
}
#Debug simulation 
Total elapsed time: 15.824021585751325. Arrivals time: 0.18466088501736522 Scheduler time: 15.4134804578498 Scheduler overhead time: 0.07262434298172593 Adapter cache time: 0.051077413372695446 Engine time: 0.07000997383147478 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-8/adapters_384_slots_64_rate_0.1-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-8/adapters_384_slots_64_rate_0.1-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 1080, 270, 135, 1080, 1080, 135, 270, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 135, 1080, 135, 1080, 270, 270, 270, 135, 135, 270, 135, 1080, 135, 1080, 270, 1080, 270, 135, 270, 1080, 270, 1080, 135, 1080, 1080, 1080, 1080, 135, 270, 270, 270, 1080, 270, 135, 270, 135, 1080, 270, 1080, 1080, 270, 1080, 1080, 135, 135, 1080, 270, 270, 135, 135, 135, 270, 135, 270, 135, 1080, 135, 270, 1080, 135, 1080, 270, 135, 1080, 1080, 1080, 1080, 270, 135, 270, 1080, 1080, 270, 135, 135, 1080, 270, 270, 135, 135, 1080, 270, 1080, 270, 1080, 1080, 270, 1080, 1080, 135, 270, 270, 270, 270, 135, 135, 1080, 135, 1080, 135, 135, 135, 270, 270, 1080, 135, 135, 1080, 135, 1080, 270, 135, 1080, 270, 270, 135, 1080, 1080, 1080, 135, 270, 1080, 135, 1080, 270, 270, 1080, 1080, 135, 270, 1080, 135, 270, 270, 135, 270, 135, 270, 1080, 1080, 270, 135, 1080, 135, 1080, 270, 270, 270, 270, 270, 135, 135, 1080, 135, 1080, 135, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 135, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 135, 135, 135, 135, 135, 270, 135, 135, 270, 1080, 1080, 135, 135, 1080, 135, 135, 135, 270, 135, 270, 1080, 1080, 270, 270, 135, 1080, 270, 1080, 135, 270, 270, 135, 135, 270, 135, 1080, 1080, 135, 1080, 1080, 135, 270, 1080, 135, 135, 270, 270, 135, 135, 1080, 1080, 1080, 1080, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 1080, 270, 270, 270, 1080, 135, 270, 270, 1080, 1080, 135, 1080, 1080, 135, 1080, 135, 135, 270, 135, 1080, 1080, 1080, 270, 135, 1080, 1080, 270, 270, 1080, 1080, 135, 1080, 1080, 270, 135, 1080, 270, 270, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 135, 1080, 135, 270, 1080, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 1080, 135, 135, 135, 270, 135, 270, 270, 135, 1080, 270, 1080, 135, 1080, 135, 270, 270, 270, 270, 135, 270, 1080, 1080, 135, 1080, 1080, 135, 1080, 270, 1080, 270, 270, 270, 135, 270, 135, 135, 1080, 135, 270, 135, 135, 270, 1080, 270, 1080, 135, 1080, 1080, 270, 1080, 270, 135, 1080, 135, 1080, 1080, 135, 135, 135]
Prompts retrieved: 190080 . Total input tokens: 42435601 . Total output tokens: 38009403
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 12.448162050917745,
    "estimated_duration": 3600.0142217670077,
    "input_throughput": 4289.495554387124,
    "output_throughput": 3783.850329711727,
    "total_throughput": 8073.3458840988515,
    "itl": 61.998642531723775,
    "ttft": 174648.29527398507,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5251,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.07062114338911,
    "arrivals": 63706,
    "finished_requests": 61938,
    "scheduler_time": 57.82414901208809
}
#Debug simulation 
Total elapsed time: 12.448232898954302. Arrivals time: 0.15873021725565195 Scheduler time: 12.037952529266477 Scheduler overhead time: 0.07942180521786213 Adapter cache time: 0.06390024116262794 Engine time: 0.07389506418257952 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-16/adapters_384_slots_64_rate_0.1-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-16/adapters_384_slots_64_rate_0.1-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 1080, 270, 135, 1080, 1080, 135, 270, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 135, 1080, 135, 1080, 270, 270, 270, 135, 135, 270, 135, 1080, 135, 1080, 270, 1080, 270, 135, 270, 1080, 270, 1080, 135, 1080, 1080, 1080, 1080, 135, 270, 270, 270, 1080, 270, 135, 270, 135, 1080, 270, 1080, 1080, 270, 1080, 1080, 135, 135, 1080, 270, 270, 135, 135, 135, 270, 135, 270, 135, 1080, 135, 270, 1080, 135, 1080, 270, 135, 1080, 1080, 1080, 1080, 270, 135, 270, 1080, 1080, 270, 135, 135, 1080, 270, 270, 135, 135, 1080, 270, 1080, 270, 1080, 1080, 270, 1080, 1080, 135, 270, 270, 270, 270, 135, 135, 1080, 135, 1080, 135, 135, 135, 270, 270, 1080, 135, 135, 1080, 135, 1080, 270, 135, 1080, 270, 270, 135, 1080, 1080, 1080, 135, 270, 1080, 135, 1080, 270, 270, 1080, 1080, 135, 270, 1080, 135, 270, 270, 135, 270, 135, 270, 1080, 1080, 270, 135, 1080, 135, 1080, 270, 270, 270, 270, 270, 135, 135, 1080, 135, 1080, 135, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 135, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 135, 135, 135, 135, 135, 270, 135, 135, 270, 1080, 1080, 135, 135, 1080, 135, 135, 135, 270, 135, 270, 1080, 1080, 270, 270, 135, 1080, 270, 1080, 135, 270, 270, 135, 135, 270, 135, 1080, 1080, 135, 1080, 1080, 135, 270, 1080, 135, 135, 270, 270, 135, 135, 1080, 1080, 1080, 1080, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 1080, 270, 270, 270, 1080, 135, 270, 270, 1080, 1080, 135, 1080, 1080, 135, 1080, 135, 135, 270, 135, 1080, 1080, 1080, 270, 135, 1080, 1080, 270, 270, 1080, 1080, 135, 1080, 1080, 270, 135, 1080, 270, 270, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 135, 1080, 135, 270, 1080, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 1080, 135, 135, 135, 270, 135, 270, 270, 135, 1080, 270, 1080, 135, 1080, 135, 270, 270, 270, 270, 135, 270, 1080, 1080, 135, 1080, 1080, 135, 1080, 270, 1080, 270, 270, 270, 135, 270, 135, 135, 1080, 135, 270, 135, 135, 270, 1080, 270, 1080, 135, 1080, 1080, 270, 1080, 270, 135, 1080, 135, 1080, 1080, 135, 135, 135]
Prompts retrieved: 190080 . Total input tokens: 42435601 . Total output tokens: 38009403
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 12.328155970200896,
    "estimated_duration": 3600.0397361608884,
    "input_throughput": 4288.519330751639,
    "output_throughput": 3782.3788063297807,
    "total_throughput": 8070.89813708142,
    "itl": 61.90417890840279,
    "ttft": 175303.2820282954,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5331,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.396191837045485,
    "arrivals": 63706,
    "finished_requests": 61907,
    "scheduler_time": 57.6129761195924
}
#Debug simulation 
Total elapsed time: 12.32827024301514. Arrivals time: 0.162978857755661 Scheduler time: 11.91283943457529 Scheduler overhead time: 0.07928220834583044 Adapter cache time: 0.0647943546064198 Engine time: 0.07400263054296374 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-32/adapters_384_slots_64_rate_0.1-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-32/adapters_384_slots_64_rate_0.1-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 1080, 270, 135, 1080, 1080, 135, 270, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 135, 1080, 135, 1080, 270, 270, 270, 135, 135, 270, 135, 1080, 135, 1080, 270, 1080, 270, 135, 270, 1080, 270, 1080, 135, 1080, 1080, 1080, 1080, 135, 270, 270, 270, 1080, 270, 135, 270, 135, 1080, 270, 1080, 1080, 270, 1080, 1080, 135, 135, 1080, 270, 270, 135, 135, 135, 270, 135, 270, 135, 1080, 135, 270, 1080, 135, 1080, 270, 135, 1080, 1080, 1080, 1080, 270, 135, 270, 1080, 1080, 270, 135, 135, 1080, 270, 270, 135, 135, 1080, 270, 1080, 270, 1080, 1080, 270, 1080, 1080, 135, 270, 270, 270, 270, 135, 135, 1080, 135, 1080, 135, 135, 135, 270, 270, 1080, 135, 135, 1080, 135, 1080, 270, 135, 1080, 270, 270, 135, 1080, 1080, 1080, 135, 270, 1080, 135, 1080, 270, 270, 1080, 1080, 135, 270, 1080, 135, 270, 270, 135, 270, 135, 270, 1080, 1080, 270, 135, 1080, 135, 1080, 270, 270, 270, 270, 270, 135, 135, 1080, 135, 1080, 135, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 135, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 135, 135, 135, 135, 135, 270, 135, 135, 270, 1080, 1080, 135, 135, 1080, 135, 135, 135, 270, 135, 270, 1080, 1080, 270, 270, 135, 1080, 270, 1080, 135, 270, 270, 135, 135, 270, 135, 1080, 1080, 135, 1080, 1080, 135, 270, 1080, 135, 135, 270, 270, 135, 135, 1080, 1080, 1080, 1080, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 1080, 270, 270, 270, 1080, 135, 270, 270, 1080, 1080, 135, 1080, 1080, 135, 1080, 135, 135, 270, 135, 1080, 1080, 1080, 270, 135, 1080, 1080, 270, 270, 1080, 1080, 135, 1080, 1080, 270, 135, 1080, 270, 270, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 135, 1080, 135, 270, 1080, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 1080, 135, 135, 135, 270, 135, 270, 270, 135, 1080, 270, 1080, 135, 1080, 135, 270, 270, 270, 270, 135, 270, 1080, 1080, 135, 1080, 1080, 135, 1080, 270, 1080, 270, 270, 270, 135, 270, 135, 135, 1080, 135, 270, 135, 135, 270, 1080, 270, 1080, 135, 1080, 1080, 270, 1080, 270, 135, 1080, 135, 1080, 1080, 135, 135, 135]
Prompts retrieved: 190080 . Total input tokens: 42435601 . Total output tokens: 38009403
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 12.341680427081883,
    "estimated_duration": 3600.0298039303602,
    "input_throughput": 4285.821740463142,
    "output_throughput": 3781.938689822962,
    "total_throughput": 8067.760430286104,
    "itl": 61.894619841946025,
    "ttft": 176289.3033036143,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5331,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.4266118057992,
    "arrivals": 63706,
    "finished_requests": 61889,
    "scheduler_time": 57.62087275573232
}
#Debug simulation 
Total elapsed time: 12.341746935155243. Arrivals time: 0.15843908255919814 Scheduler time: 11.930159098934382 Scheduler overhead time: 0.07930652378126979 Adapter cache time: 0.06502229208126664 Engine time: 0.0743932188488543 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-16/adapters_384_slots_64_rate_0.1-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-16/adapters_384_slots_64_rate_0.1-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 1080, 270, 135, 1080, 1080, 135, 270, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 135, 1080, 135, 1080, 270, 270, 270, 135, 135, 270, 135, 1080, 135, 1080, 270, 1080, 270, 135, 270, 1080, 270, 1080, 135, 1080, 1080, 1080, 1080, 135, 270, 270, 270, 1080, 270, 135, 270, 135, 1080, 270, 1080, 1080, 270, 1080, 1080, 135, 135, 1080, 270, 270, 135, 135, 135, 270, 135, 270, 135, 1080, 135, 270, 1080, 135, 1080, 270, 135, 1080, 1080, 1080, 1080, 270, 135, 270, 1080, 1080, 270, 135, 135, 1080, 270, 270, 135, 135, 1080, 270, 1080, 270, 1080, 1080, 270, 1080, 1080, 135, 270, 270, 270, 270, 135, 135, 1080, 135, 1080, 135, 135, 135, 270, 270, 1080, 135, 135, 1080, 135, 1080, 270, 135, 1080, 270, 270, 135, 1080, 1080, 1080, 135, 270, 1080, 135, 1080, 270, 270, 1080, 1080, 135, 270, 1080, 135, 270, 270, 135, 270, 135, 270, 1080, 1080, 270, 135, 1080, 135, 1080, 270, 270, 270, 270, 270, 135, 135, 1080, 135, 1080, 135, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 135, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 135, 135, 135, 135, 135, 270, 135, 135, 270, 1080, 1080, 135, 135, 1080, 135, 135, 135, 270, 135, 270, 1080, 1080, 270, 270, 135, 1080, 270, 1080, 135, 270, 270, 135, 135, 270, 135, 1080, 1080, 135, 1080, 1080, 135, 270, 1080, 135, 135, 270, 270, 135, 135, 1080, 1080, 1080, 1080, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 1080, 270, 270, 270, 1080, 135, 270, 270, 1080, 1080, 135, 1080, 1080, 135, 1080, 135, 135, 270, 135, 1080, 1080, 1080, 270, 135, 1080, 1080, 270, 270, 1080, 1080, 135, 1080, 1080, 270, 135, 1080, 270, 270, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 135, 1080, 135, 270, 1080, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 1080, 135, 135, 135, 270, 135, 270, 270, 135, 1080, 270, 1080, 135, 1080, 135, 270, 270, 270, 270, 135, 270, 1080, 1080, 135, 1080, 1080, 135, 1080, 270, 1080, 270, 270, 270, 135, 270, 135, 135, 1080, 135, 270, 135, 135, 270, 1080, 270, 1080, 135, 1080, 1080, 270, 1080, 270, 135, 1080, 135, 1080, 1080, 135, 135, 135]
Prompts retrieved: 190080 . Total input tokens: 42435601 . Total output tokens: 38009403
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 12.403278360143304,
    "estimated_duration": 3600.057798140433,
    "input_throughput": 4290.829721672548,
    "output_throughput": 3785.028953434724,
    "total_throughput": 8075.858675107272,
    "itl": 62.029827168329746,
    "ttft": 173148.52450779776,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5299,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.569124607601054,
    "arrivals": 63706,
    "finished_requests": 61957,
    "scheduler_time": 57.73926898870241
}
#Debug simulation 
Total elapsed time: 12.403384822886437. Arrivals time: 0.16422260785475373 Scheduler time: 11.987305211368948 Scheduler overhead time: 0.0787230022251606 Adapter cache time: 0.06500292336568236 Engine time: 0.07395606162026525 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-32/adapters_384_slots_64_rate_0.1-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-32/adapters_384_slots_64_rate_0.1-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 1080, 270, 135, 1080, 1080, 135, 270, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 135, 1080, 135, 1080, 270, 270, 270, 135, 135, 270, 135, 1080, 135, 1080, 270, 1080, 270, 135, 270, 1080, 270, 1080, 135, 1080, 1080, 1080, 1080, 135, 270, 270, 270, 1080, 270, 135, 270, 135, 1080, 270, 1080, 1080, 270, 1080, 1080, 135, 135, 1080, 270, 270, 135, 135, 135, 270, 135, 270, 135, 1080, 135, 270, 1080, 135, 1080, 270, 135, 1080, 1080, 1080, 1080, 270, 135, 270, 1080, 1080, 270, 135, 135, 1080, 270, 270, 135, 135, 1080, 270, 1080, 270, 1080, 1080, 270, 1080, 1080, 135, 270, 270, 270, 270, 135, 135, 1080, 135, 1080, 135, 135, 135, 270, 270, 1080, 135, 135, 1080, 135, 1080, 270, 135, 1080, 270, 270, 135, 1080, 1080, 1080, 135, 270, 1080, 135, 1080, 270, 270, 1080, 1080, 135, 270, 1080, 135, 270, 270, 135, 270, 135, 270, 1080, 1080, 270, 135, 1080, 135, 1080, 270, 270, 270, 270, 270, 135, 135, 1080, 135, 1080, 135, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 135, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 135, 135, 135, 135, 135, 270, 135, 135, 270, 1080, 1080, 135, 135, 1080, 135, 135, 135, 270, 135, 270, 1080, 1080, 270, 270, 135, 1080, 270, 1080, 135, 270, 270, 135, 135, 270, 135, 1080, 1080, 135, 1080, 1080, 135, 270, 1080, 135, 135, 270, 270, 135, 135, 1080, 1080, 1080, 1080, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 1080, 270, 270, 270, 1080, 135, 270, 270, 1080, 1080, 135, 1080, 1080, 135, 1080, 135, 135, 270, 135, 1080, 1080, 1080, 270, 135, 1080, 1080, 270, 270, 1080, 1080, 135, 1080, 1080, 270, 135, 1080, 270, 270, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 135, 1080, 135, 270, 1080, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 1080, 135, 135, 135, 270, 135, 270, 270, 135, 1080, 270, 1080, 135, 1080, 135, 270, 270, 270, 270, 135, 270, 1080, 1080, 135, 1080, 1080, 135, 1080, 270, 1080, 270, 270, 270, 135, 270, 135, 135, 1080, 135, 270, 135, 135, 270, 1080, 270, 1080, 135, 1080, 1080, 270, 1080, 270, 135, 1080, 135, 1080, 1080, 135, 135, 135]
Prompts retrieved: 190080 . Total input tokens: 42435601 . Total output tokens: 38009403
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 12.437985873781145,
    "estimated_duration": 3600.0575425341626,
    "input_throughput": 4289.44254850156,
    "output_throughput": 3783.115919423046,
    "total_throughput": 8072.558467924606,
    "itl": 61.954362983536335,
    "ttft": 174963.3025267746,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5334,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.662659343479866,
    "arrivals": 63706,
    "finished_requests": 61913,
    "scheduler_time": 57.59917262068188
}
#Debug simulation 
Total elapsed time: 12.438080308027565. Arrivals time: 0.1640023090876639 Scheduler time: 12.020464461762458 Scheduler overhead time: 0.07883933931589127 Adapter cache time: 0.0652709542773664 Engine time: 0.07460096525028348 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-16/adapters_384_slots_64_rate_0.1-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-16/adapters_384_slots_64_rate_0.1-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 1080, 270, 135, 1080, 1080, 135, 270, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 135, 1080, 135, 1080, 270, 270, 270, 135, 135, 270, 135, 1080, 135, 1080, 270, 1080, 270, 135, 270, 1080, 270, 1080, 135, 1080, 1080, 1080, 1080, 135, 270, 270, 270, 1080, 270, 135, 270, 135, 1080, 270, 1080, 1080, 270, 1080, 1080, 135, 135, 1080, 270, 270, 135, 135, 135, 270, 135, 270, 135, 1080, 135, 270, 1080, 135, 1080, 270, 135, 1080, 1080, 1080, 1080, 270, 135, 270, 1080, 1080, 270, 135, 135, 1080, 270, 270, 135, 135, 1080, 270, 1080, 270, 1080, 1080, 270, 1080, 1080, 135, 270, 270, 270, 270, 135, 135, 1080, 135, 1080, 135, 135, 135, 270, 270, 1080, 135, 135, 1080, 135, 1080, 270, 135, 1080, 270, 270, 135, 1080, 1080, 1080, 135, 270, 1080, 135, 1080, 270, 270, 1080, 1080, 135, 270, 1080, 135, 270, 270, 135, 270, 135, 270, 1080, 1080, 270, 135, 1080, 135, 1080, 270, 270, 270, 270, 270, 135, 135, 1080, 135, 1080, 135, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 135, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 135, 135, 135, 135, 135, 270, 135, 135, 270, 1080, 1080, 135, 135, 1080, 135, 135, 135, 270, 135, 270, 1080, 1080, 270, 270, 135, 1080, 270, 1080, 135, 270, 270, 135, 135, 270, 135, 1080, 1080, 135, 1080, 1080, 135, 270, 1080, 135, 135, 270, 270, 135, 135, 1080, 1080, 1080, 1080, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 1080, 270, 270, 270, 1080, 135, 270, 270, 1080, 1080, 135, 1080, 1080, 135, 1080, 135, 135, 270, 135, 1080, 1080, 1080, 270, 135, 1080, 1080, 270, 270, 1080, 1080, 135, 1080, 1080, 270, 135, 1080, 270, 270, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 135, 1080, 135, 270, 1080, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 1080, 135, 135, 135, 270, 135, 270, 270, 135, 1080, 270, 1080, 135, 1080, 135, 270, 270, 270, 270, 135, 270, 1080, 1080, 135, 1080, 1080, 135, 1080, 270, 1080, 270, 270, 270, 135, 270, 135, 135, 1080, 135, 270, 135, 135, 270, 1080, 270, 1080, 135, 1080, 1080, 270, 1080, 270, 135, 1080, 135, 1080, 1080, 135, 135, 135]
Prompts retrieved: 190080 . Total input tokens: 42435601 . Total output tokens: 38009403
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 12.453168511856347,
    "estimated_duration": 3600.0369634378253,
    "input_throughput": 4290.510946657051,
    "output_throughput": 3784.0800353869126,
    "total_throughput": 8074.590982043964,
    "itl": 62.00722328472045,
    "ttft": 174449.72293391483,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5238,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.66188344469935,
    "arrivals": 63706,
    "finished_requests": 61941,
    "scheduler_time": 57.811170044917745
}
#Debug simulation 
Total elapsed time: 12.453317039180547. Arrivals time: 0.1580244437791407 Scheduler time: 12.044135532341897 Scheduler overhead time: 0.07913837488740683 Adapter cache time: 0.06361203594133258 Engine time: 0.07397199794650078 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-32/adapters_384_slots_64_rate_0.1-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-32/adapters_384_slots_64_rate_0.1-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 1080, 270, 135, 1080, 1080, 135, 270, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 135, 1080, 135, 1080, 270, 270, 270, 135, 135, 270, 135, 1080, 135, 1080, 270, 1080, 270, 135, 270, 1080, 270, 1080, 135, 1080, 1080, 1080, 1080, 135, 270, 270, 270, 1080, 270, 135, 270, 135, 1080, 270, 1080, 1080, 270, 1080, 1080, 135, 135, 1080, 270, 270, 135, 135, 135, 270, 135, 270, 135, 1080, 135, 270, 1080, 135, 1080, 270, 135, 1080, 1080, 1080, 1080, 270, 135, 270, 1080, 1080, 270, 135, 135, 1080, 270, 270, 135, 135, 1080, 270, 1080, 270, 1080, 1080, 270, 1080, 1080, 135, 270, 270, 270, 270, 135, 135, 1080, 135, 1080, 135, 135, 135, 270, 270, 1080, 135, 135, 1080, 135, 1080, 270, 135, 1080, 270, 270, 135, 1080, 1080, 1080, 135, 270, 1080, 135, 1080, 270, 270, 1080, 1080, 135, 270, 1080, 135, 270, 270, 135, 270, 135, 270, 1080, 1080, 270, 135, 1080, 135, 1080, 270, 270, 270, 270, 270, 135, 135, 1080, 135, 1080, 135, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 135, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 135, 135, 135, 135, 135, 270, 135, 135, 270, 1080, 1080, 135, 135, 1080, 135, 135, 135, 270, 135, 270, 1080, 1080, 270, 270, 135, 1080, 270, 1080, 135, 270, 270, 135, 135, 270, 135, 1080, 1080, 135, 1080, 1080, 135, 270, 1080, 135, 135, 270, 270, 135, 135, 1080, 1080, 1080, 1080, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 1080, 270, 270, 270, 1080, 135, 270, 270, 1080, 1080, 135, 1080, 1080, 135, 1080, 135, 135, 270, 135, 1080, 1080, 1080, 270, 135, 1080, 1080, 270, 270, 1080, 1080, 135, 1080, 1080, 270, 135, 1080, 270, 270, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 135, 1080, 135, 270, 1080, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 1080, 135, 135, 135, 270, 135, 270, 270, 135, 1080, 270, 1080, 135, 1080, 135, 270, 270, 270, 270, 135, 270, 1080, 1080, 135, 1080, 1080, 135, 1080, 270, 1080, 270, 270, 270, 135, 270, 135, 135, 1080, 135, 270, 135, 135, 270, 1080, 270, 1080, 135, 1080, 1080, 270, 1080, 270, 135, 1080, 135, 1080, 1080, 135, 135, 135]
Prompts retrieved: 190080 . Total input tokens: 42435601 . Total output tokens: 38009403
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 12.271905975881964,
    "estimated_duration": 3600.0100284369255,
    "input_throughput": 4290.312770796941,
    "output_throughput": 3783.2741832426336,
    "total_throughput": 8073.586954039574,
    "itl": 61.94853924329223,
    "ttft": 173264.5721796127,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5348,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.930116377471563,
    "arrivals": 63706,
    "finished_requests": 61947,
    "scheduler_time": 57.67724937640138
}
#Debug simulation 
Total elapsed time: 12.271983209066093. Arrivals time: 0.15957216499373317 Scheduler time: 11.86134745972231 Scheduler overhead time: 0.07874885015189648 Adapter cache time: 0.06457267375662923 Engine time: 0.0736551103182137 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-8/adapters_384_slots_64_rate_0.1-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-8/adapters_384_slots_64_rate_0.1-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 1080, 270, 66, 1080, 1080, 66, 270, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 66, 1080, 66, 1080, 270, 270, 270, 66, 66, 270, 66, 1080, 66, 1080, 270, 1080, 270, 66, 270, 1080, 270, 1080, 66, 1080, 1080, 1080, 1080, 66, 270, 270, 270, 1080, 270, 66, 270, 66, 1080, 270, 1080, 1080, 270, 1080, 1080, 66, 66, 1080, 270, 270, 66, 66, 66, 270, 66, 270, 66, 1080, 66, 270, 1080, 66, 1080, 270, 66, 1080, 1080, 1080, 1080, 270, 66, 270, 1080, 1080, 270, 66, 66, 1080, 270, 270, 66, 66, 1080, 270, 1080, 270, 1080, 1080, 270, 1080, 1080, 66, 270, 270, 270, 270, 66, 66, 1080, 66, 1080, 66, 66, 66, 270, 270, 1080, 66, 66, 1080, 66, 1080, 270, 66, 1080, 270, 270, 66, 1080, 1080, 1080, 66, 270, 1080, 66, 1080, 270, 270, 1080, 1080, 66, 270, 1080, 66, 270, 270, 66, 270, 66, 270, 1080, 1080, 270, 66, 1080, 66, 1080, 270, 270, 270, 270, 270, 66, 66, 1080, 66, 1080, 66, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 66, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 66, 66, 66, 66, 66, 270, 66, 66, 270, 1080, 1080, 66, 66, 1080, 66, 66, 66, 270, 66, 270, 1080, 1080, 270, 270, 66, 1080, 270, 1080, 66, 270, 270, 66, 66, 270, 66, 1080, 1080, 66, 1080, 1080, 66, 270, 1080, 66, 66, 270, 270, 66, 66, 1080, 1080, 1080, 1080, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 1080, 270, 270, 270, 1080, 66, 270, 270, 1080, 1080, 66, 1080, 1080, 66, 1080, 66, 66, 270, 66, 1080, 1080, 1080, 270, 66, 1080, 1080, 270, 270, 1080, 1080, 66, 1080, 1080, 270, 66, 1080, 270, 270, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 66, 1080, 66, 270, 1080, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 1080, 66, 66, 66, 270, 66, 270, 270, 66, 1080, 270, 1080, 66, 1080, 66, 270, 270, 270, 270, 66, 270, 1080, 1080, 66, 1080, 1080, 66, 1080, 270, 1080, 270, 270, 270, 66, 270, 66, 66, 1080, 66, 270, 66, 66, 270, 1080, 270, 1080, 66, 1080, 1080, 270, 1080, 270, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 181248 . Total input tokens: 40496111 . Total output tokens: 36247495
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 10.87708058906719,
    "estimated_duration": 3600.0554341522197,
    "input_throughput": 4105.25595239351,
    "output_throughput": 3648.178268425151,
    "total_throughput": 7753.434220818661,
    "itl": 59.12582120530577,
    "ttft": 138954.12895780453,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5693,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.423356726207828,
    "arrivals": 60894,
    "finished_requests": 59560,
    "scheduler_time": 52.739560691320285
}
#Debug simulation 
Total elapsed time: 10.877195469103754. Arrivals time: 0.1550239622592926 Scheduler time: 10.462373528629541 Scheduler overhead time: 0.08142750384286046 Adapter cache time: 0.06806018622592092 Engine time: 0.07532048458233476 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-16/adapters_384_slots_64_rate_0.1-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-16/adapters_384_slots_64_rate_0.1-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 1080, 270, 66, 1080, 1080, 66, 270, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 66, 1080, 66, 1080, 270, 270, 270, 66, 66, 270, 66, 1080, 66, 1080, 270, 1080, 270, 66, 270, 1080, 270, 1080, 66, 1080, 1080, 1080, 1080, 66, 270, 270, 270, 1080, 270, 66, 270, 66, 1080, 270, 1080, 1080, 270, 1080, 1080, 66, 66, 1080, 270, 270, 66, 66, 66, 270, 66, 270, 66, 1080, 66, 270, 1080, 66, 1080, 270, 66, 1080, 1080, 1080, 1080, 270, 66, 270, 1080, 1080, 270, 66, 66, 1080, 270, 270, 66, 66, 1080, 270, 1080, 270, 1080, 1080, 270, 1080, 1080, 66, 270, 270, 270, 270, 66, 66, 1080, 66, 1080, 66, 66, 66, 270, 270, 1080, 66, 66, 1080, 66, 1080, 270, 66, 1080, 270, 270, 66, 1080, 1080, 1080, 66, 270, 1080, 66, 1080, 270, 270, 1080, 1080, 66, 270, 1080, 66, 270, 270, 66, 270, 66, 270, 1080, 1080, 270, 66, 1080, 66, 1080, 270, 270, 270, 270, 270, 66, 66, 1080, 66, 1080, 66, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 66, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 66, 66, 66, 66, 66, 270, 66, 66, 270, 1080, 1080, 66, 66, 1080, 66, 66, 66, 270, 66, 270, 1080, 1080, 270, 270, 66, 1080, 270, 1080, 66, 270, 270, 66, 66, 270, 66, 1080, 1080, 66, 1080, 1080, 66, 270, 1080, 66, 66, 270, 270, 66, 66, 1080, 1080, 1080, 1080, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 1080, 270, 270, 270, 1080, 66, 270, 270, 1080, 1080, 66, 1080, 1080, 66, 1080, 66, 66, 270, 66, 1080, 1080, 1080, 270, 66, 1080, 1080, 270, 270, 1080, 1080, 66, 1080, 1080, 270, 66, 1080, 270, 270, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 66, 1080, 66, 270, 1080, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 1080, 66, 66, 66, 270, 66, 270, 270, 66, 1080, 270, 1080, 66, 1080, 66, 270, 270, 270, 270, 66, 270, 1080, 1080, 66, 1080, 1080, 66, 1080, 270, 1080, 270, 270, 270, 66, 270, 66, 66, 1080, 66, 270, 66, 66, 270, 1080, 270, 1080, 66, 1080, 1080, 270, 1080, 270, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 181248 . Total input tokens: 40496111 . Total output tokens: 36247495
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 10.80837921006605,
    "estimated_duration": 3600.0601404694253,
    "input_throughput": 4110.734382917924,
    "output_throughput": 3649.469588662718,
    "total_throughput": 7760.203971580642,
    "itl": 59.17987718709472,
    "ttft": 134803.3092806398,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5762,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 18.811568062864314,
    "arrivals": 60894,
    "finished_requests": 59624,
    "scheduler_time": 52.66880873496659
}
#Debug simulation 
Total elapsed time: 10.808459469117224. Arrivals time: 0.15208286000415683 Scheduler time: 10.393877767026424 Scheduler overhead time: 0.08198856888338923 Adapter cache time: 0.06948815751820803 Engine time: 0.07590601220726967 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-32/adapters_384_slots_64_rate_0.1-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-32/adapters_384_slots_64_rate_0.1-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 1080, 270, 66, 1080, 1080, 66, 270, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 66, 1080, 66, 1080, 270, 270, 270, 66, 66, 270, 66, 1080, 66, 1080, 270, 1080, 270, 66, 270, 1080, 270, 1080, 66, 1080, 1080, 1080, 1080, 66, 270, 270, 270, 1080, 270, 66, 270, 66, 1080, 270, 1080, 1080, 270, 1080, 1080, 66, 66, 1080, 270, 270, 66, 66, 66, 270, 66, 270, 66, 1080, 66, 270, 1080, 66, 1080, 270, 66, 1080, 1080, 1080, 1080, 270, 66, 270, 1080, 1080, 270, 66, 66, 1080, 270, 270, 66, 66, 1080, 270, 1080, 270, 1080, 1080, 270, 1080, 1080, 66, 270, 270, 270, 270, 66, 66, 1080, 66, 1080, 66, 66, 66, 270, 270, 1080, 66, 66, 1080, 66, 1080, 270, 66, 1080, 270, 270, 66, 1080, 1080, 1080, 66, 270, 1080, 66, 1080, 270, 270, 1080, 1080, 66, 270, 1080, 66, 270, 270, 66, 270, 66, 270, 1080, 1080, 270, 66, 1080, 66, 1080, 270, 270, 270, 270, 270, 66, 66, 1080, 66, 1080, 66, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 66, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 66, 66, 66, 66, 66, 270, 66, 66, 270, 1080, 1080, 66, 66, 1080, 66, 66, 66, 270, 66, 270, 1080, 1080, 270, 270, 66, 1080, 270, 1080, 66, 270, 270, 66, 66, 270, 66, 1080, 1080, 66, 1080, 1080, 66, 270, 1080, 66, 66, 270, 270, 66, 66, 1080, 1080, 1080, 1080, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 1080, 270, 270, 270, 1080, 66, 270, 270, 1080, 1080, 66, 1080, 1080, 66, 1080, 66, 66, 270, 66, 1080, 1080, 1080, 270, 66, 1080, 1080, 270, 270, 1080, 1080, 66, 1080, 1080, 270, 66, 1080, 270, 270, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 66, 1080, 66, 270, 1080, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 1080, 66, 66, 66, 270, 66, 270, 270, 66, 1080, 270, 1080, 66, 1080, 66, 270, 270, 270, 270, 66, 270, 1080, 1080, 66, 1080, 1080, 66, 1080, 270, 1080, 270, 270, 270, 66, 270, 66, 66, 1080, 66, 270, 66, 66, 270, 1080, 270, 1080, 66, 1080, 1080, 270, 1080, 270, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 181248 . Total input tokens: 40496111 . Total output tokens: 36247495
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 10.73759166104719,
    "estimated_duration": 3600.0281482619753,
    "input_throughput": 4107.673160038828,
    "output_throughput": 3649.2525777451187,
    "total_throughput": 7756.925737783948,
    "itl": 59.149719394677,
    "ttft": 136939.34295518685,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5792,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 18.940628420784183,
    "arrivals": 60894,
    "finished_requests": 59578,
    "scheduler_time": 52.59127475883528
}
#Debug simulation 
Total elapsed time: 10.737718932330608. Arrivals time: 0.1558355293236673 Scheduler time: 10.318046526052058 Scheduler overhead time: 0.08279461041092873 Adapter cache time: 0.06967923091724515 Engine time: 0.07608346221968532 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-16/adapters_384_slots_64_rate_0.1-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-16/adapters_384_slots_64_rate_0.1-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 1080, 270, 66, 1080, 1080, 66, 270, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 66, 1080, 66, 1080, 270, 270, 270, 66, 66, 270, 66, 1080, 66, 1080, 270, 1080, 270, 66, 270, 1080, 270, 1080, 66, 1080, 1080, 1080, 1080, 66, 270, 270, 270, 1080, 270, 66, 270, 66, 1080, 270, 1080, 1080, 270, 1080, 1080, 66, 66, 1080, 270, 270, 66, 66, 66, 270, 66, 270, 66, 1080, 66, 270, 1080, 66, 1080, 270, 66, 1080, 1080, 1080, 1080, 270, 66, 270, 1080, 1080, 270, 66, 66, 1080, 270, 270, 66, 66, 1080, 270, 1080, 270, 1080, 1080, 270, 1080, 1080, 66, 270, 270, 270, 270, 66, 66, 1080, 66, 1080, 66, 66, 66, 270, 270, 1080, 66, 66, 1080, 66, 1080, 270, 66, 1080, 270, 270, 66, 1080, 1080, 1080, 66, 270, 1080, 66, 1080, 270, 270, 1080, 1080, 66, 270, 1080, 66, 270, 270, 66, 270, 66, 270, 1080, 1080, 270, 66, 1080, 66, 1080, 270, 270, 270, 270, 270, 66, 66, 1080, 66, 1080, 66, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 66, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 66, 66, 66, 66, 66, 270, 66, 66, 270, 1080, 1080, 66, 66, 1080, 66, 66, 66, 270, 66, 270, 1080, 1080, 270, 270, 66, 1080, 270, 1080, 66, 270, 270, 66, 66, 270, 66, 1080, 1080, 66, 1080, 1080, 66, 270, 1080, 66, 66, 270, 270, 66, 66, 1080, 1080, 1080, 1080, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 1080, 270, 270, 270, 1080, 66, 270, 270, 1080, 1080, 66, 1080, 1080, 66, 1080, 66, 66, 270, 66, 1080, 1080, 1080, 270, 66, 1080, 1080, 270, 270, 1080, 1080, 66, 1080, 1080, 270, 66, 1080, 270, 270, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 66, 1080, 66, 270, 1080, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 1080, 66, 66, 66, 270, 66, 270, 270, 66, 1080, 270, 1080, 66, 1080, 66, 270, 270, 270, 270, 66, 270, 1080, 1080, 66, 1080, 1080, 66, 1080, 270, 1080, 270, 270, 270, 66, 270, 66, 66, 1080, 66, 270, 66, 66, 270, 1080, 270, 1080, 66, 1080, 1080, 270, 1080, 270, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 181248 . Total input tokens: 40496111 . Total output tokens: 36247495
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 10.865556645672768,
    "estimated_duration": 3600.014323102042,
    "input_throughput": 4107.7942121234255,
    "output_throughput": 3648.726594143519,
    "total_throughput": 7756.520806266944,
    "itl": 59.11662678298533,
    "ttft": 137568.4253376927,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5666,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.72612798232204,
    "arrivals": 60894,
    "finished_requests": 59592,
    "scheduler_time": 52.81618535862364
}
#Debug simulation 
Total elapsed time: 10.865628903731704. Arrivals time: 0.15170020004734397 Scheduler time: 10.452950628008693 Scheduler overhead time: 0.08220937382429838 Adapter cache time: 0.06792093859985471 Engine time: 0.07590290019288659 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-32/adapters_384_slots_64_rate_0.1-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-32/adapters_384_slots_64_rate_0.1-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 1080, 270, 66, 1080, 1080, 66, 270, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 66, 1080, 66, 1080, 270, 270, 270, 66, 66, 270, 66, 1080, 66, 1080, 270, 1080, 270, 66, 270, 1080, 270, 1080, 66, 1080, 1080, 1080, 1080, 66, 270, 270, 270, 1080, 270, 66, 270, 66, 1080, 270, 1080, 1080, 270, 1080, 1080, 66, 66, 1080, 270, 270, 66, 66, 66, 270, 66, 270, 66, 1080, 66, 270, 1080, 66, 1080, 270, 66, 1080, 1080, 1080, 1080, 270, 66, 270, 1080, 1080, 270, 66, 66, 1080, 270, 270, 66, 66, 1080, 270, 1080, 270, 1080, 1080, 270, 1080, 1080, 66, 270, 270, 270, 270, 66, 66, 1080, 66, 1080, 66, 66, 66, 270, 270, 1080, 66, 66, 1080, 66, 1080, 270, 66, 1080, 270, 270, 66, 1080, 1080, 1080, 66, 270, 1080, 66, 1080, 270, 270, 1080, 1080, 66, 270, 1080, 66, 270, 270, 66, 270, 66, 270, 1080, 1080, 270, 66, 1080, 66, 1080, 270, 270, 270, 270, 270, 66, 66, 1080, 66, 1080, 66, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 66, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 66, 66, 66, 66, 66, 270, 66, 66, 270, 1080, 1080, 66, 66, 1080, 66, 66, 66, 270, 66, 270, 1080, 1080, 270, 270, 66, 1080, 270, 1080, 66, 270, 270, 66, 66, 270, 66, 1080, 1080, 66, 1080, 1080, 66, 270, 1080, 66, 66, 270, 270, 66, 66, 1080, 1080, 1080, 1080, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 1080, 270, 270, 270, 1080, 66, 270, 270, 1080, 1080, 66, 1080, 1080, 66, 1080, 66, 66, 270, 66, 1080, 1080, 1080, 270, 66, 1080, 1080, 270, 270, 1080, 1080, 66, 1080, 1080, 270, 66, 1080, 270, 270, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 66, 1080, 66, 270, 1080, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 1080, 66, 66, 66, 270, 66, 270, 270, 66, 1080, 270, 1080, 66, 1080, 66, 270, 270, 270, 270, 66, 270, 1080, 1080, 66, 1080, 1080, 66, 1080, 270, 1080, 270, 270, 270, 66, 270, 66, 66, 1080, 66, 270, 66, 66, 270, 1080, 270, 1080, 66, 1080, 1080, 270, 1080, 270, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 181248 . Total input tokens: 40496111 . Total output tokens: 36247495
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 10.75746962474659,
    "estimated_duration": 3600.0493156999587,
    "input_throughput": 4106.371803166732,
    "output_throughput": 3647.516700044674,
    "total_throughput": 7753.888503211406,
    "itl": 59.13069752270063,
    "ttft": 137814.82143148273,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5746,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.02922982938474,
    "arrivals": 60894,
    "finished_requests": 59575,
    "scheduler_time": 52.68075093748612
}
#Debug simulation 
Total elapsed time: 10.757573738694191. Arrivals time: 0.1560904560610652 Scheduler time: 10.342203724198043 Scheduler overhead time: 0.08121526008471847 Adapter cache time: 0.0686683775857091 Engine time: 0.07457262184470892 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-16/adapters_384_slots_64_rate_0.1-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-16/adapters_384_slots_64_rate_0.1-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 1080, 270, 66, 1080, 1080, 66, 270, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 66, 1080, 66, 1080, 270, 270, 270, 66, 66, 270, 66, 1080, 66, 1080, 270, 1080, 270, 66, 270, 1080, 270, 1080, 66, 1080, 1080, 1080, 1080, 66, 270, 270, 270, 1080, 270, 66, 270, 66, 1080, 270, 1080, 1080, 270, 1080, 1080, 66, 66, 1080, 270, 270, 66, 66, 66, 270, 66, 270, 66, 1080, 66, 270, 1080, 66, 1080, 270, 66, 1080, 1080, 1080, 1080, 270, 66, 270, 1080, 1080, 270, 66, 66, 1080, 270, 270, 66, 66, 1080, 270, 1080, 270, 1080, 1080, 270, 1080, 1080, 66, 270, 270, 270, 270, 66, 66, 1080, 66, 1080, 66, 66, 66, 270, 270, 1080, 66, 66, 1080, 66, 1080, 270, 66, 1080, 270, 270, 66, 1080, 1080, 1080, 66, 270, 1080, 66, 1080, 270, 270, 1080, 1080, 66, 270, 1080, 66, 270, 270, 66, 270, 66, 270, 1080, 1080, 270, 66, 1080, 66, 1080, 270, 270, 270, 270, 270, 66, 66, 1080, 66, 1080, 66, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 66, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 66, 66, 66, 66, 66, 270, 66, 66, 270, 1080, 1080, 66, 66, 1080, 66, 66, 66, 270, 66, 270, 1080, 1080, 270, 270, 66, 1080, 270, 1080, 66, 270, 270, 66, 66, 270, 66, 1080, 1080, 66, 1080, 1080, 66, 270, 1080, 66, 66, 270, 270, 66, 66, 1080, 1080, 1080, 1080, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 1080, 270, 270, 270, 1080, 66, 270, 270, 1080, 1080, 66, 1080, 1080, 66, 1080, 66, 66, 270, 66, 1080, 1080, 1080, 270, 66, 1080, 1080, 270, 270, 1080, 1080, 66, 1080, 1080, 270, 66, 1080, 270, 270, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 66, 1080, 66, 270, 1080, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 1080, 66, 66, 66, 270, 66, 270, 270, 66, 1080, 270, 1080, 66, 1080, 66, 270, 270, 270, 270, 66, 270, 1080, 1080, 66, 1080, 1080, 66, 1080, 270, 1080, 270, 270, 270, 66, 270, 66, 66, 1080, 66, 270, 66, 66, 270, 1080, 270, 1080, 66, 1080, 1080, 270, 1080, 270, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 181248 . Total input tokens: 40496111 . Total output tokens: 36247495
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 10.87010172009468,
    "estimated_duration": 3600.0362899014867,
    "input_throughput": 4108.309141629437,
    "output_throughput": 3648.2682235293255,
    "total_throughput": 7756.577365158762,
    "itl": 59.12956525798069,
    "ttft": 137211.16231296313,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5717,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.094117535957217,
    "arrivals": 60894,
    "finished_requests": 59587,
    "scheduler_time": 52.71037890542509
}
#Debug simulation 
Total elapsed time: 10.870181367732584. Arrivals time: 0.15248315688222647 Scheduler time: 10.456864695064723 Scheduler overhead time: 0.0787552585825324 Adapter cache time: 0.06839061109349132 Engine time: 0.07866841414943337 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-32/adapters_384_slots_64_rate_0.1-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-32/adapters_384_slots_64_rate_0.1-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 1080, 270, 66, 1080, 1080, 66, 270, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 66, 1080, 66, 1080, 270, 270, 270, 66, 66, 270, 66, 1080, 66, 1080, 270, 1080, 270, 66, 270, 1080, 270, 1080, 66, 1080, 1080, 1080, 1080, 66, 270, 270, 270, 1080, 270, 66, 270, 66, 1080, 270, 1080, 1080, 270, 1080, 1080, 66, 66, 1080, 270, 270, 66, 66, 66, 270, 66, 270, 66, 1080, 66, 270, 1080, 66, 1080, 270, 66, 1080, 1080, 1080, 1080, 270, 66, 270, 1080, 1080, 270, 66, 66, 1080, 270, 270, 66, 66, 1080, 270, 1080, 270, 1080, 1080, 270, 1080, 1080, 66, 270, 270, 270, 270, 66, 66, 1080, 66, 1080, 66, 66, 66, 270, 270, 1080, 66, 66, 1080, 66, 1080, 270, 66, 1080, 270, 270, 66, 1080, 1080, 1080, 66, 270, 1080, 66, 1080, 270, 270, 1080, 1080, 66, 270, 1080, 66, 270, 270, 66, 270, 66, 270, 1080, 1080, 270, 66, 1080, 66, 1080, 270, 270, 270, 270, 270, 66, 66, 1080, 66, 1080, 66, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 66, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 66, 66, 66, 66, 66, 270, 66, 66, 270, 1080, 1080, 66, 66, 1080, 66, 66, 66, 270, 66, 270, 1080, 1080, 270, 270, 66, 1080, 270, 1080, 66, 270, 270, 66, 66, 270, 66, 1080, 1080, 66, 1080, 1080, 66, 270, 1080, 66, 66, 270, 270, 66, 66, 1080, 1080, 1080, 1080, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 1080, 270, 270, 270, 1080, 66, 270, 270, 1080, 1080, 66, 1080, 1080, 66, 1080, 66, 66, 270, 66, 1080, 1080, 1080, 270, 66, 1080, 1080, 270, 270, 1080, 1080, 66, 1080, 1080, 270, 66, 1080, 270, 270, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 66, 1080, 66, 270, 1080, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 1080, 66, 66, 66, 270, 66, 270, 270, 66, 1080, 270, 1080, 66, 1080, 66, 270, 270, 270, 270, 66, 270, 1080, 1080, 66, 1080, 1080, 66, 1080, 270, 1080, 270, 270, 270, 66, 270, 66, 66, 1080, 66, 270, 66, 66, 270, 1080, 270, 1080, 66, 1080, 1080, 270, 1080, 270, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 181248 . Total input tokens: 40496111 . Total output tokens: 36247495
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 10.722918847110122,
    "estimated_duration": 3600.0082967938765,
    "input_throughput": 4106.636924466642,
    "output_throughput": 3648.838535094107,
    "total_throughput": 7755.475459560749,
    "itl": 59.18734575540664,
    "ttft": 137638.17048319775,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5765,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.342794134503645,
    "arrivals": 60894,
    "finished_requests": 59568,
    "scheduler_time": 52.615758400551826
}
#Debug simulation 
Total elapsed time: 10.723007967229933. Arrivals time: 0.15080922283232212 Scheduler time: 10.313680194318295 Scheduler overhead time: 0.08074318058788776 Adapter cache time: 0.06844003545120358 Engine time: 0.07468372816219926 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-8/adapters_384_slots_64_rate_0.1-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-8/adapters_384_slots_64_rate_0.1-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 1080, 270, 33, 1080, 1080, 33, 270, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 33, 1080, 33, 1080, 270, 270, 270, 33, 33, 270, 33, 1080, 33, 1080, 270, 1080, 270, 33, 270, 1080, 270, 1080, 33, 1080, 1080, 1080, 1080, 33, 270, 270, 270, 1080, 270, 33, 270, 33, 1080, 270, 1080, 1080, 270, 1080, 1080, 33, 33, 1080, 270, 270, 33, 33, 33, 270, 33, 270, 33, 1080, 33, 270, 1080, 33, 1080, 270, 33, 1080, 1080, 1080, 1080, 270, 33, 270, 1080, 1080, 270, 33, 33, 1080, 270, 270, 33, 33, 1080, 270, 1080, 270, 1080, 1080, 270, 1080, 1080, 33, 270, 270, 270, 270, 33, 33, 1080, 33, 1080, 33, 33, 33, 270, 270, 1080, 33, 33, 1080, 33, 1080, 270, 33, 1080, 270, 270, 33, 1080, 1080, 1080, 33, 270, 1080, 33, 1080, 270, 270, 1080, 1080, 33, 270, 1080, 33, 270, 270, 33, 270, 33, 270, 1080, 1080, 270, 33, 1080, 33, 1080, 270, 270, 270, 270, 270, 33, 33, 1080, 33, 1080, 33, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 33, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 33, 33, 33, 33, 33, 270, 33, 33, 270, 1080, 1080, 33, 33, 1080, 33, 33, 33, 270, 33, 270, 1080, 1080, 270, 270, 33, 1080, 270, 1080, 33, 270, 270, 33, 33, 270, 33, 1080, 1080, 33, 1080, 1080, 33, 270, 1080, 33, 33, 270, 270, 33, 33, 1080, 1080, 1080, 1080, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 1080, 270, 270, 270, 1080, 33, 270, 270, 1080, 1080, 33, 1080, 1080, 33, 1080, 33, 33, 270, 33, 1080, 1080, 1080, 270, 33, 1080, 1080, 270, 270, 1080, 1080, 33, 1080, 1080, 270, 33, 1080, 270, 270, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 33, 1080, 33, 270, 1080, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 1080, 33, 33, 33, 270, 33, 270, 270, 33, 1080, 270, 1080, 33, 1080, 33, 270, 270, 270, 270, 33, 270, 1080, 1080, 33, 1080, 1080, 33, 1080, 270, 1080, 270, 270, 270, 33, 270, 33, 33, 1080, 33, 270, 33, 33, 270, 1080, 270, 1080, 33, 1080, 1080, 270, 1080, 270, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 177024 . Total input tokens: 39529967 . Total output tokens: 35428185
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 9.66158343013376,
    "estimated_duration": 3599.935558206971,
    "input_throughput": 4043.597937972614,
    "output_throughput": 3580.1049189945034,
    "total_throughput": 7623.702856967117,
    "itl": 57.648579996058594,
    "ttft": 113400.75816344829,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5872,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.97118403237197,
    "arrivals": 59412,
    "finished_requests": 58358,
    "scheduler_time": 49.60371099302744
}
#Debug simulation 
Total elapsed time: 9.66166553273797. Arrivals time: 0.15090377815067768 Scheduler time: 9.247504041995853 Scheduler overhead time: 0.08277670340612531 Adapter cache time: 0.06982226204127073 Engine time: 0.0754912868142128 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-16/adapters_384_slots_64_rate_0.1-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-16/adapters_384_slots_64_rate_0.1-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 1080, 270, 33, 1080, 1080, 33, 270, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 33, 1080, 33, 1080, 270, 270, 270, 33, 33, 270, 33, 1080, 33, 1080, 270, 1080, 270, 33, 270, 1080, 270, 1080, 33, 1080, 1080, 1080, 1080, 33, 270, 270, 270, 1080, 270, 33, 270, 33, 1080, 270, 1080, 1080, 270, 1080, 1080, 33, 33, 1080, 270, 270, 33, 33, 33, 270, 33, 270, 33, 1080, 33, 270, 1080, 33, 1080, 270, 33, 1080, 1080, 1080, 1080, 270, 33, 270, 1080, 1080, 270, 33, 33, 1080, 270, 270, 33, 33, 1080, 270, 1080, 270, 1080, 1080, 270, 1080, 1080, 33, 270, 270, 270, 270, 33, 33, 1080, 33, 1080, 33, 33, 33, 270, 270, 1080, 33, 33, 1080, 33, 1080, 270, 33, 1080, 270, 270, 33, 1080, 1080, 1080, 33, 270, 1080, 33, 1080, 270, 270, 1080, 1080, 33, 270, 1080, 33, 270, 270, 33, 270, 33, 270, 1080, 1080, 270, 33, 1080, 33, 1080, 270, 270, 270, 270, 270, 33, 33, 1080, 33, 1080, 33, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 33, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 33, 33, 33, 33, 33, 270, 33, 33, 270, 1080, 1080, 33, 33, 1080, 33, 33, 33, 270, 33, 270, 1080, 1080, 270, 270, 33, 1080, 270, 1080, 33, 270, 270, 33, 33, 270, 33, 1080, 1080, 33, 1080, 1080, 33, 270, 1080, 33, 33, 270, 270, 33, 33, 1080, 1080, 1080, 1080, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 1080, 270, 270, 270, 1080, 33, 270, 270, 1080, 1080, 33, 1080, 1080, 33, 1080, 33, 33, 270, 33, 1080, 1080, 1080, 270, 33, 1080, 1080, 270, 270, 1080, 1080, 33, 1080, 1080, 270, 33, 1080, 270, 270, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 33, 1080, 33, 270, 1080, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 1080, 33, 33, 33, 270, 33, 270, 270, 33, 1080, 270, 1080, 33, 1080, 33, 270, 270, 270, 270, 33, 270, 1080, 1080, 33, 1080, 1080, 33, 1080, 270, 1080, 270, 270, 270, 33, 270, 33, 33, 1080, 33, 270, 33, 33, 270, 1080, 270, 1080, 33, 1080, 1080, 270, 1080, 270, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 177024 . Total input tokens: 39529967 . Total output tokens: 35428185
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 9.693760208785534,
    "estimated_duration": 3599.9199333391953,
    "input_throughput": 4043.2760365585996,
    "output_throughput": 3578.9595987067287,
    "total_throughput": 7622.235635265329,
    "itl": 57.7015018047366,
    "ttft": 113950.00132141136,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5872,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.15640881272261,
    "arrivals": 59412,
    "finished_requests": 58348,
    "scheduler_time": 49.589950329002505
}
#Debug simulation 
Total elapsed time: 9.693846713751554. Arrivals time: 0.14847599575296044 Scheduler time: 9.28164459951222 Scheduler overhead time: 0.0826996834948659 Adapter cache time: 0.07000873750075698 Engine time: 0.07563507184386253 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-32/adapters_384_slots_64_rate_0.1-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-32/adapters_384_slots_64_rate_0.1-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 1080, 270, 33, 1080, 1080, 33, 270, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 33, 1080, 33, 1080, 270, 270, 270, 33, 33, 270, 33, 1080, 33, 1080, 270, 1080, 270, 33, 270, 1080, 270, 1080, 33, 1080, 1080, 1080, 1080, 33, 270, 270, 270, 1080, 270, 33, 270, 33, 1080, 270, 1080, 1080, 270, 1080, 1080, 33, 33, 1080, 270, 270, 33, 33, 33, 270, 33, 270, 33, 1080, 33, 270, 1080, 33, 1080, 270, 33, 1080, 1080, 1080, 1080, 270, 33, 270, 1080, 1080, 270, 33, 33, 1080, 270, 270, 33, 33, 1080, 270, 1080, 270, 1080, 1080, 270, 1080, 1080, 33, 270, 270, 270, 270, 33, 33, 1080, 33, 1080, 33, 33, 33, 270, 270, 1080, 33, 33, 1080, 33, 1080, 270, 33, 1080, 270, 270, 33, 1080, 1080, 1080, 33, 270, 1080, 33, 1080, 270, 270, 1080, 1080, 33, 270, 1080, 33, 270, 270, 33, 270, 33, 270, 1080, 1080, 270, 33, 1080, 33, 1080, 270, 270, 270, 270, 270, 33, 33, 1080, 33, 1080, 33, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 33, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 33, 33, 33, 33, 33, 270, 33, 33, 270, 1080, 1080, 33, 33, 1080, 33, 33, 33, 270, 33, 270, 1080, 1080, 270, 270, 33, 1080, 270, 1080, 33, 270, 270, 33, 33, 270, 33, 1080, 1080, 33, 1080, 1080, 33, 270, 1080, 33, 33, 270, 270, 33, 33, 1080, 1080, 1080, 1080, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 1080, 270, 270, 270, 1080, 33, 270, 270, 1080, 1080, 33, 1080, 1080, 33, 1080, 33, 33, 270, 33, 1080, 1080, 1080, 270, 33, 1080, 1080, 270, 270, 1080, 1080, 33, 1080, 1080, 270, 33, 1080, 270, 270, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 33, 1080, 33, 270, 1080, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 1080, 33, 33, 33, 270, 33, 270, 270, 33, 1080, 270, 1080, 33, 1080, 33, 270, 270, 270, 270, 33, 270, 1080, 1080, 33, 1080, 1080, 33, 1080, 270, 1080, 270, 270, 270, 33, 270, 33, 33, 1080, 33, 270, 33, 33, 270, 1080, 270, 1080, 33, 1080, 1080, 270, 1080, 270, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 177024 . Total input tokens: 39529967 . Total output tokens: 35428185
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 9.646292802877724,
    "estimated_duration": 3599.971360705725,
    "input_throughput": 4042.7185501683966,
    "output_throughput": 3578.6709696141697,
    "total_throughput": 7621.389519782567,
    "itl": 57.69020137065856,
    "ttft": 113974.46199492147,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5876,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.204715191441696,
    "arrivals": 59412,
    "finished_requests": 58347,
    "scheduler_time": 49.57826953877246
}
#Debug simulation 
Total elapsed time: 9.64637363795191. Arrivals time: 0.15105711529031396 Scheduler time: 9.229700492229313 Scheduler overhead time: 0.08228221395984292 Adapter cache time: 0.07014213921502233 Engine time: 0.077932293061167 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-16/adapters_384_slots_64_rate_0.1-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-16/adapters_384_slots_64_rate_0.1-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 1080, 270, 33, 1080, 1080, 33, 270, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 33, 1080, 33, 1080, 270, 270, 270, 33, 33, 270, 33, 1080, 33, 1080, 270, 1080, 270, 33, 270, 1080, 270, 1080, 33, 1080, 1080, 1080, 1080, 33, 270, 270, 270, 1080, 270, 33, 270, 33, 1080, 270, 1080, 1080, 270, 1080, 1080, 33, 33, 1080, 270, 270, 33, 33, 33, 270, 33, 270, 33, 1080, 33, 270, 1080, 33, 1080, 270, 33, 1080, 1080, 1080, 1080, 270, 33, 270, 1080, 1080, 270, 33, 33, 1080, 270, 270, 33, 33, 1080, 270, 1080, 270, 1080, 1080, 270, 1080, 1080, 33, 270, 270, 270, 270, 33, 33, 1080, 33, 1080, 33, 33, 33, 270, 270, 1080, 33, 33, 1080, 33, 1080, 270, 33, 1080, 270, 270, 33, 1080, 1080, 1080, 33, 270, 1080, 33, 1080, 270, 270, 1080, 1080, 33, 270, 1080, 33, 270, 270, 33, 270, 33, 270, 1080, 1080, 270, 33, 1080, 33, 1080, 270, 270, 270, 270, 270, 33, 33, 1080, 33, 1080, 33, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 33, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 33, 33, 33, 33, 33, 270, 33, 33, 270, 1080, 1080, 33, 33, 1080, 33, 33, 33, 270, 33, 270, 1080, 1080, 270, 270, 33, 1080, 270, 1080, 33, 270, 270, 33, 33, 270, 33, 1080, 1080, 33, 1080, 1080, 33, 270, 1080, 33, 33, 270, 270, 33, 33, 1080, 1080, 1080, 1080, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 1080, 270, 270, 270, 1080, 33, 270, 270, 1080, 1080, 33, 1080, 1080, 33, 1080, 33, 33, 270, 33, 1080, 1080, 1080, 270, 33, 1080, 1080, 270, 270, 1080, 1080, 33, 1080, 1080, 270, 33, 1080, 270, 270, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 33, 1080, 33, 270, 1080, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 1080, 33, 33, 33, 270, 33, 270, 270, 33, 1080, 270, 1080, 33, 1080, 33, 270, 270, 270, 270, 33, 270, 1080, 1080, 33, 1080, 1080, 33, 1080, 270, 1080, 270, 270, 270, 33, 270, 33, 33, 1080, 33, 270, 33, 33, 270, 1080, 270, 1080, 33, 1080, 1080, 270, 1080, 270, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 177024 . Total input tokens: 39529967 . Total output tokens: 35428185
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 9.60912463022396,
    "estimated_duration": 3599.916980917804,
    "input_throughput": 4043.0682366150722,
    "output_throughput": 3578.8533647560157,
    "total_throughput": 7621.921601371088,
    "itl": 57.667685826222296,
    "ttft": 114231.7784199432,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5878,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 18.39188907967941,
    "arrivals": 59412,
    "finished_requests": 58343,
    "scheduler_time": 49.57762902335319
}
#Debug simulation 
Total elapsed time: 9.609250649344176. Arrivals time: 0.1508255284279585 Scheduler time: 9.196261140983552 Scheduler overhead time: 0.0824414580129087 Adapter cache time: 0.06972218584269285 Engine time: 0.07506880862638354 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-32/adapters_384_slots_64_rate_0.1-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-32/adapters_384_slots_64_rate_0.1-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 1080, 270, 33, 1080, 1080, 33, 270, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 33, 1080, 33, 1080, 270, 270, 270, 33, 33, 270, 33, 1080, 33, 1080, 270, 1080, 270, 33, 270, 1080, 270, 1080, 33, 1080, 1080, 1080, 1080, 33, 270, 270, 270, 1080, 270, 33, 270, 33, 1080, 270, 1080, 1080, 270, 1080, 1080, 33, 33, 1080, 270, 270, 33, 33, 33, 270, 33, 270, 33, 1080, 33, 270, 1080, 33, 1080, 270, 33, 1080, 1080, 1080, 1080, 270, 33, 270, 1080, 1080, 270, 33, 33, 1080, 270, 270, 33, 33, 1080, 270, 1080, 270, 1080, 1080, 270, 1080, 1080, 33, 270, 270, 270, 270, 33, 33, 1080, 33, 1080, 33, 33, 33, 270, 270, 1080, 33, 33, 1080, 33, 1080, 270, 33, 1080, 270, 270, 33, 1080, 1080, 1080, 33, 270, 1080, 33, 1080, 270, 270, 1080, 1080, 33, 270, 1080, 33, 270, 270, 33, 270, 33, 270, 1080, 1080, 270, 33, 1080, 33, 1080, 270, 270, 270, 270, 270, 33, 33, 1080, 33, 1080, 33, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 33, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 33, 33, 33, 33, 33, 270, 33, 33, 270, 1080, 1080, 33, 33, 1080, 33, 33, 33, 270, 33, 270, 1080, 1080, 270, 270, 33, 1080, 270, 1080, 33, 270, 270, 33, 33, 270, 33, 1080, 1080, 33, 1080, 1080, 33, 270, 1080, 33, 33, 270, 270, 33, 33, 1080, 1080, 1080, 1080, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 1080, 270, 270, 270, 1080, 33, 270, 270, 1080, 1080, 33, 1080, 1080, 33, 1080, 33, 33, 270, 33, 1080, 1080, 1080, 270, 33, 1080, 1080, 270, 270, 1080, 1080, 33, 1080, 1080, 270, 33, 1080, 270, 270, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 33, 1080, 33, 270, 1080, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 1080, 33, 33, 33, 270, 33, 270, 270, 33, 1080, 270, 1080, 33, 1080, 33, 270, 270, 270, 270, 33, 270, 1080, 1080, 33, 1080, 1080, 33, 1080, 270, 1080, 270, 270, 270, 33, 270, 33, 33, 1080, 33, 270, 33, 33, 270, 1080, 270, 1080, 33, 1080, 1080, 270, 1080, 270, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 177024 . Total input tokens: 39529967 . Total output tokens: 35428185
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 9.709777328185737,
    "estimated_duration": 3599.955097925438,
    "input_throughput": 4044.1198859368487,
    "output_throughput": 3579.307421757981,
    "total_throughput": 7623.427307694829,
    "itl": 57.73073558076696,
    "ttft": 112986.83799576513,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5861,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.3973486973893,
    "arrivals": 59412,
    "finished_requests": 58365,
    "scheduler_time": 49.60392008183218
}
#Debug simulation 
Total elapsed time: 9.709851525258273. Arrivals time: 0.14779128693044186 Scheduler time: 9.299003154505044 Scheduler overhead time: 0.0823082197457552 Adapter cache time: 0.06999474810436368 Engine time: 0.07531175157055259 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-16/adapters_384_slots_64_rate_0.1-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-16/adapters_384_slots_64_rate_0.1-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 1080, 270, 33, 1080, 1080, 33, 270, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 33, 1080, 33, 1080, 270, 270, 270, 33, 33, 270, 33, 1080, 33, 1080, 270, 1080, 270, 33, 270, 1080, 270, 1080, 33, 1080, 1080, 1080, 1080, 33, 270, 270, 270, 1080, 270, 33, 270, 33, 1080, 270, 1080, 1080, 270, 1080, 1080, 33, 33, 1080, 270, 270, 33, 33, 33, 270, 33, 270, 33, 1080, 33, 270, 1080, 33, 1080, 270, 33, 1080, 1080, 1080, 1080, 270, 33, 270, 1080, 1080, 270, 33, 33, 1080, 270, 270, 33, 33, 1080, 270, 1080, 270, 1080, 1080, 270, 1080, 1080, 33, 270, 270, 270, 270, 33, 33, 1080, 33, 1080, 33, 33, 33, 270, 270, 1080, 33, 33, 1080, 33, 1080, 270, 33, 1080, 270, 270, 33, 1080, 1080, 1080, 33, 270, 1080, 33, 1080, 270, 270, 1080, 1080, 33, 270, 1080, 33, 270, 270, 33, 270, 33, 270, 1080, 1080, 270, 33, 1080, 33, 1080, 270, 270, 270, 270, 270, 33, 33, 1080, 33, 1080, 33, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 33, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 33, 33, 33, 33, 33, 270, 33, 33, 270, 1080, 1080, 33, 33, 1080, 33, 33, 33, 270, 33, 270, 1080, 1080, 270, 270, 33, 1080, 270, 1080, 33, 270, 270, 33, 33, 270, 33, 1080, 1080, 33, 1080, 1080, 33, 270, 1080, 33, 33, 270, 270, 33, 33, 1080, 1080, 1080, 1080, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 1080, 270, 270, 270, 1080, 33, 270, 270, 1080, 1080, 33, 1080, 1080, 33, 1080, 33, 33, 270, 33, 1080, 1080, 1080, 270, 33, 1080, 1080, 270, 270, 1080, 1080, 33, 1080, 1080, 270, 33, 1080, 270, 270, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 33, 1080, 33, 270, 1080, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 1080, 33, 33, 33, 270, 33, 270, 270, 33, 1080, 270, 1080, 33, 1080, 33, 270, 270, 270, 270, 33, 270, 1080, 1080, 33, 1080, 1080, 33, 1080, 270, 1080, 270, 270, 270, 33, 270, 33, 33, 1080, 33, 270, 33, 33, 270, 1080, 270, 1080, 33, 1080, 1080, 270, 1080, 270, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 177024 . Total input tokens: 39529967 . Total output tokens: 35428185
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 9.598630933091044,
    "estimated_duration": 3599.9405488643906,
    "input_throughput": 4044.0845626165965,
    "output_throughput": 3579.341054414005,
    "total_throughput": 7623.425617030602,
    "itl": 57.66546233773387,
    "ttft": 113450.95439192682,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5901,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.644286790219034,
    "arrivals": 59412,
    "finished_requests": 58353,
    "scheduler_time": 49.549611436349345
}
#Debug simulation 
Total elapsed time: 9.59874485945329. Arrivals time: 0.14889707788825035 Scheduler time: 9.188231891486794 Scheduler overhead time: 0.08221676386892796 Adapter cache time: 0.06992945028468966 Engine time: 0.0745135797187686 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-32/adapters_384_slots_64_rate_0.1-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-32/adapters_384_slots_64_rate_0.1-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 1080, 270, 33, 1080, 1080, 33, 270, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 33, 1080, 33, 1080, 270, 270, 270, 33, 33, 270, 33, 1080, 33, 1080, 270, 1080, 270, 33, 270, 1080, 270, 1080, 33, 1080, 1080, 1080, 1080, 33, 270, 270, 270, 1080, 270, 33, 270, 33, 1080, 270, 1080, 1080, 270, 1080, 1080, 33, 33, 1080, 270, 270, 33, 33, 33, 270, 33, 270, 33, 1080, 33, 270, 1080, 33, 1080, 270, 33, 1080, 1080, 1080, 1080, 270, 33, 270, 1080, 1080, 270, 33, 33, 1080, 270, 270, 33, 33, 1080, 270, 1080, 270, 1080, 1080, 270, 1080, 1080, 33, 270, 270, 270, 270, 33, 33, 1080, 33, 1080, 33, 33, 33, 270, 270, 1080, 33, 33, 1080, 33, 1080, 270, 33, 1080, 270, 270, 33, 1080, 1080, 1080, 33, 270, 1080, 33, 1080, 270, 270, 1080, 1080, 33, 270, 1080, 33, 270, 270, 33, 270, 33, 270, 1080, 1080, 270, 33, 1080, 33, 1080, 270, 270, 270, 270, 270, 33, 33, 1080, 33, 1080, 33, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 33, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 33, 33, 33, 33, 33, 270, 33, 33, 270, 1080, 1080, 33, 33, 1080, 33, 33, 33, 270, 33, 270, 1080, 1080, 270, 270, 33, 1080, 270, 1080, 33, 270, 270, 33, 33, 270, 33, 1080, 1080, 33, 1080, 1080, 33, 270, 1080, 33, 33, 270, 270, 33, 33, 1080, 1080, 1080, 1080, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 1080, 270, 270, 270, 1080, 33, 270, 270, 1080, 1080, 33, 1080, 1080, 33, 1080, 33, 33, 270, 33, 1080, 1080, 1080, 270, 33, 1080, 1080, 270, 270, 1080, 1080, 33, 1080, 1080, 270, 33, 1080, 270, 270, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 33, 1080, 33, 270, 1080, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 1080, 33, 33, 33, 270, 33, 270, 270, 33, 1080, 270, 1080, 33, 1080, 33, 270, 270, 270, 270, 33, 270, 1080, 1080, 33, 1080, 1080, 33, 1080, 270, 1080, 270, 270, 270, 33, 270, 33, 33, 1080, 33, 270, 33, 33, 270, 1080, 270, 1080, 33, 1080, 1080, 270, 1080, 270, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 177024 . Total input tokens: 39529967 . Total output tokens: 35428185
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 9.633269913960248,
    "estimated_duration": 3599.9725653163905,
    "input_throughput": 4041.236075009197,
    "output_throughput": 3577.9503222041835,
    "total_throughput": 7619.186397213381,
    "itl": 57.69126468462299,
    "ttft": 114934.00237455803,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5872,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.685118697433175,
    "arrivals": 59412,
    "finished_requests": 58333,
    "scheduler_time": 49.59903897874406
}
#Debug simulation 
Total elapsed time: 9.633356356993318. Arrivals time: 0.15318095497787 Scheduler time: 9.215979332569987 Scheduler overhead time: 0.08226006710901856 Adapter cache time: 0.06961964583024383 Engine time: 0.07742590550333261 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-8/adapters_384_slots_64_rate_0.1-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-8/adapters_384_slots_64_rate_0.1-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 1080, 135, 66, 1080, 1080, 66, 135, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 1080, 1080, 135, 135, 66, 1080, 66, 1080, 135, 135, 135, 66, 66, 135, 66, 1080, 66, 1080, 135, 1080, 135, 66, 135, 1080, 135, 1080, 66, 1080, 1080, 1080, 1080, 66, 135, 135, 135, 1080, 135, 66, 135, 66, 1080, 135, 1080, 1080, 135, 1080, 1080, 66, 66, 1080, 135, 135, 66, 66, 66, 135, 66, 135, 66, 1080, 66, 135, 1080, 66, 1080, 135, 66, 1080, 1080, 1080, 1080, 135, 66, 135, 1080, 1080, 135, 66, 66, 1080, 135, 135, 66, 66, 1080, 135, 1080, 135, 1080, 1080, 135, 1080, 1080, 66, 135, 135, 135, 135, 66, 66, 1080, 66, 1080, 66, 66, 66, 135, 135, 1080, 66, 66, 1080, 66, 1080, 135, 66, 1080, 135, 135, 66, 1080, 1080, 1080, 66, 135, 1080, 66, 1080, 135, 135, 1080, 1080, 66, 135, 1080, 66, 135, 135, 66, 135, 66, 135, 1080, 1080, 135, 66, 1080, 66, 1080, 135, 135, 135, 135, 135, 66, 66, 1080, 66, 1080, 66, 135, 1080, 135, 1080, 135, 1080, 135, 1080, 66, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 66, 66, 66, 66, 66, 135, 66, 66, 135, 1080, 1080, 66, 66, 1080, 66, 66, 66, 135, 66, 135, 1080, 1080, 135, 135, 66, 1080, 135, 1080, 66, 135, 135, 66, 66, 135, 66, 1080, 1080, 66, 1080, 1080, 66, 135, 1080, 66, 66, 135, 135, 66, 66, 1080, 1080, 1080, 1080, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 1080, 135, 135, 135, 1080, 66, 135, 135, 1080, 1080, 66, 1080, 1080, 66, 1080, 66, 66, 135, 66, 1080, 1080, 1080, 135, 66, 1080, 1080, 135, 135, 1080, 1080, 66, 1080, 1080, 135, 66, 1080, 135, 135, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 66, 1080, 66, 135, 1080, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 1080, 66, 66, 66, 135, 66, 135, 135, 66, 1080, 135, 1080, 66, 1080, 66, 135, 135, 135, 135, 66, 135, 1080, 1080, 66, 1080, 1080, 66, 1080, 135, 1080, 135, 135, 135, 66, 135, 66, 66, 1080, 66, 135, 66, 66, 135, 1080, 135, 1080, 66, 1080, 1080, 135, 1080, 135, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 163968 . Total input tokens: 36634820 . Total output tokens: 32787314
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 8.29792671976611,
    "estimated_duration": 3600.0160616687676,
    "input_throughput": 3762.1162705929432,
    "output_throughput": 3320.819906136286,
    "total_throughput": 7082.936176729229,
    "itl": 53.285390580087544,
    "ttft": 96104.54695832271,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6844,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.945978119475573,
    "arrivals": 55057,
    "finished_requests": 54211,
    "scheduler_time": 43.387972447263095
}
#Debug simulation 
Total elapsed time: 8.2980558690615. Arrivals time: 0.1426137280650437 Scheduler time: 7.875616824254394 Scheduler overhead time: 0.08625715225934982 Adapter cache time: 0.07937902910634875 Engine time: 0.07785109197720885 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-16/adapters_384_slots_64_rate_0.1-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-16/adapters_384_slots_64_rate_0.1-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 1080, 135, 66, 1080, 1080, 66, 135, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 1080, 1080, 135, 135, 66, 1080, 66, 1080, 135, 135, 135, 66, 66, 135, 66, 1080, 66, 1080, 135, 1080, 135, 66, 135, 1080, 135, 1080, 66, 1080, 1080, 1080, 1080, 66, 135, 135, 135, 1080, 135, 66, 135, 66, 1080, 135, 1080, 1080, 135, 1080, 1080, 66, 66, 1080, 135, 135, 66, 66, 66, 135, 66, 135, 66, 1080, 66, 135, 1080, 66, 1080, 135, 66, 1080, 1080, 1080, 1080, 135, 66, 135, 1080, 1080, 135, 66, 66, 1080, 135, 135, 66, 66, 1080, 135, 1080, 135, 1080, 1080, 135, 1080, 1080, 66, 135, 135, 135, 135, 66, 66, 1080, 66, 1080, 66, 66, 66, 135, 135, 1080, 66, 66, 1080, 66, 1080, 135, 66, 1080, 135, 135, 66, 1080, 1080, 1080, 66, 135, 1080, 66, 1080, 135, 135, 1080, 1080, 66, 135, 1080, 66, 135, 135, 66, 135, 66, 135, 1080, 1080, 135, 66, 1080, 66, 1080, 135, 135, 135, 135, 135, 66, 66, 1080, 66, 1080, 66, 135, 1080, 135, 1080, 135, 1080, 135, 1080, 66, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 66, 66, 66, 66, 66, 135, 66, 66, 135, 1080, 1080, 66, 66, 1080, 66, 66, 66, 135, 66, 135, 1080, 1080, 135, 135, 66, 1080, 135, 1080, 66, 135, 135, 66, 66, 135, 66, 1080, 1080, 66, 1080, 1080, 66, 135, 1080, 66, 66, 135, 135, 66, 66, 1080, 1080, 1080, 1080, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 1080, 135, 135, 135, 1080, 66, 135, 135, 1080, 1080, 66, 1080, 1080, 66, 1080, 66, 66, 135, 66, 1080, 1080, 1080, 135, 66, 1080, 1080, 135, 135, 1080, 1080, 66, 1080, 1080, 135, 66, 1080, 135, 135, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 66, 1080, 66, 135, 1080, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 1080, 66, 66, 66, 135, 66, 135, 135, 66, 1080, 135, 1080, 66, 1080, 66, 135, 135, 135, 135, 66, 135, 1080, 1080, 66, 1080, 1080, 66, 1080, 135, 1080, 135, 135, 135, 66, 135, 66, 66, 1080, 66, 135, 66, 66, 135, 1080, 135, 1080, 66, 1080, 1080, 135, 1080, 135, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 163968 . Total input tokens: 36634820 . Total output tokens: 32787314
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 8.16035875910893,
    "estimated_duration": 3600.0250098506053,
    "input_throughput": 3763.4335769690215,
    "output_throughput": 3322.9413593702866,
    "total_throughput": 7086.374936339308,
    "itl": 53.34816849393588,
    "ttft": 92852.08330224245,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6978,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 22.783334573221886,
    "arrivals": 55057,
    "finished_requests": 54241,
    "scheduler_time": 43.20274397680626
}
#Debug simulation 
Total elapsed time: 8.16045536706224. Arrivals time: 0.13870153622701764 Scheduler time: 7.741902727633715 Scheduler overhead time: 0.08630372304469347 Adapter cache time: 0.07986866682767868 Engine time: 0.07720911130309105 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-32/adapters_384_slots_64_rate_0.1-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-32/adapters_384_slots_64_rate_0.1-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 1080, 135, 66, 1080, 1080, 66, 135, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 1080, 1080, 135, 135, 66, 1080, 66, 1080, 135, 135, 135, 66, 66, 135, 66, 1080, 66, 1080, 135, 1080, 135, 66, 135, 1080, 135, 1080, 66, 1080, 1080, 1080, 1080, 66, 135, 135, 135, 1080, 135, 66, 135, 66, 1080, 135, 1080, 1080, 135, 1080, 1080, 66, 66, 1080, 135, 135, 66, 66, 66, 135, 66, 135, 66, 1080, 66, 135, 1080, 66, 1080, 135, 66, 1080, 1080, 1080, 1080, 135, 66, 135, 1080, 1080, 135, 66, 66, 1080, 135, 135, 66, 66, 1080, 135, 1080, 135, 1080, 1080, 135, 1080, 1080, 66, 135, 135, 135, 135, 66, 66, 1080, 66, 1080, 66, 66, 66, 135, 135, 1080, 66, 66, 1080, 66, 1080, 135, 66, 1080, 135, 135, 66, 1080, 1080, 1080, 66, 135, 1080, 66, 1080, 135, 135, 1080, 1080, 66, 135, 1080, 66, 135, 135, 66, 135, 66, 135, 1080, 1080, 135, 66, 1080, 66, 1080, 135, 135, 135, 135, 135, 66, 66, 1080, 66, 1080, 66, 135, 1080, 135, 1080, 135, 1080, 135, 1080, 66, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 66, 66, 66, 66, 66, 135, 66, 66, 135, 1080, 1080, 66, 66, 1080, 66, 66, 66, 135, 66, 135, 1080, 1080, 135, 135, 66, 1080, 135, 1080, 66, 135, 135, 66, 66, 135, 66, 1080, 1080, 66, 1080, 1080, 66, 135, 1080, 66, 66, 135, 135, 66, 66, 1080, 1080, 1080, 1080, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 1080, 135, 135, 135, 1080, 66, 135, 135, 1080, 1080, 66, 1080, 1080, 66, 1080, 66, 66, 135, 66, 1080, 1080, 1080, 135, 66, 1080, 1080, 135, 135, 1080, 1080, 66, 1080, 1080, 135, 66, 1080, 135, 135, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 66, 1080, 66, 135, 1080, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 1080, 66, 66, 66, 135, 66, 135, 135, 66, 1080, 135, 1080, 66, 1080, 66, 135, 135, 135, 135, 66, 135, 1080, 1080, 66, 1080, 1080, 66, 1080, 135, 1080, 135, 135, 135, 66, 135, 66, 66, 1080, 66, 135, 66, 66, 135, 1080, 135, 1080, 66, 1080, 1080, 135, 1080, 135, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 163968 . Total input tokens: 36634820 . Total output tokens: 32787314
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 8.161137148272246,
    "estimated_duration": 3600.042291868873,
    "input_throughput": 3763.798283871254,
    "output_throughput": 3323.349569259944,
    "total_throughput": 7087.147853131198,
    "itl": 53.33742878292528,
    "ttft": 92534.37272103474,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6996,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 22.879881822746153,
    "arrivals": 55057,
    "finished_requests": 54244,
    "scheduler_time": 43.180678522162296
}
#Debug simulation 
Total elapsed time: 8.161238862201571. Arrivals time: 0.13692731224000454 Scheduler time: 7.744355279020965 Scheduler overhead time: 0.08587610069662333 Adapter cache time: 0.08015315048396587 Engine time: 0.07772550219669938 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-16/adapters_384_slots_64_rate_0.1-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-16/adapters_384_slots_64_rate_0.1-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 1080, 135, 66, 1080, 1080, 66, 135, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 1080, 1080, 135, 135, 66, 1080, 66, 1080, 135, 135, 135, 66, 66, 135, 66, 1080, 66, 1080, 135, 1080, 135, 66, 135, 1080, 135, 1080, 66, 1080, 1080, 1080, 1080, 66, 135, 135, 135, 1080, 135, 66, 135, 66, 1080, 135, 1080, 1080, 135, 1080, 1080, 66, 66, 1080, 135, 135, 66, 66, 66, 135, 66, 135, 66, 1080, 66, 135, 1080, 66, 1080, 135, 66, 1080, 1080, 1080, 1080, 135, 66, 135, 1080, 1080, 135, 66, 66, 1080, 135, 135, 66, 66, 1080, 135, 1080, 135, 1080, 1080, 135, 1080, 1080, 66, 135, 135, 135, 135, 66, 66, 1080, 66, 1080, 66, 66, 66, 135, 135, 1080, 66, 66, 1080, 66, 1080, 135, 66, 1080, 135, 135, 66, 1080, 1080, 1080, 66, 135, 1080, 66, 1080, 135, 135, 1080, 1080, 66, 135, 1080, 66, 135, 135, 66, 135, 66, 135, 1080, 1080, 135, 66, 1080, 66, 1080, 135, 135, 135, 135, 135, 66, 66, 1080, 66, 1080, 66, 135, 1080, 135, 1080, 135, 1080, 135, 1080, 66, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 66, 66, 66, 66, 66, 135, 66, 66, 135, 1080, 1080, 66, 66, 1080, 66, 66, 66, 135, 66, 135, 1080, 1080, 135, 135, 66, 1080, 135, 1080, 66, 135, 135, 66, 66, 135, 66, 1080, 1080, 66, 1080, 1080, 66, 135, 1080, 66, 66, 135, 135, 66, 66, 1080, 1080, 1080, 1080, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 1080, 135, 135, 135, 1080, 66, 135, 135, 1080, 1080, 66, 1080, 1080, 66, 1080, 66, 66, 135, 66, 1080, 1080, 1080, 135, 66, 1080, 1080, 135, 135, 1080, 1080, 66, 1080, 1080, 135, 66, 1080, 135, 135, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 66, 1080, 66, 135, 1080, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 1080, 66, 66, 66, 135, 66, 135, 135, 66, 1080, 135, 1080, 66, 1080, 66, 135, 135, 135, 135, 66, 135, 1080, 1080, 66, 1080, 1080, 66, 1080, 135, 1080, 135, 135, 135, 66, 135, 66, 66, 1080, 66, 135, 66, 66, 135, 1080, 135, 1080, 66, 1080, 1080, 135, 1080, 135, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 163968 . Total input tokens: 36634820 . Total output tokens: 32787314
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 8.138098842930049,
    "estimated_duration": 3600.0345278730283,
    "input_throughput": 3763.395293879205,
    "output_throughput": 3322.094804203448,
    "total_throughput": 7085.490098082652,
    "itl": 53.32074117113827,
    "ttft": 92631.50449408784,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7072,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 22.12422147321214,
    "arrivals": 55057,
    "finished_requests": 54235,
    "scheduler_time": 43.085557799840934
}
#Debug simulation 
Total elapsed time: 8.138175575993955. Arrivals time: 0.13910536468029022 Scheduler time: 7.717914973385632 Scheduler overhead time: 0.0859127314761281 Adapter cache time: 0.0810371395200491 Engine time: 0.07786708092316985 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-32/adapters_384_slots_64_rate_0.1-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-32/adapters_384_slots_64_rate_0.1-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 1080, 135, 66, 1080, 1080, 66, 135, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 1080, 1080, 135, 135, 66, 1080, 66, 1080, 135, 135, 135, 66, 66, 135, 66, 1080, 66, 1080, 135, 1080, 135, 66, 135, 1080, 135, 1080, 66, 1080, 1080, 1080, 1080, 66, 135, 135, 135, 1080, 135, 66, 135, 66, 1080, 135, 1080, 1080, 135, 1080, 1080, 66, 66, 1080, 135, 135, 66, 66, 66, 135, 66, 135, 66, 1080, 66, 135, 1080, 66, 1080, 135, 66, 1080, 1080, 1080, 1080, 135, 66, 135, 1080, 1080, 135, 66, 66, 1080, 135, 135, 66, 66, 1080, 135, 1080, 135, 1080, 1080, 135, 1080, 1080, 66, 135, 135, 135, 135, 66, 66, 1080, 66, 1080, 66, 66, 66, 135, 135, 1080, 66, 66, 1080, 66, 1080, 135, 66, 1080, 135, 135, 66, 1080, 1080, 1080, 66, 135, 1080, 66, 1080, 135, 135, 1080, 1080, 66, 135, 1080, 66, 135, 135, 66, 135, 66, 135, 1080, 1080, 135, 66, 1080, 66, 1080, 135, 135, 135, 135, 135, 66, 66, 1080, 66, 1080, 66, 135, 1080, 135, 1080, 135, 1080, 135, 1080, 66, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 66, 66, 66, 66, 66, 135, 66, 66, 135, 1080, 1080, 66, 66, 1080, 66, 66, 66, 135, 66, 135, 1080, 1080, 135, 135, 66, 1080, 135, 1080, 66, 135, 135, 66, 66, 135, 66, 1080, 1080, 66, 1080, 1080, 66, 135, 1080, 66, 66, 135, 135, 66, 66, 1080, 1080, 1080, 1080, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 1080, 135, 135, 135, 1080, 66, 135, 135, 1080, 1080, 66, 1080, 1080, 66, 1080, 66, 66, 135, 66, 1080, 1080, 1080, 135, 66, 1080, 1080, 135, 135, 1080, 1080, 66, 1080, 1080, 135, 66, 1080, 135, 135, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 66, 1080, 66, 135, 1080, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 1080, 66, 66, 66, 135, 66, 135, 135, 66, 1080, 135, 1080, 66, 1080, 66, 135, 135, 135, 135, 66, 135, 1080, 1080, 66, 1080, 1080, 66, 1080, 135, 1080, 135, 135, 135, 66, 135, 66, 66, 1080, 66, 135, 66, 66, 135, 1080, 135, 1080, 66, 1080, 1080, 135, 1080, 135, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 163968 . Total input tokens: 36634820 . Total output tokens: 32787314
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 8.155419529881328,
    "estimated_duration": 3600.0145237303823,
    "input_throughput": 3763.6598160054396,
    "output_throughput": 3322.1204862271557,
    "total_throughput": 7085.780302232595,
    "itl": 53.3327521742531,
    "ttft": 93203.78379712283,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6981,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 23.12483461603429,
    "arrivals": 55057,
    "finished_requests": 54236,
    "scheduler_time": 43.2018749525765
}
#Debug simulation 
Total elapsed time: 8.155530330725014. Arrivals time: 0.13628085888922215 Scheduler time: 7.743914918508381 Scheduler overhead time: 0.08278879895806313 Adapter cache time: 0.07921110140159726 Engine time: 0.0771582662127912 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-16/adapters_384_slots_64_rate_0.1-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-16/adapters_384_slots_64_rate_0.1-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 1080, 135, 66, 1080, 1080, 66, 135, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 1080, 1080, 135, 135, 66, 1080, 66, 1080, 135, 135, 135, 66, 66, 135, 66, 1080, 66, 1080, 135, 1080, 135, 66, 135, 1080, 135, 1080, 66, 1080, 1080, 1080, 1080, 66, 135, 135, 135, 1080, 135, 66, 135, 66, 1080, 135, 1080, 1080, 135, 1080, 1080, 66, 66, 1080, 135, 135, 66, 66, 66, 135, 66, 135, 66, 1080, 66, 135, 1080, 66, 1080, 135, 66, 1080, 1080, 1080, 1080, 135, 66, 135, 1080, 1080, 135, 66, 66, 1080, 135, 135, 66, 66, 1080, 135, 1080, 135, 1080, 1080, 135, 1080, 1080, 66, 135, 135, 135, 135, 66, 66, 1080, 66, 1080, 66, 66, 66, 135, 135, 1080, 66, 66, 1080, 66, 1080, 135, 66, 1080, 135, 135, 66, 1080, 1080, 1080, 66, 135, 1080, 66, 1080, 135, 135, 1080, 1080, 66, 135, 1080, 66, 135, 135, 66, 135, 66, 135, 1080, 1080, 135, 66, 1080, 66, 1080, 135, 135, 135, 135, 135, 66, 66, 1080, 66, 1080, 66, 135, 1080, 135, 1080, 135, 1080, 135, 1080, 66, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 66, 66, 66, 66, 66, 135, 66, 66, 135, 1080, 1080, 66, 66, 1080, 66, 66, 66, 135, 66, 135, 1080, 1080, 135, 135, 66, 1080, 135, 1080, 66, 135, 135, 66, 66, 135, 66, 1080, 1080, 66, 1080, 1080, 66, 135, 1080, 66, 66, 135, 135, 66, 66, 1080, 1080, 1080, 1080, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 1080, 135, 135, 135, 1080, 66, 135, 135, 1080, 1080, 66, 1080, 1080, 66, 1080, 66, 66, 135, 66, 1080, 1080, 1080, 135, 66, 1080, 1080, 135, 135, 1080, 1080, 66, 1080, 1080, 135, 66, 1080, 135, 135, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 66, 1080, 66, 135, 1080, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 1080, 66, 66, 66, 135, 66, 135, 135, 66, 1080, 135, 1080, 66, 1080, 66, 135, 135, 135, 135, 66, 135, 1080, 1080, 66, 1080, 1080, 66, 1080, 135, 1080, 135, 135, 135, 66, 135, 66, 66, 1080, 66, 135, 66, 66, 135, 1080, 135, 1080, 66, 1080, 1080, 135, 1080, 135, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 163968 . Total input tokens: 36634820 . Total output tokens: 32787314
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 8.344063975382596,
    "estimated_duration": 3600.022993699853,
    "input_throughput": 3762.8187441319988,
    "output_throughput": 3321.326564003854,
    "total_throughput": 7084.145308135852,
    "itl": 53.2813959744903,
    "ttft": 95397.54133020733,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6851,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.484834570375156,
    "arrivals": 55057,
    "finished_requests": 54220,
    "scheduler_time": 43.37439917961615
}
#Debug simulation 
Total elapsed time: 8.344144155271351. Arrivals time: 0.14165260503068566 Scheduler time: 7.921647732611746 Scheduler overhead time: 0.08585876552388072 Adapter cache time: 0.07974646426737309 Engine time: 0.07835222780704498 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-32/adapters_384_slots_64_rate_0.1-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-32/adapters_384_slots_64_rate_0.1-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 1080, 135, 66, 1080, 1080, 66, 135, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 1080, 1080, 135, 135, 66, 1080, 66, 1080, 135, 135, 135, 66, 66, 135, 66, 1080, 66, 1080, 135, 1080, 135, 66, 135, 1080, 135, 1080, 66, 1080, 1080, 1080, 1080, 66, 135, 135, 135, 1080, 135, 66, 135, 66, 1080, 135, 1080, 1080, 135, 1080, 1080, 66, 66, 1080, 135, 135, 66, 66, 66, 135, 66, 135, 66, 1080, 66, 135, 1080, 66, 1080, 135, 66, 1080, 1080, 1080, 1080, 135, 66, 135, 1080, 1080, 135, 66, 66, 1080, 135, 135, 66, 66, 1080, 135, 1080, 135, 1080, 1080, 135, 1080, 1080, 66, 135, 135, 135, 135, 66, 66, 1080, 66, 1080, 66, 66, 66, 135, 135, 1080, 66, 66, 1080, 66, 1080, 135, 66, 1080, 135, 135, 66, 1080, 1080, 1080, 66, 135, 1080, 66, 1080, 135, 135, 1080, 1080, 66, 135, 1080, 66, 135, 135, 66, 135, 66, 135, 1080, 1080, 135, 66, 1080, 66, 1080, 135, 135, 135, 135, 135, 66, 66, 1080, 66, 1080, 66, 135, 1080, 135, 1080, 135, 1080, 135, 1080, 66, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 66, 66, 66, 66, 66, 135, 66, 66, 135, 1080, 1080, 66, 66, 1080, 66, 66, 66, 135, 66, 135, 1080, 1080, 135, 135, 66, 1080, 135, 1080, 66, 135, 135, 66, 66, 135, 66, 1080, 1080, 66, 1080, 1080, 66, 135, 1080, 66, 66, 135, 135, 66, 66, 1080, 1080, 1080, 1080, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 1080, 135, 135, 135, 1080, 66, 135, 135, 1080, 1080, 66, 1080, 1080, 66, 1080, 66, 66, 135, 66, 1080, 1080, 1080, 135, 66, 1080, 1080, 135, 135, 1080, 1080, 66, 1080, 1080, 135, 66, 1080, 135, 135, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 66, 1080, 66, 135, 1080, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 1080, 66, 66, 66, 135, 66, 135, 135, 66, 1080, 135, 1080, 66, 1080, 66, 135, 135, 135, 135, 66, 135, 1080, 1080, 66, 1080, 1080, 66, 1080, 135, 1080, 135, 135, 135, 66, 135, 66, 66, 1080, 66, 135, 66, 66, 135, 1080, 135, 1080, 66, 1080, 1080, 135, 1080, 135, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 163968 . Total input tokens: 36634820 . Total output tokens: 32787314
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 8.16351416008547,
    "estimated_duration": 3600.0287401698474,
    "input_throughput": 3764.317725797,
    "output_throughput": 3323.0165266501717,
    "total_throughput": 7087.334252447172,
    "itl": 53.355749267178744,
    "ttft": 91962.9075630452,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7072,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 23.73135540604403,
    "arrivals": 55057,
    "finished_requests": 54247,
    "scheduler_time": 43.11943156750301
}
#Debug simulation 
Total elapsed time: 8.163630719296634. Arrivals time: 0.1421786635182798 Scheduler time: 7.73897563572973 Scheduler overhead time: 0.08662432245910168 Adapter cache time: 0.08116295468062162 Engine time: 0.0781924519687891 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-8/adapters_384_slots_64_rate_0.1-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-8/adapters_384_slots_64_rate_0.1-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 1080, 135, 33, 1080, 1080, 33, 135, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 1080, 1080, 135, 135, 33, 1080, 33, 1080, 135, 135, 135, 33, 33, 135, 33, 1080, 33, 1080, 135, 1080, 135, 33, 135, 1080, 135, 1080, 33, 1080, 1080, 1080, 1080, 33, 135, 135, 135, 1080, 135, 33, 135, 33, 1080, 135, 1080, 1080, 135, 1080, 1080, 33, 33, 1080, 135, 135, 33, 33, 33, 135, 33, 135, 33, 1080, 33, 135, 1080, 33, 1080, 135, 33, 1080, 1080, 1080, 1080, 135, 33, 135, 1080, 1080, 135, 33, 33, 1080, 135, 135, 33, 33, 1080, 135, 1080, 135, 1080, 1080, 135, 1080, 1080, 33, 135, 135, 135, 135, 33, 33, 1080, 33, 1080, 33, 33, 33, 135, 135, 1080, 33, 33, 1080, 33, 1080, 135, 33, 1080, 135, 135, 33, 1080, 1080, 1080, 33, 135, 1080, 33, 1080, 135, 135, 1080, 1080, 33, 135, 1080, 33, 135, 135, 33, 135, 33, 135, 1080, 1080, 135, 33, 1080, 33, 1080, 135, 135, 135, 135, 135, 33, 33, 1080, 33, 1080, 33, 135, 1080, 135, 1080, 135, 1080, 135, 1080, 33, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 33, 33, 33, 33, 33, 135, 33, 33, 135, 1080, 1080, 33, 33, 1080, 33, 33, 33, 135, 33, 135, 1080, 1080, 135, 135, 33, 1080, 135, 1080, 33, 135, 135, 33, 33, 135, 33, 1080, 1080, 33, 1080, 1080, 33, 135, 1080, 33, 33, 135, 135, 33, 33, 1080, 1080, 1080, 1080, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 1080, 135, 135, 135, 1080, 33, 135, 135, 1080, 1080, 33, 1080, 1080, 33, 1080, 33, 33, 135, 33, 1080, 1080, 1080, 135, 33, 1080, 1080, 135, 135, 1080, 1080, 33, 1080, 1080, 135, 33, 1080, 135, 135, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 33, 1080, 33, 135, 1080, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 1080, 33, 33, 33, 135, 33, 135, 135, 33, 1080, 135, 1080, 33, 1080, 33, 135, 135, 135, 135, 33, 135, 1080, 1080, 33, 1080, 1080, 33, 1080, 135, 1080, 135, 135, 135, 33, 135, 33, 33, 1080, 33, 135, 33, 33, 135, 1080, 135, 1080, 33, 1080, 1080, 135, 1080, 135, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 159744 . Total input tokens: 35685722 . Total output tokens: 31942819
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 7.191442869137973,
    "estimated_duration": 3599.9720472193662,
    "input_throughput": 3678.2421714157044,
    "output_throughput": 3219.867778960471,
    "total_throughput": 6898.109950376175,
    "itl": 51.686329094956356,
    "ttft": 75448.69843380305,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7372,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 22.561915648272592,
    "arrivals": 53529,
    "finished_requests": 52849,
    "scheduler_time": 39.63863507033048
}
#Debug simulation 
Total elapsed time: 7.191506465896964. Arrivals time: 0.13400581246241927 Scheduler time: 6.772730581928045 Scheduler overhead time: 0.08514255518093705 Adapter cache time: 0.08350319042801857 Engine time: 0.0790321328677237 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-16/adapters_384_slots_64_rate_0.1-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-16/adapters_384_slots_64_rate_0.1-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 1080, 135, 33, 1080, 1080, 33, 135, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 1080, 1080, 135, 135, 33, 1080, 33, 1080, 135, 135, 135, 33, 33, 135, 33, 1080, 33, 1080, 135, 1080, 135, 33, 135, 1080, 135, 1080, 33, 1080, 1080, 1080, 1080, 33, 135, 135, 135, 1080, 135, 33, 135, 33, 1080, 135, 1080, 1080, 135, 1080, 1080, 33, 33, 1080, 135, 135, 33, 33, 33, 135, 33, 135, 33, 1080, 33, 135, 1080, 33, 1080, 135, 33, 1080, 1080, 1080, 1080, 135, 33, 135, 1080, 1080, 135, 33, 33, 1080, 135, 135, 33, 33, 1080, 135, 1080, 135, 1080, 1080, 135, 1080, 1080, 33, 135, 135, 135, 135, 33, 33, 1080, 33, 1080, 33, 33, 33, 135, 135, 1080, 33, 33, 1080, 33, 1080, 135, 33, 1080, 135, 135, 33, 1080, 1080, 1080, 33, 135, 1080, 33, 1080, 135, 135, 1080, 1080, 33, 135, 1080, 33, 135, 135, 33, 135, 33, 135, 1080, 1080, 135, 33, 1080, 33, 1080, 135, 135, 135, 135, 135, 33, 33, 1080, 33, 1080, 33, 135, 1080, 135, 1080, 135, 1080, 135, 1080, 33, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 33, 33, 33, 33, 33, 135, 33, 33, 135, 1080, 1080, 33, 33, 1080, 33, 33, 33, 135, 33, 135, 1080, 1080, 135, 135, 33, 1080, 135, 1080, 33, 135, 135, 33, 33, 135, 33, 1080, 1080, 33, 1080, 1080, 33, 135, 1080, 33, 33, 135, 135, 33, 33, 1080, 1080, 1080, 1080, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 1080, 135, 135, 135, 1080, 33, 135, 135, 1080, 1080, 33, 1080, 1080, 33, 1080, 33, 33, 135, 33, 1080, 1080, 1080, 135, 33, 1080, 1080, 135, 135, 1080, 1080, 33, 1080, 1080, 135, 33, 1080, 135, 135, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 33, 1080, 33, 135, 1080, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 1080, 33, 33, 33, 135, 33, 135, 135, 33, 1080, 135, 1080, 33, 1080, 33, 135, 135, 135, 135, 33, 135, 1080, 1080, 33, 1080, 1080, 33, 1080, 135, 1080, 135, 135, 135, 33, 135, 33, 33, 1080, 33, 135, 33, 33, 135, 1080, 135, 1080, 33, 1080, 1080, 135, 1080, 135, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 159744 . Total input tokens: 35685722 . Total output tokens: 31942819
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 7.130683180876076,
    "estimated_duration": 3599.969060252332,
    "input_throughput": 3679.6252351878584,
    "output_throughput": 3221.317129649764,
    "total_throughput": 6900.942364837622,
    "itl": 51.73763462288686,
    "ttft": 74813.83369725462,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7372,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.07377810198396,
    "arrivals": 53529,
    "finished_requests": 52857,
    "scheduler_time": 39.63654705009824
}
#Debug simulation 
Total elapsed time: 7.130790752824396. Arrivals time: 0.13552673486992717 Scheduler time: 6.710946569219232 Scheduler overhead time: 0.08482238790020347 Adapter cache time: 0.08351745922118425 Engine time: 0.07891849242150784 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-32/adapters_384_slots_64_rate_0.1-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-32/adapters_384_slots_64_rate_0.1-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 1080, 135, 33, 1080, 1080, 33, 135, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 1080, 1080, 135, 135, 33, 1080, 33, 1080, 135, 135, 135, 33, 33, 135, 33, 1080, 33, 1080, 135, 1080, 135, 33, 135, 1080, 135, 1080, 33, 1080, 1080, 1080, 1080, 33, 135, 135, 135, 1080, 135, 33, 135, 33, 1080, 135, 1080, 1080, 135, 1080, 1080, 33, 33, 1080, 135, 135, 33, 33, 33, 135, 33, 135, 33, 1080, 33, 135, 1080, 33, 1080, 135, 33, 1080, 1080, 1080, 1080, 135, 33, 135, 1080, 1080, 135, 33, 33, 1080, 135, 135, 33, 33, 1080, 135, 1080, 135, 1080, 1080, 135, 1080, 1080, 33, 135, 135, 135, 135, 33, 33, 1080, 33, 1080, 33, 33, 33, 135, 135, 1080, 33, 33, 1080, 33, 1080, 135, 33, 1080, 135, 135, 33, 1080, 1080, 1080, 33, 135, 1080, 33, 1080, 135, 135, 1080, 1080, 33, 135, 1080, 33, 135, 135, 33, 135, 33, 135, 1080, 1080, 135, 33, 1080, 33, 1080, 135, 135, 135, 135, 135, 33, 33, 1080, 33, 1080, 33, 135, 1080, 135, 1080, 135, 1080, 135, 1080, 33, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 33, 33, 33, 33, 33, 135, 33, 33, 135, 1080, 1080, 33, 33, 1080, 33, 33, 33, 135, 33, 135, 1080, 1080, 135, 135, 33, 1080, 135, 1080, 33, 135, 135, 33, 33, 135, 33, 1080, 1080, 33, 1080, 1080, 33, 135, 1080, 33, 33, 135, 135, 33, 33, 1080, 1080, 1080, 1080, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 1080, 135, 135, 135, 1080, 33, 135, 135, 1080, 1080, 33, 1080, 1080, 33, 1080, 33, 33, 135, 33, 1080, 1080, 1080, 135, 33, 1080, 1080, 135, 135, 1080, 1080, 33, 1080, 1080, 135, 33, 1080, 135, 135, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 33, 1080, 33, 135, 1080, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 1080, 33, 33, 33, 135, 33, 135, 135, 33, 1080, 135, 1080, 33, 1080, 33, 135, 135, 135, 135, 33, 135, 1080, 1080, 33, 1080, 1080, 33, 1080, 135, 1080, 135, 135, 135, 33, 135, 33, 33, 1080, 33, 135, 33, 33, 135, 1080, 135, 1080, 33, 1080, 1080, 135, 1080, 135, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 159744 . Total input tokens: 35685722 . Total output tokens: 31942819
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 7.174002083949745,
    "estimated_duration": 3599.9918888801835,
    "input_throughput": 3678.9830112977797,
    "output_throughput": 3220.5358672645257,
    "total_throughput": 6899.518878562306,
    "itl": 51.726551863240196,
    "ttft": 74961.76030406839,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7372,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.11226650595678,
    "arrivals": 53529,
    "finished_requests": 52855,
    "scheduler_time": 39.63974342630765
}
#Debug simulation 
Total elapsed time: 7.174077176954597. Arrivals time: 0.1353572392836213 Scheduler time: 6.7492482382804155 Scheduler overhead time: 0.08692820928990841 Adapter cache time: 0.08386745024472475 Engine time: 0.08144782343879342 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-16/adapters_384_slots_64_rate_0.1-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-16/adapters_384_slots_64_rate_0.1-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 1080, 135, 33, 1080, 1080, 33, 135, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 1080, 1080, 135, 135, 33, 1080, 33, 1080, 135, 135, 135, 33, 33, 135, 33, 1080, 33, 1080, 135, 1080, 135, 33, 135, 1080, 135, 1080, 33, 1080, 1080, 1080, 1080, 33, 135, 135, 135, 1080, 135, 33, 135, 33, 1080, 135, 1080, 1080, 135, 1080, 1080, 33, 33, 1080, 135, 135, 33, 33, 33, 135, 33, 135, 33, 1080, 33, 135, 1080, 33, 1080, 135, 33, 1080, 1080, 1080, 1080, 135, 33, 135, 1080, 1080, 135, 33, 33, 1080, 135, 135, 33, 33, 1080, 135, 1080, 135, 1080, 1080, 135, 1080, 1080, 33, 135, 135, 135, 135, 33, 33, 1080, 33, 1080, 33, 33, 33, 135, 135, 1080, 33, 33, 1080, 33, 1080, 135, 33, 1080, 135, 135, 33, 1080, 1080, 1080, 33, 135, 1080, 33, 1080, 135, 135, 1080, 1080, 33, 135, 1080, 33, 135, 135, 33, 135, 33, 135, 1080, 1080, 135, 33, 1080, 33, 1080, 135, 135, 135, 135, 135, 33, 33, 1080, 33, 1080, 33, 135, 1080, 135, 1080, 135, 1080, 135, 1080, 33, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 33, 33, 33, 33, 33, 135, 33, 33, 135, 1080, 1080, 33, 33, 1080, 33, 33, 33, 135, 33, 135, 1080, 1080, 135, 135, 33, 1080, 135, 1080, 33, 135, 135, 33, 33, 135, 33, 1080, 1080, 33, 1080, 1080, 33, 135, 1080, 33, 33, 135, 135, 33, 33, 1080, 1080, 1080, 1080, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 1080, 135, 135, 135, 1080, 33, 135, 135, 1080, 1080, 33, 1080, 1080, 33, 1080, 33, 33, 135, 33, 1080, 1080, 1080, 135, 33, 1080, 1080, 135, 135, 1080, 1080, 33, 1080, 1080, 135, 33, 1080, 135, 135, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 33, 1080, 33, 135, 1080, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 1080, 33, 33, 33, 135, 33, 135, 135, 33, 1080, 135, 1080, 33, 1080, 33, 135, 135, 135, 135, 33, 135, 1080, 1080, 33, 1080, 1080, 33, 1080, 135, 1080, 135, 135, 135, 33, 135, 33, 33, 1080, 33, 135, 33, 33, 135, 1080, 135, 1080, 33, 1080, 1080, 135, 1080, 135, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 159744 . Total input tokens: 35685722 . Total output tokens: 31942819
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 7.164529542904347,
    "estimated_duration": 3599.990992969518,
    "input_throughput": 3679.0697604148545,
    "output_throughput": 3220.6733357508074,
    "total_throughput": 6899.743096165662,
    "itl": 51.710253826109124,
    "ttft": 74995.42046885776,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7368,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 23.079963350593008,
    "arrivals": 53529,
    "finished_requests": 52855,
    "scheduler_time": 39.63844155506398
}
#Debug simulation 
Total elapsed time: 7.164637289941311. Arrivals time: 0.1364700049161911 Scheduler time: 6.7416612496599555 Scheduler overhead time: 0.08638481190428138 Adapter cache time: 0.08362256968393922 Engine time: 0.07929517887532711 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-32/adapters_384_slots_64_rate_0.1-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-32/adapters_384_slots_64_rate_0.1-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 1080, 135, 33, 1080, 1080, 33, 135, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 1080, 1080, 135, 135, 33, 1080, 33, 1080, 135, 135, 135, 33, 33, 135, 33, 1080, 33, 1080, 135, 1080, 135, 33, 135, 1080, 135, 1080, 33, 1080, 1080, 1080, 1080, 33, 135, 135, 135, 1080, 135, 33, 135, 33, 1080, 135, 1080, 1080, 135, 1080, 1080, 33, 33, 1080, 135, 135, 33, 33, 33, 135, 33, 135, 33, 1080, 33, 135, 1080, 33, 1080, 135, 33, 1080, 1080, 1080, 1080, 135, 33, 135, 1080, 1080, 135, 33, 33, 1080, 135, 135, 33, 33, 1080, 135, 1080, 135, 1080, 1080, 135, 1080, 1080, 33, 135, 135, 135, 135, 33, 33, 1080, 33, 1080, 33, 33, 33, 135, 135, 1080, 33, 33, 1080, 33, 1080, 135, 33, 1080, 135, 135, 33, 1080, 1080, 1080, 33, 135, 1080, 33, 1080, 135, 135, 1080, 1080, 33, 135, 1080, 33, 135, 135, 33, 135, 33, 135, 1080, 1080, 135, 33, 1080, 33, 1080, 135, 135, 135, 135, 135, 33, 33, 1080, 33, 1080, 33, 135, 1080, 135, 1080, 135, 1080, 135, 1080, 33, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 33, 33, 33, 33, 33, 135, 33, 33, 135, 1080, 1080, 33, 33, 1080, 33, 33, 33, 135, 33, 135, 1080, 1080, 135, 135, 33, 1080, 135, 1080, 33, 135, 135, 33, 33, 135, 33, 1080, 1080, 33, 1080, 1080, 33, 135, 1080, 33, 33, 135, 135, 33, 33, 1080, 1080, 1080, 1080, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 1080, 135, 135, 135, 1080, 33, 135, 135, 1080, 1080, 33, 1080, 1080, 33, 1080, 33, 33, 135, 33, 1080, 1080, 1080, 135, 33, 1080, 1080, 135, 135, 1080, 1080, 33, 1080, 1080, 135, 33, 1080, 135, 135, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 33, 1080, 33, 135, 1080, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 1080, 33, 33, 33, 135, 33, 135, 135, 33, 1080, 135, 1080, 33, 1080, 33, 135, 135, 135, 135, 33, 135, 1080, 1080, 33, 1080, 1080, 33, 1080, 135, 1080, 135, 135, 135, 33, 135, 33, 33, 1080, 33, 135, 33, 33, 135, 1080, 135, 1080, 33, 1080, 1080, 135, 1080, 135, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 159744 . Total input tokens: 35685722 . Total output tokens: 31942819
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 7.174163470044732,
    "estimated_duration": 3599.9960290418207,
    "input_throughput": 3677.701001110242,
    "output_throughput": 3220.0118851479256,
    "total_throughput": 6897.712886258168,
    "itl": 51.72562763129731,
    "ttft": 75766.35545079583,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7330,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.27424978226336,
    "arrivals": 53529,
    "finished_requests": 52845,
    "scheduler_time": 39.65532785198934
}
#Debug simulation 
Total elapsed time: 7.174246585927904. Arrivals time: 0.13660159800201654 Scheduler time: 6.750169710721821 Scheduler overhead time: 0.08683982864022255 Adapter cache time: 0.08349593309685588 Engine time: 0.07990355510264635 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-16/adapters_384_slots_64_rate_0.1-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-16/adapters_384_slots_64_rate_0.1-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 1080, 135, 33, 1080, 1080, 33, 135, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 1080, 1080, 135, 135, 33, 1080, 33, 1080, 135, 135, 135, 33, 33, 135, 33, 1080, 33, 1080, 135, 1080, 135, 33, 135, 1080, 135, 1080, 33, 1080, 1080, 1080, 1080, 33, 135, 135, 135, 1080, 135, 33, 135, 33, 1080, 135, 1080, 1080, 135, 1080, 1080, 33, 33, 1080, 135, 135, 33, 33, 33, 135, 33, 135, 33, 1080, 33, 135, 1080, 33, 1080, 135, 33, 1080, 1080, 1080, 1080, 135, 33, 135, 1080, 1080, 135, 33, 33, 1080, 135, 135, 33, 33, 1080, 135, 1080, 135, 1080, 1080, 135, 1080, 1080, 33, 135, 135, 135, 135, 33, 33, 1080, 33, 1080, 33, 33, 33, 135, 135, 1080, 33, 33, 1080, 33, 1080, 135, 33, 1080, 135, 135, 33, 1080, 1080, 1080, 33, 135, 1080, 33, 1080, 135, 135, 1080, 1080, 33, 135, 1080, 33, 135, 135, 33, 135, 33, 135, 1080, 1080, 135, 33, 1080, 33, 1080, 135, 135, 135, 135, 135, 33, 33, 1080, 33, 1080, 33, 135, 1080, 135, 1080, 135, 1080, 135, 1080, 33, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 33, 33, 33, 33, 33, 135, 33, 33, 135, 1080, 1080, 33, 33, 1080, 33, 33, 33, 135, 33, 135, 1080, 1080, 135, 135, 33, 1080, 135, 1080, 33, 135, 135, 33, 33, 135, 33, 1080, 1080, 33, 1080, 1080, 33, 135, 1080, 33, 33, 135, 135, 33, 33, 1080, 1080, 1080, 1080, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 1080, 135, 135, 135, 1080, 33, 135, 135, 1080, 1080, 33, 1080, 1080, 33, 1080, 33, 33, 135, 33, 1080, 1080, 1080, 135, 33, 1080, 1080, 135, 135, 1080, 1080, 33, 1080, 1080, 135, 33, 1080, 135, 135, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 33, 1080, 33, 135, 1080, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 1080, 33, 33, 33, 135, 33, 135, 135, 33, 1080, 135, 1080, 33, 1080, 33, 135, 135, 135, 135, 33, 135, 1080, 1080, 33, 1080, 1080, 33, 1080, 135, 1080, 135, 135, 135, 33, 135, 33, 33, 1080, 33, 135, 33, 33, 135, 1080, 135, 1080, 33, 1080, 1080, 135, 1080, 135, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 159744 . Total input tokens: 35685722 . Total output tokens: 31942819
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 7.1179645182564855,
    "estimated_duration": 3600.0001165691147,
    "input_throughput": 3678.4621031124802,
    "output_throughput": 3220.3368401689404,
    "total_throughput": 6898.798943281421,
    "itl": 51.65942756118296,
    "ttft": 75304.46297987216,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7360,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 22.006770170479857,
    "arrivals": 53529,
    "finished_requests": 52852,
    "scheduler_time": 39.65737716503233
}
#Debug simulation 
Total elapsed time: 7.118060002103448. Arrivals time: 0.13327499385923147 Scheduler time: 6.702165094669908 Scheduler overhead time: 0.08520048577338457 Adapter cache time: 0.08238644152879715 Engine time: 0.07807013299316168 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-32/adapters_384_slots_64_rate_0.1-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-32/adapters_384_slots_64_rate_0.1-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 1080, 135, 33, 1080, 1080, 33, 135, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 1080, 1080, 135, 135, 33, 1080, 33, 1080, 135, 135, 135, 33, 33, 135, 33, 1080, 33, 1080, 135, 1080, 135, 33, 135, 1080, 135, 1080, 33, 1080, 1080, 1080, 1080, 33, 135, 135, 135, 1080, 135, 33, 135, 33, 1080, 135, 1080, 1080, 135, 1080, 1080, 33, 33, 1080, 135, 135, 33, 33, 33, 135, 33, 135, 33, 1080, 33, 135, 1080, 33, 1080, 135, 33, 1080, 1080, 1080, 1080, 135, 33, 135, 1080, 1080, 135, 33, 33, 1080, 135, 135, 33, 33, 1080, 135, 1080, 135, 1080, 1080, 135, 1080, 1080, 33, 135, 135, 135, 135, 33, 33, 1080, 33, 1080, 33, 33, 33, 135, 135, 1080, 33, 33, 1080, 33, 1080, 135, 33, 1080, 135, 135, 33, 1080, 1080, 1080, 33, 135, 1080, 33, 1080, 135, 135, 1080, 1080, 33, 135, 1080, 33, 135, 135, 33, 135, 33, 135, 1080, 1080, 135, 33, 1080, 33, 1080, 135, 135, 135, 135, 135, 33, 33, 1080, 33, 1080, 33, 135, 1080, 135, 1080, 135, 1080, 135, 1080, 33, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 33, 33, 33, 33, 33, 135, 33, 33, 135, 1080, 1080, 33, 33, 1080, 33, 33, 33, 135, 33, 135, 1080, 1080, 135, 135, 33, 1080, 135, 1080, 33, 135, 135, 33, 33, 135, 33, 1080, 1080, 33, 1080, 1080, 33, 135, 1080, 33, 33, 135, 135, 33, 33, 1080, 1080, 1080, 1080, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 1080, 135, 135, 135, 1080, 33, 135, 135, 1080, 1080, 33, 1080, 1080, 33, 1080, 33, 33, 135, 33, 1080, 1080, 1080, 135, 33, 1080, 1080, 135, 135, 1080, 1080, 33, 1080, 1080, 135, 33, 1080, 135, 135, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 33, 1080, 33, 135, 1080, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 1080, 33, 33, 33, 135, 33, 135, 135, 33, 1080, 135, 1080, 33, 1080, 33, 135, 135, 135, 135, 33, 135, 1080, 1080, 33, 1080, 1080, 33, 1080, 135, 1080, 135, 135, 135, 33, 135, 33, 33, 1080, 33, 135, 33, 33, 135, 1080, 135, 1080, 33, 1080, 1080, 135, 1080, 135, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 159744 . Total input tokens: 35685722 . Total output tokens: 31942819
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 7.148329320829362,
    "estimated_duration": 3599.970252913174,
    "input_throughput": 3678.66900824622,
    "output_throughput": 3220.2679982199293,
    "total_throughput": 6898.937006466149,
    "itl": 51.75341523172917,
    "ttft": 75960.47837635044,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7338,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.622882646543797,
    "arrivals": 53529,
    "finished_requests": 52844,
    "scheduler_time": 39.682820917013466
}
#Debug simulation 
Total elapsed time: 7.14843146270141. Arrivals time: 0.134804661385715 Scheduler time: 6.730086962226778 Scheduler overhead time: 0.0852190526202321 Adapter cache time: 0.082765590865165 Engine time: 0.07836684631183743 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-8/adapters_384_slots_64_rate_0.1-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-8/adapters_384_slots_64_rate_0.1-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 1080, 66, 33, 1080, 1080, 33, 66, 1080, 1080, 1080, 1080, 66, 66, 66, 66, 1080, 1080, 66, 66, 33, 1080, 33, 1080, 66, 66, 66, 33, 33, 66, 33, 1080, 33, 1080, 66, 1080, 66, 33, 66, 1080, 66, 1080, 33, 1080, 1080, 1080, 1080, 33, 66, 66, 66, 1080, 66, 33, 66, 33, 1080, 66, 1080, 1080, 66, 1080, 1080, 33, 33, 1080, 66, 66, 33, 33, 33, 66, 33, 66, 33, 1080, 33, 66, 1080, 33, 1080, 66, 33, 1080, 1080, 1080, 1080, 66, 33, 66, 1080, 1080, 66, 33, 33, 1080, 66, 66, 33, 33, 1080, 66, 1080, 66, 1080, 1080, 66, 1080, 1080, 33, 66, 66, 66, 66, 33, 33, 1080, 33, 1080, 33, 33, 33, 66, 66, 1080, 33, 33, 1080, 33, 1080, 66, 33, 1080, 66, 66, 33, 1080, 1080, 1080, 33, 66, 1080, 33, 1080, 66, 66, 1080, 1080, 33, 66, 1080, 33, 66, 66, 33, 66, 33, 66, 1080, 1080, 66, 33, 1080, 33, 1080, 66, 66, 66, 66, 66, 33, 33, 1080, 33, 1080, 33, 66, 1080, 66, 1080, 66, 1080, 66, 1080, 33, 66, 66, 66, 66, 66, 66, 66, 66, 1080, 33, 33, 33, 33, 33, 66, 33, 33, 66, 1080, 1080, 33, 33, 1080, 33, 33, 33, 66, 33, 66, 1080, 1080, 66, 66, 33, 1080, 66, 1080, 33, 66, 66, 33, 33, 66, 33, 1080, 1080, 33, 1080, 1080, 33, 66, 1080, 33, 33, 66, 66, 33, 33, 1080, 1080, 1080, 1080, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 1080, 66, 66, 66, 1080, 33, 66, 66, 1080, 1080, 33, 1080, 1080, 33, 1080, 33, 33, 66, 33, 1080, 1080, 1080, 66, 33, 1080, 1080, 66, 66, 1080, 1080, 33, 1080, 1080, 66, 33, 1080, 66, 66, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 33, 1080, 33, 66, 1080, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 1080, 33, 33, 33, 66, 33, 66, 66, 33, 1080, 66, 1080, 33, 1080, 33, 66, 66, 66, 66, 33, 66, 1080, 1080, 33, 1080, 1080, 33, 1080, 66, 1080, 66, 66, 66, 33, 66, 33, 33, 1080, 33, 66, 33, 33, 66, 1080, 66, 1080, 33, 1080, 1080, 66, 1080, 66, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 150912 . Total input tokens: 33712521 . Total output tokens: 30175123
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 6.053481818176806,
    "estimated_duration": 3600.0077587570627,
    "input_throughput": 3468.168358701181,
    "output_throughput": 3075.314760938855,
    "total_throughput": 6543.483119640036,
    "itl": 49.709116356942786,
    "ttft": 58729.90020924068,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7579,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 23.195436611266878,
    "arrivals": 50610,
    "finished_requests": 50078,
    "scheduler_time": 35.46029231823013
}
#Debug simulation 
Total elapsed time: 6.053589129354805. Arrivals time: 0.1270996225066483 Scheduler time: 5.637533050496131 Scheduler overhead time: 0.08664347976446152 Adapter cache time: 0.08428494818508625 Engine time: 0.07997306436300278 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-16/adapters_384_slots_64_rate_0.1-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-16/adapters_384_slots_64_rate_0.1-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 1080, 66, 33, 1080, 1080, 33, 66, 1080, 1080, 1080, 1080, 66, 66, 66, 66, 1080, 1080, 66, 66, 33, 1080, 33, 1080, 66, 66, 66, 33, 33, 66, 33, 1080, 33, 1080, 66, 1080, 66, 33, 66, 1080, 66, 1080, 33, 1080, 1080, 1080, 1080, 33, 66, 66, 66, 1080, 66, 33, 66, 33, 1080, 66, 1080, 1080, 66, 1080, 1080, 33, 33, 1080, 66, 66, 33, 33, 33, 66, 33, 66, 33, 1080, 33, 66, 1080, 33, 1080, 66, 33, 1080, 1080, 1080, 1080, 66, 33, 66, 1080, 1080, 66, 33, 33, 1080, 66, 66, 33, 33, 1080, 66, 1080, 66, 1080, 1080, 66, 1080, 1080, 33, 66, 66, 66, 66, 33, 33, 1080, 33, 1080, 33, 33, 33, 66, 66, 1080, 33, 33, 1080, 33, 1080, 66, 33, 1080, 66, 66, 33, 1080, 1080, 1080, 33, 66, 1080, 33, 1080, 66, 66, 1080, 1080, 33, 66, 1080, 33, 66, 66, 33, 66, 33, 66, 1080, 1080, 66, 33, 1080, 33, 1080, 66, 66, 66, 66, 66, 33, 33, 1080, 33, 1080, 33, 66, 1080, 66, 1080, 66, 1080, 66, 1080, 33, 66, 66, 66, 66, 66, 66, 66, 66, 1080, 33, 33, 33, 33, 33, 66, 33, 33, 66, 1080, 1080, 33, 33, 1080, 33, 33, 33, 66, 33, 66, 1080, 1080, 66, 66, 33, 1080, 66, 1080, 33, 66, 66, 33, 33, 66, 33, 1080, 1080, 33, 1080, 1080, 33, 66, 1080, 33, 33, 66, 66, 33, 33, 1080, 1080, 1080, 1080, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 1080, 66, 66, 66, 1080, 33, 66, 66, 1080, 1080, 33, 1080, 1080, 33, 1080, 33, 33, 66, 33, 1080, 1080, 1080, 66, 33, 1080, 1080, 66, 66, 1080, 1080, 33, 1080, 1080, 66, 33, 1080, 66, 66, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 33, 1080, 33, 66, 1080, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 1080, 33, 33, 33, 66, 33, 66, 66, 33, 1080, 66, 1080, 33, 1080, 33, 66, 66, 66, 66, 33, 66, 1080, 1080, 33, 1080, 1080, 33, 1080, 66, 1080, 66, 66, 66, 33, 66, 33, 33, 1080, 33, 66, 33, 33, 66, 1080, 66, 1080, 33, 1080, 1080, 66, 1080, 66, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 150912 . Total input tokens: 33712521 . Total output tokens: 30175123
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 6.015407703351229,
    "estimated_duration": 3600.0135728393648,
    "input_throughput": 3468.2605349602454,
    "output_throughput": 3075.8170145638182,
    "total_throughput": 6544.077549524064,
    "itl": 49.753763441317375,
    "ttft": 58557.71328994913,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7687,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 25.122287322990697,
    "arrivals": 50610,
    "finished_requests": 50075,
    "scheduler_time": 35.41546769169161
}
#Debug simulation 
Total elapsed time: 6.015501827001572. Arrivals time: 0.12774063274264336 Scheduler time: 5.597607320640236 Scheduler overhead time: 0.08654729276895523 Adapter cache time: 0.08576852222904563 Engine time: 0.07990767573937774 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-32/adapters_384_slots_64_rate_0.1-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-32/adapters_384_slots_64_rate_0.1-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 1080, 66, 33, 1080, 1080, 33, 66, 1080, 1080, 1080, 1080, 66, 66, 66, 66, 1080, 1080, 66, 66, 33, 1080, 33, 1080, 66, 66, 66, 33, 33, 66, 33, 1080, 33, 1080, 66, 1080, 66, 33, 66, 1080, 66, 1080, 33, 1080, 1080, 1080, 1080, 33, 66, 66, 66, 1080, 66, 33, 66, 33, 1080, 66, 1080, 1080, 66, 1080, 1080, 33, 33, 1080, 66, 66, 33, 33, 33, 66, 33, 66, 33, 1080, 33, 66, 1080, 33, 1080, 66, 33, 1080, 1080, 1080, 1080, 66, 33, 66, 1080, 1080, 66, 33, 33, 1080, 66, 66, 33, 33, 1080, 66, 1080, 66, 1080, 1080, 66, 1080, 1080, 33, 66, 66, 66, 66, 33, 33, 1080, 33, 1080, 33, 33, 33, 66, 66, 1080, 33, 33, 1080, 33, 1080, 66, 33, 1080, 66, 66, 33, 1080, 1080, 1080, 33, 66, 1080, 33, 1080, 66, 66, 1080, 1080, 33, 66, 1080, 33, 66, 66, 33, 66, 33, 66, 1080, 1080, 66, 33, 1080, 33, 1080, 66, 66, 66, 66, 66, 33, 33, 1080, 33, 1080, 33, 66, 1080, 66, 1080, 66, 1080, 66, 1080, 33, 66, 66, 66, 66, 66, 66, 66, 66, 1080, 33, 33, 33, 33, 33, 66, 33, 33, 66, 1080, 1080, 33, 33, 1080, 33, 33, 33, 66, 33, 66, 1080, 1080, 66, 66, 33, 1080, 66, 1080, 33, 66, 66, 33, 33, 66, 33, 1080, 1080, 33, 1080, 1080, 33, 66, 1080, 33, 33, 66, 66, 33, 33, 1080, 1080, 1080, 1080, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 1080, 66, 66, 66, 1080, 33, 66, 66, 1080, 1080, 33, 1080, 1080, 33, 1080, 33, 33, 66, 33, 1080, 1080, 1080, 66, 33, 1080, 1080, 66, 66, 1080, 1080, 33, 1080, 1080, 66, 33, 1080, 66, 66, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 33, 1080, 33, 66, 1080, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 1080, 33, 33, 33, 66, 33, 66, 66, 33, 1080, 66, 1080, 33, 1080, 33, 66, 66, 66, 66, 33, 66, 1080, 1080, 33, 1080, 1080, 33, 1080, 66, 1080, 66, 66, 66, 33, 66, 33, 33, 1080, 33, 66, 33, 33, 66, 1080, 66, 1080, 33, 1080, 1080, 66, 1080, 66, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 150912 . Total input tokens: 33712521 . Total output tokens: 30175123
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 6.008110957220197,
    "estimated_duration": 3600.021372813599,
    "input_throughput": 3468.4632969945774,
    "output_throughput": 3075.7456285172234,
    "total_throughput": 6544.208925511801,
    "itl": 49.74506930755317,
    "ttft": 58466.615776240076,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7705,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 25.219513086080916,
    "arrivals": 50610,
    "finished_requests": 50075,
    "scheduler_time": 35.39567351632821
}
#Debug simulation 
Total elapsed time: 6.008206678088754. Arrivals time: 0.1280409712344408 Scheduler time: 5.590611282736063 Scheduler overhead time: 0.08593863435089588 Adapter cache time: 0.08560950588434935 Engine time: 0.08000992611050606 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-16/adapters_384_slots_64_rate_0.1-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-16/adapters_384_slots_64_rate_0.1-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 1080, 66, 33, 1080, 1080, 33, 66, 1080, 1080, 1080, 1080, 66, 66, 66, 66, 1080, 1080, 66, 66, 33, 1080, 33, 1080, 66, 66, 66, 33, 33, 66, 33, 1080, 33, 1080, 66, 1080, 66, 33, 66, 1080, 66, 1080, 33, 1080, 1080, 1080, 1080, 33, 66, 66, 66, 1080, 66, 33, 66, 33, 1080, 66, 1080, 1080, 66, 1080, 1080, 33, 33, 1080, 66, 66, 33, 33, 33, 66, 33, 66, 33, 1080, 33, 66, 1080, 33, 1080, 66, 33, 1080, 1080, 1080, 1080, 66, 33, 66, 1080, 1080, 66, 33, 33, 1080, 66, 66, 33, 33, 1080, 66, 1080, 66, 1080, 1080, 66, 1080, 1080, 33, 66, 66, 66, 66, 33, 33, 1080, 33, 1080, 33, 33, 33, 66, 66, 1080, 33, 33, 1080, 33, 1080, 66, 33, 1080, 66, 66, 33, 1080, 1080, 1080, 33, 66, 1080, 33, 1080, 66, 66, 1080, 1080, 33, 66, 1080, 33, 66, 66, 33, 66, 33, 66, 1080, 1080, 66, 33, 1080, 33, 1080, 66, 66, 66, 66, 66, 33, 33, 1080, 33, 1080, 33, 66, 1080, 66, 1080, 66, 1080, 66, 1080, 33, 66, 66, 66, 66, 66, 66, 66, 66, 1080, 33, 33, 33, 33, 33, 66, 33, 33, 66, 1080, 1080, 33, 33, 1080, 33, 33, 33, 66, 33, 66, 1080, 1080, 66, 66, 33, 1080, 66, 1080, 33, 66, 66, 33, 33, 66, 33, 1080, 1080, 33, 1080, 1080, 33, 66, 1080, 33, 33, 66, 66, 33, 33, 1080, 1080, 1080, 1080, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 1080, 66, 66, 66, 1080, 33, 66, 66, 1080, 1080, 33, 1080, 1080, 33, 1080, 33, 33, 66, 33, 1080, 1080, 1080, 66, 33, 1080, 1080, 66, 66, 1080, 1080, 33, 1080, 1080, 66, 33, 1080, 66, 66, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 33, 1080, 33, 66, 1080, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 1080, 33, 33, 33, 66, 33, 66, 66, 33, 1080, 66, 1080, 33, 1080, 33, 66, 66, 66, 66, 33, 66, 1080, 1080, 33, 1080, 1080, 33, 1080, 66, 1080, 66, 66, 66, 33, 66, 33, 33, 1080, 33, 66, 33, 33, 66, 1080, 66, 1080, 33, 1080, 1080, 66, 1080, 66, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 150912 . Total input tokens: 33712521 . Total output tokens: 30175123
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 6.063813192304224,
    "estimated_duration": 3600.00142591892,
    "input_throughput": 3468.773348280681,
    "output_throughput": 3075.0393375675635,
    "total_throughput": 6543.812685848245,
    "itl": 49.71163976527102,
    "ttft": 58979.4365035156,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7590,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 23.80463521850864,
    "arrivals": 50610,
    "finished_requests": 50074,
    "scheduler_time": 35.44851596475603
}
#Debug simulation 
Total elapsed time: 6.063877077307552. Arrivals time: 0.12669437704607844 Scheduler time: 5.648380412720144 Scheduler overhead time: 0.08602825412526727 Adapter cache time: 0.08466012729331851 Engine time: 0.08025438664481044 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-32/adapters_384_slots_64_rate_0.1-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-32/adapters_384_slots_64_rate_0.1-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 1080, 66, 33, 1080, 1080, 33, 66, 1080, 1080, 1080, 1080, 66, 66, 66, 66, 1080, 1080, 66, 66, 33, 1080, 33, 1080, 66, 66, 66, 33, 33, 66, 33, 1080, 33, 1080, 66, 1080, 66, 33, 66, 1080, 66, 1080, 33, 1080, 1080, 1080, 1080, 33, 66, 66, 66, 1080, 66, 33, 66, 33, 1080, 66, 1080, 1080, 66, 1080, 1080, 33, 33, 1080, 66, 66, 33, 33, 33, 66, 33, 66, 33, 1080, 33, 66, 1080, 33, 1080, 66, 33, 1080, 1080, 1080, 1080, 66, 33, 66, 1080, 1080, 66, 33, 33, 1080, 66, 66, 33, 33, 1080, 66, 1080, 66, 1080, 1080, 66, 1080, 1080, 33, 66, 66, 66, 66, 33, 33, 1080, 33, 1080, 33, 33, 33, 66, 66, 1080, 33, 33, 1080, 33, 1080, 66, 33, 1080, 66, 66, 33, 1080, 1080, 1080, 33, 66, 1080, 33, 1080, 66, 66, 1080, 1080, 33, 66, 1080, 33, 66, 66, 33, 66, 33, 66, 1080, 1080, 66, 33, 1080, 33, 1080, 66, 66, 66, 66, 66, 33, 33, 1080, 33, 1080, 33, 66, 1080, 66, 1080, 66, 1080, 66, 1080, 33, 66, 66, 66, 66, 66, 66, 66, 66, 1080, 33, 33, 33, 33, 33, 66, 33, 33, 66, 1080, 1080, 33, 33, 1080, 33, 33, 33, 66, 33, 66, 1080, 1080, 66, 66, 33, 1080, 66, 1080, 33, 66, 66, 33, 33, 66, 33, 1080, 1080, 33, 1080, 1080, 33, 66, 1080, 33, 33, 66, 66, 33, 33, 1080, 1080, 1080, 1080, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 1080, 66, 66, 66, 1080, 33, 66, 66, 1080, 1080, 33, 1080, 1080, 33, 1080, 33, 33, 66, 33, 1080, 1080, 1080, 66, 33, 1080, 1080, 66, 66, 1080, 1080, 33, 1080, 1080, 66, 33, 1080, 66, 66, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 33, 1080, 33, 66, 1080, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 1080, 33, 33, 33, 66, 33, 66, 66, 33, 1080, 66, 1080, 33, 1080, 33, 66, 66, 66, 66, 33, 66, 1080, 1080, 33, 1080, 1080, 33, 1080, 66, 1080, 66, 66, 66, 33, 66, 33, 33, 1080, 33, 66, 33, 33, 66, 1080, 66, 1080, 33, 1080, 1080, 66, 1080, 66, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 150912 . Total input tokens: 33712521 . Total output tokens: 30175123
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 6.000379034783691,
    "estimated_duration": 3600.0283523999774,
    "input_throughput": 3469.0032348424343,
    "output_throughput": 3076.1404955650787,
    "total_throughput": 6545.1437304075125,
    "itl": 49.743949622651606,
    "ttft": 57791.59992105758,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7667,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 25.406663091647612,
    "arrivals": 50610,
    "finished_requests": 50087,
    "scheduler_time": 35.42582869078756
}
#Debug simulation 
Total elapsed time: 6.0004596267826855. Arrivals time: 0.129490006249398 Scheduler time: 5.582318702246994 Scheduler overhead time: 0.08589374227449298 Adapter cache time: 0.08529920363798738 Engine time: 0.07965125050395727 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-16/adapters_384_slots_64_rate_0.1-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-16/adapters_384_slots_64_rate_0.1-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 1080, 66, 33, 1080, 1080, 33, 66, 1080, 1080, 1080, 1080, 66, 66, 66, 66, 1080, 1080, 66, 66, 33, 1080, 33, 1080, 66, 66, 66, 33, 33, 66, 33, 1080, 33, 1080, 66, 1080, 66, 33, 66, 1080, 66, 1080, 33, 1080, 1080, 1080, 1080, 33, 66, 66, 66, 1080, 66, 33, 66, 33, 1080, 66, 1080, 1080, 66, 1080, 1080, 33, 33, 1080, 66, 66, 33, 33, 33, 66, 33, 66, 33, 1080, 33, 66, 1080, 33, 1080, 66, 33, 1080, 1080, 1080, 1080, 66, 33, 66, 1080, 1080, 66, 33, 33, 1080, 66, 66, 33, 33, 1080, 66, 1080, 66, 1080, 1080, 66, 1080, 1080, 33, 66, 66, 66, 66, 33, 33, 1080, 33, 1080, 33, 33, 33, 66, 66, 1080, 33, 33, 1080, 33, 1080, 66, 33, 1080, 66, 66, 33, 1080, 1080, 1080, 33, 66, 1080, 33, 1080, 66, 66, 1080, 1080, 33, 66, 1080, 33, 66, 66, 33, 66, 33, 66, 1080, 1080, 66, 33, 1080, 33, 1080, 66, 66, 66, 66, 66, 33, 33, 1080, 33, 1080, 33, 66, 1080, 66, 1080, 66, 1080, 66, 1080, 33, 66, 66, 66, 66, 66, 66, 66, 66, 1080, 33, 33, 33, 33, 33, 66, 33, 33, 66, 1080, 1080, 33, 33, 1080, 33, 33, 33, 66, 33, 66, 1080, 1080, 66, 66, 33, 1080, 66, 1080, 33, 66, 66, 33, 33, 66, 33, 1080, 1080, 33, 1080, 1080, 33, 66, 1080, 33, 33, 66, 66, 33, 33, 1080, 1080, 1080, 1080, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 1080, 66, 66, 66, 1080, 33, 66, 66, 1080, 1080, 33, 1080, 1080, 33, 1080, 33, 33, 66, 33, 1080, 1080, 1080, 66, 33, 1080, 1080, 66, 66, 1080, 1080, 33, 1080, 1080, 66, 33, 1080, 66, 66, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 33, 1080, 33, 66, 1080, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 1080, 33, 33, 33, 66, 33, 66, 66, 33, 1080, 66, 1080, 33, 1080, 33, 66, 66, 66, 66, 33, 66, 1080, 1080, 33, 1080, 1080, 33, 1080, 66, 1080, 66, 66, 66, 33, 66, 33, 33, 1080, 33, 66, 33, 33, 66, 1080, 66, 1080, 33, 1080, 1080, 66, 1080, 66, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 150912 . Total input tokens: 33712521 . Total output tokens: 30175123
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 6.148964433930814,
    "estimated_duration": 3600.0139656677816,
    "input_throughput": 3468.819598782747,
    "output_throughput": 3075.4472359237843,
    "total_throughput": 6544.266834706531,
    "itl": 49.69358765970217,
    "ttft": 58489.55063379887,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7570,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 22.634680732409105,
    "arrivals": 50610,
    "finished_requests": 50082,
    "scheduler_time": 35.4622025149592
}
#Debug simulation 
Total elapsed time: 6.149035058915615. Arrivals time: 0.13007888570427895 Scheduler time: 5.724968997761607 Scheduler overhead time: 0.08731885673478246 Adapter cache time: 0.08550354326143861 Engine time: 0.08286524703726172 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-32/adapters_384_slots_64_rate_0.1-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-32/adapters_384_slots_64_rate_0.1-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 1080, 66, 33, 1080, 1080, 33, 66, 1080, 1080, 1080, 1080, 66, 66, 66, 66, 1080, 1080, 66, 66, 33, 1080, 33, 1080, 66, 66, 66, 33, 33, 66, 33, 1080, 33, 1080, 66, 1080, 66, 33, 66, 1080, 66, 1080, 33, 1080, 1080, 1080, 1080, 33, 66, 66, 66, 1080, 66, 33, 66, 33, 1080, 66, 1080, 1080, 66, 1080, 1080, 33, 33, 1080, 66, 66, 33, 33, 33, 66, 33, 66, 33, 1080, 33, 66, 1080, 33, 1080, 66, 33, 1080, 1080, 1080, 1080, 66, 33, 66, 1080, 1080, 66, 33, 33, 1080, 66, 66, 33, 33, 1080, 66, 1080, 66, 1080, 1080, 66, 1080, 1080, 33, 66, 66, 66, 66, 33, 33, 1080, 33, 1080, 33, 33, 33, 66, 66, 1080, 33, 33, 1080, 33, 1080, 66, 33, 1080, 66, 66, 33, 1080, 1080, 1080, 33, 66, 1080, 33, 1080, 66, 66, 1080, 1080, 33, 66, 1080, 33, 66, 66, 33, 66, 33, 66, 1080, 1080, 66, 33, 1080, 33, 1080, 66, 66, 66, 66, 66, 33, 33, 1080, 33, 1080, 33, 66, 1080, 66, 1080, 66, 1080, 66, 1080, 33, 66, 66, 66, 66, 66, 66, 66, 66, 1080, 33, 33, 33, 33, 33, 66, 33, 33, 66, 1080, 1080, 33, 33, 1080, 33, 33, 33, 66, 33, 66, 1080, 1080, 66, 66, 33, 1080, 66, 1080, 33, 66, 66, 33, 33, 66, 33, 1080, 1080, 33, 1080, 1080, 33, 66, 1080, 33, 33, 66, 66, 33, 33, 1080, 1080, 1080, 1080, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 1080, 66, 66, 66, 1080, 33, 66, 66, 1080, 1080, 33, 1080, 1080, 33, 1080, 33, 33, 66, 33, 1080, 1080, 1080, 66, 33, 1080, 1080, 66, 66, 1080, 1080, 33, 1080, 1080, 66, 33, 1080, 66, 66, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 33, 1080, 33, 66, 1080, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 1080, 33, 33, 33, 66, 33, 66, 66, 33, 1080, 66, 1080, 33, 1080, 33, 66, 66, 66, 66, 33, 66, 1080, 1080, 33, 1080, 1080, 33, 1080, 66, 1080, 66, 66, 66, 33, 66, 33, 33, 1080, 33, 66, 33, 33, 66, 1080, 66, 1080, 33, 1080, 1080, 66, 1080, 66, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 150912 . Total input tokens: 33712521 . Total output tokens: 30175123
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 6.088101105298847,
    "estimated_duration": 3599.9773331551596,
    "input_throughput": 3467.8212790463517,
    "output_throughput": 3075.7318658713816,
    "total_throughput": 6543.553144917733,
    "itl": 49.75886352046413,
    "ttft": 58901.59537854263,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7662,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 25.7321410942802,
    "arrivals": 50610,
    "finished_requests": 50071,
    "scheduler_time": 35.42303423028548
}
#Debug simulation 
Total elapsed time: 6.088181063067168. Arrivals time: 0.12908760597929358 Scheduler time: 5.6670543984510005 Scheduler overhead time: 0.0872281426563859 Adapter cache time: 0.0861448235809803 Engine time: 0.08054103935137391 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-8/adapters_384_slots_64_rate_0.05-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-8/adapters_384_slots_64_rate_0.05-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 540, 270, 135, 540, 540, 135, 270, 540, 540, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 135, 540, 135, 540, 270, 270, 270, 135, 135, 270, 135, 540, 135, 540, 270, 540, 270, 135, 270, 540, 270, 540, 135, 540, 540, 540, 540, 135, 270, 270, 270, 540, 270, 135, 270, 135, 540, 270, 540, 540, 270, 540, 540, 135, 135, 540, 270, 270, 135, 135, 135, 270, 135, 270, 135, 540, 135, 270, 540, 135, 540, 270, 135, 540, 540, 540, 540, 270, 135, 270, 540, 540, 270, 135, 135, 540, 270, 270, 135, 135, 540, 270, 540, 270, 540, 540, 270, 540, 540, 135, 270, 270, 270, 270, 135, 135, 540, 135, 540, 135, 135, 135, 270, 270, 540, 135, 135, 540, 135, 540, 270, 135, 540, 270, 270, 135, 540, 540, 540, 135, 270, 540, 135, 540, 270, 270, 540, 540, 135, 270, 540, 135, 270, 270, 135, 270, 135, 270, 540, 540, 270, 135, 540, 135, 540, 270, 270, 270, 270, 270, 135, 135, 540, 135, 540, 135, 270, 540, 270, 540, 270, 540, 270, 540, 135, 270, 270, 270, 270, 270, 270, 270, 270, 540, 135, 135, 135, 135, 135, 270, 135, 135, 270, 540, 540, 135, 135, 540, 135, 135, 135, 270, 135, 270, 540, 540, 270, 270, 135, 540, 270, 540, 135, 270, 270, 135, 135, 270, 135, 540, 540, 135, 540, 540, 135, 270, 540, 135, 135, 270, 270, 135, 135, 540, 540, 540, 540, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 540, 270, 270, 270, 540, 135, 270, 270, 540, 540, 135, 540, 540, 135, 540, 135, 135, 270, 135, 540, 540, 540, 270, 135, 540, 540, 270, 270, 540, 540, 135, 540, 540, 270, 135, 540, 270, 270, 540, 540, 540, 135, 540, 135, 540, 540, 135, 135, 540, 135, 270, 540, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 540, 135, 135, 135, 270, 135, 270, 270, 135, 540, 270, 540, 135, 540, 135, 270, 270, 270, 270, 135, 270, 540, 540, 135, 540, 540, 135, 540, 270, 540, 270, 270, 270, 135, 270, 135, 135, 540, 135, 270, 135, 135, 270, 540, 270, 540, 135, 540, 540, 270, 540, 270, 135, 540, 135, 540, 540, 135, 135, 135]
Prompts retrieved: 120960 . Total input tokens: 27012138 . Total output tokens: 24203683
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 5.119647620245814,
    "estimated_duration": 3599.9337963688986,
    "input_throughput": 2781.060310080789,
    "output_throughput": 2427.1257457048628,
    "total_throughput": 5208.186055785652,
    "itl": 42.54827212321605,
    "ttft": 70016.6058435329,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 12603,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 38.5713270367824,
    "arrivals": 40507,
    "finished_requests": 40027,
    "scheduler_time": 24.647887876182693
}
#Debug simulation 
Total elapsed time: 5.119731110986322. Arrivals time: 0.11039023334160447 Scheduler time: 4.652662151493132 Scheduler overhead time: 0.09649776108562946 Adapter cache time: 0.12972617987543344 Engine time: 0.08824960794299841 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-16/adapters_384_slots_64_rate_0.05-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-16/adapters_384_slots_64_rate_0.05-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 540, 270, 135, 540, 540, 135, 270, 540, 540, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 135, 540, 135, 540, 270, 270, 270, 135, 135, 270, 135, 540, 135, 540, 270, 540, 270, 135, 270, 540, 270, 540, 135, 540, 540, 540, 540, 135, 270, 270, 270, 540, 270, 135, 270, 135, 540, 270, 540, 540, 270, 540, 540, 135, 135, 540, 270, 270, 135, 135, 135, 270, 135, 270, 135, 540, 135, 270, 540, 135, 540, 270, 135, 540, 540, 540, 540, 270, 135, 270, 540, 540, 270, 135, 135, 540, 270, 270, 135, 135, 540, 270, 540, 270, 540, 540, 270, 540, 540, 135, 270, 270, 270, 270, 135, 135, 540, 135, 540, 135, 135, 135, 270, 270, 540, 135, 135, 540, 135, 540, 270, 135, 540, 270, 270, 135, 540, 540, 540, 135, 270, 540, 135, 540, 270, 270, 540, 540, 135, 270, 540, 135, 270, 270, 135, 270, 135, 270, 540, 540, 270, 135, 540, 135, 540, 270, 270, 270, 270, 270, 135, 135, 540, 135, 540, 135, 270, 540, 270, 540, 270, 540, 270, 540, 135, 270, 270, 270, 270, 270, 270, 270, 270, 540, 135, 135, 135, 135, 135, 270, 135, 135, 270, 540, 540, 135, 135, 540, 135, 135, 135, 270, 135, 270, 540, 540, 270, 270, 135, 540, 270, 540, 135, 270, 270, 135, 135, 270, 135, 540, 540, 135, 540, 540, 135, 270, 540, 135, 135, 270, 270, 135, 135, 540, 540, 540, 540, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 540, 270, 270, 270, 540, 135, 270, 270, 540, 540, 135, 540, 540, 135, 540, 135, 135, 270, 135, 540, 540, 540, 270, 135, 540, 540, 270, 270, 540, 540, 135, 540, 540, 270, 135, 540, 270, 270, 540, 540, 540, 135, 540, 135, 540, 540, 135, 135, 540, 135, 270, 540, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 540, 135, 135, 135, 270, 135, 270, 270, 135, 540, 270, 540, 135, 540, 135, 270, 270, 270, 270, 135, 270, 540, 540, 135, 540, 540, 135, 540, 270, 540, 270, 270, 270, 135, 270, 135, 135, 540, 135, 270, 135, 135, 270, 540, 270, 540, 135, 540, 540, 270, 540, 270, 135, 540, 135, 540, 540, 135, 135, 135]
Prompts retrieved: 120960 . Total input tokens: 27012138 . Total output tokens: 24203683
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 5.1415527812205255,
    "estimated_duration": 3599.923790750959,
    "input_throughput": 2780.8110898680234,
    "output_throughput": 2426.7902621842945,
    "total_throughput": 5207.601352052317,
    "itl": 42.59507472176848,
    "ttft": 70484.62920140816,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 12587,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 41.090436479348696,
    "arrivals": 40507,
    "finished_requests": 40022,
    "scheduler_time": 24.66047288694811
}
#Debug simulation 
Total elapsed time: 5.141630424186587. Arrivals time: 0.1086630467325449 Scheduler time: 4.675829048734158 Scheduler overhead time: 0.09631420625373721 Adapter cache time: 0.13032215228304267 Engine time: 0.08856870327144861 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-32/adapters_384_slots_64_rate_0.05-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-32/adapters_384_slots_64_rate_0.05-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 540, 270, 135, 540, 540, 135, 270, 540, 540, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 135, 540, 135, 540, 270, 270, 270, 135, 135, 270, 135, 540, 135, 540, 270, 540, 270, 135, 270, 540, 270, 540, 135, 540, 540, 540, 540, 135, 270, 270, 270, 540, 270, 135, 270, 135, 540, 270, 540, 540, 270, 540, 540, 135, 135, 540, 270, 270, 135, 135, 135, 270, 135, 270, 135, 540, 135, 270, 540, 135, 540, 270, 135, 540, 540, 540, 540, 270, 135, 270, 540, 540, 270, 135, 135, 540, 270, 270, 135, 135, 540, 270, 540, 270, 540, 540, 270, 540, 540, 135, 270, 270, 270, 270, 135, 135, 540, 135, 540, 135, 135, 135, 270, 270, 540, 135, 135, 540, 135, 540, 270, 135, 540, 270, 270, 135, 540, 540, 540, 135, 270, 540, 135, 540, 270, 270, 540, 540, 135, 270, 540, 135, 270, 270, 135, 270, 135, 270, 540, 540, 270, 135, 540, 135, 540, 270, 270, 270, 270, 270, 135, 135, 540, 135, 540, 135, 270, 540, 270, 540, 270, 540, 270, 540, 135, 270, 270, 270, 270, 270, 270, 270, 270, 540, 135, 135, 135, 135, 135, 270, 135, 135, 270, 540, 540, 135, 135, 540, 135, 135, 135, 270, 135, 270, 540, 540, 270, 270, 135, 540, 270, 540, 135, 270, 270, 135, 135, 270, 135, 540, 540, 135, 540, 540, 135, 270, 540, 135, 135, 270, 270, 135, 135, 540, 540, 540, 540, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 540, 270, 270, 270, 540, 135, 270, 270, 540, 540, 135, 540, 540, 135, 540, 135, 135, 270, 135, 540, 540, 540, 270, 135, 540, 540, 270, 270, 540, 540, 135, 540, 540, 270, 135, 540, 270, 270, 540, 540, 540, 135, 540, 135, 540, 540, 135, 135, 540, 135, 270, 540, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 540, 135, 135, 135, 270, 135, 270, 270, 135, 540, 270, 540, 135, 540, 135, 270, 270, 270, 270, 135, 270, 540, 540, 135, 540, 540, 135, 540, 270, 540, 270, 270, 270, 135, 270, 135, 135, 540, 135, 270, 135, 135, 270, 540, 270, 540, 135, 540, 540, 270, 540, 270, 135, 540, 135, 540, 540, 135, 135, 135]
Prompts retrieved: 120960 . Total input tokens: 27012138 . Total output tokens: 24203683
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 5.104305885266513,
    "estimated_duration": 3599.931623894712,
    "input_throughput": 2780.4925331250547,
    "output_throughput": 2427.053597908986,
    "total_throughput": 5207.546131034041,
    "itl": 42.59491207765463,
    "ttft": 69974.44797766328,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 12598,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 41.19536426053115,
    "arrivals": 40507,
    "finished_requests": 40028,
    "scheduler_time": 24.667169128155543
}
#Debug simulation 
Total elapsed time: 5.104382587131113. Arrivals time: 0.10717425821349025 Scheduler time: 4.64424596214667 Scheduler overhead time: 0.09553712792694569 Adapter cache time: 0.12834256188943982 Engine time: 0.08731176517903805 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-16/adapters_384_slots_64_rate_0.05-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-16/adapters_384_slots_64_rate_0.05-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 540, 270, 135, 540, 540, 135, 270, 540, 540, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 135, 540, 135, 540, 270, 270, 270, 135, 135, 270, 135, 540, 135, 540, 270, 540, 270, 135, 270, 540, 270, 540, 135, 540, 540, 540, 540, 135, 270, 270, 270, 540, 270, 135, 270, 135, 540, 270, 540, 540, 270, 540, 540, 135, 135, 540, 270, 270, 135, 135, 135, 270, 135, 270, 135, 540, 135, 270, 540, 135, 540, 270, 135, 540, 540, 540, 540, 270, 135, 270, 540, 540, 270, 135, 135, 540, 270, 270, 135, 135, 540, 270, 540, 270, 540, 540, 270, 540, 540, 135, 270, 270, 270, 270, 135, 135, 540, 135, 540, 135, 135, 135, 270, 270, 540, 135, 135, 540, 135, 540, 270, 135, 540, 270, 270, 135, 540, 540, 540, 135, 270, 540, 135, 540, 270, 270, 540, 540, 135, 270, 540, 135, 270, 270, 135, 270, 135, 270, 540, 540, 270, 135, 540, 135, 540, 270, 270, 270, 270, 270, 135, 135, 540, 135, 540, 135, 270, 540, 270, 540, 270, 540, 270, 540, 135, 270, 270, 270, 270, 270, 270, 270, 270, 540, 135, 135, 135, 135, 135, 270, 135, 135, 270, 540, 540, 135, 135, 540, 135, 135, 135, 270, 135, 270, 540, 540, 270, 270, 135, 540, 270, 540, 135, 270, 270, 135, 135, 270, 135, 540, 540, 135, 540, 540, 135, 270, 540, 135, 135, 270, 270, 135, 135, 540, 540, 540, 540, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 540, 270, 270, 270, 540, 135, 270, 270, 540, 540, 135, 540, 540, 135, 540, 135, 135, 270, 135, 540, 540, 540, 270, 135, 540, 540, 270, 270, 540, 540, 135, 540, 540, 270, 135, 540, 270, 270, 540, 540, 540, 135, 540, 135, 540, 540, 135, 135, 540, 135, 270, 540, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 540, 135, 135, 135, 270, 135, 270, 270, 135, 540, 270, 540, 135, 540, 135, 270, 270, 270, 270, 135, 270, 540, 540, 135, 540, 540, 135, 540, 270, 540, 270, 270, 270, 135, 270, 135, 135, 540, 135, 270, 135, 135, 270, 540, 270, 540, 135, 540, 540, 270, 540, 270, 135, 540, 135, 540, 540, 135, 135, 135]
Prompts retrieved: 120960 . Total input tokens: 27012138 . Total output tokens: 24203683
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 5.099951711948961,
    "estimated_duration": 3599.926191393393,
    "input_throughput": 2781.1086860435944,
    "output_throughput": 2426.8950349280303,
    "total_throughput": 5208.003720971625,
    "itl": 42.561420492285876,
    "ttft": 69853.085852932,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 12596,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 39.41023569155887,
    "arrivals": 40507,
    "finished_requests": 40029,
    "scheduler_time": 24.653145678992708
}
#Debug simulation 
Total elapsed time: 5.100027437787503. Arrivals time: 0.10682817827910185 Scheduler time: 4.639544106088579 Scheduler overhead time: 0.09685358172282577 Adapter cache time: 0.12875517131760716 Engine time: 0.086400608997792 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-32/adapters_384_slots_64_rate_0.05-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-32/adapters_384_slots_64_rate_0.05-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 540, 270, 135, 540, 540, 135, 270, 540, 540, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 135, 540, 135, 540, 270, 270, 270, 135, 135, 270, 135, 540, 135, 540, 270, 540, 270, 135, 270, 540, 270, 540, 135, 540, 540, 540, 540, 135, 270, 270, 270, 540, 270, 135, 270, 135, 540, 270, 540, 540, 270, 540, 540, 135, 135, 540, 270, 270, 135, 135, 135, 270, 135, 270, 135, 540, 135, 270, 540, 135, 540, 270, 135, 540, 540, 540, 540, 270, 135, 270, 540, 540, 270, 135, 135, 540, 270, 270, 135, 135, 540, 270, 540, 270, 540, 540, 270, 540, 540, 135, 270, 270, 270, 270, 135, 135, 540, 135, 540, 135, 135, 135, 270, 270, 540, 135, 135, 540, 135, 540, 270, 135, 540, 270, 270, 135, 540, 540, 540, 135, 270, 540, 135, 540, 270, 270, 540, 540, 135, 270, 540, 135, 270, 270, 135, 270, 135, 270, 540, 540, 270, 135, 540, 135, 540, 270, 270, 270, 270, 270, 135, 135, 540, 135, 540, 135, 270, 540, 270, 540, 270, 540, 270, 540, 135, 270, 270, 270, 270, 270, 270, 270, 270, 540, 135, 135, 135, 135, 135, 270, 135, 135, 270, 540, 540, 135, 135, 540, 135, 135, 135, 270, 135, 270, 540, 540, 270, 270, 135, 540, 270, 540, 135, 270, 270, 135, 135, 270, 135, 540, 540, 135, 540, 540, 135, 270, 540, 135, 135, 270, 270, 135, 135, 540, 540, 540, 540, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 540, 270, 270, 270, 540, 135, 270, 270, 540, 540, 135, 540, 540, 135, 540, 135, 135, 270, 135, 540, 540, 540, 270, 135, 540, 540, 270, 270, 540, 540, 135, 540, 540, 270, 135, 540, 270, 270, 540, 540, 540, 135, 540, 135, 540, 540, 135, 135, 540, 135, 270, 540, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 540, 135, 135, 135, 270, 135, 270, 270, 135, 540, 270, 540, 135, 540, 135, 270, 270, 270, 270, 135, 270, 540, 540, 135, 540, 540, 135, 540, 270, 540, 270, 270, 270, 135, 270, 135, 135, 540, 135, 270, 135, 135, 270, 540, 270, 540, 135, 540, 540, 270, 540, 270, 135, 540, 135, 540, 540, 135, 135, 135]
Prompts retrieved: 120960 . Total input tokens: 27012138 . Total output tokens: 24203683
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 5.143544706050307,
    "estimated_duration": 3599.9296012963086,
    "input_throughput": 2780.9854938260414,
    "output_throughput": 2427.103851379128,
    "total_throughput": 5208.08934520517,
    "itl": 42.600305055446945,
    "ttft": 69657.98980817305,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 12567,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 41.618537761888916,
    "arrivals": 40507,
    "finished_requests": 40032,
    "scheduler_time": 24.673692249205804
}
#Debug simulation 
Total elapsed time: 5.143626104108989. Arrivals time: 0.11105271615087986 Scheduler time: 4.6771850399672985 Scheduler overhead time: 0.09628885379061103 Adapter cache time: 0.12960955733433366 Engine time: 0.08765141014009714 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-16/adapters_384_slots_64_rate_0.05-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-16/adapters_384_slots_64_rate_0.05-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 540, 270, 135, 540, 540, 135, 270, 540, 540, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 135, 540, 135, 540, 270, 270, 270, 135, 135, 270, 135, 540, 135, 540, 270, 540, 270, 135, 270, 540, 270, 540, 135, 540, 540, 540, 540, 135, 270, 270, 270, 540, 270, 135, 270, 135, 540, 270, 540, 540, 270, 540, 540, 135, 135, 540, 270, 270, 135, 135, 135, 270, 135, 270, 135, 540, 135, 270, 540, 135, 540, 270, 135, 540, 540, 540, 540, 270, 135, 270, 540, 540, 270, 135, 135, 540, 270, 270, 135, 135, 540, 270, 540, 270, 540, 540, 270, 540, 540, 135, 270, 270, 270, 270, 135, 135, 540, 135, 540, 135, 135, 135, 270, 270, 540, 135, 135, 540, 135, 540, 270, 135, 540, 270, 270, 135, 540, 540, 540, 135, 270, 540, 135, 540, 270, 270, 540, 540, 135, 270, 540, 135, 270, 270, 135, 270, 135, 270, 540, 540, 270, 135, 540, 135, 540, 270, 270, 270, 270, 270, 135, 135, 540, 135, 540, 135, 270, 540, 270, 540, 270, 540, 270, 540, 135, 270, 270, 270, 270, 270, 270, 270, 270, 540, 135, 135, 135, 135, 135, 270, 135, 135, 270, 540, 540, 135, 135, 540, 135, 135, 135, 270, 135, 270, 540, 540, 270, 270, 135, 540, 270, 540, 135, 270, 270, 135, 135, 270, 135, 540, 540, 135, 540, 540, 135, 270, 540, 135, 135, 270, 270, 135, 135, 540, 540, 540, 540, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 540, 270, 270, 270, 540, 135, 270, 270, 540, 540, 135, 540, 540, 135, 540, 135, 135, 270, 135, 540, 540, 540, 270, 135, 540, 540, 270, 270, 540, 540, 135, 540, 540, 270, 135, 540, 270, 270, 540, 540, 540, 135, 540, 135, 540, 540, 135, 135, 540, 135, 270, 540, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 540, 135, 135, 135, 270, 135, 270, 270, 135, 540, 270, 540, 135, 540, 135, 270, 270, 270, 270, 135, 270, 540, 540, 135, 540, 540, 135, 540, 270, 540, 270, 270, 270, 135, 270, 135, 135, 540, 135, 270, 135, 135, 270, 540, 270, 540, 135, 540, 540, 270, 540, 270, 135, 540, 135, 540, 540, 135, 135, 135]
Prompts retrieved: 120960 . Total input tokens: 27012138 . Total output tokens: 24203683
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 5.108941605780274,
    "estimated_duration": 3599.9114477135486,
    "input_throughput": 2781.197300383339,
    "output_throughput": 2427.6369368892874,
    "total_throughput": 5208.8342372726265,
    "itl": 42.53924224781002,
    "ttft": 68735.74356802742,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 12881,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 38.514837848637015,
    "arrivals": 40507,
    "finished_requests": 40031,
    "scheduler_time": 24.513830629473105
}
#Debug simulation 
Total elapsed time: 5.10901242820546. Arrivals time: 0.1072323932312429 Scheduler time: 4.643468538764864 Scheduler overhead time: 0.09613876231014729 Adapter cache time: 0.13182066241279244 Engine time: 0.08849557396024466 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-32/adapters_384_slots_64_rate_0.05-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-32/adapters_384_slots_64_rate_0.05-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 540, 270, 135, 540, 540, 135, 270, 540, 540, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 135, 540, 135, 540, 270, 270, 270, 135, 135, 270, 135, 540, 135, 540, 270, 540, 270, 135, 270, 540, 270, 540, 135, 540, 540, 540, 540, 135, 270, 270, 270, 540, 270, 135, 270, 135, 540, 270, 540, 540, 270, 540, 540, 135, 135, 540, 270, 270, 135, 135, 135, 270, 135, 270, 135, 540, 135, 270, 540, 135, 540, 270, 135, 540, 540, 540, 540, 270, 135, 270, 540, 540, 270, 135, 135, 540, 270, 270, 135, 135, 540, 270, 540, 270, 540, 540, 270, 540, 540, 135, 270, 270, 270, 270, 135, 135, 540, 135, 540, 135, 135, 135, 270, 270, 540, 135, 135, 540, 135, 540, 270, 135, 540, 270, 270, 135, 540, 540, 540, 135, 270, 540, 135, 540, 270, 270, 540, 540, 135, 270, 540, 135, 270, 270, 135, 270, 135, 270, 540, 540, 270, 135, 540, 135, 540, 270, 270, 270, 270, 270, 135, 135, 540, 135, 540, 135, 270, 540, 270, 540, 270, 540, 270, 540, 135, 270, 270, 270, 270, 270, 270, 270, 270, 540, 135, 135, 135, 135, 135, 270, 135, 135, 270, 540, 540, 135, 135, 540, 135, 135, 135, 270, 135, 270, 540, 540, 270, 270, 135, 540, 270, 540, 135, 270, 270, 135, 135, 270, 135, 540, 540, 135, 540, 540, 135, 270, 540, 135, 135, 270, 270, 135, 135, 540, 540, 540, 540, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 540, 270, 270, 270, 540, 135, 270, 270, 540, 540, 135, 540, 540, 135, 540, 135, 135, 270, 135, 540, 540, 540, 270, 135, 540, 540, 270, 270, 540, 540, 135, 540, 540, 270, 135, 540, 270, 270, 540, 540, 540, 135, 540, 135, 540, 540, 135, 135, 540, 135, 270, 540, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 540, 135, 135, 135, 270, 135, 270, 270, 135, 540, 270, 540, 135, 540, 135, 270, 270, 270, 270, 135, 270, 540, 540, 135, 540, 540, 135, 540, 270, 540, 270, 270, 270, 135, 270, 135, 135, 540, 135, 270, 135, 135, 270, 540, 270, 540, 135, 540, 540, 270, 540, 270, 135, 540, 135, 540, 540, 135, 135, 135]
Prompts retrieved: 120960 . Total input tokens: 27012138 . Total output tokens: 24203683
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 5.153221298009157,
    "estimated_duration": 3599.9382622561975,
    "input_throughput": 2780.5774073821112,
    "output_throughput": 2426.7118943658934,
    "total_throughput": 5207.289301748005,
    "itl": 42.60396339034543,
    "ttft": 70584.32626293894,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 12543,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 42.07656871464083,
    "arrivals": 40507,
    "finished_requests": 40022,
    "scheduler_time": 24.68156175982957
}
#Debug simulation 
Total elapsed time: 5.1533088139258325. Arrivals time: 0.10853658383712173 Scheduler time: 4.690522696822882 Scheduler overhead time: 0.09522283729165792 Adapter cache time: 0.12957155564799905 Engine time: 0.08742170361801982 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-8/adapters_384_slots_64_rate_0.05-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-8/adapters_384_slots_64_rate_0.05-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 540, 270, 66, 540, 540, 66, 270, 540, 540, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 66, 540, 66, 540, 270, 270, 270, 66, 66, 270, 66, 540, 66, 540, 270, 540, 270, 66, 270, 540, 270, 540, 66, 540, 540, 540, 540, 66, 270, 270, 270, 540, 270, 66, 270, 66, 540, 270, 540, 540, 270, 540, 540, 66, 66, 540, 270, 270, 66, 66, 66, 270, 66, 270, 66, 540, 66, 270, 540, 66, 540, 270, 66, 540, 540, 540, 540, 270, 66, 270, 540, 540, 270, 66, 66, 540, 270, 270, 66, 66, 540, 270, 540, 270, 540, 540, 270, 540, 540, 66, 270, 270, 270, 270, 66, 66, 540, 66, 540, 66, 66, 66, 270, 270, 540, 66, 66, 540, 66, 540, 270, 66, 540, 270, 270, 66, 540, 540, 540, 66, 270, 540, 66, 540, 270, 270, 540, 540, 66, 270, 540, 66, 270, 270, 66, 270, 66, 270, 540, 540, 270, 66, 540, 66, 540, 270, 270, 270, 270, 270, 66, 66, 540, 66, 540, 66, 270, 540, 270, 540, 270, 540, 270, 540, 66, 270, 270, 270, 270, 270, 270, 270, 270, 540, 66, 66, 66, 66, 66, 270, 66, 66, 270, 540, 540, 66, 66, 540, 66, 66, 66, 270, 66, 270, 540, 540, 270, 270, 66, 540, 270, 540, 66, 270, 270, 66, 66, 270, 66, 540, 540, 66, 540, 540, 66, 270, 540, 66, 66, 270, 270, 66, 66, 540, 540, 540, 540, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 540, 270, 270, 270, 540, 66, 270, 270, 540, 540, 66, 540, 540, 66, 540, 66, 66, 270, 66, 540, 540, 540, 270, 66, 540, 540, 270, 270, 540, 540, 66, 540, 540, 270, 66, 540, 270, 270, 540, 540, 540, 66, 540, 66, 540, 540, 66, 66, 540, 66, 270, 540, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 540, 66, 66, 66, 270, 66, 270, 270, 66, 540, 270, 540, 66, 540, 66, 270, 270, 270, 270, 66, 270, 540, 540, 66, 540, 540, 66, 540, 270, 540, 270, 270, 270, 66, 270, 66, 66, 540, 66, 270, 66, 66, 270, 540, 270, 540, 66, 540, 540, 270, 540, 270, 66, 540, 66, 540, 540, 66, 66, 66]
Prompts retrieved: 112128 . Total input tokens: 25003147 . Total output tokens: 22451802
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.395769288763404,
    "estimated_duration": 3600.0347584117803,
    "input_throughput": 2567.772985635891,
    "output_throughput": 2312.869613423773,
    "total_throughput": 4880.642599059664,
    "itl": 41.56619402090121,
    "ttft": 54867.401131400446,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 13647,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 41.766476241445524,
    "arrivals": 37708,
    "finished_requests": 37334,
    "scheduler_time": 21.163311208795914
}
#Debug simulation 
Total elapsed time: 4.395835431758314. Arrivals time: 0.09761366620659828 Scheduler time: 3.9401295385323465 Scheduler overhead time: 0.09213416930288076 Adapter cache time: 0.1361113996244967 Engine time: 0.08725206274539232 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-16/adapters_384_slots_64_rate_0.05-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-16/adapters_384_slots_64_rate_0.05-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 540, 270, 66, 540, 540, 66, 270, 540, 540, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 66, 540, 66, 540, 270, 270, 270, 66, 66, 270, 66, 540, 66, 540, 270, 540, 270, 66, 270, 540, 270, 540, 66, 540, 540, 540, 540, 66, 270, 270, 270, 540, 270, 66, 270, 66, 540, 270, 540, 540, 270, 540, 540, 66, 66, 540, 270, 270, 66, 66, 66, 270, 66, 270, 66, 540, 66, 270, 540, 66, 540, 270, 66, 540, 540, 540, 540, 270, 66, 270, 540, 540, 270, 66, 66, 540, 270, 270, 66, 66, 540, 270, 540, 270, 540, 540, 270, 540, 540, 66, 270, 270, 270, 270, 66, 66, 540, 66, 540, 66, 66, 66, 270, 270, 540, 66, 66, 540, 66, 540, 270, 66, 540, 270, 270, 66, 540, 540, 540, 66, 270, 540, 66, 540, 270, 270, 540, 540, 66, 270, 540, 66, 270, 270, 66, 270, 66, 270, 540, 540, 270, 66, 540, 66, 540, 270, 270, 270, 270, 270, 66, 66, 540, 66, 540, 66, 270, 540, 270, 540, 270, 540, 270, 540, 66, 270, 270, 270, 270, 270, 270, 270, 270, 540, 66, 66, 66, 66, 66, 270, 66, 66, 270, 540, 540, 66, 66, 540, 66, 66, 66, 270, 66, 270, 540, 540, 270, 270, 66, 540, 270, 540, 66, 270, 270, 66, 66, 270, 66, 540, 540, 66, 540, 540, 66, 270, 540, 66, 66, 270, 270, 66, 66, 540, 540, 540, 540, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 540, 270, 270, 270, 540, 66, 270, 270, 540, 540, 66, 540, 540, 66, 540, 66, 66, 270, 66, 540, 540, 540, 270, 66, 540, 540, 270, 270, 540, 540, 66, 540, 540, 270, 66, 540, 270, 270, 540, 540, 540, 66, 540, 66, 540, 540, 66, 66, 540, 66, 270, 540, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 540, 66, 66, 66, 270, 66, 270, 270, 66, 540, 270, 540, 66, 540, 66, 270, 270, 270, 270, 66, 270, 540, 540, 66, 540, 540, 66, 540, 270, 540, 270, 270, 270, 66, 270, 66, 66, 540, 66, 270, 66, 66, 270, 540, 270, 540, 66, 540, 540, 270, 540, 270, 66, 540, 66, 540, 540, 66, 66, 66]
Prompts retrieved: 112128 . Total input tokens: 25003147 . Total output tokens: 22451802
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.4381238599307835,
    "estimated_duration": 3600.0010581017245,
    "input_throughput": 2567.592578673851,
    "output_throughput": 2312.8707090965318,
    "total_throughput": 4880.4632877703825,
    "itl": 41.616554267003345,
    "ttft": 54949.61226486859,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 13620,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 44.487647899407555,
    "arrivals": 37708,
    "finished_requests": 37333,
    "scheduler_time": 21.188788332459104
}
#Debug simulation 
Total elapsed time: 4.438200829084963. Arrivals time: 0.09906838834285736 Scheduler time: 3.9778810711577535 Scheduler overhead time: 0.09193430934101343 Adapter cache time: 0.13804775476455688 Engine time: 0.08854120783507824 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-32/adapters_384_slots_64_rate_0.05-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-32/adapters_384_slots_64_rate_0.05-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 540, 270, 66, 540, 540, 66, 270, 540, 540, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 66, 540, 66, 540, 270, 270, 270, 66, 66, 270, 66, 540, 66, 540, 270, 540, 270, 66, 270, 540, 270, 540, 66, 540, 540, 540, 540, 66, 270, 270, 270, 540, 270, 66, 270, 66, 540, 270, 540, 540, 270, 540, 540, 66, 66, 540, 270, 270, 66, 66, 66, 270, 66, 270, 66, 540, 66, 270, 540, 66, 540, 270, 66, 540, 540, 540, 540, 270, 66, 270, 540, 540, 270, 66, 66, 540, 270, 270, 66, 66, 540, 270, 540, 270, 540, 540, 270, 540, 540, 66, 270, 270, 270, 270, 66, 66, 540, 66, 540, 66, 66, 66, 270, 270, 540, 66, 66, 540, 66, 540, 270, 66, 540, 270, 270, 66, 540, 540, 540, 66, 270, 540, 66, 540, 270, 270, 540, 540, 66, 270, 540, 66, 270, 270, 66, 270, 66, 270, 540, 540, 270, 66, 540, 66, 540, 270, 270, 270, 270, 270, 66, 66, 540, 66, 540, 66, 270, 540, 270, 540, 270, 540, 270, 540, 66, 270, 270, 270, 270, 270, 270, 270, 270, 540, 66, 66, 66, 66, 66, 270, 66, 66, 270, 540, 540, 66, 66, 540, 66, 66, 66, 270, 66, 270, 540, 540, 270, 270, 66, 540, 270, 540, 66, 270, 270, 66, 66, 270, 66, 540, 540, 66, 540, 540, 66, 270, 540, 66, 66, 270, 270, 66, 66, 540, 540, 540, 540, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 540, 270, 270, 270, 540, 66, 270, 270, 540, 540, 66, 540, 540, 66, 540, 66, 66, 270, 66, 540, 540, 540, 270, 66, 540, 540, 270, 270, 540, 540, 66, 540, 540, 270, 66, 540, 270, 270, 540, 540, 540, 66, 540, 66, 540, 540, 66, 66, 540, 66, 270, 540, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 540, 66, 66, 66, 270, 66, 270, 270, 66, 540, 270, 540, 66, 540, 66, 270, 270, 270, 270, 66, 270, 540, 540, 66, 540, 540, 66, 540, 270, 540, 270, 270, 270, 66, 270, 66, 66, 540, 66, 270, 66, 66, 270, 540, 270, 540, 66, 540, 540, 270, 540, 270, 66, 540, 66, 540, 540, 66, 66, 66]
Prompts retrieved: 112128 . Total input tokens: 25003147 . Total output tokens: 22451802
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.4074812033213675,
    "estimated_duration": 3600.0472921106016,
    "input_throughput": 2567.4187725965126,
    "output_throughput": 2312.809895094067,
    "total_throughput": 4880.22866769058,
    "itl": 41.620189004327614,
    "ttft": 55316.427043141484,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 13618,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 44.552014612191535,
    "arrivals": 37708,
    "finished_requests": 37330,
    "scheduler_time": 21.186053915139173
}
#Debug simulation 
Total elapsed time: 4.407560431398451. Arrivals time: 0.0981814656406641 Scheduler time: 3.952459600288421 Scheduler overhead time: 0.09022558992728591 Adapter cache time: 0.13710356270894408 Engine time: 0.08720825845375657 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-16/adapters_384_slots_64_rate_0.05-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-16/adapters_384_slots_64_rate_0.05-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 540, 270, 66, 540, 540, 66, 270, 540, 540, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 66, 540, 66, 540, 270, 270, 270, 66, 66, 270, 66, 540, 66, 540, 270, 540, 270, 66, 270, 540, 270, 540, 66, 540, 540, 540, 540, 66, 270, 270, 270, 540, 270, 66, 270, 66, 540, 270, 540, 540, 270, 540, 540, 66, 66, 540, 270, 270, 66, 66, 66, 270, 66, 270, 66, 540, 66, 270, 540, 66, 540, 270, 66, 540, 540, 540, 540, 270, 66, 270, 540, 540, 270, 66, 66, 540, 270, 270, 66, 66, 540, 270, 540, 270, 540, 540, 270, 540, 540, 66, 270, 270, 270, 270, 66, 66, 540, 66, 540, 66, 66, 66, 270, 270, 540, 66, 66, 540, 66, 540, 270, 66, 540, 270, 270, 66, 540, 540, 540, 66, 270, 540, 66, 540, 270, 270, 540, 540, 66, 270, 540, 66, 270, 270, 66, 270, 66, 270, 540, 540, 270, 66, 540, 66, 540, 270, 270, 270, 270, 270, 66, 66, 540, 66, 540, 66, 270, 540, 270, 540, 270, 540, 270, 540, 66, 270, 270, 270, 270, 270, 270, 270, 270, 540, 66, 66, 66, 66, 66, 270, 66, 66, 270, 540, 540, 66, 66, 540, 66, 66, 66, 270, 66, 270, 540, 540, 270, 270, 66, 540, 270, 540, 66, 270, 270, 66, 66, 270, 66, 540, 540, 66, 540, 540, 66, 270, 540, 66, 66, 270, 270, 66, 66, 540, 540, 540, 540, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 540, 270, 270, 270, 540, 66, 270, 270, 540, 540, 66, 540, 540, 66, 540, 66, 66, 270, 66, 540, 540, 540, 270, 66, 540, 540, 270, 270, 540, 540, 66, 540, 540, 270, 66, 540, 270, 270, 540, 540, 540, 66, 540, 66, 540, 540, 66, 66, 540, 66, 270, 540, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 540, 66, 66, 66, 270, 66, 270, 270, 66, 540, 270, 540, 66, 540, 66, 270, 270, 270, 270, 66, 270, 540, 540, 66, 540, 540, 66, 540, 270, 540, 270, 270, 270, 66, 270, 66, 66, 540, 66, 270, 66, 66, 270, 540, 270, 540, 66, 540, 540, 270, 540, 270, 66, 540, 66, 540, 540, 66, 66, 66]
Prompts retrieved: 112128 . Total input tokens: 25003147 . Total output tokens: 22451802
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 4.389084688387811,
    "estimated_duration": 3600.0333198460617,
    "input_throughput": 2567.8798440663586,
    "output_throughput": 2312.956925730913,
    "total_throughput": 4880.836769797272,
    "itl": 41.58197847654577,
    "ttft": 54723.47835118624,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 13636,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 42.71683094174794,
    "arrivals": 37708,
    "finished_requests": 37335,
    "scheduler_time": 21.173269169898656
}
#Debug simulation 
Total elapsed time: 4.389148104004562. Arrivals time: 0.09816099749878049 Scheduler time: 3.9352823668159544 Scheduler overhead time: 0.0901146843098104 Adapter cache time: 0.1363383918069303 Engine time: 0.08695611776784062 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-32/adapters_384_slots_64_rate_0.05-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-32/adapters_384_slots_64_rate_0.05-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 540, 270, 66, 540, 540, 66, 270, 540, 540, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 66, 540, 66, 540, 270, 270, 270, 66, 66, 270, 66, 540, 66, 540, 270, 540, 270, 66, 270, 540, 270, 540, 66, 540, 540, 540, 540, 66, 270, 270, 270, 540, 270, 66, 270, 66, 540, 270, 540, 540, 270, 540, 540, 66, 66, 540, 270, 270, 66, 66, 66, 270, 66, 270, 66, 540, 66, 270, 540, 66, 540, 270, 66, 540, 540, 540, 540, 270, 66, 270, 540, 540, 270, 66, 66, 540, 270, 270, 66, 66, 540, 270, 540, 270, 540, 540, 270, 540, 540, 66, 270, 270, 270, 270, 66, 66, 540, 66, 540, 66, 66, 66, 270, 270, 540, 66, 66, 540, 66, 540, 270, 66, 540, 270, 270, 66, 540, 540, 540, 66, 270, 540, 66, 540, 270, 270, 540, 540, 66, 270, 540, 66, 270, 270, 66, 270, 66, 270, 540, 540, 270, 66, 540, 66, 540, 270, 270, 270, 270, 270, 66, 66, 540, 66, 540, 66, 270, 540, 270, 540, 270, 540, 270, 540, 66, 270, 270, 270, 270, 270, 270, 270, 270, 540, 66, 66, 66, 66, 66, 270, 66, 66, 270, 540, 540, 66, 66, 540, 66, 66, 66, 270, 66, 270, 540, 540, 270, 270, 66, 540, 270, 540, 66, 270, 270, 66, 66, 270, 66, 540, 540, 66, 540, 540, 66, 270, 540, 66, 66, 270, 270, 66, 66, 540, 540, 540, 540, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 540, 270, 270, 270, 540, 66, 270, 270, 540, 540, 66, 540, 540, 66, 540, 66, 66, 270, 66, 540, 540, 540, 270, 66, 540, 540, 270, 270, 540, 540, 66, 540, 540, 270, 66, 540, 270, 270, 540, 540, 540, 66, 540, 66, 540, 540, 66, 66, 540, 66, 270, 540, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 540, 66, 66, 66, 270, 66, 270, 270, 66, 540, 270, 540, 66, 540, 66, 270, 270, 270, 270, 66, 270, 540, 540, 66, 540, 540, 66, 540, 270, 540, 270, 270, 270, 66, 270, 66, 66, 540, 66, 270, 66, 66, 270, 540, 270, 540, 66, 540, 540, 270, 540, 270, 66, 540, 66, 540, 540, 66, 66, 66]
Prompts retrieved: 112128 . Total input tokens: 25003147 . Total output tokens: 22451802
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 4.373089702334255,
    "estimated_duration": 3600.0288296734952,
    "input_throughput": 2567.589160345233,
    "output_throughput": 2312.872866841781,
    "total_throughput": 4880.4620271870135,
    "itl": 41.62611573335564,
    "ttft": 54861.51975734133,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 13623,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 45.12755106483132,
    "arrivals": 37708,
    "finished_requests": 37334,
    "scheduler_time": 21.193623278964985
}
#Debug simulation 
Total elapsed time: 4.3731685862876475. Arrivals time: 0.09910328639671206 Scheduler time: 3.9184196298010647 Scheduler overhead time: 0.08995888195931911 Adapter cache time: 0.1364947622641921 Engine time: 0.08706399006769061 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-16/adapters_384_slots_64_rate_0.05-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-16/adapters_384_slots_64_rate_0.05-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 540, 270, 66, 540, 540, 66, 270, 540, 540, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 66, 540, 66, 540, 270, 270, 270, 66, 66, 270, 66, 540, 66, 540, 270, 540, 270, 66, 270, 540, 270, 540, 66, 540, 540, 540, 540, 66, 270, 270, 270, 540, 270, 66, 270, 66, 540, 270, 540, 540, 270, 540, 540, 66, 66, 540, 270, 270, 66, 66, 66, 270, 66, 270, 66, 540, 66, 270, 540, 66, 540, 270, 66, 540, 540, 540, 540, 270, 66, 270, 540, 540, 270, 66, 66, 540, 270, 270, 66, 66, 540, 270, 540, 270, 540, 540, 270, 540, 540, 66, 270, 270, 270, 270, 66, 66, 540, 66, 540, 66, 66, 66, 270, 270, 540, 66, 66, 540, 66, 540, 270, 66, 540, 270, 270, 66, 540, 540, 540, 66, 270, 540, 66, 540, 270, 270, 540, 540, 66, 270, 540, 66, 270, 270, 66, 270, 66, 270, 540, 540, 270, 66, 540, 66, 540, 270, 270, 270, 270, 270, 66, 66, 540, 66, 540, 66, 270, 540, 270, 540, 270, 540, 270, 540, 66, 270, 270, 270, 270, 270, 270, 270, 270, 540, 66, 66, 66, 66, 66, 270, 66, 66, 270, 540, 540, 66, 66, 540, 66, 66, 66, 270, 66, 270, 540, 540, 270, 270, 66, 540, 270, 540, 66, 270, 270, 66, 66, 270, 66, 540, 540, 66, 540, 540, 66, 270, 540, 66, 66, 270, 270, 66, 66, 540, 540, 540, 540, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 540, 270, 270, 270, 540, 66, 270, 270, 540, 540, 66, 540, 540, 66, 540, 66, 66, 270, 66, 540, 540, 540, 270, 66, 540, 540, 270, 270, 540, 540, 66, 540, 540, 270, 66, 540, 270, 270, 540, 540, 540, 66, 540, 66, 540, 540, 66, 66, 540, 66, 270, 540, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 540, 66, 66, 66, 270, 66, 270, 270, 66, 540, 270, 540, 66, 540, 66, 270, 270, 270, 270, 66, 270, 540, 540, 66, 540, 540, 66, 540, 270, 540, 270, 270, 270, 66, 270, 66, 66, 540, 66, 270, 66, 66, 270, 540, 270, 540, 66, 540, 540, 270, 540, 270, 66, 540, 66, 540, 540, 66, 66, 66]
Prompts retrieved: 112128 . Total input tokens: 25003147 . Total output tokens: 22451802
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.376890975050628,
    "estimated_duration": 3600.000184886093,
    "input_throughput": 2567.7976459027573,
    "output_throughput": 2312.8918256606853,
    "total_throughput": 4880.689471563443,
    "itl": 41.54970110266646,
    "ttft": 54767.405249970194,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 13649,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 40.81119647512385,
    "arrivals": 37708,
    "finished_requests": 37334,
    "scheduler_time": 21.157244110057288
}
#Debug simulation 
Total elapsed time: 4.376953967381269. Arrivals time: 0.09759783605113626 Scheduler time: 3.9242873741313815 Scheduler overhead time: 0.08982509421184659 Adapter cache time: 0.13609793363139033 Engine time: 0.08704016730189323 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-32/adapters_384_slots_64_rate_0.05-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-32/adapters_384_slots_64_rate_0.05-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 540, 270, 66, 540, 540, 66, 270, 540, 540, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 66, 540, 66, 540, 270, 270, 270, 66, 66, 270, 66, 540, 66, 540, 270, 540, 270, 66, 270, 540, 270, 540, 66, 540, 540, 540, 540, 66, 270, 270, 270, 540, 270, 66, 270, 66, 540, 270, 540, 540, 270, 540, 540, 66, 66, 540, 270, 270, 66, 66, 66, 270, 66, 270, 66, 540, 66, 270, 540, 66, 540, 270, 66, 540, 540, 540, 540, 270, 66, 270, 540, 540, 270, 66, 66, 540, 270, 270, 66, 66, 540, 270, 540, 270, 540, 540, 270, 540, 540, 66, 270, 270, 270, 270, 66, 66, 540, 66, 540, 66, 66, 66, 270, 270, 540, 66, 66, 540, 66, 540, 270, 66, 540, 270, 270, 66, 540, 540, 540, 66, 270, 540, 66, 540, 270, 270, 540, 540, 66, 270, 540, 66, 270, 270, 66, 270, 66, 270, 540, 540, 270, 66, 540, 66, 540, 270, 270, 270, 270, 270, 66, 66, 540, 66, 540, 66, 270, 540, 270, 540, 270, 540, 270, 540, 66, 270, 270, 270, 270, 270, 270, 270, 270, 540, 66, 66, 66, 66, 66, 270, 66, 66, 270, 540, 540, 66, 66, 540, 66, 66, 66, 270, 66, 270, 540, 540, 270, 270, 66, 540, 270, 540, 66, 270, 270, 66, 66, 270, 66, 540, 540, 66, 540, 540, 66, 270, 540, 66, 66, 270, 270, 66, 66, 540, 540, 540, 540, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 540, 270, 270, 270, 540, 66, 270, 270, 540, 540, 66, 540, 540, 66, 540, 66, 66, 270, 66, 540, 540, 540, 270, 66, 540, 540, 270, 270, 540, 540, 66, 540, 540, 270, 66, 540, 270, 270, 540, 540, 540, 66, 540, 66, 540, 540, 66, 66, 540, 66, 270, 540, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 540, 66, 66, 66, 270, 66, 270, 270, 66, 540, 270, 540, 66, 540, 66, 270, 270, 270, 270, 66, 270, 540, 540, 66, 540, 540, 66, 540, 270, 540, 270, 270, 270, 66, 270, 66, 66, 540, 66, 270, 66, 66, 270, 540, 270, 540, 66, 540, 540, 270, 540, 270, 66, 540, 66, 540, 540, 66, 66, 66]
Prompts retrieved: 112128 . Total input tokens: 25003147 . Total output tokens: 22451802
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.39650648785755,
    "estimated_duration": 3600.0214723438294,
    "input_throughput": 2567.7824621366926,
    "output_throughput": 2312.8781491903183,
    "total_throughput": 4880.660611327011,
    "itl": 41.634449138578425,
    "ttft": 54896.2139135091,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 13596,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 45.63559004232355,
    "arrivals": 37708,
    "finished_requests": 37334,
    "scheduler_time": 21.201159676294054
}
#Debug simulation 
Total elapsed time: 4.3965802560560405. Arrivals time: 0.0984069649130106 Scheduler time: 3.942025631200522 Scheduler overhead time: 0.09033640613779426 Adapter cache time: 0.13602355914190412 Engine time: 0.0874860561452806 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-8/adapters_384_slots_64_rate_0.05-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-8/adapters_384_slots_64_rate_0.05-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 540, 270, 33, 540, 540, 33, 270, 540, 540, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 33, 540, 33, 540, 270, 270, 270, 33, 33, 270, 33, 540, 33, 540, 270, 540, 270, 33, 270, 540, 270, 540, 33, 540, 540, 540, 540, 33, 270, 270, 270, 540, 270, 33, 270, 33, 540, 270, 540, 540, 270, 540, 540, 33, 33, 540, 270, 270, 33, 33, 33, 270, 33, 270, 33, 540, 33, 270, 540, 33, 540, 270, 33, 540, 540, 540, 540, 270, 33, 270, 540, 540, 270, 33, 33, 540, 270, 270, 33, 33, 540, 270, 540, 270, 540, 540, 270, 540, 540, 33, 270, 270, 270, 270, 33, 33, 540, 33, 540, 33, 33, 33, 270, 270, 540, 33, 33, 540, 33, 540, 270, 33, 540, 270, 270, 33, 540, 540, 540, 33, 270, 540, 33, 540, 270, 270, 540, 540, 33, 270, 540, 33, 270, 270, 33, 270, 33, 270, 540, 540, 270, 33, 540, 33, 540, 270, 270, 270, 270, 270, 33, 33, 540, 33, 540, 33, 270, 540, 270, 540, 270, 540, 270, 540, 33, 270, 270, 270, 270, 270, 270, 270, 270, 540, 33, 33, 33, 33, 33, 270, 33, 33, 270, 540, 540, 33, 33, 540, 33, 33, 33, 270, 33, 270, 540, 540, 270, 270, 33, 540, 270, 540, 33, 270, 270, 33, 33, 270, 33, 540, 540, 33, 540, 540, 33, 270, 540, 33, 33, 270, 270, 33, 33, 540, 540, 540, 540, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 540, 270, 270, 270, 540, 33, 270, 270, 540, 540, 33, 540, 540, 33, 540, 33, 33, 270, 33, 540, 540, 540, 270, 33, 540, 540, 270, 270, 540, 540, 33, 540, 540, 270, 33, 540, 270, 270, 540, 540, 540, 33, 540, 33, 540, 540, 33, 33, 540, 33, 270, 540, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 540, 33, 33, 33, 270, 33, 270, 270, 33, 540, 270, 540, 33, 540, 33, 270, 270, 270, 270, 33, 270, 540, 540, 33, 540, 540, 33, 540, 270, 540, 270, 270, 270, 33, 270, 33, 33, 540, 33, 270, 33, 33, 270, 540, 270, 540, 33, 540, 540, 270, 540, 270, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 107904 . Total input tokens: 24035451 . Total output tokens: 21614343
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.855996449943632,
    "estimated_duration": 3600.0218297910505,
    "input_throughput": 2474.7208270448436,
    "output_throughput": 2179.6728939433797,
    "total_throughput": 4654.393720988223,
    "itl": 40.36221787620622,
    "ttft": 29243.639145016536,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 15377,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 47.06112003844476,
    "arrivals": 36171,
    "finished_requests": 36002,
    "scheduler_time": 17.72708426602131
}
#Debug simulation 
Total elapsed time: 3.856061279773712. Arrivals time: 0.09405162185430527 Scheduler time: 3.3873333195224404 Scheduler overhead time: 0.09185409685596824 Adapter cache time: 0.15057888440787792 Engine time: 0.08873711107298732 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-16/adapters_384_slots_64_rate_0.05-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-16/adapters_384_slots_64_rate_0.05-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 540, 270, 33, 540, 540, 33, 270, 540, 540, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 33, 540, 33, 540, 270, 270, 270, 33, 33, 270, 33, 540, 33, 540, 270, 540, 270, 33, 270, 540, 270, 540, 33, 540, 540, 540, 540, 33, 270, 270, 270, 540, 270, 33, 270, 33, 540, 270, 540, 540, 270, 540, 540, 33, 33, 540, 270, 270, 33, 33, 33, 270, 33, 270, 33, 540, 33, 270, 540, 33, 540, 270, 33, 540, 540, 540, 540, 270, 33, 270, 540, 540, 270, 33, 33, 540, 270, 270, 33, 33, 540, 270, 540, 270, 540, 540, 270, 540, 540, 33, 270, 270, 270, 270, 33, 33, 540, 33, 540, 33, 33, 33, 270, 270, 540, 33, 33, 540, 33, 540, 270, 33, 540, 270, 270, 33, 540, 540, 540, 33, 270, 540, 33, 540, 270, 270, 540, 540, 33, 270, 540, 33, 270, 270, 33, 270, 33, 270, 540, 540, 270, 33, 540, 33, 540, 270, 270, 270, 270, 270, 33, 33, 540, 33, 540, 33, 270, 540, 270, 540, 270, 540, 270, 540, 33, 270, 270, 270, 270, 270, 270, 270, 270, 540, 33, 33, 33, 33, 33, 270, 33, 33, 270, 540, 540, 33, 33, 540, 33, 33, 33, 270, 33, 270, 540, 540, 270, 270, 33, 540, 270, 540, 33, 270, 270, 33, 33, 270, 33, 540, 540, 33, 540, 540, 33, 270, 540, 33, 33, 270, 270, 33, 33, 540, 540, 540, 540, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 540, 270, 270, 270, 540, 33, 270, 270, 540, 540, 33, 540, 540, 33, 540, 33, 33, 270, 33, 540, 540, 540, 270, 33, 540, 540, 270, 270, 540, 540, 33, 540, 540, 270, 33, 540, 270, 270, 540, 540, 540, 33, 540, 33, 540, 540, 33, 33, 540, 33, 270, 540, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 540, 33, 33, 33, 270, 33, 270, 270, 33, 540, 270, 540, 33, 540, 33, 270, 270, 270, 270, 33, 270, 540, 540, 33, 540, 540, 33, 540, 270, 540, 270, 270, 270, 33, 270, 33, 33, 540, 33, 270, 33, 33, 270, 540, 270, 540, 33, 540, 540, 270, 540, 270, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 107904 . Total input tokens: 24035451 . Total output tokens: 21614343
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 3.8474761629477143,
    "estimated_duration": 3600.0275172226275,
    "input_throughput": 2474.457752720871,
    "output_throughput": 2179.6508394618336,
    "total_throughput": 4654.108592182704,
    "itl": 40.41423821236515,
    "ttft": 29374.04303527868,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 15340,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 50.13800979214626,
    "arrivals": 36171,
    "finished_requests": 36001,
    "scheduler_time": 17.74879933432372
}
#Debug simulation 
Total elapsed time: 3.847552841063589. Arrivals time: 0.09433379536494613 Scheduler time: 3.3808075692504644 Scheduler overhead time: 0.09140072716400027 Adapter cache time: 0.14998565800487995 Engine time: 0.08781286142766476 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-32/adapters_384_slots_64_rate_0.05-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-32/adapters_384_slots_64_rate_0.05-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 540, 270, 33, 540, 540, 33, 270, 540, 540, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 33, 540, 33, 540, 270, 270, 270, 33, 33, 270, 33, 540, 33, 540, 270, 540, 270, 33, 270, 540, 270, 540, 33, 540, 540, 540, 540, 33, 270, 270, 270, 540, 270, 33, 270, 33, 540, 270, 540, 540, 270, 540, 540, 33, 33, 540, 270, 270, 33, 33, 33, 270, 33, 270, 33, 540, 33, 270, 540, 33, 540, 270, 33, 540, 540, 540, 540, 270, 33, 270, 540, 540, 270, 33, 33, 540, 270, 270, 33, 33, 540, 270, 540, 270, 540, 540, 270, 540, 540, 33, 270, 270, 270, 270, 33, 33, 540, 33, 540, 33, 33, 33, 270, 270, 540, 33, 33, 540, 33, 540, 270, 33, 540, 270, 270, 33, 540, 540, 540, 33, 270, 540, 33, 540, 270, 270, 540, 540, 33, 270, 540, 33, 270, 270, 33, 270, 33, 270, 540, 540, 270, 33, 540, 33, 540, 270, 270, 270, 270, 270, 33, 33, 540, 33, 540, 33, 270, 540, 270, 540, 270, 540, 270, 540, 33, 270, 270, 270, 270, 270, 270, 270, 270, 540, 33, 33, 33, 33, 33, 270, 33, 33, 270, 540, 540, 33, 33, 540, 33, 33, 33, 270, 33, 270, 540, 540, 270, 270, 33, 540, 270, 540, 33, 270, 270, 33, 33, 270, 33, 540, 540, 33, 540, 540, 33, 270, 540, 33, 33, 270, 270, 33, 33, 540, 540, 540, 540, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 540, 270, 270, 270, 540, 33, 270, 270, 540, 540, 33, 540, 540, 33, 540, 33, 33, 270, 33, 540, 540, 540, 270, 33, 540, 540, 270, 270, 540, 540, 33, 540, 540, 270, 33, 540, 270, 270, 540, 540, 540, 33, 540, 33, 540, 540, 33, 33, 540, 33, 270, 540, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 540, 33, 33, 33, 270, 33, 270, 270, 33, 540, 270, 540, 33, 540, 33, 270, 270, 270, 270, 33, 270, 540, 540, 33, 540, 540, 33, 540, 270, 540, 270, 270, 270, 33, 270, 33, 33, 540, 33, 270, 33, 33, 270, 540, 270, 540, 33, 540, 540, 270, 540, 270, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 107904 . Total input tokens: 24035451 . Total output tokens: 21614343
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 3.852881560102105,
    "estimated_duration": 3600.0272040555515,
    "input_throughput": 2474.457967974439,
    "output_throughput": 2179.6510290700894,
    "total_throughput": 4654.108997044528,
    "itl": 40.41215933074257,
    "ttft": 29390.182431704765,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 15335,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 50.196260616250584,
    "arrivals": 36171,
    "finished_requests": 36001,
    "scheduler_time": 17.751495940258803
}
#Debug simulation 
Total elapsed time: 3.8529846877790987. Arrivals time: 0.09500339301303029 Scheduler time: 3.383452022448182 Scheduler overhead time: 0.09167619235813618 Adapter cache time: 0.1501860381104052 Engine time: 0.0894409311003983 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-16/adapters_384_slots_64_rate_0.05-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-16/adapters_384_slots_64_rate_0.05-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 540, 270, 33, 540, 540, 33, 270, 540, 540, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 33, 540, 33, 540, 270, 270, 270, 33, 33, 270, 33, 540, 33, 540, 270, 540, 270, 33, 270, 540, 270, 540, 33, 540, 540, 540, 540, 33, 270, 270, 270, 540, 270, 33, 270, 33, 540, 270, 540, 540, 270, 540, 540, 33, 33, 540, 270, 270, 33, 33, 33, 270, 33, 270, 33, 540, 33, 270, 540, 33, 540, 270, 33, 540, 540, 540, 540, 270, 33, 270, 540, 540, 270, 33, 33, 540, 270, 270, 33, 33, 540, 270, 540, 270, 540, 540, 270, 540, 540, 33, 270, 270, 270, 270, 33, 33, 540, 33, 540, 33, 33, 33, 270, 270, 540, 33, 33, 540, 33, 540, 270, 33, 540, 270, 270, 33, 540, 540, 540, 33, 270, 540, 33, 540, 270, 270, 540, 540, 33, 270, 540, 33, 270, 270, 33, 270, 33, 270, 540, 540, 270, 33, 540, 33, 540, 270, 270, 270, 270, 270, 33, 33, 540, 33, 540, 33, 270, 540, 270, 540, 270, 540, 270, 540, 33, 270, 270, 270, 270, 270, 270, 270, 270, 540, 33, 33, 33, 33, 33, 270, 33, 33, 270, 540, 540, 33, 33, 540, 33, 33, 33, 270, 33, 270, 540, 540, 270, 270, 33, 540, 270, 540, 33, 270, 270, 33, 33, 270, 33, 540, 540, 33, 540, 540, 33, 270, 540, 33, 33, 270, 270, 33, 33, 540, 540, 540, 540, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 540, 270, 270, 270, 540, 33, 270, 270, 540, 540, 33, 540, 540, 33, 540, 33, 33, 270, 33, 540, 540, 540, 270, 33, 540, 540, 270, 270, 540, 540, 33, 540, 540, 270, 33, 540, 270, 270, 540, 540, 540, 33, 540, 33, 540, 540, 33, 33, 540, 33, 270, 540, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 540, 33, 33, 33, 270, 33, 270, 270, 33, 540, 270, 540, 33, 540, 33, 270, 270, 270, 270, 33, 270, 540, 540, 33, 540, 540, 33, 540, 270, 540, 270, 270, 270, 33, 270, 33, 33, 540, 33, 270, 33, 33, 270, 540, 270, 540, 33, 540, 540, 270, 540, 270, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 107904 . Total input tokens: 24035451 . Total output tokens: 21614343
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 3.8421967797912657,
    "estimated_duration": 3600.0307194792763,
    "input_throughput": 2474.714716125712,
    "output_throughput": 2179.667511596958,
    "total_throughput": 4654.38222772267,
    "itl": 40.37758721915773,
    "ttft": 29258.543970767678,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 15365,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 48.154666430534924,
    "arrivals": 36171,
    "finished_requests": 36002,
    "scheduler_time": 17.735240916953
}
#Debug simulation 
Total elapsed time: 3.8422601870261133. Arrivals time: 0.0941174360923469 Scheduler time: 3.374504528939724 Scheduler overhead time: 0.09213319281116128 Adapter cache time: 0.15053084772080183 Engine time: 0.08770264172926545 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-32/adapters_384_slots_64_rate_0.05-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-32/adapters_384_slots_64_rate_0.05-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 540, 270, 33, 540, 540, 33, 270, 540, 540, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 33, 540, 33, 540, 270, 270, 270, 33, 33, 270, 33, 540, 33, 540, 270, 540, 270, 33, 270, 540, 270, 540, 33, 540, 540, 540, 540, 33, 270, 270, 270, 540, 270, 33, 270, 33, 540, 270, 540, 540, 270, 540, 540, 33, 33, 540, 270, 270, 33, 33, 33, 270, 33, 270, 33, 540, 33, 270, 540, 33, 540, 270, 33, 540, 540, 540, 540, 270, 33, 270, 540, 540, 270, 33, 33, 540, 270, 270, 33, 33, 540, 270, 540, 270, 540, 540, 270, 540, 540, 33, 270, 270, 270, 270, 33, 33, 540, 33, 540, 33, 33, 33, 270, 270, 540, 33, 33, 540, 33, 540, 270, 33, 540, 270, 270, 33, 540, 540, 540, 33, 270, 540, 33, 540, 270, 270, 540, 540, 33, 270, 540, 33, 270, 270, 33, 270, 33, 270, 540, 540, 270, 33, 540, 33, 540, 270, 270, 270, 270, 270, 33, 33, 540, 33, 540, 33, 270, 540, 270, 540, 270, 540, 270, 540, 33, 270, 270, 270, 270, 270, 270, 270, 270, 540, 33, 33, 33, 33, 33, 270, 33, 33, 270, 540, 540, 33, 33, 540, 33, 33, 33, 270, 33, 270, 540, 540, 270, 270, 33, 540, 270, 540, 33, 270, 270, 33, 33, 270, 33, 540, 540, 33, 540, 540, 33, 270, 540, 33, 33, 270, 270, 33, 33, 540, 540, 540, 540, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 540, 270, 270, 270, 540, 33, 270, 270, 540, 540, 33, 540, 540, 33, 540, 33, 33, 270, 33, 540, 540, 540, 270, 33, 540, 540, 270, 270, 540, 540, 33, 540, 540, 270, 33, 540, 270, 270, 540, 540, 540, 33, 540, 33, 540, 540, 33, 33, 540, 33, 270, 540, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 540, 33, 33, 33, 270, 33, 270, 270, 33, 540, 270, 540, 33, 540, 33, 270, 270, 270, 270, 33, 270, 540, 540, 33, 540, 540, 33, 540, 270, 540, 270, 270, 270, 33, 270, 33, 33, 540, 33, 270, 33, 33, 270, 540, 270, 540, 33, 540, 540, 270, 540, 270, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 107904 . Total input tokens: 24035451 . Total output tokens: 21614343
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 3.8879455029964447,
    "estimated_duration": 3600.000302894014,
    "input_throughput": 2474.4764584710815,
    "output_throughput": 2179.667316608838,
    "total_throughput": 4654.14377507992,
    "itl": 40.422927424801536,
    "ttft": 29324.288432563342,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 15327,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 50.8052428355136,
    "arrivals": 36171,
    "finished_requests": 36001,
    "scheduler_time": 17.759673602252125
}
#Debug simulation 
Total elapsed time: 3.8880535159260035. Arrivals time: 0.09571934165433049 Scheduler time: 3.415895107667893 Scheduler overhead time: 0.09199214680120349 Adapter cache time: 0.15160036738961935 Engine time: 0.08941678330302238 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-16/adapters_384_slots_64_rate_0.05-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-16/adapters_384_slots_64_rate_0.05-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 540, 270, 33, 540, 540, 33, 270, 540, 540, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 33, 540, 33, 540, 270, 270, 270, 33, 33, 270, 33, 540, 33, 540, 270, 540, 270, 33, 270, 540, 270, 540, 33, 540, 540, 540, 540, 33, 270, 270, 270, 540, 270, 33, 270, 33, 540, 270, 540, 540, 270, 540, 540, 33, 33, 540, 270, 270, 33, 33, 33, 270, 33, 270, 33, 540, 33, 270, 540, 33, 540, 270, 33, 540, 540, 540, 540, 270, 33, 270, 540, 540, 270, 33, 33, 540, 270, 270, 33, 33, 540, 270, 540, 270, 540, 540, 270, 540, 540, 33, 270, 270, 270, 270, 33, 33, 540, 33, 540, 33, 33, 33, 270, 270, 540, 33, 33, 540, 33, 540, 270, 33, 540, 270, 270, 33, 540, 540, 540, 33, 270, 540, 33, 540, 270, 270, 540, 540, 33, 270, 540, 33, 270, 270, 33, 270, 33, 270, 540, 540, 270, 33, 540, 33, 540, 270, 270, 270, 270, 270, 33, 33, 540, 33, 540, 33, 270, 540, 270, 540, 270, 540, 270, 540, 33, 270, 270, 270, 270, 270, 270, 270, 270, 540, 33, 33, 33, 33, 33, 270, 33, 33, 270, 540, 540, 33, 33, 540, 33, 33, 33, 270, 33, 270, 540, 540, 270, 270, 33, 540, 270, 540, 33, 270, 270, 33, 33, 270, 33, 540, 540, 33, 540, 540, 33, 270, 540, 33, 33, 270, 270, 33, 33, 540, 540, 540, 540, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 540, 270, 270, 270, 540, 33, 270, 270, 540, 540, 33, 540, 540, 33, 540, 33, 33, 270, 33, 540, 540, 540, 270, 33, 540, 540, 270, 270, 540, 540, 33, 540, 540, 270, 33, 540, 270, 270, 540, 540, 540, 33, 540, 33, 540, 540, 33, 33, 540, 33, 270, 540, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 540, 33, 33, 33, 270, 33, 270, 270, 33, 540, 270, 540, 33, 540, 33, 270, 270, 270, 270, 33, 270, 540, 540, 33, 540, 540, 33, 540, 270, 540, 270, 270, 270, 33, 270, 33, 33, 540, 33, 270, 33, 33, 270, 540, 270, 540, 33, 540, 540, 270, 540, 270, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 107904 . Total input tokens: 24035451 . Total output tokens: 21614343
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.9064259519800544,
    "estimated_duration": 3600.012910209506,
    "input_throughput": 2474.7269585434706,
    "output_throughput": 2179.678294415712,
    "total_throughput": 4654.405252959183,
    "itl": 40.34560520444484,
    "ttft": 29127.797981011303,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 15395,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 46.031824290027515,
    "arrivals": 36171,
    "finished_requests": 36002,
    "scheduler_time": 17.718791449780074
}
#Debug simulation 
Total elapsed time: 3.9064878169447184. Arrivals time: 0.09447316499426961 Scheduler time: 3.434184796642512 Scheduler overhead time: 0.09108391776680946 Adapter cache time: 0.15177439991384745 Engine time: 0.09179764613509178 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-32/adapters_384_slots_64_rate_0.05-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-32/adapters_384_slots_64_rate_0.05-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 540, 270, 33, 540, 540, 33, 270, 540, 540, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 33, 540, 33, 540, 270, 270, 270, 33, 33, 270, 33, 540, 33, 540, 270, 540, 270, 33, 270, 540, 270, 540, 33, 540, 540, 540, 540, 33, 270, 270, 270, 540, 270, 33, 270, 33, 540, 270, 540, 540, 270, 540, 540, 33, 33, 540, 270, 270, 33, 33, 33, 270, 33, 270, 33, 540, 33, 270, 540, 33, 540, 270, 33, 540, 540, 540, 540, 270, 33, 270, 540, 540, 270, 33, 33, 540, 270, 270, 33, 33, 540, 270, 540, 270, 540, 540, 270, 540, 540, 33, 270, 270, 270, 270, 33, 33, 540, 33, 540, 33, 33, 33, 270, 270, 540, 33, 33, 540, 33, 540, 270, 33, 540, 270, 270, 33, 540, 540, 540, 33, 270, 540, 33, 540, 270, 270, 540, 540, 33, 270, 540, 33, 270, 270, 33, 270, 33, 270, 540, 540, 270, 33, 540, 33, 540, 270, 270, 270, 270, 270, 33, 33, 540, 33, 540, 33, 270, 540, 270, 540, 270, 540, 270, 540, 33, 270, 270, 270, 270, 270, 270, 270, 270, 540, 33, 33, 33, 33, 33, 270, 33, 33, 270, 540, 540, 33, 33, 540, 33, 33, 33, 270, 33, 270, 540, 540, 270, 270, 33, 540, 270, 540, 33, 270, 270, 33, 33, 270, 33, 540, 540, 33, 540, 540, 33, 270, 540, 33, 33, 270, 270, 33, 33, 540, 540, 540, 540, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 540, 270, 270, 270, 540, 33, 270, 270, 540, 540, 33, 540, 540, 33, 540, 33, 33, 270, 33, 540, 540, 540, 270, 33, 540, 540, 270, 270, 540, 540, 33, 540, 540, 270, 33, 540, 270, 270, 540, 540, 540, 33, 540, 33, 540, 540, 33, 33, 540, 33, 270, 540, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 540, 33, 33, 33, 270, 33, 270, 270, 33, 540, 270, 540, 33, 540, 33, 270, 270, 270, 270, 33, 270, 540, 540, 33, 540, 540, 33, 540, 270, 540, 270, 270, 270, 33, 270, 33, 33, 540, 33, 270, 33, 33, 270, 540, 270, 540, 33, 540, 540, 270, 540, 270, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 107904 . Total input tokens: 24035451 . Total output tokens: 21614343
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 3.860812704078853,
    "estimated_duration": 3600.036384892125,
    "input_throughput": 2474.820820530949,
    "output_throughput": 2179.699636628849,
    "total_throughput": 4654.520457159798,
    "itl": 40.437785276482266,
    "ttft": 29324.14705276263,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 15323,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 51.47096169661917,
    "arrivals": 36171,
    "finished_requests": 36003,
    "scheduler_time": 17.764413286236707
}
#Debug simulation 
Total elapsed time: 3.8608916238881648. Arrivals time: 0.09683924820274115 Scheduler time: 3.387542375829071 Scheduler overhead time: 0.09255864517763257 Adapter cache time: 0.1508319959975779 Engine time: 0.08898928761482239 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-8/adapters_384_slots_64_rate_0.05-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-8/adapters_384_slots_64_rate_0.05-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 540, 135, 66, 540, 540, 66, 135, 540, 540, 540, 540, 135, 135, 135, 135, 540, 540, 135, 135, 66, 540, 66, 540, 135, 135, 135, 66, 66, 135, 66, 540, 66, 540, 135, 540, 135, 66, 135, 540, 135, 540, 66, 540, 540, 540, 540, 66, 135, 135, 135, 540, 135, 66, 135, 66, 540, 135, 540, 540, 135, 540, 540, 66, 66, 540, 135, 135, 66, 66, 66, 135, 66, 135, 66, 540, 66, 135, 540, 66, 540, 135, 66, 540, 540, 540, 540, 135, 66, 135, 540, 540, 135, 66, 66, 540, 135, 135, 66, 66, 540, 135, 540, 135, 540, 540, 135, 540, 540, 66, 135, 135, 135, 135, 66, 66, 540, 66, 540, 66, 66, 66, 135, 135, 540, 66, 66, 540, 66, 540, 135, 66, 540, 135, 135, 66, 540, 540, 540, 66, 135, 540, 66, 540, 135, 135, 540, 540, 66, 135, 540, 66, 135, 135, 66, 135, 66, 135, 540, 540, 135, 66, 540, 66, 540, 135, 135, 135, 135, 135, 66, 66, 540, 66, 540, 66, 135, 540, 135, 540, 135, 540, 135, 540, 66, 135, 135, 135, 135, 135, 135, 135, 135, 540, 66, 66, 66, 66, 66, 135, 66, 66, 135, 540, 540, 66, 66, 540, 66, 66, 66, 135, 66, 135, 540, 540, 135, 135, 66, 540, 135, 540, 66, 135, 135, 66, 66, 135, 66, 540, 540, 66, 540, 540, 66, 135, 540, 66, 66, 135, 135, 66, 66, 540, 540, 540, 540, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 540, 135, 135, 135, 540, 66, 135, 135, 540, 540, 66, 540, 540, 66, 540, 66, 66, 135, 66, 540, 540, 540, 135, 66, 540, 540, 135, 135, 540, 540, 66, 540, 540, 135, 66, 540, 135, 135, 540, 540, 540, 66, 540, 66, 540, 540, 66, 66, 540, 66, 135, 540, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 540, 66, 66, 66, 135, 66, 135, 135, 66, 540, 135, 540, 66, 540, 66, 135, 135, 135, 135, 66, 135, 540, 540, 66, 540, 540, 66, 540, 135, 540, 135, 135, 135, 66, 135, 66, 66, 540, 66, 135, 66, 66, 135, 540, 135, 540, 66, 540, 540, 135, 540, 135, 66, 540, 66, 540, 540, 66, 66, 66]
Prompts retrieved: 94848 . Total input tokens: 21112697 . Total output tokens: 18991968
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.076265594922006,
    "estimated_duration": 3599.759446445892,
    "input_throughput": 2204.7264874423304,
    "output_throughput": 1935.1429181962997,
    "total_throughput": 4139.86940563863,
    "itl": 38.46689784657498,
    "ttft": 16212.441612142022,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 18373,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 56.23034131925963,
    "arrivals": 31815,
    "finished_requests": 31717,
    "scheduler_time": 12.228501560748796
}
#Debug simulation 
Total elapsed time: 3.0763271381147206. Arrivals time: 0.08432706072926521 Scheduler time: 2.5900327367708087 Scheduler overhead time: 0.09492531325668097 Adapter cache time: 0.1717378981411457 Engine time: 0.09048405382782221 
