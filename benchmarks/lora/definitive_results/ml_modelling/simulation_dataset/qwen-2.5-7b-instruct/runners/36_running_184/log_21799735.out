INFO 06-01 00:47:00 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 06-01 00:47:01 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-32/adapters_96_slots_32_rate_0.1-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-32/adapters_96_slots_32_rate_0.1-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 1080, 270, 270, 270, 270, 1080, 270, 1080, 270, 33, 1080, 33, 33, 1080, 270, 1080, 270, 1080, 1080, 270, 33, 1080, 270, 33, 33, 270, 1080, 33, 270, 33, 33, 270, 270, 270, 33, 33, 1080, 270, 270, 33, 1080, 1080, 270, 1080, 1080, 270, 1080, 33, 1080, 270, 270, 270, 1080, 1080, 33, 33, 270, 33, 1080, 33, 33, 1080, 33, 270, 270, 33, 270, 1080, 1080, 1080, 270, 1080, 1080, 33, 33, 1080, 270, 1080, 33, 270, 1080, 33, 1080, 270, 33, 1080, 33, 33, 1080, 33, 33, 270]
Prompts retrieved: 44256 . Total input tokens: 9790606 . Total output tokens: 8891185
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.5459886188618839,
    "estimated_duration": 3599.7523772896034,
    "input_throughput": 1021.1671844961091,
    "output_throughput": 912.4938761685659,
    "total_throughput": 1933.661060664675,
    "itl": 22.413744664120433,
    "ttft": 6516.987992123758,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5934,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.224756447168954,
    "arrivals": 15003,
    "finished_requests": 14976,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.546074423007667. Arrivals time: 0.04905632231384516 Scheduler time: 1.0927775111049414 Scheduler overhead time: 0.135268101003021 Adapter cache time: 0.06585473893210292 Engine time: 0.13651105016469955 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-16/adapters_96_slots_32_rate_0.1-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-16/adapters_96_slots_32_rate_0.1-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 1080, 270, 270, 270, 270, 1080, 270, 1080, 270, 33, 1080, 33, 33, 1080, 270, 1080, 270, 1080, 1080, 270, 33, 1080, 270, 33, 33, 270, 1080, 33, 270, 33, 33, 270, 270, 270, 33, 33, 1080, 270, 270, 33, 1080, 1080, 270, 1080, 1080, 270, 1080, 33, 1080, 270, 270, 270, 1080, 1080, 33, 33, 270, 33, 1080, 33, 33, 1080, 33, 270, 270, 33, 270, 1080, 1080, 1080, 270, 1080, 1080, 33, 33, 1080, 270, 1080, 33, 270, 1080, 33, 1080, 270, 33, 1080, 33, 33, 1080, 33, 33, 270]
Prompts retrieved: 44256 . Total input tokens: 9790606 . Total output tokens: 8891185
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 1.504426039289683,
    "estimated_duration": 3599.74302804274,
    "input_throughput": 1021.1698366698955,
    "output_throughput": 912.4962460962088,
    "total_throughput": 1933.6660827661042,
    "itl": 22.40766114390472,
    "ttft": 6516.966913255899,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5927,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 18.471391911905414,
    "arrivals": 15003,
    "finished_requests": 14976,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5045117172412574. Arrivals time: 0.047530919313430786 Scheduler time: 1.0555481100454926 Scheduler overhead time: 0.13701613014563918 Adapter cache time: 0.06511239241808653 Engine time: 0.13289157953113317 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-32/adapters_96_slots_32_rate_0.1-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-32/adapters_96_slots_32_rate_0.1-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 1080, 270, 270, 270, 270, 1080, 270, 1080, 270, 33, 1080, 33, 33, 1080, 270, 1080, 270, 1080, 1080, 270, 33, 1080, 270, 33, 33, 270, 1080, 33, 270, 33, 33, 270, 270, 270, 33, 33, 1080, 270, 270, 33, 1080, 1080, 270, 1080, 1080, 270, 1080, 33, 1080, 270, 270, 270, 1080, 1080, 33, 33, 270, 33, 1080, 33, 33, 1080, 33, 270, 270, 33, 270, 1080, 1080, 1080, 270, 1080, 1080, 33, 33, 1080, 270, 1080, 33, 270, 1080, 33, 1080, 270, 33, 1080, 33, 33, 1080, 33, 33, 270]
Prompts retrieved: 44256 . Total input tokens: 9790606 . Total output tokens: 8891185
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 1.5249732751399279,
    "estimated_duration": 3599.7673525485197,
    "input_throughput": 1021.162936376304,
    "output_throughput": 912.490080136568,
    "total_throughput": 1933.653016512872,
    "itl": 22.415436450554022,
    "ttft": 6516.9189447293065,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5935,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.432195594998753,
    "arrivals": 15003,
    "finished_requests": 14976,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5250679370947182. Arrivals time: 0.04782012617215514 Scheduler time: 1.0743735749274492 Scheduler overhead time: 0.1365697467699647 Adapter cache time: 0.0656608771532774 Engine time: 0.1338824057020247 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-16/adapters_96_slots_32_rate_0.1-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-16/adapters_96_slots_32_rate_0.1-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 1080, 270, 270, 270, 270, 1080, 270, 1080, 270, 33, 1080, 33, 33, 1080, 270, 1080, 270, 1080, 1080, 270, 33, 1080, 270, 33, 33, 270, 1080, 33, 270, 33, 33, 270, 270, 270, 33, 33, 1080, 270, 270, 33, 1080, 1080, 270, 1080, 1080, 270, 1080, 33, 1080, 270, 270, 270, 1080, 1080, 33, 33, 270, 33, 1080, 33, 33, 1080, 33, 270, 270, 33, 270, 1080, 1080, 1080, 270, 1080, 1080, 33, 33, 1080, 270, 1080, 33, 270, 1080, 33, 1080, 270, 33, 1080, 33, 33, 1080, 33, 33, 270]
Prompts retrieved: 44256 . Total input tokens: 9790606 . Total output tokens: 8891185
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 1.5007415488362312,
    "estimated_duration": 3599.7516351845534,
    "input_throughput": 1021.1673950143341,
    "output_throughput": 912.4940642832977,
    "total_throughput": 1933.6614592976318,
    "itl": 22.40200310352088,
    "ttft": 6516.760288135774,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5934,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.742958449950773,
    "arrivals": 15003,
    "finished_requests": 14976,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5008199429139495. Arrivals time: 0.047869610134512186 Scheduler time: 1.0534484526142478 Scheduler overhead time: 0.135663578286767 Adapter cache time: 0.06547272438183427 Engine time: 0.13199447374790907 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-32/adapters_96_slots_32_rate_0.1-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-32/adapters_96_slots_32_rate_0.1-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 1080, 270, 270, 270, 270, 1080, 270, 1080, 270, 33, 1080, 33, 33, 1080, 270, 1080, 270, 1080, 1080, 270, 33, 1080, 270, 33, 33, 270, 1080, 33, 270, 33, 33, 270, 270, 270, 33, 33, 1080, 270, 270, 33, 1080, 1080, 270, 1080, 1080, 270, 1080, 33, 1080, 270, 270, 270, 1080, 1080, 33, 33, 270, 33, 1080, 33, 33, 1080, 33, 270, 270, 33, 270, 1080, 1080, 1080, 270, 1080, 1080, 33, 33, 1080, 270, 1080, 33, 270, 1080, 33, 1080, 270, 33, 1080, 33, 33, 1080, 33, 33, 270]
Prompts retrieved: 44256 . Total input tokens: 9790606 . Total output tokens: 8891185
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.524963610805571,
    "estimated_duration": 3599.7562789248827,
    "input_throughput": 1021.1660776928691,
    "output_throughput": 912.4928871520815,
    "total_throughput": 1933.6589648449506,
    "itl": 22.417252123047163,
    "ttft": 6516.9566130723715,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5934,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.661299278063996,
    "arrivals": 15003,
    "finished_requests": 14976,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5250347168184817. Arrivals time: 0.04787933686748147 Scheduler time: 1.0757875074632466 Scheduler overhead time: 0.13672275841236115 Adapter cache time: 0.0653573228046298 Engine time: 0.13268610695376992 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-8/adapters_96_slots_32_rate_0.1-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-8/adapters_96_slots_32_rate_0.1-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 1080, 135, 135, 135, 135, 1080, 135, 1080, 135, 66, 1080, 66, 66, 1080, 135, 1080, 135, 1080, 1080, 135, 66, 1080, 135, 66, 66, 135, 1080, 66, 135, 66, 66, 135, 135, 135, 66, 66, 1080, 135, 135, 66, 1080, 1080, 135, 1080, 1080, 135, 1080, 66, 1080, 135, 135, 135, 1080, 1080, 66, 66, 135, 66, 1080, 66, 66, 1080, 66, 135, 135, 66, 135, 1080, 1080, 1080, 135, 1080, 1080, 66, 66, 1080, 135, 1080, 66, 135, 1080, 66, 1080, 135, 66, 1080, 66, 66, 1080, 66, 66, 135]
Prompts retrieved: 40992 . Total input tokens: 9052551 . Total output tokens: 8252881
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 1.4830037532374263,
    "estimated_duration": 3599.923705528769,
    "input_throughput": 946.5017257913023,
    "output_throughput": 854.6870021924723,
    "total_throughput": 1801.1887279837747,
    "itl": 22.01688974622422,
    "ttft": 4700.6164055262525,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4939,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.115748967282295,
    "arrivals": 13896,
    "finished_requests": 13878,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4830819121561944. Arrivals time: 0.04635687591508031 Scheduler time: 1.0271973651833832 Scheduler overhead time: 0.13837204780429602 Adapter cache time: 0.06145106768235564 Engine time: 0.14017612487077713 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-16/adapters_96_slots_32_rate_0.1-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-16/adapters_96_slots_32_rate_0.1-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 1080, 135, 135, 135, 135, 1080, 135, 1080, 135, 66, 1080, 66, 66, 1080, 135, 1080, 135, 1080, 1080, 135, 66, 1080, 135, 66, 66, 135, 1080, 66, 135, 66, 66, 135, 135, 135, 66, 66, 1080, 135, 135, 66, 1080, 1080, 135, 1080, 1080, 135, 1080, 66, 1080, 135, 135, 135, 1080, 1080, 66, 66, 135, 66, 1080, 66, 66, 1080, 66, 135, 135, 66, 135, 1080, 1080, 1080, 135, 1080, 1080, 66, 66, 1080, 135, 1080, 66, 135, 1080, 66, 1080, 135, 66, 1080, 66, 66, 1080, 66, 66, 135]
Prompts retrieved: 40992 . Total input tokens: 9052551 . Total output tokens: 8252881
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.4843884999863803,
    "estimated_duration": 3599.940631882957,
    "input_throughput": 946.4972754891756,
    "output_throughput": 854.6829835887235,
    "total_throughput": 1801.180259077899,
    "itl": 22.02411676635281,
    "ttft": 4700.739185024789,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4938,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.98043942858814,
    "arrivals": 13896,
    "finished_requests": 13878,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4844682831317186. Arrivals time: 0.04554969631135464 Scheduler time: 1.0357911488972604 Scheduler overhead time: 0.13760306360200047 Adapter cache time: 0.06159703340381384 Engine time: 0.13654485903680325 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-32/adapters_96_slots_32_rate_0.1-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-32/adapters_96_slots_32_rate_0.1-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 1080, 135, 135, 135, 135, 1080, 135, 1080, 135, 66, 1080, 66, 66, 1080, 135, 1080, 135, 1080, 1080, 135, 66, 1080, 135, 66, 66, 135, 1080, 66, 135, 66, 66, 135, 135, 135, 66, 66, 1080, 135, 135, 66, 1080, 1080, 135, 1080, 1080, 135, 1080, 66, 1080, 135, 135, 135, 1080, 1080, 66, 66, 135, 66, 1080, 66, 66, 1080, 66, 135, 135, 66, 135, 1080, 1080, 1080, 135, 1080, 1080, 66, 66, 1080, 135, 1080, 66, 135, 1080, 66, 1080, 135, 66, 1080, 66, 66, 1080, 66, 66, 135]
Prompts retrieved: 40992 . Total input tokens: 9052551 . Total output tokens: 8252881
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.4887164253741503,
    "estimated_duration": 3599.9289743070703,
    "input_throughput": 946.5003405118175,
    "output_throughput": 854.6857512910341,
    "total_throughput": 1801.1860918028515,
    "itl": 22.023727078529426,
    "ttft": 4700.633663034449,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4942,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.04539318930213,
    "arrivals": 13896,
    "finished_requests": 13878,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4887900091707706. Arrivals time: 0.04617738677188754 Scheduler time: 1.0378704704344273 Scheduler overhead time: 0.1382671925239265 Adapter cache time: 0.062088663689792156 Engine time: 0.13673452753573656 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-16/adapters_96_slots_32_rate_0.1-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-16/adapters_96_slots_32_rate_0.1-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 1080, 135, 135, 135, 135, 1080, 135, 1080, 135, 66, 1080, 66, 66, 1080, 135, 1080, 135, 1080, 1080, 135, 66, 1080, 135, 66, 66, 135, 1080, 66, 135, 66, 66, 135, 135, 135, 66, 66, 1080, 135, 135, 66, 1080, 1080, 135, 1080, 1080, 135, 1080, 66, 1080, 135, 135, 135, 1080, 1080, 66, 66, 135, 66, 1080, 66, 66, 1080, 66, 135, 135, 66, 135, 1080, 1080, 1080, 135, 1080, 1080, 66, 66, 1080, 135, 1080, 66, 135, 1080, 66, 1080, 135, 66, 1080, 66, 66, 1080, 66, 66, 135]
Prompts retrieved: 40992 . Total input tokens: 9052551 . Total output tokens: 8252881
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 1.4919863091781735,
    "estimated_duration": 3599.924277962637,
    "input_throughput": 946.5015752854578,
    "output_throughput": 854.6868662863396,
    "total_throughput": 1801.1884415717973,
    "itl": 22.01889842493834,
    "ttft": 4700.562280153248,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4935,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.383092019149515,
    "arrivals": 13896,
    "finished_requests": 13878,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4920628922991455. Arrivals time: 0.04622771870344877 Scheduler time: 1.04078173590824 Scheduler overhead time: 0.13783874828368425 Adapter cache time: 0.06213468173518777 Engine time: 0.13702031038701534 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-32/adapters_96_slots_32_rate_0.1-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-32/adapters_96_slots_32_rate_0.1-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 1080, 135, 135, 135, 135, 1080, 135, 1080, 135, 66, 1080, 66, 66, 1080, 135, 1080, 135, 1080, 1080, 135, 66, 1080, 135, 66, 66, 135, 1080, 66, 135, 66, 66, 135, 135, 135, 66, 66, 1080, 135, 135, 66, 1080, 1080, 135, 1080, 1080, 135, 1080, 66, 1080, 135, 135, 135, 1080, 1080, 66, 66, 135, 66, 1080, 66, 66, 1080, 66, 135, 135, 66, 135, 1080, 1080, 1080, 135, 1080, 1080, 66, 66, 1080, 135, 1080, 66, 135, 1080, 66, 1080, 135, 66, 1080, 66, 66, 1080, 66, 66, 135]
Prompts retrieved: 40992 . Total input tokens: 9052551 . Total output tokens: 8252881
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 1.4938274030573666,
    "estimated_duration": 3599.9314376138486,
    "input_throughput": 946.4996928548427,
    "output_throughput": 854.6851664595613,
    "total_throughput": 1801.1848593144039,
    "itl": 22.027052921548812,
    "ttft": 4700.611585611232,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4939,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.217136591485318,
    "arrivals": 13896,
    "finished_requests": 13878,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.493901732377708. Arrivals time: 0.04657773673534393 Scheduler time: 1.0399433732964098 Scheduler overhead time: 0.13860831782221794 Adapter cache time: 0.06216019485145807 Engine time: 0.1387264053337276 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-16/adapters_96_slots_32_rate_0.1-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-16/adapters_96_slots_32_rate_0.1-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 1080, 135, 135, 135, 135, 1080, 135, 1080, 135, 66, 1080, 66, 66, 1080, 135, 1080, 135, 1080, 1080, 135, 66, 1080, 135, 66, 66, 135, 1080, 66, 135, 66, 66, 135, 135, 135, 66, 66, 1080, 135, 135, 66, 1080, 1080, 135, 1080, 1080, 135, 1080, 66, 1080, 135, 135, 135, 1080, 1080, 66, 66, 135, 66, 1080, 66, 66, 1080, 66, 135, 135, 66, 135, 1080, 1080, 1080, 135, 1080, 1080, 66, 66, 1080, 135, 1080, 66, 135, 1080, 66, 1080, 135, 66, 1080, 66, 66, 1080, 66, 66, 135]
Prompts retrieved: 40992 . Total input tokens: 9052551 . Total output tokens: 8252881
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 1.4914738941006362,
    "estimated_duration": 3599.9347752317717,
    "input_throughput": 946.4988153238494,
    "output_throughput": 854.684374052835,
    "total_throughput": 1801.1831893766844,
    "itl": 22.014254473278157,
    "ttft": 4700.506104279541,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4942,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.776828557408075,
    "arrivals": 13896,
    "finished_requests": 13878,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4915503719821572. Arrivals time: 0.04655868001282215 Scheduler time: 1.040673150215298 Scheduler overhead time: 0.13820482697337866 Adapter cache time: 0.06190055143088102 Engine time: 0.13635443896055222 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-32/adapters_96_slots_32_rate_0.1-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-32/adapters_96_slots_32_rate_0.1-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 1080, 135, 135, 135, 135, 1080, 135, 1080, 135, 66, 1080, 66, 66, 1080, 135, 1080, 135, 1080, 1080, 135, 66, 1080, 135, 66, 66, 135, 1080, 66, 135, 66, 66, 135, 135, 135, 66, 66, 1080, 135, 135, 66, 1080, 1080, 135, 1080, 1080, 135, 1080, 66, 1080, 135, 135, 135, 1080, 1080, 66, 66, 135, 66, 1080, 66, 66, 1080, 66, 135, 135, 66, 135, 1080, 1080, 1080, 135, 1080, 1080, 66, 66, 1080, 135, 1080, 66, 135, 1080, 66, 1080, 135, 66, 1080, 66, 66, 1080, 66, 66, 135]
Prompts retrieved: 40992 . Total input tokens: 9052551 . Total output tokens: 8252881
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.4934302349574864,
    "estimated_duration": 3599.9431817435743,
    "input_throughput": 946.4966050796704,
    "output_throughput": 854.6823782118132,
    "total_throughput": 1801.1789832914837,
    "itl": 22.026058928807466,
    "ttft": 4700.644544412392,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4938,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.407713889850953,
    "arrivals": 13896,
    "finished_requests": 13878,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4935044790618122. Arrivals time: 0.04649927467107773 Scheduler time: 1.041132244747132 Scheduler overhead time: 0.13868643064051867 Adapter cache time: 0.062173415906727314 Engine time: 0.13706194842234254 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-8/adapters_96_slots_32_rate_0.1-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-8/adapters_96_slots_32_rate_0.1-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 1080, 135, 135, 135, 135, 1080, 135, 1080, 135, 33, 1080, 33, 33, 1080, 135, 1080, 135, 1080, 1080, 135, 33, 1080, 135, 33, 33, 135, 1080, 33, 135, 33, 33, 135, 135, 135, 33, 33, 1080, 135, 135, 33, 1080, 1080, 135, 1080, 1080, 135, 1080, 33, 1080, 135, 135, 135, 1080, 1080, 33, 33, 135, 33, 1080, 33, 33, 1080, 33, 135, 135, 33, 135, 1080, 1080, 1080, 135, 1080, 1080, 33, 33, 1080, 135, 1080, 33, 135, 1080, 33, 1080, 135, 33, 1080, 33, 33, 1080, 33, 33, 135]
Prompts retrieved: 39936 . Total input tokens: 8825272 . Total output tokens: 8039205
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 1.430718305055052,
    "estimated_duration": 3599.980799609805,
    "input_throughput": 919.6051824384244,
    "output_throughput": 824.7535654417419,
    "total_throughput": 1744.3587478801664,
    "itl": 21.681195022005657,
    "ttft": 5891.708543321278,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4178,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.786717794150064,
    "arrivals": 13527,
    "finished_requests": 13505,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4307939391583204. Arrivals time: 0.04532323684543371 Scheduler time: 0.98130949633196 Scheduler overhead time: 0.14021935826167464 Adapter cache time: 0.059896310325711966 Engine time: 0.13570894300937653 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-16/adapters_96_slots_32_rate_0.1-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-16/adapters_96_slots_32_rate_0.1-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 1080, 135, 135, 135, 135, 1080, 135, 1080, 135, 33, 1080, 33, 33, 1080, 135, 1080, 135, 1080, 1080, 135, 33, 1080, 135, 33, 33, 135, 1080, 33, 135, 33, 33, 135, 135, 135, 33, 33, 1080, 135, 135, 33, 1080, 1080, 135, 1080, 1080, 135, 1080, 33, 1080, 135, 135, 135, 1080, 1080, 33, 33, 135, 33, 1080, 33, 33, 1080, 33, 135, 135, 33, 135, 1080, 1080, 1080, 135, 1080, 1080, 33, 33, 1080, 135, 1080, 33, 135, 1080, 33, 1080, 135, 33, 1080, 33, 33, 1080, 33, 33, 135]
Prompts retrieved: 39936 . Total input tokens: 8825272 . Total output tokens: 8039205
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.4610756491310894,
    "estimated_duration": 3599.9861604590046,
    "input_throughput": 919.6382576031575,
    "output_throughput": 824.7659484394875,
    "total_throughput": 1744.404206042645,
    "itl": 21.687073568095528,
    "ttft": 5625.777221502546,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4177,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.507659615360435,
    "arrivals": 13527,
    "finished_requests": 13506,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4611491691321135. Arrivals time: 0.04556087777018547 Scheduler time: 1.00811606971547 Scheduler overhead time: 0.13922846969217062 Adapter cache time: 0.059834628365933895 Engine time: 0.14038176368921995 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-32/adapters_96_slots_32_rate_0.1-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-32/adapters_96_slots_32_rate_0.1-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 1080, 135, 135, 135, 135, 1080, 135, 1080, 135, 33, 1080, 33, 33, 1080, 135, 1080, 135, 1080, 1080, 135, 33, 1080, 135, 33, 33, 135, 1080, 33, 135, 33, 33, 135, 135, 135, 33, 33, 1080, 135, 135, 33, 1080, 1080, 135, 1080, 1080, 135, 1080, 33, 1080, 135, 135, 135, 1080, 1080, 33, 33, 135, 33, 1080, 33, 33, 1080, 33, 135, 135, 33, 135, 1080, 1080, 1080, 135, 1080, 1080, 33, 33, 1080, 135, 1080, 33, 135, 1080, 33, 1080, 135, 33, 1080, 33, 33, 1080, 33, 33, 135]
Prompts retrieved: 39936 . Total input tokens: 8825272 . Total output tokens: 8039205
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.464302934706211,
    "estimated_duration": 3599.975348206501,
    "input_throughput": 919.6065749864963,
    "output_throughput": 824.7548143570474,
    "total_throughput": 1744.3613893435438,
    "itl": 21.687441693453454,
    "ttft": 5891.8619735402835,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4178,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.555905259008417,
    "arrivals": 13527,
    "finished_requests": 13505,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4643770959228277. Arrivals time: 0.04581472696736455 Scheduler time: 1.011469489429146 Scheduler overhead time: 0.1399905220605433 Adapter cache time: 0.05971728591248393 Engine time: 0.1388655756600201 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-16/adapters_96_slots_32_rate_0.1-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-16/adapters_96_slots_32_rate_0.1-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 1080, 135, 135, 135, 135, 1080, 135, 1080, 135, 33, 1080, 33, 33, 1080, 135, 1080, 135, 1080, 1080, 135, 33, 1080, 135, 33, 33, 135, 1080, 33, 135, 33, 33, 135, 135, 135, 33, 33, 1080, 135, 135, 33, 1080, 1080, 135, 1080, 1080, 135, 1080, 33, 1080, 135, 135, 135, 1080, 1080, 33, 33, 135, 33, 1080, 33, 33, 1080, 33, 135, 135, 33, 135, 1080, 1080, 1080, 135, 1080, 1080, 33, 33, 1080, 135, 1080, 33, 135, 1080, 33, 1080, 135, 33, 1080, 33, 33, 1080, 33, 33, 135]
Prompts retrieved: 39936 . Total input tokens: 8825272 . Total output tokens: 8039205
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 1.4515858087688684,
    "estimated_duration": 3599.986011961125,
    "input_throughput": 919.6382955378414,
    "output_throughput": 824.7659824607293,
    "total_throughput": 1744.4042779985707,
    "itl": 21.683596015755718,
    "ttft": 5625.564487149796,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4174,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.008783677665862,
    "arrivals": 13527,
    "finished_requests": 13506,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.451662260107696. Arrivals time: 0.04539382876828313 Scheduler time: 0.9970761118456721 Scheduler overhead time: 0.13980775605887175 Adapter cache time: 0.06029079295694828 Engine time: 0.14063782896846533 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-32/adapters_96_slots_32_rate_0.1-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-32/adapters_96_slots_32_rate_0.1-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 1080, 135, 135, 135, 135, 1080, 135, 1080, 135, 33, 1080, 33, 33, 1080, 135, 1080, 135, 1080, 1080, 135, 33, 1080, 135, 33, 33, 135, 1080, 33, 135, 33, 33, 135, 135, 135, 33, 33, 1080, 135, 135, 33, 1080, 1080, 135, 1080, 1080, 135, 1080, 33, 1080, 135, 135, 135, 1080, 1080, 33, 33, 135, 33, 1080, 33, 33, 1080, 33, 135, 135, 33, 135, 1080, 1080, 1080, 135, 1080, 1080, 33, 33, 1080, 135, 1080, 33, 135, 1080, 33, 1080, 135, 33, 1080, 33, 33, 1080, 33, 33, 135]
Prompts retrieved: 39936 . Total input tokens: 8825272 . Total output tokens: 8039205
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 1.4330436470918357,
    "estimated_duration": 3599.9968405249056,
    "input_throughput": 919.6355293237641,
    "output_throughput": 824.763501616595,
    "total_throughput": 1744.3990309403591,
    "itl": 21.68840502577034,
    "ttft": 5625.523502079834,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4178,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.70689554262806,
    "arrivals": 13527,
    "finished_requests": 13506,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4331179792061448. Arrivals time: 0.04497909918427467 Scheduler time: 0.9848590716719627 Scheduler overhead time: 0.13833706034347415 Adapter cache time: 0.05945082614198327 Engine time: 0.13600265188142657 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-16/adapters_96_slots_32_rate_0.1-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-16/adapters_96_slots_32_rate_0.1-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 1080, 135, 135, 135, 135, 1080, 135, 1080, 135, 33, 1080, 33, 33, 1080, 135, 1080, 135, 1080, 1080, 135, 33, 1080, 135, 33, 33, 135, 1080, 33, 135, 33, 33, 135, 135, 135, 33, 33, 1080, 135, 135, 33, 1080, 1080, 135, 1080, 1080, 135, 1080, 33, 1080, 135, 135, 135, 1080, 1080, 33, 33, 135, 33, 1080, 33, 33, 1080, 33, 135, 135, 33, 135, 1080, 1080, 1080, 135, 1080, 1080, 33, 33, 1080, 135, 1080, 33, 135, 1080, 33, 1080, 135, 33, 1080, 33, 33, 1080, 33, 33, 135]
Prompts retrieved: 39936 . Total input tokens: 8825272 . Total output tokens: 8039205
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 1.4721207823604345,
    "estimated_duration": 3599.9825217713037,
    "input_throughput": 919.6047425172222,
    "output_throughput": 824.7531708957052,
    "total_throughput": 1744.3579134129275,
    "itl": 21.679361165909555,
    "ttft": 5891.663554615832,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4175,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.483459981217507,
    "arrivals": 13527,
    "finished_requests": 13505,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4721878422424197. Arrivals time: 0.045776668936014175 Scheduler time: 1.0164066045545042 Scheduler overhead time: 0.14061845652759075 Adapter cache time: 0.059598967898637056 Engine time: 0.1403659344650805 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-32/adapters_96_slots_32_rate_0.1-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-32/adapters_96_slots_32_rate_0.1-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 1080, 135, 135, 135, 135, 1080, 135, 1080, 135, 33, 1080, 33, 33, 1080, 135, 1080, 135, 1080, 1080, 135, 33, 1080, 135, 33, 33, 135, 1080, 33, 135, 33, 33, 135, 135, 135, 33, 33, 1080, 135, 135, 33, 1080, 1080, 135, 1080, 1080, 135, 1080, 33, 1080, 135, 135, 135, 1080, 1080, 33, 33, 135, 33, 1080, 33, 33, 1080, 33, 135, 135, 33, 135, 1080, 1080, 1080, 135, 1080, 1080, 33, 33, 1080, 135, 1080, 33, 135, 1080, 33, 1080, 135, 33, 1080, 33, 33, 1080, 33, 33, 135]
Prompts retrieved: 39936 . Total input tokens: 8825272 . Total output tokens: 8039205
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.488066816702485,
    "estimated_duration": 3599.979240137117,
    "input_throughput": 919.6055808016011,
    "output_throughput": 824.7539227162077,
    "total_throughput": 1744.359503517809,
    "itl": 21.69066045365086,
    "ttft": 5891.799615040636,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4177,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.866114422119196,
    "arrivals": 13527,
    "finished_requests": 13505,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4881705320440233. Arrivals time: 0.045693275053054094 Scheduler time: 1.029068592004478 Scheduler overhead time: 0.14246212411671877 Adapter cache time: 0.05960689950734377 Engine time: 0.14149059681221843 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-8/adapters_96_slots_32_rate_0.1-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-8/adapters_96_slots_32_rate_0.1-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 1080, 66, 66, 66, 66, 1080, 66, 1080, 66, 33, 1080, 33, 33, 1080, 66, 1080, 66, 1080, 1080, 66, 33, 1080, 66, 33, 33, 66, 1080, 33, 66, 33, 33, 66, 66, 66, 33, 33, 1080, 66, 66, 33, 1080, 1080, 66, 1080, 1080, 66, 1080, 33, 1080, 66, 66, 66, 1080, 1080, 33, 33, 66, 33, 1080, 33, 33, 1080, 33, 66, 66, 33, 66, 1080, 1080, 1080, 66, 1080, 1080, 33, 33, 1080, 66, 1080, 33, 66, 1080, 33, 1080, 66, 33, 1080, 33, 33, 1080, 33, 33, 66]
Prompts retrieved: 37728 . Total input tokens: 8336361 . Total output tokens: 7580355
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 1.4220108822919428,
    "estimated_duration": 3599.8340482404706,
    "input_throughput": 854.0957607484174,
    "output_throughput": 775.1749004551871,
    "total_throughput": 1629.2706612036045,
    "itl": 21.380286021354863,
    "ttft": 4844.224472472809,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2908,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.89989835935646,
    "arrivals": 12728,
    "finished_requests": 12711,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4221112662926316. Arrivals time: 0.04421974625438452 Scheduler time: 0.9705335656180978 Scheduler overhead time: 0.14027968887239695 Adapter cache time: 0.05661040311679244 Engine time: 0.1413012552075088 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-16/adapters_96_slots_32_rate_0.1-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-16/adapters_96_slots_32_rate_0.1-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 1080, 66, 66, 66, 66, 1080, 66, 1080, 66, 33, 1080, 33, 33, 1080, 66, 1080, 66, 1080, 1080, 66, 33, 1080, 66, 33, 33, 66, 1080, 33, 66, 33, 33, 66, 66, 66, 33, 33, 1080, 66, 66, 33, 1080, 1080, 66, 1080, 1080, 66, 1080, 33, 1080, 66, 66, 66, 1080, 1080, 33, 33, 66, 33, 1080, 33, 33, 1080, 33, 66, 66, 33, 66, 1080, 1080, 1080, 66, 1080, 1080, 33, 33, 1080, 66, 1080, 33, 66, 1080, 33, 1080, 66, 33, 1080, 33, 33, 1080, 33, 33, 66]
Prompts retrieved: 37728 . Total input tokens: 8336361 . Total output tokens: 7580355
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.3743407307192683,
    "estimated_duration": 3599.827037268705,
    "input_throughput": 854.0974241731325,
    "output_throughput": 775.1764101747609,
    "total_throughput": 1629.2738343478934,
    "itl": 21.38463997370356,
    "ttft": 4844.298148305746,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2905,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.416255940743637,
    "arrivals": 12728,
    "finished_requests": 12711,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3744152947328985. Arrivals time: 0.04306799406185746 Scheduler time: 0.9278079145587981 Scheduler overhead time: 0.14061237825080752 Adapter cache time: 0.054767945781350136 Engine time: 0.1391615541651845 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-32/adapters_96_slots_32_rate_0.1-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-32/adapters_96_slots_32_rate_0.1-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 1080, 66, 66, 66, 66, 1080, 66, 1080, 66, 33, 1080, 33, 33, 1080, 66, 1080, 66, 1080, 1080, 66, 33, 1080, 66, 33, 33, 66, 1080, 33, 66, 33, 33, 66, 66, 66, 33, 33, 1080, 66, 66, 33, 1080, 1080, 66, 1080, 1080, 66, 1080, 33, 1080, 66, 66, 66, 1080, 1080, 33, 33, 66, 33, 1080, 33, 33, 1080, 33, 66, 66, 33, 66, 1080, 1080, 1080, 66, 1080, 1080, 33, 33, 1080, 66, 1080, 33, 66, 1080, 33, 1080, 66, 33, 1080, 33, 33, 1080, 33, 33, 66]
Prompts retrieved: 37728 . Total input tokens: 8336361 . Total output tokens: 7580355
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.3694350370205939,
    "estimated_duration": 3599.817998485742,
    "input_throughput": 854.0995687263431,
    "output_throughput": 775.1783565651986,
    "total_throughput": 1629.2779252915418,
    "itl": 21.384483384805478,
    "ttft": 4844.180763921493,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2907,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.450845061074622,
    "arrivals": 12728,
    "finished_requests": 12711,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3695499347522855. Arrivals time: 0.04306994332000613 Scheduler time: 0.9190106210298836 Scheduler overhead time: 0.1417318983003497 Adapter cache time: 0.055179181043058634 Engine time: 0.14069854794070125 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-16/adapters_96_slots_32_rate_0.1-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-16/adapters_96_slots_32_rate_0.1-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 1080, 66, 66, 66, 66, 1080, 66, 1080, 66, 33, 1080, 33, 33, 1080, 66, 1080, 66, 1080, 1080, 66, 33, 1080, 66, 33, 33, 66, 1080, 33, 66, 33, 33, 66, 66, 66, 33, 33, 1080, 66, 66, 33, 1080, 1080, 66, 1080, 1080, 66, 1080, 33, 1080, 66, 66, 66, 1080, 1080, 33, 33, 66, 33, 1080, 33, 33, 1080, 33, 66, 66, 33, 66, 1080, 1080, 1080, 66, 1080, 1080, 33, 33, 1080, 66, 1080, 33, 66, 1080, 33, 1080, 66, 33, 1080, 33, 33, 1080, 33, 33, 66]
Prompts retrieved: 37728 . Total input tokens: 8336361 . Total output tokens: 7580355
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 1.3972164960578084,
    "estimated_duration": 3599.8375011860685,
    "input_throughput": 854.0949415041609,
    "output_throughput": 775.1741569114134,
    "total_throughput": 1629.2690984155745,
    "itl": 21.381606550339985,
    "ttft": 4844.149458033811,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2908,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.075877094361868,
    "arrivals": 12728,
    "finished_requests": 12711,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.397299698088318. Arrivals time: 0.043848037254065275 Scheduler time: 0.9440835355781019 Scheduler overhead time: 0.14152234885841608 Adapter cache time: 0.05558686191216111 Engine time: 0.14304441213607788 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-32/adapters_96_slots_32_rate_0.1-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-32/adapters_96_slots_32_rate_0.1-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 1080, 66, 66, 66, 66, 1080, 66, 1080, 66, 33, 1080, 33, 33, 1080, 66, 1080, 66, 1080, 1080, 66, 33, 1080, 66, 33, 33, 66, 1080, 33, 66, 33, 33, 66, 66, 66, 33, 33, 1080, 66, 66, 33, 1080, 1080, 66, 1080, 1080, 66, 1080, 33, 1080, 66, 66, 66, 1080, 1080, 33, 33, 66, 33, 1080, 33, 33, 1080, 33, 66, 66, 33, 66, 1080, 1080, 1080, 66, 1080, 1080, 33, 33, 1080, 66, 1080, 33, 66, 1080, 33, 1080, 66, 33, 1080, 33, 33, 1080, 33, 33, 66]
Prompts retrieved: 37728 . Total input tokens: 8336361 . Total output tokens: 7580355
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 1.3807763028889894,
    "estimated_duration": 3599.8311698839298,
    "input_throughput": 854.0964436671443,
    "output_throughput": 775.175520270295,
    "total_throughput": 1629.2719639374393,
    "itl": 21.38461668287987,
    "ttft": 4844.20259303429,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2904,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.548685250710282,
    "arrivals": 12728,
    "finished_requests": 12711,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3808489660732448. Arrivals time: 0.0434457715600729 Scheduler time: 0.9336045677773654 Scheduler overhead time: 0.1415805104188621 Adapter cache time: 0.055000629741698503 Engine time: 0.13823310798034072 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-16/adapters_96_slots_32_rate_0.1-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-16/adapters_96_slots_32_rate_0.1-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 1080, 66, 66, 66, 66, 1080, 66, 1080, 66, 33, 1080, 33, 33, 1080, 66, 1080, 66, 1080, 1080, 66, 33, 1080, 66, 33, 33, 66, 1080, 33, 66, 33, 33, 66, 66, 66, 33, 33, 1080, 66, 66, 33, 1080, 1080, 66, 1080, 1080, 66, 1080, 33, 1080, 66, 66, 66, 1080, 1080, 33, 33, 66, 33, 1080, 33, 33, 1080, 33, 66, 66, 33, 66, 1080, 1080, 1080, 66, 1080, 1080, 33, 33, 1080, 66, 1080, 33, 66, 1080, 33, 1080, 66, 33, 1080, 33, 33, 1080, 33, 33, 66]
Prompts retrieved: 37728 . Total input tokens: 8336361 . Total output tokens: 7580355
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 1.3694407120347023,
    "estimated_duration": 3599.82102862908,
    "input_throughput": 854.0988497894577,
    "output_throughput": 775.1777040601118,
    "total_throughput": 1629.2765538495696,
    "itl": 21.379446340146107,
    "ttft": 4844.1362886962315,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2908,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.69506625757546,
    "arrivals": 12728,
    "finished_requests": 12711,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3695517918094993. Arrivals time: 0.0433203661814332 Scheduler time: 0.920205460395664 Scheduler overhead time: 0.14157735742628574 Adapter cache time: 0.0553467208519578 Engine time: 0.1396385943517089 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-32/adapters_96_slots_32_rate_0.1-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-32/adapters_96_slots_32_rate_0.1-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 1080, 66, 66, 66, 66, 1080, 66, 1080, 66, 33, 1080, 33, 33, 1080, 66, 1080, 66, 1080, 1080, 66, 33, 1080, 66, 33, 33, 66, 1080, 33, 66, 33, 33, 66, 66, 66, 33, 33, 1080, 66, 66, 33, 1080, 1080, 66, 1080, 1080, 66, 1080, 33, 1080, 66, 66, 66, 1080, 1080, 33, 33, 66, 33, 1080, 33, 33, 1080, 33, 66, 66, 33, 66, 1080, 1080, 1080, 66, 1080, 1080, 33, 33, 1080, 66, 1080, 33, 66, 1080, 33, 1080, 66, 33, 1080, 33, 33, 1080, 33, 33, 66]
Prompts retrieved: 37728 . Total input tokens: 8336361 . Total output tokens: 7580355
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.3820679769851267,
    "estimated_duration": 3599.8174513524145,
    "input_throughput": 854.0996985402421,
    "output_throughput": 775.1784743839268,
    "total_throughput": 1629.2781729241688,
    "itl": 21.38692022982384,
    "ttft": 4844.272304410805,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2907,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.67674458753266,
    "arrivals": 12728,
    "finished_requests": 12711,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3821698827669024. Arrivals time: 0.04337675357237458 Scheduler time: 0.9328280659392476 Scheduler overhead time: 0.14108671294525266 Adapter cache time: 0.0550804054364562 Engine time: 0.14030559128150344 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-8/adapters_96_slots_32_rate_0.05-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-8/adapters_96_slots_32_rate_0.05-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 540, 270, 270, 270, 270, 540, 270, 540, 270, 135, 540, 135, 135, 540, 270, 540, 270, 540, 540, 270, 135, 540, 270, 135, 135, 270, 540, 135, 270, 135, 135, 270, 270, 270, 135, 135, 540, 270, 270, 135, 540, 540, 270, 540, 540, 270, 540, 135, 540, 270, 270, 270, 540, 540, 135, 135, 270, 135, 540, 135, 135, 540, 135, 270, 270, 135, 270, 540, 540, 540, 270, 540, 540, 135, 135, 540, 270, 540, 135, 270, 540, 135, 540, 270, 135, 540, 135, 135, 540, 135, 135, 270]
Prompts retrieved: 30240 . Total input tokens: 6671644 . Total output tokens: 6073603
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 1.2111778152175248,
    "estimated_duration": 3599.898443061169,
    "input_throughput": 688.5622022970722,
    "output_throughput": 616.962126884717,
    "total_throughput": 1305.5243291817892,
    "itl": 20.8638857758262,
    "ttft": 5343.483838905215,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5986,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 18.320079635180416,
    "arrivals": 10175,
    "finished_requests": 10160,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2112757000140846. Arrivals time: 0.03821327444165945 Scheduler time: 0.7612042799592018 Scheduler overhead time: 0.1417427584528923 Adapter cache time: 0.059702597092837095 Engine time: 0.14091033255681396 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-16/adapters_96_slots_32_rate_0.05-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-16/adapters_96_slots_32_rate_0.05-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 540, 270, 270, 270, 270, 540, 270, 540, 270, 135, 540, 135, 135, 540, 270, 540, 270, 540, 540, 270, 135, 540, 270, 135, 135, 270, 540, 135, 270, 135, 135, 270, 270, 270, 135, 135, 540, 270, 270, 135, 540, 540, 270, 540, 540, 270, 540, 135, 540, 270, 270, 270, 540, 540, 135, 135, 270, 135, 540, 135, 135, 540, 135, 270, 270, 135, 270, 540, 540, 540, 270, 540, 540, 135, 135, 540, 270, 540, 135, 270, 540, 135, 540, 270, 135, 540, 135, 135, 540, 135, 135, 270]
Prompts retrieved: 30240 . Total input tokens: 6671644 . Total output tokens: 6073603
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.2259766929782927,
    "estimated_duration": 3599.893507833266,
    "input_throughput": 688.5631462726054,
    "output_throughput": 616.9629727010438,
    "total_throughput": 1305.5261189736493,
    "itl": 20.871777590908426,
    "ttft": 5343.511668382219,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5985,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.422371720001,
    "arrivals": 10175,
    "finished_requests": 10160,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2260487261228263. Arrivals time: 0.03877427987754345 Scheduler time: 0.7678016084246337 Scheduler overhead time: 0.14360824041068554 Adapter cache time: 0.06060272268950939 Engine time: 0.1449917359277606 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-32/adapters_96_slots_32_rate_0.05-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-32/adapters_96_slots_32_rate_0.05-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 540, 270, 270, 270, 270, 540, 270, 540, 270, 135, 540, 135, 135, 540, 270, 540, 270, 540, 540, 270, 135, 540, 270, 135, 135, 270, 540, 135, 270, 135, 135, 270, 270, 270, 135, 135, 540, 270, 270, 135, 540, 540, 270, 540, 540, 270, 540, 135, 540, 270, 270, 270, 540, 540, 135, 135, 270, 135, 540, 135, 135, 540, 135, 270, 270, 135, 270, 540, 540, 540, 270, 540, 540, 135, 135, 540, 270, 540, 135, 270, 540, 135, 540, 270, 135, 540, 135, 135, 540, 135, 135, 270]
Prompts retrieved: 30240 . Total input tokens: 6671644 . Total output tokens: 6073603
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.2191039263270795,
    "estimated_duration": 3599.8970375222216,
    "input_throughput": 688.5624711383705,
    "output_throughput": 616.9623677705782,
    "total_throughput": 1305.5248389089486,
    "itl": 20.87155296787815,
    "ttft": 5343.547785423209,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5982,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.466623640376227,
    "arrivals": 10175,
    "finished_requests": 10160,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2191711352206767. Arrivals time: 0.03843448590487242 Scheduler time: 0.762550710234791 Scheduler overhead time: 0.14441363792866468 Adapter cache time: 0.059906842187047005 Engine time: 0.14327073702588677 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-16/adapters_96_slots_32_rate_0.05-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-16/adapters_96_slots_32_rate_0.05-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 540, 270, 270, 270, 270, 540, 270, 540, 270, 135, 540, 135, 135, 540, 270, 540, 270, 540, 540, 270, 135, 540, 270, 135, 135, 270, 540, 135, 270, 135, 135, 270, 270, 270, 135, 135, 540, 270, 270, 135, 540, 540, 270, 540, 540, 270, 540, 135, 540, 270, 270, 270, 540, 540, 135, 135, 270, 135, 540, 135, 135, 540, 135, 270, 270, 135, 270, 540, 540, 540, 270, 540, 540, 135, 135, 540, 270, 540, 135, 270, 540, 135, 540, 270, 135, 540, 135, 135, 540, 135, 135, 270]
Prompts retrieved: 30240 . Total input tokens: 6671644 . Total output tokens: 6073603
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 1.2222958817146719,
    "estimated_duration": 3599.883201173291,
    "input_throughput": 688.5651176660712,
    "output_throughput": 616.9647390993465,
    "total_throughput": 1305.5298567654177,
    "itl": 20.865948971341922,
    "ttft": 5343.403968238387,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5985,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 18.66524459493168,
    "arrivals": 10175,
    "finished_requests": 10160,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2223684065975249. Arrivals time: 0.03746236301958561 Scheduler time: 0.7710737092420459 Scheduler overhead time: 0.14290627976879478 Adapter cache time: 0.06022079847753048 Engine time: 0.14043502882122993 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-32/adapters_96_slots_32_rate_0.05-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-32/adapters_96_slots_32_rate_0.05-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 540, 270, 270, 270, 270, 540, 270, 540, 270, 135, 540, 135, 135, 540, 270, 540, 270, 540, 540, 270, 135, 540, 270, 135, 135, 270, 540, 135, 270, 135, 135, 270, 270, 270, 135, 135, 540, 270, 270, 135, 540, 540, 270, 540, 540, 270, 540, 135, 540, 270, 270, 270, 540, 540, 135, 135, 270, 135, 540, 135, 135, 540, 135, 270, 270, 135, 270, 540, 540, 540, 270, 540, 540, 135, 135, 540, 270, 540, 135, 270, 540, 135, 540, 270, 135, 540, 135, 135, 540, 135, 135, 270]
Prompts retrieved: 30240 . Total input tokens: 6671644 . Total output tokens: 6073603
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 1.2286542053334415,
    "estimated_duration": 3599.893796638506,
    "input_throughput": 688.5630910319079,
    "output_throughput": 616.9629232045448,
    "total_throughput": 1305.5260142364527,
    "itl": 20.873367654663554,
    "ttft": 5343.5024030223585,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5986,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.712493976986718,
    "arrivals": 10175,
    "finished_requests": 10160,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2287280960008502. Arrivals time: 0.038493537344038486 Scheduler time: 0.7731541548855603 Scheduler overhead time: 0.14157262817025185 Adapter cache time: 0.05988968815654516 Engine time: 0.14545326307415962 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-16/adapters_96_slots_32_rate_0.05-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-16/adapters_96_slots_32_rate_0.05-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 540, 270, 270, 270, 270, 540, 270, 540, 270, 135, 540, 135, 135, 540, 270, 540, 270, 540, 540, 270, 135, 540, 270, 135, 135, 270, 540, 135, 270, 135, 135, 270, 270, 270, 135, 135, 540, 270, 270, 135, 540, 540, 270, 540, 540, 270, 540, 135, 540, 270, 270, 270, 540, 540, 135, 135, 270, 135, 540, 135, 135, 540, 135, 270, 270, 135, 270, 540, 540, 540, 270, 540, 540, 135, 135, 540, 270, 540, 135, 270, 540, 135, 540, 270, 135, 540, 135, 135, 540, 135, 135, 270]
Prompts retrieved: 30240 . Total input tokens: 6671644 . Total output tokens: 6073603
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 1.239799308590591,
    "estimated_duration": 3599.8901369058694,
    "input_throughput": 688.5637910412751,
    "output_throughput": 616.9635504235042,
    "total_throughput": 1305.5273414647793,
    "itl": 20.679067343083254,
    "ttft": 5343.068155846991,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5953,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.799769405553896,
    "arrivals": 10175,
    "finished_requests": 10160,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2399028986692429. Arrivals time: 0.03830069303512573 Scheduler time: 0.7795764990150928 Scheduler overhead time: 0.1462889974936843 Adapter cache time: 0.060635811649262905 Engine time: 0.1441170098260045 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-32/adapters_96_slots_32_rate_0.05-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-32/adapters_96_slots_32_rate_0.05-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 540, 270, 270, 270, 270, 540, 270, 540, 270, 135, 540, 135, 135, 540, 270, 540, 270, 540, 540, 270, 135, 540, 270, 135, 135, 270, 540, 135, 270, 135, 135, 270, 270, 270, 135, 135, 540, 270, 270, 135, 540, 540, 270, 540, 540, 270, 540, 135, 540, 270, 270, 270, 540, 540, 135, 135, 270, 135, 540, 135, 135, 540, 135, 270, 270, 135, 270, 540, 540, 540, 270, 540, 540, 135, 135, 540, 270, 540, 135, 270, 540, 135, 540, 270, 135, 540, 135, 135, 540, 135, 135, 270]
Prompts retrieved: 30240 . Total input tokens: 6671644 . Total output tokens: 6073603
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.2202456030063331,
    "estimated_duration": 3599.8903591482126,
    "input_throughput": 688.5637485321942,
    "output_throughput": 616.9635123347261,
    "total_throughput": 1305.5272608669204,
    "itl": 20.87462322762013,
    "ttft": 5343.517126966702,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5983,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.939146057775552,
    "arrivals": 10175,
    "finished_requests": 10160,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.220340855885297. Arrivals time: 0.039534409530460835 Scheduler time: 0.7685265503823757 Scheduler overhead time: 0.1425818083807826 Adapter cache time: 0.060201034881174564 Engine time: 0.13955569174140692 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-8/adapters_96_slots_32_rate_0.05-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-8/adapters_96_slots_32_rate_0.05-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 540, 270, 270, 270, 270, 540, 270, 540, 270, 66, 540, 66, 66, 540, 270, 540, 270, 540, 540, 270, 66, 540, 270, 66, 66, 270, 540, 66, 270, 66, 66, 270, 270, 270, 66, 66, 540, 270, 270, 66, 540, 540, 270, 540, 540, 270, 540, 66, 540, 270, 270, 270, 540, 540, 66, 66, 270, 66, 540, 66, 66, 540, 66, 270, 270, 66, 270, 540, 540, 540, 270, 540, 540, 66, 66, 540, 270, 540, 66, 270, 540, 66, 540, 270, 66, 540, 66, 66, 540, 66, 66, 270]
Prompts retrieved: 28032 . Total input tokens: 6188869 . Total output tokens: 5619558
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 1.1761072240769863,
    "estimated_duration": 3599.988863834404,
    "input_throughput": 647.0833905632754,
    "output_throughput": 571.1673223927459,
    "total_throughput": 1218.2507129560213,
    "itl": 20.481990088767756,
    "ttft": 6102.372375561229,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5091,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.580943104359955,
    "arrivals": 9494,
    "finished_requests": 9478,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1761575168929994. Arrivals time: 0.03696663910523057 Scheduler time: 0.7212924649938941 Scheduler overhead time: 0.145845387596637 Adapter cache time: 0.05718250060454011 Engine time: 0.14299214025959373 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-16/adapters_96_slots_32_rate_0.05-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-16/adapters_96_slots_32_rate_0.05-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 540, 270, 270, 270, 270, 540, 270, 540, 270, 66, 540, 66, 66, 540, 270, 540, 270, 540, 540, 270, 66, 540, 270, 66, 66, 270, 540, 66, 270, 66, 66, 270, 270, 270, 66, 66, 540, 270, 270, 66, 540, 540, 270, 540, 540, 270, 540, 66, 540, 270, 270, 270, 540, 540, 66, 66, 270, 66, 540, 66, 66, 540, 66, 270, 270, 66, 270, 540, 540, 540, 270, 540, 540, 66, 66, 540, 270, 540, 66, 270, 540, 66, 540, 270, 66, 540, 66, 66, 540, 66, 66, 270]
Prompts retrieved: 28032 . Total input tokens: 6188869 . Total output tokens: 5619558
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.1796944891102612,
    "estimated_duration": 3599.9933881469224,
    "input_throughput": 647.1470219002857,
    "output_throughput": 571.2063268700862,
    "total_throughput": 1218.353348770372,
    "itl": 20.488879153091993,
    "ttft": 5723.283634924937,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5091,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.491851705742114,
    "arrivals": 9494,
    "finished_requests": 9479,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.17975535383448. Arrivals time: 0.036154522094875574 Scheduler time: 0.728024763520807 Scheduler overhead time: 0.14405853068456054 Adapter cache time: 0.05711773596704006 Engine time: 0.14304571924731135 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-32/adapters_96_slots_32_rate_0.05-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-32/adapters_96_slots_32_rate_0.05-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 540, 270, 270, 270, 270, 540, 270, 540, 270, 66, 540, 66, 66, 540, 270, 540, 270, 540, 540, 270, 66, 540, 270, 66, 66, 270, 540, 66, 270, 66, 66, 270, 270, 270, 66, 66, 540, 270, 270, 66, 540, 540, 270, 540, 540, 270, 540, 66, 540, 270, 270, 270, 540, 540, 66, 66, 270, 66, 540, 66, 66, 540, 66, 270, 270, 66, 270, 540, 540, 540, 270, 540, 540, 66, 66, 540, 270, 540, 66, 270, 540, 66, 540, 270, 66, 540, 66, 66, 540, 66, 66, 270]
Prompts retrieved: 28032 . Total input tokens: 6188869 . Total output tokens: 5619558
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.1837433399632573,
    "estimated_duration": 3599.989157087693,
    "input_throughput": 647.083337852191,
    "output_throughput": 571.1672758657458,
    "total_throughput": 1218.2506137179369,
    "itl": 20.489540447239314,
    "ttft": 6102.450651989964,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5093,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.548806709757578,
    "arrivals": 9494,
    "finished_requests": 9478,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1838208469562232. Arrivals time: 0.03707620734348893 Scheduler time: 0.7313017225824296 Scheduler overhead time: 0.14354714890941978 Adapter cache time: 0.057443500496447086 Engine time: 0.14219101890921593 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-16/adapters_96_slots_32_rate_0.05-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-16/adapters_96_slots_32_rate_0.05-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 540, 270, 270, 270, 270, 540, 270, 540, 270, 66, 540, 66, 66, 540, 270, 540, 270, 540, 540, 270, 66, 540, 270, 66, 66, 270, 540, 66, 270, 66, 66, 270, 270, 270, 66, 66, 540, 270, 270, 66, 540, 540, 270, 540, 540, 270, 540, 66, 540, 270, 270, 270, 540, 540, 66, 66, 270, 66, 540, 66, 66, 540, 66, 270, 270, 66, 270, 540, 540, 540, 270, 540, 540, 66, 66, 540, 270, 540, 66, 270, 540, 66, 540, 270, 66, 540, 66, 66, 540, 66, 66, 270]
Prompts retrieved: 28032 . Total input tokens: 6188869 . Total output tokens: 5619558
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 1.1700596790760756,
    "estimated_duration": 3599.991712484522,
    "input_throughput": 647.082878530381,
    "output_throughput": 571.1668704317442,
    "total_throughput": 1218.2497489621253,
    "itl": 20.483878345970737,
    "ttft": 6102.376369167629,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5089,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.873795818129134,
    "arrivals": 9494,
    "finished_requests": 9478,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1701332502998412. Arrivals time: 0.0363333816640079 Scheduler time: 0.7174283917993307 Scheduler overhead time: 0.14498044084757566 Adapter cache time: 0.05659971525892615 Engine time: 0.14305344969034195 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-32/adapters_96_slots_32_rate_0.05-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-32/adapters_96_slots_32_rate_0.05-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 540, 270, 270, 270, 270, 540, 270, 540, 270, 66, 540, 66, 66, 540, 270, 540, 270, 540, 540, 270, 66, 540, 270, 66, 66, 270, 540, 66, 270, 66, 66, 270, 270, 270, 66, 66, 540, 270, 270, 66, 540, 540, 270, 540, 540, 270, 540, 66, 540, 270, 270, 270, 540, 540, 66, 66, 270, 66, 540, 66, 66, 540, 66, 270, 270, 66, 270, 540, 540, 540, 270, 540, 540, 66, 66, 540, 270, 540, 66, 270, 540, 66, 540, 270, 66, 540, 66, 66, 540, 66, 66, 270]
Prompts retrieved: 28032 . Total input tokens: 6188869 . Total output tokens: 5619558
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 1.177155853714794,
    "estimated_duration": 3599.995996285008,
    "input_throughput": 647.1465530528768,
    "output_throughput": 571.205913040466,
    "total_throughput": 1218.3524660933429,
    "itl": 20.49069626749124,
    "ttft": 5723.219482016682,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5089,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.723622802569174,
    "arrivals": 9494,
    "finished_requests": 9479,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1772168409079313. Arrivals time: 0.03627737332135439 Scheduler time: 0.723925203550607 Scheduler overhead time: 0.14562923228368163 Adapter cache time: 0.05650858301669359 Engine time: 0.1434460561722517 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-16/adapters_96_slots_32_rate_0.05-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-16/adapters_96_slots_32_rate_0.05-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 540, 270, 270, 270, 270, 540, 270, 540, 270, 66, 540, 66, 66, 540, 270, 540, 270, 540, 540, 270, 66, 540, 270, 66, 66, 270, 540, 66, 270, 66, 66, 270, 270, 270, 66, 66, 540, 270, 270, 66, 540, 540, 270, 540, 540, 270, 540, 66, 540, 270, 270, 270, 540, 540, 66, 66, 270, 66, 540, 66, 66, 540, 66, 270, 270, 66, 270, 540, 540, 540, 270, 540, 540, 66, 66, 540, 270, 540, 66, 270, 540, 66, 540, 270, 66, 540, 66, 66, 540, 66, 66, 270]
Prompts retrieved: 28032 . Total input tokens: 6188869 . Total output tokens: 5619558
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 1.1715121832676232,
    "estimated_duration": 3599.9882237716874,
    "input_throughput": 647.0835056119721,
    "output_throughput": 571.1674239438859,
    "total_throughput": 1218.250929555858,
    "itl": 20.478421806776293,
    "ttft": 6102.32964010214,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5091,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.222346051348616,
    "arrivals": 9494,
    "finished_requests": 9478,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.171577824279666. Arrivals time: 0.036729070357978344 Scheduler time: 0.7196061881259084 Scheduler overhead time: 0.14427227014675736 Adapter cache time: 0.05682178772985935 Engine time: 0.1424717679619789 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-32/adapters_96_slots_32_rate_0.05-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-32/adapters_96_slots_32_rate_0.05-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 540, 270, 270, 270, 270, 540, 270, 540, 270, 66, 540, 66, 66, 540, 270, 540, 270, 540, 540, 270, 66, 540, 270, 66, 66, 270, 540, 66, 270, 66, 66, 270, 270, 270, 66, 66, 540, 270, 270, 66, 540, 540, 270, 540, 540, 270, 540, 66, 540, 270, 270, 270, 540, 540, 66, 66, 270, 66, 540, 66, 66, 540, 66, 270, 270, 66, 270, 540, 540, 540, 270, 540, 540, 66, 66, 540, 270, 540, 66, 270, 540, 66, 540, 270, 66, 540, 66, 66, 540, 66, 66, 270]
Prompts retrieved: 28032 . Total input tokens: 6188869 . Total output tokens: 5619558
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.1657503750175238,
    "estimated_duration": 3599.9821683481405,
    "input_throughput": 647.0845940520013,
    "output_throughput": 571.1683846877191,
    "total_throughput": 1218.2529787397204,
    "itl": 20.490107773433856,
    "ttft": 6102.568845655654,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5088,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.923042879848413,
    "arrivals": 9494,
    "finished_requests": 9478,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1658289306797087. Arrivals time: 0.03639447968453169 Scheduler time: 0.7142728930339217 Scheduler overhead time: 0.14529663091525435 Adapter cache time: 0.056570096872746944 Engine time: 0.14187202136963606 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-8/adapters_96_slots_32_rate_0.05-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-8/adapters_96_slots_32_rate_0.05-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 540, 270, 270, 270, 270, 540, 270, 540, 270, 33, 540, 33, 33, 540, 270, 540, 270, 540, 540, 270, 33, 540, 270, 33, 33, 270, 540, 33, 270, 33, 33, 270, 270, 270, 33, 33, 540, 270, 270, 33, 540, 540, 270, 540, 540, 270, 540, 33, 540, 270, 270, 270, 540, 540, 33, 33, 270, 33, 540, 33, 33, 540, 33, 270, 270, 33, 270, 540, 540, 540, 270, 540, 540, 33, 33, 540, 270, 540, 33, 270, 540, 33, 540, 270, 33, 540, 33, 33, 540, 33, 33, 270]
Prompts retrieved: 26976 . Total input tokens: 5949445 . Total output tokens: 5404596
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 1.1662080199457705,
    "estimated_duration": 3599.9423467785095,
    "input_throughput": 623.5758197652369,
    "output_throughput": 558.1117158162134,
    "total_throughput": 1181.6875355814504,
    "itl": 20.407869742468606,
    "ttft": 4784.408517897988,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4649,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.228207521542023,
    "arrivals": 9096,
    "finished_requests": 9084,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.166284965351224. Arrivals time: 0.036038470920175314 Scheduler time: 0.7100700978189707 Scheduler overhead time: 0.14559400407597423 Adapter cache time: 0.05596235813573003 Engine time: 0.14653828646987677 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-16/adapters_96_slots_32_rate_0.05-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-16/adapters_96_slots_32_rate_0.05-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 540, 270, 270, 270, 270, 540, 270, 540, 270, 33, 540, 33, 33, 540, 270, 540, 270, 540, 540, 270, 33, 540, 270, 33, 33, 270, 540, 33, 270, 33, 33, 270, 270, 270, 33, 33, 540, 270, 270, 33, 540, 540, 270, 540, 540, 270, 540, 33, 540, 270, 270, 270, 540, 540, 33, 33, 270, 33, 540, 33, 33, 540, 33, 270, 270, 33, 270, 540, 540, 540, 270, 540, 540, 33, 33, 540, 270, 540, 33, 270, 540, 33, 540, 270, 33, 540, 33, 33, 540, 33, 33, 270]
Prompts retrieved: 26976 . Total input tokens: 5949445 . Total output tokens: 5404596
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.156611813697964,
    "estimated_duration": 3599.9383596639213,
    "input_throughput": 623.5765104071312,
    "output_throughput": 558.1123339532874,
    "total_throughput": 1181.6888443604184,
    "itl": 20.412617003357337,
    "ttft": 4784.481025884947,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4651,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.008296900106194,
    "arrivals": 9096,
    "finished_requests": 9084,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1566699165850878. Arrivals time: 0.03511561593040824 Scheduler time: 0.705437873955816 Scheduler overhead time: 0.14618304232135415 Adapter cache time: 0.05507007008418441 Engine time: 0.14280434977263212 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-32/adapters_96_slots_32_rate_0.05-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-32/adapters_96_slots_32_rate_0.05-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 540, 270, 270, 270, 270, 540, 270, 540, 270, 33, 540, 33, 33, 540, 270, 540, 270, 540, 540, 270, 33, 540, 270, 33, 33, 270, 540, 33, 270, 33, 33, 270, 270, 270, 33, 33, 540, 270, 270, 33, 540, 540, 270, 540, 540, 270, 540, 33, 540, 270, 270, 270, 540, 540, 33, 33, 270, 33, 540, 33, 33, 540, 33, 270, 270, 33, 270, 540, 540, 540, 270, 540, 540, 33, 33, 540, 270, 540, 33, 270, 540, 33, 540, 270, 33, 540, 33, 33, 540, 33, 33, 270]
Prompts retrieved: 26976 . Total input tokens: 5949445 . Total output tokens: 5404596
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.1606769459322095,
    "estimated_duration": 3599.935147416477,
    "input_throughput": 623.577066828836,
    "output_throughput": 558.1128319608472,
    "total_throughput": 1181.6898987896832,
    "itl": 20.413219902487864,
    "ttft": 4784.543783123982,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4649,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.058538373148638,
    "arrivals": 9096,
    "finished_requests": 9084,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.160737448837608. Arrivals time: 0.03562629455700517 Scheduler time: 0.7096144584938884 Scheduler overhead time: 0.14494146639481187 Adapter cache time: 0.05500750569626689 Engine time: 0.1435861005447805 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-16/adapters_96_slots_32_rate_0.05-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-16/adapters_96_slots_32_rate_0.05-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 540, 270, 270, 270, 270, 540, 270, 540, 270, 33, 540, 33, 33, 540, 270, 540, 270, 540, 540, 270, 33, 540, 270, 33, 33, 270, 540, 33, 270, 33, 33, 270, 270, 270, 33, 33, 540, 270, 270, 33, 540, 540, 270, 540, 540, 270, 540, 33, 540, 270, 270, 270, 540, 540, 33, 33, 270, 33, 540, 33, 33, 540, 33, 270, 270, 33, 270, 540, 540, 540, 270, 540, 540, 33, 33, 540, 270, 540, 33, 270, 540, 33, 540, 270, 33, 540, 33, 33, 540, 33, 33, 270]
Prompts retrieved: 26976 . Total input tokens: 5949445 . Total output tokens: 5404596
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 1.160175882279873,
    "estimated_duration": 3599.929831532144,
    "input_throughput": 623.5779876422171,
    "output_throughput": 558.113656105594,
    "total_throughput": 1181.6916437478112,
    "itl": 20.409176525425806,
    "ttft": 4784.48986631004,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4648,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.466109858656983,
    "arrivals": 9096,
    "finished_requests": 9084,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1602912601083517. Arrivals time: 0.03590771974995732 Scheduler time: 0.7074478678405285 Scheduler overhead time: 0.1459993696771562 Adapter cache time: 0.05541127594187856 Engine time: 0.14352155942469835 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-32/adapters_96_slots_32_rate_0.05-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-32/adapters_96_slots_32_rate_0.05-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 540, 270, 270, 270, 270, 540, 270, 540, 270, 33, 540, 33, 33, 540, 270, 540, 270, 540, 540, 270, 33, 540, 270, 33, 33, 270, 540, 33, 270, 33, 33, 270, 270, 270, 33, 33, 540, 270, 270, 33, 540, 540, 270, 540, 540, 270, 540, 33, 540, 270, 270, 270, 540, 540, 33, 33, 270, 33, 540, 33, 33, 540, 33, 270, 270, 33, 270, 540, 540, 540, 270, 540, 540, 33, 33, 540, 270, 540, 33, 270, 540, 33, 540, 270, 33, 540, 33, 33, 540, 33, 33, 270]
Prompts retrieved: 26976 . Total input tokens: 5949445 . Total output tokens: 5404596
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 1.1587083572521806,
    "estimated_duration": 3599.9285248127353,
    "input_throughput": 623.5782139915609,
    "output_throughput": 558.1138586923792,
    "total_throughput": 1181.69207268394,
    "itl": 20.414521569360087,
    "ttft": 4784.500366655948,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4649,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.222647064420114,
    "arrivals": 9096,
    "finished_requests": 9084,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1587808690965176. Arrivals time: 0.035455476958304644 Scheduler time: 0.7083429507911205 Scheduler overhead time: 0.14547656569629908 Adapter cache time: 0.055035282392054796 Engine time: 0.1423600041307509 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-16/adapters_96_slots_32_rate_0.05-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-16/adapters_96_slots_32_rate_0.05-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 540, 270, 270, 270, 270, 540, 270, 540, 270, 33, 540, 33, 33, 540, 270, 540, 270, 540, 540, 270, 33, 540, 270, 33, 33, 270, 540, 33, 270, 33, 33, 270, 270, 270, 33, 33, 540, 270, 270, 33, 540, 540, 270, 540, 540, 270, 540, 33, 540, 270, 270, 270, 540, 540, 33, 33, 270, 33, 540, 33, 33, 540, 33, 270, 270, 33, 270, 540, 540, 540, 270, 540, 540, 33, 33, 540, 270, 540, 33, 270, 540, 33, 540, 270, 33, 540, 33, 33, 540, 33, 33, 270]
Prompts retrieved: 26976 . Total input tokens: 5949445 . Total output tokens: 5404596
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 1.1688548922538757,
    "estimated_duration": 3599.928759020392,
    "input_throughput": 623.5781734222046,
    "output_throughput": 558.1138223820665,
    "total_throughput": 1181.691995804271,
    "itl": 20.405105450636572,
    "ttft": 4784.506284329408,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4648,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.897753770706606,
    "arrivals": 9096,
    "finished_requests": 9084,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1689270911738276. Arrivals time: 0.03636400494724512 Scheduler time: 0.7130076070316136 Scheduler overhead time: 0.14561003679409623 Adapter cache time: 0.05579968122765422 Engine time: 0.1455306769348681 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-32/adapters_96_slots_32_rate_0.05-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-32/adapters_96_slots_32_rate_0.05-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 540, 270, 270, 270, 270, 540, 270, 540, 270, 33, 540, 33, 33, 540, 270, 540, 270, 540, 540, 270, 33, 540, 270, 33, 33, 270, 540, 33, 270, 33, 33, 270, 270, 270, 33, 33, 540, 270, 270, 33, 540, 540, 270, 540, 540, 270, 540, 33, 540, 270, 270, 270, 540, 540, 33, 33, 270, 33, 540, 33, 33, 540, 33, 270, 270, 33, 270, 540, 540, 540, 270, 540, 540, 33, 33, 540, 270, 540, 33, 270, 540, 33, 540, 270, 33, 540, 33, 33, 540, 33, 33, 270]
Prompts retrieved: 26976 . Total input tokens: 5949445 . Total output tokens: 5404596
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.161931088194251,
    "estimated_duration": 3599.9267987869275,
    "input_throughput": 623.578512973221,
    "output_throughput": 558.1141262864103,
    "total_throughput": 1181.6926392596313,
    "itl": 20.417388252483295,
    "ttft": 4784.447054620985,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4647,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.39148354362584,
    "arrivals": 9096,
    "finished_requests": 9084,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1620267303660512. Arrivals time: 0.03524692542850971 Scheduler time: 0.7093303520232439 Scheduler overhead time: 0.148282200563699 Adapter cache time: 0.055139660369604826 Engine time: 0.1415110994130373 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-8/adapters_96_slots_32_rate_0.05-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-8/adapters_96_slots_32_rate_0.05-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 540, 135, 135, 135, 135, 540, 135, 540, 135, 66, 540, 66, 66, 540, 135, 540, 135, 540, 540, 135, 66, 540, 135, 66, 66, 135, 540, 66, 135, 66, 66, 135, 135, 135, 66, 66, 540, 135, 135, 66, 540, 540, 135, 540, 540, 135, 540, 66, 540, 135, 135, 135, 540, 540, 66, 66, 135, 66, 540, 66, 66, 540, 66, 135, 135, 66, 135, 540, 540, 540, 135, 540, 540, 66, 66, 540, 135, 540, 66, 135, 540, 66, 540, 135, 66, 540, 66, 66, 540, 66, 66, 135]
Prompts retrieved: 23712 . Total input tokens: 5233067 . Total output tokens: 4747550
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 1.0941833960823715,
    "estimated_duration": 3599.8361026211714,
    "input_throughput": 543.1419498727545,
    "output_throughput": 491.5468231210781,
    "total_throughput": 1034.6887729938326,
    "itl": 19.98415704352334,
    "ttft": 5399.355303077524,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3822,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.697184157310282,
    "arrivals": 8052,
    "finished_requests": 8040,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0942457490600646. Arrivals time: 0.0340783828869462 Scheduler time: 0.6437988798134029 Scheduler overhead time: 0.1466951477341354 Adapter cache time: 0.05136403441429138 Engine time: 0.1451944042928517 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-16/adapters_96_slots_32_rate_0.05-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-16/adapters_96_slots_32_rate_0.05-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 540, 135, 135, 135, 135, 540, 135, 540, 135, 66, 540, 66, 66, 540, 135, 540, 135, 540, 540, 135, 66, 540, 135, 66, 66, 135, 540, 66, 135, 66, 66, 135, 135, 135, 66, 66, 540, 135, 135, 66, 540, 540, 135, 540, 540, 135, 540, 66, 540, 135, 135, 135, 540, 540, 66, 66, 135, 66, 540, 66, 66, 540, 66, 135, 135, 66, 135, 540, 540, 540, 135, 540, 540, 66, 66, 540, 135, 540, 66, 135, 540, 66, 540, 135, 66, 540, 66, 66, 540, 66, 66, 135]
Prompts retrieved: 23712 . Total input tokens: 5233067 . Total output tokens: 4747550
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.0885711992159486,
    "estimated_duration": 3599.8202114757473,
    "input_throughput": 543.1443475335276,
    "output_throughput": 491.54899301890356,
    "total_throughput": 1034.6933405524312,
    "itl": 19.988732812397107,
    "ttft": 5399.406353200908,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3818,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.36763052258455,
    "arrivals": 8052,
    "finished_requests": 8040,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0886426931247115. Arrivals time: 0.03329550148919225 Scheduler time: 0.6361925965175033 Scheduler overhead time: 0.14701668825000525 Adapter cache time: 0.05138643737882376 Engine time: 0.1480804025195539 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-32/adapters_96_slots_32_rate_0.05-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-32/adapters_96_slots_32_rate_0.05-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 540, 135, 135, 135, 135, 540, 135, 540, 135, 66, 540, 66, 66, 540, 135, 540, 135, 540, 540, 135, 66, 540, 135, 66, 66, 135, 540, 66, 135, 66, 66, 135, 135, 135, 66, 66, 540, 135, 135, 66, 540, 540, 135, 540, 540, 135, 540, 66, 540, 135, 135, 135, 540, 540, 66, 66, 135, 66, 540, 66, 66, 540, 66, 135, 135, 66, 135, 540, 540, 540, 135, 540, 540, 66, 66, 540, 135, 540, 66, 135, 540, 66, 540, 135, 66, 540, 66, 66, 540, 66, 66, 135]
Prompts retrieved: 23712 . Total input tokens: 5233067 . Total output tokens: 4747550
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.0928790336474776,
    "estimated_duration": 3599.825708010345,
    "input_throughput": 543.1435182123492,
    "output_throughput": 491.54824247810916,
    "total_throughput": 1034.6917606904585,
    "itl": 19.989650539949594,
    "ttft": 5399.615416776742,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3819,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.40864789819262,
    "arrivals": 8052,
    "finished_requests": 8040,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0929742278531194. Arrivals time: 0.03350190306082368 Scheduler time: 0.6403809720650315 Scheduler overhead time: 0.14720185473561287 Adapter cache time: 0.05118511663749814 Engine time: 0.1480741803534329 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-16/adapters_96_slots_32_rate_0.05-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-16/adapters_96_slots_32_rate_0.05-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 540, 135, 135, 135, 135, 540, 135, 540, 135, 66, 540, 66, 66, 540, 135, 540, 135, 540, 540, 135, 66, 540, 135, 66, 66, 135, 540, 66, 135, 66, 66, 135, 135, 135, 66, 66, 540, 135, 135, 66, 540, 540, 135, 540, 540, 135, 540, 66, 540, 135, 135, 135, 540, 540, 66, 66, 135, 66, 540, 66, 66, 540, 66, 135, 135, 66, 135, 540, 540, 540, 135, 540, 540, 66, 66, 540, 135, 540, 66, 135, 540, 66, 540, 135, 66, 540, 66, 66, 540, 66, 66, 135]
Prompts retrieved: 23712 . Total input tokens: 5233067 . Total output tokens: 4747550
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 1.089812961872667,
    "estimated_duration": 3599.8360331877084,
    "input_throughput": 543.14196034885,
    "output_throughput": 491.5468326020094,
    "total_throughput": 1034.6887929508594,
    "itl": 19.985860038687395,
    "ttft": 5399.376500598476,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3821,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.903855890033869,
    "arrivals": 8052,
    "finished_requests": 8040,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0898677720688283. Arrivals time: 0.033650849014520645 Scheduler time: 0.6370978029444814 Scheduler overhead time: 0.14616819377988577 Adapter cache time: 0.051433907356113195 Engine time: 0.14855167735368013 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-32/adapters_96_slots_32_rate_0.05-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-32/adapters_96_slots_32_rate_0.05-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 540, 135, 135, 135, 135, 540, 135, 540, 135, 66, 540, 66, 66, 540, 135, 540, 135, 540, 540, 135, 66, 540, 135, 66, 66, 135, 540, 66, 135, 66, 66, 135, 135, 135, 66, 66, 540, 135, 135, 66, 540, 540, 135, 540, 540, 135, 540, 66, 540, 135, 135, 135, 540, 540, 66, 66, 135, 66, 540, 66, 66, 540, 66, 135, 135, 66, 135, 540, 540, 540, 135, 540, 540, 66, 66, 540, 135, 540, 66, 135, 540, 66, 540, 135, 66, 540, 66, 66, 540, 66, 66, 135]
Prompts retrieved: 23712 . Total input tokens: 5233067 . Total output tokens: 4747550
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 1.0888261422514915,
    "estimated_duration": 3599.838653843489,
    "input_throughput": 543.1415649455404,
    "output_throughput": 491.5464747595692,
    "total_throughput": 1034.6880397051095,
    "itl": 19.9904274573656,
    "ttft": 5399.411068088205,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3818,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.551101510225894,
    "arrivals": 8052,
    "finished_requests": 8040,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0889002061448991. Arrivals time: 0.03308512829244137 Scheduler time: 0.6394739630632102 Scheduler overhead time: 0.1477702264674008 Adapter cache time: 0.051018097903579473 Engine time: 0.14457850949838758 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-16/adapters_96_slots_32_rate_0.05-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-16/adapters_96_slots_32_rate_0.05-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 540, 135, 135, 135, 135, 540, 135, 540, 135, 66, 540, 66, 66, 540, 135, 540, 135, 540, 540, 135, 66, 540, 135, 66, 66, 135, 540, 66, 135, 66, 66, 135, 135, 135, 66, 66, 540, 135, 135, 66, 540, 540, 135, 540, 540, 135, 540, 66, 540, 135, 135, 135, 540, 540, 66, 66, 135, 66, 540, 66, 66, 540, 66, 135, 135, 66, 135, 540, 540, 540, 135, 540, 540, 66, 66, 540, 135, 540, 66, 135, 540, 66, 540, 135, 66, 540, 66, 66, 540, 66, 66, 135]
Prompts retrieved: 23712 . Total input tokens: 5233067 . Total output tokens: 4747550
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 1.0991241661831737,
    "estimated_duration": 3599.824716843078,
    "input_throughput": 543.1436677602076,
    "output_throughput": 491.5483778198456,
    "total_throughput": 1034.6920455800532,
    "itl": 19.982447416070986,
    "ttft": 5399.329903678003,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3820,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.421992126526957,
    "arrivals": 8052,
    "finished_requests": 8040,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.099195112939924. Arrivals time: 0.03311608266085386 Scheduler time: 0.6495056431740522 Scheduler overhead time: 0.14662497816607356 Adapter cache time: 0.05071669118478894 Engine time: 0.14631430944427848 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-32/adapters_96_slots_32_rate_0.05-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-32/adapters_96_slots_32_rate_0.05-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 540, 135, 135, 135, 135, 540, 135, 540, 135, 66, 540, 66, 66, 540, 135, 540, 135, 540, 540, 135, 66, 540, 135, 66, 66, 135, 540, 66, 135, 66, 66, 135, 135, 135, 66, 66, 540, 135, 135, 66, 540, 540, 135, 540, 540, 135, 540, 66, 540, 135, 135, 135, 540, 540, 66, 66, 135, 66, 540, 66, 66, 540, 66, 135, 135, 66, 135, 540, 540, 540, 135, 540, 540, 66, 66, 540, 135, 540, 66, 135, 540, 66, 540, 135, 66, 540, 66, 66, 540, 66, 66, 135]
Prompts retrieved: 23712 . Total input tokens: 5233067 . Total output tokens: 4747550
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.0950406482443213,
    "estimated_duration": 3599.834246691534,
    "input_throughput": 543.1422298948813,
    "output_throughput": 491.54707654283436,
    "total_throughput": 1034.6893064377157,
    "itl": 19.990155811890133,
    "ttft": 5399.563619850546,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3819,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.70152846675283,
    "arrivals": 8052,
    "finished_requests": 8040,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0950926202349365. Arrivals time: 0.0336775342002511 Scheduler time: 0.6446600165218115 Scheduler overhead time: 0.14702715910971165 Adapter cache time: 0.050625747069716454 Engine time: 0.1463261409662664 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-8/adapters_96_slots_32_rate_0.05-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-8/adapters_96_slots_32_rate_0.05-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 540, 135, 135, 135, 135, 540, 135, 540, 135, 33, 540, 33, 33, 540, 135, 540, 135, 540, 540, 135, 33, 540, 135, 33, 33, 135, 540, 33, 135, 33, 33, 135, 135, 135, 33, 33, 540, 135, 135, 33, 540, 540, 135, 540, 540, 135, 540, 33, 540, 135, 135, 135, 540, 540, 33, 33, 135, 33, 540, 33, 33, 540, 33, 135, 135, 33, 135, 540, 540, 540, 135, 540, 540, 33, 33, 540, 135, 540, 33, 135, 540, 33, 540, 135, 33, 540, 33, 33, 540, 33, 33, 135]
Prompts retrieved: 22656 . Total input tokens: 5005309 . Total output tokens: 4536837
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 1.0592610789462924,
    "estimated_duration": 3599.4346308487807,
    "input_throughput": 517.6326815416129,
    "output_throughput": 465.54200085718935,
    "total_throughput": 983.1746823988022,
    "itl": 19.758196151315484,
    "ttft": 6634.044686252252,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3137,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.600750052716881,
    "arrivals": 7636,
    "finished_requests": 7622,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0593354511074722. Arrivals time: 0.03212335333228111 Scheduler time: 0.6056682607159019 Scheduler overhead time: 0.14720436790958047 Adapter cache time: 0.049036015290766954 Engine time: 0.15170986903831363 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-16/adapters_96_slots_32_rate_0.05-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-16/adapters_96_slots_32_rate_0.05-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 540, 135, 135, 135, 135, 540, 135, 540, 135, 33, 540, 33, 33, 540, 135, 540, 135, 540, 540, 135, 33, 540, 135, 33, 33, 135, 540, 33, 135, 33, 33, 135, 135, 135, 33, 33, 540, 135, 135, 33, 540, 540, 135, 540, 540, 135, 540, 33, 540, 135, 135, 135, 540, 540, 33, 33, 135, 33, 540, 33, 33, 540, 33, 135, 135, 33, 135, 540, 540, 540, 135, 540, 540, 33, 33, 540, 135, 540, 33, 135, 540, 33, 540, 135, 33, 540, 33, 33, 540, 33, 33, 135]
Prompts retrieved: 22656 . Total input tokens: 5005309 . Total output tokens: 4536837
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.0715829501859844,
    "estimated_duration": 3599.437701014442,
    "input_throughput": 517.6322400231825,
    "output_throughput": 465.5416037698708,
    "total_throughput": 983.1738437930533,
    "itl": 19.762005538603255,
    "ttft": 6633.9372556207,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3137,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.155710284826403,
    "arrivals": 7636,
    "finished_requests": 7622,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0717200501821935. Arrivals time: 0.03215020848438144 Scheduler time: 0.6214932724833488 Scheduler overhead time: 0.14818909484893084 Adapter cache time: 0.04907037690281868 Engine time: 0.14629428600892425 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-32/adapters_96_slots_32_rate_0.05-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-32/adapters_96_slots_32_rate_0.05-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 540, 135, 135, 135, 135, 540, 135, 540, 135, 33, 540, 33, 33, 540, 135, 540, 135, 540, 540, 135, 33, 540, 135, 33, 33, 135, 540, 33, 135, 33, 33, 135, 135, 135, 33, 33, 540, 135, 135, 33, 540, 540, 135, 540, 540, 135, 540, 33, 540, 135, 135, 135, 540, 540, 33, 33, 135, 33, 540, 33, 33, 540, 33, 135, 135, 33, 135, 540, 540, 540, 135, 540, 540, 33, 33, 540, 135, 540, 33, 135, 540, 33, 540, 135, 33, 540, 33, 33, 540, 33, 33, 135]
Prompts retrieved: 22656 . Total input tokens: 5005309 . Total output tokens: 4536837
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.0649190279655159,
    "estimated_duration": 3599.4370649446805,
    "input_throughput": 517.6323314958794,
    "output_throughput": 465.5416860374397,
    "total_throughput": 983.1740175333191,
    "itl": 19.761330570881945,
    "ttft": 6634.027631200282,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3138,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.190995139535062,
    "arrivals": 7636,
    "finished_requests": 7622,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0649825669825077. Arrivals time: 0.032472372986376286 Scheduler time: 0.6142284153029323 Scheduler overhead time: 0.14779026433825493 Adapter cache time: 0.04900835873559117 Engine time: 0.14815646782517433 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-16/adapters_96_slots_32_rate_0.05-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-16/adapters_96_slots_32_rate_0.05-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 540, 135, 135, 135, 135, 540, 135, 540, 135, 33, 540, 33, 33, 540, 135, 540, 135, 540, 540, 135, 33, 540, 135, 33, 33, 135, 540, 33, 135, 33, 33, 135, 135, 135, 33, 33, 540, 135, 135, 33, 540, 540, 135, 540, 540, 135, 540, 33, 540, 135, 135, 135, 540, 540, 33, 33, 135, 33, 540, 33, 33, 540, 33, 135, 135, 33, 135, 540, 540, 540, 135, 540, 540, 33, 33, 540, 135, 540, 33, 135, 540, 33, 540, 135, 33, 540, 33, 33, 540, 33, 33, 135]
Prompts retrieved: 22656 . Total input tokens: 5005309 . Total output tokens: 4536837
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 1.0670860786922276,
    "estimated_duration": 3599.4277277118713,
    "input_throughput": 517.6336742797757,
    "output_throughput": 465.54289369361004,
    "total_throughput": 983.1765679733858,
    "itl": 19.7583589227971,
    "ttft": 6634.007524644669,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3137,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.783888545045723,
    "arrivals": 7636,
    "finished_requests": 7622,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0671366546303034. Arrivals time: 0.03203916037455201 Scheduler time: 0.6184211154468358 Scheduler overhead time: 0.1472610356286168 Adapter cache time: 0.04840955417603254 Engine time: 0.14773176982998848 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-32/adapters_96_slots_32_rate_0.05-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-32/adapters_96_slots_32_rate_0.05-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 540, 135, 135, 135, 135, 540, 135, 540, 135, 33, 540, 33, 33, 540, 135, 540, 135, 540, 540, 135, 33, 540, 135, 33, 33, 135, 540, 33, 135, 33, 33, 135, 135, 135, 33, 33, 540, 135, 135, 33, 540, 540, 135, 540, 540, 135, 540, 33, 540, 135, 135, 135, 540, 540, 33, 33, 135, 33, 540, 33, 33, 540, 33, 135, 135, 33, 135, 540, 540, 540, 135, 540, 540, 33, 33, 540, 135, 540, 33, 135, 540, 33, 540, 135, 33, 540, 33, 33, 540, 33, 33, 135]
Prompts retrieved: 22656 . Total input tokens: 5005309 . Total output tokens: 4536837
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 1.0757118999026716,
    "estimated_duration": 3599.427781014022,
    "input_throughput": 517.633666614394,
    "output_throughput": 465.5428867996149,
    "total_throughput": 983.1765534140088,
    "itl": 19.762184496809866,
    "ttft": 6634.149752026634,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3137,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.302050318829194,
    "arrivals": 7636,
    "finished_requests": 7622,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0757714631035924. Arrivals time: 0.032364058773964643 Scheduler time: 0.6227080742828548 Scheduler overhead time: 0.1469372953288257 Adapter cache time: 0.04870482021942735 Engine time: 0.151122878305614 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-16/adapters_96_slots_32_rate_0.05-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-16/adapters_96_slots_32_rate_0.05-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 540, 135, 135, 135, 135, 540, 135, 540, 135, 33, 540, 33, 33, 540, 135, 540, 135, 540, 540, 135, 33, 540, 135, 33, 33, 135, 540, 33, 135, 33, 33, 135, 135, 135, 33, 33, 540, 135, 135, 33, 540, 540, 135, 540, 540, 135, 540, 33, 540, 135, 135, 135, 540, 540, 33, 33, 135, 33, 540, 33, 33, 540, 33, 135, 135, 33, 135, 540, 540, 540, 135, 540, 540, 33, 33, 540, 135, 540, 33, 135, 540, 33, 540, 135, 33, 540, 33, 33, 540, 33, 33, 135]
Prompts retrieved: 22656 . Total input tokens: 5005309 . Total output tokens: 4536837
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 1.0659422567114234,
    "estimated_duration": 3599.438575143619,
    "input_throughput": 517.6321143153993,
    "output_throughput": 465.5414907123785,
    "total_throughput": 983.1736050277779,
    "itl": 19.75646836810285,
    "ttft": 6633.917923468252,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3137,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.379787775108237,
    "arrivals": 7636,
    "finished_requests": 7622,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0660125496797264. Arrivals time: 0.03204176528379321 Scheduler time: 0.6195981637574732 Scheduler overhead time: 0.1469016019254923 Adapter cache time: 0.04846403654664755 Engine time: 0.14599158009514213 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-32/adapters_96_slots_32_rate_0.05-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-32/adapters_96_slots_32_rate_0.05-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 540, 135, 135, 135, 135, 540, 135, 540, 135, 33, 540, 33, 33, 540, 135, 540, 135, 540, 540, 135, 33, 540, 135, 33, 33, 135, 540, 33, 135, 33, 33, 135, 135, 135, 33, 33, 540, 135, 135, 33, 540, 540, 135, 540, 540, 135, 540, 33, 540, 135, 135, 135, 540, 540, 33, 33, 135, 33, 540, 33, 33, 540, 33, 135, 135, 33, 135, 540, 540, 540, 135, 540, 540, 33, 33, 540, 135, 540, 33, 135, 540, 33, 540, 135, 33, 540, 33, 33, 540, 33, 33, 135]
Prompts retrieved: 22656 . Total input tokens: 5005309 . Total output tokens: 4536837
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.0564523860812187,
    "estimated_duration": 3599.441222452305,
    "input_throughput": 517.6317336085319,
    "output_throughput": 465.5411483170022,
    "total_throughput": 983.172881925534,
    "itl": 19.762362160774238,
    "ttft": 6634.259581381105,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3136,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.423251540958281,
    "arrivals": 7636,
    "finished_requests": 7622,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.056504073087126. Arrivals time: 0.032428789883852005 Scheduler time: 0.6088169915601611 Scheduler overhead time: 0.1476632277481258 Adapter cache time: 0.048246150836348534 Engine time: 0.1461032866500318 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-8/adapters_96_slots_32_rate_0.05-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-8/adapters_96_slots_32_rate_0.05-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 540, 66, 66, 66, 66, 540, 66, 540, 66, 33, 540, 33, 33, 540, 66, 540, 66, 540, 540, 66, 33, 540, 66, 33, 33, 66, 540, 33, 66, 33, 33, 66, 66, 66, 33, 33, 540, 66, 66, 33, 540, 540, 66, 540, 540, 66, 540, 33, 540, 66, 66, 66, 540, 540, 33, 33, 66, 33, 540, 33, 33, 540, 33, 66, 66, 33, 66, 540, 540, 540, 66, 540, 540, 33, 33, 540, 66, 540, 33, 66, 540, 33, 540, 66, 33, 540, 33, 33, 540, 33, 33, 66]
Prompts retrieved: 20448 . Total input tokens: 4537851 . Total output tokens: 4108920
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 1.0111354957334697,
    "estimated_duration": 3599.3613809382923,
    "input_throughput": 471.83953492251914,
    "output_throughput": 422.4127113359352,
    "total_throughput": 894.2522462584543,
    "itl": 19.5229409860679,
    "ttft": 5217.348539077378,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2357,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.2135696124497155,
    "arrivals": 6944,
    "finished_requests": 6934,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0111952750012279. Arrivals time: 0.030378625262528658 Scheduler time: 0.5667931800708175 Scheduler overhead time: 0.14693104475736618 Adapter cache time: 0.04557938175275922 Engine time: 0.1478884886018932 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-16/adapters_96_slots_32_rate_0.05-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-16/adapters_96_slots_32_rate_0.05-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 540, 66, 66, 66, 66, 540, 66, 540, 66, 33, 540, 33, 33, 540, 66, 540, 66, 540, 540, 66, 33, 540, 66, 33, 33, 66, 540, 33, 66, 33, 33, 66, 66, 66, 33, 33, 540, 66, 66, 33, 540, 540, 66, 540, 540, 66, 540, 33, 540, 66, 66, 66, 540, 540, 33, 33, 66, 33, 540, 33, 33, 540, 33, 66, 66, 33, 66, 540, 540, 540, 66, 540, 540, 33, 33, 540, 66, 540, 33, 66, 540, 33, 540, 66, 33, 540, 33, 33, 540, 33, 33, 66]
Prompts retrieved: 20448 . Total input tokens: 4537851 . Total output tokens: 4108920
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.0161433769389987,
    "estimated_duration": 3599.3486408659683,
    "input_throughput": 471.8412050218621,
    "output_throughput": 422.41420648659437,
    "total_throughput": 894.2554115084565,
    "itl": 19.52599430958122,
    "ttft": 5217.4589937546225,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2357,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.6363343989566514,
    "arrivals": 6944,
    "finished_requests": 6934,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0162519118748605. Arrivals time: 0.031000378541648388 Scheduler time: 0.5679489127360284 Scheduler overhead time: 0.14840509602800012 Adapter cache time: 0.04550950601696968 Engine time: 0.14941473165526986 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-32/adapters_96_slots_32_rate_0.05-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-32/adapters_96_slots_32_rate_0.05-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 540, 66, 66, 66, 66, 540, 66, 540, 66, 33, 540, 33, 33, 540, 66, 540, 66, 540, 540, 66, 33, 540, 66, 33, 33, 66, 540, 33, 66, 33, 33, 66, 66, 66, 33, 33, 540, 66, 66, 33, 540, 540, 66, 540, 540, 66, 540, 33, 540, 66, 66, 66, 540, 540, 33, 33, 66, 33, 540, 33, 33, 540, 33, 66, 66, 33, 66, 540, 540, 540, 66, 540, 540, 33, 33, 540, 66, 540, 33, 66, 540, 33, 540, 66, 33, 540, 33, 33, 540, 33, 33, 66]
Prompts retrieved: 20448 . Total input tokens: 4537851 . Total output tokens: 4108920
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.0102797979488969,
    "estimated_duration": 3599.3529723107113,
    "input_throughput": 471.8406372103352,
    "output_throughput": 422.41369815528924,
    "total_throughput": 894.2543353656245,
    "itl": 19.526318127807514,
    "ttft": 5217.474388120746,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2357,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.659547566156765,
    "arrivals": 6944,
    "finished_requests": 6934,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0103302081115544. Arrivals time: 0.03070941101759672 Scheduler time: 0.5629324456676841 Scheduler overhead time: 0.14743210980668664 Adapter cache time: 0.04584450088441372 Engine time: 0.15001202607527375 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-16/adapters_96_slots_32_rate_0.05-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-16/adapters_96_slots_32_rate_0.05-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 540, 66, 66, 66, 66, 540, 66, 540, 66, 33, 540, 33, 33, 540, 66, 540, 66, 540, 540, 66, 33, 540, 66, 33, 33, 66, 540, 33, 66, 33, 33, 66, 66, 66, 33, 33, 540, 66, 66, 33, 540, 540, 66, 540, 540, 66, 540, 33, 540, 66, 66, 66, 540, 540, 33, 33, 66, 33, 540, 33, 33, 540, 33, 66, 66, 33, 66, 540, 540, 540, 66, 540, 540, 33, 33, 540, 66, 540, 33, 66, 540, 33, 540, 66, 33, 540, 33, 33, 540, 33, 33, 66]
Prompts retrieved: 20448 . Total input tokens: 4537851 . Total output tokens: 4108920
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 1.0082520749419928,
    "estimated_duration": 3599.357075703864,
    "input_throughput": 471.84009929548006,
    "output_throughput": 422.4132165888761,
    "total_throughput": 894.2533158843561,
    "itl": 19.523721326033264,
    "ttft": 5217.326511222817,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2356,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.34283307725072,
    "arrivals": 6944,
    "finished_requests": 6934,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0083185080438852. Arrivals time: 0.03009542776271701 Scheduler time: 0.5659325504675508 Scheduler overhead time: 0.1475303820334375 Adapter cache time: 0.045522135216742754 Engine time: 0.14564674254506826 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-32/adapters_96_slots_32_rate_0.05-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-32/adapters_96_slots_32_rate_0.05-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 540, 66, 66, 66, 66, 540, 66, 540, 66, 33, 540, 33, 33, 540, 66, 540, 66, 540, 540, 66, 33, 540, 66, 33, 33, 66, 540, 33, 66, 33, 33, 66, 66, 66, 33, 33, 540, 66, 66, 33, 540, 540, 66, 540, 540, 66, 540, 33, 540, 66, 66, 66, 540, 540, 33, 33, 66, 33, 540, 33, 33, 540, 33, 66, 66, 33, 66, 540, 540, 540, 66, 540, 540, 33, 33, 540, 66, 540, 33, 66, 540, 33, 540, 66, 33, 540, 33, 33, 540, 33, 33, 66]
Prompts retrieved: 20448 . Total input tokens: 4537851 . Total output tokens: 4108920
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 1.0153480912558734,
    "estimated_duration": 3599.362847620481,
    "input_throughput": 471.8393426555344,
    "output_throughput": 422.41253920958223,
    "total_throughput": 894.2518818651166,
    "itl": 19.526052433685216,
    "ttft": 5217.43567549615,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2357,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.748958508297608,
    "arrivals": 6944,
    "finished_requests": 6934,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0153964282944798. Arrivals time: 0.03047401923686266 Scheduler time: 0.5690138125792146 Scheduler overhead time: 0.14812059933319688 Adapter cache time: 0.04574872553348541 Engine time: 0.14810766419395804 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-16/adapters_96_slots_32_rate_0.05-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-16/adapters_96_slots_32_rate_0.05-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 540, 66, 66, 66, 66, 540, 66, 540, 66, 33, 540, 33, 33, 540, 66, 540, 66, 540, 540, 66, 33, 540, 66, 33, 33, 66, 540, 33, 66, 33, 33, 66, 66, 66, 33, 33, 540, 66, 66, 33, 540, 540, 66, 540, 540, 66, 540, 33, 540, 66, 66, 66, 540, 540, 33, 33, 66, 33, 540, 33, 33, 540, 33, 66, 66, 33, 66, 540, 540, 540, 66, 540, 540, 33, 33, 540, 66, 540, 33, 66, 540, 33, 540, 66, 33, 540, 33, 33, 540, 33, 33, 66]
Prompts retrieved: 20448 . Total input tokens: 4537851 . Total output tokens: 4108920
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 1.0202864981256425,
    "estimated_duration": 3599.3616792498146,
    "input_throughput": 471.83949581692696,
    "output_throughput": 422.4126763267891,
    "total_throughput": 894.252172143716,
    "itl": 19.522336069397586,
    "ttft": 5217.3777001748285,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2357,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.047548545084214,
    "arrivals": 6944,
    "finished_requests": 6934,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0203628963790834. Arrivals time: 0.03096793545410037 Scheduler time: 0.5730670974589884 Scheduler overhead time: 0.1489439569413662 Adapter cache time: 0.0454705199226737 Engine time: 0.1478444216772914 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-32/adapters_96_slots_32_rate_0.05-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-32/adapters_96_slots_32_rate_0.05-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 540, 66, 66, 66, 66, 540, 66, 540, 66, 33, 540, 33, 33, 540, 66, 540, 66, 540, 540, 66, 33, 540, 66, 33, 33, 66, 540, 33, 66, 33, 33, 66, 66, 66, 33, 33, 540, 66, 66, 33, 540, 540, 66, 540, 540, 66, 540, 33, 540, 66, 66, 66, 540, 540, 33, 33, 66, 33, 540, 33, 33, 540, 33, 66, 66, 33, 66, 540, 540, 540, 66, 540, 540, 33, 33, 540, 66, 540, 33, 66, 540, 33, 540, 66, 33, 540, 33, 33, 540, 33, 33, 66]
Prompts retrieved: 20448 . Total input tokens: 4537851 . Total output tokens: 4108920
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.0138267348520458,
    "estimated_duration": 3599.3521923271514,
    "input_throughput": 471.84073945871774,
    "output_throughput": 422.41378969280004,
    "total_throughput": 894.2545291515178,
    "itl": 19.52725471762904,
    "ttft": 5217.5280979785675,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2357,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.840758772380318,
    "arrivals": 6944,
    "finished_requests": 6934,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0138845620676875. Arrivals time: 0.03042318532243371 Scheduler time: 0.5656471992842853 Scheduler overhead time: 0.14801183762028813 Adapter cache time: 0.045745634008198977 Engine time: 0.15034741489216685 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-8/adapters_96_slots_32_rate_0.025-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-8/adapters_96_slots_32_rate_0.025-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 270, 135, 135, 135, 135, 270, 135, 270, 135, 66, 270, 66, 66, 270, 135, 270, 135, 270, 270, 135, 66, 270, 135, 66, 66, 135, 270, 66, 135, 66, 66, 135, 135, 135, 66, 66, 270, 135, 135, 66, 270, 270, 135, 270, 270, 135, 270, 66, 270, 135, 135, 135, 270, 270, 66, 66, 135, 66, 270, 66, 66, 270, 66, 135, 135, 66, 135, 270, 270, 270, 135, 270, 270, 66, 66, 270, 135, 270, 66, 135, 270, 66, 270, 135, 66, 270, 66, 66, 270, 66, 66, 135]
Prompts retrieved: 15072 . Total input tokens: 3314737 . Total output tokens: 3054771
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 0.8986970819532871,
    "estimated_duration": 3599.485382756669,
    "input_throughput": 354.6854242320189,
    "output_throughput": 311.3353384815669,
    "total_throughput": 666.0207627135858,
    "itl": 18.901814169023233,
    "ttft": 5713.303585952387,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2963,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.068225185272718,
    "arrivals": 5070,
    "finished_requests": 5062,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.898758867289871. Arrivals time: 0.026611260138452053 Scheduler time: 0.4517816985026002 Scheduler overhead time: 0.15102329710498452 Adapter cache time: 0.042776040732860565 Engine time: 0.1508074221201241 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-16/adapters_96_slots_32_rate_0.025-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-16/adapters_96_slots_32_rate_0.025-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 270, 135, 135, 135, 135, 270, 135, 270, 135, 66, 270, 66, 66, 270, 135, 270, 135, 270, 270, 135, 66, 270, 135, 66, 66, 135, 270, 66, 135, 66, 66, 135, 135, 135, 66, 66, 270, 135, 135, 66, 270, 270, 135, 270, 270, 135, 270, 66, 270, 135, 135, 135, 270, 270, 66, 66, 135, 66, 270, 66, 66, 270, 66, 135, 135, 66, 135, 270, 270, 270, 135, 270, 270, 66, 66, 270, 135, 270, 66, 135, 270, 66, 270, 135, 66, 270, 66, 66, 270, 66, 66, 135]
Prompts retrieved: 15072 . Total input tokens: 3314737 . Total output tokens: 3054771
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 0.8917598691768944,
    "estimated_duration": 3599.4929651904845,
    "input_throughput": 354.6846770771333,
    "output_throughput": 311.334682644864,
    "total_throughput": 666.0193597219973,
    "itl": 18.906600523294617,
    "ttft": 5713.484127157416,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2963,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.624000864596983,
    "arrivals": 5070,
    "finished_requests": 5062,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8918057950213552. Arrivals time: 0.026393908075988293 Scheduler time: 0.4509010436013341 Scheduler overhead time: 0.14956777729094028 Adapter cache time: 0.0421266364865005 Engine time: 0.14794935705140233 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-32/adapters_96_slots_32_rate_0.025-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-32/adapters_96_slots_32_rate_0.025-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 270, 135, 135, 135, 135, 270, 135, 270, 135, 66, 270, 66, 66, 270, 135, 270, 135, 270, 270, 135, 66, 270, 135, 66, 66, 135, 270, 66, 135, 66, 66, 135, 135, 135, 66, 66, 270, 135, 135, 66, 270, 270, 135, 270, 270, 135, 270, 66, 270, 135, 135, 135, 270, 270, 66, 66, 135, 66, 270, 66, 66, 270, 66, 135, 135, 66, 135, 270, 270, 270, 135, 270, 270, 66, 66, 270, 135, 270, 66, 135, 270, 66, 270, 135, 66, 270, 66, 66, 270, 66, 66, 135]
Prompts retrieved: 15072 . Total input tokens: 3314737 . Total output tokens: 3054771
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 0.8949258346110582,
    "estimated_duration": 3599.4976522112697,
    "input_throughput": 354.6842152308941,
    "output_throughput": 311.33427724603627,
    "total_throughput": 666.0184924769303,
    "itl": 18.9051158833324,
    "ttft": 5713.530366337518,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2963,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.648936411160632,
    "arrivals": 5070,
    "finished_requests": 5062,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8950001266784966. Arrivals time: 0.026636134833097458 Scheduler time: 0.4512237929739058 Scheduler overhead time: 0.14959742035716772 Adapter cache time: 0.04244027705863118 Engine time: 0.15027088625356555 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-16/adapters_96_slots_32_rate_0.025-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-16/adapters_96_slots_32_rate_0.025-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 270, 135, 135, 135, 135, 270, 135, 270, 135, 66, 270, 66, 66, 270, 135, 270, 135, 270, 270, 135, 66, 270, 135, 66, 66, 135, 270, 66, 135, 66, 66, 135, 135, 135, 66, 66, 270, 135, 135, 66, 270, 270, 135, 270, 270, 135, 270, 66, 270, 135, 135, 135, 270, 270, 66, 66, 135, 66, 270, 66, 66, 270, 66, 135, 135, 66, 135, 270, 270, 270, 135, 270, 270, 66, 66, 270, 135, 270, 66, 135, 270, 66, 270, 135, 66, 270, 66, 66, 270, 66, 66, 135]
Prompts retrieved: 15072 . Total input tokens: 3314737 . Total output tokens: 3054771
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 0.9072216427884996,
    "estimated_duration": 3599.4840425513557,
    "input_throughput": 354.68555629297106,
    "output_throughput": 311.3354544018682,
    "total_throughput": 666.0210106948393,
    "itl": 18.902518647186067,
    "ttft": 5713.370494444518,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2963,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.241964241855282,
    "arrivals": 5070,
    "finished_requests": 5062,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9072741940617561. Arrivals time: 0.027082541026175022 Scheduler time: 0.4579029963351786 Scheduler overhead time: 0.15080405259504914 Adapter cache time: 0.042552145663648844 Engine time: 0.15334605379030108 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-32/adapters_96_slots_32_rate_0.025-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-32/adapters_96_slots_32_rate_0.025-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 270, 135, 135, 135, 135, 270, 135, 270, 135, 66, 270, 66, 66, 270, 135, 270, 135, 270, 270, 135, 66, 270, 135, 66, 66, 135, 270, 66, 135, 66, 66, 135, 135, 135, 66, 66, 270, 135, 135, 66, 270, 270, 135, 270, 270, 135, 270, 66, 270, 135, 135, 135, 270, 270, 66, 66, 135, 66, 270, 66, 66, 270, 66, 135, 135, 66, 135, 270, 270, 270, 135, 270, 270, 66, 66, 270, 135, 270, 66, 135, 270, 66, 270, 135, 66, 270, 66, 66, 270, 66, 66, 135]
Prompts retrieved: 15072 . Total input tokens: 3314737 . Total output tokens: 3054771
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 0.8995231851004064,
    "estimated_duration": 3599.483050873549,
    "input_throughput": 354.68565401083487,
    "output_throughput": 311.3355401765354,
    "total_throughput": 666.0211941873703,
    "itl": 18.906524650304934,
    "ttft": 5713.546259086251,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2963,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.766516201458431,
    "arrivals": 5070,
    "finished_requests": 5062,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.899590564891696. Arrivals time: 0.02646992728114128 Scheduler time: 0.4554529902525246 Scheduler overhead time: 0.14843308320268989 Adapter cache time: 0.04256206750869751 Engine time: 0.15075475769117475 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-16/adapters_96_slots_32_rate_0.025-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-16/adapters_96_slots_32_rate_0.025-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 270, 135, 135, 135, 135, 270, 135, 270, 135, 66, 270, 66, 66, 270, 135, 270, 135, 270, 270, 135, 66, 270, 135, 66, 66, 135, 270, 66, 135, 66, 66, 135, 135, 135, 66, 66, 270, 135, 135, 66, 270, 270, 135, 270, 270, 135, 270, 66, 270, 135, 135, 135, 270, 270, 66, 66, 135, 66, 270, 66, 66, 270, 66, 135, 135, 66, 135, 270, 270, 270, 135, 270, 270, 66, 66, 270, 135, 270, 66, 135, 270, 66, 270, 135, 66, 270, 66, 66, 270, 66, 66, 135]
Prompts retrieved: 15072 . Total input tokens: 3314737 . Total output tokens: 3054771
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 0.8998267739079893,
    "estimated_duration": 3599.4779193082372,
    "input_throughput": 354.68615966544354,
    "output_throughput": 311.3359840294202,
    "total_throughput": 666.0221436948638,
    "itl": 18.90171684808764,
    "ttft": 5713.307754736736,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2964,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.862509074090026,
    "arrivals": 5070,
    "finished_requests": 5062,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8999647260643542. Arrivals time: 0.026703896466642618 Scheduler time: 0.4561947640031576 Scheduler overhead time: 0.15002707252278924 Adapter cache time: 0.042502681259065866 Engine time: 0.14944843016564846 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-32/adapters_96_slots_32_rate_0.025-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-32/adapters_96_slots_32_rate_0.025-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 270, 135, 135, 135, 135, 270, 135, 270, 135, 66, 270, 66, 66, 270, 135, 270, 135, 270, 270, 135, 66, 270, 135, 66, 66, 135, 270, 66, 135, 66, 66, 135, 135, 135, 66, 66, 270, 135, 135, 66, 270, 270, 135, 270, 270, 135, 270, 66, 270, 135, 135, 135, 270, 270, 66, 66, 135, 66, 270, 66, 66, 270, 66, 135, 135, 66, 135, 270, 270, 270, 135, 270, 270, 66, 66, 270, 135, 270, 66, 135, 270, 66, 270, 135, 66, 270, 66, 66, 270, 66, 66, 135]
Prompts retrieved: 15072 . Total input tokens: 3314737 . Total output tokens: 3054771
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 0.8982725352980196,
    "estimated_duration": 3599.489887692076,
    "input_throughput": 354.68498032608335,
    "output_throughput": 311.334948830357,
    "total_throughput": 666.0199291564404,
    "itl": 18.90622080167387,
    "ttft": 5713.534016627537,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2963,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.88422174554265,
    "arrivals": 5070,
    "finished_requests": 5062,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8984308810904622. Arrivals time: 0.026926652062684298 Scheduler time: 0.45478026708588004 Scheduler overhead time: 0.14947107573971152 Adapter cache time: 0.042355459183454514 Engine time: 0.14982012379914522 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-8/adapters_96_slots_32_rate_0.025-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-8/adapters_96_slots_32_rate_0.025-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 270, 135, 135, 135, 135, 270, 135, 270, 135, 33, 270, 33, 33, 270, 135, 270, 135, 270, 270, 135, 33, 270, 135, 33, 33, 135, 270, 33, 135, 33, 33, 135, 135, 135, 33, 33, 270, 135, 135, 33, 270, 270, 135, 270, 270, 135, 270, 33, 270, 135, 135, 135, 270, 270, 33, 33, 135, 33, 270, 33, 33, 270, 33, 135, 135, 33, 135, 270, 270, 270, 135, 270, 270, 33, 33, 270, 135, 270, 33, 135, 270, 33, 270, 135, 33, 270, 33, 33, 270, 33, 33, 135]
Prompts retrieved: 14016 . Total input tokens: 3078471 . Total output tokens: 2840300
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 0.86598658002913,
    "estimated_duration": 3598.5689049728426,
    "input_throughput": 324.56485643111904,
    "output_throughput": 281.96847880217473,
    "total_throughput": 606.5333352332938,
    "itl": 18.732731615508374,
    "ttft": 6914.422816411407,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2513,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.691005700503242,
    "arrivals": 4708,
    "finished_requests": 4699,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8660389133729041. Arrivals time: 0.025462890509516 Scheduler time: 0.42135433154180646 Scheduler overhead time: 0.1505252756178379 Adapter cache time: 0.041500992607325315 Engine time: 0.15174332167953253 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-16/adapters_96_slots_32_rate_0.025-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-16/adapters_96_slots_32_rate_0.025-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 270, 135, 135, 135, 135, 270, 135, 270, 135, 33, 270, 33, 33, 270, 135, 270, 135, 270, 270, 135, 33, 270, 135, 33, 33, 135, 270, 33, 135, 33, 33, 135, 135, 135, 33, 33, 270, 135, 135, 33, 270, 270, 135, 270, 270, 135, 270, 33, 270, 135, 135, 135, 270, 270, 33, 33, 135, 33, 270, 33, 33, 270, 33, 135, 135, 33, 135, 270, 270, 270, 135, 270, 270, 33, 33, 270, 135, 270, 33, 135, 270, 33, 270, 135, 33, 270, 33, 33, 270, 33, 33, 135]
Prompts retrieved: 14016 . Total input tokens: 3078471 . Total output tokens: 2840300
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 0.87264125328511,
    "estimated_duration": 3598.5887247195787,
    "input_throughput": 324.5630688433323,
    "output_throughput": 281.96692582008507,
    "total_throughput": 606.5299946634174,
    "itl": 18.73603563435729,
    "ttft": 6914.443088641465,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2513,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.124437796838727,
    "arrivals": 4708,
    "finished_requests": 4699,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8727011880837381. Arrivals time: 0.025845753494650126 Scheduler time: 0.42858352791517973 Scheduler overhead time: 0.15033191302791238 Adapter cache time: 0.04116167314350605 Engine time: 0.15119825908914208 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-32/adapters_96_slots_32_rate_0.025-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-32/adapters_96_slots_32_rate_0.025-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 270, 135, 135, 135, 135, 270, 135, 270, 135, 33, 270, 33, 33, 270, 135, 270, 135, 270, 270, 135, 33, 270, 135, 33, 33, 135, 270, 33, 135, 33, 33, 135, 135, 135, 33, 33, 270, 135, 135, 33, 270, 270, 135, 270, 270, 135, 270, 33, 270, 135, 135, 135, 270, 270, 33, 33, 135, 33, 270, 33, 33, 270, 33, 135, 135, 33, 135, 270, 270, 270, 135, 270, 270, 33, 33, 270, 135, 270, 33, 135, 270, 33, 270, 135, 33, 270, 33, 33, 270, 33, 33, 135]
Prompts retrieved: 14016 . Total input tokens: 3078471 . Total output tokens: 2840300
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 0.8700859472155571,
    "estimated_duration": 3598.5689664024767,
    "input_throughput": 324.564850890611,
    "output_throughput": 281.96847398881124,
    "total_throughput": 606.5333248794223,
    "itl": 18.736541332128795,
    "ttft": 6914.451263254304,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2513,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.152210623770834,
    "arrivals": 4708,
    "finished_requests": 4699,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8701507318764925. Arrivals time: 0.02600509999319911 Scheduler time: 0.42634741915389895 Scheduler overhead time: 0.1494915853254497 Adapter cache time: 0.04094752762466669 Engine time: 0.1519483868032694 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-16/adapters_96_slots_32_rate_0.025-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-16/adapters_96_slots_32_rate_0.025-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 270, 135, 135, 135, 135, 270, 135, 270, 135, 33, 270, 33, 33, 270, 135, 270, 135, 270, 270, 135, 33, 270, 135, 33, 33, 135, 270, 33, 135, 33, 33, 135, 135, 135, 33, 33, 270, 135, 135, 33, 270, 270, 135, 270, 270, 135, 270, 33, 270, 135, 135, 135, 270, 270, 33, 33, 135, 33, 270, 33, 33, 270, 33, 135, 135, 33, 135, 270, 270, 270, 135, 270, 270, 33, 33, 270, 135, 270, 33, 135, 270, 33, 270, 135, 33, 270, 33, 33, 270, 33, 33, 135]
Prompts retrieved: 14016 . Total input tokens: 3078471 . Total output tokens: 2840300
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 0.8661008281633258,
    "estimated_duration": 3598.5739469709165,
    "input_throughput": 324.56440168004127,
    "output_throughput": 281.9680837333091,
    "total_throughput": 606.5324854133504,
    "itl": 18.73392004741048,
    "ttft": 6914.342950018125,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2513,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.828206190969506,
    "arrivals": 4708,
    "finished_requests": 4699,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8661466771736741. Arrivals time: 0.025578610599040985 Scheduler time: 0.4229954988695681 Scheduler overhead time: 0.1503739138133824 Adapter cache time: 0.040625846944749355 Engine time: 0.15112174209207296 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-32/adapters_96_slots_32_rate_0.025-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-32/adapters_96_slots_32_rate_0.025-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 270, 135, 135, 135, 135, 270, 135, 270, 135, 33, 270, 33, 33, 270, 135, 270, 135, 270, 270, 135, 33, 270, 135, 33, 33, 135, 270, 33, 135, 33, 33, 135, 135, 135, 33, 33, 270, 135, 135, 33, 270, 270, 135, 270, 270, 135, 270, 33, 270, 135, 135, 135, 270, 270, 33, 33, 135, 33, 270, 33, 33, 270, 33, 135, 135, 33, 135, 270, 270, 270, 135, 270, 270, 33, 33, 270, 135, 270, 33, 135, 270, 33, 270, 135, 33, 270, 33, 33, 270, 33, 33, 135]
Prompts retrieved: 14016 . Total input tokens: 3078471 . Total output tokens: 2840300
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 0.8735514809377491,
    "estimated_duration": 3598.5734869642106,
    "input_throughput": 324.5644431692041,
    "output_throughput": 281.96811977737207,
    "total_throughput": 606.5325629465761,
    "itl": 18.736631448642193,
    "ttft": 6914.40061108098,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2513,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.243382118921478,
    "arrivals": 4708,
    "finished_requests": 4699,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8736232002265751. Arrivals time: 0.025641893036663532 Scheduler time: 0.4302238351665437 Scheduler overhead time: 0.1495313486084342 Adapter cache time: 0.041326460894197226 Engine time: 0.15048089576885104 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-16/adapters_96_slots_32_rate_0.025-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-16/adapters_96_slots_32_rate_0.025-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 270, 135, 135, 135, 135, 270, 135, 270, 135, 33, 270, 33, 33, 270, 135, 270, 135, 270, 270, 135, 33, 270, 135, 33, 33, 135, 270, 33, 135, 33, 33, 135, 135, 135, 33, 33, 270, 135, 135, 33, 270, 270, 135, 270, 270, 135, 270, 33, 270, 135, 135, 135, 270, 270, 33, 33, 135, 33, 270, 33, 33, 270, 33, 135, 135, 33, 135, 270, 270, 270, 135, 270, 270, 33, 33, 270, 135, 270, 33, 135, 270, 33, 270, 135, 33, 270, 33, 33, 270, 33, 33, 135]
Prompts retrieved: 14016 . Total input tokens: 3078471 . Total output tokens: 2840300
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 0.8713957420550287,
    "estimated_duration": 3598.580845173122,
    "input_throughput": 324.5637795150913,
    "output_throughput": 281.9675432222186,
    "total_throughput": 606.5313227373099,
    "itl": 18.731422339544032,
    "ttft": 6914.247451905331,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2513,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.513996391088937,
    "arrivals": 4708,
    "finished_requests": 4699,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.871441968716681. Arrivals time: 0.02571251755580306 Scheduler time: 0.4269250179640949 Scheduler overhead time: 0.15089585445821285 Adapter cache time: 0.04095464898273349 Engine time: 0.1513577471487224 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-32/adapters_96_slots_32_rate_0.025-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-32/adapters_96_slots_32_rate_0.025-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 270, 135, 135, 135, 135, 270, 135, 270, 135, 33, 270, 33, 33, 270, 135, 270, 135, 270, 270, 135, 33, 270, 135, 33, 33, 135, 270, 33, 135, 33, 33, 135, 135, 135, 33, 33, 270, 135, 135, 33, 270, 270, 135, 270, 270, 135, 270, 33, 270, 135, 135, 135, 270, 270, 33, 33, 135, 33, 270, 33, 33, 270, 33, 135, 135, 33, 135, 270, 270, 270, 135, 270, 270, 33, 33, 270, 135, 270, 33, 135, 270, 33, 270, 135, 33, 270, 33, 33, 270, 33, 33, 135]
Prompts retrieved: 14016 . Total input tokens: 3078471 . Total output tokens: 2840300
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 0.8660137206315994,
    "estimated_duration": 3598.576771371756,
    "input_throughput": 324.564146940452,
    "output_throughput": 281.9678624261249,
    "total_throughput": 606.5320093665769,
    "itl": 18.738774059719763,
    "ttft": 6914.652803916227,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2512,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.337043261825649,
    "arrivals": 4708,
    "finished_requests": 4699,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8662085980176926. Arrivals time: 0.025623780209571123 Scheduler time: 0.4227799051441252 Scheduler overhead time: 0.14935056399554014 Adapter cache time: 0.04100241092965007 Engine time: 0.15178331919014454 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-8/adapters_96_slots_32_rate_0.025-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-8/adapters_96_slots_32_rate_0.025-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 270, 66, 66, 66, 66, 270, 66, 270, 66, 33, 270, 33, 33, 270, 66, 270, 66, 270, 270, 66, 33, 270, 66, 33, 33, 66, 270, 33, 66, 33, 33, 66, 66, 66, 33, 33, 270, 66, 66, 33, 270, 270, 66, 270, 270, 66, 270, 33, 270, 66, 66, 66, 270, 270, 33, 33, 66, 33, 270, 33, 33, 270, 33, 66, 66, 33, 66, 270, 270, 270, 66, 270, 270, 33, 33, 270, 66, 270, 33, 66, 270, 33, 270, 66, 33, 270, 33, 33, 270, 33, 33, 66]
Prompts retrieved: 11808 . Total input tokens: 2568820 . Total output tokens: 2402004
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 0.8147511449642479,
    "estimated_duration": 3599.5902700687607,
    "input_throughput": 265.78441661965167,
    "output_throughput": 238.5988225219849,
    "total_throughput": 504.3832391416366,
    "itl": 18.540520271168596,
    "ttft": 3698.8727990498733,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1863,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.7016886669468825,
    "arrivals": 3927,
    "finished_requests": 3923,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8148048780858517. Arrivals time: 0.02364488923922181 Scheduler time: 0.37923331605270505 Scheduler overhead time: 0.1486160927452147 Adapter cache time: 0.03708023065701127 Engine time: 0.15073917480185628 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-16/adapters_96_slots_32_rate_0.025-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-16/adapters_96_slots_32_rate_0.025-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 270, 66, 66, 66, 66, 270, 66, 270, 66, 33, 270, 33, 33, 270, 66, 270, 66, 270, 270, 66, 33, 270, 66, 33, 33, 66, 270, 33, 66, 33, 33, 66, 66, 66, 33, 33, 270, 66, 66, 33, 270, 270, 66, 270, 270, 66, 270, 33, 270, 66, 66, 66, 270, 270, 33, 33, 66, 33, 270, 33, 33, 270, 33, 66, 66, 33, 66, 270, 270, 270, 66, 270, 270, 33, 33, 270, 66, 270, 33, 66, 270, 33, 270, 66, 33, 270, 33, 33, 270, 33, 33, 66]
Prompts retrieved: 11808 . Total input tokens: 2568820 . Total output tokens: 2402004
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 0.8142504869028926,
    "estimated_duration": 3599.595334549544,
    "input_throughput": 265.7840426720422,
    "output_throughput": 238.59848682337457,
    "total_throughput": 504.38252949541675,
    "itl": 18.542159042977822,
    "ttft": 3698.8634710920505,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1863,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.045660054748696,
    "arrivals": 3927,
    "finished_requests": 3923,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8142982521094382. Arrivals time: 0.024076949805021286 Scheduler time: 0.377132716588676 Scheduler overhead time: 0.1489548347890377 Adapter cache time: 0.03765243384987116 Engine time: 0.15101349586620927 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-32/adapters_96_slots_32_rate_0.025-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-32/adapters_96_slots_32_rate_0.025-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 270, 66, 66, 66, 66, 270, 66, 270, 66, 33, 270, 33, 33, 270, 66, 270, 66, 270, 270, 66, 33, 270, 66, 33, 33, 66, 270, 33, 66, 33, 33, 66, 66, 66, 33, 33, 270, 66, 66, 33, 270, 270, 66, 270, 270, 66, 270, 33, 270, 66, 66, 66, 270, 270, 33, 33, 66, 33, 270, 33, 33, 270, 33, 66, 66, 33, 66, 270, 270, 270, 66, 270, 270, 33, 33, 270, 66, 270, 33, 66, 270, 33, 270, 66, 33, 270, 33, 33, 270, 33, 33, 66]
Prompts retrieved: 11808 . Total input tokens: 2568820 . Total output tokens: 2402004
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 0.8192221987992525,
    "estimated_duration": 3599.5768828208834,
    "input_throughput": 265.785405103016,
    "output_throughput": 238.5997098989418,
    "total_throughput": 504.3851150019578,
    "itl": 18.54263733613824,
    "ttft": 3698.905167490758,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1863,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.062294451389404,
    "arrivals": 3927,
    "finished_requests": 3923,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8193443357013166. Arrivals time: 0.023727160412818193 Scheduler time: 0.38119051791727543 Scheduler overhead time: 0.15005994401872158 Adapter cache time: 0.037469832226634026 Engine time: 0.15137759130448103 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-16/adapters_96_slots_32_rate_0.025-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-16/adapters_96_slots_32_rate_0.025-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 270, 66, 66, 66, 66, 270, 66, 270, 66, 33, 270, 33, 33, 270, 66, 270, 66, 270, 270, 66, 33, 270, 66, 33, 33, 66, 270, 33, 66, 33, 33, 66, 66, 66, 33, 33, 270, 66, 66, 33, 270, 270, 66, 270, 270, 66, 270, 33, 270, 66, 66, 66, 270, 270, 33, 33, 66, 33, 270, 33, 33, 270, 33, 66, 66, 33, 66, 270, 270, 270, 66, 270, 270, 33, 33, 270, 66, 270, 33, 66, 270, 33, 270, 66, 33, 270, 33, 33, 270, 33, 33, 66]
Prompts retrieved: 11808 . Total input tokens: 2568820 . Total output tokens: 2402004
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 0.8147517507895827,
    "estimated_duration": 3599.5790090492615,
    "input_throughput": 265.785248106748,
    "output_throughput": 238.59956896093962,
    "total_throughput": 504.3848170676876,
    "itl": 18.540072583661996,
    "ttft": 3698.8676782490543,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1863,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.818481057695882,
    "arrivals": 3927,
    "finished_requests": 3923,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8147985329851508. Arrivals time: 0.023753988556563854 Scheduler time: 0.37692191638052464 Scheduler overhead time: 0.14921266259625554 Adapter cache time: 0.03766894480213523 Engine time: 0.15203834371641278 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-32/adapters_96_slots_32_rate_0.025-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-32/adapters_96_slots_32_rate_0.025-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 270, 66, 66, 66, 66, 270, 66, 270, 66, 33, 270, 33, 33, 270, 66, 270, 66, 270, 270, 66, 33, 270, 66, 33, 33, 66, 270, 33, 66, 33, 33, 66, 66, 66, 33, 33, 270, 66, 66, 33, 270, 270, 66, 270, 270, 66, 270, 33, 270, 66, 66, 66, 270, 270, 33, 33, 66, 33, 270, 33, 33, 270, 33, 66, 66, 33, 66, 270, 270, 270, 66, 270, 270, 33, 33, 270, 66, 270, 33, 66, 270, 33, 270, 66, 33, 270, 33, 33, 270, 33, 33, 66]
Prompts retrieved: 11808 . Total input tokens: 2568820 . Total output tokens: 2402004
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 0.8132599736563861,
    "estimated_duration": 3599.5821027226007,
    "input_throughput": 265.7850196766934,
    "output_throughput": 238.59936389571146,
    "total_throughput": 504.3843835724049,
    "itl": 18.54273492919596,
    "ttft": 3698.8396572745523,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1863,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.132213556636014,
    "arrivals": 3927,
    "finished_requests": 3923,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8133201468735933. Arrivals time: 0.023790159728378057 Scheduler time: 0.37575849145650864 Scheduler overhead time: 0.14908938249573112 Adapter cache time: 0.037323383148759604 Engine time: 0.15181875322014093 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-16/adapters_96_slots_32_rate_0.025-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-16/adapters_96_slots_32_rate_0.025-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 270, 66, 66, 66, 66, 270, 66, 270, 66, 33, 270, 33, 33, 270, 66, 270, 66, 270, 270, 66, 33, 270, 66, 33, 33, 66, 270, 33, 66, 33, 33, 66, 66, 66, 33, 33, 270, 66, 66, 33, 270, 270, 66, 270, 270, 66, 270, 33, 270, 66, 66, 66, 270, 270, 33, 33, 66, 33, 270, 33, 33, 270, 33, 66, 66, 33, 66, 270, 270, 270, 66, 270, 270, 33, 33, 270, 66, 270, 33, 66, 270, 33, 270, 66, 33, 270, 33, 33, 270, 33, 33, 66]
Prompts retrieved: 11808 . Total input tokens: 2568820 . Total output tokens: 2402004
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 0.8107055379077792,
    "estimated_duration": 3599.580360793256,
    "input_throughput": 265.78514829688766,
    "output_throughput": 238.59947936006893,
    "total_throughput": 504.3846276569566,
    "itl": 18.539496245583532,
    "ttft": 3698.6153593089266,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1863,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.570463699402592,
    "arrivals": 3927,
    "finished_requests": 3923,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8107652110047638. Arrivals time: 0.023622358217835426 Scheduler time: 0.37489659106358886 Scheduler overhead time: 0.14898692769929767 Adapter cache time: 0.03717835061252117 Engine time: 0.15113925002515316 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-32/adapters_96_slots_32_rate_0.025-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-32/adapters_96_slots_32_rate_0.025-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 270, 66, 66, 66, 66, 270, 66, 270, 66, 33, 270, 33, 33, 270, 66, 270, 66, 270, 270, 66, 33, 270, 66, 33, 33, 66, 270, 33, 66, 33, 33, 66, 66, 66, 33, 33, 270, 66, 66, 33, 270, 270, 66, 270, 270, 66, 270, 33, 270, 66, 66, 66, 270, 270, 33, 33, 66, 33, 270, 33, 33, 270, 33, 66, 66, 33, 66, 270, 270, 270, 66, 270, 270, 33, 33, 270, 66, 270, 33, 66, 270, 33, 270, 66, 33, 270, 33, 33, 270, 33, 33, 66]
Prompts retrieved: 11808 . Total input tokens: 2568820 . Total output tokens: 2402004
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 0.817544081248343,
    "estimated_duration": 3599.5871885158126,
    "input_throughput": 265.7846441537298,
    "output_throughput": 238.59902678288108,
    "total_throughput": 504.3836709366109,
    "itl": 18.543097119627365,
    "ttft": 3699.0146290324046,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1863,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.208546104989781,
    "arrivals": 3927,
    "finished_requests": 3923,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8175948122516274. Arrivals time: 0.02371507929638028 Scheduler time: 0.3798913601785898 Scheduler overhead time: 0.14927901746705174 Adapter cache time: 0.037388662807643414 Engine time: 0.1519305119290948 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-8/adapters_96_slots_32_rate_0.0125-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-8/adapters_96_slots_32_rate_0.0125-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 135, 66, 66, 66, 66, 135, 66, 135, 66, 33, 135, 33, 33, 135, 66, 135, 66, 135, 135, 66, 33, 135, 66, 33, 33, 66, 135, 33, 66, 33, 33, 66, 66, 66, 33, 33, 135, 66, 66, 33, 135, 135, 66, 135, 135, 66, 135, 33, 135, 66, 66, 66, 135, 135, 33, 33, 66, 33, 135, 33, 33, 135, 33, 66, 66, 33, 66, 135, 135, 135, 66, 135, 135, 33, 33, 135, 66, 135, 33, 66, 135, 33, 135, 66, 33, 135, 33, 33, 135, 33, 33, 66]
Prompts retrieved: 7488 . Total input tokens: 1626076 . Total output tokens: 1517852
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 0.6937724617309868,
    "estimated_duration": 3599.024362648696,
    "input_throughput": 161.63463799724852,
    "output_throughput": 147.42300872048594,
    "total_throughput": 309.0576467177344,
    "itl": 17.979553178230375,
    "ttft": 8938.328427588533,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1429,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.373436986080021,
    "arrivals": 2425,
    "finished_requests": 2419,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6938332668505609. Arrivals time: 0.020088307093828917 Scheduler time: 0.2757248976267874 Scheduler overhead time: 0.14578252006322145 Adapter cache time: 0.031818099319934845 Engine time: 0.14665195159614086 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-16/adapters_96_slots_32_rate_0.0125-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-16/adapters_96_slots_32_rate_0.0125-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 135, 66, 66, 66, 66, 135, 66, 135, 66, 33, 135, 33, 33, 135, 66, 135, 66, 135, 135, 66, 33, 135, 66, 33, 33, 66, 135, 33, 66, 33, 33, 66, 66, 66, 33, 33, 135, 66, 66, 33, 135, 135, 66, 135, 135, 66, 135, 33, 135, 66, 66, 66, 135, 135, 33, 33, 66, 33, 135, 33, 33, 135, 33, 66, 66, 33, 66, 135, 135, 135, 66, 135, 135, 33, 33, 135, 66, 135, 33, 66, 135, 33, 135, 66, 33, 135, 33, 33, 135, 33, 33, 66]
Prompts retrieved: 7488 . Total input tokens: 1626076 . Total output tokens: 1517852
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 0.6942340768873692,
    "estimated_duration": 3599.026180283566,
    "input_throughput": 161.6345563660684,
    "output_throughput": 147.42293426667874,
    "total_throughput": 309.05749063274715,
    "itl": 17.980796864414582,
    "ttft": 8938.180415155906,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1429,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.640109062693026,
    "arrivals": 2425,
    "finished_requests": 2419,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6942944647744298. Arrivals time: 0.020219265017658472 Scheduler time: 0.2767986226826906 Scheduler overhead time: 0.14478472154587507 Adapter cache time: 0.03190903551876545 Engine time: 0.1469871075823903 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-32/adapters_96_slots_32_rate_0.0125-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-32/adapters_96_slots_32_rate_0.0125-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 135, 66, 66, 66, 66, 135, 66, 135, 66, 33, 135, 33, 33, 135, 66, 135, 66, 135, 135, 66, 33, 135, 66, 33, 33, 66, 135, 33, 66, 33, 33, 66, 66, 66, 33, 33, 135, 66, 66, 33, 135, 135, 66, 135, 135, 66, 135, 33, 135, 66, 66, 66, 135, 135, 33, 33, 66, 33, 135, 33, 33, 135, 33, 66, 66, 33, 66, 135, 135, 135, 66, 135, 135, 33, 33, 135, 66, 135, 33, 66, 135, 33, 135, 66, 33, 135, 33, 33, 135, 33, 33, 66]
Prompts retrieved: 7488 . Total input tokens: 1626076 . Total output tokens: 1517852
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 0.6918000979349017,
    "estimated_duration": 3599.0262334136087,
    "input_throughput": 161.63455397996444,
    "output_throughput": 147.42293209037152,
    "total_throughput": 309.0574860703359,
    "itl": 17.980840210149882,
    "ttft": 8938.18417726536,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1429,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.652373932469578,
    "arrivals": 2425,
    "finished_requests": 2419,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6918537323363125. Arrivals time: 0.01973143359646201 Scheduler time: 0.2748101460747421 Scheduler overhead time: 0.14488206570968032 Adapter cache time: 0.03171422192826867 Engine time: 0.14708573604002595 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-16/adapters_96_slots_32_rate_0.0125-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-16/adapters_96_slots_32_rate_0.0125-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 135, 66, 66, 66, 66, 135, 66, 135, 66, 33, 135, 33, 33, 135, 66, 135, 66, 135, 135, 66, 33, 135, 66, 33, 33, 66, 135, 33, 66, 33, 33, 66, 66, 66, 33, 33, 135, 66, 66, 33, 135, 135, 66, 135, 135, 66, 135, 33, 135, 66, 66, 66, 135, 135, 33, 33, 66, 33, 135, 33, 33, 135, 33, 66, 66, 33, 66, 135, 135, 135, 66, 135, 135, 33, 33, 135, 66, 135, 33, 66, 135, 33, 135, 66, 33, 135, 33, 33, 135, 33, 33, 66]
Prompts retrieved: 7488 . Total input tokens: 1626076 . Total output tokens: 1517852
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 0.691712305881083,
    "estimated_duration": 3599.025771688248,
    "input_throughput": 161.6345747163463,
    "output_throughput": 147.42295100351936,
    "total_throughput": 309.0575257198656,
    "itl": 17.978924230026454,
    "ttft": 8938.27601045128,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1429,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.453381002165763,
    "arrivals": 2425,
    "finished_requests": 2419,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6917586978524923. Arrivals time: 0.020068578887730837 Scheduler time: 0.2750706570222974 Scheduler overhead time: 0.14486752962693572 Adapter cache time: 0.03168778494000435 Engine time: 0.146583653986454 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-32/adapters_96_slots_32_rate_0.0125-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-32/adapters_96_slots_32_rate_0.0125-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 135, 66, 66, 66, 66, 135, 66, 135, 66, 33, 135, 33, 33, 135, 66, 135, 66, 135, 135, 66, 33, 135, 66, 33, 33, 66, 135, 33, 66, 33, 33, 66, 66, 66, 33, 33, 135, 66, 66, 33, 135, 135, 66, 135, 135, 66, 135, 33, 135, 66, 66, 66, 135, 135, 33, 33, 66, 33, 135, 33, 33, 135, 33, 66, 66, 33, 66, 135, 135, 135, 66, 135, 135, 33, 33, 135, 66, 135, 33, 66, 135, 33, 135, 66, 33, 135, 33, 33, 135, 33, 33, 66]
Prompts retrieved: 7488 . Total input tokens: 1626076 . Total output tokens: 1517852
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 0.691355227958411,
    "estimated_duration": 3599.0263591673947,
    "input_throughput": 161.63454833228224,
    "output_throughput": 147.4229269392584,
    "total_throughput": 309.0574752715406,
    "itl": 17.981785165539765,
    "ttft": 8938.15281236362,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1429,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.709843412861192,
    "arrivals": 2425,
    "finished_requests": 2419,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6914155539125204. Arrivals time: 0.01994080888107419 Scheduler time: 0.2747448608279228 Scheduler overhead time: 0.14543818728998303 Adapter cache time: 0.03182733850553632 Engine time: 0.14600625494495034 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-16/adapters_96_slots_32_rate_0.0125-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-16/adapters_96_slots_32_rate_0.0125-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 135, 66, 66, 66, 66, 135, 66, 135, 66, 33, 135, 33, 33, 135, 66, 135, 66, 135, 135, 66, 33, 135, 66, 33, 33, 66, 135, 33, 66, 33, 33, 66, 66, 66, 33, 33, 135, 66, 66, 33, 135, 135, 66, 135, 135, 66, 135, 33, 135, 66, 66, 66, 135, 135, 33, 33, 66, 33, 135, 33, 33, 135, 33, 66, 66, 33, 66, 135, 135, 135, 66, 135, 135, 33, 33, 135, 66, 135, 33, 66, 135, 33, 135, 66, 33, 135, 33, 33, 135, 33, 33, 66]
Prompts retrieved: 7488 . Total input tokens: 1626076 . Total output tokens: 1517852
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 0.6973279309459031,
    "estimated_duration": 3599.02345724679,
    "input_throughput": 161.63467865947567,
    "output_throughput": 147.42304580751096,
    "total_throughput": 309.05772446698666,
    "itl": 17.97898957678422,
    "ttft": 8938.308793429745,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1429,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.272781871415094,
    "arrivals": 2425,
    "finished_requests": 2419,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6973881321027875. Arrivals time: 0.02033480489626527 Scheduler time: 0.2789377854205668 Scheduler overhead time: 0.14501622831448913 Adapter cache time: 0.0315909874625504 Engine time: 0.14789643744006753 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-32/adapters_96_slots_32_rate_0.0125-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-32/adapters_96_slots_32_rate_0.0125-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 135, 66, 66, 66, 66, 135, 66, 135, 66, 33, 135, 33, 33, 135, 66, 135, 66, 135, 135, 66, 33, 135, 66, 33, 33, 66, 135, 33, 66, 33, 33, 66, 66, 66, 33, 33, 135, 66, 66, 33, 135, 135, 66, 135, 135, 66, 135, 33, 135, 66, 66, 66, 135, 135, 33, 33, 66, 33, 135, 33, 33, 135, 33, 66, 66, 33, 66, 135, 135, 135, 66, 135, 135, 33, 33, 135, 66, 135, 33, 66, 135, 33, 135, 66, 33, 135, 33, 33, 135, 33, 33, 66]
Prompts retrieved: 7488 . Total input tokens: 1626076 . Total output tokens: 1517852
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 0.6954762111417949,
    "estimated_duration": 3599.026987936325,
    "input_throughput": 161.63452009387714,
    "output_throughput": 147.42290118369826,
    "total_throughput": 309.0574212775754,
    "itl": 17.982808894671706,
    "ttft": 8938.248943877594,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1429,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.765426586456579,
    "arrivals": 2425,
    "finished_requests": 2419,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6955288113094866. Arrivals time: 0.019949535839259624 Scheduler time: 0.27974293660372496 Scheduler overhead time: 0.14508570171892643 Adapter cache time: 0.031598560977727175 Engine time: 0.14574279263615608 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-8-8/adapters_96_slots_64_rate_3.2-1.6-0.8_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-8-8/adapters_96_slots_64_rate_3.2-1.6-0.8_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [32 32 32]
Adapter prompts. [8640, 8640, 8640, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 8640, 34560, 8640, 8640, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 8640, 34560, 17280, 8640, 8640, 17280, 34560, 8640, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 34560, 17280, 17280, 8640, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 8640, 34560, 17280, 17280, 17280, 34560, 34560, 8640, 8640, 17280, 8640, 34560, 8640, 8640, 34560, 8640, 17280, 17280, 8640, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 8640, 8640, 34560, 17280, 34560, 8640, 17280, 34560, 8640, 34560, 17280, 8640, 34560, 8640, 8640, 34560, 8640, 8640, 17280]
Prompts retrieved: 1935360 . Total input tokens: 431807893 . Total output tokens: 386940663
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 57.64377412898466,
    "estimated_duration": 3600.052810890478,
    "input_throughput": 6520.519901538228,
    "output_throughput": 5734.968092007833,
    "total_throughput": 12255.48799354606,
    "itl": 149.44693932409902,
    "ttft": 1979476.5942608675,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 146,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4468312106141815,
    "arrivals": 644954,
    "finished_requests": 94936,
    "scheduler_time": 106.18556111157497
}
#Debug simulation 
Total elapsed time: 57.643951181788. Arrivals time: 0.48466191813349724 Scheduler time: 57.002796155400574 Scheduler overhead time: 0.06078627239912748 Adapter cache time: 0.012390071991831064 Engine time: 0.06071158358827233 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-8-16/adapters_96_slots_64_rate_3.2-1.6-0.8_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-8-16/adapters_96_slots_64_rate_3.2-1.6-0.8_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [32 32 32]
Adapter prompts. [8640, 8640, 8640, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 8640, 34560, 8640, 8640, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 8640, 34560, 17280, 8640, 8640, 17280, 34560, 8640, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 34560, 17280, 17280, 8640, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 8640, 34560, 17280, 17280, 17280, 34560, 34560, 8640, 8640, 17280, 8640, 34560, 8640, 8640, 34560, 8640, 17280, 17280, 8640, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 8640, 8640, 34560, 17280, 34560, 8640, 17280, 34560, 8640, 34560, 17280, 8640, 34560, 8640, 8640, 34560, 8640, 8640, 17280]
Prompts retrieved: 1935360 . Total input tokens: 431807893 . Total output tokens: 386940663
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 49.550074136350304,
    "estimated_duration": 3600.0694666708214,
    "input_throughput": 6500.359011583422,
    "output_throughput": 5724.220377074265,
    "total_throughput": 12224.579388657688,
    "itl": 149.9250163100837,
    "ttft": 1973512.3851072993,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 158,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5165562409861015,
    "arrivals": 644954,
    "finished_requests": 94694,
    "scheduler_time": 105.90711707769309
}
#Debug simulation 
Total elapsed time: 49.55019479012117. Arrivals time: 0.4781146664172411 Scheduler time: 48.921044915448874 Scheduler overhead time: 0.060554363299161196 Adapter cache time: 0.012184180319309235 Engine time: 0.05639572814106941 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-8-32/adapters_96_slots_64_rate_3.2-1.6-0.8_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-8-32/adapters_96_slots_64_rate_3.2-1.6-0.8_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [32 32 32]
Adapter prompts. [8640, 8640, 8640, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 8640, 34560, 8640, 8640, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 8640, 34560, 17280, 8640, 8640, 17280, 34560, 8640, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 34560, 17280, 17280, 8640, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 8640, 34560, 17280, 17280, 17280, 34560, 34560, 8640, 8640, 17280, 8640, 34560, 8640, 8640, 34560, 8640, 17280, 17280, 8640, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 8640, 8640, 34560, 17280, 34560, 8640, 17280, 34560, 8640, 34560, 17280, 8640, 34560, 8640, 8640, 34560, 8640, 8640, 17280]
Prompts retrieved: 1935360 . Total input tokens: 431807893 . Total output tokens: 386940663
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 49.46953907236457,
    "estimated_duration": 3600.070217515652,
    "input_throughput": 6500.357655842932,
    "output_throughput": 5724.219183208307,
    "total_throughput": 12224.57683905124,
    "itl": 149.92502272900705,
    "ttft": 1973512.8915927422,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 158,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5172987075150032,
    "arrivals": 644954,
    "finished_requests": 94694,
    "scheduler_time": 105.90712545598689
}
#Debug simulation 
Total elapsed time: 49.46970417816192. Arrivals time: 0.48501682933419943 Scheduler time: 48.83342169504613 Scheduler overhead time: 0.05910496134310961 Adapter cache time: 0.012398161459714174 Engine time: 0.05785118043422699 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-16-16/adapters_96_slots_64_rate_3.2-1.6-0.8_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-16-16/adapters_96_slots_64_rate_3.2-1.6-0.8_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [32 32 32]
Adapter prompts. [8640, 8640, 8640, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 8640, 34560, 8640, 8640, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 8640, 34560, 17280, 8640, 8640, 17280, 34560, 8640, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 34560, 17280, 17280, 8640, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 8640, 34560, 17280, 17280, 17280, 34560, 34560, 8640, 8640, 17280, 8640, 34560, 8640, 8640, 34560, 8640, 17280, 17280, 8640, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 8640, 8640, 34560, 17280, 34560, 8640, 17280, 34560, 8640, 34560, 17280, 8640, 34560, 8640, 8640, 34560, 8640, 8640, 17280]
Prompts retrieved: 1935360 . Total input tokens: 431807893 . Total output tokens: 386940663
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 49.41796799516305,
    "estimated_duration": 3600.0995768977937,
    "input_throughput": 6506.081984594218,
    "output_throughput": 5723.898897751244,
    "total_throughput": 12229.98088234546,
    "itl": 149.85852499497744,
    "ttft": 1973572.1545396664,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5025151709723289,
    "arrivals": 644954,
    "finished_requests": 94676,
    "scheduler_time": 105.91298309099142
}
#Debug simulation 
Total elapsed time: 49.418130518868566. Arrivals time: 0.48593791341409087 Scheduler time: 48.779697622172534 Scheduler overhead time: 0.06019141944125295 Adapter cache time: 0.01224110135808587 Engine time: 0.05780758988112211 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-16-32/adapters_96_slots_64_rate_3.2-1.6-0.8_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-16-32/adapters_96_slots_64_rate_3.2-1.6-0.8_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [32 32 32]
Adapter prompts. [8640, 8640, 8640, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 8640, 34560, 8640, 8640, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 8640, 34560, 17280, 8640, 8640, 17280, 34560, 8640, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 34560, 17280, 17280, 8640, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 8640, 34560, 17280, 17280, 17280, 34560, 34560, 8640, 8640, 17280, 8640, 34560, 8640, 8640, 34560, 8640, 17280, 17280, 8640, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 8640, 8640, 34560, 17280, 34560, 8640, 17280, 34560, 8640, 34560, 17280, 8640, 34560, 8640, 8640, 34560, 8640, 8640, 17280]
Prompts retrieved: 1935360 . Total input tokens: 431807893 . Total output tokens: 386940663
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 49.754355950281024,
    "estimated_duration": 3600.117232017957,
    "input_throughput": 6497.507578909675,
    "output_throughput": 5721.366186860123,
    "total_throughput": 12218.873765769798,
    "itl": 149.9805234214296,
    "ttft": 1973372.7788163186,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 157,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.52020563049242,
    "arrivals": 644954,
    "finished_requests": 94653,
    "scheduler_time": 105.8688585290836
}
#Debug simulation 
Total elapsed time: 49.75452135596424. Arrivals time: 0.434142435900867 Scheduler time: 49.16519656730816 Scheduler overhead time: 0.061373906675726175 Adapter cache time: 0.012762293219566345 Engine time: 0.05883211875334382 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_16-16-16/adapters_96_slots_64_rate_3.2-1.6-0.8_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_16-16-16/adapters_96_slots_64_rate_3.2-1.6-0.8_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [32 32 32]
Adapter prompts. [8640, 8640, 8640, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 8640, 34560, 8640, 8640, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 8640, 34560, 17280, 8640, 8640, 17280, 34560, 8640, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 34560, 17280, 17280, 8640, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 8640, 34560, 17280, 17280, 17280, 34560, 34560, 8640, 8640, 17280, 8640, 34560, 8640, 8640, 34560, 8640, 17280, 17280, 8640, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 8640, 8640, 34560, 17280, 34560, 8640, 17280, 34560, 8640, 34560, 17280, 8640, 34560, 8640, 8640, 34560, 8640, 8640, 17280]
Prompts retrieved: 1935360 . Total input tokens: 431807893 . Total output tokens: 386940663
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 57.75642448104918,
    "estimated_duration": 3600.017683310967,
    "input_throughput": 6520.583526248282,
    "output_throughput": 5735.024051607303,
    "total_throughput": 12255.607577855586,
    "itl": 149.44596471161267,
    "ttft": 1979470.0679108552,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 146,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4365473430557182,
    "arrivals": 644954,
    "finished_requests": 94936,
    "scheduler_time": 106.18511376643701
}
#Debug simulation 
Total elapsed time: 57.75659649493173. Arrivals time: 0.4854886448010802 Scheduler time: 57.116204641759396 Scheduler overhead time: 0.06121807778254151 Adapter cache time: 0.012416393496096134 Engine time: 0.058659862261265516 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_16-16-32/adapters_96_slots_64_rate_3.2-1.6-0.8_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_16-16-32/adapters_96_slots_64_rate_3.2-1.6-0.8_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [32 32 32]
Adapter prompts. [8640, 8640, 8640, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 8640, 34560, 8640, 8640, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 8640, 34560, 17280, 8640, 8640, 17280, 34560, 8640, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 34560, 17280, 17280, 8640, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 8640, 34560, 17280, 17280, 17280, 34560, 34560, 8640, 8640, 17280, 8640, 34560, 8640, 8640, 34560, 8640, 17280, 17280, 8640, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 8640, 8640, 34560, 17280, 34560, 8640, 17280, 34560, 8640, 34560, 17280, 8640, 34560, 8640, 8640, 34560, 8640, 8640, 17280]
Prompts retrieved: 1935360 . Total input tokens: 431807893 . Total output tokens: 386940663
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 49.90492288209498,
    "estimated_duration": 3600.1248354355744,
    "input_throughput": 6497.493856256753,
    "output_throughput": 5721.354103407896,
    "total_throughput": 12218.84795966465,
    "itl": 149.98080416292282,
    "ttft": 1973376.268721167,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 157,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5273735963180661,
    "arrivals": 644954,
    "finished_requests": 94653,
    "scheduler_time": 105.86889831672022
}
#Debug simulation 
Total elapsed time: 49.90509147616103. Arrivals time: 0.7222783658653498 Scheduler time: 49.031584033276886 Scheduler overhead time: 0.059790536761283875 Adapter cache time: 0.01224757032468915 Engine time: 0.057132202200591564 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-8-8/adapters_96_slots_64_rate_3.2-1.6-0.4_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-8-8/adapters_96_slots_64_rate_3.2-1.6-0.4_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [32 32 32]
Adapter prompts. [4320, 4320, 4320, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 4320, 34560, 4320, 4320, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 4320, 34560, 17280, 4320, 4320, 17280, 34560, 4320, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 4320, 34560, 17280, 17280, 4320, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 4320, 34560, 17280, 17280, 17280, 34560, 34560, 4320, 4320, 17280, 4320, 34560, 4320, 4320, 34560, 4320, 17280, 17280, 4320, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 4320, 4320, 34560, 17280, 34560, 4320, 17280, 34560, 4320, 34560, 17280, 4320, 34560, 4320, 4320, 34560, 4320, 4320, 17280]
Prompts retrieved: 1797120 . Total input tokens: 400994416 . Total output tokens: 359255850
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 40.711022421717644,
    "estimated_duration": 3600.031537142823,
    "input_throughput": 6402.833353591683,
    "output_throughput": 5634.3253637434145,
    "total_throughput": 12037.158717335098,
    "itl": 152.51202993613677,
    "ttft": 1945565.769185558,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 92,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.28156487244181305,
    "arrivals": 599169,
    "finished_requests": 93043,
    "scheduler_time": 104.17193074299774
}
#Debug simulation 
Total elapsed time: 40.71119951410219. Arrivals time: 0.4022727212868631 Scheduler time: 40.16230381419882 Scheduler overhead time: 0.05834482330828905 Adapter cache time: 0.011079985182732344 Engine time: 0.055776892229914665 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-8-16/adapters_96_slots_64_rate_3.2-1.6-0.4_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-8-16/adapters_96_slots_64_rate_3.2-1.6-0.4_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [32 32 32]
Adapter prompts. [4320, 4320, 4320, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 4320, 34560, 4320, 4320, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 4320, 34560, 17280, 4320, 4320, 17280, 34560, 4320, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 4320, 34560, 17280, 17280, 4320, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 4320, 34560, 17280, 17280, 17280, 34560, 34560, 4320, 4320, 17280, 4320, 34560, 4320, 4320, 34560, 4320, 17280, 17280, 4320, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 4320, 4320, 34560, 17280, 34560, 4320, 17280, 34560, 4320, 34560, 17280, 4320, 34560, 4320, 4320, 34560, 4320, 4320, 17280]
Prompts retrieved: 1797120 . Total input tokens: 400994416 . Total output tokens: 359255850
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 40.48114819871262,
    "estimated_duration": 3600.1436028958965,
    "input_throughput": 6402.71598651187,
    "output_throughput": 5634.244418384814,
    "total_throughput": 12036.960404896685,
    "itl": 152.51313813043444,
    "ttft": 1945543.0285763517,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 92,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.29837456028209997,
    "arrivals": 599169,
    "finished_requests": 93043,
    "scheduler_time": 104.17515829947048
}
#Debug simulation 
Total elapsed time: 40.48132300376892. Arrivals time: 0.45925605529919267 Scheduler time: 39.876055299304426 Scheduler overhead time: 0.05796415917575359 Adapter cache time: 0.011075765360146761 Engine time: 0.05600248323753476 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-8-32/adapters_96_slots_64_rate_3.2-1.6-0.4_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-8-32/adapters_96_slots_64_rate_3.2-1.6-0.4_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [32 32 32]
Adapter prompts. [4320, 4320, 4320, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 4320, 34560, 4320, 4320, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 4320, 34560, 17280, 4320, 4320, 17280, 34560, 4320, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 4320, 34560, 17280, 17280, 4320, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 4320, 34560, 17280, 17280, 17280, 34560, 34560, 4320, 4320, 17280, 4320, 34560, 4320, 4320, 34560, 4320, 17280, 17280, 4320, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 4320, 4320, 34560, 17280, 34560, 4320, 17280, 34560, 4320, 34560, 17280, 4320, 34560, 4320, 4320, 34560, 4320, 4320, 17280]
Prompts retrieved: 1797120 . Total input tokens: 400994416 . Total output tokens: 359255850
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 40.52943804068491,
    "estimated_duration": 3600.144437844852,
    "input_throughput": 6402.7145015878305,
    "output_throughput": 5634.243111685438,
    "total_throughput": 12036.957613273269,
    "itl": 152.51313575729273,
    "ttft": 1945543.685351373,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 92,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2992268412746491,
    "arrivals": 599169,
    "finished_requests": 93043,
    "scheduler_time": 104.1751654670282
}
#Debug simulation 
Total elapsed time: 40.52961379569024. Arrivals time: 0.45837061712518334 Scheduler time: 39.92509875493124 Scheduler overhead time: 0.05860962672159076 Adapter cache time: 0.01084617292508483 Engine time: 0.05544513603672385 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-16-16/adapters_96_slots_64_rate_3.2-1.6-0.4_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-16-16/adapters_96_slots_64_rate_3.2-1.6-0.4_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [32 32 32]
Adapter prompts. [4320, 4320, 4320, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 4320, 34560, 4320, 4320, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 4320, 34560, 17280, 4320, 4320, 17280, 34560, 4320, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 4320, 34560, 17280, 17280, 4320, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 4320, 34560, 17280, 17280, 17280, 34560, 34560, 4320, 4320, 17280, 4320, 34560, 4320, 4320, 34560, 4320, 17280, 17280, 4320, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 4320, 4320, 34560, 17280, 34560, 4320, 17280, 34560, 4320, 34560, 17280, 4320, 34560, 4320, 4320, 34560, 4320, 4320, 17280]
Prompts retrieved: 1797120 . Total input tokens: 400994416 . Total output tokens: 359255850
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 40.64459786610678,
    "estimated_duration": 3600.0379956258134,
    "input_throughput": 6402.8218668822765,
    "output_throughput": 5634.315255740507,
    "total_throughput": 12037.137122622784,
    "itl": 152.51213611461222,
    "ttft": 1945570.2884666277,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 92,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.28693389136577035,
    "arrivals": 599169,
    "finished_requests": 93043,
    "scheduler_time": 104.17199947007555
}
#Debug simulation 
Total elapsed time: 40.64477627025917. Arrivals time: 0.45849408069625497 Scheduler time: 40.041052963119 Scheduler overhead time: 0.057509470731019974 Adapter cache time: 0.01086220983415842 Engine time: 0.055622981395572424 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-16-32/adapters_96_slots_64_rate_3.2-1.6-0.4_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-16-32/adapters_96_slots_64_rate_3.2-1.6-0.4_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [32 32 32]
Adapter prompts. [4320, 4320, 4320, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 4320, 34560, 4320, 4320, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 4320, 34560, 17280, 4320, 4320, 17280, 34560, 4320, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 4320, 34560, 17280, 17280, 4320, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 4320, 34560, 17280, 17280, 17280, 34560, 34560, 4320, 4320, 17280, 4320, 34560, 4320, 4320, 34560, 4320, 17280, 17280, 4320, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 4320, 4320, 34560, 17280, 34560, 4320, 17280, 34560, 4320, 34560, 17280, 4320, 34560, 4320, 4320, 34560, 4320, 4320, 17280]
Prompts retrieved: 1797120 . Total input tokens: 400994416 . Total output tokens: 359255850
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 40.643996831960976,
    "estimated_duration": 3600.1493616961166,
    "input_throughput": 6402.7057447250645,
    "output_throughput": 5634.235405845407,
    "total_throughput": 12036.94115057047,
    "itl": 152.513159990609,
    "ttft": 1945546.7771359496,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 92,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.30274794729426496,
    "arrivals": 599169,
    "finished_requests": 93043,
    "scheduler_time": 104.1752193224688
}
#Debug simulation 
Total elapsed time: 40.6441699648276. Arrivals time: 0.45750712463632226 Scheduler time: 40.04033538280055 Scheduler overhead time: 0.05857506021857262 Adapter cache time: 0.011131186969578266 Engine time: 0.055572316981852055 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_16-16-16/adapters_96_slots_64_rate_3.2-1.6-0.4_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_16-16-16/adapters_96_slots_64_rate_3.2-1.6-0.4_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [32 32 32]
Adapter prompts. [4320, 4320, 4320, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 4320, 34560, 4320, 4320, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 4320, 34560, 17280, 4320, 4320, 17280, 34560, 4320, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 4320, 34560, 17280, 17280, 4320, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 4320, 34560, 17280, 17280, 17280, 34560, 34560, 4320, 4320, 17280, 4320, 34560, 4320, 4320, 34560, 4320, 17280, 17280, 4320, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 4320, 4320, 34560, 17280, 34560, 4320, 17280, 34560, 4320, 34560, 17280, 4320, 34560, 4320, 4320, 34560, 4320, 4320, 17280]
Prompts retrieved: 1797120 . Total input tokens: 400994416 . Total output tokens: 359255850
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 43.00526582216844,
    "estimated_duration": 3600.15888141306,
    "input_throughput": 6402.735201217717,
    "output_throughput": 5634.289948903147,
    "total_throughput": 12037.025150120864,
    "itl": 152.51211485724974,
    "ttft": 1945568.3088264044,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 92,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.27508462713100046,
    "arrivals": 599169,
    "finished_requests": 93045,
    "scheduler_time": 104.17568032068168
}
#Debug simulation 
Total elapsed time: 43.005422052927315. Arrivals time: 0.429133010096848 Scheduler time: 42.4180642189458 Scheduler overhead time: 0.06389476824551821 Adapter cache time: 0.011426948010921478 Engine time: 0.060517887119203806 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_16-16-32/adapters_96_slots_64_rate_3.2-1.6-0.4_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_16-16-32/adapters_96_slots_64_rate_3.2-1.6-0.4_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [32 32 32]
Adapter prompts. [4320, 4320, 4320, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 4320, 34560, 4320, 4320, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 4320, 34560, 17280, 4320, 4320, 17280, 34560, 4320, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 4320, 34560, 17280, 17280, 4320, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 4320, 34560, 17280, 17280, 17280, 34560, 34560, 4320, 4320, 17280, 4320, 34560, 4320, 4320, 34560, 4320, 17280, 17280, 4320, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 4320, 4320, 34560, 17280, 34560, 4320, 17280, 34560, 4320, 34560, 17280, 4320, 34560, 4320, 4320, 34560, 4320, 4320, 17280]
Prompts retrieved: 1797120 . Total input tokens: 400994416 . Total output tokens: 359255850
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 41.32757697906345,
    "estimated_duration": 3600.153032383208,
    "input_throughput": 6402.6992165777565,
    "output_throughput": 5634.229661224278,
    "total_throughput": 12036.928877802035,
    "itl": 152.51323700784218,
    "ttft": 1945549.3675117374,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 92,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.30639480710029565,
    "arrivals": 599169,
    "finished_requests": 93043,
    "scheduler_time": 104.17524314975523
}
#Debug simulation 
Total elapsed time: 41.3277228847146. Arrivals time: 0.4619588856585324 Scheduler time: 40.71877365000546 Scheduler overhead time: 0.05675678001716733 Adapter cache time: 0.010688079986721277 Engine time: 0.057921193074434996 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-8-8/adapters_96_slots_64_rate_3.2-1.6-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-8-8/adapters_96_slots_64_rate_3.2-1.6-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 1080, 34560, 1080, 1080, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 1080, 34560, 17280, 1080, 1080, 17280, 34560, 1080, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 34560, 17280, 17280, 1080, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 1080, 34560, 17280, 17280, 17280, 34560, 34560, 1080, 1080, 17280, 1080, 34560, 1080, 1080, 34560, 1080, 17280, 17280, 1080, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 1080, 1080, 34560, 17280, 34560, 1080, 17280, 34560, 1080, 34560, 17280, 1080, 34560, 1080, 1080, 34560, 1080, 1080, 17280]
Prompts retrieved: 1693440 . Total input tokens: 377834478 . Total output tokens: 338505042
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 13.886050707660615,
    "estimated_duration": 3600.06697717915,
    "input_throughput": 6413.695952426995,
    "output_throughput": 5630.16802978534,
    "total_throughput": 12043.863982212335,
    "itl": 152.2691278377983,
    "ttft": 1945975.0685376385,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 113,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3458351150644008,
    "arrivals": 564644,
    "finished_requests": 92946,
    "scheduler_time": 104.11114486498877
}
#Debug simulation 
Total elapsed time: 13.886170256882906. Arrivals time: 0.33160652220249176 Scheduler time: 13.444993396289647 Scheduler overhead time: 0.04134789668023586 Adapter cache time: 0.007875811774283648 Engine time: 0.04218766000121832 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-8-16/adapters_96_slots_64_rate_3.2-1.6-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-8-16/adapters_96_slots_64_rate_3.2-1.6-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 1080, 34560, 1080, 1080, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 1080, 34560, 17280, 1080, 1080, 17280, 34560, 1080, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 34560, 17280, 17280, 1080, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 1080, 34560, 17280, 17280, 17280, 34560, 34560, 1080, 1080, 17280, 1080, 34560, 1080, 1080, 34560, 1080, 17280, 17280, 1080, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 1080, 1080, 34560, 17280, 34560, 1080, 17280, 34560, 1080, 34560, 17280, 1080, 34560, 1080, 1080, 34560, 1080, 1080, 17280]
Prompts retrieved: 1693440 . Total input tokens: 377834478 . Total output tokens: 338505042
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 13.96503943623975,
    "estimated_duration": 3600.062750639641,
    "input_throughput": 6413.3184889340555,
    "output_throughput": 5630.044364198595,
    "total_throughput": 12043.36285313265,
    "itl": 152.2720908775495,
    "ttft": 1945995.27428283,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 113,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3705633087991736,
    "arrivals": 564644,
    "finished_requests": 92944,
    "scheduler_time": 104.11073639182158
}
#Debug simulation 
Total elapsed time: 13.965152281336486. Arrivals time: 0.34230686677619815 Scheduler time: 13.512826063670218 Scheduler overhead time: 0.04182673804461956 Adapter cache time: 0.007569498848170042 Engine time: 0.04268966894596815 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-8-32/adapters_96_slots_64_rate_3.2-1.6-0.1_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-8-32/adapters_96_slots_64_rate_3.2-1.6-0.1_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 1080, 34560, 1080, 1080, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 1080, 34560, 17280, 1080, 1080, 17280, 34560, 1080, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 34560, 17280, 17280, 1080, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 1080, 34560, 17280, 17280, 17280, 34560, 34560, 1080, 1080, 17280, 1080, 34560, 1080, 1080, 34560, 1080, 17280, 17280, 1080, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 1080, 1080, 34560, 17280, 34560, 1080, 17280, 34560, 1080, 34560, 17280, 1080, 34560, 1080, 1080, 34560, 1080, 1080, 17280]
Prompts retrieved: 1693440 . Total input tokens: 377834478 . Total output tokens: 338505042
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 13.833207496907562,
    "estimated_duration": 3600.0128985768315,
    "input_throughput": 6413.682575728479,
    "output_throughput": 5630.07510556769,
    "total_throughput": 12043.757681296169,
    "itl": 152.27076465053128,
    "ttft": 1945941.96039901,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 113,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3708974294736989,
    "arrivals": 564644,
    "finished_requests": 92944,
    "scheduler_time": 104.10942843935544
}
#Debug simulation 
Total elapsed time: 13.833329949062318. Arrivals time: 0.32183795142918825 Scheduler time: 13.402026833966374 Scheduler overhead time: 0.041417460422962904 Adapter cache time: 0.007750297896564007 Engine time: 0.042255112901329994 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-16-16/adapters_96_slots_64_rate_3.2-1.6-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-16-16/adapters_96_slots_64_rate_3.2-1.6-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 1080, 34560, 1080, 1080, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 1080, 34560, 17280, 1080, 1080, 17280, 34560, 1080, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 34560, 17280, 17280, 1080, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 1080, 34560, 17280, 17280, 17280, 34560, 34560, 1080, 1080, 17280, 1080, 34560, 1080, 1080, 34560, 1080, 17280, 17280, 1080, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 1080, 1080, 34560, 17280, 34560, 1080, 17280, 34560, 1080, 34560, 17280, 1080, 34560, 1080, 1080, 34560, 1080, 1080, 17280]
Prompts retrieved: 1693440 . Total input tokens: 377834478 . Total output tokens: 338505042
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 13.910660305991769,
    "estimated_duration": 3600.092768617525,
    "input_throughput": 6413.726946504997,
    "output_throughput": 5630.2296364945205,
    "total_throughput": 12043.956582999517,
    "itl": 152.2696626556307,
    "ttft": 1945972.3389705704,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 113,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3538109007431196,
    "arrivals": 564644,
    "finished_requests": 92947,
    "scheduler_time": 104.11176470155799
}
#Debug simulation 
Total elapsed time: 13.910775227006525. Arrivals time: 0.38842021115124226 Scheduler time: 13.412525496911258 Scheduler overhead time: 0.04141854215413332 Adapter cache time: 0.007861112710088491 Engine time: 0.04263234045356512 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-16-32/adapters_96_slots_64_rate_3.2-1.6-0.1_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-16-32/adapters_96_slots_64_rate_3.2-1.6-0.1_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 1080, 34560, 1080, 1080, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 1080, 34560, 17280, 1080, 1080, 17280, 34560, 1080, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 34560, 17280, 17280, 1080, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 1080, 34560, 17280, 17280, 17280, 34560, 34560, 1080, 1080, 17280, 1080, 34560, 1080, 1080, 34560, 1080, 17280, 17280, 1080, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 1080, 1080, 34560, 17280, 34560, 1080, 17280, 34560, 1080, 34560, 17280, 1080, 34560, 1080, 1080, 34560, 1080, 1080, 17280]
Prompts retrieved: 1693440 . Total input tokens: 377834478 . Total output tokens: 338505042
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 14.589588892180473,
    "estimated_duration": 3600.0418603945086,
    "input_throughput": 6413.817643073098,
    "output_throughput": 5630.309253620399,
    "total_throughput": 12044.126896693499,
    "itl": 152.27079947385454,
    "ttft": 1945968.7578822402,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 113,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3760533347167076,
    "arrivals": 564644,
    "finished_requests": 92947,
    "scheduler_time": 104.11021266017065
}
#Debug simulation 
Total elapsed time: 14.589701151009649. Arrivals time: 0.4154267213307321 Scheduler time: 14.057236281223595 Scheduler overhead time: 0.04420147696509957 Adapter cache time: 0.008369657676666975 Engine time: 0.04562262957915664 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_16-16-16/adapters_96_slots_64_rate_3.2-1.6-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_16-16-16/adapters_96_slots_64_rate_3.2-1.6-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 1080, 34560, 1080, 1080, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 1080, 34560, 17280, 1080, 1080, 17280, 34560, 1080, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 34560, 17280, 17280, 1080, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 1080, 34560, 17280, 17280, 17280, 34560, 34560, 1080, 1080, 17280, 1080, 34560, 1080, 1080, 34560, 1080, 17280, 17280, 1080, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 1080, 1080, 34560, 17280, 34560, 1080, 17280, 34560, 1080, 34560, 17280, 1080, 34560, 1080, 1080, 34560, 1080, 1080, 17280]
Prompts retrieved: 1693440 . Total input tokens: 377834478 . Total output tokens: 338505042
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 14.527919544838369,
    "estimated_duration": 3600.0308241350526,
    "input_throughput": 6413.837305281305,
    "output_throughput": 5630.326513904207,
    "total_throughput": 12044.16381918551,
    "itl": 152.26857889180923,
    "ttft": 1945966.2900441817,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 113,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.33787568332394624,
    "arrivals": 564644,
    "finished_requests": 92947,
    "scheduler_time": 104.11019554108088
}
#Debug simulation 
Total elapsed time: 14.528013434726745. Arrivals time: 0.3991297441534698 Scheduler time: 14.013292124960572 Scheduler overhead time: 0.04404193116351962 Adapter cache time: 0.008310920093208551 Engine time: 0.044514641631394625 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_16-16-32/adapters_96_slots_64_rate_3.2-1.6-0.1_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_16-16-32/adapters_96_slots_64_rate_3.2-1.6-0.1_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 1080, 34560, 1080, 1080, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 1080, 34560, 17280, 1080, 1080, 17280, 34560, 1080, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 34560, 17280, 17280, 1080, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 1080, 34560, 17280, 17280, 17280, 34560, 34560, 1080, 1080, 17280, 1080, 34560, 1080, 1080, 34560, 1080, 17280, 17280, 1080, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 1080, 1080, 34560, 17280, 34560, 1080, 17280, 34560, 1080, 34560, 17280, 1080, 34560, 1080, 1080, 34560, 1080, 1080, 17280]
Prompts retrieved: 1693440 . Total input tokens: 377834478 . Total output tokens: 338505042
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 14.466169785708189,
    "estimated_duration": 3600.045617602261,
    "input_throughput": 6413.810949256428,
    "output_throughput": 5630.303377516643,
    "total_throughput": 12044.114326773071,
    "itl": 152.27076633971228,
    "ttft": 1945970.8754205166,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 113,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3809577323868866,
    "arrivals": 564644,
    "finished_requests": 92947,
    "scheduler_time": 104.11020768570867
}
#Debug simulation 
Total elapsed time: 14.466307203751057. Arrivals time: 0.41942395037040114 Scheduler time: 13.931936956942081 Scheduler overhead time: 0.04329277714714408 Adapter cache time: 0.008302292786538601 Engine time: 0.04457572055980563 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-8-8/adapters_96_slots_64_rate_3.2-1.6-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-8-8/adapters_96_slots_64_rate_3.2-1.6-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 540, 34560, 540, 540, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 540, 34560, 17280, 540, 540, 17280, 34560, 540, 17280, 540, 540, 17280, 17280, 17280, 540, 540, 34560, 17280, 17280, 540, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 540, 34560, 17280, 17280, 17280, 34560, 34560, 540, 540, 17280, 540, 34560, 540, 540, 34560, 540, 17280, 17280, 540, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 540, 540, 34560, 17280, 34560, 540, 17280, 34560, 540, 34560, 17280, 540, 34560, 540, 540, 34560, 540, 540, 17280]
Prompts retrieved: 1676160 . Total input tokens: 373978445 . Total output tokens: 335072734
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 10.444431188050658,
    "estimated_duration": 3600.0926853364836,
    "input_throughput": 6387.079725379585,
    "output_throughput": 5633.113303610557,
    "total_throughput": 12020.193028990141,
    "itl": 152.7855669624435,
    "ttft": 1941389.9073708695,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 71,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21729462981922532,
    "arrivals": 558915,
    "finished_requests": 92891,
    "scheduler_time": 104.09178430730381
}
#Debug simulation 
Total elapsed time: 10.44453384866938. Arrivals time: 0.3226460642181337 Scheduler time: 10.01534957299009 Scheduler overhead time: 0.0403010593727231 Adapter cache time: 0.006983467843383551 Engine time: 0.0412727827206254 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-8-16/adapters_96_slots_64_rate_3.2-1.6-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-8-16/adapters_96_slots_64_rate_3.2-1.6-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 540, 34560, 540, 540, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 540, 34560, 17280, 540, 540, 17280, 34560, 540, 17280, 540, 540, 17280, 17280, 17280, 540, 540, 34560, 17280, 17280, 540, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 540, 34560, 17280, 17280, 17280, 34560, 34560, 540, 540, 17280, 540, 34560, 540, 540, 34560, 540, 17280, 17280, 540, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 540, 540, 34560, 17280, 34560, 540, 17280, 34560, 540, 34560, 17280, 540, 34560, 540, 540, 34560, 540, 540, 17280]
Prompts retrieved: 1676160 . Total input tokens: 373978445 . Total output tokens: 335072734
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 10.535655041690916,
    "estimated_duration": 3600.1606674622967,
    "input_throughput": 6387.468817109627,
    "output_throughput": 5633.194702472925,
    "total_throughput": 12020.663519582551,
    "itl": 152.78585832391394,
    "ttft": 1941391.2308335043,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 71,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2294545743125491,
    "arrivals": 558915,
    "finished_requests": 92894,
    "scheduler_time": 104.09374986063683
}
#Debug simulation 
Total elapsed time: 10.53577980492264. Arrivals time: 0.3532450832426548 Scheduler time: 10.075137318577617 Scheduler overhead time: 0.04087952710688114 Adapter cache time: 0.006843944545835257 Engine time: 0.041532344184815884 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-8-32/adapters_96_slots_64_rate_3.2-1.6-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-8-32/adapters_96_slots_64_rate_3.2-1.6-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 540, 34560, 540, 540, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 540, 34560, 17280, 540, 540, 17280, 34560, 540, 17280, 540, 540, 17280, 17280, 17280, 540, 540, 34560, 17280, 17280, 540, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 540, 34560, 17280, 17280, 17280, 34560, 34560, 540, 540, 17280, 540, 34560, 540, 540, 34560, 540, 17280, 17280, 540, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 540, 540, 34560, 17280, 34560, 540, 17280, 34560, 540, 34560, 17280, 540, 34560, 540, 540, 34560, 540, 540, 17280]
Prompts retrieved: 1676160 . Total input tokens: 373978445 . Total output tokens: 335072734
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 10.535995844751596,
    "estimated_duration": 3600.1614635752244,
    "input_throughput": 6387.467404632283,
    "output_throughput": 5633.193456790149,
    "total_throughput": 12020.660861422431,
    "itl": 152.78585164947094,
    "ttft": 1941391.8520525456,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 71,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23025423303246487,
    "arrivals": 558915,
    "finished_requests": 92894,
    "scheduler_time": 104.09375693133566
}
#Debug simulation 
Total elapsed time: 10.536098269745708. Arrivals time: 0.33012020448222756 Scheduler time: 10.099328877869993 Scheduler overhead time: 0.04076441656798124 Adapter cache time: 0.006938072387129068 Engine time: 0.041000441648066044 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-16-16/adapters_96_slots_64_rate_3.2-1.6-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-16-16/adapters_96_slots_64_rate_3.2-1.6-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 540, 34560, 540, 540, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 540, 34560, 17280, 540, 540, 17280, 34560, 540, 17280, 540, 540, 17280, 17280, 17280, 540, 540, 34560, 17280, 17280, 540, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 540, 34560, 17280, 17280, 17280, 34560, 34560, 540, 540, 17280, 540, 34560, 540, 540, 34560, 540, 17280, 17280, 540, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 540, 540, 34560, 17280, 34560, 540, 17280, 34560, 540, 34560, 17280, 540, 34560, 540, 540, 34560, 540, 540, 17280]
Prompts retrieved: 1676160 . Total input tokens: 373978445 . Total output tokens: 335072734
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 10.561303383670747,
    "estimated_duration": 3600.103823175817,
    "input_throughput": 6387.135796465899,
    "output_throughput": 5633.096431677439,
    "total_throughput": 12020.232228143337,
    "itl": 152.78494314240592,
    "ttft": 1941401.2255114657,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 71,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.22087407262530187,
    "arrivals": 558915,
    "finished_requests": 92892,
    "scheduler_time": 104.09206776388329
}
#Debug simulation 
Total elapsed time: 10.561442519072443. Arrivals time: 0.3555016564205289 Scheduler time: 10.097709557041526 Scheduler overhead time: 0.041280137840658426 Adapter cache time: 0.006977228447794914 Engine time: 0.04176861606538296 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-16-32/adapters_96_slots_64_rate_3.2-1.6-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-16-32/adapters_96_slots_64_rate_3.2-1.6-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 540, 34560, 540, 540, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 540, 34560, 17280, 540, 540, 17280, 34560, 540, 17280, 540, 540, 17280, 17280, 17280, 540, 540, 34560, 17280, 17280, 540, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 540, 34560, 17280, 17280, 17280, 34560, 34560, 540, 540, 17280, 540, 34560, 540, 540, 34560, 540, 17280, 17280, 540, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 540, 540, 34560, 17280, 34560, 540, 17280, 34560, 540, 34560, 17280, 540, 34560, 540, 540, 34560, 540, 540, 17280]
Prompts retrieved: 1676160 . Total input tokens: 373978445 . Total output tokens: 335072734
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 10.45306141115725,
    "estimated_duration": 3600.1643948721194,
    "input_throughput": 6387.462203879952,
    "output_throughput": 5633.188870176684,
    "total_throughput": 12020.651074056635,
    "itl": 152.78591898984598,
    "ttft": 1941394.0939368007,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 71,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2328950625471769,
    "arrivals": 558915,
    "finished_requests": 92894,
    "scheduler_time": 104.09379015583318
}
#Debug simulation 
Total elapsed time: 10.453158492222428. Arrivals time: 0.3222294566221535 Scheduler time: 10.023930145893246 Scheduler overhead time: 0.04076219676062465 Adapter cache time: 0.0069334846921265125 Engine time: 0.04121005488559604 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_16-16-16/adapters_96_slots_64_rate_3.2-1.6-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_16-16-16/adapters_96_slots_64_rate_3.2-1.6-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 540, 34560, 540, 540, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 540, 34560, 17280, 540, 540, 17280, 34560, 540, 17280, 540, 540, 17280, 17280, 17280, 540, 540, 34560, 17280, 17280, 540, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 540, 34560, 17280, 17280, 17280, 34560, 34560, 540, 540, 17280, 540, 34560, 540, 540, 34560, 540, 17280, 17280, 540, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 540, 540, 34560, 17280, 34560, 540, 17280, 34560, 540, 34560, 17280, 540, 34560, 540, 540, 34560, 540, 540, 17280]
Prompts retrieved: 1676160 . Total input tokens: 373978445 . Total output tokens: 335072734
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 10.487883881665766,
    "estimated_duration": 3600.0833486586826,
    "input_throughput": 6387.096290025375,
    "output_throughput": 5633.1279128734095,
    "total_throughput": 12020.224202898784,
    "itl": 152.7858538484998,
    "ttft": 1941386.6972466696,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 71,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21229357093805468,
    "arrivals": 558915,
    "finished_requests": 92891,
    "scheduler_time": 104.09160669754324
}
#Debug simulation 
Total elapsed time: 10.48801376670599. Arrivals time: 0.32598217809572816 Scheduler time: 10.055875965859741 Scheduler overhead time: 0.04018061188980937 Adapter cache time: 0.006780216470360756 Engine time: 0.04118272243067622 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_16-16-32/adapters_96_slots_64_rate_3.2-1.6-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_16-16-32/adapters_96_slots_64_rate_3.2-1.6-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 540, 34560, 540, 540, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 540, 34560, 17280, 540, 540, 17280, 34560, 540, 17280, 540, 540, 17280, 17280, 17280, 540, 540, 34560, 17280, 17280, 540, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 540, 34560, 17280, 17280, 17280, 34560, 34560, 540, 540, 17280, 540, 34560, 540, 540, 34560, 540, 17280, 17280, 540, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 540, 540, 34560, 17280, 34560, 540, 17280, 34560, 540, 34560, 17280, 540, 34560, 540, 540, 34560, 540, 540, 17280]
Prompts retrieved: 1676160 . Total input tokens: 373978445 . Total output tokens: 335072734
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 10.48150888690725,
    "estimated_duration": 3600.0172605217185,
    "input_throughput": 6387.048543391638,
    "output_throughput": 5632.96827000801,
    "total_throughput": 12020.016813399649,
    "itl": 152.78573488636482,
    "ttft": 1941355.8048254661,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 71,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2355358920618889,
    "arrivals": 558915,
    "finished_requests": 92888,
    "scheduler_time": 104.08951857475522
}
#Debug simulation 
Total elapsed time: 10.481605375185609. Arrivals time: 0.32218949124217033 Scheduler time: 10.052500726189464 Scheduler overhead time: 0.04049143474549055 Adapter cache time: 0.0068687815219163895 Engine time: 0.04153057420626283 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-8-8/adapters_96_slots_64_rate_3.2-1.6-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-8-8/adapters_96_slots_64_rate_3.2-1.6-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 270, 34560, 270, 270, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 270, 34560, 17280, 270, 270, 17280, 34560, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 270, 34560, 17280, 17280, 270, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 270, 34560, 17280, 17280, 17280, 34560, 34560, 270, 270, 17280, 270, 34560, 270, 270, 34560, 270, 17280, 17280, 270, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 270, 270, 34560, 17280, 34560, 270, 17280, 34560, 270, 34560, 17280, 270, 34560, 270, 270, 34560, 270, 270, 17280]
Prompts retrieved: 1667520 . Total input tokens: 372043367 . Total output tokens: 333338958
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 8.553935748990625,
    "estimated_duration": 3600.030463526828,
    "input_throughput": 6343.17743456779,
    "output_throughput": 5636.827022880212,
    "total_throughput": 11980.004457448003,
    "itl": 153.36878000752557,
    "ttft": 1940100.9045815193,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 66,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20199219109956157,
    "arrivals": 556029,
    "finished_requests": 92599,
    "scheduler_time": 104.07457382825837
}
#Debug simulation 
Total elapsed time: 8.554058387409896. Arrivals time: 0.3147116657346487 Scheduler time: 8.13570836186409 Scheduler overhead time: 0.03925847448408604 Adapter cache time: 0.006633352022618055 Engine time: 0.03986763954162598 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-8-16/adapters_96_slots_64_rate_3.2-1.6-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-8-16/adapters_96_slots_64_rate_3.2-1.6-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 270, 34560, 270, 270, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 270, 34560, 17280, 270, 270, 17280, 34560, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 270, 34560, 17280, 17280, 270, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 270, 34560, 17280, 17280, 17280, 34560, 34560, 270, 270, 17280, 270, 34560, 270, 270, 34560, 270, 17280, 17280, 270, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 270, 270, 34560, 17280, 34560, 270, 17280, 34560, 270, 34560, 17280, 270, 34560, 270, 270, 34560, 270, 270, 17280]
Prompts retrieved: 1667520 . Total input tokens: 372043367 . Total output tokens: 333338958
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 8.541411583777517,
    "estimated_duration": 3600.0868078691883,
    "input_throughput": 6343.13399057064,
    "output_throughput": 5636.7865784911255,
    "total_throughput": 11979.920569061765,
    "itl": 153.36905690491622,
    "ttft": 1940140.0924937793,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 66,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2124613462458365,
    "arrivals": 556029,
    "finished_requests": 92600,
    "scheduler_time": 104.0761625886591
}
#Debug simulation 
Total elapsed time: 8.541506876703352. Arrivals time: 0.32119391905143857 Scheduler time: 8.116328906267881 Scheduler overhead time: 0.03969058580696583 Adapter cache time: 0.006621245294809341 Engine time: 0.039996905252337456 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-8-32/adapters_96_slots_64_rate_3.2-1.6-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-8-32/adapters_96_slots_64_rate_3.2-1.6-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 270, 34560, 270, 270, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 270, 34560, 17280, 270, 270, 17280, 34560, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 270, 34560, 17280, 17280, 270, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 270, 34560, 17280, 17280, 17280, 34560, 34560, 270, 270, 17280, 270, 34560, 270, 270, 34560, 270, 17280, 17280, 270, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 270, 270, 34560, 17280, 34560, 270, 17280, 34560, 270, 34560, 17280, 270, 34560, 270, 270, 34560, 270, 270, 17280]
Prompts retrieved: 1667520 . Total input tokens: 372043367 . Total output tokens: 333338958
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 8.48201347514987,
    "estimated_duration": 3600.087694008049,
    "input_throughput": 6343.132429248249,
    "output_throughput": 5636.785191031691,
    "total_throughput": 11979.917620279939,
    "itl": 153.36906394677854,
    "ttft": 1940140.780248259,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 66,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.213350401315838,
    "arrivals": 556029,
    "finished_requests": 92600,
    "scheduler_time": 104.07617028894069
}
#Debug simulation 
Total elapsed time: 8.482139379251748. Arrivals time: 0.3104598671197891 Scheduler time: 8.06877220980823 Scheduler overhead time: 0.03934154054149985 Adapter cache time: 0.00657951133325696 Engine time: 0.03920316509902477 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-16-16/adapters_96_slots_64_rate_3.2-1.6-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-16-16/adapters_96_slots_64_rate_3.2-1.6-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 270, 34560, 270, 270, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 270, 34560, 17280, 270, 270, 17280, 34560, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 270, 34560, 17280, 17280, 270, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 270, 34560, 17280, 17280, 17280, 34560, 34560, 270, 270, 17280, 270, 34560, 270, 270, 34560, 270, 17280, 17280, 270, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 270, 270, 34560, 17280, 34560, 270, 17280, 34560, 270, 34560, 17280, 270, 34560, 270, 270, 34560, 270, 270, 17280]
Prompts retrieved: 1667520 . Total input tokens: 372043367 . Total output tokens: 333338958
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 8.577484015375376,
    "estimated_duration": 3600.074495947936,
    "input_throughput": 6343.155683501236,
    "output_throughput": 5636.805855779012,
    "total_throughput": 11979.961539280248,
    "itl": 153.36909103529447,
    "ttft": 1940135.042005156,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 66,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2051066305139103,
    "arrivals": 556029,
    "finished_requests": 92600,
    "scheduler_time": 104.07597267093165
}
#Debug simulation 
Total elapsed time: 8.577579427976161. Arrivals time: 0.35814636992290616 Scheduler time: 8.11483257310465 Scheduler overhead time: 0.03990273317322135 Adapter cache time: 0.006779540795832872 Engine time: 0.03986829333007336 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-16-32/adapters_96_slots_64_rate_3.2-1.6-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-16-32/adapters_96_slots_64_rate_3.2-1.6-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 270, 34560, 270, 270, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 270, 34560, 17280, 270, 270, 17280, 34560, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 270, 34560, 17280, 17280, 270, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 270, 34560, 17280, 17280, 17280, 34560, 34560, 270, 270, 17280, 270, 34560, 270, 270, 34560, 270, 17280, 17280, 270, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 270, 270, 34560, 17280, 34560, 270, 17280, 34560, 270, 34560, 17280, 270, 34560, 270, 270, 34560, 270, 270, 17280]
Prompts retrieved: 1667520 . Total input tokens: 372043367 . Total output tokens: 333338958
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 8.529037835076451,
    "estimated_duration": 3600.1466727286142,
    "input_throughput": 6343.0360137778225,
    "output_throughput": 5636.76256684827,
    "total_throughput": 11979.798580626091,
    "itl": 153.36983333954987,
    "ttft": 1940165.1743165578,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 66,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21561396947130546,
    "arrivals": 556029,
    "finished_requests": 92601,
    "scheduler_time": 104.07800847924058
}
#Debug simulation 
Total elapsed time: 8.529157374054193. Arrivals time: 0.3210399257950485 Scheduler time: 8.103991595096886 Scheduler overhead time: 0.03982724994421005 Adapter cache time: 0.006673985626548529 Engine time: 0.03988638240844011 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_16-16-16/adapters_96_slots_64_rate_3.2-1.6-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_16-16-16/adapters_96_slots_64_rate_3.2-1.6-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 270, 34560, 270, 270, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 270, 34560, 17280, 270, 270, 17280, 34560, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 270, 34560, 17280, 17280, 270, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 270, 34560, 17280, 17280, 17280, 34560, 34560, 270, 270, 17280, 270, 34560, 270, 270, 34560, 270, 17280, 17280, 270, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 270, 270, 34560, 17280, 34560, 270, 17280, 34560, 270, 34560, 17280, 270, 34560, 270, 270, 34560, 270, 270, 17280]
Prompts retrieved: 1667520 . Total input tokens: 372043367 . Total output tokens: 333338958
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 8.490281085018069,
    "estimated_duration": 3600.0256934476297,
    "input_throughput": 6343.185839357453,
    "output_throughput": 5636.834491746719,
    "total_throughput": 11980.020331104171,
    "itl": 153.36884161009755,
    "ttft": 1940097.793428648,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 66,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.19734331946354378,
    "arrivals": 556029,
    "finished_requests": 92599,
    "scheduler_time": 104.07454632603084
}
#Debug simulation 
Total elapsed time: 8.49038173398003. Arrivals time: 0.31698802346363664 Scheduler time: 8.069918280933052 Scheduler overhead time: 0.039368143770843744 Adapter cache time: 0.006655852776020765 Engine time: 0.039831789676100016 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_16-16-32/adapters_96_slots_64_rate_3.2-1.6-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_16-16-32/adapters_96_slots_64_rate_3.2-1.6-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 270, 34560, 270, 270, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 270, 34560, 17280, 270, 270, 17280, 34560, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 270, 34560, 17280, 17280, 270, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 270, 34560, 17280, 17280, 17280, 34560, 34560, 270, 270, 17280, 270, 34560, 270, 270, 34560, 270, 17280, 17280, 270, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 270, 270, 34560, 17280, 34560, 270, 17280, 34560, 270, 34560, 17280, 270, 34560, 270, 270, 34560, 270, 270, 17280]
Prompts retrieved: 1667520 . Total input tokens: 372043367 . Total output tokens: 333338958
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 8.471819932106882,
    "estimated_duration": 3600.1490570461865,
    "input_throughput": 6343.031812892807,
    "output_throughput": 5636.7588337161615,
    "total_throughput": 11979.790646608968,
    "itl": 153.36984682677138,
    "ttft": 1940167.0268403278,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 66,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21800329141318772,
    "arrivals": 556029,
    "finished_requests": 92601,
    "scheduler_time": 104.07803124107923
}
#Debug simulation 
Total elapsed time: 8.471944192890078. Arrivals time: 0.3129401463083923 Scheduler time: 8.0557337035425 Scheduler overhead time: 0.03949756734073162 Adapter cache time: 0.006502884440124035 Engine time: 0.03952464880421758 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-8/adapters_96_slots_64_rate_3.2-1.6-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-8/adapters_96_slots_64_rate_3.2-1.6-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 135, 34560, 135, 135, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 135, 34560, 17280, 135, 135, 17280, 34560, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 135, 34560, 17280, 17280, 135, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 135, 34560, 17280, 17280, 17280, 34560, 34560, 135, 135, 17280, 135, 34560, 135, 135, 34560, 135, 17280, 17280, 135, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 135, 135, 34560, 17280, 34560, 135, 17280, 34560, 135, 34560, 17280, 135, 34560, 135, 135, 34560, 135, 135, 17280]
Prompts retrieved: 1663200 . Total input tokens: 371069728 . Total output tokens: 332471114
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 7.627092674840242,
    "estimated_duration": 3600.030851608517,
    "input_throughput": 6390.852453311672,
    "output_throughput": 5629.609254860879,
    "total_throughput": 12020.461708172552,
    "itl": 152.54656305355437,
    "ttft": 1937041.9686503059,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 66,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20199219109956157,
    "arrivals": 554568,
    "finished_requests": 92835,
    "scheduler_time": 104.097642649214
}
#Debug simulation 
Total elapsed time: 7.627189930994064. Arrivals time: 0.31330709299072623 Scheduler time: 7.211696513928473 Scheduler overhead time: 0.03909160802140832 Adapter cache time: 0.006513544823974371 Engine time: 0.038987461011856794 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-16/adapters_96_slots_64_rate_3.2-1.6-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-16/adapters_96_slots_64_rate_3.2-1.6-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 135, 34560, 135, 135, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 135, 34560, 17280, 135, 135, 17280, 34560, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 135, 34560, 17280, 17280, 135, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 135, 34560, 17280, 17280, 17280, 34560, 34560, 135, 135, 17280, 135, 34560, 135, 135, 34560, 135, 17280, 17280, 135, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 135, 135, 34560, 17280, 34560, 135, 17280, 34560, 135, 34560, 17280, 135, 34560, 135, 135, 34560, 135, 135, 17280]
Prompts retrieved: 1663200 . Total input tokens: 371069728 . Total output tokens: 332471114
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.932677912991494,
    "estimated_duration": 3600.062326802214,
    "input_throughput": 6390.796578357131,
    "output_throughput": 5629.560035423644,
    "total_throughput": 12020.356613780776,
    "itl": 152.54646102071314,
    "ttft": 1937050.1154554177,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 66,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21246134624583649,
    "arrivals": 554568,
    "finished_requests": 92835,
    "scheduler_time": 104.09839529261065
}
#Debug simulation 
Total elapsed time: 7.932779290247709. Arrivals time: 0.3179592336528003 Scheduler time: 7.511486635543406 Scheduler overhead time: 0.03924731910228729 Adapter cache time: 0.006532022729516029 Engine time: 0.039765968918800354 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-32/adapters_96_slots_64_rate_3.2-1.6-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-32/adapters_96_slots_64_rate_3.2-1.6-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 135, 34560, 135, 135, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 135, 34560, 17280, 135, 135, 17280, 34560, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 135, 34560, 17280, 17280, 135, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 135, 34560, 17280, 17280, 17280, 34560, 34560, 135, 135, 17280, 135, 34560, 135, 135, 34560, 135, 17280, 17280, 135, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 135, 135, 34560, 17280, 34560, 135, 17280, 34560, 135, 34560, 17280, 135, 34560, 135, 135, 34560, 135, 135, 17280]
Prompts retrieved: 1663200 . Total input tokens: 371069728 . Total output tokens: 332471114
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.6326247858814895,
    "estimated_duration": 3600.0811531944896,
    "input_throughput": 6390.763158098471,
    "output_throughput": 5629.530596002405,
    "total_throughput": 12020.293754100876,
    "itl": 152.5466155741858,
    "ttft": 1937060.5457036844,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 66,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.213350401315838,
    "arrivals": 554568,
    "finished_requests": 92835,
    "scheduler_time": 104.09903412111716
}
#Debug simulation 
Total elapsed time: 7.6327202641405165. Arrivals time: 0.35852241795510054 Scheduler time: 7.171059244312346 Scheduler overhead time: 0.03918184246867895 Adapter cache time: 0.006564641371369362 Engine time: 0.03962927404791117 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-16-16/adapters_96_slots_64_rate_3.2-1.6-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-16-16/adapters_96_slots_64_rate_3.2-1.6-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 135, 34560, 135, 135, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 135, 34560, 17280, 135, 135, 17280, 34560, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 135, 34560, 17280, 17280, 135, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 135, 34560, 17280, 17280, 17280, 34560, 34560, 135, 135, 17280, 135, 34560, 135, 135, 34560, 135, 17280, 17280, 135, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 135, 135, 34560, 17280, 34560, 135, 17280, 34560, 135, 34560, 17280, 135, 34560, 135, 135, 34560, 135, 135, 17280]
Prompts retrieved: 1663200 . Total input tokens: 371069728 . Total output tokens: 332471114
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 7.622319413349032,
    "estimated_duration": 3600.0371015274154,
    "input_throughput": 6390.841358340038,
    "output_throughput": 5629.59948146125,
    "total_throughput": 12020.440839801287,
    "itl": 152.54659166545017,
    "ttft": 1937045.5553695522,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 66,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2051066305139103,
    "arrivals": 554568,
    "finished_requests": 92835,
    "scheduler_time": 104.09775226023699
}
#Debug simulation 
Total elapsed time: 7.622447138186544. Arrivals time: 0.31025048485025764 Scheduler time: 7.209529363550246 Scheduler overhead time: 0.039070242550224066 Adapter cache time: 0.006518152542412281 Engine time: 0.039235270116478205 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-16-32/adapters_96_slots_64_rate_3.2-1.6-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-16-32/adapters_96_slots_64_rate_3.2-1.6-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 135, 34560, 135, 135, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 135, 34560, 17280, 135, 135, 17280, 34560, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 135, 34560, 17280, 17280, 135, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 135, 34560, 17280, 17280, 17280, 34560, 34560, 135, 135, 17280, 135, 34560, 135, 135, 34560, 135, 17280, 17280, 135, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 135, 135, 34560, 17280, 34560, 135, 17280, 34560, 135, 34560, 17280, 135, 34560, 135, 135, 34560, 135, 135, 17280]
Prompts retrieved: 1663200 . Total input tokens: 371069728 . Total output tokens: 332471114
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 7.880278725642711,
    "estimated_duration": 3600.100371485467,
    "input_throughput": 6390.729042509108,
    "output_throughput": 5629.500544074432,
    "total_throughput": 12020.229586583539,
    "itl": 152.5465591402628,
    "ttft": 1937058.6362596268,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 66,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21561396947130543,
    "arrivals": 554568,
    "finished_requests": 92835,
    "scheduler_time": 104.09963778035174
}
#Debug simulation 
Total elapsed time: 7.8803457217291. Arrivals time: 0.3653500690124929 Scheduler time: 7.4129813951440156 Scheduler overhead time: 0.03904610872268677 Adapter cache time: 0.006445014849305153 Engine time: 0.03889188030734658 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_16-16-16/adapters_96_slots_64_rate_3.2-1.6-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_16-16-16/adapters_96_slots_64_rate_3.2-1.6-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 135, 34560, 135, 135, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 135, 34560, 17280, 135, 135, 17280, 34560, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 135, 34560, 17280, 17280, 135, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 135, 34560, 17280, 17280, 17280, 34560, 34560, 135, 135, 17280, 135, 34560, 135, 135, 34560, 135, 17280, 17280, 135, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 135, 135, 34560, 17280, 34560, 135, 17280, 34560, 135, 34560, 17280, 135, 34560, 135, 135, 34560, 135, 135, 17280]
Prompts retrieved: 1663200 . Total input tokens: 371069728 . Total output tokens: 332471114
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 7.604466741904616,
    "estimated_duration": 3600.022987380165,
    "input_throughput": 6390.866414090044,
    "output_throughput": 5629.621552708107,
    "total_throughput": 12020.48796679815,
    "itl": 152.5464173707393,
    "ttft": 1937040.6065785852,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 66,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.19734331946354378,
    "arrivals": 554568,
    "finished_requests": 92835,
    "scheduler_time": 104.0974870534837
}
#Debug simulation 
Total elapsed time: 7.6045887330546975. Arrivals time: 0.3079838976264 Scheduler time: 7.19401784054935 Scheduler overhead time: 0.03904123278334737 Adapter cache time: 0.006533300504088402 Engine time: 0.03922607423737645 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_16-16-32/adapters_96_slots_64_rate_3.2-1.6-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_16-16-32/adapters_96_slots_64_rate_3.2-1.6-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 135, 34560, 135, 135, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 135, 34560, 17280, 135, 135, 17280, 34560, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 135, 34560, 17280, 17280, 135, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 135, 34560, 17280, 17280, 17280, 34560, 34560, 135, 135, 17280, 135, 34560, 135, 135, 34560, 135, 17280, 17280, 135, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 135, 135, 34560, 17280, 34560, 135, 17280, 34560, 135, 34560, 17280, 135, 34560, 135, 135, 34560, 135, 135, 17280]
Prompts retrieved: 1663200 . Total input tokens: 371069728 . Total output tokens: 332471114
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.419539038091898,
    "estimated_duration": 3600.1278834863865,
    "input_throughput": 6390.94630652917,
    "output_throughput": 5629.54140961605,
    "total_throughput": 12020.48771614522,
    "itl": 152.54721145887726,
    "ttft": 1937075.972380843,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 66,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21800329141318772,
    "arrivals": 554568,
    "finished_requests": 92837,
    "scheduler_time": 104.10048385696177
}
#Debug simulation 
Total elapsed time: 7.419640072155744. Arrivals time: 0.34326001536101103 Scheduler time: 6.976079936604947 Scheduler overhead time: 0.038155204616487026 Adapter cache time: 0.006485971622169018 Engine time: 0.03835463570430875 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-8/adapters_96_slots_64_rate_3.2-1.6-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-8/adapters_96_slots_64_rate_3.2-1.6-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 66, 34560, 66, 66, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 66, 34560, 17280, 66, 66, 17280, 34560, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 66, 34560, 17280, 17280, 66, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 66, 34560, 17280, 17280, 17280, 34560, 34560, 66, 66, 17280, 66, 34560, 66, 66, 34560, 66, 17280, 17280, 66, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 66, 66, 34560, 17280, 34560, 66, 17280, 34560, 66, 34560, 17280, 66, 34560, 66, 66, 34560, 66, 66, 17280]
Prompts retrieved: 1660992 . Total input tokens: 370572591 . Total output tokens: 332033415
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 7.376045232173055,
    "estimated_duration": 3600.090121290676,
    "input_throughput": 6361.726020288924,
    "output_throughput": 5631.6590187834945,
    "total_throughput": 11993.385039072418,
    "itl": 153.10971237769328,
    "ttft": 1940653.7358676135,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 104,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31829072536900604,
    "arrivals": 553859,
    "finished_requests": 92497,
    "scheduler_time": 104.07325179829897
}
#Debug simulation 
Total elapsed time: 7.376154164317995. Arrivals time: 0.3250753013417125 Scheduler time: 6.9511610912159085 Scheduler overhead time: 0.037893254309892654 Adapter cache time: 0.006880027242004871 Engine time: 0.037908738013356924 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-16/adapters_96_slots_64_rate_3.2-1.6-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-16/adapters_96_slots_64_rate_3.2-1.6-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 66, 34560, 66, 66, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 66, 34560, 17280, 66, 66, 17280, 34560, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 66, 34560, 17280, 17280, 66, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 66, 34560, 17280, 17280, 17280, 34560, 34560, 66, 66, 17280, 66, 34560, 66, 66, 34560, 66, 17280, 17280, 66, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 66, 66, 34560, 17280, 34560, 66, 17280, 34560, 66, 34560, 17280, 66, 34560, 66, 66, 34560, 66, 66, 17280]
Prompts retrieved: 1660992 . Total input tokens: 370572591 . Total output tokens: 332033415
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.498625885229558,
    "estimated_duration": 3600.115764756624,
    "input_throughput": 6361.6807059948205,
    "output_throughput": 5631.618904724472,
    "total_throughput": 11993.299610719292,
    "itl": 153.1100975697667,
    "ttft": 1940661.480093955,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 104,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.33997549827909096,
    "arrivals": 553859,
    "finished_requests": 92497,
    "scheduler_time": 104.0734875485557
}
#Debug simulation 
Total elapsed time: 7.4987225122749805. Arrivals time: 0.3136119726113975 Scheduler time: 7.081247732974589 Scheduler overhead time: 0.03904336504638195 Adapter cache time: 0.007126703392714262 Engine time: 0.03978951182216406 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-32/adapters_96_slots_64_rate_3.2-1.6-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-32/adapters_96_slots_64_rate_3.2-1.6-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 66, 34560, 66, 66, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 66, 34560, 17280, 66, 66, 17280, 34560, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 66, 34560, 17280, 17280, 66, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 66, 34560, 17280, 17280, 17280, 34560, 34560, 66, 66, 17280, 66, 34560, 66, 66, 34560, 66, 17280, 17280, 66, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 66, 66, 34560, 17280, 34560, 66, 17280, 34560, 66, 34560, 17280, 66, 34560, 66, 66, 34560, 66, 66, 17280]
Prompts retrieved: 1660992 . Total input tokens: 370572591 . Total output tokens: 332033415
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.497570373117924,
    "estimated_duration": 3600.116089133973,
    "input_throughput": 6361.6801327952135,
    "output_throughput": 5631.61839730483,
    "total_throughput": 11993.298530100044,
    "itl": 153.11006288453657,
    "ttft": 1940661.9541397376,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 104,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.34047053238377034,
    "arrivals": 553859,
    "finished_requests": 92497,
    "scheduler_time": 104.07349042915814
}
#Debug simulation 
Total elapsed time: 7.497667401097715. Arrivals time: 0.3657866595312953 Scheduler time: 7.029858545865864 Scheduler overhead time: 0.038719805888831615 Adapter cache time: 0.0070327469147741795 Engine time: 0.03866847278550267 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-16-16/adapters_96_slots_64_rate_3.2-1.6-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-16-16/adapters_96_slots_64_rate_3.2-1.6-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 66, 34560, 66, 66, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 66, 34560, 17280, 66, 66, 17280, 34560, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 66, 34560, 17280, 17280, 66, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 66, 34560, 17280, 17280, 17280, 34560, 34560, 66, 66, 17280, 66, 34560, 66, 66, 34560, 66, 17280, 17280, 66, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 66, 66, 34560, 17280, 34560, 66, 17280, 34560, 66, 34560, 17280, 66, 34560, 66, 66, 34560, 66, 66, 17280]
Prompts retrieved: 1660992 . Total input tokens: 370572591 . Total output tokens: 332033415
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 7.49479293404147,
    "estimated_duration": 3600.1003518864177,
    "input_throughput": 6361.707941835333,
    "output_throughput": 5631.643014999949,
    "total_throughput": 11993.350956835282,
    "itl": 153.10978433234618,
    "ttft": 1940657.1138898067,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 104,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.32567466213367896,
    "arrivals": 553859,
    "finished_requests": 92497,
    "scheduler_time": 104.07337787533282
}
#Debug simulation 
Total elapsed time: 7.4949166141450405. Arrivals time: 0.35999127523973584 Scheduler time: 7.032320953905582 Scheduler overhead time: 0.03884472232311964 Adapter cache time: 0.007212596945464611 Engine time: 0.038870471995323896 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-16-32/adapters_96_slots_64_rate_3.2-1.6-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-16-32/adapters_96_slots_64_rate_3.2-1.6-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 66, 34560, 66, 66, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 66, 34560, 17280, 66, 66, 17280, 34560, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 66, 34560, 17280, 17280, 66, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 66, 34560, 17280, 17280, 17280, 34560, 34560, 66, 66, 17280, 66, 34560, 66, 66, 34560, 66, 17280, 17280, 66, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 66, 66, 34560, 17280, 34560, 66, 17280, 34560, 66, 34560, 17280, 66, 34560, 66, 66, 34560, 66, 66, 17280]
Prompts retrieved: 1660992 . Total input tokens: 370572591 . Total output tokens: 332033415
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 7.556878474075347,
    "estimated_duration": 3600.160971598246,
    "input_throughput": 6361.704429519559,
    "output_throughput": 5631.594020363853,
    "total_throughput": 11993.298449883412,
    "itl": 153.1107195064268,
    "ttft": 1940654.5304812023,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 104,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.34487191490828994,
    "arrivals": 553859,
    "finished_requests": 92498,
    "scheduler_time": 104.07483469754581
}
#Debug simulation 
Total elapsed time: 7.556977229192853. Arrivals time: 0.34682724764570594 Scheduler time: 7.107261316850781 Scheduler overhead time: 0.03891772357746959 Adapter cache time: 0.007117378991097212 Engine time: 0.03901102440431714 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_16-16-16/adapters_96_slots_64_rate_3.2-1.6-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_16-16-16/adapters_96_slots_64_rate_3.2-1.6-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 66, 34560, 66, 66, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 66, 34560, 17280, 66, 66, 17280, 34560, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 66, 34560, 17280, 17280, 66, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 66, 34560, 17280, 17280, 17280, 34560, 34560, 66, 66, 17280, 66, 34560, 66, 66, 34560, 66, 17280, 17280, 66, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 66, 66, 34560, 17280, 34560, 66, 17280, 34560, 66, 34560, 17280, 66, 34560, 66, 66, 34560, 66, 66, 17280]
Prompts retrieved: 1660992 . Total input tokens: 370572591 . Total output tokens: 332033415
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 7.461502043996006,
    "estimated_duration": 3600.0801145612804,
    "input_throughput": 6361.743703248399,
    "output_throughput": 5631.67467245954,
    "total_throughput": 11993.418375707939,
    "itl": 153.1096470749492,
    "ttft": 1940650.451015453,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 104,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3109652306698266,
    "arrivals": 553859,
    "finished_requests": 92497,
    "scheduler_time": 104.07313298568124
}
#Debug simulation 
Total elapsed time: 7.461627017240971. Arrivals time: 0.307473121676594 Scheduler time: 7.051458188332617 Scheduler overhead time: 0.03870550636202097 Adapter cache time: 0.007063683122396469 Engine time: 0.03912905976176262 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_16-16-32/adapters_96_slots_64_rate_3.2-1.6-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_16-16-32/adapters_96_slots_64_rate_3.2-1.6-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 66, 34560, 66, 66, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 66, 34560, 17280, 66, 66, 17280, 34560, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 66, 34560, 17280, 17280, 66, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 66, 34560, 17280, 17280, 17280, 34560, 34560, 66, 66, 17280, 66, 34560, 66, 66, 34560, 66, 17280, 17280, 66, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 66, 66, 34560, 17280, 34560, 66, 17280, 34560, 66, 34560, 17280, 66, 34560, 66, 66, 34560, 66, 66, 17280]
Prompts retrieved: 1660992 . Total input tokens: 370572591 . Total output tokens: 332033415
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.322097719181329,
    "estimated_duration": 3600.1708333786564,
    "input_throughput": 6361.687003198691,
    "output_throughput": 5631.57859400045,
    "total_throughput": 11993.26559719914,
    "itl": 153.11097235621116,
    "ttft": 1940659.0929557732,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 104,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.34939905121922454,
    "arrivals": 553859,
    "finished_requests": 92498,
    "scheduler_time": 104.07499127325815
}
#Debug simulation 
Total elapsed time: 7.322192577179521. Arrivals time: 0.343027934897691 Scheduler time: 6.878779407124966 Scheduler overhead time: 0.03808513609692454 Adapter cache time: 0.00688333110883832 Engine time: 0.038249421864748 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-8-8/adapters_96_slots_64_rate_3.2-1.6-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-8-8/adapters_96_slots_64_rate_3.2-1.6-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 33, 34560, 33, 33, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 33, 34560, 17280, 33, 33, 17280, 34560, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 33, 34560, 17280, 17280, 33, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 33, 34560, 17280, 17280, 17280, 34560, 34560, 33, 33, 17280, 33, 34560, 33, 33, 34560, 33, 17280, 17280, 33, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 33, 33, 34560, 17280, 34560, 33, 17280, 34560, 33, 34560, 17280, 33, 34560, 33, 33, 34560, 33, 33, 17280]
Prompts retrieved: 1659936 . Total input tokens: 370337047 . Total output tokens: 331827132
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.636136452201754,
    "estimated_duration": 3600.161972862079,
    "input_throughput": 6388.803385341782,
    "output_throughput": 5631.987158589092,
    "total_throughput": 12020.790543930874,
    "itl": 152.51925600245679,
    "ttft": 1940115.0596004617,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.19587121561169607,
    "arrivals": 553508,
    "finished_requests": 92773,
    "scheduler_time": 104.09570608698081
}
#Debug simulation 
Total elapsed time: 6.636261350940913. Arrivals time: 0.27971160877496004 Scheduler time: 6.258252647239715 Scheduler overhead time: 0.037255953531712294 Adapter cache time: 0.00618477538228035 Engine time: 0.03763923421502113 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-8-16/adapters_96_slots_64_rate_3.2-1.6-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-8-16/adapters_96_slots_64_rate_3.2-1.6-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 33, 34560, 33, 33, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 33, 34560, 17280, 33, 33, 17280, 34560, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 33, 34560, 17280, 17280, 33, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 33, 34560, 17280, 17280, 17280, 34560, 34560, 33, 33, 17280, 33, 34560, 33, 33, 34560, 33, 17280, 17280, 33, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 33, 33, 34560, 17280, 34560, 33, 17280, 34560, 33, 34560, 17280, 33, 34560, 33, 33, 34560, 33, 33, 17280]
Prompts retrieved: 1659936 . Total input tokens: 370337047 . Total output tokens: 331827132
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.651007681153715,
    "estimated_duration": 3600.0057594616533,
    "input_throughput": 6388.965056389098,
    "output_throughput": 5632.08654505931,
    "total_throughput": 12021.051601448407,
    "itl": 152.5192451265039,
    "ttft": 1940060.6468624542,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20607265033759178,
    "arrivals": 553508,
    "finished_requests": 92772,
    "scheduler_time": 104.09093835813307
}
#Debug simulation 
Total elapsed time: 6.651103494223207. Arrivals time: 0.33050156058743596 Scheduler time: 6.222105018794537 Scheduler overhead time: 0.03740222565829754 Adapter cache time: 0.0062170568853616714 Engine time: 0.03759776847437024 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-8-32/adapters_96_slots_64_rate_3.2-1.6-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-8-32/adapters_96_slots_64_rate_3.2-1.6-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 33, 34560, 33, 33, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 33, 34560, 17280, 33, 33, 17280, 34560, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 33, 34560, 17280, 17280, 33, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 33, 34560, 17280, 17280, 17280, 34560, 34560, 33, 33, 17280, 33, 34560, 33, 33, 34560, 33, 17280, 17280, 33, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 33, 33, 34560, 17280, 34560, 33, 17280, 34560, 33, 34560, 17280, 33, 34560, 33, 33, 34560, 33, 33, 17280]
Prompts retrieved: 1659936 . Total input tokens: 370337047 . Total output tokens: 331827132
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.666268535889685,
    "estimated_duration": 3600.007172781731,
    "input_throughput": 6388.962548157266,
    "output_throughput": 5632.084333968995,
    "total_throughput": 12021.04688212626,
    "itl": 152.51916130766003,
    "ttft": 1940061.7218668652,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2069261161237954,
    "arrivals": 553508,
    "finished_requests": 92772,
    "scheduler_time": 104.09095398826368
}
#Debug simulation 
Total elapsed time: 6.666363644879311. Arrivals time: 0.35729799466207623 Scheduler time: 6.2110396339558065 Scheduler overhead time: 0.03716143686324358 Adapter cache time: 0.006160762161016464 Engine time: 0.03744910378009081 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-16-16/adapters_96_slots_64_rate_3.2-1.6-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-16-16/adapters_96_slots_64_rate_3.2-1.6-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 33, 34560, 33, 33, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 33, 34560, 17280, 33, 33, 17280, 34560, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 33, 34560, 17280, 17280, 33, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 33, 34560, 17280, 17280, 17280, 34560, 34560, 33, 33, 17280, 33, 34560, 33, 33, 34560, 33, 17280, 17280, 33, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 33, 33, 34560, 17280, 34560, 33, 17280, 34560, 33, 34560, 17280, 33, 34560, 33, 33, 34560, 33, 33, 17280]
Prompts retrieved: 1659936 . Total input tokens: 370337047 . Total output tokens: 331827132
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 6.941008652094752,
    "estimated_duration": 3600.1655318752114,
    "input_throughput": 6388.797069566869,
    "output_throughput": 5631.981590979469,
    "total_throughput": 12020.778660546339,
    "itl": 152.51921766655886,
    "ttft": 1940117.8770686185,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.19912652992410595,
    "arrivals": 553508,
    "finished_requests": 92773,
    "scheduler_time": 104.09574737213232
}
#Debug simulation 
Total elapsed time: 6.941072599962354. Arrivals time: 0.5726921553723514 Scheduler time: 6.270077331922948 Scheduler overhead time: 0.03722992446273565 Adapter cache time: 0.006181138567626476 Engine time: 0.037750224117189646 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-16-32/adapters_96_slots_64_rate_3.2-1.6-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-16-32/adapters_96_slots_64_rate_3.2-1.6-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 33, 34560, 33, 33, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 33, 34560, 17280, 33, 33, 17280, 34560, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 33, 34560, 17280, 17280, 33, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 33, 34560, 17280, 17280, 17280, 34560, 34560, 33, 33, 17280, 33, 34560, 33, 33, 34560, 33, 17280, 17280, 33, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 33, 33, 34560, 17280, 34560, 33, 17280, 34560, 33, 34560, 17280, 33, 34560, 33, 33, 34560, 33, 33, 17280]
Prompts retrieved: 1659936 . Total input tokens: 370337047 . Total output tokens: 331827132
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 6.691483182832599,
    "estimated_duration": 3600.0093311786136,
    "input_throughput": 6388.958717634737,
    "output_throughput": 5632.080957235173,
    "total_throughput": 12021.03967486991,
    "itl": 152.51918443473363,
    "ttft": 1940063.3991977426,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.209063930492848,
    "arrivals": 553508,
    "finished_requests": 92772,
    "scheduler_time": 104.09097457077736
}
#Debug simulation 
Total elapsed time: 6.691581110935658. Arrivals time: 0.35973811615258455 Scheduler time: 6.233589468989521 Scheduler overhead time: 0.0372989559546113 Adapter cache time: 0.006209626328200102 Engine time: 0.03760246653109789 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_16-16-16/adapters_96_slots_64_rate_3.2-1.6-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_16-16-16/adapters_96_slots_64_rate_3.2-1.6-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 33, 34560, 33, 33, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 33, 34560, 17280, 33, 33, 17280, 34560, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 33, 34560, 17280, 17280, 33, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 33, 34560, 17280, 17280, 17280, 34560, 34560, 33, 33, 17280, 33, 34560, 33, 33, 34560, 33, 17280, 17280, 33, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 33, 33, 34560, 17280, 34560, 33, 17280, 34560, 33, 34560, 17280, 33, 34560, 33, 33, 34560, 33, 33, 17280]
Prompts retrieved: 1659936 . Total input tokens: 370337047 . Total output tokens: 331827132
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.700794228818268,
    "estimated_duration": 3600.1542029394327,
    "input_throughput": 6388.817173781195,
    "output_throughput": 5631.999313653042,
    "total_throughput": 12020.816487434238,
    "itl": 152.5192026707206,
    "ttft": 1940097.9743006057,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.19136321887373942,
    "arrivals": 553508,
    "finished_requests": 92773,
    "scheduler_time": 104.095565990572
}
#Debug simulation 
Total elapsed time: 6.700907958671451. Arrivals time: 0.2979032387956977 Scheduler time: 6.3044872134923935 Scheduler overhead time: 0.03722279518842697 Adapter cache time: 0.006205675192177296 Engine time: 0.03760349052026868 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_16-16-32/adapters_96_slots_64_rate_3.2-1.6-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_16-16-32/adapters_96_slots_64_rate_3.2-1.6-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 33, 34560, 33, 33, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 33, 34560, 17280, 33, 33, 17280, 34560, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 33, 34560, 17280, 17280, 33, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 33, 34560, 17280, 17280, 17280, 34560, 34560, 33, 33, 17280, 33, 34560, 33, 33, 34560, 33, 17280, 17280, 33, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 33, 33, 34560, 17280, 34560, 33, 17280, 34560, 33, 34560, 17280, 33, 34560, 33, 33, 34560, 33, 33, 17280]
Prompts retrieved: 1659936 . Total input tokens: 370337047 . Total output tokens: 331827132
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.636185531038791,
    "estimated_duration": 3600.0391438758215,
    "input_throughput": 6388.9058092956575,
    "output_throughput": 5632.034316763356,
    "total_throughput": 12020.940126059013,
    "itl": 152.51945920521243,
    "ttft": 1940061.8296116053,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2114532524347303,
    "arrivals": 553508,
    "finished_requests": 92772,
    "scheduler_time": 104.09190252400772
}
#Debug simulation 
Total elapsed time: 6.636277963872999. Arrivals time: 0.3262990820221603 Scheduler time: 6.211613583844155 Scheduler overhead time: 0.037394136656075716 Adapter cache time: 0.0061837052926421165 Engine time: 0.037556775379925966 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-8-8/adapters_96_slots_64_rate_3.2-0.8-0.4_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-8-8/adapters_96_slots_64_rate_3.2-0.8-0.4_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [32 32 32]
Adapter prompts. [4320, 4320, 4320, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 4320, 34560, 4320, 4320, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 4320, 34560, 8640, 4320, 4320, 8640, 34560, 4320, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 34560, 8640, 8640, 4320, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 4320, 34560, 8640, 8640, 8640, 34560, 34560, 4320, 4320, 8640, 4320, 34560, 4320, 4320, 34560, 4320, 8640, 8640, 4320, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 4320, 4320, 34560, 8640, 34560, 4320, 8640, 34560, 4320, 34560, 8640, 4320, 34560, 4320, 4320, 34560, 4320, 4320, 8640]
Prompts retrieved: 1520640 . Total input tokens: 339170557 . Total output tokens: 304105255
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 15.793334919959307,
    "estimated_duration": 3600.0238454031964,
    "input_throughput": 6377.35720259616,
    "output_throughput": 5634.905175948363,
    "total_throughput": 12012.262378544523,
    "itl": 152.84887368240493,
    "ttft": 1918038.3947363733,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 210,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6427024262258775,
    "arrivals": 507133,
    "finished_requests": 92801,
    "scheduler_time": 104.00762604666667
}
#Debug simulation 
Total elapsed time: 15.793446531053632. Arrivals time: 0.37561514880508184 Scheduler time: 15.305695777293295 Scheduler overhead time: 0.042458366602659225 Adapter cache time: 0.008909536991268396 Engine time: 0.0426796181127429 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-8-16/adapters_96_slots_64_rate_3.2-0.8-0.4_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-8-16/adapters_96_slots_64_rate_3.2-0.8-0.4_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [32 32 32]
Adapter prompts. [4320, 4320, 4320, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 4320, 34560, 4320, 4320, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 4320, 34560, 8640, 4320, 4320, 8640, 34560, 4320, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 34560, 8640, 8640, 4320, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 4320, 34560, 8640, 8640, 8640, 34560, 34560, 4320, 4320, 8640, 4320, 34560, 4320, 4320, 34560, 4320, 8640, 8640, 4320, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 4320, 4320, 34560, 8640, 34560, 4320, 8640, 34560, 4320, 34560, 8640, 4320, 34560, 4320, 4320, 34560, 4320, 4320, 8640]
Prompts retrieved: 1520640 . Total input tokens: 339170557 . Total output tokens: 304105255
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 15.128121763002127,
    "estimated_duration": 3600.014926313094,
    "input_throughput": 6377.85216727269,
    "output_throughput": 5631.290818219479,
    "total_throughput": 12009.14298549217,
    "itl": 152.8205161378783,
    "ttft": 1918136.7337146536,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 219,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7206048608524752,
    "arrivals": 507133,
    "finished_requests": 92778,
    "scheduler_time": 104.00583015009212
}
#Debug simulation 
Total elapsed time: 15.128244806081057. Arrivals time: 0.3679719022475183 Scheduler time: 14.64950699545443 Scheduler overhead time: 0.04164956836029887 Adapter cache time: 0.009106919169425964 Engine time: 0.04201896954327822 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-8-32/adapters_96_slots_64_rate_3.2-0.8-0.4_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-8-32/adapters_96_slots_64_rate_3.2-0.8-0.4_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [32 32 32]
Adapter prompts. [4320, 4320, 4320, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 4320, 34560, 4320, 4320, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 4320, 34560, 8640, 4320, 4320, 8640, 34560, 4320, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 34560, 8640, 8640, 4320, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 4320, 34560, 8640, 8640, 8640, 34560, 34560, 4320, 4320, 8640, 4320, 34560, 4320, 4320, 34560, 4320, 8640, 8640, 4320, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 4320, 4320, 34560, 8640, 34560, 4320, 8640, 34560, 4320, 34560, 8640, 4320, 34560, 4320, 4320, 34560, 4320, 4320, 8640]
Prompts retrieved: 1520640 . Total input tokens: 339170557 . Total output tokens: 304105255
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 15.176997027825564,
    "estimated_duration": 3600.0151541571327,
    "input_throughput": 6377.851763620057,
    "output_throughput": 5631.290461816523,
    "total_throughput": 12009.14222543658,
    "itl": 152.8205035212252,
    "ttft": 1918137.0078218488,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 219,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7208274745009873,
    "arrivals": 507133,
    "finished_requests": 92778,
    "scheduler_time": 104.00583538047206
}
#Debug simulation 
Total elapsed time: 15.177105880808085. Arrivals time: 0.3821828691288829 Scheduler time: 14.683460524305701 Scheduler overhead time: 0.04200221970677376 Adapter cache time: 0.008905064314603806 Engine time: 0.04278852930292487 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-16-16/adapters_96_slots_64_rate_3.2-0.8-0.4_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-16-16/adapters_96_slots_64_rate_3.2-0.8-0.4_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [32 32 32]
Adapter prompts. [4320, 4320, 4320, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 4320, 34560, 4320, 4320, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 4320, 34560, 8640, 4320, 4320, 8640, 34560, 4320, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 34560, 8640, 8640, 4320, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 4320, 34560, 8640, 8640, 8640, 34560, 34560, 4320, 4320, 8640, 4320, 34560, 4320, 4320, 34560, 4320, 8640, 8640, 4320, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 4320, 4320, 34560, 8640, 34560, 4320, 8640, 34560, 4320, 34560, 8640, 4320, 34560, 4320, 4320, 34560, 4320, 4320, 8640]
Prompts retrieved: 1520640 . Total input tokens: 339170557 . Total output tokens: 304105255
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 15.849073553923517,
    "estimated_duration": 3600.050531443149,
    "input_throughput": 6377.310207031064,
    "output_throughput": 5634.950349396326,
    "total_throughput": 12012.260556427389,
    "itl": 152.85105722045182,
    "ttft": 1918052.3688099356,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 210,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6573294248571632,
    "arrivals": 507133,
    "finished_requests": 92802,
    "scheduler_time": 104.00816971796837
}
#Debug simulation 
Total elapsed time: 15.849169075954705. Arrivals time: 0.3692758260294795 Scheduler time: 15.367857580073178 Scheduler overhead time: 0.04206384485587478 Adapter cache time: 0.009015134070068598 Engine time: 0.04279542528092861 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-16-32/adapters_96_slots_64_rate_3.2-0.8-0.4_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-16-32/adapters_96_slots_64_rate_3.2-0.8-0.4_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [32 32 32]
Adapter prompts. [4320, 4320, 4320, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 4320, 34560, 4320, 4320, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 4320, 34560, 8640, 4320, 4320, 8640, 34560, 4320, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 34560, 8640, 8640, 4320, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 4320, 34560, 8640, 8640, 8640, 34560, 34560, 4320, 4320, 8640, 4320, 34560, 4320, 4320, 34560, 4320, 8640, 8640, 4320, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 4320, 4320, 34560, 8640, 34560, 4320, 8640, 34560, 4320, 34560, 8640, 4320, 34560, 4320, 4320, 34560, 4320, 4320, 8640]
Prompts retrieved: 1520640 . Total input tokens: 339170557 . Total output tokens: 304105255
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 15.287476335652173,
    "estimated_duration": 3600.02726730751,
    "input_throughput": 6377.830303816628,
    "output_throughput": 5631.271513996654,
    "total_throughput": 12009.101817813282,
    "itl": 152.8208376309957,
    "ttft": 1918143.2709337445,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 219,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7315165463462502,
    "arrivals": 507133,
    "finished_requests": 92778,
    "scheduler_time": 104.00590437486123
}
#Debug simulation 
Total elapsed time: 15.28761673765257. Arrivals time: 0.3870323090814054 Scheduler time: 14.787623948883265 Scheduler overhead time: 0.04275625664740801 Adapter cache time: 0.009323825128376484 Engine time: 0.0429149423725903 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_16-16-16/adapters_96_slots_64_rate_3.2-0.8-0.4_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_16-16-16/adapters_96_slots_64_rate_3.2-0.8-0.4_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [32 32 32]
Adapter prompts. [4320, 4320, 4320, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 4320, 34560, 4320, 4320, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 4320, 34560, 8640, 4320, 4320, 8640, 34560, 4320, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 34560, 8640, 8640, 4320, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 4320, 34560, 8640, 8640, 8640, 34560, 34560, 4320, 4320, 8640, 4320, 34560, 4320, 4320, 34560, 4320, 8640, 8640, 4320, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 4320, 4320, 34560, 8640, 34560, 4320, 8640, 34560, 4320, 34560, 8640, 4320, 34560, 4320, 4320, 34560, 4320, 4320, 8640]
Prompts retrieved: 1520640 . Total input tokens: 339170557 . Total output tokens: 304105255
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 15.375539509113878,
    "estimated_duration": 3600.072872323272,
    "input_throughput": 6375.839549377563,
    "output_throughput": 5633.1054173669445,
    "total_throughput": 12008.944966744508,
    "itl": 152.85553355670083,
    "ttft": 1918062.8465159757,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 217,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.648840913993773,
    "arrivals": 507133,
    "finished_requests": 92778,
    "scheduler_time": 104.00815613395497
}
#Debug simulation 
Total elapsed time: 15.375632991082966. Arrivals time: 0.3667843258008361 Scheduler time: 14.89770090719685 Scheduler overhead time: 0.04166098823770881 Adapter cache time: 0.008920290507376194 Engine time: 0.04257085081189871 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_16-16-32/adapters_96_slots_64_rate_3.2-0.8-0.4_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_16-16-32/adapters_96_slots_64_rate_3.2-0.8-0.4_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [32 32 32]
Adapter prompts. [4320, 4320, 4320, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 4320, 34560, 4320, 4320, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 4320, 34560, 8640, 4320, 4320, 8640, 34560, 4320, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 34560, 8640, 8640, 4320, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 4320, 34560, 8640, 8640, 8640, 34560, 34560, 4320, 4320, 8640, 4320, 34560, 4320, 4320, 34560, 4320, 8640, 8640, 4320, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 4320, 4320, 34560, 8640, 34560, 4320, 8640, 34560, 4320, 34560, 8640, 4320, 34560, 4320, 4320, 34560, 4320, 4320, 8640]
Prompts retrieved: 1520640 . Total input tokens: 339170557 . Total output tokens: 304105255
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 15.156217373907566,
    "estimated_duration": 3600.039818520663,
    "input_throughput": 6377.808068088238,
    "output_throughput": 5631.251881077948,
    "total_throughput": 12009.059949166185,
    "itl": 152.82122477956239,
    "ttft": 1918149.1229210151,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 219,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7410738341137791,
    "arrivals": 507133,
    "finished_requests": 92778,
    "scheduler_time": 104.00600030171819
}
#Debug simulation 
Total elapsed time: 15.15635369066149. Arrivals time: 0.3308485224843025 Scheduler time: 14.714476566761732 Scheduler overhead time: 0.041596196591854095 Adapter cache time: 0.00912690069526434 Engine time: 0.04240620695054531 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-8-8/adapters_96_slots_64_rate_3.2-0.8-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-8-8/adapters_96_slots_64_rate_3.2-0.8-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 1080, 34560, 1080, 1080, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 1080, 34560, 8640, 1080, 1080, 8640, 34560, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 34560, 8640, 8640, 1080, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 1080, 34560, 8640, 8640, 8640, 34560, 34560, 1080, 1080, 8640, 1080, 34560, 1080, 1080, 34560, 1080, 8640, 8640, 1080, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 1080, 1080, 34560, 8640, 34560, 1080, 8640, 34560, 1080, 34560, 8640, 1080, 34560, 1080, 1080, 34560, 1080, 1080, 8640]
Prompts retrieved: 1416960 . Total input tokens: 316002805 . Total output tokens: 283393833
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 9.061566921882331,
    "estimated_duration": 3600.1225189922684,
    "input_throughput": 6388.354251465238,
    "output_throughput": 5635.723199131372,
    "total_throughput": 12024.07745059661,
    "itl": 152.79786970830682,
    "ttft": 1902427.6310258962,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 264,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8079687643982459,
    "arrivals": 472666,
    "finished_requests": 92729,
    "scheduler_time": 103.91455067613299
}
#Debug simulation 
Total elapsed time: 9.06166344601661. Arrivals time: 0.3251593289896846 Scheduler time: 8.63264955719933 Scheduler overhead time: 0.03802873659878969 Adapter cache time: 0.009067524690181017 Engine time: 0.03908542916178703 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-8-16/adapters_96_slots_64_rate_3.2-0.8-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-8-16/adapters_96_slots_64_rate_3.2-0.8-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 1080, 34560, 1080, 1080, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 1080, 34560, 8640, 1080, 1080, 8640, 34560, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 34560, 8640, 8640, 1080, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 1080, 34560, 8640, 8640, 8640, 34560, 34560, 1080, 1080, 8640, 1080, 34560, 1080, 1080, 34560, 1080, 8640, 8640, 1080, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 1080, 1080, 34560, 8640, 34560, 1080, 8640, 34560, 1080, 34560, 8640, 1080, 34560, 1080, 1080, 34560, 1080, 1080, 8640]
Prompts retrieved: 1416960 . Total input tokens: 316002805 . Total output tokens: 283393833
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 9.035957428161055,
    "estimated_duration": 3600.0776028190685,
    "input_throughput": 6388.118684439318,
    "output_throughput": 5635.388799428505,
    "total_throughput": 12023.507483867823,
    "itl": 152.79984547191896,
    "ttft": 1902440.876446279,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 264,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8715009368606892,
    "arrivals": 472666,
    "finished_requests": 92723,
    "scheduler_time": 103.91175606011832
}
#Debug simulation 
Total elapsed time: 9.036052347160876. Arrivals time: 0.3275480689480901 Scheduler time: 8.605061201844364 Scheduler overhead time: 0.03822185471653938 Adapter cache time: 0.00911091873422265 Engine time: 0.03875942761078477 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-8-32/adapters_96_slots_64_rate_3.2-0.8-0.1_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-8-32/adapters_96_slots_64_rate_3.2-0.8-0.1_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 1080, 34560, 1080, 1080, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 1080, 34560, 8640, 1080, 1080, 8640, 34560, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 34560, 8640, 8640, 1080, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 1080, 34560, 8640, 8640, 8640, 34560, 34560, 1080, 1080, 8640, 1080, 34560, 1080, 1080, 34560, 1080, 8640, 8640, 1080, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 1080, 1080, 34560, 8640, 34560, 1080, 8640, 34560, 1080, 34560, 8640, 1080, 34560, 1080, 1080, 34560, 1080, 1080, 8640]
Prompts retrieved: 1416960 . Total input tokens: 316002805 . Total output tokens: 283393833
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 9.029554065782577,
    "estimated_duration": 3600.078807890398,
    "input_throughput": 6388.116546114274,
    "output_throughput": 5635.386913068279,
    "total_throughput": 12023.503459182553,
    "itl": 152.79998396496381,
    "ttft": 1902440.6026538573,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 264,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8712757224775897,
    "arrivals": 472666,
    "finished_requests": 92723,
    "scheduler_time": 103.91179975107265
}
#Debug simulation 
Total elapsed time: 9.02967039262876. Arrivals time: 0.3270749435760081 Scheduler time: 8.598709713667631 Scheduler overhead time: 0.03858018293976784 Adapter cache time: 0.009161312598735094 Engine time: 0.03882525581866503 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-16-16/adapters_96_slots_64_rate_3.2-0.8-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-16-16/adapters_96_slots_64_rate_3.2-0.8-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 1080, 34560, 1080, 1080, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 1080, 34560, 8640, 1080, 1080, 8640, 34560, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 34560, 8640, 8640, 1080, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 1080, 34560, 8640, 8640, 8640, 34560, 34560, 1080, 1080, 8640, 1080, 34560, 1080, 1080, 34560, 1080, 8640, 8640, 1080, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 1080, 1080, 34560, 8640, 34560, 1080, 8640, 34560, 1080, 34560, 8640, 1080, 34560, 1080, 1080, 34560, 1080, 1080, 8640]
Prompts retrieved: 1416960 . Total input tokens: 316002805 . Total output tokens: 283393833
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 9.085532298311591,
    "estimated_duration": 3600.008460822168,
    "input_throughput": 6388.1858196377225,
    "output_throughput": 5635.468977583097,
    "total_throughput": 12023.65479722082,
    "itl": 152.7987756364786,
    "ttft": 1902418.7741862838,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 264,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.830232809698212,
    "arrivals": 472666,
    "finished_requests": 92722,
    "scheduler_time": 103.91074897697426
}
#Debug simulation 
Total elapsed time: 9.085630101151764. Arrivals time: 0.28700289223343134 Scheduler time: 8.694569451734424 Scheduler overhead time: 0.03826131019741297 Adapter cache time: 0.009259720332920551 Engine time: 0.03892140043899417 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-16-32/adapters_96_slots_64_rate_3.2-0.8-0.1_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-16-32/adapters_96_slots_64_rate_3.2-0.8-0.1_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 1080, 34560, 1080, 1080, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 1080, 34560, 8640, 1080, 1080, 8640, 34560, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 34560, 8640, 8640, 1080, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 1080, 34560, 8640, 8640, 8640, 34560, 34560, 1080, 1080, 8640, 1080, 34560, 1080, 1080, 34560, 1080, 8640, 8640, 1080, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 1080, 1080, 34560, 8640, 34560, 1080, 8640, 34560, 1080, 34560, 8640, 1080, 34560, 1080, 1080, 34560, 1080, 1080, 8640]
Prompts retrieved: 1416960 . Total input tokens: 316002805 . Total output tokens: 283393833
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 9.064821602776647,
    "estimated_duration": 3600.09350488935,
    "input_throughput": 6388.090467307694,
    "output_throughput": 5635.363907200392,
    "total_throughput": 12023.454374508086,
    "itl": 152.8003810518695,
    "ttft": 1902447.425830148,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 264,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8839768549054907,
    "arrivals": 472666,
    "finished_requests": 92723,
    "scheduler_time": 103.91186085146246
}
#Debug simulation 
Total elapsed time: 9.064921640790999. Arrivals time: 0.2963302154093981 Scheduler time: 8.665405760053545 Scheduler overhead time: 0.03814564226195216 Adapter cache time: 0.009059005416929722 Engine time: 0.03860385389998555 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_16-16-16/adapters_96_slots_64_rate_3.2-0.8-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_16-16-16/adapters_96_slots_64_rate_3.2-0.8-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 1080, 34560, 1080, 1080, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 1080, 34560, 8640, 1080, 1080, 8640, 34560, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 34560, 8640, 8640, 1080, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 1080, 34560, 8640, 8640, 8640, 34560, 34560, 1080, 1080, 8640, 1080, 34560, 1080, 1080, 34560, 1080, 8640, 8640, 1080, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 1080, 1080, 34560, 8640, 34560, 1080, 8640, 34560, 1080, 34560, 8640, 1080, 34560, 1080, 1080, 34560, 1080, 1080, 8640]
Prompts retrieved: 1416960 . Total input tokens: 316002805 . Total output tokens: 283393833
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 9.088012842927128,
    "estimated_duration": 3600.1007372492977,
    "input_throughput": 6388.392903019866,
    "output_throughput": 5635.757297031163,
    "total_throughput": 12024.150200051028,
    "itl": 152.79736812120808,
    "ttft": 1902416.8503137769,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 264,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7893732778541754,
    "arrivals": 472666,
    "finished_requests": 92729,
    "scheduler_time": 103.9144111822439
}
#Debug simulation 
Total elapsed time: 9.088133223820478. Arrivals time: 0.33038858277723193 Scheduler time: 8.653593711089343 Scheduler overhead time: 0.03827528981491923 Adapter cache time: 0.009135953150689602 Engine time: 0.03916203137487173 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_16-16-32/adapters_96_slots_64_rate_3.2-0.8-0.1_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_16-16-32/adapters_96_slots_64_rate_3.2-0.8-0.1_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 1080, 34560, 1080, 1080, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 1080, 34560, 8640, 1080, 1080, 8640, 34560, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 34560, 8640, 8640, 1080, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 1080, 34560, 8640, 8640, 8640, 34560, 34560, 1080, 1080, 8640, 1080, 34560, 1080, 1080, 34560, 1080, 8640, 8640, 1080, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 1080, 1080, 34560, 8640, 34560, 1080, 8640, 34560, 1080, 34560, 8640, 1080, 34560, 1080, 1080, 34560, 1080, 1080, 8640]
Prompts retrieved: 1416960 . Total input tokens: 316002805 . Total output tokens: 283393833
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 9.095449970569462,
    "estimated_duration": 3600.1077798909705,
    "input_throughput": 6388.065137509991,
    "output_throughput": 5635.341562083571,
    "total_throughput": 12023.406699593563,
    "itl": 152.80081525465584,
    "ttft": 1902454.1133615833,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 264,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8965522335469768,
    "arrivals": 472666,
    "finished_requests": 92723,
    "scheduler_time": 103.91192405758368
}
#Debug simulation 
Total elapsed time: 9.095543568953872. Arrivals time: 0.3290102556347847 Scheduler time: 8.66238517826423 Scheduler overhead time: 0.03831382840871811 Adapter cache time: 0.009144064970314503 Engine time: 0.03901862492784858 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-8-8/adapters_96_slots_64_rate_3.2-0.8-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-8-8/adapters_96_slots_64_rate_3.2-0.8-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 540, 34560, 540, 540, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 540, 34560, 8640, 540, 540, 8640, 34560, 540, 8640, 540, 540, 8640, 8640, 8640, 540, 540, 34560, 8640, 8640, 540, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 540, 34560, 8640, 8640, 8640, 34560, 34560, 540, 540, 8640, 540, 34560, 540, 540, 34560, 540, 8640, 8640, 540, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 540, 540, 34560, 8640, 34560, 540, 8640, 34560, 540, 34560, 8640, 540, 34560, 540, 540, 34560, 540, 540, 8640]
Prompts retrieved: 1399680 . Total input tokens: 312160527 . Total output tokens: 279955315
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 8.200984817929566,
    "estimated_duration": 3600.057779582553,
    "input_throughput": 6358.768220285189,
    "output_throughput": 5632.757928221746,
    "total_throughput": 11991.526148506935,
    "itl": 152.95707034185094,
    "ttft": 1894926.4109527878,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 249,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7620614482392547,
    "arrivals": 466828,
    "finished_requests": 92577,
    "scheduler_time": 103.89623290908803
}
#Debug simulation 
Total elapsed time: 8.201108270790428. Arrivals time: 0.3042073333635926 Scheduler time: 7.79428087035194 Scheduler overhead time: 0.03785758651793003 Adapter cache time: 0.008759957272559404 Engine time: 0.03846496669575572 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-8-16/adapters_96_slots_64_rate_3.2-0.8-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-8-16/adapters_96_slots_64_rate_3.2-0.8-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 540, 34560, 540, 540, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 540, 34560, 8640, 540, 540, 8640, 34560, 540, 8640, 540, 540, 8640, 8640, 8640, 540, 540, 34560, 8640, 8640, 540, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 540, 34560, 8640, 8640, 8640, 34560, 34560, 540, 540, 8640, 540, 34560, 540, 540, 34560, 540, 8640, 8640, 540, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 540, 540, 34560, 8640, 34560, 540, 8640, 34560, 540, 34560, 8640, 540, 34560, 540, 540, 34560, 540, 540, 8640]
Prompts retrieved: 1399680 . Total input tokens: 312160527 . Total output tokens: 279955315
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 8.181948107201606,
    "estimated_duration": 3600.0378917022663,
    "input_throughput": 6358.684738503079,
    "output_throughput": 5633.040431808085,
    "total_throughput": 11991.725170311163,
    "itl": 152.96370408987187,
    "ttft": 1894924.9341710762,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 251,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8273185438872357,
    "arrivals": 466828,
    "finished_requests": 92578,
    "scheduler_time": 103.89404172558777
}
#Debug simulation 
Total elapsed time: 8.18204314308241. Arrivals time: 0.28381458297371864 Scheduler time: 7.795215434394777 Scheduler overhead time: 0.03818440204486251 Adapter cache time: 0.008886607363820076 Engine time: 0.03866766253486276 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-8-32/adapters_96_slots_64_rate_3.2-0.8-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-8-32/adapters_96_slots_64_rate_3.2-0.8-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 540, 34560, 540, 540, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 540, 34560, 8640, 540, 540, 8640, 34560, 540, 8640, 540, 540, 8640, 8640, 8640, 540, 540, 34560, 8640, 8640, 540, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 540, 34560, 8640, 8640, 8640, 34560, 34560, 540, 540, 8640, 540, 34560, 540, 540, 34560, 540, 8640, 8640, 540, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 540, 540, 34560, 8640, 34560, 540, 8640, 34560, 540, 34560, 8640, 540, 34560, 540, 540, 34560, 540, 540, 8640]
Prompts retrieved: 1399680 . Total input tokens: 312160527 . Total output tokens: 279955315
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 8.450188420247287,
    "estimated_duration": 3600.037906085967,
    "input_throughput": 6358.684713097397,
    "output_throughput": 5633.040409301664,
    "total_throughput": 11991.72512239906,
    "itl": 152.96368098134758,
    "ttft": 1894925.2499719963,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 251,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8273257600143593,
    "arrivals": 466828,
    "finished_requests": 92578,
    "scheduler_time": 103.89404889314547
}
#Debug simulation 
Total elapsed time: 8.450280510820448. Arrivals time: 0.5593586503528059 Scheduler time: 7.7880906271748245 Scheduler overhead time: 0.038003886584192514 Adapter cache time: 0.008860423229634762 Engine time: 0.038387494161725044 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-16-16/adapters_96_slots_64_rate_3.2-0.8-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-16-16/adapters_96_slots_64_rate_3.2-0.8-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 540, 34560, 540, 540, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 540, 34560, 8640, 540, 540, 8640, 34560, 540, 8640, 540, 540, 8640, 8640, 8640, 540, 540, 34560, 8640, 8640, 540, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 540, 34560, 8640, 8640, 8640, 34560, 34560, 540, 540, 8640, 540, 34560, 540, 540, 34560, 540, 8640, 8640, 540, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 540, 540, 34560, 8640, 34560, 540, 8640, 34560, 540, 34560, 8640, 540, 34560, 540, 540, 34560, 540, 540, 8640]
Prompts retrieved: 1399680 . Total input tokens: 312160527 . Total output tokens: 279955315
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 8.188321799971163,
    "estimated_duration": 3600.075511663157,
    "input_throughput": 6358.736900333633,
    "output_throughput": 5632.730184215465,
    "total_throughput": 11991.467084549098,
    "itl": 152.95760341107265,
    "ttft": 1894931.064596585,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 249,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7812961020902753,
    "arrivals": 466828,
    "finished_requests": 92577,
    "scheduler_time": 103.89623344110366
}
#Debug simulation 
Total elapsed time: 8.188440213911235. Arrivals time: 0.31969389831647277 Scheduler time: 7.765917836688459 Scheduler overhead time: 0.03800027444958687 Adapter cache time: 0.008810249622911215 Engine time: 0.03862037882208824 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-16-32/adapters_96_slots_64_rate_3.2-0.8-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-16-32/adapters_96_slots_64_rate_3.2-0.8-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 540, 34560, 540, 540, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 540, 34560, 8640, 540, 540, 8640, 34560, 540, 8640, 540, 540, 8640, 8640, 8640, 540, 540, 34560, 8640, 8640, 540, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 540, 34560, 8640, 8640, 8640, 34560, 34560, 540, 540, 8640, 540, 34560, 540, 540, 34560, 540, 8640, 8640, 540, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 540, 540, 34560, 8640, 34560, 540, 8640, 34560, 540, 34560, 8640, 540, 34560, 540, 540, 34560, 540, 540, 8640]
Prompts retrieved: 1399680 . Total input tokens: 312160527 . Total output tokens: 279955315
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 8.227578067220747,
    "estimated_duration": 3600.0512406296048,
    "input_throughput": 6358.661160610746,
    "output_throughput": 5633.019544592211,
    "total_throughput": 11991.680705202958,
    "itl": 152.96412560700307,
    "ttft": 1894931.2361423736,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 251,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8395238772966007,
    "arrivals": 466828,
    "finished_requests": 92578,
    "scheduler_time": 103.8941033335373
}
#Debug simulation 
Total elapsed time: 8.227671508211643. Arrivals time: 0.3464985843747854 Scheduler time: 7.778502075001597 Scheduler overhead time: 0.03793823253363371 Adapter cache time: 0.008850852493196726 Engine time: 0.038472067564725876 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_16-16-16/adapters_96_slots_64_rate_3.2-0.8-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_16-16-16/adapters_96_slots_64_rate_3.2-0.8-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 540, 34560, 540, 540, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 540, 34560, 8640, 540, 540, 8640, 34560, 540, 8640, 540, 540, 8640, 8640, 8640, 540, 540, 34560, 8640, 8640, 540, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 540, 34560, 8640, 8640, 8640, 34560, 34560, 540, 540, 8640, 540, 34560, 540, 540, 34560, 540, 8640, 8640, 540, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 540, 540, 34560, 8640, 34560, 540, 8640, 34560, 540, 34560, 8640, 540, 34560, 540, 540, 34560, 540, 540, 8640]
Prompts retrieved: 1399680 . Total input tokens: 312160527 . Total output tokens: 279955315
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 8.194093941245228,
    "estimated_duration": 3600.0262212884227,
    "input_throughput": 6358.823962067461,
    "output_throughput": 5632.807305704169,
    "total_throughput": 11991.63126777163,
    "itl": 152.95636527606922,
    "ttft": 1894917.3777860585,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 249,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7445225234306427,
    "arrivals": 466828,
    "finished_requests": 92577,
    "scheduler_time": 103.89573554251001
}
#Debug simulation 
Total elapsed time: 8.19420215813443. Arrivals time: 0.32567756809294224 Scheduler time: 7.76626453269273 Scheduler overhead time: 0.037809766829013824 Adapter cache time: 0.00884954584762454 Engine time: 0.03822227893397212 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_16-16-32/adapters_96_slots_64_rate_3.2-0.8-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_16-16-32/adapters_96_slots_64_rate_3.2-0.8-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 540, 34560, 540, 540, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 540, 34560, 8640, 540, 540, 8640, 34560, 540, 8640, 540, 540, 8640, 8640, 8640, 540, 540, 34560, 8640, 8640, 540, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 540, 34560, 8640, 8640, 8640, 34560, 34560, 540, 540, 8640, 540, 34560, 540, 540, 34560, 540, 8640, 8640, 540, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 540, 540, 34560, 8640, 34560, 540, 8640, 34560, 540, 34560, 8640, 540, 34560, 540, 540, 34560, 540, 540, 8640]
Prompts retrieved: 1399680 . Total input tokens: 312160527 . Total output tokens: 279955315
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 8.169793288689107,
    "estimated_duration": 3600.062683478256,
    "input_throughput": 6358.640949518973,
    "output_throughput": 5633.001639962274,
    "total_throughput": 11991.642589481247,
    "itl": 152.9645062323966,
    "ttft": 1894936.1885284095,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 251,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.850967471860353,
    "arrivals": 466828,
    "finished_requests": 92578,
    "scheduler_time": 103.89412708723012
}
#Debug simulation 
Total elapsed time: 8.16991089982912. Arrivals time: 0.2831177031621337 Scheduler time: 7.783779041841626 Scheduler overhead time: 0.03820737171918154 Adapter cache time: 0.008851511403918266 Engine time: 0.03848682530224323 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-8-8/adapters_96_slots_64_rate_3.2-0.8-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-8-8/adapters_96_slots_64_rate_3.2-0.8-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 270, 34560, 270, 270, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 270, 34560, 8640, 270, 270, 8640, 34560, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 270, 34560, 8640, 8640, 270, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 270, 34560, 8640, 8640, 8640, 34560, 34560, 270, 270, 8640, 270, 34560, 270, 270, 34560, 270, 8640, 8640, 270, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 270, 270, 34560, 8640, 34560, 270, 8640, 34560, 270, 34560, 8640, 270, 34560, 270, 270, 34560, 270, 270, 8640]
Prompts retrieved: 1391040 . Total input tokens: 310246563 . Total output tokens: 278256734
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 7.918591655790806,
    "estimated_duration": 3600.1710356169174,
    "input_throughput": 6352.885397313018,
    "output_throughput": 5633.306806637512,
    "total_throughput": 11986.19220395053,
    "itl": 153.1576611722738,
    "ttft": 1898361.0198040244,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 227,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6947307178727342,
    "arrivals": 463915,
    "finished_requests": 92719,
    "scheduler_time": 103.8892563117021
}
#Debug simulation 
Total elapsed time: 7.918658722192049. Arrivals time: 0.5532527207396924 Scheduler time: 7.262973084580153 Scheduler overhead time: 0.03795628482475877 Adapter cache time: 0.008608258794993162 Engine time: 0.038471460808068514 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-8-16/adapters_96_slots_64_rate_3.2-0.8-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-8-16/adapters_96_slots_64_rate_3.2-0.8-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 270, 34560, 270, 270, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 270, 34560, 8640, 270, 270, 8640, 34560, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 270, 34560, 8640, 8640, 270, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 270, 34560, 8640, 8640, 8640, 34560, 34560, 270, 270, 8640, 270, 34560, 270, 270, 34560, 270, 8640, 8640, 270, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 270, 270, 34560, 8640, 34560, 270, 8640, 34560, 270, 34560, 8640, 270, 34560, 270, 270, 34560, 270, 270, 8640]
Prompts retrieved: 1391040 . Total input tokens: 310246563 . Total output tokens: 278256734
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.666755607817322,
    "estimated_duration": 3600.130293703319,
    "input_throughput": 6353.201727171954,
    "output_throughput": 5633.426388892616,
    "total_throughput": 11986.62811606457,
    "itl": 153.16360758419648,
    "ttft": 1898379.620478724,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 227,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7482026210776563,
    "arrivals": 463915,
    "finished_requests": 92718,
    "scheduler_time": 103.88691241901375
}
#Debug simulation 
Total elapsed time: 7.666876600589603. Arrivals time: 0.2805363810621202 Scheduler time: 7.284704644232988 Scheduler overhead time: 0.037524950224906206 Adapter cache time: 0.00860042404383421 Engine time: 0.03807448968291283 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-8-32/adapters_96_slots_64_rate_3.2-0.8-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-8-32/adapters_96_slots_64_rate_3.2-0.8-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 270, 34560, 270, 270, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 270, 34560, 8640, 270, 270, 8640, 34560, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 270, 34560, 8640, 8640, 270, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 270, 34560, 8640, 8640, 8640, 34560, 34560, 270, 270, 8640, 270, 34560, 270, 270, 34560, 270, 8640, 8640, 270, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 270, 270, 34560, 8640, 34560, 270, 8640, 34560, 270, 34560, 8640, 270, 34560, 270, 270, 34560, 270, 270, 8640]
Prompts retrieved: 1391040 . Total input tokens: 310246563 . Total output tokens: 278256734
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.636106499936432,
    "estimated_duration": 3600.130677873669,
    "input_throughput": 6353.201049221082,
    "output_throughput": 5633.425787749052,
    "total_throughput": 11986.626836970134,
    "itl": 153.16359892758808,
    "ttft": 1898380.2903527552,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 227,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7482108527421987,
    "arrivals": 463915,
    "finished_requests": 92718,
    "scheduler_time": 103.88693515948611
}
#Debug simulation 
Total elapsed time: 7.636202675756067. Arrivals time: 0.27437440725043416 Scheduler time: 7.260092876385897 Scheduler overhead time: 0.037797873839735985 Adapter cache time: 0.008553131483495235 Engine time: 0.03807986015453935 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-16-16/adapters_96_slots_64_rate_3.2-0.8-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-16-16/adapters_96_slots_64_rate_3.2-0.8-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 270, 34560, 270, 270, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 270, 34560, 8640, 270, 270, 8640, 34560, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 270, 34560, 8640, 8640, 270, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 270, 34560, 8640, 8640, 8640, 34560, 34560, 270, 270, 8640, 270, 34560, 270, 270, 34560, 270, 8640, 8640, 270, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 270, 270, 34560, 8640, 34560, 270, 8640, 34560, 270, 34560, 8640, 270, 34560, 270, 270, 34560, 270, 270, 8640]
Prompts retrieved: 1391040 . Total input tokens: 310246563 . Total output tokens: 278256734
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 7.659895590972155,
    "estimated_duration": 3600.0154745802884,
    "input_throughput": 6352.917414241502,
    "output_throughput": 5633.508562172069,
    "total_throughput": 11986.425976413571,
    "itl": 153.1586324867043,
    "ttft": 1898300.6541255799,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 227,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7110204470995832,
    "arrivals": 463915,
    "finished_requests": 92716,
    "scheduler_time": 103.88428434877116
}
#Debug simulation 
Total elapsed time: 7.659991775173694. Arrivals time: 0.31997740594670177 Scheduler time: 7.237561564426869 Scheduler overhead time: 0.03825582470744848 Adapter cache time: 0.008638004772365093 Engine time: 0.038153660017997026 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-16-32/adapters_96_slots_64_rate_3.2-0.8-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-16-32/adapters_96_slots_64_rate_3.2-0.8-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 270, 34560, 270, 270, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 270, 34560, 8640, 270, 270, 8640, 34560, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 270, 34560, 8640, 8640, 270, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 270, 34560, 8640, 8640, 8640, 34560, 34560, 270, 270, 8640, 270, 34560, 270, 270, 34560, 270, 8640, 8640, 270, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 270, 270, 34560, 8640, 34560, 270, 8640, 34560, 270, 34560, 8640, 270, 34560, 270, 270, 34560, 270, 270, 8640]
Prompts retrieved: 1391040 . Total input tokens: 310246563 . Total output tokens: 278256734
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 7.636079065036029,
    "estimated_duration": 3600.1409353194354,
    "input_throughput": 6353.182947814394,
    "output_throughput": 5633.409737110886,
    "total_throughput": 11986.592684925281,
    "itl": 153.1638405721127,
    "ttft": 1898383.4740722599,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 227,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7596544473059507,
    "arrivals": 463915,
    "finished_requests": 92718,
    "scheduler_time": 103.88693069638192
}
#Debug simulation 
Total elapsed time: 7.636193851009011. Arrivals time: 0.27879760041832924 Scheduler time: 7.255678866989911 Scheduler overhead time: 0.037553051952272654 Adapter cache time: 0.008586623705923557 Engine time: 0.03822471061721444 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_16-16-16/adapters_96_slots_64_rate_3.2-0.8-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_16-16-16/adapters_96_slots_64_rate_3.2-0.8-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 270, 34560, 270, 270, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 270, 34560, 8640, 270, 270, 8640, 34560, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 270, 34560, 8640, 8640, 270, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 270, 34560, 8640, 8640, 8640, 34560, 34560, 270, 270, 8640, 270, 34560, 270, 270, 34560, 270, 8640, 8640, 270, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 270, 270, 34560, 8640, 34560, 270, 8640, 34560, 270, 34560, 8640, 270, 34560, 270, 270, 34560, 270, 270, 8640]
Prompts retrieved: 1391040 . Total input tokens: 310246563 . Total output tokens: 278256734
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 7.924631475005299,
    "estimated_duration": 3600.137298314485,
    "input_throughput": 6352.944930935823,
    "output_throughput": 5633.359597006234,
    "total_throughput": 11986.304527942058,
    "itl": 153.15717924802132,
    "ttft": 1898340.8630437995,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 227,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6787414169427948,
    "arrivals": 463915,
    "finished_requests": 92719,
    "scheduler_time": 103.88863185107157
}
#Debug simulation 
Total elapsed time: 7.924694826826453. Arrivals time: 0.32838176703080535 Scheduler time: 7.494358375668526 Scheduler overhead time: 0.03797970153391361 Adapter cache time: 0.008534227032214403 Engine time: 0.037994515150785446 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_16-16-32/adapters_96_slots_64_rate_3.2-0.8-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_16-16-32/adapters_96_slots_64_rate_3.2-0.8-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 270, 34560, 270, 270, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 270, 34560, 8640, 270, 270, 8640, 34560, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 270, 34560, 8640, 8640, 270, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 270, 34560, 8640, 8640, 8640, 34560, 34560, 270, 270, 8640, 270, 34560, 270, 270, 34560, 270, 8640, 8640, 270, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 270, 270, 34560, 8640, 34560, 270, 8640, 34560, 270, 34560, 8640, 270, 34560, 270, 270, 34560, 270, 270, 8640]
Prompts retrieved: 1391040 . Total input tokens: 310246563 . Total output tokens: 278256734
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.705690938979387,
    "estimated_duration": 3600.151017654288,
    "input_throughput": 6353.1651555280305,
    "output_throughput": 5633.393960571776,
    "total_throughput": 11986.559116099806,
    "itl": 153.16418315900393,
    "ttft": 1898388.0047353916,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 227,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7695889964327246,
    "arrivals": 463915,
    "finished_requests": 92718,
    "scheduler_time": 103.88696292712635
}
#Debug simulation 
Total elapsed time: 7.705802193842828. Arrivals time: 0.29289675038307905 Scheduler time: 7.310558608267456 Scheduler overhead time: 0.03781689424067736 Adapter cache time: 0.008630346972495317 Engine time: 0.03841402707621455 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-8-8/adapters_96_slots_64_rate_3.2-0.8-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-8-8/adapters_96_slots_64_rate_3.2-0.8-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 135, 34560, 135, 135, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 135, 34560, 8640, 135, 135, 8640, 34560, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 135, 34560, 8640, 8640, 135, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 135, 34560, 8640, 8640, 8640, 34560, 34560, 135, 135, 8640, 135, 34560, 135, 135, 34560, 135, 8640, 8640, 135, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 135, 135, 34560, 8640, 34560, 135, 8640, 34560, 135, 34560, 8640, 135, 34560, 135, 135, 34560, 135, 135, 8640]
Prompts retrieved: 1386720 . Total input tokens: 309283426 . Total output tokens: 277385822
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.89098055427894,
    "estimated_duration": 3600.017177944633,
    "input_throughput": 6362.734361472618,
    "output_throughput": 5635.204777434538,
    "total_throughput": 11997.939138907155,
    "itl": 153.06625629100563,
    "ttft": 1891273.1462741606,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 262,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8018477889103804,
    "arrivals": 462529,
    "finished_requests": 92668,
    "scheduler_time": 103.88108070439569
}
#Debug simulation 
Total elapsed time: 6.891078965272754. Arrivals time: 0.31397655978798866 Scheduler time: 6.4762437622994184 Scheduler overhead time: 0.037322483491152525 Adapter cache time: 0.008683609310537577 Engine time: 0.0377600803039968 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-8-16/adapters_96_slots_64_rate_3.2-0.8-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-8-16/adapters_96_slots_64_rate_3.2-0.8-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 135, 34560, 135, 135, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 135, 34560, 8640, 135, 135, 8640, 34560, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 135, 34560, 8640, 8640, 135, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 135, 34560, 8640, 8640, 8640, 34560, 34560, 135, 135, 8640, 135, 34560, 135, 135, 34560, 135, 8640, 8640, 135, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 135, 135, 34560, 8640, 34560, 135, 8640, 34560, 135, 34560, 8640, 135, 34560, 135, 135, 34560, 135, 135, 8640]
Prompts retrieved: 1386720 . Total input tokens: 309283426 . Total output tokens: 277385822
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.9513454949483275,
    "estimated_duration": 3600.107759567927,
    "input_throughput": 6362.61621311833,
    "output_throughput": 5635.063546663047,
    "total_throughput": 11997.679759781377,
    "itl": 153.06797664187587,
    "ttft": 1891305.0680942242,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 258,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8519262538175144,
    "arrivals": 462529,
    "finished_requests": 92669,
    "scheduler_time": 103.88251947049882
}
#Debug simulation 
Total elapsed time: 6.9514509490691125. Arrivals time: 0.3231268199160695 Scheduler time: 6.5269383722916245 Scheduler overhead time: 0.037441366352140903 Adapter cache time: 0.008849915582686663 Engine time: 0.0377967176027596 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-8-32/adapters_96_slots_64_rate_3.2-0.8-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-8-32/adapters_96_slots_64_rate_3.2-0.8-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 135, 34560, 135, 135, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 135, 34560, 8640, 135, 135, 8640, 34560, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 135, 34560, 8640, 8640, 135, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 135, 34560, 8640, 8640, 8640, 34560, 34560, 135, 135, 8640, 135, 34560, 135, 135, 34560, 135, 8640, 8640, 135, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 135, 135, 34560, 8640, 34560, 135, 8640, 34560, 135, 34560, 8640, 135, 34560, 135, 135, 34560, 135, 135, 8640]
Prompts retrieved: 1386720 . Total input tokens: 309283426 . Total output tokens: 277385822
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.9210188100114465,
    "estimated_duration": 3600.109772431499,
    "input_throughput": 6362.612655705027,
    "output_throughput": 5635.060396032967,
    "total_throughput": 11997.673051737995,
    "itl": 153.06791528763847,
    "ttft": 1891305.0481621851,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 258,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8516656194068535,
    "arrivals": 462529,
    "finished_requests": 92669,
    "scheduler_time": 103.88258081683367
}
#Debug simulation 
Total elapsed time: 6.921114776749164. Arrivals time: 0.2800579904578626 Scheduler time: 6.539428453426808 Scheduler overhead time: 0.03735110256820917 Adapter cache time: 0.008856034372001886 Engine time: 0.03810354741290212 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-16-16/adapters_96_slots_64_rate_3.2-0.8-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-16-16/adapters_96_slots_64_rate_3.2-0.8-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 135, 34560, 135, 135, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 135, 34560, 8640, 135, 135, 8640, 34560, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 135, 34560, 8640, 8640, 135, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 135, 34560, 8640, 8640, 8640, 34560, 34560, 135, 135, 8640, 135, 34560, 135, 135, 34560, 135, 8640, 8640, 135, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 135, 135, 34560, 8640, 34560, 135, 8640, 34560, 135, 34560, 8640, 135, 34560, 135, 135, 34560, 135, 135, 8640]
Prompts retrieved: 1386720 . Total input tokens: 309283426 . Total output tokens: 277385822
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 6.881024894770235,
    "estimated_duration": 3600.040745245555,
    "input_throughput": 6362.692708478667,
    "output_throughput": 5635.167887139081,
    "total_throughput": 11997.860595617749,
    "itl": 153.06719657658928,
    "ttft": 1891283.307936913,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 262,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8234355184715269,
    "arrivals": 462529,
    "finished_requests": 92668,
    "scheduler_time": 103.88118002131358
}
#Debug simulation 
Total elapsed time: 6.881123072933406. Arrivals time: 0.31127893226221204 Scheduler time: 6.468913529999554 Scheduler overhead time: 0.03734204452484846 Adapter cache time: 0.008741958532482386 Engine time: 0.03776449803262949 
