INFO 06-01 00:47:00 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 06-01 00:47:01 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_16-16-32/adapters_96_slots_64_rate_1.6-0.8-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_16-16-32/adapters_96_slots_64_rate_1.6-0.8-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 540, 17280, 540, 540, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 540, 17280, 8640, 540, 540, 8640, 17280, 540, 8640, 540, 540, 8640, 8640, 8640, 540, 540, 17280, 8640, 8640, 540, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 540, 17280, 8640, 8640, 8640, 17280, 17280, 540, 540, 8640, 540, 17280, 540, 540, 17280, 540, 8640, 8640, 540, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 540, 540, 17280, 8640, 17280, 540, 8640, 17280, 540, 17280, 8640, 540, 17280, 540, 540, 17280, 540, 540, 8640]
Prompts retrieved: 846720 . Total input tokens: 188628101 . Total output tokens: 169501607
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 13.815534613037016,
    "estimated_duration": 3600.1249334725853,
    "input_throughput": 6322.350868541969,
    "output_throughput": 5636.619943749107,
    "total_throughput": 11958.970812291076,
    "itl": 153.52309639056654,
    "ttft": 1712756.0614483913,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 85,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2841641725972291,
    "arrivals": 282072,
    "finished_requests": 92019,
    "scheduler_time": 102.97310813135067
}
#Debug simulation 
Total elapsed time: 13.815722680010367. Arrivals time: 0.3437663324875757 Scheduler time: 13.365182215056848 Scheduler overhead time: 0.03977003262843937 Adapter cache time: 0.007401675742585212 Engine time: 0.0415354126598686 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-8-8/adapters_96_slots_64_rate_1.6-0.8-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-8-8/adapters_96_slots_64_rate_1.6-0.8-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 270, 17280, 270, 270, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 270, 17280, 8640, 270, 270, 8640, 17280, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 270, 17280, 8640, 8640, 270, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 270, 17280, 8640, 8640, 8640, 17280, 17280, 270, 270, 8640, 270, 17280, 270, 270, 17280, 270, 8640, 8640, 270, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 270, 270, 17280, 8640, 17280, 270, 8640, 17280, 270, 17280, 8640, 270, 17280, 270, 270, 17280, 270, 270, 8640]
Prompts retrieved: 838080 . Total input tokens: 186703178 . Total output tokens: 167718589
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 10.40751997201005,
    "estimated_duration": 3600.117370495172,
    "input_throughput": 6345.318679667928,
    "output_throughput": 5633.361058228643,
    "total_throughput": 11978.679737896571,
    "itl": 153.10706347409845,
    "ttft": 1708584.3112663683,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 103,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3152302376250733,
    "arrivals": 279133,
    "finished_requests": 92110,
    "scheduler_time": 102.93902020945634
}
#Debug simulation 
Total elapsed time: 10.407629880995955. Arrivals time: 0.30771508591715246 Scheduler time: 9.996741151378956 Scheduler overhead time: 0.03891510464018211 Adapter cache time: 0.007078786031343043 Engine time: 0.039495454693678766 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-8-16/adapters_96_slots_64_rate_1.6-0.8-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-8-16/adapters_96_slots_64_rate_1.6-0.8-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 270, 17280, 270, 270, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 270, 17280, 8640, 270, 270, 8640, 17280, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 270, 17280, 8640, 8640, 270, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 270, 17280, 8640, 8640, 8640, 17280, 17280, 270, 270, 8640, 270, 17280, 270, 270, 17280, 270, 8640, 8640, 270, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 270, 270, 17280, 8640, 17280, 270, 8640, 17280, 270, 17280, 8640, 270, 17280, 270, 270, 17280, 270, 270, 8640]
Prompts retrieved: 838080 . Total input tokens: 186703178 . Total output tokens: 167718589
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 10.447786158008967,
    "estimated_duration": 3600.0251241301858,
    "input_throughput": 6345.177106373424,
    "output_throughput": 5633.385962799357,
    "total_throughput": 11978.56306917278,
    "itl": 153.10715335648743,
    "ttft": 1708547.6362124386,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 103,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3361682573473081,
    "arrivals": 279133,
    "finished_requests": 92106,
    "scheduler_time": 102.93612740986768
}
#Debug simulation 
Total elapsed time: 10.447903144988231. Arrivals time: 0.32380295521579683 Scheduler time: 10.020755059667863 Scheduler overhead time: 0.03877151611959562 Adapter cache time: 0.007363163342233747 Engine time: 0.039470884832553566 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-8-32/adapters_96_slots_64_rate_1.6-0.8-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-8-32/adapters_96_slots_64_rate_1.6-0.8-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 270, 17280, 270, 270, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 270, 17280, 8640, 270, 270, 8640, 17280, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 270, 17280, 8640, 8640, 270, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 270, 17280, 8640, 8640, 8640, 17280, 17280, 270, 270, 8640, 270, 17280, 270, 270, 17280, 270, 8640, 8640, 270, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 270, 270, 17280, 8640, 17280, 270, 8640, 17280, 270, 17280, 8640, 270, 17280, 270, 270, 17280, 270, 270, 8640]
Prompts retrieved: 838080 . Total input tokens: 186703178 . Total output tokens: 167718589
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 10.413005731999874,
    "estimated_duration": 3600.026991993228,
    "input_throughput": 6345.173814197605,
    "output_throughput": 5633.383039934204,
    "total_throughput": 11978.55685413181,
    "itl": 153.1071609502159,
    "ttft": 1708548.533381768,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 103,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3367525185458367,
    "arrivals": 279133,
    "finished_requests": 92106,
    "scheduler_time": 102.93618291570726
}
#Debug simulation 
Total elapsed time: 10.413102660037111. Arrivals time: 0.3118836115463637 Scheduler time: 9.997817820869386 Scheduler overhead time: 0.039078692556358874 Adapter cache time: 0.0072149537154473364 Engine time: 0.03937742247944698 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-16-16/adapters_96_slots_64_rate_1.6-0.8-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-16-16/adapters_96_slots_64_rate_1.6-0.8-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 270, 17280, 270, 270, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 270, 17280, 8640, 270, 270, 8640, 17280, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 270, 17280, 8640, 8640, 270, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 270, 17280, 8640, 8640, 8640, 17280, 17280, 270, 270, 8640, 270, 17280, 270, 270, 17280, 270, 8640, 8640, 270, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 270, 270, 17280, 8640, 17280, 270, 8640, 17280, 270, 17280, 8640, 270, 17280, 270, 270, 17280, 270, 270, 8640]
Prompts retrieved: 838080 . Total input tokens: 186703178 . Total output tokens: 167718589
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 10.39514836500166,
    "estimated_duration": 3600.148810311607,
    "input_throughput": 6345.417704559474,
    "output_throughput": 5633.323528713974,
    "total_throughput": 11978.74123327345,
    "itl": 153.10757447029386,
    "ttft": 1708589.2254598595,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 103,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3218674212018961,
    "arrivals": 279133,
    "finished_requests": 92111,
    "scheduler_time": 102.93991277833152
}
#Debug simulation 
Total elapsed time: 10.395274784998037. Arrivals time: 0.3188461463432759 Scheduler time: 9.973050444037654 Scheduler overhead time: 0.03917044441914186 Adapter cache time: 0.007426059513818473 Engine time: 0.039096267777495086 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-16-32/adapters_96_slots_64_rate_1.6-0.8-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-16-32/adapters_96_slots_64_rate_1.6-0.8-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 270, 17280, 270, 270, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 270, 17280, 8640, 270, 270, 8640, 17280, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 270, 17280, 8640, 8640, 270, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 270, 17280, 8640, 8640, 8640, 17280, 17280, 270, 270, 8640, 270, 17280, 270, 270, 17280, 270, 8640, 8640, 270, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 270, 270, 17280, 8640, 17280, 270, 8640, 17280, 270, 17280, 8640, 270, 17280, 270, 270, 17280, 270, 270, 8640]
Prompts retrieved: 838080 . Total input tokens: 186703178 . Total output tokens: 167718589
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 10.531724468979519,
    "estimated_duration": 3600.0345752264416,
    "input_throughput": 6345.160448511301,
    "output_throughput": 5633.37117358779,
    "total_throughput": 11978.531622099092,
    "itl": 153.1070594476194,
    "ttft": 1708551.1723985395,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 103,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3411539010703564,
    "arrivals": 279133,
    "finished_requests": 92106,
    "scheduler_time": 102.93630867889978
}
#Debug simulation 
Total elapsed time: 10.531818103976548. Arrivals time: 0.31464470335049555 Scheduler time: 10.112493087362964 Scheduler overhead time: 0.03940699843224138 Adapter cache time: 0.007465008529834449 Engine time: 0.0400031351018697 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_16-16-16/adapters_96_slots_64_rate_1.6-0.8-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_16-16-16/adapters_96_slots_64_rate_1.6-0.8-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 270, 17280, 270, 270, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 270, 17280, 8640, 270, 270, 8640, 17280, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 270, 17280, 8640, 8640, 270, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 270, 17280, 8640, 8640, 8640, 17280, 17280, 270, 270, 8640, 270, 17280, 270, 270, 17280, 270, 8640, 8640, 270, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 270, 270, 17280, 8640, 17280, 270, 8640, 17280, 270, 17280, 8640, 270, 17280, 270, 270, 17280, 270, 270, 8640]
Prompts retrieved: 838080 . Total input tokens: 186703178 . Total output tokens: 167718589
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 10.403418614005204,
    "estimated_duration": 3600.0870093307535,
    "input_throughput": 6345.27608382625,
    "output_throughput": 5633.389400710658,
    "total_throughput": 11978.665484536908,
    "itl": 153.10647787299442,
    "ttft": 1708576.7942757744,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 103,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.30797518037492444,
    "arrivals": 279133,
    "finished_requests": 92109,
    "scheduler_time": 102.93823769316546
}
#Debug simulation 
Total elapsed time: 10.403532074997202. Arrivals time: 0.3176940561388619 Scheduler time: 9.983559324929956 Scheduler overhead time: 0.038667508226353675 Adapter cache time: 0.007237272569909692 Engine time: 0.03868491284083575 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_16-16-32/adapters_96_slots_64_rate_1.6-0.8-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_16-16-32/adapters_96_slots_64_rate_1.6-0.8-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 270, 17280, 270, 270, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 270, 17280, 8640, 270, 270, 8640, 17280, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 270, 17280, 8640, 8640, 270, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 270, 17280, 8640, 8640, 8640, 17280, 17280, 270, 270, 8640, 270, 17280, 270, 270, 17280, 270, 8640, 8640, 270, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 270, 270, 17280, 8640, 17280, 270, 8640, 17280, 270, 17280, 8640, 270, 17280, 270, 270, 17280, 270, 270, 8640]
Prompts retrieved: 838080 . Total input tokens: 186703178 . Total output tokens: 167718589
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 10.458470811019652,
    "estimated_duration": 3600.056757481118,
    "input_throughput": 6345.244127757286,
    "output_throughput": 5633.39146191402,
    "total_throughput": 11978.635589671305,
    "itl": 153.10763588270464,
    "ttft": 1708530.0701833176,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 103,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3454295298084612,
    "arrivals": 279133,
    "finished_requests": 92108,
    "scheduler_time": 102.93693904982152
}
#Debug simulation 
Total elapsed time: 10.458568434987683. Arrivals time: 0.3180398310068995 Scheduler time: 10.03735363233136 Scheduler overhead time: 0.039351211045868695 Adapter cache time: 0.0072942792903631926 Engine time: 0.03895671776263043 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-8/adapters_96_slots_64_rate_1.6-0.8-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-8/adapters_96_slots_64_rate_1.6-0.8-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 135, 17280, 135, 135, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 135, 17280, 8640, 135, 135, 8640, 17280, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 135, 17280, 8640, 8640, 135, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 135, 17280, 8640, 8640, 8640, 17280, 17280, 135, 135, 8640, 135, 17280, 135, 135, 17280, 135, 8640, 8640, 135, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 135, 135, 17280, 8640, 17280, 135, 8640, 17280, 135, 17280, 8640, 135, 17280, 135, 135, 17280, 135, 135, 8640]
Prompts retrieved: 833760 . Total input tokens: 185761784 . Total output tokens: 166859550
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 8.348683075979352,
    "estimated_duration": 3600.030380008253,
    "input_throughput": 6350.619185593537,
    "output_throughput": 5634.744671225107,
    "total_throughput": 11985.363856818643,
    "itl": 152.99343509137637,
    "ttft": 1706570.3128992135,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 99,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3029882866493423,
    "arrivals": 277639,
    "finished_requests": 92359,
    "scheduler_time": 102.92936016660748
}
#Debug simulation 
Total elapsed time: 8.348775653983466. Arrivals time: 0.32985794683918357 Scheduler time: 7.917732318048365 Scheduler overhead time: 0.03824922698549926 Adapter cache time: 0.007036411727312952 Engine time: 0.03828887711279094 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-16/adapters_96_slots_64_rate_1.6-0.8-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-16/adapters_96_slots_64_rate_1.6-0.8-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 135, 17280, 135, 135, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 135, 17280, 8640, 135, 135, 8640, 17280, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 135, 17280, 8640, 8640, 135, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 135, 17280, 8640, 8640, 8640, 17280, 17280, 135, 135, 8640, 135, 17280, 135, 135, 17280, 135, 8640, 8640, 135, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 135, 135, 17280, 8640, 17280, 135, 8640, 17280, 135, 17280, 8640, 135, 17280, 135, 135, 17280, 135, 135, 8640]
Prompts retrieved: 833760 . Total input tokens: 185761784 . Total output tokens: 166859550
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 8.330755588016473,
    "estimated_duration": 3600.07587142301,
    "input_throughput": 6350.538937659422,
    "output_throughput": 5634.673469251581,
    "total_throughput": 11985.212406911003,
    "itl": 152.99382137099997,
    "ttft": 1706584.8723672742,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 99,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3233908655308187,
    "arrivals": 277639,
    "finished_requests": 92359,
    "scheduler_time": 102.93027625510116
}
#Debug simulation 
Total elapsed time: 8.330873929022346. Arrivals time: 0.3284894364187494 Scheduler time: 7.9014133083983324 Scheduler overhead time: 0.038203782693017274 Adapter cache time: 0.006891460914630443 Engine time: 0.03828042862005532 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-32/adapters_96_slots_64_rate_1.6-0.8-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-32/adapters_96_slots_64_rate_1.6-0.8-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 135, 17280, 135, 135, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 135, 17280, 8640, 135, 135, 8640, 17280, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 135, 17280, 8640, 8640, 135, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 135, 17280, 8640, 8640, 8640, 17280, 17280, 135, 135, 8640, 135, 17280, 135, 135, 17280, 135, 8640, 8640, 135, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 135, 135, 17280, 8640, 17280, 135, 8640, 17280, 135, 17280, 8640, 135, 17280, 135, 135, 17280, 135, 135, 8640]
Prompts retrieved: 833760 . Total input tokens: 185761784 . Total output tokens: 166859550
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 8.337642374972347,
    "estimated_duration": 3600.076885395089,
    "input_throughput": 6350.537149011742,
    "output_throughput": 5634.671882229482,
    "total_throughput": 11985.209031241224,
    "itl": 152.99360230594385,
    "ttft": 1706584.027140499,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 99,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3239039481617515,
    "arrivals": 277639,
    "finished_requests": 92359,
    "scheduler_time": 102.93029940817313
}
#Debug simulation 
Total elapsed time: 8.337739316979423. Arrivals time: 0.30994969740277156 Scheduler time: 7.926737462810706 Scheduler overhead time: 0.038109463814180344 Adapter cache time: 0.007059346418827772 Engine time: 0.03842319914838299 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-16-16/adapters_96_slots_64_rate_1.6-0.8-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-16-16/adapters_96_slots_64_rate_1.6-0.8-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 135, 17280, 135, 135, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 135, 17280, 8640, 135, 135, 8640, 17280, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 135, 17280, 8640, 8640, 135, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 135, 17280, 8640, 8640, 8640, 17280, 17280, 135, 135, 8640, 135, 17280, 135, 135, 17280, 135, 8640, 8640, 135, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 135, 135, 17280, 8640, 17280, 135, 8640, 17280, 135, 17280, 8640, 135, 17280, 135, 135, 17280, 135, 135, 8640]
Prompts retrieved: 833760 . Total input tokens: 185761784 . Total output tokens: 166859550
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 8.321148824994452,
    "estimated_duration": 3600.056355396165,
    "input_throughput": 6350.573364145052,
    "output_throughput": 5634.704015006378,
    "total_throughput": 11985.27737915143,
    "itl": 152.99414472772486,
    "ttft": 1706576.2325815402,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 99,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.30909002938540664,
    "arrivals": 277639,
    "finished_requests": 92359,
    "scheduler_time": 102.93004755987324
}
#Debug simulation 
Total elapsed time: 8.321305119956378. Arrivals time: 0.3089796722633764 Scheduler time: 7.911439334333409 Scheduler overhead time: 0.0381894750171341 Adapter cache time: 0.006995305942837149 Engine time: 0.03817689174320549 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-16-32/adapters_96_slots_64_rate_1.6-0.8-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-16-32/adapters_96_slots_64_rate_1.6-0.8-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 135, 17280, 135, 135, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 135, 17280, 8640, 135, 135, 8640, 17280, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 135, 17280, 8640, 8640, 135, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 135, 17280, 8640, 8640, 8640, 17280, 17280, 135, 135, 8640, 135, 17280, 135, 135, 17280, 135, 8640, 8640, 135, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 135, 135, 17280, 8640, 17280, 135, 8640, 17280, 135, 17280, 8640, 135, 17280, 135, 135, 17280, 135, 135, 8640]
Prompts retrieved: 833760 . Total input tokens: 185761784 . Total output tokens: 166859550
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 8.322891029005405,
    "estimated_duration": 3600.0837789513284,
    "input_throughput": 6350.524988798904,
    "output_throughput": 5634.661092778488,
    "total_throughput": 11985.18608157739,
    "itl": 152.99363135522333,
    "ttft": 1706587.5067369123,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 99,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3283053306862712,
    "arrivals": 277639,
    "finished_requests": 92359,
    "scheduler_time": 102.9304061637578
}
#Debug simulation 
Total elapsed time: 8.322991669003386. Arrivals time: 0.33058291079942137 Scheduler time: 7.891251135035418 Scheduler overhead time: 0.03817325719865039 Adapter cache time: 0.006950511538889259 Engine time: 0.03848201787332073 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_16-16-16/adapters_96_slots_64_rate_1.6-0.8-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_16-16-16/adapters_96_slots_64_rate_1.6-0.8-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 135, 17280, 135, 135, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 135, 17280, 8640, 135, 135, 8640, 17280, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 135, 17280, 8640, 8640, 135, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 135, 17280, 8640, 8640, 8640, 17280, 17280, 135, 135, 8640, 135, 17280, 135, 135, 17280, 135, 8640, 8640, 135, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 135, 135, 17280, 8640, 17280, 135, 8640, 17280, 135, 17280, 8640, 135, 17280, 135, 135, 17280, 135, 135, 8640]
Prompts retrieved: 833760 . Total input tokens: 185761784 . Total output tokens: 166859550
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 8.381871922989376,
    "estimated_duration": 3600.0207398632097,
    "input_throughput": 6350.63619129836,
    "output_throughput": 5634.759759959266,
    "total_throughput": 11985.395951257628,
    "itl": 152.99365316308482,
    "ttft": 1706567.2893200372,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 99,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2960149791953157,
    "arrivals": 277639,
    "finished_requests": 92359,
    "scheduler_time": 102.9292675927756
}
#Debug simulation 
Total elapsed time: 8.381967614986934. Arrivals time: 0.33447600732324645 Scheduler time: 7.946205842774361 Scheduler overhead time: 0.038173314882442355 Adapter cache time: 0.006946700043044984 Engine time: 0.03852695826208219 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_16-16-32/adapters_96_slots_64_rate_1.6-0.8-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_16-16-32/adapters_96_slots_64_rate_1.6-0.8-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 135, 17280, 135, 135, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 135, 17280, 8640, 135, 135, 8640, 17280, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 135, 17280, 8640, 8640, 135, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 135, 17280, 8640, 8640, 8640, 17280, 17280, 135, 135, 8640, 135, 17280, 135, 135, 17280, 135, 8640, 8640, 135, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 135, 135, 17280, 8640, 17280, 135, 8640, 17280, 135, 17280, 8640, 135, 17280, 135, 135, 17280, 135, 135, 8640]
Prompts retrieved: 833760 . Total input tokens: 185761784 . Total output tokens: 166859550
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 8.36287493101554,
    "estimated_duration": 3600.089233949438,
    "input_throughput": 6350.515366231362,
    "output_throughput": 5634.652554916337,
    "total_throughput": 11985.167921147699,
    "itl": 152.9934123175783,
    "ttft": 1706589.5330432125,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 99,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3323294518515464,
    "arrivals": 277639,
    "finished_requests": 92359,
    "scheduler_time": 102.9304808690238
}
#Debug simulation 
Total elapsed time: 8.363044285972137. Arrivals time: 0.3321746904402971 Scheduler time: 7.929030795989092 Scheduler overhead time: 0.038571814249735326 Adapter cache time: 0.007086634228471667 Engine time: 0.03856715909205377 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-8/adapters_96_slots_64_rate_1.6-0.8-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-8/adapters_96_slots_64_rate_1.6-0.8-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 66, 17280, 66, 66, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 66, 17280, 8640, 66, 66, 8640, 17280, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 66, 17280, 8640, 8640, 66, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 66, 17280, 8640, 8640, 8640, 17280, 17280, 66, 66, 8640, 66, 17280, 66, 66, 17280, 66, 8640, 8640, 66, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 66, 66, 17280, 8640, 17280, 66, 8640, 17280, 66, 17280, 8640, 66, 17280, 66, 66, 17280, 66, 66, 8640]
Prompts retrieved: 831552 . Total input tokens: 185270176 . Total output tokens: 166411436
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 8.041985248972196,
    "estimated_duration": 3600.158720027677,
    "input_throughput": 6337.23087626109,
    "output_throughput": 5638.7261170096235,
    "total_throughput": 11975.956993270713,
    "itl": 153.3386915556692,
    "ttft": 1703599.4709472999,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 125,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3825609679915938,
    "arrivals": 276898,
    "finished_requests": 92683,
    "scheduler_time": 102.90160208697817
}
#Debug simulation 
Total elapsed time: 8.042079818958882. Arrivals time: 0.33023809565929696 Scheduler time: 7.610693374881521 Scheduler overhead time: 0.037890547537244856 Adapter cache time: 0.0074481850024312735 Engine time: 0.03830407001078129 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-16/adapters_96_slots_64_rate_1.6-0.8-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-16/adapters_96_slots_64_rate_1.6-0.8-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 66, 17280, 66, 66, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 66, 17280, 8640, 66, 66, 8640, 17280, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 66, 17280, 8640, 8640, 66, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 66, 17280, 8640, 8640, 8640, 17280, 17280, 66, 66, 8640, 66, 17280, 66, 66, 17280, 66, 8640, 8640, 66, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 66, 66, 17280, 8640, 17280, 66, 8640, 17280, 66, 17280, 8640, 66, 17280, 66, 66, 17280, 66, 66, 8640]
Prompts retrieved: 831552 . Total input tokens: 185270176 . Total output tokens: 166411436
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 8.067843791970517,
    "estimated_duration": 3600.0750610087784,
    "input_throughput": 6337.116202684744,
    "output_throughput": 5638.542990354195,
    "total_throughput": 11975.65919303894,
    "itl": 153.33952025869402,
    "ttft": 1703510.2341177356,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 125,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.40971267488552254,
    "arrivals": 276898,
    "finished_requests": 92680,
    "scheduler_time": 102.89871556374965
}
#Debug simulation 
Total elapsed time: 8.06796132499585. Arrivals time: 0.31324799032881856 Scheduler time: 7.653581686317921 Scheduler overhead time: 0.0381505717523396 Adapter cache time: 0.007394644140731543 Engine time: 0.03807444730773568 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-32/adapters_96_slots_64_rate_1.6-0.8-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-32/adapters_96_slots_64_rate_1.6-0.8-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 66, 17280, 66, 66, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 66, 17280, 8640, 66, 66, 8640, 17280, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 66, 17280, 8640, 8640, 66, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 66, 17280, 8640, 8640, 8640, 17280, 17280, 66, 66, 8640, 66, 17280, 66, 66, 17280, 66, 8640, 8640, 66, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 66, 66, 17280, 8640, 17280, 66, 8640, 17280, 66, 17280, 8640, 66, 17280, 66, 66, 17280, 66, 66, 8640]
Prompts retrieved: 831552 . Total input tokens: 185270176 . Total output tokens: 166411436
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 8.035212927032262,
    "estimated_duration": 3600.075885888759,
    "input_throughput": 6337.114750670828,
    "output_throughput": 5638.541698403309,
    "total_throughput": 11975.656449074137,
    "itl": 153.33950407595074,
    "ttft": 1703511.1422556255,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 125,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.41011763561517106,
    "arrivals": 276898,
    "finished_requests": 92680,
    "scheduler_time": 102.89874145213587
}
#Debug simulation 
Total elapsed time: 8.035377042018808. Arrivals time: 0.3069665743387304 Scheduler time: 7.627655807475094 Scheduler overhead time: 0.03787061769980937 Adapter cache time: 0.007368666992988437 Engine time: 0.038052274205256253 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-16-16/adapters_96_slots_64_rate_1.6-0.8-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-16-16/adapters_96_slots_64_rate_1.6-0.8-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 66, 17280, 66, 66, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 66, 17280, 8640, 66, 66, 8640, 17280, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 66, 17280, 8640, 8640, 66, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 66, 17280, 8640, 8640, 8640, 17280, 17280, 66, 66, 8640, 66, 17280, 66, 66, 17280, 66, 8640, 8640, 66, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 66, 66, 17280, 8640, 17280, 66, 8640, 17280, 66, 17280, 8640, 66, 17280, 66, 66, 17280, 66, 66, 8640]
Prompts retrieved: 831552 . Total input tokens: 185270176 . Total output tokens: 166411436
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 8.098444377013948,
    "estimated_duration": 3600.0132601218875,
    "input_throughput": 6337.224713229965,
    "output_throughput": 5638.550620036531,
    "total_throughput": 11975.775333266496,
    "itl": 153.33873984015506,
    "ttft": 1703517.6275789172,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 125,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3901000996003861,
    "arrivals": 276898,
    "finished_requests": 92679,
    "scheduler_time": 102.89724951098094
}
#Debug simulation 
Total elapsed time: 8.09853799303528. Arrivals time: 0.3490128854755312 Scheduler time: 7.648014419886749 Scheduler overhead time: 0.038241062546148896 Adapter cache time: 0.0073665069648995996 Engine time: 0.03836064721690491 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-16-32/adapters_96_slots_64_rate_1.6-0.8-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-16-32/adapters_96_slots_64_rate_1.6-0.8-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 66, 17280, 66, 66, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 66, 17280, 8640, 66, 66, 8640, 17280, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 66, 17280, 8640, 8640, 66, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 66, 17280, 8640, 8640, 8640, 17280, 17280, 66, 66, 8640, 66, 17280, 66, 66, 17280, 66, 8640, 8640, 66, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 66, 66, 17280, 8640, 17280, 66, 8640, 17280, 66, 17280, 8640, 66, 17280, 66, 66, 17280, 66, 66, 8640]
Prompts retrieved: 831552 . Total input tokens: 185270176 . Total output tokens: 166411436
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 8.023939745966345,
    "estimated_duration": 3600.0961078562013,
    "input_throughput": 6337.079154696629,
    "output_throughput": 5638.51002635811,
    "total_throughput": 11975.589181054738,
    "itl": 153.3394316242684,
    "ttft": 1703545.7009571528,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 125,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.41615381736308354,
    "arrivals": 276898,
    "finished_requests": 92680,
    "scheduler_time": 102.89917862329341
}
#Debug simulation 
Total elapsed time: 8.024069392995443. Arrivals time: 0.3046375855919905 Scheduler time: 7.6182429327163845 Scheduler overhead time: 0.03815665189176798 Adapter cache time: 0.007266911561600864 Engine time: 0.03833148517878726 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_16-16-16/adapters_96_slots_64_rate_1.6-0.8-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_16-16-16/adapters_96_slots_64_rate_1.6-0.8-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 66, 17280, 66, 66, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 66, 17280, 8640, 66, 66, 8640, 17280, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 66, 17280, 8640, 8640, 66, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 66, 17280, 8640, 8640, 8640, 17280, 17280, 66, 66, 8640, 66, 17280, 66, 66, 17280, 66, 8640, 8640, 66, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 66, 66, 17280, 8640, 17280, 66, 8640, 17280, 66, 17280, 8640, 66, 17280, 66, 66, 17280, 66, 66, 8640]
Prompts retrieved: 831552 . Total input tokens: 185270176 . Total output tokens: 166411436
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 8.035314761975314,
    "estimated_duration": 3600.1340319757887,
    "input_throughput": 6337.274334055525,
    "output_throughput": 5638.7647847819135,
    "total_throughput": 11976.039118837438,
    "itl": 153.3386479105325,
    "ttft": 1703597.9547561244,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 125,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3737562868627724,
    "arrivals": 276898,
    "finished_requests": 92683,
    "scheduler_time": 102.90102202237576
}
#Debug simulation 
Total elapsed time: 8.035459395963699. Arrivals time: 0.3289358248584904 Scheduler time: 7.60524675459601 Scheduler overhead time: 0.03796256019268185 Adapter cache time: 0.007414870313368738 Engine time: 0.03846770623931661 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_16-16-32/adapters_96_slots_64_rate_1.6-0.8-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_16-16-32/adapters_96_slots_64_rate_1.6-0.8-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 66, 17280, 66, 66, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 66, 17280, 8640, 66, 66, 8640, 17280, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 66, 17280, 8640, 8640, 66, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 66, 17280, 8640, 8640, 8640, 17280, 17280, 66, 66, 8640, 66, 17280, 66, 66, 17280, 66, 8640, 8640, 66, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 66, 66, 17280, 8640, 17280, 66, 8640, 17280, 66, 17280, 8640, 66, 17280, 66, 66, 17280, 66, 66, 8640]
Prompts retrieved: 831552 . Total input tokens: 185270176 . Total output tokens: 166411436
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 8.03515333199175,
    "estimated_duration": 3600.1469035517375,
    "input_throughput": 6337.2516764501315,
    "output_throughput": 5638.744624552031,
    "total_throughput": 11975.996301002164,
    "itl": 153.34038955933127,
    "ttft": 1703555.2640227093,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 125,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4211839688196773,
    "arrivals": 276898,
    "finished_requests": 92683,
    "scheduler_time": 102.90073591855467
}
#Debug simulation 
Total elapsed time: 8.035272551991511. Arrivals time: 0.3068739901063964 Scheduler time: 7.627589784970041 Scheduler overhead time: 0.03788200160488486 Adapter cache time: 0.007317568582948297 Engine time: 0.03817874629748985 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-8/adapters_96_slots_64_rate_1.6-0.8-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-8/adapters_96_slots_64_rate_1.6-0.8-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 33, 17280, 33, 33, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 33, 17280, 8640, 33, 33, 8640, 17280, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 33, 17280, 8640, 8640, 33, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 33, 17280, 8640, 8640, 8640, 17280, 17280, 33, 33, 8640, 33, 17280, 33, 33, 17280, 33, 8640, 8640, 33, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 33, 33, 17280, 8640, 17280, 33, 8640, 17280, 33, 17280, 8640, 33, 17280, 33, 33, 17280, 33, 33, 8640]
Prompts retrieved: 830496 . Total input tokens: 185017985 . Total output tokens: 166201334
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.768436799000483,
    "estimated_duration": 3600.0277303172847,
    "input_throughput": 6400.641530049874,
    "output_throughput": 5633.44605076489,
    "total_throughput": 12034.087580814765,
    "itl": 152.53349103380566,
    "ttft": 1704157.6497078897,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 66,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20199219109956157,
    "arrivals": 276581,
    "finished_requests": 92721,
    "scheduler_time": 102.92696076853717
}
#Debug simulation 
Total elapsed time: 6.768561962991953. Arrivals time: 0.3230019354377873 Scheduler time: 6.34649156749947 Scheduler overhead time: 0.03757830482209101 Adapter cache time: 0.0063796608010306954 Engine time: 0.03775747324107215 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-16/adapters_96_slots_64_rate_1.6-0.8-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-16/adapters_96_slots_64_rate_1.6-0.8-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 33, 17280, 33, 33, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 33, 17280, 8640, 33, 33, 8640, 17280, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 33, 17280, 8640, 8640, 33, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 33, 17280, 8640, 8640, 8640, 17280, 17280, 33, 33, 8640, 33, 17280, 33, 33, 17280, 33, 8640, 8640, 33, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 33, 33, 17280, 8640, 17280, 33, 8640, 17280, 33, 17280, 8640, 33, 17280, 33, 33, 17280, 33, 33, 8640]
Prompts retrieved: 830496 . Total input tokens: 185017985 . Total output tokens: 166201334
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.772884840029292,
    "estimated_duration": 3600.0984259506827,
    "input_throughput": 6400.515839762114,
    "output_throughput": 5633.335426001439,
    "total_throughput": 12033.851265763553,
    "itl": 152.53399173624692,
    "ttft": 1704206.8738804564,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 66,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21246134624583649,
    "arrivals": 276581,
    "finished_requests": 92721,
    "scheduler_time": 102.9290823000471
}
#Debug simulation 
Total elapsed time: 6.77304748701863. Arrivals time: 0.3004005658440292 Scheduler time: 6.373492670652922 Scheduler overhead time: 0.037551097688265145 Adapter cache time: 0.00637430656934157 Engine time: 0.03773760161129758 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-32/adapters_96_slots_64_rate_1.6-0.8-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-32/adapters_96_slots_64_rate_1.6-0.8-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 33, 17280, 33, 33, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 33, 17280, 8640, 33, 33, 8640, 17280, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 33, 17280, 8640, 8640, 33, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 33, 17280, 8640, 8640, 8640, 17280, 17280, 33, 33, 8640, 33, 17280, 33, 33, 17280, 33, 8640, 8640, 33, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 33, 33, 17280, 8640, 17280, 33, 8640, 17280, 33, 17280, 8640, 33, 17280, 33, 33, 17280, 33, 33, 8640]
Prompts retrieved: 830496 . Total input tokens: 185017985 . Total output tokens: 166201334
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.753589743049815,
    "estimated_duration": 3600.1173401907404,
    "input_throughput": 6400.5758208923135,
    "output_throughput": 5633.324995714028,
    "total_throughput": 12033.900816606341,
    "itl": 152.53454185124448,
    "ttft": 1704193.734300741,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 66,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21335040131583793,
    "arrivals": 276581,
    "finished_requests": 92722,
    "scheduler_time": 102.92971662651398
}
#Debug simulation 
Total elapsed time: 6.7536873950157315. Arrivals time: 0.29991843254538253 Scheduler time: 6.354752798797563 Scheduler overhead time: 0.037554277456365526 Adapter cache time: 0.006346627604216337 Engine time: 0.03775080916238949 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-16-16/adapters_96_slots_64_rate_1.6-0.8-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-16-16/adapters_96_slots_64_rate_1.6-0.8-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 33, 17280, 33, 33, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 33, 17280, 8640, 33, 33, 8640, 17280, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 33, 17280, 8640, 8640, 33, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 33, 17280, 8640, 8640, 8640, 17280, 17280, 33, 33, 8640, 33, 17280, 33, 33, 17280, 33, 8640, 8640, 33, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 33, 33, 17280, 8640, 17280, 33, 8640, 17280, 33, 17280, 8640, 33, 17280, 33, 33, 17280, 33, 33, 8640]
Prompts retrieved: 830496 . Total input tokens: 185017985 . Total output tokens: 166201334
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 6.784814121027011,
    "estimated_duration": 3600.05986312193,
    "input_throughput": 6400.584400287673,
    "output_throughput": 5633.395768706172,
    "total_throughput": 12033.980168993845,
    "itl": 152.5336820763413,
    "ttft": 1704201.7898448985,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 66,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20510663051391034,
    "arrivals": 276581,
    "finished_requests": 92721,
    "scheduler_time": 102.92801245472143
}
#Debug simulation 
Total elapsed time: 6.7849083589972. Arrivals time: 0.33052350184880197 Scheduler time: 6.354983088560402 Scheduler overhead time: 0.03773682314204052 Adapter cache time: 0.006334014993626624 Engine time: 0.03797026735264808 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-16-32/adapters_96_slots_64_rate_1.6-0.8-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-16-32/adapters_96_slots_64_rate_1.6-0.8-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 33, 17280, 33, 33, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 33, 17280, 8640, 33, 33, 8640, 17280, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 33, 17280, 8640, 8640, 33, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 33, 17280, 8640, 8640, 8640, 17280, 17280, 33, 33, 8640, 33, 17280, 33, 33, 17280, 33, 8640, 8640, 33, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 33, 33, 17280, 8640, 17280, 33, 8640, 17280, 33, 17280, 8640, 33, 17280, 33, 33, 17280, 33, 33, 8640]
Prompts retrieved: 830496 . Total input tokens: 185017985 . Total output tokens: 166201334
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 6.7821376489591785,
    "estimated_duration": 3600.127350702319,
    "input_throughput": 6400.558023455689,
    "output_throughput": 5633.309331694508,
    "total_throughput": 12033.867355150198,
    "itl": 152.53412237143638,
    "ttft": 1704195.3830298814,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 66,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21561396947130537,
    "arrivals": 276581,
    "finished_requests": 92722,
    "scheduler_time": 102.92994200479625
}
#Debug simulation 
Total elapsed time: 6.78228617500281. Arrivals time: 0.302175673248712 Scheduler time: 6.379359208629467 Scheduler overhead time: 0.03755515144439414 Adapter cache time: 0.006480836775153875 Engine time: 0.038817224209196866 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_16-16-16/adapters_96_slots_64_rate_1.6-0.8-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_16-16-16/adapters_96_slots_64_rate_1.6-0.8-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 33, 17280, 33, 33, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 33, 17280, 8640, 33, 33, 8640, 17280, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 33, 17280, 8640, 8640, 33, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 33, 17280, 8640, 8640, 8640, 17280, 17280, 33, 33, 8640, 33, 17280, 33, 33, 17280, 33, 8640, 8640, 33, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 33, 33, 17280, 8640, 17280, 33, 8640, 17280, 33, 17280, 8640, 33, 17280, 33, 33, 17280, 33, 33, 8640]
Prompts retrieved: 830496 . Total input tokens: 185017985 . Total output tokens: 166201334
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.80450489098439,
    "estimated_duration": 3600.153102889046,
    "input_throughput": 6400.57918134327,
    "output_throughput": 5633.385142349888,
    "total_throughput": 12033.964323693157,
    "itl": 152.53312723416497,
    "ttft": 1704183.3522435022,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 66,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.19734331946354378,
    "arrivals": 276581,
    "finished_requests": 92723,
    "scheduler_time": 102.93058911213107
}
#Debug simulation 
Total elapsed time: 6.804601321986411. Arrivals time: 0.2917774560628459 Scheduler time: 6.4133576604072005 Scheduler overhead time: 0.03774424543371424 Adapter cache time: 0.006377481622621417 Engine time: 0.03789717750623822 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_16-16-32/adapters_96_slots_64_rate_1.6-0.8-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_16-16-32/adapters_96_slots_64_rate_1.6-0.8-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 8640, 17280, 8640, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 33, 17280, 33, 33, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 33, 17280, 8640, 33, 33, 8640, 17280, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 33, 17280, 8640, 8640, 33, 17280, 17280, 8640, 17280, 17280, 8640, 17280, 33, 17280, 8640, 8640, 8640, 17280, 17280, 33, 33, 8640, 33, 17280, 33, 33, 17280, 33, 8640, 8640, 33, 8640, 17280, 17280, 17280, 8640, 17280, 17280, 33, 33, 17280, 8640, 17280, 33, 8640, 17280, 33, 17280, 8640, 33, 17280, 33, 33, 17280, 33, 33, 8640]
Prompts retrieved: 830496 . Total input tokens: 185017985 . Total output tokens: 166201334
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.795639741001651,
    "estimated_duration": 3600.129117121819,
    "input_throughput": 6400.554882993184,
    "output_throughput": 5633.306567686016,
    "total_throughput": 12033.8614506792,
    "itl": 152.53379193874562,
    "ttft": 1704195.159031898,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 66,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21800329141318767,
    "arrivals": 276581,
    "finished_requests": 92722,
    "scheduler_time": 102.9299550014557
}
#Debug simulation 
Total elapsed time: 6.795754778024275. Arrivals time: 0.3043034427682869 Scheduler time: 6.392173799627926 Scheduler overhead time: 0.03754023456713185 Adapter cache time: 0.0063918790547177196 Engine time: 0.03798575751716271 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-8-8/adapters_96_slots_64_rate_1.6-0.4-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-8-8/adapters_96_slots_64_rate_1.6-0.4-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 1080, 17280, 1080, 1080, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 1080, 17280, 4320, 1080, 1080, 4320, 17280, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 17280, 4320, 4320, 1080, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 1080, 17280, 4320, 4320, 4320, 17280, 17280, 1080, 1080, 4320, 1080, 17280, 1080, 1080, 17280, 1080, 4320, 4320, 1080, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 1080, 1080, 17280, 4320, 17280, 1080, 4320, 17280, 1080, 17280, 4320, 1080, 17280, 1080, 1080, 17280, 1080, 1080, 4320]
Prompts retrieved: 725760 . Total input tokens: 161758167 . Total output tokens: 145106966
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 11.936954187985975,
    "estimated_duration": 3600.0354976878775,
    "input_throughput": 6342.0169091842345,
    "output_throughput": 5636.323589873453,
    "total_throughput": 11978.340499057687,
    "itl": 152.9576172631342,
    "ttft": 1635315.6618148817,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 219,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6702468159212722,
    "arrivals": 241359,
    "finished_requests": 92652,
    "scheduler_time": 102.42007401363253
}
#Debug simulation 
Total elapsed time: 11.937152417027391. Arrivals time: 0.337265637004748 Scheduler time: 11.492538569378667 Scheduler overhead time: 0.03944692120421678 Adapter cache time: 0.00915928278118372 Engine time: 0.04062109981896356 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-8-16/adapters_96_slots_64_rate_1.6-0.4-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-8-16/adapters_96_slots_64_rate_1.6-0.4-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 1080, 17280, 1080, 1080, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 1080, 17280, 4320, 1080, 1080, 4320, 17280, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 17280, 4320, 4320, 1080, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 1080, 17280, 4320, 4320, 4320, 17280, 17280, 1080, 1080, 4320, 1080, 17280, 1080, 1080, 17280, 1080, 4320, 4320, 1080, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 1080, 1080, 17280, 4320, 17280, 1080, 4320, 17280, 1080, 17280, 4320, 1080, 17280, 1080, 1080, 17280, 1080, 1080, 4320]
Prompts retrieved: 725760 . Total input tokens: 161758167 . Total output tokens: 145106966
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 11.443129260034766,
    "estimated_duration": 3600.1331184707747,
    "input_throughput": 6342.597967516062,
    "output_throughput": 5636.408524976804,
    "total_throughput": 11979.006492492867,
    "itl": 152.94718829601112,
    "ttft": 1635197.7023500807,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 229,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7541827216674606,
    "arrivals": 241359,
    "finished_requests": 92652,
    "scheduler_time": 102.42135869209815
}
#Debug simulation 
Total elapsed time: 11.44322886300506. Arrivals time: 0.3277266562799923 Scheduler time: 11.009582204394974 Scheduler overhead time: 0.03911842912202701 Adapter cache time: 0.009204464440699667 Engine time: 0.03972884896211326 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-8-32/adapters_96_slots_64_rate_1.6-0.4-0.1_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-8-32/adapters_96_slots_64_rate_1.6-0.4-0.1_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 1080, 17280, 1080, 1080, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 1080, 17280, 4320, 1080, 1080, 4320, 17280, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 17280, 4320, 4320, 1080, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 1080, 17280, 4320, 4320, 4320, 17280, 17280, 1080, 1080, 4320, 1080, 17280, 1080, 1080, 17280, 1080, 4320, 4320, 1080, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 1080, 1080, 17280, 4320, 17280, 1080, 4320, 17280, 1080, 17280, 4320, 1080, 17280, 1080, 1080, 17280, 1080, 1080, 4320]
Prompts retrieved: 725760 . Total input tokens: 161758167 . Total output tokens: 145106966
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 11.476442151004449,
    "estimated_duration": 3600.1315048304714,
    "input_throughput": 6342.600810376579,
    "output_throughput": 5636.4110513111755,
    "total_throughput": 11979.011861687753,
    "itl": 152.9469822577533,
    "ttft": 1635196.240511524,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 229,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7542978904396331,
    "arrivals": 241359,
    "finished_requests": 92652,
    "scheduler_time": 102.42132197118602
}
#Debug simulation 
Total elapsed time: 11.476567162026186. Arrivals time: 0.3249876797199249 Scheduler time: 11.04511412390275 Scheduler overhead time: 0.03960995067609474 Adapter cache time: 0.00926757015986368 Engine time: 0.039905150479171425 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-16-16/adapters_96_slots_64_rate_1.6-0.4-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-16-16/adapters_96_slots_64_rate_1.6-0.4-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 1080, 17280, 1080, 1080, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 1080, 17280, 4320, 1080, 1080, 4320, 17280, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 17280, 4320, 4320, 1080, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 1080, 17280, 4320, 4320, 4320, 17280, 17280, 1080, 1080, 4320, 1080, 17280, 1080, 1080, 17280, 1080, 4320, 4320, 1080, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 1080, 1080, 17280, 4320, 17280, 1080, 4320, 17280, 1080, 17280, 4320, 1080, 17280, 1080, 1080, 17280, 1080, 1080, 4320]
Prompts retrieved: 725760 . Total input tokens: 161758167 . Total output tokens: 145106966
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 11.466108650958631,
    "estimated_duration": 3600.0630696066883,
    "input_throughput": 6342.657214195595,
    "output_throughput": 5636.4409755234865,
    "total_throughput": 11979.098189719081,
    "itl": 152.94558864585727,
    "ttft": 1635193.0494378568,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 229,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7182263336447086,
    "arrivals": 241359,
    "finished_requests": 92651,
    "scheduler_time": 102.42009096572747
}
#Debug simulation 
Total elapsed time: 11.466280991968233. Arrivals time: 0.329833822674118 Scheduler time: 11.030860610830132 Scheduler overhead time: 0.03901100705843419 Adapter cache time: 0.009145291929598898 Engine time: 0.0397073146305047 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-16-32/adapters_96_slots_64_rate_1.6-0.4-0.1_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-16-32/adapters_96_slots_64_rate_1.6-0.4-0.1_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 1080, 17280, 1080, 1080, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 1080, 17280, 4320, 1080, 1080, 4320, 17280, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 17280, 4320, 4320, 1080, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 1080, 17280, 4320, 4320, 4320, 17280, 17280, 1080, 1080, 4320, 1080, 17280, 1080, 1080, 17280, 1080, 4320, 4320, 1080, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 1080, 1080, 17280, 4320, 17280, 1080, 4320, 17280, 1080, 17280, 4320, 1080, 17280, 1080, 1080, 17280, 1080, 1080, 4320]
Prompts retrieved: 725760 . Total input tokens: 161758167 . Total output tokens: 145106966
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 11.500343872990925,
    "estimated_duration": 3600.086567463658,
    "input_throughput": 6342.414709234765,
    "output_throughput": 5636.364742833322,
    "total_throughput": 11978.779452068087,
    "itl": 152.94540811100973,
    "ttft": 1635284.8545066179,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 229,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7653642236441406,
    "arrivals": 241359,
    "finished_requests": 92653,
    "scheduler_time": 102.41983081868514
}
#Debug simulation 
Total elapsed time: 11.500490037025884. Arrivals time: 0.3329733299324289 Scheduler time: 11.060476644837763 Scheduler overhead time: 0.03966038057114929 Adapter cache time: 0.009310740744695067 Engine time: 0.04008889017859474 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_16-16-16/adapters_96_slots_64_rate_1.6-0.4-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_16-16-16/adapters_96_slots_64_rate_1.6-0.4-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 1080, 17280, 1080, 1080, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 1080, 17280, 4320, 1080, 1080, 4320, 17280, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 17280, 4320, 4320, 1080, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 1080, 17280, 4320, 4320, 4320, 17280, 17280, 1080, 1080, 4320, 1080, 17280, 1080, 1080, 17280, 1080, 4320, 4320, 1080, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 1080, 1080, 17280, 4320, 17280, 1080, 4320, 17280, 1080, 17280, 4320, 1080, 17280, 1080, 1080, 17280, 1080, 1080, 4320]
Prompts retrieved: 725760 . Total input tokens: 161758167 . Total output tokens: 145106966
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 11.462180710979737,
    "estimated_duration": 3600.0413991508217,
    "input_throughput": 6342.509840410702,
    "output_throughput": 5636.581569530413,
    "total_throughput": 11979.091409941115,
    "itl": 152.9417674430208,
    "ttft": 1635248.6766207435,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 229,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6847215175325991,
    "arrivals": 241359,
    "finished_requests": 92654,
    "scheduler_time": 102.41999044925115
}
#Debug simulation 
Total elapsed time: 11.462280240026303. Arrivals time: 0.324514253414236 Scheduler time: 11.031940485467203 Scheduler overhead time: 0.03910800733137876 Adapter cache time: 0.009077451191842556 Engine time: 0.03977426904020831 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_16-16-32/adapters_96_slots_64_rate_1.6-0.4-0.1_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_16-16-32/adapters_96_slots_64_rate_1.6-0.4-0.1_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 1080, 17280, 1080, 1080, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 1080, 17280, 4320, 1080, 1080, 4320, 17280, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 17280, 4320, 4320, 1080, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 1080, 17280, 4320, 4320, 4320, 17280, 17280, 1080, 1080, 4320, 1080, 17280, 1080, 1080, 17280, 1080, 4320, 4320, 1080, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 1080, 1080, 17280, 4320, 17280, 1080, 4320, 17280, 1080, 17280, 4320, 1080, 17280, 1080, 1080, 17280, 1080, 1080, 4320]
Prompts retrieved: 725760 . Total input tokens: 161758167 . Total output tokens: 145106966
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 11.458246450987644,
    "estimated_duration": 3600.100094556438,
    "input_throughput": 6342.390878110639,
    "output_throughput": 5636.34356463638,
    "total_throughput": 11978.734442747018,
    "itl": 152.94545454691053,
    "ttft": 1635288.9178697213,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 229,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.775676034130159,
    "arrivals": 241359,
    "finished_requests": 92653,
    "scheduler_time": 102.41995687245385
}
#Debug simulation 
Total elapsed time: 11.458413759013638. Arrivals time: 0.3327855245443061 Scheduler time: 11.019214579893742 Scheduler overhead time: 0.03937055420828983 Adapter cache time: 0.009153329534456134 Engine time: 0.039818396675400436 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-8-8/adapters_96_slots_64_rate_1.6-0.4-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-8-8/adapters_96_slots_64_rate_1.6-0.4-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 540, 17280, 540, 540, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 540, 17280, 4320, 540, 540, 4320, 17280, 540, 4320, 540, 540, 4320, 4320, 4320, 540, 540, 17280, 4320, 4320, 540, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 540, 17280, 4320, 4320, 4320, 17280, 17280, 540, 540, 4320, 540, 17280, 540, 540, 17280, 540, 4320, 4320, 540, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 540, 540, 17280, 4320, 17280, 540, 4320, 17280, 540, 17280, 4320, 540, 17280, 540, 540, 17280, 540, 540, 4320]
Prompts retrieved: 708480 . Total input tokens: 157970588 . Total output tokens: 141629128
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 8.969106946024112,
    "estimated_duration": 3600.1460000098737,
    "input_throughput": 6351.262143240105,
    "output_throughput": 5635.18701739995,
    "total_throughput": 11986.449160640055,
    "itl": 152.97230239239286,
    "ttft": 1619111.5148705808,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 272,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8324526663497079,
    "arrivals": 235577,
    "finished_requests": 92697,
    "scheduler_time": 102.33201642199528
}
#Debug simulation 
Total elapsed time: 8.96923222701298. Arrivals time: 0.3118269629776478 Scheduler time: 8.553707772982307 Scheduler overhead time: 0.03831665974576026 Adapter cache time: 0.009263325424399227 Engine time: 0.03860530204838142 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-8-16/adapters_96_slots_64_rate_1.6-0.4-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-8-16/adapters_96_slots_64_rate_1.6-0.4-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 540, 17280, 540, 540, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 540, 17280, 4320, 540, 540, 4320, 17280, 540, 4320, 540, 540, 4320, 4320, 4320, 540, 540, 17280, 4320, 4320, 540, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 540, 17280, 4320, 4320, 4320, 17280, 17280, 540, 540, 4320, 540, 17280, 540, 540, 17280, 540, 4320, 4320, 540, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 540, 540, 17280, 4320, 17280, 540, 4320, 17280, 540, 17280, 4320, 540, 17280, 540, 540, 17280, 540, 540, 4320]
Prompts retrieved: 708480 . Total input tokens: 157970588 . Total output tokens: 141629128
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 8.970511570980307,
    "estimated_duration": 3600.081679596636,
    "input_throughput": 6351.16673312863,
    "output_throughput": 5635.1540896908255,
    "total_throughput": 11986.320822819456,
    "itl": 152.97454775375562,
    "ttft": 1619114.7632274104,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 272,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8962385298567875,
    "arrivals": 235577,
    "finished_requests": 92692,
    "scheduler_time": 102.3285717518154
}
#Debug simulation 
Total elapsed time: 8.970610063988715. Arrivals time: 0.3113029004307464 Scheduler time: 8.55554490844952 Scheduler overhead time: 0.03830931952688843 Adapter cache time: 0.009407908888533711 Engine time: 0.038517710694577545 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-8-32/adapters_96_slots_64_rate_1.6-0.4-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-8-32/adapters_96_slots_64_rate_1.6-0.4-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 540, 17280, 540, 540, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 540, 17280, 4320, 540, 540, 4320, 17280, 540, 4320, 540, 540, 4320, 4320, 4320, 540, 540, 17280, 4320, 4320, 540, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 540, 17280, 4320, 4320, 4320, 17280, 17280, 540, 540, 4320, 540, 17280, 540, 540, 17280, 540, 4320, 4320, 540, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 540, 540, 17280, 4320, 17280, 540, 4320, 17280, 540, 17280, 4320, 540, 17280, 540, 540, 17280, 540, 540, 4320]
Prompts retrieved: 708480 . Total input tokens: 157970588 . Total output tokens: 141629128
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 8.941626954008825,
    "estimated_duration": 3600.0834979910796,
    "input_throughput": 6351.163525167953,
    "output_throughput": 5635.151243386596,
    "total_throughput": 11986.31476855455,
    "itl": 152.97433856362682,
    "ttft": 1619115.1284375656,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 272,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8962983682565437,
    "arrivals": 235577,
    "finished_requests": 92692,
    "scheduler_time": 102.32863951410202
}
#Debug simulation 
Total elapsed time: 8.941807914001402. Arrivals time: 0.307942823972553 Scheduler time: 8.530046586180106 Scheduler overhead time: 0.038151892833411694 Adapter cache time: 0.009581951540894806 Engine time: 0.03846990322927013 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-16-16/adapters_96_slots_64_rate_1.6-0.4-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-16-16/adapters_96_slots_64_rate_1.6-0.4-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 540, 17280, 540, 540, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 540, 17280, 4320, 540, 540, 4320, 17280, 540, 4320, 540, 540, 4320, 4320, 4320, 540, 540, 17280, 4320, 4320, 540, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 540, 17280, 4320, 4320, 4320, 17280, 17280, 540, 540, 4320, 540, 17280, 540, 540, 17280, 540, 4320, 4320, 540, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 540, 540, 17280, 4320, 17280, 540, 4320, 17280, 540, 17280, 4320, 540, 17280, 540, 540, 17280, 540, 540, 4320]
Prompts retrieved: 708480 . Total input tokens: 157970588 . Total output tokens: 141629128
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 8.980101974972058,
    "estimated_duration": 3600.0303408882514,
    "input_throughput": 6351.257304781072,
    "output_throughput": 5635.2344505503515,
    "total_throughput": 11986.491755331424,
    "itl": 152.97337728308779,
    "ttft": 1619079.3764727463,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 272,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8541532120574296,
    "arrivals": 235577,
    "finished_requests": 92692,
    "scheduler_time": 102.32818351338662
}
#Debug simulation 
Total elapsed time: 8.980199668963905. Arrivals time: 0.31000660464633256 Scheduler time: 8.565766635525506 Scheduler overhead time: 0.03836410224903375 Adapter cache time: 0.009482498629949987 Engine time: 0.03890133195091039 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-16-32/adapters_96_slots_64_rate_1.6-0.4-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-16-32/adapters_96_slots_64_rate_1.6-0.4-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 540, 17280, 540, 540, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 540, 17280, 4320, 540, 540, 4320, 17280, 540, 4320, 540, 540, 4320, 4320, 4320, 540, 540, 17280, 4320, 4320, 540, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 540, 17280, 4320, 4320, 4320, 17280, 17280, 540, 540, 4320, 540, 17280, 540, 540, 17280, 540, 4320, 4320, 540, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 540, 540, 17280, 4320, 17280, 540, 4320, 17280, 540, 17280, 4320, 540, 17280, 540, 540, 17280, 540, 540, 4320]
Prompts retrieved: 708480 . Total input tokens: 157970588 . Total output tokens: 141629128
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 8.96093138604192,
    "estimated_duration": 3600.10734125647,
    "input_throughput": 6351.156183032021,
    "output_throughput": 5635.133088259425,
    "total_throughput": 11986.289271291445,
    "itl": 152.97436285963286,
    "ttft": 1619111.3559171476,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 272,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9092510082572746,
    "arrivals": 235577,
    "finished_requests": 92694,
    "scheduler_time": 102.32905469639192
}
#Debug simulation 
Total elapsed time: 8.961048705037683. Arrivals time: 0.3162082392955199 Scheduler time: 8.54106803855393 Scheduler overhead time: 0.03827045240905136 Adapter cache time: 0.00943993718829006 Engine time: 0.038427150109782815 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_16-16-16/adapters_96_slots_64_rate_1.6-0.4-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_16-16-16/adapters_96_slots_64_rate_1.6-0.4-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 540, 17280, 540, 540, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 540, 17280, 4320, 540, 540, 4320, 17280, 540, 4320, 540, 540, 4320, 4320, 4320, 540, 540, 17280, 4320, 4320, 540, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 540, 17280, 4320, 4320, 4320, 17280, 17280, 540, 540, 4320, 540, 17280, 540, 540, 17280, 540, 4320, 4320, 540, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 540, 540, 17280, 4320, 17280, 540, 4320, 17280, 540, 17280, 4320, 540, 17280, 540, 540, 17280, 540, 540, 4320]
Prompts retrieved: 708480 . Total input tokens: 157970588 . Total output tokens: 141629128
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 9.232183354964945,
    "estimated_duration": 3600.110318012652,
    "input_throughput": 6351.231206887601,
    "output_throughput": 5635.2228703922465,
    "total_throughput": 11986.454077279846,
    "itl": 152.9715748434197,
    "ttft": 1619082.7913219845,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 272,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8132936802133929,
    "arrivals": 235577,
    "finished_requests": 92696,
    "scheduler_time": 102.33140613742084
}
#Debug simulation 
Total elapsed time: 9.232344652002212. Arrivals time: 0.31475865870015696 Scheduler time: 8.812882443424314 Scheduler overhead time: 0.038254945597145706 Adapter cache time: 0.009447629330679774 Engine time: 0.03935472120065242 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_16-16-32/adapters_96_slots_64_rate_1.6-0.4-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_16-16-32/adapters_96_slots_64_rate_1.6-0.4-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 540, 17280, 540, 540, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 540, 17280, 4320, 540, 540, 4320, 17280, 540, 4320, 540, 540, 4320, 4320, 4320, 540, 540, 17280, 4320, 4320, 540, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 540, 17280, 4320, 4320, 4320, 17280, 17280, 540, 540, 4320, 540, 17280, 540, 540, 17280, 540, 4320, 4320, 540, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 540, 540, 17280, 4320, 17280, 540, 4320, 17280, 540, 17280, 4320, 540, 17280, 540, 540, 17280, 540, 540, 4320]
Prompts retrieved: 708480 . Total input tokens: 157970588 . Total output tokens: 141629128
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 8.98269634594908,
    "estimated_duration": 3600.138786348938,
    "input_throughput": 6351.100709422445,
    "output_throughput": 5635.083868689973,
    "total_throughput": 11986.184578112418,
    "itl": 152.97509771518565,
    "ttft": 1619112.9769447134,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 272,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9218263868987608,
    "arrivals": 235577,
    "finished_requests": 92694,
    "scheduler_time": 102.32972623614012
}
#Debug simulation 
Total elapsed time: 8.982798789977096. Arrivals time: 0.3184749008505605 Scheduler time: 8.559939151571598 Scheduler overhead time: 0.03853110806085169 Adapter cache time: 0.009469456563238055 Engine time: 0.03876807074993849 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-8-8/adapters_96_slots_64_rate_1.6-0.4-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-8-8/adapters_96_slots_64_rate_1.6-0.4-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 270, 17280, 270, 270, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 270, 17280, 4320, 270, 270, 4320, 17280, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 270, 17280, 4320, 4320, 270, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 270, 17280, 4320, 4320, 4320, 17280, 17280, 270, 270, 4320, 270, 17280, 270, 270, 17280, 270, 4320, 4320, 270, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 270, 270, 17280, 4320, 17280, 270, 4320, 17280, 270, 17280, 4320, 270, 17280, 270, 270, 17280, 270, 270, 4320]
Prompts retrieved: 699840 . Total input tokens: 156062165 . Total output tokens: 139886480
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 8.18861851701513,
    "estimated_duration": 3600.0659635657803,
    "input_throughput": 6396.771123935329,
    "output_throughput": 5630.880157518424,
    "total_throughput": 12027.651281453755,
    "itl": 152.47491370501783,
    "ttft": 1616075.6654579164,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 257,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7865453501907167,
    "arrivals": 232682,
    "finished_requests": 92899,
    "scheduler_time": 102.31992142002082
}
#Debug simulation 
Total elapsed time: 8.188743397011422. Arrivals time: 0.32969346281606704 Scheduler time: 7.755345892277546 Scheduler overhead time: 0.0382315045571886 Adapter cache time: 0.009235889068804681 Engine time: 0.03873974864836782 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-8-16/adapters_96_slots_64_rate_1.6-0.4-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-8-16/adapters_96_slots_64_rate_1.6-0.4-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 270, 17280, 270, 270, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 270, 17280, 4320, 270, 270, 4320, 17280, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 270, 17280, 4320, 4320, 270, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 270, 17280, 4320, 4320, 4320, 17280, 17280, 270, 270, 4320, 270, 17280, 270, 270, 17280, 270, 4320, 4320, 270, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 270, 270, 17280, 4320, 17280, 270, 4320, 17280, 270, 17280, 4320, 270, 17280, 270, 270, 17280, 270, 270, 4320]
Prompts retrieved: 699840 . Total input tokens: 156062165 . Total output tokens: 139886480
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 8.194392956036609,
    "estimated_duration": 3600.010825252371,
    "input_throughput": 6396.668542902414,
    "output_throughput": 5630.794734784985,
    "total_throughput": 12027.463277687399,
    "itl": 152.47698550403663,
    "ttft": 1616085.908047102,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 257,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.847710417567291,
    "arrivals": 232682,
    "finished_requests": 92896,
    "scheduler_time": 102.31689269323182
}
#Debug simulation 
Total elapsed time: 8.194545010046568. Arrivals time: 0.3064144701929763 Scheduler time: 7.7845474517089315 Scheduler overhead time: 0.03835845732828602 Adapter cache time: 0.00911865703528747 Engine time: 0.03844059881521389 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-8-32/adapters_96_slots_64_rate_1.6-0.4-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-8-32/adapters_96_slots_64_rate_1.6-0.4-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 270, 17280, 270, 270, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 270, 17280, 4320, 270, 270, 4320, 17280, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 270, 17280, 4320, 4320, 270, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 270, 17280, 4320, 4320, 4320, 17280, 17280, 270, 270, 4320, 270, 17280, 270, 270, 17280, 270, 4320, 4320, 270, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 270, 270, 17280, 4320, 17280, 270, 4320, 17280, 270, 17280, 4320, 270, 17280, 270, 270, 17280, 270, 270, 4320]
Prompts retrieved: 699840 . Total input tokens: 156062165 . Total output tokens: 139886480
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 8.20751905196812,
    "estimated_duration": 3600.0108643752806,
    "input_throughput": 6396.668473386989,
    "output_throughput": 5630.79467359265,
    "total_throughput": 12027.463146979639,
    "itl": 152.4769526638782,
    "ttft": 1616086.2818174292,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 257,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8476103580743117,
    "arrivals": 232682,
    "finished_requests": 92896,
    "scheduler_time": 102.31690652078754
}
#Debug simulation 
Total elapsed time: 8.20763389597414. Arrivals time: 0.3095960589707829 Scheduler time: 7.794511412794236 Scheduler overhead time: 0.03827053389977664 Adapter cache time: 0.009101678791921586 Engine time: 0.03863015992101282 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-16-16/adapters_96_slots_64_rate_1.6-0.4-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-16-16/adapters_96_slots_64_rate_1.6-0.4-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 270, 17280, 270, 270, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 270, 17280, 4320, 270, 270, 4320, 17280, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 270, 17280, 4320, 4320, 270, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 270, 17280, 4320, 4320, 4320, 17280, 17280, 270, 270, 4320, 270, 17280, 270, 270, 17280, 270, 4320, 4320, 270, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 270, 270, 17280, 4320, 17280, 270, 4320, 17280, 270, 17280, 4320, 270, 17280, 270, 270, 17280, 270, 270, 4320]
Prompts retrieved: 699840 . Total input tokens: 156062165 . Total output tokens: 139886480
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 8.436020463996101,
    "estimated_duration": 3600.099025192543,
    "input_throughput": 6396.598493222941,
    "output_throughput": 5630.82733506638,
    "total_throughput": 12027.42582828932,
    "itl": 152.475690635827,
    "ttft": 1616086.7093709072,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 257,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8084852669970157,
    "arrivals": 232682,
    "finished_requests": 92899,
    "scheduler_time": 102.32034393082664
}
#Debug simulation 
Total elapsed time: 8.43609147198731. Arrivals time: 0.5508759104995988 Scheduler time: 7.781944077811204 Scheduler overhead time: 0.03819877305068076 Adapter cache time: 0.00922174210427329 Engine time: 0.038346525048837066 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-16-32/adapters_96_slots_64_rate_1.6-0.4-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-16-32/adapters_96_slots_64_rate_1.6-0.4-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 270, 17280, 270, 270, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 270, 17280, 4320, 270, 270, 4320, 17280, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 270, 17280, 4320, 4320, 270, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 270, 17280, 4320, 4320, 4320, 17280, 17280, 270, 270, 4320, 270, 17280, 270, 270, 17280, 270, 4320, 4320, 270, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 270, 270, 17280, 4320, 17280, 270, 4320, 17280, 270, 17280, 4320, 270, 17280, 270, 270, 17280, 270, 270, 4320]
Prompts retrieved: 699840 . Total input tokens: 156062165 . Total output tokens: 139886480
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 8.246618496021256,
    "estimated_duration": 3600.0238162148676,
    "input_throughput": 6396.6454600325815,
    "output_throughput": 5630.774415629624,
    "total_throughput": 12027.419875662205,
    "itl": 152.47713076318007,
    "ttft": 1616092.1982159005,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 257,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8596827215701384,
    "arrivals": 232682,
    "finished_requests": 92896,
    "scheduler_time": 102.3169581912063
}
#Debug simulation 
Total elapsed time: 8.246764776995406. Arrivals time: 0.313266645593103 Scheduler time: 7.827045711688697 Scheduler overhead time: 0.040629843540955335 Adapter cache time: 0.009148632758297026 Engine time: 0.03895876882597804 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_16-16-16/adapters_96_slots_64_rate_1.6-0.4-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_16-16-16/adapters_96_slots_64_rate_1.6-0.4-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 270, 17280, 270, 270, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 270, 17280, 4320, 270, 270, 4320, 17280, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 270, 17280, 4320, 4320, 270, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 270, 17280, 4320, 4320, 4320, 17280, 17280, 270, 270, 4320, 270, 17280, 270, 270, 17280, 270, 4320, 4320, 270, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 270, 270, 17280, 4320, 17280, 270, 4320, 17280, 270, 17280, 4320, 270, 17280, 270, 270, 17280, 270, 270, 4320]
Prompts retrieved: 699840 . Total input tokens: 156062165 . Total output tokens: 139886480
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 8.208217338018585,
    "estimated_duration": 3600.02356415509,
    "input_throughput": 6396.732296224473,
    "output_throughput": 5630.898142400799,
    "total_throughput": 12027.630438625272,
    "itl": 152.4744361921424,
    "ttft": 1616067.3208509092,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 257,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7684429257898602,
    "arrivals": 232682,
    "finished_requests": 92898,
    "scheduler_time": 102.31907153077894
}
#Debug simulation 
Total elapsed time: 8.208334692986682. Arrivals time: 0.32593393995193765 Scheduler time: 7.778076274029445 Scheduler overhead time: 0.03818809305084869 Adapter cache time: 0.009160278248600662 Engine time: 0.039333792461548 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_16-16-32/adapters_96_slots_64_rate_1.6-0.4-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_16-16-32/adapters_96_slots_64_rate_1.6-0.4-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 270, 17280, 270, 270, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 270, 17280, 4320, 270, 270, 4320, 17280, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 270, 17280, 4320, 4320, 270, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 270, 17280, 4320, 4320, 4320, 17280, 17280, 270, 270, 4320, 270, 17280, 270, 270, 17280, 270, 4320, 4320, 270, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 270, 270, 17280, 4320, 17280, 270, 4320, 17280, 270, 17280, 4320, 270, 17280, 270, 270, 17280, 270, 270, 4320]
Prompts retrieved: 699840 . Total input tokens: 156062165 . Total output tokens: 139886480
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 8.189563698018901,
    "estimated_duration": 3600.070201668819,
    "input_throughput": 6396.649429037564,
    "output_throughput": 5630.825196298442,
    "total_throughput": 12027.474625336006,
    "itl": 152.47838609464696,
    "ttft": 1616067.340499675,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 257,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8720065926387947,
    "arrivals": 232682,
    "finished_requests": 92898,
    "scheduler_time": 102.31817895359487
}
#Debug simulation 
Total elapsed time: 8.18966036598431. Arrivals time: 0.3062177547835745 Scheduler time: 7.780386684928089 Scheduler overhead time: 0.03815296199172735 Adapter cache time: 0.009127580153290182 Engine time: 0.03826001629931852 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-8/adapters_96_slots_64_rate_1.6-0.4-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-8/adapters_96_slots_64_rate_1.6-0.4-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 135, 17280, 135, 135, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 135, 17280, 4320, 135, 135, 4320, 17280, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 135, 17280, 4320, 4320, 135, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 135, 17280, 4320, 4320, 4320, 17280, 17280, 135, 135, 4320, 135, 17280, 135, 135, 17280, 135, 4320, 4320, 135, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 135, 135, 17280, 4320, 17280, 135, 4320, 17280, 135, 17280, 4320, 135, 17280, 135, 135, 17280, 135, 135, 4320]
Prompts retrieved: 695520 . Total input tokens: 155117441 . Total output tokens: 139015307
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 7.592605896992609,
    "estimated_duration": 3600.1141648532343,
    "input_throughput": 6363.441255184177,
    "output_throughput": 5634.782418303391,
    "total_throughput": 11998.223673487568,
    "itl": 152.9455898269745,
    "ttft": 1614900.1057325234,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 216,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.661065352689474,
    "arrivals": 231202,
    "finished_requests": 92473,
    "scheduler_time": 102.24301050976908
}
#Debug simulation 
Total elapsed time: 7.592769318958744. Arrivals time: 0.3083374121924862 Scheduler time: 7.182678184355609 Scheduler overhead time: 0.03777363937115297 Adapter cache time: 0.00850463891401887 Engine time: 0.037997131468728185 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-16/adapters_96_slots_64_rate_1.6-0.4-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-16/adapters_96_slots_64_rate_1.6-0.4-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 135, 17280, 135, 135, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 135, 17280, 4320, 135, 135, 4320, 17280, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 135, 17280, 4320, 4320, 135, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 135, 17280, 4320, 4320, 4320, 17280, 17280, 135, 135, 4320, 135, 17280, 135, 135, 17280, 135, 4320, 4320, 135, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 135, 135, 17280, 4320, 17280, 135, 4320, 17280, 135, 17280, 4320, 135, 17280, 135, 135, 17280, 135, 135, 4320]
Prompts retrieved: 695520 . Total input tokens: 155117441 . Total output tokens: 139015307
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.614426977001131,
    "estimated_duration": 3600.015479383922,
    "input_throughput": 6361.470980096775,
    "output_throughput": 5634.586605575192,
    "total_throughput": 11996.057585671968,
    "itl": 152.96363664896026,
    "ttft": 1614733.859554208,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 206,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6796912304265449,
    "arrivals": 231202,
    "finished_requests": 92459,
    "scheduler_time": 102.23957866761188
}
#Debug simulation 
Total elapsed time: 7.61454615497496. Arrivals time: 0.3061604768736288 Scheduler time: 7.206668141996488 Scheduler overhead time: 0.037649540114216506 Adapter cache time: 0.008331813849508762 Engine time: 0.03837262117303908 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-32/adapters_96_slots_64_rate_1.6-0.4-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-32/adapters_96_slots_64_rate_1.6-0.4-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 135, 17280, 135, 135, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 135, 17280, 4320, 135, 135, 4320, 17280, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 135, 17280, 4320, 4320, 135, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 135, 17280, 4320, 4320, 4320, 17280, 17280, 135, 135, 4320, 135, 17280, 135, 135, 17280, 135, 4320, 4320, 135, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 135, 135, 17280, 4320, 17280, 135, 4320, 17280, 135, 17280, 4320, 135, 17280, 135, 135, 17280, 135, 135, 4320]
Prompts retrieved: 695520 . Total input tokens: 155117441 . Total output tokens: 139015307
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.5710486940224655,
    "estimated_duration": 3600.077574981236,
    "input_throughput": 6363.4578763540685,
    "output_throughput": 5634.762467613141,
    "total_throughput": 11998.220343967208,
    "itl": 152.94727043815058,
    "ttft": 1614910.358946003,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 216,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7130459079332683,
    "arrivals": 231202,
    "finished_requests": 92472,
    "scheduler_time": 102.24089271990566
}
#Debug simulation 
Total elapsed time: 7.571146160014905. Arrivals time: 0.29932943149469793 Scheduler time: 7.170126546348911 Scheduler overhead time: 0.03770084766438231 Adapter cache time: 0.008516484987922013 Engine time: 0.03810036985669285 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-16-16/adapters_96_slots_64_rate_1.6-0.4-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-16-16/adapters_96_slots_64_rate_1.6-0.4-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 135, 17280, 135, 135, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 135, 17280, 4320, 135, 135, 4320, 17280, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 135, 17280, 4320, 4320, 135, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 135, 17280, 4320, 4320, 4320, 17280, 17280, 135, 135, 4320, 135, 17280, 135, 135, 17280, 135, 4320, 4320, 135, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 135, 135, 17280, 4320, 17280, 135, 4320, 17280, 135, 17280, 4320, 135, 17280, 135, 135, 17280, 135, 135, 4320]
Prompts retrieved: 695520 . Total input tokens: 155117441 . Total output tokens: 139015307
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 7.557679240999278,
    "estimated_duration": 3600.130708000686,
    "input_throughput": 6363.412014205023,
    "output_throughput": 5634.756525622273,
    "total_throughput": 11998.168539827297,
    "itl": 152.94590917009455,
    "ttft": 1614906.0190133296,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 216,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6777212985372187,
    "arrivals": 231202,
    "finished_requests": 92473,
    "scheduler_time": 102.24306029333842
}
#Debug simulation 
Total elapsed time: 7.557860033004545. Arrivals time: 0.3018627926358022 Scheduler time: 7.154057235806249 Scheduler overhead time: 0.0376630348036997 Adapter cache time: 0.008488092746119946 Engine time: 0.03816287557128817 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-16-32/adapters_96_slots_64_rate_1.6-0.4-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-16-32/adapters_96_slots_64_rate_1.6-0.4-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 135, 17280, 135, 135, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 135, 17280, 4320, 135, 135, 4320, 17280, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 135, 17280, 4320, 4320, 135, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 135, 17280, 4320, 4320, 4320, 17280, 17280, 135, 135, 4320, 135, 17280, 135, 135, 17280, 135, 4320, 4320, 135, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 135, 135, 17280, 4320, 17280, 135, 4320, 17280, 135, 17280, 4320, 135, 17280, 135, 135, 17280, 135, 135, 4320]
Prompts retrieved: 695520 . Total input tokens: 155117441 . Total output tokens: 139015307
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 7.539456302009057,
    "estimated_duration": 3600.099765501018,
    "input_throughput": 6363.418652874975,
    "output_throughput": 5634.7277357123185,
    "total_throughput": 11998.146388587294,
    "itl": 152.94771060589972,
    "ttft": 1614914.8525781396,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 216,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7239864873513607,
    "arrivals": 231202,
    "finished_requests": 92472,
    "scheduler_time": 102.2412673377897
}
#Debug simulation 
Total elapsed time: 7.539553738024551. Arrivals time: 0.3007639091229066 Scheduler time: 7.137208343716338 Scheduler overhead time: 0.03754218708490953 Adapter cache time: 0.008502925164066255 Engine time: 0.03827073465799913 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_16-16-16/adapters_96_slots_64_rate_1.6-0.4-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_16-16-16/adapters_96_slots_64_rate_1.6-0.4-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 135, 17280, 135, 135, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 135, 17280, 4320, 135, 135, 4320, 17280, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 135, 17280, 4320, 4320, 135, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 135, 17280, 4320, 4320, 4320, 17280, 17280, 135, 135, 4320, 135, 17280, 135, 135, 17280, 135, 4320, 4320, 135, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 135, 135, 17280, 4320, 17280, 135, 4320, 17280, 135, 17280, 4320, 135, 17280, 135, 135, 17280, 135, 135, 4320]
Prompts retrieved: 695520 . Total input tokens: 155117441 . Total output tokens: 139015307
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 7.836985657981131,
    "estimated_duration": 3600.070798283509,
    "input_throughput": 6363.469854793645,
    "output_throughput": 5634.77307437177,
    "total_throughput": 11998.242929165415,
    "itl": 152.94452583748787,
    "ttft": 1614892.0148138916,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 216,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6458508636988708,
    "arrivals": 231202,
    "finished_requests": 92472,
    "scheduler_time": 102.24201465086263
}
#Debug simulation 
Total elapsed time: 7.837055818992667. Arrivals time: 0.3078671991825104 Scheduler time: 7.4273029253818095 Scheduler overhead time: 0.03778288123430684 Adapter cache time: 0.008576222811825573 Engine time: 0.038168549828696996 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_16-16-32/adapters_96_slots_64_rate_1.6-0.4-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_16-16-32/adapters_96_slots_64_rate_1.6-0.4-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 135, 17280, 135, 135, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 135, 17280, 4320, 135, 135, 4320, 17280, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 135, 17280, 4320, 4320, 135, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 135, 17280, 4320, 4320, 4320, 17280, 17280, 135, 135, 4320, 135, 17280, 135, 135, 17280, 135, 4320, 4320, 135, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 135, 135, 17280, 4320, 17280, 135, 4320, 17280, 135, 17280, 4320, 135, 17280, 135, 135, 17280, 135, 135, 4320]
Prompts retrieved: 695520 . Total input tokens: 155117441 . Total output tokens: 139015307
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.585352873022202,
    "estimated_duration": 3600.1086772389776,
    "input_throughput": 6363.402900817288,
    "output_throughput": 5634.713787461986,
    "total_throughput": 11998.116688279273,
    "itl": 152.94784087280047,
    "ttft": 1614917.4274796774,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 216,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7337952826917197,
    "arrivals": 231202,
    "finished_requests": 92472,
    "scheduler_time": 102.2412922732567
}
#Debug simulation 
Total elapsed time: 7.585540093015879. Arrivals time: 0.29941751330625266 Scheduler time: 7.183533085219096 Scheduler overhead time: 0.03790750994812697 Adapter cache time: 0.008675698307342827 Engine time: 0.03848110721446574 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-8/adapters_96_slots_64_rate_1.6-0.4-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-8/adapters_96_slots_64_rate_1.6-0.4-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 66, 17280, 66, 66, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 66, 17280, 4320, 66, 66, 4320, 17280, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 66, 17280, 4320, 4320, 66, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 66, 17280, 4320, 4320, 4320, 17280, 17280, 66, 66, 4320, 66, 17280, 66, 66, 17280, 66, 4320, 4320, 66, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 66, 66, 17280, 4320, 17280, 66, 4320, 17280, 66, 17280, 4320, 66, 17280, 66, 66, 17280, 66, 66, 4320]
Prompts retrieved: 693312 . Total input tokens: 154620069 . Total output tokens: 138577647
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.82699417101685,
    "estimated_duration": 3600.1001009331744,
    "input_throughput": 6339.935657367898,
    "output_throughput": 5638.243501823335,
    "total_throughput": 11978.179159191232,
    "itl": 153.2297174671995,
    "ttft": 1615716.366547195,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 250,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7651219359831875,
    "arrivals": 230450,
    "finished_requests": 92332,
    "scheduler_time": 102.27160927693046
}
#Debug simulation 
Total elapsed time: 6.827087387035135. Arrivals time: 0.30068700277479365 Scheduler time: 6.424823326407932 Scheduler overhead time: 0.03742134210187942 Adapter cache time: 0.008890475146472454 Engine time: 0.03799792507197708 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-16/adapters_96_slots_64_rate_1.6-0.4-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-16/adapters_96_slots_64_rate_1.6-0.4-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 66, 17280, 66, 66, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 66, 17280, 4320, 66, 66, 4320, 17280, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 66, 17280, 4320, 4320, 66, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 66, 17280, 4320, 4320, 4320, 17280, 17280, 66, 66, 4320, 66, 17280, 66, 66, 17280, 66, 4320, 4320, 66, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 66, 66, 17280, 4320, 17280, 66, 4320, 17280, 66, 17280, 4320, 66, 17280, 66, 66, 17280, 66, 66, 4320]
Prompts retrieved: 693312 . Total input tokens: 154620069 . Total output tokens: 138577647
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.062151612946764,
    "estimated_duration": 3600.0270620169044,
    "input_throughput": 6339.872897292356,
    "output_throughput": 5638.133450204795,
    "total_throughput": 11978.00634749715,
    "itl": 153.23146586364535,
    "ttft": 1615724.6706463553,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 250,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8222855170001316,
    "arrivals": 230450,
    "finished_requests": 92329,
    "scheduler_time": 102.26806148218773
}
#Debug simulation 
Total elapsed time: 7.062219939951319. Arrivals time: 0.543971729290206 Scheduler time: 6.417643863009289 Scheduler overhead time: 0.03727861517108977 Adapter cache time: 0.008794216613750905 Engine time: 0.037329296057578176 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-32/adapters_96_slots_64_rate_1.6-0.4-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-32/adapters_96_slots_64_rate_1.6-0.4-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 66, 17280, 66, 66, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 66, 17280, 4320, 66, 66, 4320, 17280, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 66, 17280, 4320, 4320, 66, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 66, 17280, 4320, 4320, 4320, 17280, 17280, 66, 66, 4320, 66, 17280, 66, 66, 17280, 66, 4320, 4320, 66, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 66, 66, 17280, 4320, 17280, 66, 4320, 17280, 66, 17280, 4320, 66, 17280, 66, 66, 17280, 66, 66, 4320]
Prompts retrieved: 693312 . Total input tokens: 154620069 . Total output tokens: 138577647
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.837453266954981,
    "estimated_duration": 3600.027755740299,
    "input_throughput": 6339.8716756022895,
    "output_throughput": 5638.132363739539,
    "total_throughput": 11978.004039341828,
    "itl": 153.23138141988312,
    "ttft": 1615725.1659644616,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 250,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8225960036926012,
    "arrivals": 230450,
    "finished_requests": 92329,
    "scheduler_time": 102.26809240533717
}
#Debug simulation 
Total elapsed time: 6.837606921966653. Arrivals time: 0.2997027200763114 Scheduler time: 6.436231455067173 Scheduler overhead time: 0.03741786675527692 Adapter cache time: 0.008871979778632522 Engine time: 0.0377986294333823 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-16-16/adapters_96_slots_64_rate_1.6-0.4-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-16-16/adapters_96_slots_64_rate_1.6-0.4-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 66, 17280, 66, 66, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 66, 17280, 4320, 66, 66, 4320, 17280, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 66, 17280, 4320, 4320, 66, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 66, 17280, 4320, 4320, 4320, 17280, 17280, 66, 66, 4320, 66, 17280, 66, 66, 17280, 66, 4320, 4320, 66, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 66, 66, 17280, 4320, 17280, 66, 4320, 17280, 66, 17280, 4320, 66, 17280, 66, 66, 17280, 66, 66, 4320]
Prompts retrieved: 693312 . Total input tokens: 154620069 . Total output tokens: 138577647
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 6.831196465995163,
    "estimated_duration": 3600.146713336633,
    "input_throughput": 6339.853571924638,
    "output_throughput": 5638.170501442563,
    "total_throughput": 11978.024073367202,
    "itl": 153.23083646267824,
    "ttft": 1615736.4405800903,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 250,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7838775570667373,
    "arrivals": 230450,
    "finished_requests": 92332,
    "scheduler_time": 102.27258150796472
}
#Debug simulation 
Total elapsed time: 6.831302713952027. Arrivals time: 0.2962637267773971 Scheduler time: 6.433732023520861 Scheduler overhead time: 0.037462230189703405 Adapter cache time: 0.008787859929725528 Engine time: 0.037719729472883046 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-16-32/adapters_96_slots_64_rate_1.6-0.4-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-16-32/adapters_96_slots_64_rate_1.6-0.4-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 66, 17280, 66, 66, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 66, 17280, 4320, 66, 66, 4320, 17280, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 66, 17280, 4320, 4320, 66, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 66, 17280, 4320, 4320, 4320, 17280, 17280, 66, 66, 4320, 66, 17280, 66, 66, 17280, 66, 4320, 4320, 66, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 66, 66, 17280, 4320, 17280, 66, 4320, 17280, 66, 17280, 4320, 66, 17280, 66, 66, 17280, 66, 66, 4320]
Prompts retrieved: 693312 . Total input tokens: 154620069 . Total output tokens: 138577647
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 6.810597653966397,
    "estimated_duration": 3600.038118012432,
    "input_throughput": 6339.853427052292,
    "output_throughput": 5638.116135060854,
    "total_throughput": 11977.969562113145,
    "itl": 153.23137202515093,
    "ttft": 1615728.2214348514,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 250,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.834416859615598,
    "arrivals": 230450,
    "finished_requests": 92329,
    "scheduler_time": 102.26806812509501
}
#Debug simulation 
Total elapsed time: 6.810717148007825. Arrivals time: 0.29768649575999007 Scheduler time: 6.4122685576439835 Scheduler overhead time: 0.03720712807262316 Adapter cache time: 0.008734873437788337 Engine time: 0.03756014246027917 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_16-16-16/adapters_96_slots_64_rate_1.6-0.4-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_16-16-16/adapters_96_slots_64_rate_1.6-0.4-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 66, 17280, 66, 66, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 66, 17280, 4320, 66, 66, 4320, 17280, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 66, 17280, 4320, 4320, 66, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 66, 17280, 4320, 4320, 4320, 17280, 17280, 66, 66, 4320, 66, 17280, 66, 66, 17280, 66, 4320, 4320, 66, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 66, 66, 17280, 4320, 17280, 66, 4320, 17280, 66, 17280, 4320, 66, 17280, 66, 66, 17280, 66, 66, 4320]
Prompts retrieved: 693312 . Total input tokens: 154620069 . Total output tokens: 138577647
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.823070407030173,
    "estimated_duration": 3600.0795022961006,
    "input_throughput": 6339.971932687261,
    "output_throughput": 5638.2757622585705,
    "total_throughput": 11978.24769494583,
    "itl": 153.22959818039212,
    "ttft": 1615708.932199431,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 250,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7475125737255449,
    "arrivals": 230450,
    "finished_requests": 92332,
    "scheduler_time": 102.2714651181456
}
#Debug simulation 
Total elapsed time: 6.823224037012551. Arrivals time: 0.29380220151506364 Scheduler time: 6.428033075935673 Scheduler overhead time: 0.03742276568664238 Adapter cache time: 0.008818018366582692 Engine time: 0.03773460374213755 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_16-16-32/adapters_96_slots_64_rate_1.6-0.4-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_16-16-32/adapters_96_slots_64_rate_1.6-0.4-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 66, 17280, 66, 66, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 66, 17280, 4320, 66, 66, 4320, 17280, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 66, 17280, 4320, 4320, 66, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 66, 17280, 4320, 4320, 4320, 17280, 17280, 66, 66, 4320, 66, 17280, 66, 66, 17280, 66, 4320, 4320, 66, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 66, 66, 17280, 4320, 17280, 66, 4320, 17280, 66, 17280, 4320, 66, 17280, 66, 66, 17280, 66, 66, 4320]
Prompts retrieved: 693312 . Total input tokens: 154620069 . Total output tokens: 138577647
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.815950569987763,
    "estimated_duration": 3600.0615458623556,
    "input_throughput": 6339.869390908643,
    "output_throughput": 5638.183331429097,
    "total_throughput": 11978.05272233774,
    "itl": 153.2319455167312,
    "ttft": 1615754.6989641667,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 250,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8456089466065205,
    "arrivals": 230450,
    "finished_requests": 92330,
    "scheduler_time": 102.26849323542211
}
#Debug simulation 
Total elapsed time: 6.816058893979061. Arrivals time: 0.2987964249914512 Scheduler time: 6.416431047779042 Scheduler overhead time: 0.03731418907409534 Adapter cache time: 0.008861982671078295 Engine time: 0.03738647332647815 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-8/adapters_96_slots_64_rate_1.6-0.4-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-8/adapters_96_slots_64_rate_1.6-0.4-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 33, 17280, 33, 33, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 33, 17280, 4320, 33, 33, 4320, 17280, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 33, 17280, 4320, 4320, 33, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 33, 17280, 4320, 4320, 4320, 17280, 17280, 33, 33, 4320, 33, 17280, 33, 33, 17280, 33, 4320, 4320, 33, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 33, 33, 17280, 4320, 17280, 33, 4320, 17280, 33, 17280, 4320, 33, 17280, 33, 33, 17280, 33, 33, 4320]
Prompts retrieved: 692256 . Total input tokens: 154379477 . Total output tokens: 138362450
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.51404427504167,
    "estimated_duration": 3600.075973702958,
    "input_throughput": 6336.415444182007,
    "output_throughput": 5637.479361060442,
    "total_throughput": 11973.89480524245,
    "itl": 153.36684099158933,
    "ttft": 1616245.644594173,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 190,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5814926713472225,
    "arrivals": 230128,
    "finished_requests": 92137,
    "scheduler_time": 102.32235511268009
}
#Debug simulation 
Total elapsed time: 6.51416592503665. Arrivals time: 0.2920580058125779 Scheduler time: 6.1224265996715985 Scheduler overhead time: 0.037064762436784804 Adapter cache time: 0.008025812625419348 Engine time: 0.03740365064004436 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-16/adapters_96_slots_64_rate_1.6-0.4-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-16/adapters_96_slots_64_rate_1.6-0.4-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 33, 17280, 33, 33, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 33, 17280, 4320, 33, 33, 4320, 17280, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 33, 17280, 4320, 4320, 33, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 33, 17280, 4320, 4320, 4320, 17280, 17280, 33, 33, 4320, 33, 17280, 33, 33, 17280, 33, 4320, 4320, 33, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 33, 33, 17280, 4320, 17280, 33, 4320, 17280, 33, 17280, 4320, 33, 17280, 33, 33, 17280, 33, 33, 4320]
Prompts retrieved: 692256 . Total input tokens: 154379477 . Total output tokens: 138362450
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.7776284260326065,
    "estimated_duration": 3600.0742590804375,
    "input_throughput": 6336.4184620532615,
    "output_throughput": 5637.482046046466,
    "total_throughput": 11973.900508099727,
    "itl": 153.36959933526876,
    "ttft": 1616234.893085344,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 190,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6265386865683847,
    "arrivals": 230128,
    "finished_requests": 92137,
    "scheduler_time": 102.3216055015789
}
#Debug simulation 
Total elapsed time: 6.777744596009143. Arrivals time: 0.5359797717537731 Scheduler time: 6.141766157990787 Scheduler overhead time: 0.03713729768060148 Adapter cache time: 0.008082904503680766 Engine time: 0.03747554315486923 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-32/adapters_96_slots_64_rate_1.6-0.4-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-32/adapters_96_slots_64_rate_1.6-0.4-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 33, 17280, 33, 33, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 33, 17280, 4320, 33, 33, 4320, 17280, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 33, 17280, 4320, 4320, 33, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 33, 17280, 4320, 4320, 4320, 17280, 17280, 33, 33, 4320, 33, 17280, 33, 33, 17280, 33, 4320, 4320, 33, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 33, 33, 17280, 4320, 17280, 33, 4320, 17280, 33, 17280, 4320, 33, 17280, 33, 33, 17280, 33, 33, 4320]
Prompts retrieved: 692256 . Total input tokens: 154379477 . Total output tokens: 138362450
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.784850592026487,
    "estimated_duration": 3600.075460071581,
    "input_throughput": 6336.416348213555,
    "output_throughput": 5637.480165373107,
    "total_throughput": 11973.896513586662,
    "itl": 153.36956128838895,
    "ttft": 1616236.0964830753,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 190,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6264949729852405,
    "arrivals": 230128,
    "finished_requests": 92137,
    "scheduler_time": 102.3216632138066
}
#Debug simulation 
Total elapsed time: 6.784957399009727. Arrivals time: 0.5432378487312235 Scheduler time: 6.141814373317175 Scheduler overhead time: 0.037188647664152086 Adapter cache time: 0.008059224812313914 Engine time: 0.03742680576397106 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-16-16/adapters_96_slots_64_rate_1.6-0.4-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-16-16/adapters_96_slots_64_rate_1.6-0.4-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 33, 17280, 33, 33, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 33, 17280, 4320, 33, 33, 4320, 17280, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 33, 17280, 4320, 4320, 33, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 33, 17280, 4320, 4320, 4320, 17280, 17280, 33, 33, 4320, 33, 17280, 33, 33, 17280, 33, 4320, 4320, 33, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 33, 33, 17280, 4320, 17280, 33, 4320, 17280, 33, 17280, 4320, 33, 17280, 33, 33, 17280, 33, 33, 4320]
Prompts retrieved: 692256 . Total input tokens: 154379477 . Total output tokens: 138362450
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 6.782182179042138,
    "estimated_duration": 3600.012702158393,
    "input_throughput": 6336.526809009114,
    "output_throughput": 5637.578441829355,
    "total_throughput": 11974.10525083847,
    "itl": 153.36873915972149,
    "ttft": 1616222.4542949644,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 190,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5983456095960001,
    "arrivals": 230128,
    "finished_requests": 92137,
    "scheduler_time": 102.32041131888066
}
#Debug simulation 
Total elapsed time: 6.7822593340533786. Arrivals time: 0.29359987465431914 Scheduler time: 6.388312264520209 Scheduler overhead time: 0.0372588430182077 Adapter cache time: 0.008035143604502082 Engine time: 0.037799209414515644 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-16-32/adapters_96_slots_64_rate_1.6-0.4-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-16-32/adapters_96_slots_64_rate_1.6-0.4-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 33, 17280, 33, 33, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 33, 17280, 4320, 33, 33, 4320, 17280, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 33, 17280, 4320, 4320, 33, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 33, 17280, 4320, 4320, 4320, 17280, 17280, 33, 33, 4320, 33, 17280, 33, 33, 17280, 33, 4320, 4320, 33, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 33, 33, 17280, 4320, 17280, 33, 4320, 17280, 33, 17280, 4320, 33, 17280, 33, 33, 17280, 33, 33, 4320]
Prompts retrieved: 692256 . Total input tokens: 154379477 . Total output tokens: 138362450
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 6.8059828340192325,
    "estimated_duration": 3600.094030354421,
    "input_throughput": 6336.383663221777,
    "output_throughput": 5637.451085687883,
    "total_throughput": 11973.834748909661,
    "itl": 153.36978488967304,
    "ttft": 1616255.4274400559,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 190,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6351719842478651,
    "arrivals": 230128,
    "finished_requests": 92137,
    "scheduler_time": 102.32196220365869
}
#Debug simulation 
Total elapsed time: 6.8061031909892336. Arrivals time: 0.2998142255237326 Scheduler time: 6.40609212545678 Scheduler overhead time: 0.037151479977183044 Adapter cache time: 0.008170865301508456 Engine time: 0.037557763687800616 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_16-16-16/adapters_96_slots_64_rate_1.6-0.4-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_16-16-16/adapters_96_slots_64_rate_1.6-0.4-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 33, 17280, 33, 33, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 33, 17280, 4320, 33, 33, 4320, 17280, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 33, 17280, 4320, 4320, 33, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 33, 17280, 4320, 4320, 4320, 17280, 17280, 33, 33, 4320, 33, 17280, 33, 33, 17280, 33, 4320, 4320, 33, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 33, 33, 17280, 4320, 17280, 33, 4320, 17280, 33, 17280, 4320, 33, 17280, 33, 33, 17280, 33, 33, 4320]
Prompts retrieved: 692256 . Total input tokens: 154379477 . Total output tokens: 138362450
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.7520378500339575,
    "estimated_duration": 3600.058928296595,
    "input_throughput": 6336.445445573174,
    "output_throughput": 5637.506053158679,
    "total_throughput": 11973.951498731853,
    "itl": 153.36663286755123,
    "ttft": 1616239.8867443511,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 190,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5681095560314141,
    "arrivals": 230128,
    "finished_requests": 92137,
    "scheduler_time": 102.3221864139373
}
#Debug simulation 
Total elapsed time: 6.752103743026964. Arrivals time: 0.2897889169398695 Scheduler time: 6.362542489601765 Scheduler overhead time: 0.03714517445769161 Adapter cache time: 0.007975342916324735 Engine time: 0.037556282710283995 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_16-16-32/adapters_96_slots_64_rate_1.6-0.4-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_16-16-32/adapters_96_slots_64_rate_1.6-0.4-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 33, 17280, 33, 33, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 33, 17280, 4320, 33, 33, 4320, 17280, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 33, 17280, 4320, 4320, 33, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 33, 17280, 4320, 4320, 4320, 17280, 17280, 33, 33, 4320, 33, 17280, 33, 33, 17280, 33, 4320, 4320, 33, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 33, 33, 17280, 4320, 17280, 33, 4320, 17280, 33, 17280, 4320, 33, 17280, 33, 33, 17280, 33, 33, 4320]
Prompts retrieved: 692256 . Total input tokens: 154379477 . Total output tokens: 138362450
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.766395341022871,
    "estimated_duration": 3600.104583172841,
    "input_throughput": 6336.365089676289,
    "output_throughput": 5637.434560890816,
    "total_throughput": 11973.799650567105,
    "itl": 153.36999603763832,
    "ttft": 1616259.694833863,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 190,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6444777644425642,
    "arrivals": 230128,
    "finished_requests": 92137,
    "scheduler_time": 102.32203824358241
}
#Debug simulation 
Total elapsed time: 6.766466144006699. Arrivals time: 0.5363942573894747 Scheduler time: 6.13030306546716 Scheduler overhead time: 0.037071153812576085 Adapter cache time: 0.008216332469601184 Engine time: 0.037332568725105375 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-8-8/adapters_96_slots_64_rate_1.6-0.1-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-8-8/adapters_96_slots_64_rate_1.6-0.1-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 540, 17280, 540, 540, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 540, 17280, 1080, 540, 540, 1080, 17280, 540, 1080, 540, 540, 1080, 1080, 1080, 540, 540, 17280, 1080, 1080, 540, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 540, 17280, 1080, 1080, 1080, 17280, 17280, 540, 540, 1080, 540, 17280, 540, 540, 17280, 540, 1080, 1080, 540, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 540, 540, 17280, 1080, 17280, 540, 1080, 17280, 540, 17280, 1080, 540, 17280, 540, 540, 17280, 540, 540, 1080]
Prompts retrieved: 604800 . Total input tokens: 134810828 . Total output tokens: 121020589
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.8821635270142,
    "estimated_duration": 3600.005185775888,
    "input_throughput": 6421.292694615326,
    "output_throughput": 5625.511063155658,
    "total_throughput": 12046.803757770984,
    "itl": 152.1084222761196,
    "ttft": 1524188.2035437522,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 988,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.0237618910056296,
    "arrivals": 200953,
    "finished_requests": 92886,
    "scheduler_time": 101.47213994972857
}
#Debug simulation 
Total elapsed time: 6.882336856040638. Arrivals time: 0.295635937305633 Scheduler time: 6.476247705635615 Scheduler overhead time: 0.03787613072199747 Adapter cache time: 0.016882231400813907 Engine time: 0.038093363866209984 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-8-16/adapters_96_slots_64_rate_1.6-0.1-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-8-16/adapters_96_slots_64_rate_1.6-0.1-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 540, 17280, 540, 540, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 540, 17280, 1080, 540, 540, 1080, 17280, 540, 1080, 540, 540, 1080, 1080, 1080, 540, 540, 17280, 1080, 1080, 540, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 540, 17280, 1080, 1080, 1080, 17280, 17280, 540, 540, 1080, 540, 17280, 540, 540, 17280, 540, 1080, 1080, 540, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 540, 540, 17280, 1080, 17280, 540, 1080, 17280, 540, 17280, 1080, 540, 17280, 540, 540, 17280, 540, 540, 1080]
Prompts retrieved: 604800 . Total input tokens: 134810828 . Total output tokens: 121020589
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.852112769964151,
    "estimated_duration": 3600.099901973256,
    "input_throughput": 6420.717932669113,
    "output_throughput": 5625.133343910866,
    "total_throughput": 12045.851276579979,
    "itl": 152.11858058768266,
    "ttft": 1524305.4597517487,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 980,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.2093198914988994,
    "arrivals": 200953,
    "finished_requests": 92882,
    "scheduler_time": 101.47003984160233
}
#Debug simulation 
Total elapsed time: 6.852206065959763. Arrivals time: 0.2923811140935868 Scheduler time: 6.4503641002229415 Scheduler overhead time: 0.03773703268961981 Adapter cache time: 0.0165596233564429 Engine time: 0.037737091653980315 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-8-32/adapters_96_slots_64_rate_1.6-0.1-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-8-32/adapters_96_slots_64_rate_1.6-0.1-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 540, 17280, 540, 540, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 540, 17280, 1080, 540, 540, 1080, 17280, 540, 1080, 540, 540, 1080, 1080, 1080, 540, 540, 17280, 1080, 1080, 540, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 540, 17280, 1080, 1080, 1080, 17280, 17280, 540, 540, 1080, 540, 17280, 540, 540, 17280, 540, 1080, 1080, 540, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 540, 540, 17280, 1080, 17280, 540, 1080, 17280, 540, 17280, 1080, 540, 17280, 540, 540, 17280, 540, 540, 1080]
Prompts retrieved: 604800 . Total input tokens: 134810828 . Total output tokens: 121020589
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.878452006028965,
    "estimated_duration": 3600.10506366505,
    "input_throughput": 6420.708726891371,
    "output_throughput": 5625.1252788116235,
    "total_throughput": 12045.834005702995,
    "itl": 152.11868662219317,
    "ttft": 1524306.7757557137,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 980,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.2129885105602085,
    "arrivals": 200953,
    "finished_requests": 92882,
    "scheduler_time": 101.4701107285376
}
#Debug simulation 
Total elapsed time: 6.8785507720313035. Arrivals time: 0.29627600632375106 Scheduler time: 6.472479007439688 Scheduler overhead time: 0.03781446354696527 Adapter cache time: 0.016730225645005703 Engine time: 0.03773838002234697 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-16-16/adapters_96_slots_64_rate_1.6-0.1-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-16-16/adapters_96_slots_64_rate_1.6-0.1-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 540, 17280, 540, 540, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 540, 17280, 1080, 540, 540, 1080, 17280, 540, 1080, 540, 540, 1080, 1080, 1080, 540, 540, 17280, 1080, 1080, 540, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 540, 17280, 1080, 1080, 1080, 17280, 17280, 540, 540, 1080, 540, 17280, 540, 540, 17280, 540, 1080, 1080, 540, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 540, 540, 17280, 1080, 17280, 540, 1080, 17280, 540, 17280, 1080, 540, 17280, 540, 540, 17280, 540, 540, 1080]
Prompts retrieved: 604800 . Total input tokens: 134810828 . Total output tokens: 121020589
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 6.8724703709594905,
    "estimated_duration": 3600.0882093197347,
    "input_throughput": 6421.144609778348,
    "output_throughput": 5625.381330261002,
    "total_throughput": 12046.525940039352,
    "itl": 152.1112954820043,
    "ttft": 1524214.8801112722,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 988,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.0947264809067994,
    "arrivals": 200953,
    "finished_requests": 92886,
    "scheduler_time": 101.47263282851658
}
#Debug simulation 
Total elapsed time: 6.872647308977321. Arrivals time: 0.2938489135704003 Scheduler time: 6.4685935388552025 Scheduler overhead time: 0.03776394476881251 Adapter cache time: 0.016878338530659676 Engine time: 0.03801245347131044 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-16-32/adapters_96_slots_64_rate_1.6-0.1-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-16-32/adapters_96_slots_64_rate_1.6-0.1-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 540, 17280, 540, 540, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 540, 17280, 1080, 540, 540, 1080, 17280, 540, 1080, 540, 540, 1080, 1080, 1080, 540, 540, 17280, 1080, 1080, 540, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 540, 17280, 1080, 1080, 1080, 17280, 17280, 540, 540, 1080, 540, 17280, 540, 540, 17280, 540, 1080, 1080, 540, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 540, 540, 17280, 1080, 17280, 540, 1080, 17280, 540, 17280, 1080, 540, 17280, 540, 540, 17280, 540, 540, 1080]
Prompts retrieved: 604800 . Total input tokens: 134810828 . Total output tokens: 121020589
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 6.873040415986907,
    "estimated_duration": 3600.1501999628927,
    "input_throughput": 6420.628228299545,
    "output_throughput": 5625.054754717937,
    "total_throughput": 12045.682983017481,
    "itl": 152.12008145333576,
    "ttft": 1524324.4326257154,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 980,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.2562478130869565,
    "arrivals": 200953,
    "finished_requests": 92882,
    "scheduler_time": 101.47028229838828
}
#Debug simulation 
Total elapsed time: 6.873136454960331. Arrivals time: 0.28766801848541945 Scheduler time: 6.474591713631526 Scheduler overhead time: 0.03786143352044746 Adapter cache time: 0.016977620602119714 Engine time: 0.038426983112003654 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_16-16-16/adapters_96_slots_64_rate_1.6-0.1-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_16-16-16/adapters_96_slots_64_rate_1.6-0.1-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 540, 17280, 540, 540, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 540, 17280, 1080, 540, 540, 1080, 17280, 540, 1080, 540, 540, 1080, 1080, 1080, 540, 540, 17280, 1080, 1080, 540, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 540, 17280, 1080, 1080, 1080, 17280, 17280, 540, 540, 1080, 540, 17280, 540, 540, 17280, 540, 1080, 1080, 540, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 540, 540, 17280, 1080, 17280, 540, 1080, 17280, 540, 17280, 1080, 540, 17280, 540, 540, 17280, 540, 540, 1080]
Prompts retrieved: 604800 . Total input tokens: 134810828 . Total output tokens: 121020589
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.851321290014312,
    "estimated_duration": 3600.0539583902582,
    "input_throughput": 6421.475974303707,
    "output_throughput": 5625.450683260182,
    "total_throughput": 12046.926657563889,
    "itl": 152.10358428864373,
    "ttft": 1524239.496863578,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 984,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.9422094901836733,
    "arrivals": 200953,
    "finished_requests": 92889,
    "scheduler_time": 101.47570602445168
}
#Debug simulation 
Total elapsed time: 6.851429989968892. Arrivals time: 0.29675094061531126 Scheduler time: 6.4454752106103115 Scheduler overhead time: 0.0374721490079537 Adapter cache time: 0.01667096745222807 Engine time: 0.03770731505937874 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_16-16-32/adapters_96_slots_64_rate_1.6-0.1-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_16-16-32/adapters_96_slots_64_rate_1.6-0.1-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 540, 17280, 540, 540, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 540, 17280, 1080, 540, 540, 1080, 17280, 540, 1080, 540, 540, 1080, 1080, 1080, 540, 540, 17280, 1080, 1080, 540, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 540, 17280, 1080, 1080, 1080, 17280, 17280, 540, 540, 1080, 540, 17280, 540, 540, 17280, 540, 1080, 1080, 540, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 540, 540, 17280, 1080, 17280, 540, 1080, 17280, 540, 17280, 1080, 540, 17280, 540, 540, 17280, 540, 540, 1080]
Prompts retrieved: 604800 . Total input tokens: 134810828 . Total output tokens: 121020589
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.842415962019004,
    "estimated_duration": 3600.0268110570673,
    "input_throughput": 6420.800514319721,
    "output_throughput": 5625.196717369387,
    "total_throughput": 12045.997231689107,
    "itl": 152.12157045040382,
    "ttft": 1524267.5729415223,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 980,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.2988783466816343,
    "arrivals": 200953,
    "finished_requests": 92881,
    "scheduler_time": 101.46553533010265
}
#Debug simulation 
Total elapsed time: 6.842588966013864. Arrivals time: 0.290164825564716 Scheduler time: 6.442444640968461 Scheduler overhead time: 0.03784920257749036 Adapter cache time: 0.016809517168439925 Engine time: 0.03776137746172026 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-8-8/adapters_96_slots_64_rate_1.6-0.1-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-8-8/adapters_96_slots_64_rate_1.6-0.1-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 270, 17280, 270, 270, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 270, 17280, 1080, 270, 270, 1080, 17280, 270, 1080, 270, 270, 1080, 1080, 1080, 270, 270, 17280, 1080, 1080, 270, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 270, 17280, 1080, 1080, 1080, 17280, 17280, 270, 270, 1080, 270, 17280, 270, 270, 17280, 270, 1080, 1080, 270, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 270, 270, 17280, 1080, 17280, 270, 1080, 17280, 270, 17280, 1080, 270, 17280, 270, 270, 17280, 270, 270, 1080]
Prompts retrieved: 596160 . Total input tokens: 132911004 . Total output tokens: 119303065
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.553647312044632,
    "estimated_duration": 3600.0131906565252,
    "input_throughput": 6346.867577958269,
    "output_throughput": 5631.468810341442,
    "total_throughput": 11978.336388299711,
    "itl": 152.8087122727021,
    "ttft": 1521173.8601774774,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1273,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.896000898026495,
    "arrivals": 198151,
    "finished_requests": 92467,
    "scheduler_time": 101.38904998039023
}
#Debug simulation 
Total elapsed time: 6.553740404022392. Arrivals time: 0.2816908530658111 Scheduler time: 6.160357480170205 Scheduler overhead time: 0.0373485938180238 Adapter cache time: 0.01952924660872668 Engine time: 0.03752784215612337 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-8-16/adapters_96_slots_64_rate_1.6-0.1-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-8-16/adapters_96_slots_64_rate_1.6-0.1-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 270, 17280, 270, 270, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 270, 17280, 1080, 270, 270, 1080, 17280, 270, 1080, 270, 270, 1080, 1080, 1080, 270, 270, 17280, 1080, 1080, 270, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 270, 17280, 1080, 1080, 1080, 17280, 17280, 270, 270, 1080, 270, 17280, 270, 270, 17280, 270, 1080, 1080, 270, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 270, 270, 17280, 1080, 17280, 270, 1080, 17280, 270, 17280, 1080, 270, 17280, 270, 270, 17280, 270, 270, 1080]
Prompts retrieved: 596160 . Total input tokens: 132911004 . Total output tokens: 119303065
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.583806161012035,
    "estimated_duration": 3600.004651309095,
    "input_throughput": 6346.443744646803,
    "output_throughput": 5631.11605776074,
    "total_throughput": 11977.559802407543,
    "itl": 152.82082999493795,
    "ttft": 1521244.7269643603,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1274,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.175016885709479,
    "arrivals": 198151,
    "finished_requests": 92460,
    "scheduler_time": 101.38128362603597
}
#Debug simulation 
Total elapsed time: 6.583919627009891. Arrivals time: 0.295769180636853 Scheduler time: 6.176582153071649 Scheduler overhead time: 0.037481409090105444 Adapter cache time: 0.01945685804821551 Engine time: 0.03725116903660819 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-8-32/adapters_96_slots_64_rate_1.6-0.1-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-8-32/adapters_96_slots_64_rate_1.6-0.1-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 270, 17280, 270, 270, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 270, 17280, 1080, 270, 270, 1080, 17280, 270, 1080, 270, 270, 1080, 1080, 1080, 270, 270, 17280, 1080, 1080, 270, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 270, 17280, 1080, 1080, 1080, 17280, 17280, 270, 270, 1080, 270, 17280, 270, 270, 17280, 270, 1080, 1080, 270, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 270, 270, 17280, 1080, 17280, 270, 1080, 17280, 270, 17280, 1080, 270, 17280, 270, 270, 17280, 270, 270, 1080]
Prompts retrieved: 596160 . Total input tokens: 132911004 . Total output tokens: 119303065
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.553324958018493,
    "estimated_duration": 3600.005351362869,
    "input_throughput": 6346.44251052311,
    "output_throughput": 5631.114962739021,
    "total_throughput": 11977.557473262132,
    "itl": 152.8207008982108,
    "ttft": 1521244.659997097,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1274,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.179279520939967,
    "arrivals": 198151,
    "finished_requests": 92460,
    "scheduler_time": 101.3811775641328
}
#Debug simulation 
Total elapsed time: 6.553504495997913. Arrivals time: 0.2888855075580068 Scheduler time: 6.153483288537245 Scheduler overhead time: 0.03727643773891032 Adapter cache time: 0.019363657454960048 Engine time: 0.03726887592347339 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-16-16/adapters_96_slots_64_rate_1.6-0.1-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-16-16/adapters_96_slots_64_rate_1.6-0.1-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 270, 17280, 270, 270, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 270, 17280, 1080, 270, 270, 1080, 17280, 270, 1080, 270, 270, 1080, 1080, 1080, 270, 270, 17280, 1080, 1080, 270, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 270, 17280, 1080, 1080, 1080, 17280, 17280, 270, 270, 1080, 270, 17280, 270, 270, 17280, 270, 1080, 1080, 270, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 270, 270, 17280, 1080, 17280, 270, 1080, 17280, 270, 17280, 1080, 270, 17280, 270, 270, 17280, 270, 270, 1080]
Prompts retrieved: 596160 . Total input tokens: 132911004 . Total output tokens: 119303065
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 6.574918663012795,
    "estimated_duration": 3600.1214699803986,
    "input_throughput": 6346.763071892795,
    "output_throughput": 5631.369154916426,
    "total_throughput": 11978.13222680922,
    "itl": 152.81276980770156,
    "ttft": 1521212.5392096632,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1274,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.987880229863759,
    "arrivals": 198151,
    "finished_requests": 92468,
    "scheduler_time": 101.38965978304768
}
#Debug simulation 
Total elapsed time: 6.575012375018559. Arrivals time: 0.2873737799236551 Scheduler time: 6.175507538137026 Scheduler overhead time: 0.0375383083592169 Adapter cache time: 0.01963156828423962 Engine time: 0.03746273129945621 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-16-32/adapters_96_slots_64_rate_1.6-0.1-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-16-32/adapters_96_slots_64_rate_1.6-0.1-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 270, 17280, 270, 270, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 270, 17280, 1080, 270, 270, 1080, 17280, 270, 1080, 270, 270, 1080, 1080, 1080, 270, 270, 17280, 1080, 1080, 270, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 270, 17280, 1080, 1080, 1080, 17280, 17280, 270, 270, 1080, 270, 17280, 270, 270, 17280, 270, 1080, 1080, 270, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 270, 270, 17280, 1080, 17280, 270, 1080, 17280, 270, 17280, 1080, 270, 17280, 270, 270, 17280, 270, 270, 1080]
Prompts retrieved: 596160 . Total input tokens: 132911004 . Total output tokens: 119303065
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 6.560939681017771,
    "estimated_duration": 3600.077191358813,
    "input_throughput": 6346.31586645967,
    "output_throughput": 5631.002593127322,
    "total_throughput": 11977.318459586992,
    "itl": 152.8229973489212,
    "ttft": 1521264.2046144805,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1273,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.233368234988296,
    "arrivals": 198151,
    "finished_requests": 92460,
    "scheduler_time": 101.38179922393019
}
#Debug simulation 
Total elapsed time: 6.561052123026457. Arrivals time: 0.293619881849736 Scheduler time: 6.155884849431459 Scheduler overhead time: 0.03734947461634874 Adapter cache time: 0.019489081401843578 Engine time: 0.037400425237137824 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_16-16-16/adapters_96_slots_64_rate_1.6-0.1-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_16-16-16/adapters_96_slots_64_rate_1.6-0.1-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 270, 17280, 270, 270, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 270, 17280, 1080, 270, 270, 1080, 17280, 270, 1080, 270, 270, 1080, 1080, 1080, 270, 270, 17280, 1080, 1080, 270, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 270, 17280, 1080, 1080, 1080, 17280, 17280, 270, 270, 1080, 270, 17280, 270, 270, 17280, 270, 1080, 1080, 270, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 270, 270, 17280, 1080, 17280, 270, 1080, 17280, 270, 17280, 1080, 270, 17280, 270, 270, 17280, 270, 270, 1080]
Prompts retrieved: 596160 . Total input tokens: 132911004 . Total output tokens: 119303065
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.561049295007251,
    "estimated_duration": 3600.092418298291,
    "input_throughput": 6346.955673654809,
    "output_throughput": 5631.4948741185835,
    "total_throughput": 11978.450547773393,
    "itl": 152.80494378375653,
    "ttft": 1521201.9385484052,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1274,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.8093240757052733,
    "arrivals": 198151,
    "finished_requests": 92470,
    "scheduler_time": 101.3936793249504
}
#Debug simulation 
Total elapsed time: 6.561218461021781. Arrivals time: 0.2917645695852116 Scheduler time: 6.157528677082155 Scheduler overhead time: 0.03746752790175378 Adapter cache time: 0.019411231740377843 Engine time: 0.03765447693876922 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_16-16-32/adapters_96_slots_64_rate_1.6-0.1-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_16-16-32/adapters_96_slots_64_rate_1.6-0.1-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 270, 17280, 270, 270, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 270, 17280, 1080, 270, 270, 1080, 17280, 270, 1080, 270, 270, 1080, 1080, 1080, 270, 270, 17280, 1080, 1080, 270, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 270, 17280, 1080, 1080, 1080, 17280, 17280, 270, 270, 1080, 270, 17280, 270, 270, 17280, 270, 1080, 1080, 270, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 270, 270, 17280, 1080, 17280, 270, 1080, 17280, 270, 17280, 1080, 270, 17280, 270, 270, 17280, 270, 270, 1080]
Prompts retrieved: 596160 . Total input tokens: 132911004 . Total output tokens: 119303065
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.561534931999631,
    "estimated_duration": 3600.134818460556,
    "input_throughput": 6346.214281433395,
    "output_throughput": 5630.912458069688,
    "total_throughput": 11977.126739503083,
    "itl": 152.824308487179,
    "ttft": 1521286.2998079155,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1273,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.288322639651634,
    "arrivals": 198151,
    "finished_requests": 92460,
    "scheduler_time": 101.38199987661098
}
#Debug simulation 
Total elapsed time: 6.561628065013792. Arrivals time: 0.2926265345304273 Scheduler time: 6.157724355638493 Scheduler overhead time: 0.03734288673149422 Adapter cache time: 0.019382445665542036 Engine time: 0.037347598699852824 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-8/adapters_96_slots_64_rate_1.6-0.1-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-8/adapters_96_slots_64_rate_1.6-0.1-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 135, 17280, 135, 135, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 135, 17280, 1080, 135, 135, 1080, 17280, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 135, 17280, 1080, 1080, 135, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 135, 17280, 1080, 1080, 1080, 17280, 17280, 135, 135, 1080, 135, 17280, 135, 135, 17280, 135, 1080, 1080, 135, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 135, 135, 17280, 1080, 17280, 135, 1080, 17280, 135, 17280, 1080, 135, 17280, 135, 135, 17280, 135, 135, 1080]
Prompts retrieved: 591840 . Total input tokens: 131946218 . Total output tokens: 118450311
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.427775221003685,
    "estimated_duration": 3600.049190138847,
    "input_throughput": 6362.381953763416,
    "output_throughput": 5648.127546617155,
    "total_throughput": 12010.50950038057,
    "itl": 152.3821688099596,
    "ttft": 1513974.1023113737,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1424,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.358134547360357,
    "arrivals": 196793,
    "finished_requests": 92799,
    "scheduler_time": 101.66243221856497
}
#Debug simulation 
Total elapsed time: 6.427872078027576. Arrivals time: 0.28806854237336665 Scheduler time: 6.027494847250637 Scheduler overhead time: 0.03678480355301872 Adapter cache time: 0.021093345363624394 Engine time: 0.0374066632357426 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-16/adapters_96_slots_64_rate_1.6-0.1-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-16/adapters_96_slots_64_rate_1.6-0.1-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 135, 17280, 135, 135, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 135, 17280, 1080, 135, 135, 1080, 17280, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 135, 17280, 1080, 1080, 135, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 135, 17280, 1080, 1080, 1080, 17280, 17280, 135, 135, 1080, 135, 17280, 135, 135, 17280, 135, 1080, 1080, 135, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 135, 135, 17280, 1080, 17280, 135, 1080, 17280, 135, 17280, 1080, 135, 17280, 135, 135, 17280, 135, 135, 1080]
Prompts retrieved: 591840 . Total input tokens: 131946218 . Total output tokens: 118450311
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.452373682986945,
    "estimated_duration": 3600.046146222305,
    "input_throughput": 6362.128447723977,
    "output_throughput": 5647.6420507373405,
    "total_throughput": 12009.770498461317,
    "itl": 152.39496340404997,
    "ttft": 1514032.1858220452,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1428,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.666946470644271,
    "arrivals": 196793,
    "finished_requests": 92793,
    "scheduler_time": 101.65421209172688
}
#Debug simulation 
Total elapsed time: 6.452520939987153. Arrivals time: 0.2911977297626436 Scheduler time: 6.048876625427511 Scheduler overhead time: 0.03688761964440346 Adapter cache time: 0.021124931809026748 Engine time: 0.03727060998789966 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-32/adapters_96_slots_64_rate_1.6-0.1-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-32/adapters_96_slots_64_rate_1.6-0.1-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 135, 17280, 135, 135, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 135, 17280, 1080, 135, 135, 1080, 17280, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 135, 17280, 1080, 1080, 135, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 135, 17280, 1080, 1080, 1080, 17280, 17280, 135, 135, 1080, 135, 17280, 135, 135, 17280, 135, 1080, 1080, 135, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 135, 135, 17280, 1080, 17280, 135, 1080, 17280, 135, 17280, 1080, 135, 17280, 135, 135, 17280, 135, 135, 1080]
Prompts retrieved: 591840 . Total input tokens: 131946218 . Total output tokens: 118450311
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.424192492035218,
    "estimated_duration": 3600.0565325882367,
    "input_throughput": 6362.110092624949,
    "output_throughput": 5647.625756971824,
    "total_throughput": 12009.735849596773,
    "itl": 152.39527631399704,
    "ttft": 1514034.8726071166,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1428,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.673949480727257,
    "arrivals": 196793,
    "finished_requests": 92793,
    "scheduler_time": 101.65426120867778
}
#Debug simulation 
Total elapsed time: 6.4242890540044755. Arrivals time: 0.28611165104666725 Scheduler time: 6.026111557672266 Scheduler overhead time: 0.03680015355348587 Adapter cache time: 0.020924875396303833 Engine time: 0.03731796203646809 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-16-16/adapters_96_slots_64_rate_1.6-0.1-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-16-16/adapters_96_slots_64_rate_1.6-0.1-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 135, 17280, 135, 135, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 135, 17280, 1080, 135, 135, 1080, 17280, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 135, 17280, 1080, 1080, 135, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 135, 17280, 1080, 1080, 1080, 17280, 17280, 135, 135, 1080, 135, 17280, 135, 135, 17280, 135, 1080, 1080, 135, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 135, 135, 17280, 1080, 17280, 135, 1080, 17280, 135, 17280, 1080, 135, 17280, 135, 135, 17280, 135, 135, 1080]
Prompts retrieved: 591840 . Total input tokens: 131946218 . Total output tokens: 118450311
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 6.4264825959689915,
    "estimated_duration": 3600.000182496485,
    "input_throughput": 6362.283010807142,
    "output_throughput": 5648.001658127652,
    "total_throughput": 12010.284668934795,
    "itl": 152.3872467397173,
    "ttft": 1513960.12917581,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1429,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.470950600858699,
    "arrivals": 196793,
    "finished_requests": 92796,
    "scheduler_time": 101.65817730837834
}
#Debug simulation 
Total elapsed time: 6.426576728001237. Arrivals time: 0.28926151990890503 Scheduler time: 6.02506548142992 Scheduler overhead time: 0.036909630929585546 Adapter cache time: 0.021311179327312857 Engine time: 0.03702501050429419 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-16-32/adapters_96_slots_64_rate_1.6-0.1-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-16-32/adapters_96_slots_64_rate_1.6-0.1-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 135, 17280, 135, 135, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 135, 17280, 1080, 135, 135, 1080, 17280, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 135, 17280, 1080, 1080, 135, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 135, 17280, 1080, 1080, 1080, 17280, 17280, 135, 135, 1080, 135, 17280, 135, 135, 17280, 135, 1080, 1080, 135, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 135, 135, 17280, 1080, 17280, 135, 1080, 17280, 135, 17280, 1080, 135, 17280, 135, 135, 17280, 135, 135, 1080]
Prompts retrieved: 591840 . Total input tokens: 131946218 . Total output tokens: 118450311
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 6.420022462960333,
    "estimated_duration": 3600.121740411424,
    "input_throughput": 6361.994857813481,
    "output_throughput": 5647.523463380567,
    "total_throughput": 12009.518321194048,
    "itl": 152.39779770530455,
    "ttft": 1514060.0837453948,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1428,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.735191574711321,
    "arrivals": 196793,
    "finished_requests": 92793,
    "scheduler_time": 101.65448431885034
}
#Debug simulation 
Total elapsed time: 6.420189241995104. Arrivals time: 0.2892131011467427 Scheduler time: 6.019191301020328 Scheduler overhead time: 0.03655597782926634 Adapter cache time: 0.02102049731183797 Engine time: 0.03721244295593351 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_16-16-16/adapters_96_slots_64_rate_1.6-0.1-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_16-16-16/adapters_96_slots_64_rate_1.6-0.1-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 135, 17280, 135, 135, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 135, 17280, 1080, 135, 135, 1080, 17280, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 135, 17280, 1080, 1080, 135, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 135, 17280, 1080, 1080, 1080, 17280, 17280, 135, 135, 1080, 135, 17280, 135, 135, 17280, 135, 1080, 1080, 135, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 135, 135, 17280, 1080, 17280, 135, 1080, 17280, 135, 17280, 1080, 135, 17280, 135, 135, 17280, 135, 135, 1080]
Prompts retrieved: 591840 . Total input tokens: 131946218 . Total output tokens: 118450311
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.4165052809985355,
    "estimated_duration": 3600.126036815141,
    "input_throughput": 6362.40308416073,
    "output_throughput": 5648.075592927942,
    "total_throughput": 12010.478677088671,
    "itl": 152.37887723697966,
    "ttft": 1513962.736694697,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1426,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.263811720530388,
    "arrivals": 196793,
    "finished_requests": 92801,
    "scheduler_time": 101.66714557443872
}
#Debug simulation 
Total elapsed time: 6.416592548019253. Arrivals time: 0.2901990991085768 Scheduler time: 6.015051277470775 Scheduler overhead time: 0.03655117750167847 Adapter cache time: 0.020963504386600107 Engine time: 0.036979904340114444 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_16-16-32/adapters_96_slots_64_rate_1.6-0.1-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_16-16-32/adapters_96_slots_64_rate_1.6-0.1-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 135, 17280, 135, 135, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 135, 17280, 1080, 135, 135, 1080, 17280, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 135, 17280, 1080, 1080, 135, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 135, 17280, 1080, 1080, 1080, 17280, 17280, 135, 135, 1080, 135, 17280, 135, 135, 17280, 135, 1080, 1080, 135, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 135, 135, 17280, 1080, 17280, 135, 1080, 17280, 135, 17280, 1080, 135, 17280, 135, 135, 17280, 135, 135, 1080]
Prompts retrieved: 591840 . Total input tokens: 131946218 . Total output tokens: 118450311
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.4438733930001035,
    "estimated_duration": 3600.0177219636307,
    "input_throughput": 6361.5597946301905,
    "output_throughput": 5647.391643647412,
    "total_throughput": 12008.951438277601,
    "itl": 152.40018594140275,
    "ttft": 1514118.4173072756,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1428,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.796182161122544,
    "arrivals": 196793,
    "finished_requests": 92786,
    "scheduler_time": 101.64972800795793
}
#Debug simulation 
Total elapsed time: 6.443991156993434. Arrivals time: 0.29229090531589463 Scheduler time: 6.039612971828319 Scheduler overhead time: 0.03689055307768285 Adapter cache time: 0.020920964947436005 Engine time: 0.03718692128313705 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-8/adapters_96_slots_64_rate_1.6-0.1-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-8/adapters_96_slots_64_rate_1.6-0.1-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 66, 17280, 66, 66, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 66, 17280, 1080, 66, 66, 1080, 17280, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 66, 17280, 1080, 1080, 66, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 66, 17280, 1080, 1080, 1080, 17280, 17280, 66, 66, 1080, 66, 17280, 66, 66, 17280, 66, 1080, 1080, 66, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 66, 66, 17280, 1080, 17280, 66, 1080, 17280, 66, 17280, 1080, 66, 17280, 66, 66, 17280, 66, 66, 1080]
Prompts retrieved: 589632 . Total input tokens: 131460243 . Total output tokens: 118014727
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.4607647699886,
    "estimated_duration": 3600.07470513747,
    "input_throughput": 6444.65931967766,
    "output_throughput": 5704.50301231063,
    "total_throughput": 12149.16233198829,
    "itl": 150.6020199143237,
    "ttft": 1491572.1811019427,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 973,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.9778545748466367,
    "arrivals": 196113,
    "finished_requests": 93879,
    "scheduler_time": 102.48838595207656
}
#Debug simulation 
Total elapsed time: 6.46094334096415. Arrivals time: 0.2846649690764025 Scheduler time: 6.067014091997407 Scheduler overhead time: 0.036434693553019315 Adapter cache time: 0.01895517809316516 Engine time: 0.036909854505211115 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-16/adapters_96_slots_64_rate_1.6-0.1-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-16/adapters_96_slots_64_rate_1.6-0.1-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 66, 17280, 66, 66, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 66, 17280, 1080, 66, 66, 1080, 17280, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 66, 17280, 1080, 1080, 66, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 66, 17280, 1080, 1080, 1080, 17280, 17280, 66, 66, 1080, 66, 17280, 66, 66, 17280, 66, 1080, 1080, 66, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 66, 66, 17280, 1080, 17280, 66, 1080, 17280, 66, 17280, 1080, 66, 17280, 66, 66, 17280, 66, 66, 1080]
Prompts retrieved: 589632 . Total input tokens: 131460243 . Total output tokens: 118014727
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.471524962980766,
    "estimated_duration": 3600.152115975951,
    "input_throughput": 6444.5207459547755,
    "output_throughput": 5704.380353504259,
    "total_throughput": 12148.901099459035,
    "itl": 150.609915647413,
    "ttft": 1491572.0393059275,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 971,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.1587109103752344,
    "arrivals": 196113,
    "finished_requests": 93879,
    "scheduler_time": 102.48594175157277
}
#Debug simulation 
Total elapsed time: 6.471615293994546. Arrivals time: 0.29000367905246094 Scheduler time: 6.072114513313863 Scheduler overhead time: 0.03656363062327728 Adapter cache time: 0.018833066918887198 Engine time: 0.037250908848363906 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-32/adapters_96_slots_64_rate_1.6-0.1-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-32/adapters_96_slots_64_rate_1.6-0.1-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 66, 17280, 66, 66, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 66, 17280, 1080, 66, 66, 1080, 17280, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 66, 17280, 1080, 1080, 66, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 66, 17280, 1080, 1080, 1080, 17280, 17280, 66, 66, 1080, 66, 17280, 66, 66, 17280, 66, 1080, 1080, 66, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 66, 66, 17280, 1080, 17280, 66, 1080, 17280, 66, 17280, 1080, 66, 17280, 66, 66, 17280, 66, 66, 1080]
Prompts retrieved: 589632 . Total input tokens: 131460243 . Total output tokens: 118014727
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.464623658976052,
    "estimated_duration": 3600.1586602759667,
    "input_throughput": 6444.509031227399,
    "output_throughput": 5704.369984190026,
    "total_throughput": 12148.879015417424,
    "itl": 150.61013895544502,
    "ttft": 1491575.068961863,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 971,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.1660364862344843,
    "arrivals": 196113,
    "finished_requests": 93879,
    "scheduler_time": 102.48595588727342
}
#Debug simulation 
Total elapsed time: 6.464720994001254. Arrivals time: 0.28862572234356776 Scheduler time: 6.066819244239014 Scheduler overhead time: 0.03636961878510192 Adapter cache time: 0.01901685626944527 Engine time: 0.03704763267887756 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-16-16/adapters_96_slots_64_rate_1.6-0.1-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-16-16/adapters_96_slots_64_rate_1.6-0.1-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 66, 17280, 66, 66, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 66, 17280, 1080, 66, 66, 1080, 17280, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 66, 17280, 1080, 1080, 66, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 66, 17280, 1080, 1080, 1080, 17280, 17280, 66, 66, 1080, 66, 17280, 66, 66, 17280, 66, 1080, 1080, 66, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 66, 66, 17280, 1080, 17280, 66, 1080, 17280, 66, 17280, 1080, 66, 17280, 66, 66, 17280, 66, 66, 1080]
Prompts retrieved: 589632 . Total input tokens: 131460243 . Total output tokens: 118014727
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 6.468506385979708,
    "estimated_duration": 3600.1448564415878,
    "input_throughput": 6444.533741048494,
    "output_throughput": 5704.391856137305,
    "total_throughput": 12148.925597185798,
    "itl": 150.60387152966203,
    "ttft": 1491607.680385351,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 974,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.0434680844540405,
    "arrivals": 196113,
    "finished_requests": 93879,
    "scheduler_time": 102.48907842093986
}
#Debug simulation 
Total elapsed time: 6.468648972979281. Arrivals time: 0.30720468412619084 Scheduler time: 6.0513755936408415 Scheduler overhead time: 0.036816892970819026 Adapter cache time: 0.01901147107128054 Engine time: 0.03720749862259254 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-16-32/adapters_96_slots_64_rate_1.6-0.1-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-16-32/adapters_96_slots_64_rate_1.6-0.1-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 66, 17280, 66, 66, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 66, 17280, 1080, 66, 66, 1080, 17280, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 66, 17280, 1080, 1080, 66, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 66, 17280, 1080, 1080, 1080, 17280, 17280, 66, 66, 1080, 66, 17280, 66, 66, 17280, 66, 1080, 1080, 66, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 66, 66, 17280, 1080, 17280, 66, 1080, 17280, 66, 17280, 1080, 66, 17280, 66, 66, 17280, 66, 66, 1080]
Prompts retrieved: 589632 . Total input tokens: 131460243 . Total output tokens: 118014727
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 6.440216758986935,
    "estimated_duration": 3600.036146609918,
    "input_throughput": 6444.687235112353,
    "output_throughput": 5704.562999829582,
    "total_throughput": 12149.250234941934,
    "itl": 150.61330678357538,
    "ttft": 1491479.5526905695,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 970,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.2010106247477244,
    "arrivals": 196113,
    "finished_requests": 93877,
    "scheduler_time": 102.48132825364809
}
#Debug simulation 
Total elapsed time: 6.44034885201836. Arrivals time: 0.28853195789270103 Scheduler time: 6.042787488899194 Scheduler overhead time: 0.036407626408617944 Adapter cache time: 0.018792826507706195 Engine time: 0.036836091603618115 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_16-16-16/adapters_96_slots_64_rate_1.6-0.1-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_16-16-16/adapters_96_slots_64_rate_1.6-0.1-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 66, 17280, 66, 66, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 66, 17280, 1080, 66, 66, 1080, 17280, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 66, 17280, 1080, 1080, 66, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 66, 17280, 1080, 1080, 1080, 17280, 17280, 66, 66, 1080, 66, 17280, 66, 66, 17280, 66, 1080, 1080, 66, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 66, 66, 17280, 1080, 17280, 66, 1080, 17280, 66, 17280, 1080, 66, 17280, 66, 66, 17280, 66, 66, 1080]
Prompts retrieved: 589632 . Total input tokens: 131460243 . Total output tokens: 118014727
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.451543594012037,
    "estimated_duration": 3600.1133614272344,
    "input_throughput": 6444.769558812393,
    "output_throughput": 5704.4470377061725,
    "total_throughput": 12149.216596518567,
    "itl": 150.59799955721394,
    "ttft": 1491585.636605433,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 970,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.9003487860550443,
    "arrivals": 196113,
    "finished_requests": 93880,
    "scheduler_time": 102.49141814821752
}
#Debug simulation 
Total elapsed time: 6.451650016999338. Arrivals time: 0.2863454640028067 Scheduler time: 6.056186926085502 Scheduler overhead time: 0.03635364054935053 Adapter cache time: 0.018996184458956122 Engine time: 0.03692331997444853 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_16-16-32/adapters_96_slots_64_rate_1.6-0.1-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_16-16-32/adapters_96_slots_64_rate_1.6-0.1-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 66, 17280, 66, 66, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 66, 17280, 1080, 66, 66, 1080, 17280, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 66, 17280, 1080, 1080, 66, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 66, 17280, 1080, 1080, 1080, 17280, 17280, 66, 66, 1080, 66, 17280, 66, 66, 17280, 66, 1080, 1080, 66, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 66, 66, 17280, 1080, 17280, 66, 1080, 17280, 66, 17280, 1080, 66, 17280, 66, 66, 17280, 66, 66, 1080]
Prompts retrieved: 589632 . Total input tokens: 131460243 . Total output tokens: 118014727
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.4704859320190735,
    "estimated_duration": 3600.0754608787183,
    "input_throughput": 6444.61685654139,
    "output_throughput": 5704.500703712291,
    "total_throughput": 12149.11756025368,
    "itl": 150.61489503563027,
    "ttft": 1491496.3715572103,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 970,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.241126082614101,
    "arrivals": 196113,
    "finished_requests": 93877,
    "scheduler_time": 102.48139849011231
}
#Debug simulation 
Total elapsed time: 6.470627875009086. Arrivals time: 0.30410916660912335 Scheduler time: 6.0562211103970185 Scheduler overhead time: 0.03666603279998526 Adapter cache time: 0.018932087463326752 Engine time: 0.03767113294452429 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-8/adapters_96_slots_64_rate_1.6-0.1-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-8/adapters_96_slots_64_rate_1.6-0.1-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 33, 17280, 33, 33, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 33, 17280, 1080, 33, 33, 1080, 17280, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 33, 17280, 1080, 1080, 33, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 33, 17280, 1080, 1080, 1080, 17280, 17280, 33, 33, 1080, 33, 17280, 33, 33, 17280, 33, 1080, 1080, 33, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 33, 33, 17280, 1080, 17280, 33, 1080, 17280, 33, 17280, 1080, 33, 17280, 33, 33, 17280, 33, 33, 1080]
Prompts retrieved: 588576 . Total input tokens: 131231793 . Total output tokens: 117798990
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.740406375960447,
    "estimated_duration": 3600.033184140664,
    "input_throughput": 6522.681819558054,
    "output_throughput": 5761.1857833334925,
    "total_throughput": 12283.867602891545,
    "itl": 148.95646441561956,
    "ttft": 1482814.4185328353,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 623,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9066838644701358,
    "arrivals": 195753,
    "finished_requests": 95136,
    "scheduler_time": 103.65725652347544
}
#Debug simulation 
Total elapsed time: 6.740473106969148. Arrivals time: 0.2926682434626855 Scheduler time: 6.340066046745051 Scheduler overhead time: 0.036547158495523036 Adapter cache time: 0.017187190300319344 Engine time: 0.03718627238413319 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-16/adapters_96_slots_64_rate_1.6-0.1-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-16/adapters_96_slots_64_rate_1.6-0.1-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 33, 17280, 33, 33, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 33, 17280, 1080, 33, 33, 1080, 17280, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 33, 17280, 1080, 1080, 33, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 33, 17280, 1080, 1080, 1080, 17280, 17280, 33, 33, 1080, 33, 17280, 33, 33, 17280, 33, 1080, 1080, 33, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 33, 33, 17280, 1080, 17280, 33, 1080, 17280, 33, 17280, 1080, 33, 17280, 33, 33, 17280, 33, 33, 1080]
Prompts retrieved: 588576 . Total input tokens: 131231793 . Total output tokens: 117798990
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.553180077986326,
    "estimated_duration": 3600.0981617094176,
    "input_throughput": 6522.528260410065,
    "output_throughput": 5760.944026635135,
    "total_throughput": 12283.4722870452,
    "itl": 148.96350446484377,
    "ttft": 1482864.8576201694,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 625,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0224132740474325,
    "arrivals": 195753,
    "finished_requests": 95135,
    "scheduler_time": 103.6554101032545
}
#Debug simulation 
Total elapsed time: 6.5532753900042735. Arrivals time: 0.29428660991834477 Scheduler time: 6.15021397563396 Scheduler overhead time: 0.03690135007491335 Adapter cache time: 0.017352818162180483 Engine time: 0.03754719841526821 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-32/adapters_96_slots_64_rate_1.6-0.1-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-32/adapters_96_slots_64_rate_1.6-0.1-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 33, 17280, 33, 33, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 33, 17280, 1080, 33, 33, 1080, 17280, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 33, 17280, 1080, 1080, 33, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 33, 17280, 1080, 1080, 1080, 17280, 17280, 33, 33, 1080, 33, 17280, 33, 33, 17280, 33, 1080, 1080, 33, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 33, 33, 17280, 1080, 17280, 33, 1080, 17280, 33, 17280, 1080, 33, 17280, 33, 33, 17280, 33, 33, 1080]
Prompts retrieved: 588576 . Total input tokens: 131231793 . Total output tokens: 117798990
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.5004885389935225,
    "estimated_duration": 3600.10713311624,
    "input_throughput": 6522.512006378623,
    "output_throughput": 5760.929670458879,
    "total_throughput": 12283.441676837501,
    "itl": 148.96371021422095,
    "ttft": 1482869.347410874,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 625,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.029004338420939,
    "arrivals": 195753,
    "finished_requests": 95135,
    "scheduler_time": 103.65551697706466
}
#Debug simulation 
Total elapsed time: 6.500629991991445. Arrivals time: 0.29117221804335713 Scheduler time: 6.101558760972694 Scheduler overhead time: 0.03647506673587486 Adapter cache time: 0.017103313002735376 Engine time: 0.037329890590626746 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-16-16/adapters_96_slots_64_rate_1.6-0.1-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-16-16/adapters_96_slots_64_rate_1.6-0.1-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 33, 17280, 33, 33, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 33, 17280, 1080, 33, 33, 1080, 17280, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 33, 17280, 1080, 1080, 33, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 33, 17280, 1080, 1080, 1080, 17280, 17280, 33, 33, 1080, 33, 17280, 33, 33, 17280, 33, 1080, 1080, 33, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 33, 33, 17280, 1080, 17280, 33, 1080, 17280, 33, 17280, 1080, 33, 17280, 33, 33, 17280, 33, 33, 1080]
Prompts retrieved: 588576 . Total input tokens: 131231793 . Total output tokens: 117798990
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 6.5324596330174245,
    "estimated_duration": 3600.0680779897534,
    "input_throughput": 6522.618598121642,
    "output_throughput": 5761.1299427374415,
    "total_throughput": 12283.748540859084,
    "itl": 148.95697413878577,
    "ttft": 1482828.6540031016,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 624,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9458760664332524,
    "arrivals": 195753,
    "finished_requests": 95136,
    "scheduler_time": 103.65782883604636
}
#Debug simulation 
Total elapsed time: 6.532555645972025. Arrivals time: 0.29511687089689076 Scheduler time: 6.1282343015191145 Scheduler overhead time: 0.036780140246264637 Adapter cache time: 0.017591278592590243 Engine time: 0.03779190720524639 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-16-32/adapters_96_slots_64_rate_1.6-0.1-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-16-32/adapters_96_slots_64_rate_1.6-0.1-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 33, 17280, 33, 33, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 33, 17280, 1080, 33, 33, 1080, 17280, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 33, 17280, 1080, 1080, 33, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 33, 17280, 1080, 1080, 1080, 17280, 17280, 33, 33, 1080, 33, 17280, 33, 33, 17280, 33, 1080, 1080, 33, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 33, 33, 17280, 1080, 17280, 33, 1080, 17280, 33, 17280, 1080, 33, 17280, 33, 33, 17280, 33, 33, 1080]
Prompts retrieved: 588576 . Total input tokens: 131231793 . Total output tokens: 117798990
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 6.493580873007886,
    "estimated_duration": 3600.129181627721,
    "input_throughput": 6522.472060122918,
    "output_throughput": 5760.894388412716,
    "total_throughput": 12283.366448535633,
    "itl": 148.96413537757573,
    "ttft": 1482877.8180541063,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 625,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.051640019975607,
    "arrivals": 195753,
    "finished_requests": 95135,
    "scheduler_time": 103.6556707343745
}
#Debug simulation 
Total elapsed time: 6.4937070939922705. Arrivals time: 0.28843585262075067 Scheduler time: 6.0968674282194115 Scheduler overhead time: 0.036508641263935715 Adapter cache time: 0.017219925299286842 Engine time: 0.0375118765514344 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_16-16-16/adapters_96_slots_64_rate_1.6-0.1-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_16-16-16/adapters_96_slots_64_rate_1.6-0.1-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 33, 17280, 33, 33, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 33, 17280, 1080, 33, 33, 1080, 17280, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 33, 17280, 1080, 1080, 33, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 33, 17280, 1080, 1080, 1080, 17280, 17280, 33, 33, 1080, 33, 17280, 33, 33, 17280, 33, 1080, 1080, 33, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 33, 33, 17280, 1080, 17280, 33, 1080, 17280, 33, 17280, 1080, 33, 17280, 33, 33, 17280, 33, 33, 1080]
Prompts retrieved: 588576 . Total input tokens: 131231793 . Total output tokens: 117798990
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.50098984799115,
    "estimated_duration": 3600.1587734723266,
    "input_throughput": 6522.5587196398965,
    "output_throughput": 5761.2489629158945,
    "total_throughput": 12283.807682555791,
    "itl": 148.95651730688326,
    "ttft": 1482766.0427721385,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 627,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8747615349036344,
    "arrivals": 195753,
    "finished_requests": 95140,
    "scheduler_time": 103.66128258840473
}
#Debug simulation 
Total elapsed time: 6.501134717953391. Arrivals time: 0.2931433985941112 Scheduler time: 6.0992685770615935 Scheduler overhead time: 0.0367000934202224 Adapter cache time: 0.017368402855936438 Engine time: 0.03760765719925985 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_16-16-32/adapters_96_slots_64_rate_1.6-0.1-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_16-16-32/adapters_96_slots_64_rate_1.6-0.1-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 33, 17280, 33, 33, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 33, 17280, 1080, 33, 33, 1080, 17280, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 33, 17280, 1080, 1080, 33, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 33, 17280, 1080, 1080, 1080, 17280, 17280, 33, 33, 1080, 33, 17280, 33, 33, 17280, 33, 1080, 1080, 33, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 33, 33, 17280, 1080, 17280, 33, 1080, 17280, 33, 17280, 1080, 33, 17280, 33, 33, 17280, 33, 33, 1080]
Prompts retrieved: 588576 . Total input tokens: 131231793 . Total output tokens: 117798990
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.510034431004897,
    "estimated_duration": 3600.019417045627,
    "input_throughput": 6522.60676395746,
    "output_throughput": 5760.907538943185,
    "total_throughput": 12283.514302900645,
    "itl": 148.9653851443062,
    "ttft": 1482856.5847561155,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 626,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0793312809616302,
    "arrivals": 195753,
    "finished_requests": 95133,
    "scheduler_time": 103.65133558158414
}
#Debug simulation 
Total elapsed time: 6.510130351991393. Arrivals time: 0.28890506067546085 Scheduler time: 6.113242883759085 Scheduler overhead time: 0.03659219399560243 Adapter cache time: 0.01728009182261303 Engine time: 0.03725664294324815 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-8-8/adapters_96_slots_64_rate_1.6-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-8-8/adapters_96_slots_64_rate_1.6-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 270, 17280, 270, 270, 17280, 540, 17280, 540, 17280, 17280, 540, 270, 17280, 540, 270, 270, 540, 17280, 270, 540, 270, 270, 540, 540, 540, 270, 270, 17280, 540, 540, 270, 17280, 17280, 540, 17280, 17280, 540, 17280, 270, 17280, 540, 540, 540, 17280, 17280, 270, 270, 540, 270, 17280, 270, 270, 17280, 270, 540, 540, 270, 540, 17280, 17280, 17280, 540, 17280, 17280, 270, 270, 17280, 540, 17280, 270, 540, 17280, 270, 17280, 540, 270, 17280, 270, 270, 17280, 270, 270, 540]
Prompts retrieved: 578880 . Total input tokens: 129047310 . Total output tokens: 115859917
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.445533478050493,
    "estimated_duration": 3600.0349034982123,
    "input_throughput": 6434.309838910567,
    "output_throughput": 5675.593583869303,
    "total_throughput": 12109.90342277987,
    "itl": 151.24649297657172,
    "ttft": 1490737.6735585514,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1908,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.839410615423861,
    "arrivals": 192543,
    "finished_requests": 93138,
    "scheduler_time": 102.01088910939204
}
#Debug simulation 
Total elapsed time: 6.4456563730491325. Arrivals time: 0.28400321741355583 Scheduler time: 6.044207152619492 Scheduler overhead time: 0.03683976427419111 Adapter cache time: 0.026081990741658956 Engine time: 0.03743853740161285 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-8-16/adapters_96_slots_64_rate_1.6-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-8-16/adapters_96_slots_64_rate_1.6-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 270, 17280, 270, 270, 17280, 540, 17280, 540, 17280, 17280, 540, 270, 17280, 540, 270, 270, 540, 17280, 270, 540, 270, 270, 540, 540, 540, 270, 270, 17280, 540, 540, 270, 17280, 17280, 540, 17280, 17280, 540, 17280, 270, 17280, 540, 540, 540, 17280, 17280, 270, 270, 540, 270, 17280, 270, 270, 17280, 270, 540, 540, 270, 540, 17280, 17280, 17280, 540, 17280, 17280, 270, 270, 17280, 540, 17280, 270, 540, 17280, 270, 17280, 540, 270, 17280, 270, 270, 17280, 270, 270, 540]
Prompts retrieved: 578880 . Total input tokens: 129047310 . Total output tokens: 115859917
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.450905081990641,
    "estimated_duration": 3600.128880215257,
    "input_throughput": 6433.466070418887,
    "output_throughput": 5674.545184276434,
    "total_throughput": 12108.011254695322,
    "itl": 151.2605778913886,
    "ttft": 1490889.908968011,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1906,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.232661347966443,
    "arrivals": 192543,
    "finished_requests": 93126,
    "scheduler_time": 102.00304109397841
}
#Debug simulation 
Total elapsed time: 6.45105741097359. Arrivals time: 0.2870767388958484 Scheduler time: 6.046155845746398 Scheduler overhead time: 0.03706296317977831 Adapter cache time: 0.026112419844139367 Engine time: 0.03730782575439662 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-8-32/adapters_96_slots_64_rate_1.6-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-8-32/adapters_96_slots_64_rate_1.6-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 270, 17280, 270, 270, 17280, 540, 17280, 540, 17280, 17280, 540, 270, 17280, 540, 270, 270, 540, 17280, 270, 540, 270, 270, 540, 540, 540, 270, 270, 17280, 540, 540, 270, 17280, 17280, 540, 17280, 17280, 540, 17280, 270, 17280, 540, 540, 540, 17280, 17280, 270, 270, 540, 270, 17280, 270, 270, 17280, 270, 540, 540, 270, 540, 17280, 17280, 17280, 540, 17280, 17280, 270, 270, 17280, 540, 17280, 270, 540, 17280, 270, 17280, 540, 270, 17280, 270, 270, 17280, 270, 270, 540]
Prompts retrieved: 578880 . Total input tokens: 129047310 . Total output tokens: 115859917
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.476240630028769,
    "estimated_duration": 3600.1359245145127,
    "input_throughput": 6433.453482210775,
    "output_throughput": 5674.5340810305415,
    "total_throughput": 12107.987563241317,
    "itl": 151.25985180749885,
    "ttft": 1490906.1710208165,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1906,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.24139215361323,
    "arrivals": 192543,
    "finished_requests": 93126,
    "scheduler_time": 102.00356400613872
}
#Debug simulation 
Total elapsed time: 6.476356715022121. Arrivals time: 0.29295752523466945 Scheduler time: 6.066780839872081 Scheduler overhead time: 0.036859137122519314 Adapter cache time: 0.02577824064064771 Engine time: 0.03694327193079516 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-16-16/adapters_96_slots_64_rate_1.6-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-16-16/adapters_96_slots_64_rate_1.6-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 270, 17280, 270, 270, 17280, 540, 17280, 540, 17280, 17280, 540, 270, 17280, 540, 270, 270, 540, 17280, 270, 540, 270, 270, 540, 540, 540, 270, 270, 17280, 540, 540, 270, 17280, 17280, 540, 17280, 17280, 540, 17280, 270, 17280, 540, 540, 540, 17280, 17280, 270, 270, 540, 270, 17280, 270, 270, 17280, 270, 540, 540, 270, 540, 17280, 17280, 17280, 540, 17280, 17280, 270, 270, 17280, 540, 17280, 270, 540, 17280, 270, 17280, 540, 270, 17280, 270, 270, 17280, 270, 270, 540]
Prompts retrieved: 578880 . Total input tokens: 129047310 . Total output tokens: 115859917
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 6.421173351991456,
    "estimated_duration": 3600.1637730518846,
    "input_throughput": 6434.07979753208,
    "output_throughput": 5675.544582984038,
    "total_throughput": 12109.62438051612,
    "itl": 151.25183923073112,
    "ttft": 1490771.3491870773,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1907,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.969655845956706,
    "arrivals": 192543,
    "finished_requests": 93139,
    "scheduler_time": 102.01111991082952
}
#Debug simulation 
Total elapsed time: 6.421295717009343. Arrivals time: 0.29051834903657436 Scheduler time: 6.013022136874497 Scheduler overhead time: 0.03724587231408805 Adapter cache time: 0.025980693520978093 Engine time: 0.03755427623400465 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-16-32/adapters_96_slots_64_rate_1.6-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-16-32/adapters_96_slots_64_rate_1.6-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 270, 17280, 270, 270, 17280, 540, 17280, 540, 17280, 17280, 540, 270, 17280, 540, 270, 270, 540, 17280, 270, 540, 270, 270, 540, 540, 540, 270, 270, 17280, 540, 540, 270, 17280, 17280, 540, 17280, 17280, 540, 17280, 270, 17280, 540, 540, 540, 17280, 17280, 270, 270, 540, 270, 17280, 270, 270, 17280, 270, 540, 540, 270, 540, 17280, 17280, 17280, 540, 17280, 17280, 270, 270, 17280, 540, 17280, 270, 540, 17280, 270, 17280, 540, 270, 17280, 270, 270, 17280, 270, 270, 540]
Prompts retrieved: 578880 . Total input tokens: 129047310 . Total output tokens: 115859917
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 6.441147051984444,
    "estimated_duration": 3600.0619147602642,
    "input_throughput": 6433.295745565612,
    "output_throughput": 5674.5343507127955,
    "total_throughput": 12107.830096278409,
    "itl": 151.26310455903206,
    "ttft": 1490879.7633665914,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1907,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.326890142485394,
    "arrivals": 192543,
    "finished_requests": 93123,
    "scheduler_time": 101.99896683582017
}
#Debug simulation 
Total elapsed time: 6.4412962589995. Arrivals time: 0.28435427643125877 Scheduler time: 6.0395235304604284 Scheduler overhead time: 0.036848415271379054 Adapter cache time: 0.025850724428892136 Engine time: 0.037519233010243624 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_16-16-16/adapters_96_slots_64_rate_1.6-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_16-16-16/adapters_96_slots_64_rate_1.6-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 270, 17280, 270, 270, 17280, 540, 17280, 540, 17280, 17280, 540, 270, 17280, 540, 270, 270, 540, 17280, 270, 540, 270, 270, 540, 540, 540, 270, 270, 17280, 540, 540, 270, 17280, 17280, 540, 17280, 17280, 540, 17280, 270, 17280, 540, 540, 540, 17280, 17280, 270, 270, 540, 270, 17280, 270, 270, 17280, 270, 540, 540, 270, 540, 17280, 17280, 17280, 540, 17280, 17280, 270, 270, 17280, 540, 17280, 270, 540, 17280, 270, 17280, 540, 270, 17280, 270, 270, 17280, 270, 270, 540]
Prompts retrieved: 578880 . Total input tokens: 129047310 . Total output tokens: 115859917
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.443740325979888,
    "estimated_duration": 3600.055594360678,
    "input_throughput": 6434.340913036266,
    "output_throughput": 5675.716239495632,
    "total_throughput": 12110.057152531897,
    "itl": 151.239337773057,
    "ttft": 1490706.7949202762,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1908,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.705015962673185,
    "arrivals": 192543,
    "finished_requests": 93141,
    "scheduler_time": 102.01524692051038
}
#Debug simulation 
Total elapsed time: 6.443849245959427. Arrivals time: 0.2873790603480302 Scheduler time: 6.0398691649897955 Scheduler overhead time: 0.036642965220380574 Adapter cache time: 0.025813596381340176 Engine time: 0.037239772849716246 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_16-16-32/adapters_96_slots_64_rate_1.6-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_16-16-32/adapters_96_slots_64_rate_1.6-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 270, 17280, 270, 270, 17280, 540, 17280, 540, 17280, 17280, 540, 270, 17280, 540, 270, 270, 540, 17280, 270, 540, 270, 270, 540, 540, 540, 270, 270, 17280, 540, 540, 270, 17280, 17280, 540, 17280, 17280, 540, 17280, 270, 17280, 540, 540, 540, 17280, 17280, 270, 270, 540, 270, 17280, 270, 270, 17280, 270, 540, 540, 270, 540, 17280, 17280, 17280, 540, 17280, 17280, 270, 270, 17280, 540, 17280, 270, 540, 17280, 270, 17280, 540, 270, 17280, 270, 270, 17280, 270, 270, 540]
Prompts retrieved: 578880 . Total input tokens: 129047310 . Total output tokens: 115859917
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.431946441996843,
    "estimated_duration": 3600.0114841079967,
    "input_throughput": 6432.913923256047,
    "output_throughput": 5674.4388428143075,
    "total_throughput": 12107.352766070355,
    "itl": 151.26822450107704,
    "ttft": 1490908.596307713,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1906,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.405626598670907,
    "arrivals": 192543,
    "finished_requests": 93119,
    "scheduler_time": 101.99526922032267
}
#Debug simulation 
Total elapsed time: 6.4320704390411265. Arrivals time: 0.28255964984418824 Scheduler time: 6.033274057612289 Scheduler overhead time: 0.03665296663530171 Adapter cache time: 0.02557091589551419 Engine time: 0.03703487728489563 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-8/adapters_96_slots_64_rate_1.6-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-8/adapters_96_slots_64_rate_1.6-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 135, 17280, 135, 135, 17280, 540, 17280, 540, 17280, 17280, 540, 135, 17280, 540, 135, 135, 540, 17280, 135, 540, 135, 135, 540, 540, 540, 135, 135, 17280, 540, 540, 135, 17280, 17280, 540, 17280, 17280, 540, 17280, 135, 17280, 540, 540, 540, 17280, 17280, 135, 135, 540, 135, 17280, 135, 135, 17280, 135, 540, 540, 135, 540, 17280, 17280, 17280, 540, 17280, 17280, 135, 135, 17280, 540, 17280, 135, 540, 17280, 135, 17280, 540, 135, 17280, 135, 135, 17280, 135, 135, 540]
Prompts retrieved: 574560 . Total input tokens: 128078117 . Total output tokens: 114993343
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.559402656974271,
    "estimated_duration": 3600.120406164368,
    "input_throughput": 6603.351643265739,
    "output_throughput": 5826.91872307402,
    "total_throughput": 12430.270366339759,
    "itl": 147.43241227965774,
    "ttft": 1462462.81201048,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1403,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.293864304737767,
    "arrivals": 191076,
    "finished_requests": 95541,
    "scheduler_time": 104.63261122115026
}
#Debug simulation 
Total elapsed time: 6.559575829014648. Arrivals time: 0.2942255064845085 Scheduler time: 6.150777563510928 Scheduler overhead time: 0.03703359357314184 Adapter cache time: 0.022818448836915195 Engine time: 0.037594354478642344 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-16/adapters_96_slots_64_rate_1.6-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-16/adapters_96_slots_64_rate_1.6-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 135, 17280, 135, 135, 17280, 540, 17280, 540, 17280, 17280, 540, 135, 17280, 540, 135, 135, 540, 17280, 135, 540, 135, 135, 540, 540, 540, 135, 135, 17280, 540, 540, 135, 17280, 17280, 540, 17280, 17280, 540, 17280, 135, 17280, 540, 540, 540, 17280, 17280, 135, 135, 540, 135, 17280, 135, 135, 17280, 135, 540, 540, 135, 540, 17280, 17280, 17280, 540, 17280, 17280, 135, 135, 17280, 540, 17280, 135, 540, 17280, 135, 17280, 540, 135, 17280, 135, 135, 17280, 135, 135, 540]
Prompts retrieved: 574560 . Total input tokens: 128078117 . Total output tokens: 114993343
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.55430623202119,
    "estimated_duration": 3600.094386900483,
    "input_throughput": 6602.8282720847155,
    "output_throughput": 5826.5552915293165,
    "total_throughput": 12429.383563614032,
    "itl": 147.44193910915016,
    "ttft": 1462530.6155922317,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1405,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.581422905805471,
    "arrivals": 191076,
    "finished_requests": 95534,
    "scheduler_time": 104.62465927354252
}
#Debug simulation 
Total elapsed time: 6.554403660004027. Arrivals time: 0.2980900830007158 Scheduler time: 6.141577463306021 Scheduler overhead time: 0.03728967177448794 Adapter cache time: 0.02286771940998733 Engine time: 0.037695308157708496 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-32/adapters_96_slots_64_rate_1.6-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-32/adapters_96_slots_64_rate_1.6-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 135, 17280, 135, 135, 17280, 540, 17280, 540, 17280, 17280, 540, 135, 17280, 540, 135, 135, 540, 17280, 135, 540, 135, 135, 540, 540, 540, 135, 135, 17280, 540, 540, 135, 17280, 17280, 540, 17280, 17280, 540, 17280, 135, 17280, 540, 540, 540, 17280, 17280, 135, 135, 540, 135, 17280, 135, 135, 17280, 135, 540, 540, 135, 540, 17280, 17280, 17280, 540, 17280, 17280, 135, 135, 17280, 540, 17280, 135, 540, 17280, 135, 17280, 540, 135, 17280, 135, 135, 17280, 135, 135, 540]
Prompts retrieved: 574560 . Total input tokens: 128078117 . Total output tokens: 114993343
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.540607294999063,
    "estimated_duration": 3600.106578533291,
    "input_throughput": 6602.805911841752,
    "output_throughput": 5826.535560107176,
    "total_throughput": 12429.341471948928,
    "itl": 147.44235786404636,
    "ttft": 1462533.42608772,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1405,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.59012139992783,
    "arrivals": 191076,
    "finished_requests": 95534,
    "scheduler_time": 104.62475202732136
}
#Debug simulation 
Total elapsed time: 6.540705315012019. Arrivals time: 0.2897657783469185 Scheduler time: 6.137371756252833 Scheduler overhead time: 0.03694125881884247 Adapter cache time: 0.022608869592659175 Engine time: 0.03702535020420328 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-16-16/adapters_96_slots_64_rate_1.6-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-16-16/adapters_96_slots_64_rate_1.6-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 135, 17280, 135, 135, 17280, 540, 17280, 540, 17280, 17280, 540, 135, 17280, 540, 135, 135, 540, 17280, 135, 540, 135, 135, 540, 540, 540, 135, 135, 17280, 540, 540, 135, 17280, 17280, 540, 17280, 17280, 540, 17280, 135, 17280, 540, 540, 540, 17280, 17280, 135, 135, 540, 135, 17280, 135, 135, 17280, 135, 540, 540, 135, 540, 17280, 17280, 17280, 540, 17280, 17280, 135, 135, 17280, 540, 17280, 135, 540, 17280, 135, 17280, 540, 135, 17280, 135, 135, 17280, 135, 135, 540]
Prompts retrieved: 574560 . Total input tokens: 128078117 . Total output tokens: 114993343
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 6.460889036010485,
    "estimated_duration": 3600.0698631152627,
    "input_throughput": 6603.245187977868,
    "output_throughput": 5826.869976864218,
    "total_throughput": 12430.115164842086,
    "itl": 147.43637118784503,
    "ttft": 1462509.7523982292,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1405,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.392243273367565,
    "arrivals": 191076,
    "finished_requests": 95539,
    "scheduler_time": 104.62835706185587
}
#Debug simulation 
Total elapsed time: 6.461020527000073. Arrivals time: 0.2755461488268338 Scheduler time: 6.072964161343407 Scheduler overhead time: 0.036707188468426466 Adapter cache time: 0.022117081738542765 Engine time: 0.03682924713939428 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-16-32/adapters_96_slots_64_rate_1.6-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-16-32/adapters_96_slots_64_rate_1.6-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 135, 17280, 135, 135, 17280, 540, 17280, 540, 17280, 17280, 540, 135, 17280, 540, 135, 135, 540, 17280, 135, 540, 135, 135, 540, 540, 540, 135, 135, 17280, 540, 540, 135, 17280, 17280, 540, 17280, 17280, 540, 17280, 135, 17280, 540, 540, 540, 17280, 17280, 135, 135, 540, 135, 17280, 135, 135, 17280, 135, 540, 540, 135, 540, 17280, 17280, 17280, 540, 17280, 17280, 135, 135, 17280, 540, 17280, 135, 540, 17280, 135, 17280, 540, 135, 17280, 135, 135, 17280, 135, 135, 540]
Prompts retrieved: 574560 . Total input tokens: 128078117 . Total output tokens: 114993343
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 6.50611255702097,
    "estimated_duration": 3600.169954698414,
    "input_throughput": 6602.6896782963895,
    "output_throughput": 5826.432991760571,
    "total_throughput": 12429.12267005696,
    "itl": 147.44436807550042,
    "ttft": 1462552.5844195536,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1403,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.641921117845899,
    "arrivals": 191076,
    "finished_requests": 95534,
    "scheduler_time": 104.62510292095197
}
#Debug simulation 
Total elapsed time: 6.5062084890087135. Arrivals time: 0.27996557956794277 Scheduler time: 6.113681269518565 Scheduler overhead time: 0.0367337028728798 Adapter cache time: 0.022134655388072133 Engine time: 0.03688205126672983 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_16-16-16/adapters_96_slots_64_rate_1.6-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_16-16-16/adapters_96_slots_64_rate_1.6-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 135, 17280, 135, 135, 17280, 540, 17280, 540, 17280, 17280, 540, 135, 17280, 540, 135, 135, 540, 17280, 135, 540, 135, 135, 540, 540, 540, 135, 135, 17280, 540, 540, 135, 17280, 17280, 540, 17280, 17280, 540, 17280, 135, 17280, 540, 540, 540, 17280, 17280, 135, 135, 540, 135, 17280, 135, 135, 17280, 135, 540, 540, 135, 540, 17280, 17280, 17280, 540, 17280, 17280, 135, 135, 17280, 540, 17280, 135, 540, 17280, 135, 17280, 540, 135, 17280, 135, 135, 17280, 135, 135, 540]
Prompts retrieved: 574560 . Total input tokens: 128078117 . Total output tokens: 114993343
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.510281735972967,
    "estimated_duration": 3600.1698157915125,
    "input_throughput": 6603.970428204058,
    "output_throughput": 5827.270121531099,
    "total_throughput": 12431.240549735157,
    "itl": 147.42890701456386,
    "ttft": 1462415.0662802092,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1403,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.19504056374764,
    "arrivals": 191076,
    "finished_requests": 95547,
    "scheduler_time": 104.637063606899
}
#Debug simulation 
Total elapsed time: 6.510395199002232. Arrivals time: 0.2827872831840068 Scheduler time: 6.113925073761493 Scheduler overhead time: 0.03701924707274884 Adapter cache time: 0.022261759266257286 Engine time: 0.037540008197538555 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_16-16-32/adapters_96_slots_64_rate_1.6-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_16-16-32/adapters_96_slots_64_rate_1.6-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 135, 17280, 135, 135, 17280, 540, 17280, 540, 17280, 17280, 540, 135, 17280, 540, 135, 135, 540, 17280, 135, 540, 135, 135, 540, 540, 540, 135, 135, 17280, 540, 540, 135, 17280, 17280, 540, 17280, 17280, 540, 17280, 135, 17280, 540, 540, 540, 17280, 17280, 135, 135, 540, 135, 17280, 135, 135, 17280, 135, 540, 540, 135, 540, 17280, 17280, 17280, 540, 17280, 17280, 135, 135, 17280, 540, 17280, 135, 540, 17280, 135, 17280, 540, 135, 17280, 135, 135, 17280, 135, 135, 540]
Prompts retrieved: 574560 . Total input tokens: 128078117 . Total output tokens: 114993343
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.513438019959722,
    "estimated_duration": 3600.0589390394925,
    "input_throughput": 6602.66079042081,
    "output_throughput": 5826.498775488491,
    "total_throughput": 12429.159565909302,
    "itl": 147.44567490444746,
    "ttft": 1462566.039072556,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1403,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.700648136101657,
    "arrivals": 191076,
    "finished_requests": 95531,
    "scheduler_time": 104.62016535289922
}
#Debug simulation 
Total elapsed time: 6.513596069999039. Arrivals time: 0.2803550582029857 Scheduler time: 6.1192432414973155 Scheduler overhead time: 0.03703521110583097 Adapter cache time: 0.022179100895300508 Engine time: 0.037913073727395386 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-8/adapters_96_slots_64_rate_1.6-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-8/adapters_96_slots_64_rate_1.6-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 66, 17280, 66, 66, 17280, 540, 17280, 540, 17280, 17280, 540, 66, 17280, 540, 66, 66, 540, 17280, 66, 540, 66, 66, 540, 540, 540, 66, 66, 17280, 540, 540, 66, 17280, 17280, 540, 17280, 17280, 540, 17280, 66, 17280, 540, 540, 540, 17280, 17280, 66, 66, 540, 66, 17280, 66, 66, 17280, 66, 540, 540, 66, 540, 17280, 17280, 17280, 540, 17280, 17280, 66, 66, 17280, 540, 17280, 66, 540, 17280, 66, 17280, 540, 66, 17280, 66, 66, 17280, 66, 66, 540]
Prompts retrieved: 572352 . Total input tokens: 127568280 . Total output tokens: 114562164
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.674799998989329,
    "estimated_duration": 3600.0834014858488,
    "input_throughput": 6731.145725679171,
    "output_throughput": 5965.772346033918,
    "total_throughput": 12696.91807171309,
    "itl": 144.37688766482157,
    "ttft": 1425004.4316306824,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 880,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.6932292146608807,
    "arrivals": 190312,
    "finished_requests": 97955,
    "scheduler_time": 106.87027557893414
}
#Debug simulation 
Total elapsed time: 6.6748976549715735. Arrivals time: 0.28918630111729726 Scheduler time: 6.273079071135726 Scheduler overhead time: 0.037540609773714095 Adapter cache time: 0.02033129194751382 Engine time: 0.03761584986932576 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-16/adapters_96_slots_64_rate_1.6-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-16/adapters_96_slots_64_rate_1.6-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 66, 17280, 66, 66, 17280, 540, 17280, 540, 17280, 17280, 540, 66, 17280, 540, 66, 66, 540, 17280, 66, 540, 66, 66, 540, 540, 540, 66, 66, 17280, 540, 540, 66, 17280, 17280, 540, 17280, 17280, 540, 17280, 66, 17280, 540, 540, 540, 17280, 17280, 66, 66, 540, 66, 17280, 66, 66, 17280, 66, 540, 540, 66, 540, 17280, 17280, 17280, 540, 17280, 17280, 66, 66, 17280, 540, 17280, 66, 540, 17280, 66, 17280, 540, 66, 17280, 66, 66, 17280, 66, 66, 540]
Prompts retrieved: 572352 . Total input tokens: 127568280 . Total output tokens: 114562164
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.658163255953696,
    "estimated_duration": 3600.1245745851593,
    "input_throughput": 6730.8679180337085,
    "output_throughput": 5965.624398559815,
    "total_throughput": 12696.492316593523,
    "itl": 144.38398700387674,
    "ttft": 1425066.1592423948,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 878,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.8565291091613503,
    "arrivals": 190312,
    "finished_requests": 97953,
    "scheduler_time": 106.86719535788787
}
#Debug simulation 
Total elapsed time: 6.658260042953771. Arrivals time: 0.28554287482984364 Scheduler time: 6.260222874348983 Scheduler overhead time: 0.03744473913684487 Adapter cache time: 0.020024538913276047 Engine time: 0.0378235443495214 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-32/adapters_96_slots_64_rate_1.6-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-32/adapters_96_slots_64_rate_1.6-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 66, 17280, 66, 66, 17280, 540, 17280, 540, 17280, 17280, 540, 66, 17280, 540, 66, 66, 540, 17280, 66, 540, 66, 66, 540, 540, 540, 66, 66, 17280, 540, 540, 66, 17280, 17280, 540, 17280, 17280, 540, 17280, 66, 17280, 540, 540, 540, 17280, 17280, 66, 66, 540, 66, 17280, 66, 66, 17280, 66, 540, 540, 66, 540, 17280, 17280, 17280, 540, 17280, 17280, 66, 66, 17280, 540, 17280, 66, 540, 17280, 66, 17280, 540, 66, 17280, 66, 66, 17280, 66, 66, 540]
Prompts retrieved: 572352 . Total input tokens: 127568280 . Total output tokens: 114562164
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.679920156020671,
    "estimated_duration": 3600.1447809179276,
    "input_throughput": 6730.830140064974,
    "output_throughput": 5965.590915630904,
    "total_throughput": 12696.421055695879,
    "itl": 144.3847813812792,
    "ttft": 1425068.5518069149,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 878,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.863091631121915,
    "arrivals": 190312,
    "finished_requests": 97953,
    "scheduler_time": 106.86751238936544
}
#Debug simulation 
Total elapsed time: 6.6800459420192055. Arrivals time: 0.2875658455886878 Scheduler time: 6.279336845385842 Scheduler overhead time: 0.03777754376642406 Adapter cache time: 0.019967566418927163 Engine time: 0.03791344480123371 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-16-16/adapters_96_slots_64_rate_1.6-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-16-16/adapters_96_slots_64_rate_1.6-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 66, 17280, 66, 66, 17280, 540, 17280, 540, 17280, 17280, 540, 66, 17280, 540, 66, 66, 540, 17280, 66, 540, 66, 66, 540, 540, 540, 66, 66, 17280, 540, 540, 66, 17280, 17280, 540, 17280, 17280, 540, 17280, 66, 17280, 540, 540, 540, 17280, 17280, 66, 66, 540, 66, 17280, 66, 66, 17280, 66, 540, 540, 66, 540, 17280, 17280, 17280, 540, 17280, 17280, 66, 66, 17280, 540, 17280, 66, 540, 17280, 66, 17280, 540, 66, 17280, 66, 66, 17280, 66, 66, 540]
Prompts retrieved: 572352 . Total input tokens: 127568280 . Total output tokens: 114562164
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 6.717436195991468,
    "estimated_duration": 3600.139090067136,
    "input_throughput": 6731.041605269786,
    "output_throughput": 5965.680064766467,
    "total_throughput": 12696.721670036253,
    "itl": 144.37892746476032,
    "ttft": 1425029.4367918337,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 880,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.743199376766541,
    "arrivals": 190312,
    "finished_requests": 97955,
    "scheduler_time": 106.87063945593178
}
#Debug simulation 
Total elapsed time: 6.717528509965632. Arrivals time: 0.29081933794077486 Scheduler time: 6.311944319517352 Scheduler overhead time: 0.03876148693962023 Adapter cache time: 0.020191922143567353 Engine time: 0.03806324035394937 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-16-32/adapters_96_slots_64_rate_1.6-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-16-32/adapters_96_slots_64_rate_1.6-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 66, 17280, 66, 66, 17280, 540, 17280, 540, 17280, 17280, 540, 66, 17280, 540, 66, 66, 540, 17280, 66, 540, 66, 66, 540, 540, 540, 66, 66, 17280, 540, 540, 66, 17280, 17280, 540, 17280, 17280, 540, 17280, 66, 17280, 540, 540, 540, 17280, 17280, 66, 66, 540, 66, 17280, 66, 66, 17280, 66, 540, 540, 66, 540, 17280, 17280, 17280, 540, 17280, 17280, 66, 66, 17280, 540, 17280, 66, 540, 17280, 66, 17280, 540, 66, 17280, 66, 66, 17280, 66, 66, 540]
Prompts retrieved: 572352 . Total input tokens: 127568280 . Total output tokens: 114562164
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 6.691947406041436,
    "estimated_duration": 3600.034512695405,
    "input_throughput": 6731.000748617053,
    "output_throughput": 5965.7180852746815,
    "total_throughput": 12696.718833891735,
    "itl": 144.3865095909741,
    "ttft": 1425027.6922554562,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 878,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.900274738036102,
    "arrivals": 190312,
    "finished_requests": 97951,
    "scheduler_time": 106.86350708618384
}
#Debug simulation 
Total elapsed time: 6.692040725029074. Arrivals time: 0.2868207829305902 Scheduler time: 6.292790129664354 Scheduler overhead time: 0.037611147155985236 Adapter cache time: 0.019911032228264958 Engine time: 0.037492825533263385 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_16-16-16/adapters_96_slots_64_rate_1.6-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_16-16-16/adapters_96_slots_64_rate_1.6-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 66, 17280, 66, 66, 17280, 540, 17280, 540, 17280, 17280, 540, 66, 17280, 540, 66, 66, 540, 17280, 66, 540, 66, 66, 540, 540, 540, 66, 66, 17280, 540, 540, 66, 17280, 17280, 540, 17280, 17280, 540, 17280, 66, 17280, 540, 540, 540, 17280, 17280, 66, 66, 540, 66, 17280, 66, 66, 17280, 66, 540, 540, 66, 540, 17280, 17280, 17280, 540, 17280, 17280, 66, 66, 17280, 540, 17280, 66, 540, 17280, 66, 17280, 540, 66, 17280, 66, 66, 17280, 66, 66, 540]
Prompts retrieved: 572352 . Total input tokens: 127568280 . Total output tokens: 114562164
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.654661418986507,
    "estimated_duration": 3600.014084878664,
    "input_throughput": 6731.275330778809,
    "output_throughput": 5965.887214222907,
    "total_throughput": 12697.162545001715,
    "itl": 144.37482058071214,
    "ttft": 1424977.4197269848,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 880,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.631244259513858,
    "arrivals": 190312,
    "finished_requests": 97955,
    "scheduler_time": 106.8698353192083
}
#Debug simulation 
Total elapsed time: 6.654798296978697. Arrivals time: 0.28746527404291555 Scheduler time: 6.254824313218705 Scheduler overhead time: 0.037456874328199774 Adapter cache time: 0.020271159533876926 Engine time: 0.037489159556571394 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_16-16-32/adapters_96_slots_64_rate_1.6-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_16-16-32/adapters_96_slots_64_rate_1.6-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 66, 17280, 66, 66, 17280, 540, 17280, 540, 17280, 17280, 540, 66, 17280, 540, 66, 66, 540, 17280, 66, 540, 66, 66, 540, 540, 540, 66, 66, 17280, 540, 540, 66, 17280, 17280, 540, 17280, 17280, 540, 17280, 66, 17280, 540, 540, 540, 17280, 17280, 66, 66, 540, 66, 17280, 66, 66, 17280, 66, 540, 540, 66, 540, 17280, 17280, 17280, 540, 17280, 17280, 66, 66, 17280, 540, 17280, 66, 540, 17280, 66, 17280, 540, 66, 17280, 66, 66, 17280, 66, 66, 540]
Prompts retrieved: 572352 . Total input tokens: 127568280 . Total output tokens: 114562164
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.669941679982003,
    "estimated_duration": 3600.072110506556,
    "input_throughput": 6730.930452554298,
    "output_throughput": 5965.655781538793,
    "total_throughput": 12696.58623409309,
    "itl": 144.38787356208567,
    "ttft": 1425043.467511277,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 878,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.9347312755137938,
    "arrivals": 190312,
    "finished_requests": 97951,
    "scheduler_time": 106.86379630824474
}
#Debug simulation 
Total elapsed time: 6.670033439993858. Arrivals time: 0.2874981692293659 Scheduler time: 6.270310106338002 Scheduler overhead time: 0.03747431602096185 Adapter cache time: 0.01992206770228222 Engine time: 0.03756228485144675 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-8/adapters_96_slots_64_rate_1.6-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-8/adapters_96_slots_64_rate_1.6-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 33, 17280, 33, 33, 17280, 540, 17280, 540, 17280, 17280, 540, 33, 17280, 540, 33, 33, 540, 17280, 33, 540, 33, 33, 540, 540, 540, 33, 33, 17280, 540, 540, 33, 17280, 17280, 540, 17280, 17280, 540, 17280, 33, 17280, 540, 540, 540, 17280, 17280, 33, 33, 540, 33, 17280, 33, 33, 17280, 33, 540, 540, 33, 540, 17280, 17280, 17280, 540, 17280, 17280, 33, 33, 17280, 540, 17280, 33, 540, 17280, 33, 17280, 540, 33, 17280, 33, 33, 17280, 33, 33, 540]
Prompts retrieved: 571296 . Total input tokens: 127344419 . Total output tokens: 114344834
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.731957543990575,
    "estimated_duration": 3600.0742294041115,
    "input_throughput": 6770.948443481047,
    "output_throughput": 6021.937498657744,
    "total_throughput": 12792.885942138792,
    "itl": 143.22565770682385,
    "ttft": 1416254.5338714893,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 578,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.768961915993157,
    "arrivals": 189952,
    "finished_requests": 98766,
    "scheduler_time": 107.79544842949122
}
#Debug simulation 
Total elapsed time: 6.732050090970006. Arrivals time: 0.28755622066091746 Scheduler time: 6.332233457418624 Scheduler overhead time: 0.03807503799907863 Adapter cache time: 0.018405070761218667 Engine time: 0.038252067752182484 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-16/adapters_96_slots_64_rate_1.6-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-16/adapters_96_slots_64_rate_1.6-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 33, 17280, 33, 33, 17280, 540, 17280, 540, 17280, 17280, 540, 33, 17280, 540, 33, 33, 540, 17280, 33, 540, 33, 33, 540, 540, 540, 33, 33, 17280, 540, 540, 33, 17280, 17280, 540, 17280, 17280, 540, 17280, 33, 17280, 540, 540, 540, 17280, 17280, 33, 33, 540, 33, 17280, 33, 33, 17280, 33, 540, 540, 33, 540, 17280, 17280, 17280, 540, 17280, 17280, 33, 33, 17280, 540, 17280, 33, 540, 17280, 33, 17280, 540, 33, 17280, 33, 33, 17280, 33, 33, 540]
Prompts retrieved: 571296 . Total input tokens: 127344419 . Total output tokens: 114344834
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.718849010008853,
    "estimated_duration": 3600.0207178132828,
    "input_throughput": 6770.770756787689,
    "output_throughput": 6021.832289111949,
    "total_throughput": 12792.603045899637,
    "itl": 143.22902788617859,
    "ttft": 1416236.4863239122,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 576,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8697718798206222,
    "arrivals": 189952,
    "finished_requests": 98762,
    "scheduler_time": 107.79173936256667
}
#Debug simulation 
Total elapsed time: 6.718982429010794. Arrivals time: 0.2885377411148511 Scheduler time: 6.3191424298565835 Scheduler overhead time: 0.03781639342196286 Adapter cache time: 0.01820466574281454 Engine time: 0.03787930845282972 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-32/adapters_96_slots_64_rate_1.6-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-32/adapters_96_slots_64_rate_1.6-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 33, 17280, 33, 33, 17280, 540, 17280, 540, 17280, 17280, 540, 33, 17280, 540, 33, 33, 540, 17280, 33, 540, 33, 33, 540, 540, 540, 33, 33, 17280, 540, 540, 33, 17280, 17280, 540, 17280, 17280, 540, 17280, 33, 17280, 540, 540, 540, 17280, 17280, 33, 33, 540, 33, 17280, 33, 33, 17280, 33, 540, 540, 33, 540, 17280, 17280, 17280, 540, 17280, 17280, 33, 33, 17280, 540, 17280, 33, 540, 17280, 33, 17280, 540, 33, 17280, 33, 33, 17280, 33, 33, 540]
Prompts retrieved: 571296 . Total input tokens: 127344419 . Total output tokens: 114344834
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.75945353199495,
    "estimated_duration": 3600.02229859573,
    "input_throughput": 6770.767783718447,
    "output_throughput": 6021.829644904221,
    "total_throughput": 12792.597428622668,
    "itl": 143.22909535945035,
    "ttft": 1416237.0197545353,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 577,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8781939687579985,
    "arrivals": 189952,
    "finished_requests": 98762,
    "scheduler_time": 107.79174771189878
}
#Debug simulation 
Total elapsed time: 6.759547391033266. Arrivals time: 0.29070802027126774 Scheduler time: 6.35673053242499 Scheduler overhead time: 0.037838946853298694 Adapter cache time: 0.018596940906718373 Engine time: 0.03820144891506061 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-16-16/adapters_96_slots_64_rate_1.6-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-16-16/adapters_96_slots_64_rate_1.6-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 33, 17280, 33, 33, 17280, 540, 17280, 540, 17280, 17280, 540, 33, 17280, 540, 33, 33, 540, 17280, 33, 540, 33, 33, 540, 540, 540, 33, 33, 17280, 540, 540, 33, 17280, 17280, 540, 17280, 17280, 540, 17280, 33, 17280, 540, 540, 540, 17280, 17280, 33, 33, 540, 33, 17280, 33, 33, 17280, 33, 540, 540, 33, 540, 17280, 17280, 17280, 540, 17280, 17280, 33, 33, 17280, 540, 17280, 33, 540, 17280, 33, 17280, 540, 33, 17280, 33, 33, 17280, 33, 33, 540]
Prompts retrieved: 571296 . Total input tokens: 127344419 . Total output tokens: 114344834
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 6.740943159966264,
    "estimated_duration": 3600.121130739424,
    "input_throughput": 6770.8602335259375,
    "output_throughput": 6021.8590466002715,
    "total_throughput": 12792.719280126208,
    "itl": 143.22650871767092,
    "ttft": 1416258.3487497878,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 578,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8026134184095894,
    "arrivals": 189952,
    "finished_requests": 98766,
    "scheduler_time": 107.79586660063681
}
#Debug simulation 
Total elapsed time: 6.741034103964921. Arrivals time: 0.30822098249336705 Scheduler time: 6.321176559722517 Scheduler overhead time: 0.03801225428469479 Adapter cache time: 0.01822619012091309 Engine time: 0.038068271533120424 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-16-32/adapters_96_slots_64_rate_1.6-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-16-32/adapters_96_slots_64_rate_1.6-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 33, 17280, 33, 33, 17280, 540, 17280, 540, 17280, 17280, 540, 33, 17280, 540, 33, 33, 540, 17280, 33, 540, 33, 33, 540, 540, 540, 33, 33, 17280, 540, 540, 33, 17280, 17280, 540, 17280, 17280, 540, 17280, 33, 17280, 540, 540, 540, 17280, 17280, 33, 33, 540, 33, 17280, 33, 33, 17280, 33, 540, 540, 33, 540, 17280, 17280, 17280, 540, 17280, 17280, 33, 33, 17280, 540, 17280, 33, 540, 17280, 33, 17280, 540, 33, 17280, 33, 33, 17280, 33, 33, 540]
Prompts retrieved: 571296 . Total input tokens: 127344419 . Total output tokens: 114344834
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 6.757902811048552,
    "estimated_duration": 3600.0511451742245,
    "input_throughput": 6770.713530743568,
    "output_throughput": 6021.781393039309,
    "total_throughput": 12792.494923782877,
    "itl": 143.2300483633337,
    "ttft": 1416247.405517062,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 577,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9008296503126663,
    "arrivals": 189952,
    "finished_requests": 98762,
    "scheduler_time": 107.79192507761323
}
#Debug simulation 
Total elapsed time: 6.758024463022593. Arrivals time: 0.314467417425476 Scheduler time: 6.331208271381911 Scheduler overhead time: 0.038026094262022525 Adapter cache time: 0.01836275216192007 Engine time: 0.03845260263187811 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_16-16-16/adapters_96_slots_64_rate_1.6-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_16-16-16/adapters_96_slots_64_rate_1.6-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 33, 17280, 33, 33, 17280, 540, 17280, 540, 17280, 17280, 540, 33, 17280, 540, 33, 33, 540, 17280, 33, 540, 33, 33, 540, 540, 540, 33, 33, 17280, 540, 540, 33, 17280, 17280, 540, 17280, 17280, 540, 17280, 33, 17280, 540, 540, 540, 17280, 17280, 33, 33, 540, 33, 17280, 33, 33, 17280, 33, 540, 540, 33, 540, 17280, 17280, 17280, 540, 17280, 17280, 33, 33, 17280, 540, 17280, 33, 540, 17280, 33, 17280, 540, 33, 17280, 33, 33, 17280, 33, 33, 540]
Prompts retrieved: 571296 . Total input tokens: 127344419 . Total output tokens: 114344834
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.8358341990388,
    "estimated_duration": 3600.008216732026,
    "input_throughput": 6771.072601086364,
    "output_throughput": 6022.0479217905495,
    "total_throughput": 12793.120522876912,
    "itl": 143.22346597236117,
    "ttft": 1416233.2956708178,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 578,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.728249070453433,
    "arrivals": 189952,
    "finished_requests": 98766,
    "scheduler_time": 107.7950548965837
}
#Debug simulation 
Total elapsed time: 6.83593938103877. Arrivals time: 0.3144145265687257 Scheduler time: 6.408536997565534 Scheduler overhead time: 0.03823310189181939 Adapter cache time: 0.018604039039928466 Engine time: 0.03841489675687626 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_16-16-32/adapters_96_slots_64_rate_1.6-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_16-16-32/adapters_96_slots_64_rate_1.6-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 540, 17280, 540, 540, 540, 540, 17280, 540, 17280, 540, 33, 17280, 33, 33, 17280, 540, 17280, 540, 17280, 17280, 540, 33, 17280, 540, 33, 33, 540, 17280, 33, 540, 33, 33, 540, 540, 540, 33, 33, 17280, 540, 540, 33, 17280, 17280, 540, 17280, 17280, 540, 17280, 33, 17280, 540, 540, 540, 17280, 17280, 33, 33, 540, 33, 17280, 33, 33, 17280, 33, 540, 540, 33, 540, 17280, 17280, 17280, 540, 17280, 17280, 33, 33, 17280, 540, 17280, 33, 540, 17280, 33, 17280, 540, 33, 17280, 33, 33, 17280, 33, 33, 540]
Prompts retrieved: 571296 . Total input tokens: 127344419 . Total output tokens: 114344834
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.760672463977244,
    "estimated_duration": 3600.0963998296734,
    "input_throughput": 6770.732584036704,
    "output_throughput": 6021.706252373036,
    "total_throughput": 12792.43883640974,
    "itl": 143.2304717514134,
    "ttft": 1416278.133733979,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 578,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.927223359569904,
    "arrivals": 189952,
    "finished_requests": 98763,
    "scheduler_time": 107.79256217453091
}
#Debug simulation 
Total elapsed time: 6.760782910976559. Arrivals time: 0.28876763622974977 Scheduler time: 6.359929572150577 Scheduler overhead time: 0.03792607854120433 Adapter cache time: 0.018405848590191454 Engine time: 0.0381702653830871 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-8/adapters_96_slots_64_rate_1.6-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-8/adapters_96_slots_64_rate_1.6-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 17280, 270, 270, 270, 270, 17280, 270, 17280, 270, 135, 17280, 135, 135, 17280, 270, 17280, 270, 17280, 17280, 270, 135, 17280, 270, 135, 135, 270, 17280, 135, 270, 135, 135, 270, 270, 270, 135, 135, 17280, 270, 270, 135, 17280, 17280, 270, 17280, 17280, 270, 17280, 135, 17280, 270, 270, 270, 17280, 17280, 135, 135, 270, 135, 17280, 135, 135, 17280, 135, 270, 270, 135, 270, 17280, 17280, 17280, 270, 17280, 17280, 135, 135, 17280, 270, 17280, 135, 270, 17280, 135, 17280, 270, 135, 17280, 135, 135, 17280, 135, 135, 270]
Prompts retrieved: 565920 . Total input tokens: 126139240 . Total output tokens: 113278943
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.802222155965865,
    "estimated_duration": 3600.044290347807,
    "input_throughput": 6948.087574106875,
    "output_throughput": 6103.325189334607,
    "total_throughput": 13051.412763441482,
    "itl": 140.344416358381,
    "ttft": 1385136.95917831,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1098,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.3604155428382443,
    "arrivals": 188134,
    "finished_requests": 100626,
    "scheduler_time": 109.12383396256439
}
#Debug simulation 
Total elapsed time: 6.8023548479541205. Arrivals time: 0.3132303861784749 Scheduler time: 6.374439205508679 Scheduler overhead time: 0.03829495614627376 Adapter cache time: 0.02002982678823173 Engine time: 0.03855056007159874 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-16/adapters_96_slots_64_rate_1.6-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-16/adapters_96_slots_64_rate_1.6-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 17280, 270, 270, 270, 270, 17280, 270, 17280, 270, 135, 17280, 135, 135, 17280, 270, 17280, 270, 17280, 17280, 270, 135, 17280, 270, 135, 135, 270, 17280, 135, 270, 135, 135, 270, 270, 270, 135, 135, 17280, 270, 270, 135, 17280, 17280, 270, 17280, 17280, 270, 17280, 135, 17280, 270, 270, 270, 17280, 17280, 135, 135, 270, 135, 17280, 135, 135, 17280, 135, 270, 270, 135, 270, 17280, 17280, 17280, 270, 17280, 17280, 135, 135, 17280, 270, 17280, 135, 270, 17280, 135, 17280, 270, 135, 17280, 135, 135, 17280, 135, 135, 270]
Prompts retrieved: 565920 . Total input tokens: 126139240 . Total output tokens: 113278943
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.845115292002447,
    "estimated_duration": 3600.011456774692,
    "input_throughput": 6947.603723019305,
    "output_throughput": 6102.91724451449,
    "total_throughput": 13050.520967533796,
    "itl": 140.3535669953874,
    "ttft": 1385279.434776512,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1100,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.597953385133304,
    "arrivals": 188134,
    "finished_requests": 100618,
    "scheduler_time": 109.11548981885038
}
#Debug simulation 
Total elapsed time: 6.845201173971873. Arrivals time: 0.2866626172326505 Scheduler time: 6.442173286632169 Scheduler overhead time: 0.03886326955398545 Adapter cache time: 0.020194945915136486 Engine time: 0.03935831197304651 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-32/adapters_96_slots_64_rate_1.6-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-32/adapters_96_slots_64_rate_1.6-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 17280, 270, 270, 270, 270, 17280, 270, 17280, 270, 135, 17280, 135, 135, 17280, 270, 17280, 270, 17280, 17280, 270, 135, 17280, 270, 135, 135, 270, 17280, 135, 270, 135, 135, 270, 270, 270, 135, 135, 17280, 270, 270, 135, 17280, 17280, 270, 17280, 17280, 270, 17280, 135, 17280, 270, 270, 270, 17280, 17280, 135, 135, 270, 135, 17280, 135, 135, 17280, 135, 270, 270, 135, 270, 17280, 17280, 17280, 270, 17280, 17280, 135, 135, 17280, 270, 17280, 135, 270, 17280, 135, 17280, 270, 135, 17280, 135, 135, 17280, 135, 135, 270]
Prompts retrieved: 565920 . Total input tokens: 126139240 . Total output tokens: 113278943
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.802219762001187,
    "estimated_duration": 3600.0163316670423,
    "input_throughput": 6947.594315056362,
    "output_throughput": 6102.908980367373,
    "total_throughput": 13050.503295423734,
    "itl": 140.35372828987127,
    "ttft": 1385281.4090705896,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1100,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.602829839512655,
    "arrivals": 188134,
    "finished_requests": 100618,
    "scheduler_time": 109.11550458983076
}
#Debug simulation 
Total elapsed time: 6.802310522994958. Arrivals time: 0.2906211194349453 Scheduler time: 6.396871774224564 Scheduler overhead time: 0.03838559158612043 Adapter cache time: 0.02007765369489789 Engine time: 0.03845737298252061 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-16-16/adapters_96_slots_64_rate_1.6-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-16-16/adapters_96_slots_64_rate_1.6-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 17280, 270, 270, 270, 270, 17280, 270, 17280, 270, 135, 17280, 135, 135, 17280, 270, 17280, 270, 17280, 17280, 270, 135, 17280, 270, 135, 135, 270, 17280, 135, 270, 135, 135, 270, 270, 270, 135, 135, 17280, 270, 270, 135, 17280, 17280, 270, 17280, 17280, 270, 17280, 135, 17280, 270, 270, 270, 17280, 17280, 135, 135, 270, 135, 17280, 135, 135, 17280, 135, 270, 270, 135, 270, 17280, 17280, 17280, 270, 17280, 17280, 135, 135, 17280, 270, 17280, 135, 270, 17280, 135, 17280, 270, 135, 17280, 135, 135, 17280, 135, 135, 270]
Prompts retrieved: 565920 . Total input tokens: 126139240 . Total output tokens: 113278943
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 6.85991026397096,
    "estimated_duration": 3600.1416916663866,
    "input_throughput": 6947.899594591266,
    "output_throughput": 6103.1600647445,
    "total_throughput": 13051.059659335766,
    "itl": 140.34788781891055,
    "ttft": 1385174.5650555466,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1099,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.437245541920381,
    "arrivals": 188134,
    "finished_requests": 100626,
    "scheduler_time": 109.12445179311598
}
#Debug simulation 
Total elapsed time: 6.860024304012768. Arrivals time: 0.2893326821504161 Scheduler time: 6.454817301186267 Scheduler overhead time: 0.038934868993237615 Adapter cache time: 0.02006982045713812 Engine time: 0.0390417140442878 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-16-32/adapters_96_slots_64_rate_1.6-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-16-32/adapters_96_slots_64_rate_1.6-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 17280, 270, 270, 270, 270, 17280, 270, 17280, 270, 135, 17280, 135, 135, 17280, 270, 17280, 270, 17280, 17280, 270, 135, 17280, 270, 135, 135, 270, 17280, 135, 270, 135, 135, 270, 270, 270, 135, 135, 17280, 270, 270, 135, 17280, 17280, 270, 17280, 17280, 270, 17280, 135, 17280, 270, 270, 270, 17280, 17280, 135, 135, 270, 135, 17280, 135, 135, 17280, 135, 270, 270, 135, 270, 17280, 17280, 17280, 270, 17280, 17280, 135, 135, 17280, 270, 17280, 135, 270, 17280, 135, 17280, 270, 135, 17280, 135, 135, 17280, 135, 135, 270]
Prompts retrieved: 565920 . Total input tokens: 126139240 . Total output tokens: 113278943
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 6.820205289986916,
    "estimated_duration": 3600.0500043961065,
    "input_throughput": 6947.615163527602,
    "output_throughput": 6103.055227891368,
    "total_throughput": 13050.67039141897,
    "itl": 140.35479978222568,
    "ttft": 1385294.5153572413,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1100,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.6513708010688455,
    "arrivals": 188134,
    "finished_requests": 100619,
    "scheduler_time": 109.1156547840198
}
#Debug simulation 
Total elapsed time: 6.820306551991962. Arrivals time: 0.29510472755646333 Scheduler time: 6.410552895569708 Scheduler overhead time: 0.038525625539477915 Adapter cache time: 0.019941898062825203 Engine time: 0.0385244723292999 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_16-16-16/adapters_96_slots_64_rate_1.6-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_16-16-16/adapters_96_slots_64_rate_1.6-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 17280, 270, 270, 270, 270, 17280, 270, 17280, 270, 135, 17280, 135, 135, 17280, 270, 17280, 270, 17280, 17280, 270, 135, 17280, 270, 135, 135, 270, 17280, 135, 270, 135, 135, 270, 270, 270, 135, 135, 17280, 270, 270, 135, 17280, 17280, 270, 17280, 17280, 270, 17280, 135, 17280, 270, 270, 270, 17280, 17280, 135, 135, 270, 135, 17280, 135, 135, 17280, 135, 270, 270, 135, 270, 17280, 17280, 17280, 270, 17280, 17280, 135, 135, 17280, 270, 17280, 135, 270, 17280, 135, 17280, 270, 135, 17280, 135, 135, 17280, 135, 135, 270]
Prompts retrieved: 565920 . Total input tokens: 126139240 . Total output tokens: 113278943
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.844883779995143,
    "estimated_duration": 3600.120033156386,
    "input_throughput": 6948.380545542041,
    "output_throughput": 6103.510937865859,
    "total_throughput": 13051.8914834079,
    "itl": 140.34225743084446,
    "ttft": 1385104.4359551263,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1097,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.280085173507607,
    "arrivals": 188134,
    "finished_requests": 100631,
    "scheduler_time": 109.12855985406976
}
#Debug simulation 
Total elapsed time: 6.844973260012921. Arrivals time: 0.3128174092271365 Scheduler time: 6.416055685142055 Scheduler overhead time: 0.03878876712406054 Adapter cache time: 0.020243882958311588 Engine time: 0.03917536453809589 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_16-16-32/adapters_96_slots_64_rate_1.6-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_16-16-32/adapters_96_slots_64_rate_1.6-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 17280, 270, 270, 270, 270, 17280, 270, 17280, 270, 135, 17280, 135, 135, 17280, 270, 17280, 270, 17280, 17280, 270, 135, 17280, 270, 135, 135, 270, 17280, 135, 270, 135, 135, 270, 270, 270, 135, 135, 17280, 270, 270, 135, 17280, 17280, 270, 17280, 17280, 270, 17280, 135, 17280, 270, 270, 270, 17280, 17280, 135, 135, 270, 135, 17280, 135, 135, 17280, 135, 270, 270, 135, 270, 17280, 17280, 17280, 270, 17280, 17280, 135, 135, 17280, 270, 17280, 135, 270, 17280, 135, 17280, 270, 135, 17280, 135, 135, 17280, 135, 135, 270]
Prompts retrieved: 565920 . Total input tokens: 126139240 . Total output tokens: 113278943
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.859383684000932,
    "estimated_duration": 3600.105660380047,
    "input_throughput": 6947.507756580572,
    "output_throughput": 6102.960877453966,
    "total_throughput": 13050.468634034538,
    "itl": 140.35670982303597,
    "ttft": 1385314.5017649774,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1100,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.697899702042395,
    "arrivals": 188134,
    "finished_requests": 100619,
    "scheduler_time": 109.11597962498686
}
#Debug simulation 
Total elapsed time: 6.859526737011038. Arrivals time: 0.29070835845777765 Scheduler time: 6.453095193661284 Scheduler overhead time: 0.038779446156695485 Adapter cache time: 0.02018869697349146 Engine time: 0.03888085496146232 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-8/adapters_96_slots_64_rate_1.6-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-8/adapters_96_slots_64_rate_1.6-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 17280, 270, 270, 270, 270, 17280, 270, 17280, 270, 66, 17280, 66, 66, 17280, 270, 17280, 270, 17280, 17280, 270, 66, 17280, 270, 66, 66, 270, 17280, 66, 270, 66, 66, 270, 270, 270, 66, 66, 17280, 270, 270, 66, 17280, 17280, 270, 17280, 17280, 270, 17280, 66, 17280, 270, 270, 270, 17280, 17280, 66, 66, 270, 66, 17280, 66, 66, 17280, 66, 270, 270, 66, 270, 17280, 17280, 17280, 270, 17280, 17280, 66, 66, 17280, 270, 17280, 66, 270, 17280, 66, 17280, 270, 66, 17280, 66, 66, 17280, 66, 66, 270]
Prompts retrieved: 563712 . Total input tokens: 125628176 . Total output tokens: 112839488
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.994538324011955,
    "estimated_duration": 3600.1254318789665,
    "input_throughput": 7030.980580804104,
    "output_throughput": 6222.351255219574,
    "total_throughput": 13253.331836023677,
    "itl": 138.34156958630714,
    "ttft": 1370284.971468585,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 802,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.4545111706341176,
    "arrivals": 187468,
    "finished_requests": 102237,
    "scheduler_time": 111.164260142779
}
#Debug simulation 
Total elapsed time: 6.994626772007905. Arrivals time: 0.2994498022017069 Scheduler time: 6.579643361386843 Scheduler overhead time: 0.03933786757988855 Adapter cache time: 0.01846737606683746 Engine time: 0.03955635876627639 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-16/adapters_96_slots_64_rate_1.6-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-16/adapters_96_slots_64_rate_1.6-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 17280, 270, 270, 270, 270, 17280, 270, 17280, 270, 66, 17280, 66, 66, 17280, 270, 17280, 270, 17280, 17280, 270, 66, 17280, 270, 66, 66, 270, 17280, 66, 270, 66, 66, 270, 270, 270, 66, 66, 17280, 270, 270, 66, 17280, 17280, 270, 17280, 17280, 270, 17280, 66, 17280, 270, 270, 270, 17280, 17280, 66, 66, 270, 66, 17280, 66, 66, 17280, 66, 270, 270, 66, 270, 17280, 17280, 17280, 270, 17280, 17280, 66, 66, 17280, 270, 17280, 66, 270, 17280, 66, 17280, 270, 66, 17280, 66, 66, 17280, 66, 66, 270]
Prompts retrieved: 563712 . Total input tokens: 125628176 . Total output tokens: 112839488
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.932325059024151,
    "estimated_duration": 3600.139193784711,
    "input_throughput": 7030.574274377238,
    "output_throughput": 6222.1094225112765,
    "total_throughput": 13252.683696888515,
    "itl": 138.34709133243703,
    "ttft": 1370368.571387759,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 804,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.625050504377583,
    "arrivals": 187468,
    "finished_requests": 102231,
    "scheduler_time": 111.16154047561041
}
#Debug simulation 
Total elapsed time: 6.93243991502095. Arrivals time: 0.29756541596725583 Scheduler time: 6.520486734050792 Scheduler overhead time: 0.03894348698668182 Adapter cache time: 0.018299768154975027 Engine time: 0.03918992931721732 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-32/adapters_96_slots_64_rate_1.6-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-32/adapters_96_slots_64_rate_1.6-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 17280, 270, 270, 270, 270, 17280, 270, 17280, 270, 66, 17280, 66, 66, 17280, 270, 17280, 270, 17280, 17280, 270, 66, 17280, 270, 66, 66, 270, 17280, 66, 270, 66, 66, 270, 270, 270, 66, 66, 17280, 270, 270, 66, 17280, 17280, 270, 17280, 17280, 270, 17280, 66, 17280, 270, 270, 270, 17280, 17280, 66, 66, 270, 66, 17280, 66, 66, 17280, 66, 270, 270, 66, 270, 17280, 17280, 17280, 270, 17280, 17280, 66, 66, 17280, 270, 17280, 66, 270, 17280, 66, 17280, 270, 66, 17280, 66, 66, 17280, 66, 66, 270]
Prompts retrieved: 563712 . Total input tokens: 125628176 . Total output tokens: 112839488
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.153276432014536,
    "estimated_duration": 3600.1432753204317,
    "input_throughput": 7030.566303711116,
    "output_throughput": 6222.102368413724,
    "total_throughput": 13252.66867212484,
    "itl": 138.34713704813396,
    "ttft": 1370367.74935401,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 804,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.6294400489516434,
    "arrivals": 187468,
    "finished_requests": 102231,
    "scheduler_time": 111.16150283833663
}
#Debug simulation 
Total elapsed time: 7.1533719440340064. Arrivals time: 0.29652533953776583 Scheduler time: 6.7417865446186624 Scheduler overhead time: 0.03917036019265652 Adapter cache time: 0.018490541144274175 Engine time: 0.0392620661878027 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-16-16/adapters_96_slots_64_rate_1.6-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-16-16/adapters_96_slots_64_rate_1.6-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 17280, 270, 270, 270, 270, 17280, 270, 17280, 270, 66, 17280, 66, 66, 17280, 270, 17280, 270, 17280, 17280, 270, 66, 17280, 270, 66, 66, 270, 17280, 66, 270, 66, 66, 270, 270, 270, 66, 66, 17280, 270, 270, 66, 17280, 17280, 270, 17280, 17280, 270, 17280, 66, 17280, 270, 270, 270, 17280, 17280, 66, 66, 270, 66, 17280, 66, 66, 17280, 66, 270, 270, 66, 270, 17280, 17280, 17280, 270, 17280, 17280, 66, 66, 17280, 270, 17280, 66, 270, 17280, 66, 17280, 270, 66, 17280, 66, 66, 17280, 66, 66, 270]
Prompts retrieved: 563712 . Total input tokens: 125628176 . Total output tokens: 112839488
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 6.988792417978402,
    "estimated_duration": 3600.0105730554005,
    "input_throughput": 7030.825461859134,
    "output_throughput": 6222.3317252616525,
    "total_throughput": 13253.157187120785,
    "itl": 138.3427817626011,
    "ttft": 1370316.4561282282,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 804,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.511461005851138,
    "arrivals": 187468,
    "finished_requests": 102231,
    "scheduler_time": 111.16083180091702
}
#Debug simulation 
Total elapsed time: 6.988902605022304. Arrivals time: 0.2998891602619551 Scheduler time: 6.573616987850983 Scheduler overhead time: 0.03932696074480191 Adapter cache time: 0.01853266340913251 Engine time: 0.03949438489507884 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-16-32/adapters_96_slots_64_rate_1.6-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-16-32/adapters_96_slots_64_rate_1.6-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 17280, 270, 270, 270, 270, 17280, 270, 17280, 270, 66, 17280, 66, 66, 17280, 270, 17280, 270, 17280, 17280, 270, 66, 17280, 270, 66, 66, 270, 17280, 66, 270, 66, 66, 270, 270, 270, 66, 66, 17280, 270, 270, 66, 17280, 17280, 270, 17280, 17280, 270, 17280, 66, 17280, 270, 270, 270, 17280, 17280, 66, 66, 270, 66, 17280, 66, 66, 17280, 66, 270, 270, 66, 270, 17280, 17280, 17280, 270, 17280, 17280, 66, 66, 17280, 270, 17280, 66, 270, 17280, 66, 17280, 270, 66, 17280, 66, 66, 17280, 66, 66, 270]
Prompts retrieved: 563712 . Total input tokens: 125628176 . Total output tokens: 112839488
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 6.927726611029357,
    "estimated_duration": 3600.0167044570276,
    "input_throughput": 7030.549599579537,
    "output_throughput": 6222.17751719529,
    "total_throughput": 13252.727116774828,
    "itl": 138.3482695519402,
    "ttft": 1370371.3307311945,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 804,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.664399601574987,
    "arrivals": 187468,
    "finished_requests": 102227,
    "scheduler_time": 111.1567687648675
}
#Debug simulation 
Total elapsed time: 6.927845041034743. Arrivals time: 0.29651783575536683 Scheduler time: 6.516782118938863 Scheduler overhead time: 0.03900509711820632 Adapter cache time: 0.018368629505857825 Engine time: 0.03916672902414575 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_16-16-16/adapters_96_slots_64_rate_1.6-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_16-16-16/adapters_96_slots_64_rate_1.6-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 17280, 270, 270, 270, 270, 17280, 270, 17280, 270, 66, 17280, 66, 66, 17280, 270, 17280, 270, 17280, 17280, 270, 66, 17280, 270, 66, 66, 270, 17280, 66, 270, 66, 66, 270, 270, 270, 66, 66, 17280, 270, 270, 66, 17280, 17280, 270, 17280, 17280, 270, 17280, 66, 17280, 270, 270, 270, 17280, 17280, 66, 66, 270, 66, 17280, 66, 66, 17280, 66, 270, 270, 66, 270, 17280, 17280, 17280, 270, 17280, 17280, 66, 66, 17280, 270, 17280, 66, 270, 17280, 66, 17280, 270, 66, 17280, 66, 66, 17280, 66, 66, 270]
Prompts retrieved: 563712 . Total input tokens: 125628176 . Total output tokens: 112839488
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.932027857983485,
    "estimated_duration": 3600.059871661484,
    "input_throughput": 7031.108621067995,
    "output_throughput": 6222.464569641025,
    "total_throughput": 13253.57319070902,
    "itl": 138.3396039259779,
    "ttft": 1370257.3325531387,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 802,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3980203365114967,
    "arrivals": 187468,
    "finished_requests": 102237,
    "scheduler_time": 111.16387655879548
}
#Debug simulation 
Total elapsed time: 6.93215893895831. Arrivals time: 0.2931668236851692 Scheduler time: 6.523928071372211 Scheduler overhead time: 0.039248839661013335 Adapter cache time: 0.018401392619125545 Engine time: 0.039358156092930585 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_16-16-32/adapters_96_slots_64_rate_1.6-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_16-16-32/adapters_96_slots_64_rate_1.6-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 17280, 270, 270, 270, 270, 17280, 270, 17280, 270, 66, 17280, 66, 66, 17280, 270, 17280, 270, 17280, 17280, 270, 66, 17280, 270, 66, 66, 270, 17280, 66, 270, 66, 66, 270, 270, 270, 66, 66, 17280, 270, 270, 66, 17280, 17280, 270, 17280, 17280, 270, 17280, 66, 17280, 270, 270, 270, 17280, 17280, 66, 66, 270, 66, 17280, 66, 66, 17280, 66, 270, 270, 66, 270, 17280, 17280, 17280, 270, 17280, 17280, 66, 66, 17280, 270, 17280, 66, 270, 17280, 66, 17280, 270, 66, 17280, 66, 66, 17280, 66, 66, 270]
Prompts retrieved: 563712 . Total input tokens: 125628176 . Total output tokens: 112839488
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.950859455042519,
    "estimated_duration": 3600.0813635031996,
    "input_throughput": 7030.423327813632,
    "output_throughput": 6222.065764147858,
    "total_throughput": 13252.48909196149,
    "itl": 138.35038497442977,
    "ttft": 1370386.4186838146,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 803,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.6944293285533973,
    "arrivals": 187468,
    "finished_requests": 102227,
    "scheduler_time": 111.15746310918718
}
#Debug simulation 
Total elapsed time: 6.950947655015625. Arrivals time: 0.2973836624296382 Scheduler time: 6.538820871675853 Scheduler overhead time: 0.03921540634473786 Adapter cache time: 0.0182256709667854 Engine time: 0.03928449872182682 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-8/adapters_96_slots_64_rate_1.6-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-8/adapters_96_slots_64_rate_1.6-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 17280, 270, 270, 270, 270, 17280, 270, 17280, 270, 33, 17280, 33, 33, 17280, 270, 17280, 270, 17280, 17280, 270, 33, 17280, 270, 33, 33, 270, 17280, 33, 270, 33, 33, 270, 270, 270, 33, 33, 17280, 270, 270, 33, 17280, 17280, 270, 17280, 17280, 270, 17280, 33, 17280, 270, 270, 270, 17280, 17280, 33, 33, 270, 33, 17280, 33, 33, 17280, 33, 270, 270, 33, 270, 17280, 17280, 17280, 270, 17280, 17280, 33, 33, 17280, 270, 17280, 33, 270, 17280, 33, 17280, 270, 33, 17280, 33, 33, 17280, 33, 33, 270]
Prompts retrieved: 562656 . Total input tokens: 125378570 . Total output tokens: 112631294
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 7.0392618389450945,
    "estimated_duration": 3600.0954030631838,
    "input_throughput": 7072.075083992756,
    "output_throughput": 6302.841024905407,
    "total_throughput": 13374.916108898162,
    "itl": 137.0271045410598,
    "ttft": 1356494.82773113,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 500,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.530243871966394,
    "arrivals": 186986,
    "finished_requests": 103109,
    "scheduler_time": 112.43668113722592
}
#Debug simulation 
Total elapsed time: 7.039347713987809. Arrivals time: 0.301794039492961 Scheduler time: 6.6234325687401 Scheduler overhead time: 0.03958629770204425 Adapter cache time: 0.01654957968275994 Engine time: 0.039734982361551374 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-16/adapters_96_slots_64_rate_1.6-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-16/adapters_96_slots_64_rate_1.6-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 17280, 270, 270, 270, 270, 17280, 270, 17280, 270, 33, 17280, 33, 33, 17280, 270, 17280, 270, 17280, 17280, 270, 33, 17280, 270, 33, 33, 270, 17280, 33, 270, 33, 33, 270, 270, 270, 33, 33, 17280, 270, 270, 33, 17280, 17280, 270, 17280, 17280, 270, 17280, 33, 17280, 270, 270, 270, 17280, 17280, 33, 33, 270, 33, 17280, 33, 33, 17280, 33, 270, 270, 33, 270, 17280, 17280, 17280, 270, 17280, 17280, 33, 33, 17280, 270, 17280, 33, 270, 17280, 33, 17280, 270, 33, 17280, 33, 33, 17280, 33, 33, 270]
Prompts retrieved: 562656 . Total input tokens: 125378570 . Total output tokens: 112631294
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.069958177977242,
    "estimated_duration": 3600.0603257549283,
    "input_throughput": 7071.424003057944,
    "output_throughput": 6302.503554643091,
    "total_throughput": 13373.927557701036,
    "itl": 137.02936276208055,
    "ttft": 1356525.8448372134,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 500,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6245498633966824,
    "arrivals": 186986,
    "finished_requests": 103103,
    "scheduler_time": 112.43256976740015
}
#Debug simulation 
Total elapsed time: 7.070089517976157. Arrivals time: 0.32175400375854224 Scheduler time: 6.633898795582354 Scheduler overhead time: 0.039688868331722915 Adapter cache time: 0.01668917224742472 Engine time: 0.039754801720846444 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-32/adapters_96_slots_64_rate_1.6-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-32/adapters_96_slots_64_rate_1.6-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 17280, 270, 270, 270, 270, 17280, 270, 17280, 270, 33, 17280, 33, 33, 17280, 270, 17280, 270, 17280, 17280, 270, 33, 17280, 270, 33, 33, 270, 17280, 33, 270, 33, 33, 270, 270, 270, 33, 33, 17280, 270, 270, 33, 17280, 17280, 270, 17280, 17280, 270, 17280, 33, 17280, 270, 270, 270, 17280, 17280, 33, 33, 270, 33, 17280, 33, 33, 17280, 33, 270, 270, 33, 270, 17280, 17280, 17280, 270, 17280, 17280, 33, 33, 17280, 270, 17280, 33, 270, 17280, 33, 17280, 270, 33, 17280, 33, 33, 17280, 33, 33, 270]
Prompts retrieved: 562656 . Total input tokens: 125378570 . Total output tokens: 112631294
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.02125603397144,
    "estimated_duration": 3600.0753601094684,
    "input_throughput": 7071.607523023041,
    "output_throughput": 6302.715007418637,
    "total_throughput": 13374.322530441677,
    "itl": 137.0296692723608,
    "ttft": 1356522.1421564333,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 500,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.628666880149404,
    "arrivals": 186986,
    "finished_requests": 103105,
    "scheduler_time": 112.43370633615159
}
#Debug simulation 
Total elapsed time: 7.021366355998907. Arrivals time: 0.31893763050902635 Scheduler time: 6.588651631725952 Scheduler overhead time: 0.0393133609322831 Adapter cache time: 0.016520682198461145 Engine time: 0.03976780746597797 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-16-16/adapters_96_slots_64_rate_1.6-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-16-16/adapters_96_slots_64_rate_1.6-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 17280, 270, 270, 270, 270, 17280, 270, 17280, 270, 33, 17280, 33, 33, 17280, 270, 17280, 270, 17280, 17280, 270, 33, 17280, 270, 33, 33, 270, 17280, 33, 270, 33, 33, 270, 270, 270, 33, 33, 17280, 270, 270, 33, 17280, 17280, 270, 17280, 17280, 270, 17280, 33, 17280, 270, 270, 270, 17280, 17280, 33, 33, 270, 33, 17280, 33, 33, 17280, 33, 270, 270, 33, 270, 17280, 17280, 17280, 270, 17280, 17280, 33, 33, 17280, 270, 17280, 33, 270, 17280, 33, 17280, 270, 33, 17280, 33, 33, 17280, 33, 33, 270]
Prompts retrieved: 562656 . Total input tokens: 125378570 . Total output tokens: 112631294
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 7.042929068033118,
    "estimated_duration": 3600.1449479200733,
    "input_throughput": 7071.977758759184,
    "output_throughput": 6302.754285798761,
    "total_throughput": 13374.732044557946,
    "itl": 137.0277849935417,
    "ttft": 1356512.0358695784,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 500,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5608089937199778,
    "arrivals": 186986,
    "finished_requests": 103109,
    "scheduler_time": 112.43722792368237
}
#Debug simulation 
Total elapsed time: 7.043046186037827. Arrivals time: 0.30079930933425203 Scheduler time: 6.627349546470214 Scheduler overhead time: 0.03970090951770544 Adapter cache time: 0.016589437087532133 Engine time: 0.040227632503956556 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-16-32/adapters_96_slots_64_rate_1.6-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-16-32/adapters_96_slots_64_rate_1.6-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 17280, 270, 270, 270, 270, 17280, 270, 17280, 270, 33, 17280, 33, 33, 17280, 270, 17280, 270, 17280, 17280, 270, 33, 17280, 270, 33, 33, 270, 17280, 33, 270, 33, 33, 270, 270, 270, 33, 33, 17280, 270, 270, 33, 17280, 17280, 270, 17280, 17280, 270, 17280, 33, 17280, 270, 270, 270, 17280, 17280, 33, 33, 270, 33, 17280, 33, 33, 17280, 33, 270, 270, 33, 270, 17280, 17280, 17280, 270, 17280, 17280, 33, 33, 17280, 270, 17280, 33, 270, 17280, 33, 17280, 270, 33, 17280, 33, 33, 17280, 33, 33, 270]
Prompts retrieved: 562656 . Total input tokens: 125378570 . Total output tokens: 112631294
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 7.074156556976959,
    "estimated_duration": 3600.1082160983665,
    "input_throughput": 7071.61742698692,
    "output_throughput": 6302.658041927046,
    "total_throughput": 13374.275468913966,
    "itl": 137.0304254628337,
    "ttft": 1356532.5877384883,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 500,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6482844708301172,
    "arrivals": 186986,
    "finished_requests": 103106,
    "scheduler_time": 112.43415978007877
}
#Debug simulation 
Total elapsed time: 7.07426643098006. Arrivals time: 0.326549501682166 Scheduler time: 6.633015042927582 Scheduler overhead time: 0.03980283462442458 Adapter cache time: 0.016728484246414155 Engine time: 0.03973671537823975 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_16-16-16/adapters_96_slots_64_rate_1.6-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_16-16-16/adapters_96_slots_64_rate_1.6-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 17280, 270, 270, 270, 270, 17280, 270, 17280, 270, 33, 17280, 33, 33, 17280, 270, 17280, 270, 17280, 17280, 270, 33, 17280, 270, 33, 33, 270, 17280, 33, 270, 33, 33, 270, 270, 270, 33, 33, 17280, 270, 270, 33, 17280, 17280, 270, 17280, 17280, 270, 17280, 33, 17280, 270, 270, 270, 17280, 17280, 33, 33, 270, 33, 17280, 33, 33, 17280, 33, 270, 270, 33, 270, 17280, 17280, 17280, 270, 17280, 17280, 33, 33, 17280, 270, 17280, 33, 270, 17280, 33, 17280, 270, 33, 17280, 33, 33, 17280, 33, 33, 270]
Prompts retrieved: 562656 . Total input tokens: 125378570 . Total output tokens: 112631294
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 7.068448440055363,
    "estimated_duration": 3600.021643056139,
    "input_throughput": 7071.993039016012,
    "output_throughput": 6302.854051937755,
    "total_throughput": 13374.847090953766,
    "itl": 137.02413195755975,
    "ttft": 1356482.467025683,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 500,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4950251474510716,
    "arrivals": 186986,
    "finished_requests": 103107,
    "scheduler_time": 112.43511781344739
}
#Debug simulation 
Total elapsed time: 7.068535714002792. Arrivals time: 0.3029814928304404 Scheduler time: 6.651443807175383 Scheduler overhead time: 0.0395855606184341 Adapter cache time: 0.01642344187712297 Engine time: 0.039889794832561165 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_16-16-32/adapters_96_slots_64_rate_1.6-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_16-16-32/adapters_96_slots_64_rate_1.6-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 17280, 270, 270, 270, 270, 17280, 270, 17280, 270, 33, 17280, 33, 33, 17280, 270, 17280, 270, 17280, 17280, 270, 33, 17280, 270, 33, 33, 270, 17280, 33, 270, 33, 33, 270, 270, 270, 33, 33, 17280, 270, 270, 33, 17280, 17280, 270, 17280, 17280, 270, 17280, 33, 17280, 270, 270, 270, 17280, 17280, 33, 33, 270, 33, 17280, 33, 33, 17280, 33, 270, 270, 33, 270, 17280, 17280, 17280, 270, 17280, 17280, 33, 33, 17280, 270, 17280, 33, 270, 17280, 33, 17280, 270, 33, 17280, 33, 33, 17280, 33, 33, 270]
Prompts retrieved: 562656 . Total input tokens: 125378570 . Total output tokens: 112631294
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.057962929015048,
    "estimated_duration": 3600.129276822399,
    "input_throughput": 7071.576058088294,
    "output_throughput": 6302.621171433937,
    "total_throughput": 13374.197229522231,
    "itl": 137.03093350305065,
    "ttft": 1356539.8444423978,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 500,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.668530830442904,
    "arrivals": 186986,
    "finished_requests": 103106,
    "scheduler_time": 112.43417545602756
}
#Debug simulation 
Total elapsed time: 7.058054631983396. Arrivals time: 0.3194618945126422 Scheduler time: 6.624481014965568 Scheduler overhead time: 0.03961539623560384 Adapter cache time: 0.016550730913877487 Engine time: 0.0397800006903708 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-8/adapters_96_slots_64_rate_1.6-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-8/adapters_96_slots_64_rate_1.6-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 17280, 135, 135, 135, 135, 17280, 135, 17280, 135, 66, 17280, 66, 66, 17280, 135, 17280, 135, 17280, 17280, 135, 66, 17280, 135, 66, 66, 135, 17280, 66, 135, 66, 66, 135, 135, 135, 66, 66, 17280, 135, 135, 66, 17280, 17280, 135, 17280, 17280, 135, 17280, 66, 17280, 135, 135, 135, 17280, 17280, 66, 66, 135, 66, 17280, 66, 66, 17280, 66, 135, 135, 66, 135, 17280, 17280, 17280, 135, 17280, 17280, 66, 66, 17280, 135, 17280, 66, 135, 17280, 66, 17280, 135, 66, 17280, 66, 66, 17280, 66, 66, 135]
Prompts retrieved: 559392 . Total input tokens: 124640771 . Total output tokens: 111969357
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 7.174602486018557,
    "estimated_duration": 3600.104529683501,
    "input_throughput": 7261.354714691634,
    "output_throughput": 6429.3022075208655,
    "total_throughput": 13690.6569222125,
    "itl": 133.95512151767306,
    "ttft": 1321980.4414144056,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 617,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8883209380065387,
    "arrivals": 186004,
    "finished_requests": 105458,
    "scheduler_time": 114.43882146306782
}
#Debug simulation 
Total elapsed time: 7.174714480002876. Arrivals time: 0.30857124546309933 Scheduler time: 6.750505326606799 Scheduler overhead time: 0.040384915948379785 Adapter cache time: 0.01617453043581918 Engine time: 0.04043912305496633 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-16/adapters_96_slots_64_rate_1.6-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-16/adapters_96_slots_64_rate_1.6-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 17280, 135, 135, 135, 135, 17280, 135, 17280, 135, 66, 17280, 66, 66, 17280, 135, 17280, 135, 17280, 17280, 135, 66, 17280, 135, 66, 66, 135, 17280, 66, 135, 66, 66, 135, 135, 135, 66, 66, 17280, 135, 135, 66, 17280, 17280, 135, 17280, 17280, 135, 17280, 66, 17280, 135, 135, 135, 17280, 17280, 66, 66, 135, 66, 17280, 66, 66, 17280, 66, 135, 135, 66, 135, 17280, 17280, 17280, 135, 17280, 17280, 66, 66, 17280, 135, 17280, 66, 135, 17280, 66, 17280, 135, 66, 17280, 66, 66, 17280, 66, 66, 135]
Prompts retrieved: 559392 . Total input tokens: 124640771 . Total output tokens: 111969357
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.16273360903142,
    "estimated_duration": 3600.097457022105,
    "input_throughput": 7260.967046603899,
    "output_throughput": 6429.157342630761,
    "total_throughput": 13690.12438923466,
    "itl": 133.9586763351819,
    "ttft": 1321986.126567775,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 616,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.013072420086253,
    "arrivals": 186004,
    "finished_requests": 105453,
    "scheduler_time": 114.4350233080582
}
#Debug simulation 
Total elapsed time: 7.162838954012841. Arrivals time: 0.31849911296740174 Scheduler time: 6.728872140054591 Scheduler overhead time: 0.04033511795569211 Adapter cache time: 0.016032525629270822 Engine time: 0.04062089521903545 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-32/adapters_96_slots_64_rate_1.6-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-32/adapters_96_slots_64_rate_1.6-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 17280, 135, 135, 135, 135, 17280, 135, 17280, 135, 66, 17280, 66, 66, 17280, 135, 17280, 135, 17280, 17280, 135, 66, 17280, 135, 66, 66, 135, 17280, 66, 135, 66, 66, 135, 135, 135, 66, 66, 17280, 135, 135, 66, 17280, 17280, 135, 17280, 17280, 135, 17280, 66, 17280, 135, 135, 135, 17280, 17280, 66, 66, 135, 66, 17280, 66, 66, 17280, 66, 135, 135, 66, 135, 17280, 17280, 17280, 135, 17280, 17280, 66, 66, 17280, 135, 17280, 66, 135, 17280, 66, 17280, 135, 66, 17280, 66, 66, 17280, 66, 66, 135]
Prompts retrieved: 559392 . Total input tokens: 124640771 . Total output tokens: 111969357
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.195258228981402,
    "estimated_duration": 3600.102679883809,
    "input_throughput": 7260.9565127302585,
    "output_throughput": 6429.1480155079935,
    "total_throughput": 13690.104528238253,
    "itl": 133.95888828023297,
    "ttft": 1321985.7720755963,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 616,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0161143110506354,
    "arrivals": 186004,
    "finished_requests": 105453,
    "scheduler_time": 114.43500809551551
}
#Debug simulation 
Total elapsed time: 7.1953660160070285. Arrivals time: 0.33556603209581226 Scheduler time: 6.743768342130352 Scheduler overhead time: 0.04032399650895968 Adapter cache time: 0.01632881216937676 Engine time: 0.04077681613853201 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-16-16/adapters_96_slots_64_rate_1.6-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-16-16/adapters_96_slots_64_rate_1.6-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 17280, 135, 135, 135, 135, 17280, 135, 17280, 135, 66, 17280, 66, 66, 17280, 135, 17280, 135, 17280, 17280, 135, 66, 17280, 135, 66, 66, 135, 17280, 66, 135, 66, 66, 135, 135, 135, 66, 66, 17280, 135, 135, 66, 17280, 17280, 135, 17280, 17280, 135, 17280, 66, 17280, 135, 135, 135, 17280, 17280, 66, 66, 135, 66, 17280, 66, 66, 17280, 66, 135, 135, 66, 135, 17280, 17280, 17280, 135, 17280, 17280, 66, 66, 17280, 135, 17280, 66, 135, 17280, 66, 17280, 135, 66, 17280, 66, 66, 17280, 66, 66, 135]
Prompts retrieved: 559392 . Total input tokens: 124640771 . Total output tokens: 111969357
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 7.1686101270024665,
    "estimated_duration": 3600.007669767219,
    "input_throughput": 7261.148141301115,
    "output_throughput": 6429.317691286092,
    "total_throughput": 13690.465832587208,
    "itl": 133.95619588990021,
    "ttft": 1321936.094248932,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 617,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9310746441455446,
    "arrivals": 186004,
    "finished_requests": 105453,
    "scheduler_time": 114.43411255083065
}
#Debug simulation 
Total elapsed time: 7.168744552007411. Arrivals time: 0.30494084738893434 Scheduler time: 6.747939566441346 Scheduler overhead time: 0.040257326094433665 Adapter cache time: 0.016143997316248715 Engine time: 0.04090584040386602 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-16-32/adapters_96_slots_64_rate_1.6-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-16-32/adapters_96_slots_64_rate_1.6-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 17280, 135, 135, 135, 135, 17280, 135, 17280, 135, 66, 17280, 66, 66, 17280, 135, 17280, 135, 17280, 17280, 135, 66, 17280, 135, 66, 66, 135, 17280, 66, 135, 66, 66, 135, 135, 135, 66, 66, 17280, 135, 135, 66, 17280, 17280, 135, 17280, 17280, 135, 17280, 66, 17280, 135, 135, 135, 17280, 17280, 66, 66, 135, 66, 17280, 66, 66, 17280, 66, 135, 135, 66, 135, 17280, 17280, 17280, 135, 17280, 17280, 66, 66, 17280, 135, 17280, 66, 135, 17280, 66, 17280, 135, 66, 17280, 66, 66, 17280, 66, 66, 135]
Prompts retrieved: 559392 . Total input tokens: 124640771 . Total output tokens: 111969357
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 7.187974498025142,
    "estimated_duration": 3600.1297235487277,
    "input_throughput": 7260.901969452655,
    "output_throughput": 6429.099720658087,
    "total_throughput": 13690.001690110741,
    "itl": 133.95980791738964,
    "ttft": 1321996.8415602422,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 616,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.042396852411333,
    "arrivals": 186004,
    "finished_requests": 105453,
    "scheduler_time": 114.43515755447655
}
#Debug simulation 
Total elapsed time: 7.188089494011365. Arrivals time: 0.3138952092267573 Scheduler time: 6.757955351378769 Scheduler overhead time: 0.04042089486028999 Adapter cache time: 0.016184866311959922 Engine time: 0.04086926451418549 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_16-16-16/adapters_96_slots_64_rate_1.6-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_16-16-16/adapters_96_slots_64_rate_1.6-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 17280, 135, 135, 135, 135, 17280, 135, 17280, 135, 66, 17280, 66, 66, 17280, 135, 17280, 135, 17280, 17280, 135, 66, 17280, 135, 66, 66, 135, 17280, 66, 135, 66, 66, 135, 135, 135, 66, 66, 17280, 135, 135, 66, 17280, 17280, 135, 17280, 17280, 135, 17280, 66, 17280, 135, 135, 135, 17280, 17280, 66, 66, 135, 66, 17280, 66, 66, 17280, 66, 135, 135, 66, 135, 17280, 17280, 17280, 135, 17280, 17280, 66, 66, 17280, 135, 17280, 66, 135, 17280, 66, 17280, 135, 66, 17280, 66, 66, 17280, 66, 66, 135]
Prompts retrieved: 559392 . Total input tokens: 124640771 . Total output tokens: 111969357
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 7.159332456998527,
    "estimated_duration": 3600.0339518708697,
    "input_throughput": 7261.29457374008,
    "output_throughput": 6429.345475470178,
    "total_throughput": 13690.640049210257,
    "itl": 133.95291040483497,
    "ttft": 1321942.0384782741,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 616,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8418709816597116,
    "arrivals": 186004,
    "finished_requests": 105456,
    "scheduler_time": 114.43757710318962
}
#Debug simulation 
Total elapsed time: 7.159420903946739. Arrivals time: 0.3055043042404577 Scheduler time: 6.738777469785418 Scheduler overhead time: 0.040225041448138654 Adapter cache time: 0.01602505601476878 Engine time: 0.04036179376998916 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_16-16-32/adapters_96_slots_64_rate_1.6-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_16-16-32/adapters_96_slots_64_rate_1.6-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 17280, 135, 135, 135, 135, 17280, 135, 17280, 135, 66, 17280, 66, 66, 17280, 135, 17280, 135, 17280, 17280, 135, 66, 17280, 135, 66, 66, 135, 17280, 66, 135, 66, 66, 135, 135, 135, 66, 66, 17280, 135, 135, 66, 17280, 17280, 135, 17280, 17280, 135, 17280, 66, 17280, 135, 135, 135, 17280, 17280, 66, 66, 135, 66, 17280, 66, 66, 17280, 66, 135, 135, 66, 135, 17280, 17280, 17280, 135, 17280, 17280, 66, 66, 17280, 135, 17280, 66, 135, 17280, 66, 17280, 135, 66, 17280, 66, 66, 17280, 66, 66, 135]
Prompts retrieved: 559392 . Total input tokens: 124640771 . Total output tokens: 111969357
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.187211666954681,
    "estimated_duration": 3600.0345476319712,
    "input_throughput": 7260.866431738535,
    "output_throughput": 6429.067191931315,
    "total_throughput": 13689.93362366985,
    "itl": 133.96121118563025,
    "ttft": 1322003.1078499455,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 616,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.068805147558448,
    "arrivals": 186004,
    "finished_requests": 105450,
    "scheduler_time": 114.43073836330721
}
#Debug simulation 
Total elapsed time: 7.187328772968613. Arrivals time: 0.31942058604909107 Scheduler time: 6.751876540074591 Scheduler overhead time: 0.040406983403954655 Adapter cache time: 0.016158402431756258 Engine time: 0.04093534126877785 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-8/adapters_96_slots_64_rate_1.6-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-8/adapters_96_slots_64_rate_1.6-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 17280, 135, 135, 135, 135, 17280, 135, 17280, 135, 33, 17280, 33, 33, 17280, 135, 17280, 135, 17280, 17280, 135, 33, 17280, 135, 33, 33, 135, 17280, 33, 135, 33, 33, 135, 135, 135, 33, 33, 17280, 135, 135, 33, 17280, 17280, 135, 17280, 17280, 135, 17280, 33, 17280, 135, 135, 135, 17280, 17280, 33, 33, 135, 33, 17280, 33, 33, 17280, 33, 135, 135, 33, 135, 17280, 17280, 17280, 135, 17280, 17280, 33, 33, 17280, 135, 17280, 33, 135, 17280, 33, 17280, 135, 33, 17280, 33, 33, 17280, 33, 33, 135]
Prompts retrieved: 558336 . Total input tokens: 124411758 . Total output tokens: 111757417
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 7.441396397945937,
    "estimated_duration": 3600.058471742681,
    "input_throughput": 7320.105272413365,
    "output_throughput": 6497.773906621148,
    "total_throughput": 13817.879179034513,
    "itl": 132.640246018637,
    "ttft": 1310953.622649249,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 424,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2976468034274966,
    "arrivals": 185665,
    "finished_requests": 106474,
    "scheduler_time": 115.64213186473424
}
#Debug simulation 
Total elapsed time: 7.441461613983847. Arrivals time: 0.3093181063886732 Scheduler time: 7.017124890931882 Scheduler overhead time: 0.04043373354943469 Adapter cache time: 0.0142992211622186 Engine time: 0.04158540675416589 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-16/adapters_96_slots_64_rate_1.6-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-16/adapters_96_slots_64_rate_1.6-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 17280, 135, 135, 135, 135, 17280, 135, 17280, 135, 33, 17280, 33, 33, 17280, 135, 17280, 135, 17280, 17280, 135, 33, 17280, 135, 33, 33, 135, 17280, 33, 135, 33, 33, 135, 135, 135, 33, 33, 17280, 135, 135, 33, 17280, 17280, 135, 17280, 17280, 135, 17280, 33, 17280, 135, 135, 135, 17280, 17280, 33, 33, 135, 33, 17280, 33, 33, 17280, 33, 135, 135, 33, 135, 17280, 17280, 17280, 135, 17280, 17280, 33, 33, 17280, 135, 17280, 33, 135, 17280, 33, 17280, 135, 33, 17280, 33, 33, 17280, 33, 33, 135]
Prompts retrieved: 558336 . Total input tokens: 124411758 . Total output tokens: 111757417
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.278468031960074,
    "estimated_duration": 3600.055487626414,
    "input_throughput": 7320.023285911825,
    "output_throughput": 6497.7301267717185,
    "total_throughput": 13817.753412683544,
    "itl": 132.64333088218171,
    "ttft": 1310965.8251592154,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 424,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3813708235649451,
    "arrivals": 185665,
    "finished_requests": 106473,
    "scheduler_time": 115.6397838904493
}
#Debug simulation 
Total elapsed time: 7.278555402997881. Arrivals time: 0.3270914134918712 Scheduler time: 6.836101921158843 Scheduler overhead time: 0.04095858585787937 Adapter cache time: 0.014288830512668937 Engine time: 0.04127635678742081 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-32/adapters_96_slots_64_rate_1.6-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-32/adapters_96_slots_64_rate_1.6-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 17280, 135, 135, 135, 135, 17280, 135, 17280, 135, 33, 17280, 33, 33, 17280, 135, 17280, 135, 17280, 17280, 135, 33, 17280, 135, 33, 33, 135, 17280, 33, 135, 33, 33, 135, 135, 135, 33, 33, 17280, 135, 135, 33, 17280, 17280, 135, 17280, 17280, 135, 17280, 33, 17280, 135, 135, 135, 17280, 17280, 33, 33, 135, 33, 17280, 33, 33, 17280, 33, 135, 135, 33, 135, 17280, 17280, 17280, 135, 17280, 17280, 33, 33, 17280, 135, 17280, 33, 135, 17280, 33, 17280, 135, 33, 17280, 33, 33, 17280, 33, 33, 135]
Prompts retrieved: 558336 . Total input tokens: 124411758 . Total output tokens: 111757417
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.2807727290201,
    "estimated_duration": 3600.0567872782854,
    "input_throughput": 7320.020643319632,
    "output_throughput": 6497.727781034521,
    "total_throughput": 13817.748424354153,
    "itl": 132.6432484115176,
    "ttft": 1310964.8472844341,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 424,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3842067953571757,
    "arrivals": 185665,
    "finished_requests": 106473,
    "scheduler_time": 115.63981453251691
}
#Debug simulation 
Total elapsed time: 7.280904993007425. Arrivals time: 0.3098805220797658 Scheduler time: 6.855903955700342 Scheduler overhead time: 0.04072475607972592 Adapter cache time: 0.014270641782786697 Engine time: 0.04125270288204774 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-16-16/adapters_96_slots_64_rate_1.6-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-16-16/adapters_96_slots_64_rate_1.6-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 17280, 135, 135, 135, 135, 17280, 135, 17280, 135, 33, 17280, 33, 33, 17280, 135, 17280, 135, 17280, 17280, 135, 33, 17280, 135, 33, 33, 135, 17280, 33, 135, 33, 33, 135, 135, 135, 33, 33, 17280, 135, 135, 33, 17280, 17280, 135, 17280, 17280, 135, 17280, 33, 17280, 135, 135, 135, 17280, 17280, 33, 33, 135, 33, 17280, 33, 33, 17280, 33, 135, 135, 33, 135, 17280, 17280, 17280, 135, 17280, 17280, 33, 33, 17280, 135, 17280, 33, 135, 17280, 33, 17280, 135, 33, 17280, 33, 33, 17280, 33, 33, 135]
Prompts retrieved: 558336 . Total input tokens: 124411758 . Total output tokens: 111757417
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 7.438143593957648,
    "estimated_duration": 3600.120592073976,
    "input_throughput": 7320.045627921148,
    "output_throughput": 6497.788727272534,
    "total_throughput": 13817.834355193681,
    "itl": 132.64186929879926,
    "ttft": 1310954.5299546195,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 424,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.324984669620169,
    "arrivals": 185665,
    "finished_requests": 106475,
    "scheduler_time": 115.64312110186884
}
#Debug simulation 
Total elapsed time: 7.43823667394463. Arrivals time: 0.3097993574338034 Scheduler time: 7.013504511793144 Scheduler overhead time: 0.040710469940677285 Adapter cache time: 0.014228820335119963 Engine time: 0.04122126701986417 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-16-32/adapters_96_slots_64_rate_1.6-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-16-32/adapters_96_slots_64_rate_1.6-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 17280, 135, 135, 135, 135, 17280, 135, 17280, 135, 33, 17280, 33, 33, 17280, 135, 17280, 135, 17280, 17280, 135, 33, 17280, 135, 33, 33, 135, 17280, 33, 135, 33, 33, 135, 135, 135, 33, 33, 17280, 135, 135, 33, 17280, 17280, 135, 17280, 17280, 135, 17280, 33, 17280, 135, 135, 135, 17280, 17280, 33, 33, 135, 33, 17280, 33, 33, 17280, 33, 135, 135, 33, 135, 17280, 17280, 17280, 135, 17280, 17280, 33, 33, 17280, 135, 17280, 33, 135, 17280, 33, 17280, 135, 33, 17280, 33, 33, 17280, 33, 33, 135]
Prompts retrieved: 558336 . Total input tokens: 124411758 . Total output tokens: 111757417
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 7.2553470459533855,
    "estimated_duration": 3600.0735411172172,
    "input_throughput": 7320.074631537079,
    "output_throughput": 6497.746707902141,
    "total_throughput": 13817.821339439219,
    "itl": 132.64393836586675,
    "ttft": 1310954.6774567992,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 424,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4015608178824228,
    "arrivals": 185665,
    "finished_requests": 106474,
    "scheduler_time": 115.63989013087917
}
#Debug simulation 
Total elapsed time: 7.255460214975756. Arrivals time: 0.3313257235568017 Scheduler time: 6.809520349197555 Scheduler overhead time: 0.04068163601914421 Adapter cache time: 0.01420356152812019 Engine time: 0.04102173150749877 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_16-16-16/adapters_96_slots_64_rate_1.6-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_16-16-16/adapters_96_slots_64_rate_1.6-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 17280, 135, 135, 135, 135, 17280, 135, 17280, 135, 33, 17280, 33, 33, 17280, 135, 17280, 135, 17280, 17280, 135, 33, 17280, 135, 33, 33, 135, 17280, 33, 135, 33, 33, 135, 135, 135, 33, 33, 17280, 135, 135, 33, 17280, 17280, 135, 17280, 17280, 135, 17280, 33, 17280, 135, 135, 135, 17280, 17280, 33, 33, 135, 33, 17280, 33, 33, 17280, 33, 135, 135, 33, 135, 17280, 17280, 17280, 135, 17280, 17280, 33, 33, 17280, 135, 17280, 33, 135, 17280, 33, 17280, 135, 33, 17280, 33, 33, 17280, 33, 33, 135]
Prompts retrieved: 558336 . Total input tokens: 124411758 . Total output tokens: 111757417
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 7.238254656025674,
    "estimated_duration": 3600.0171106344146,
    "input_throughput": 7320.1893741432705,
    "output_throughput": 6497.848560469111,
    "total_throughput": 13818.037934612381,
    "itl": 132.6393230753385,
    "ttft": 1310933.1908322247,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 424,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2677813250385144,
    "arrivals": 185665,
    "finished_requests": 106474,
    "scheduler_time": 115.6414282533012
}
#Debug simulation 
Total elapsed time: 7.238383555028122. Arrivals time: 0.32344894274137914 Scheduler time: 6.800299529801123 Scheduler overhead time: 0.04076458187773824 Adapter cache time: 0.01416794303804636 Engine time: 0.040940895793028176 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_16-16-32/adapters_96_slots_64_rate_1.6-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_16-16-32/adapters_96_slots_64_rate_1.6-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 17280, 135, 135, 135, 135, 17280, 135, 17280, 135, 33, 17280, 33, 33, 17280, 135, 17280, 135, 17280, 17280, 135, 33, 17280, 135, 33, 33, 135, 17280, 33, 135, 33, 33, 135, 135, 135, 33, 33, 17280, 135, 135, 33, 17280, 17280, 135, 17280, 17280, 135, 17280, 33, 17280, 135, 135, 135, 17280, 17280, 33, 33, 135, 33, 17280, 33, 33, 17280, 33, 135, 135, 33, 135, 17280, 17280, 17280, 135, 17280, 17280, 33, 33, 17280, 135, 17280, 33, 135, 17280, 33, 17280, 135, 33, 17280, 33, 33, 17280, 33, 33, 135]
Prompts retrieved: 558336 . Total input tokens: 124411758 . Total output tokens: 111757417
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.445736912020948,
    "estimated_duration": 3600.1060481424556,
    "input_throughput": 7320.008535192245,
    "output_throughput": 6497.688036737069,
    "total_throughput": 13817.696571929315,
    "itl": 132.6449199232397,
    "ttft": 1310963.953990746,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 424,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4191663479804997,
    "arrivals": 185665,
    "finished_requests": 106474,
    "scheduler_time": 115.63999896323315
}
#Debug simulation 
Total elapsed time: 7.4458053830312565. Arrivals time: 0.3080556546919979 Scheduler time: 7.022781721316278 Scheduler overhead time: 0.040535027568694204 Adapter cache time: 0.014280630566645414 Engine time: 0.04141067806631327 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-8/adapters_96_slots_64_rate_1.6-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-8/adapters_96_slots_64_rate_1.6-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 17280, 66, 66, 66, 66, 17280, 66, 17280, 66, 33, 17280, 33, 33, 17280, 66, 17280, 66, 17280, 17280, 66, 33, 17280, 66, 33, 33, 66, 17280, 33, 66, 33, 33, 66, 66, 66, 33, 33, 17280, 66, 66, 33, 17280, 17280, 66, 17280, 17280, 66, 17280, 33, 17280, 66, 66, 66, 17280, 17280, 33, 33, 66, 33, 17280, 33, 33, 17280, 33, 66, 66, 33, 66, 17280, 17280, 17280, 66, 17280, 17280, 33, 33, 17280, 66, 17280, 33, 66, 17280, 33, 17280, 66, 33, 17280, 33, 33, 17280, 33, 33, 66]
Prompts retrieved: 556128 . Total input tokens: 123911371 . Total output tokens: 111312136
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 7.397244324034546,
    "estimated_duration": 3600.0373104398564,
    "input_throughput": 7511.632149361241,
    "output_throughput": 6639.829240291799,
    "total_throughput": 14151.461389653039,
    "itl": 129.50768239941593,
    "ttft": 1274310.327701644,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 357,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.092594124583995,
    "arrivals": 184921,
    "finished_requests": 109054,
    "scheduler_time": 117.86987688332862
}
#Debug simulation 
Total elapsed time: 7.3973313930328. Arrivals time: 0.33480837696697563 Scheduler time: 6.9469163788016886 Scheduler overhead time: 0.04160913865780458 Adapter cache time: 0.012662972672842443 Engine time: 0.04217382875503972 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-16/adapters_96_slots_64_rate_1.6-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-16/adapters_96_slots_64_rate_1.6-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 17280, 66, 66, 66, 66, 17280, 66, 17280, 66, 33, 17280, 33, 33, 17280, 66, 17280, 66, 17280, 17280, 66, 33, 17280, 66, 33, 33, 66, 17280, 33, 66, 33, 33, 66, 66, 66, 33, 33, 17280, 66, 66, 33, 17280, 17280, 66, 17280, 17280, 66, 17280, 33, 17280, 66, 66, 66, 17280, 17280, 33, 33, 66, 33, 17280, 33, 33, 17280, 33, 66, 66, 33, 66, 17280, 17280, 17280, 66, 17280, 17280, 33, 33, 17280, 66, 17280, 33, 66, 17280, 33, 17280, 66, 33, 17280, 33, 33, 17280, 33, 33, 66]
Prompts retrieved: 556128 . Total input tokens: 123911371 . Total output tokens: 111312136
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.395224750973284,
    "estimated_duration": 3600.107014667842,
    "input_throughput": 7511.486711317941,
    "output_throughput": 6639.7006818436,
    "total_throughput": 14151.187393161541,
    "itl": 129.5093687170154,
    "ttft": 1274340.6209927036,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 357,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1655108317057656,
    "arrivals": 184921,
    "finished_requests": 109054,
    "scheduler_time": 117.87060673047579
}
#Debug simulation 
Total elapsed time: 7.3953474599984474. Arrivals time: 0.3169705339241773 Scheduler time: 6.96329967037309 Scheduler overhead time: 0.04149322066223249 Adapter cache time: 0.012617299857083708 Engine time: 0.04175520275020972 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-32/adapters_96_slots_64_rate_1.6-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-32/adapters_96_slots_64_rate_1.6-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 17280, 66, 66, 66, 66, 17280, 66, 17280, 66, 33, 17280, 33, 33, 17280, 66, 17280, 66, 17280, 17280, 66, 33, 17280, 66, 33, 33, 66, 17280, 33, 66, 33, 33, 66, 66, 66, 33, 33, 17280, 66, 66, 33, 17280, 17280, 66, 17280, 17280, 66, 17280, 33, 17280, 66, 66, 66, 17280, 17280, 33, 33, 66, 33, 17280, 33, 33, 17280, 33, 66, 66, 33, 66, 17280, 17280, 17280, 66, 17280, 17280, 33, 33, 17280, 66, 17280, 33, 66, 17280, 33, 17280, 66, 33, 17280, 33, 33, 17280, 33, 33, 66]
Prompts retrieved: 556128 . Total input tokens: 123911371 . Total output tokens: 111312136
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.388925798994023,
    "estimated_duration": 3600.109103356776,
    "input_throughput": 7511.482353350246,
    "output_throughput": 6639.696829663309,
    "total_throughput": 14151.179183013555,
    "itl": 129.50942382555212,
    "ttft": 1274341.589428721,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 357,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1674756276980107,
    "arrivals": 184921,
    "finished_requests": 109054,
    "scheduler_time": 117.87062486825207
}
#Debug simulation 
Total elapsed time: 7.389013135980349. Arrivals time: 0.3258804202778265 Scheduler time: 6.948137349507306 Scheduler overhead time: 0.04149048152612522 Adapter cache time: 0.01250129082472995 Engine time: 0.04192397143924609 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-16-16/adapters_96_slots_64_rate_1.6-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-16-16/adapters_96_slots_64_rate_1.6-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 17280, 66, 66, 66, 66, 17280, 66, 17280, 66, 33, 17280, 33, 33, 17280, 66, 17280, 66, 17280, 17280, 66, 33, 17280, 66, 33, 33, 66, 17280, 33, 66, 33, 33, 66, 66, 66, 33, 33, 17280, 66, 66, 33, 17280, 17280, 66, 17280, 17280, 66, 17280, 33, 17280, 66, 66, 66, 17280, 17280, 33, 33, 66, 33, 17280, 33, 33, 17280, 33, 66, 66, 33, 66, 17280, 17280, 17280, 66, 17280, 17280, 33, 33, 17280, 66, 17280, 33, 66, 17280, 33, 17280, 66, 33, 17280, 33, 33, 17280, 33, 33, 66]
Prompts retrieved: 556128 . Total input tokens: 123911371 . Total output tokens: 111312136
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 7.4267072469810955,
    "estimated_duration": 3600.067784373885,
    "input_throughput": 7511.568564729985,
    "output_throughput": 6639.77303531724,
    "total_throughput": 14151.341600047224,
    "itl": 129.50858970947345,
    "ttft": 1274324.0212341526,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 357,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.117705179448241,
    "arrivals": 184921,
    "finished_requests": 109054,
    "scheduler_time": 117.87027621329136
}
#Debug simulation 
Total elapsed time: 7.426798230968416. Arrivals time: 0.31671225058380514 Scheduler time: 6.99454291415168 Scheduler overhead time: 0.041695813182741404 Adapter cache time: 0.01274819829268381 Engine time: 0.0418750824755989 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-16-32/adapters_96_slots_64_rate_1.6-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-16-32/adapters_96_slots_64_rate_1.6-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 17280, 66, 66, 66, 66, 17280, 66, 17280, 66, 33, 17280, 33, 33, 17280, 66, 17280, 66, 17280, 17280, 66, 33, 17280, 66, 33, 33, 66, 17280, 33, 66, 33, 33, 66, 66, 66, 33, 33, 17280, 66, 66, 33, 17280, 17280, 66, 17280, 17280, 66, 17280, 33, 17280, 66, 66, 66, 17280, 17280, 33, 33, 66, 33, 17280, 33, 33, 17280, 33, 66, 66, 33, 66, 17280, 17280, 17280, 66, 17280, 17280, 33, 33, 17280, 66, 17280, 33, 66, 17280, 33, 17280, 66, 33, 17280, 33, 33, 17280, 33, 33, 66]
Prompts retrieved: 556128 . Total input tokens: 123911371 . Total output tokens: 111312136
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 7.413334073964506,
    "estimated_duration": 3600.02630143506,
    "input_throughput": 7511.587342909251,
    "output_throughput": 6639.682324118482,
    "total_throughput": 14151.269667027733,
    "itl": 129.5110254275361,
    "ttft": 1274359.9896254411,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 357,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1821888207085478,
    "arrivals": 184921,
    "finished_requests": 109051,
    "scheduler_time": 117.86691349950082
}
#Debug simulation 
Total elapsed time: 7.413462966971565. Arrivals time: 0.3167394401389174 Scheduler time: 6.981161286996212 Scheduler overhead time: 0.041784294007811695 Adapter cache time: 0.012515992217231542 Engine time: 0.04208207316696644 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_16-16-16/adapters_96_slots_64_rate_1.6-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_16-16-16/adapters_96_slots_64_rate_1.6-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 17280, 66, 66, 66, 66, 17280, 66, 17280, 66, 33, 17280, 33, 33, 17280, 66, 17280, 66, 17280, 17280, 66, 33, 17280, 66, 33, 33, 66, 17280, 33, 66, 33, 33, 66, 66, 66, 33, 33, 17280, 66, 66, 33, 17280, 17280, 66, 17280, 17280, 66, 17280, 33, 17280, 66, 66, 66, 17280, 17280, 33, 33, 66, 33, 17280, 33, 33, 17280, 33, 66, 66, 33, 66, 17280, 17280, 17280, 66, 17280, 17280, 33, 33, 17280, 66, 17280, 33, 66, 17280, 33, 17280, 66, 33, 17280, 33, 33, 17280, 33, 33, 66]
Prompts retrieved: 556128 . Total input tokens: 123911371 . Total output tokens: 111312136
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 7.410949104989413,
    "estimated_duration": 3600.0065398878455,
    "input_throughput": 7511.696353985643,
    "output_throughput": 6639.88599330286,
    "total_throughput": 14151.582347288504,
    "itl": 129.50685083551332,
    "ttft": 1274300.9672944054,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 357,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0674479552800757,
    "arrivals": 184921,
    "finished_requests": 109054,
    "scheduler_time": 117.86964794334159
}
#Debug simulation 
Total elapsed time: 7.411061686987523. Arrivals time: 0.33539092901628464 Scheduler time: 6.9594230079092085 Scheduler overhead time: 0.04193799162749201 Adapter cache time: 0.01266748271882534 Engine time: 0.04236511298222467 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_16-16-32/adapters_96_slots_64_rate_1.6-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_16-16-32/adapters_96_slots_64_rate_1.6-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 17280, 66, 66, 66, 66, 17280, 66, 17280, 66, 33, 17280, 33, 33, 17280, 66, 17280, 66, 17280, 17280, 66, 33, 17280, 66, 33, 33, 66, 17280, 33, 66, 33, 33, 66, 66, 66, 33, 33, 17280, 66, 66, 33, 17280, 17280, 66, 17280, 17280, 66, 17280, 33, 17280, 66, 66, 66, 17280, 17280, 33, 33, 66, 33, 17280, 33, 33, 17280, 33, 66, 66, 33, 66, 17280, 17280, 17280, 66, 17280, 17280, 33, 33, 17280, 66, 17280, 33, 66, 17280, 33, 17280, 66, 33, 17280, 33, 33, 17280, 33, 33, 66]
Prompts retrieved: 556128 . Total input tokens: 123911371 . Total output tokens: 111312136
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.404980372986756,
    "estimated_duration": 3600.0366727207265,
    "input_throughput": 7511.6123690937175,
    "output_throughput": 6639.736528554608,
    "total_throughput": 14151.348897648326,
    "itl": 129.51115761629424,
    "ttft": 1274340.736643693,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 357,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1976565364375744,
    "arrivals": 184921,
    "finished_requests": 109052,
    "scheduler_time": 117.86770984144741
}
#Debug simulation 
Total elapsed time: 7.405094759014901. Arrivals time: 0.31153758137952536 Scheduler time: 6.9779885283787735 Scheduler overhead time: 0.041505933622829616 Adapter cache time: 0.012635251856409013 Engine time: 0.04227653716225177 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-8-8/adapters_96_slots_64_rate_0.8-0.4-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-8-8/adapters_96_slots_64_rate_0.8-0.4-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 1080, 8640, 1080, 1080, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 1080, 8640, 4320, 1080, 1080, 4320, 8640, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 8640, 4320, 4320, 1080, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 1080, 8640, 4320, 4320, 4320, 8640, 8640, 1080, 1080, 4320, 1080, 8640, 1080, 1080, 8640, 1080, 4320, 4320, 1080, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 1080, 1080, 8640, 4320, 8640, 1080, 4320, 8640, 1080, 8640, 4320, 1080, 8640, 1080, 1080, 8640, 1080, 1080, 4320]
Prompts retrieved: 449280 . Total input tokens: 100180638 . Total output tokens: 89863988
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 29.28817567700753,
    "estimated_duration": 3600.150912272615,
    "input_throughput": 6325.966759438846,
    "output_throughput": 5635.575422918176,
    "total_throughput": 11961.542182357021,
    "itl": 152.90244509556607,
    "ttft": 1299427.6772820035,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 121,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3703190170158628,
    "arrivals": 149510,
    "finished_requests": 92449,
    "scheduler_time": 98.70052451505367
}
#Debug simulation 
Total elapsed time: 29.28830116399331. Arrivals time: 0.37514982518041506 Scheduler time: 28.78538566478528 Scheduler overhead time: 0.04823885438963771 Adapter cache time: 0.009357646282296628 Engine time: 0.05088461661944166 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-8-16/adapters_96_slots_64_rate_0.8-0.4-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-8-16/adapters_96_slots_64_rate_0.8-0.4-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 1080, 8640, 1080, 1080, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 1080, 8640, 4320, 1080, 1080, 4320, 8640, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 8640, 4320, 4320, 1080, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 1080, 8640, 4320, 4320, 4320, 8640, 8640, 1080, 1080, 4320, 1080, 8640, 1080, 1080, 8640, 1080, 4320, 4320, 1080, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 1080, 1080, 8640, 4320, 8640, 1080, 4320, 8640, 1080, 8640, 4320, 1080, 8640, 1080, 1080, 8640, 1080, 1080, 4320]
Prompts retrieved: 449280 . Total input tokens: 100180638 . Total output tokens: 89863988
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 27.991120672028046,
    "estimated_duration": 3600.044141248835,
    "input_throughput": 6326.571593674726,
    "output_throughput": 5636.428666944354,
    "total_throughput": 11963.00026061908,
    "itl": 152.917117985502,
    "ttft": 1302389.0895686008,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 125,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.40930407956708215,
    "arrivals": 149510,
    "finished_requests": 92432,
    "scheduler_time": 98.6966430366691
}
#Debug simulation 
Total elapsed time: 27.991277710010763. Arrivals time: 0.36657759081572294 Scheduler time: 27.50050627766177 Scheduler overhead time: 0.04762213758658618 Adapter cache time: 0.008976206707302481 Engine time: 0.04879088653251529 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-8-32/adapters_96_slots_64_rate_0.8-0.4-0.1_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-8-32/adapters_96_slots_64_rate_0.8-0.4-0.1_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 1080, 8640, 1080, 1080, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 1080, 8640, 4320, 1080, 1080, 4320, 8640, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 8640, 4320, 4320, 1080, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 1080, 8640, 4320, 4320, 4320, 8640, 8640, 1080, 1080, 4320, 1080, 8640, 1080, 1080, 8640, 1080, 4320, 4320, 1080, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 1080, 1080, 8640, 4320, 8640, 1080, 4320, 8640, 1080, 8640, 4320, 1080, 8640, 1080, 1080, 8640, 1080, 1080, 4320]
Prompts retrieved: 449280 . Total input tokens: 100180638 . Total output tokens: 89863988
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 27.831754322978668,
    "estimated_duration": 3600.0539985630144,
    "input_throughput": 6326.5792705029435,
    "output_throughput": 5636.415178244395,
    "total_throughput": 11962.994448747339,
    "itl": 152.91730008396084,
    "ttft": 1302393.5979770108,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 125,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4097803881205629,
    "arrivals": 149510,
    "finished_requests": 92432,
    "scheduler_time": 98.69697602659764
}
#Debug simulation 
Total elapsed time: 27.831874197989237. Arrivals time: 0.3664560482138768 Scheduler time: 27.34116103546694 Scheduler overhead time: 0.04738755087601021 Adapter cache time: 0.009124740667175502 Engine time: 0.0487364653381519 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-16-16/adapters_96_slots_64_rate_0.8-0.4-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-16-16/adapters_96_slots_64_rate_0.8-0.4-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 1080, 8640, 1080, 1080, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 1080, 8640, 4320, 1080, 1080, 4320, 8640, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 8640, 4320, 4320, 1080, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 1080, 8640, 4320, 4320, 4320, 8640, 8640, 1080, 1080, 4320, 1080, 8640, 1080, 1080, 8640, 1080, 4320, 4320, 1080, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 1080, 1080, 8640, 4320, 8640, 1080, 4320, 8640, 1080, 8640, 4320, 1080, 8640, 1080, 1080, 8640, 1080, 1080, 4320]
Prompts retrieved: 449280 . Total input tokens: 100180638 . Total output tokens: 89863988
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 28.043983993993606,
    "estimated_duration": 3600.0042904256898,
    "input_throughput": 6326.700515489327,
    "output_throughput": 5636.623837912301,
    "total_throughput": 11963.324353401627,
    "itl": 152.91748498754993,
    "ttft": 1302344.634547541,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 125,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3909172902372668,
    "arrivals": 149510,
    "finished_requests": 92433,
    "scheduler_time": 98.69572435007562
}
#Debug simulation 
Total elapsed time: 28.044174114009365. Arrivals time: 0.3649832199444063 Scheduler time: 27.553794125036802 Scheduler overhead time: 0.04736246191896498 Adapter cache time: 0.009456118161324412 Engine time: 0.04946123727131635 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-16-32/adapters_96_slots_64_rate_0.8-0.4-0.1_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-16-32/adapters_96_slots_64_rate_0.8-0.4-0.1_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 1080, 8640, 1080, 1080, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 1080, 8640, 4320, 1080, 1080, 4320, 8640, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 8640, 4320, 4320, 1080, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 1080, 8640, 4320, 4320, 4320, 8640, 8640, 1080, 1080, 4320, 1080, 8640, 1080, 1080, 8640, 1080, 4320, 4320, 1080, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 1080, 1080, 8640, 4320, 8640, 1080, 4320, 8640, 1080, 8640, 4320, 1080, 8640, 1080, 1080, 8640, 1080, 1080, 4320]
Prompts retrieved: 449280 . Total input tokens: 100180638 . Total output tokens: 89863988
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 28.442376673978288,
    "estimated_duration": 3600.0902607280495,
    "input_throughput": 6327.009699860587,
    "output_throughput": 5636.64089796911,
    "total_throughput": 11963.650597829697,
    "itl": 152.9183579849348,
    "ttft": 1302313.0552779238,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 125,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.41543930850923094,
    "arrivals": 149510,
    "finished_requests": 92438,
    "scheduler_time": 98.69801578156923
}
#Debug simulation 
Total elapsed time: 28.442504225997254. Arrivals time: 0.3736164713627659 Scheduler time: 27.940511617751326 Scheduler overhead time: 0.049005879438482225 Adapter cache time: 0.009876883181277663 Engine time: 0.05004668509354815 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_16-16-16/adapters_96_slots_64_rate_0.8-0.4-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_16-16-16/adapters_96_slots_64_rate_0.8-0.4-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 1080, 8640, 1080, 1080, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 1080, 8640, 4320, 1080, 1080, 4320, 8640, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 8640, 4320, 4320, 1080, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 1080, 8640, 4320, 4320, 4320, 8640, 8640, 1080, 1080, 4320, 1080, 8640, 1080, 1080, 8640, 1080, 4320, 4320, 1080, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 1080, 1080, 8640, 4320, 8640, 1080, 4320, 8640, 1080, 8640, 4320, 1080, 8640, 1080, 1080, 8640, 1080, 1080, 4320]
Prompts retrieved: 449280 . Total input tokens: 100180638 . Total output tokens: 89863988
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 29.434014711005148,
    "estimated_duration": 3600.127713265315,
    "input_throughput": 6326.007523589655,
    "output_throughput": 5635.611738228573,
    "total_throughput": 11961.619261818227,
    "itl": 152.90287543830104,
    "ttft": 1299403.1162595074,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 121,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3617960856831637,
    "arrivals": 149510,
    "finished_requests": 92449,
    "scheduler_time": 98.69999040381956
}
#Debug simulation 
Total elapsed time: 29.434136596042663. Arrivals time: 0.36710868711816147 Scheduler time: 28.94209541537566 Scheduler overhead time: 0.04763493698555976 Adapter cache time: 0.00929730461211875 Engine time: 0.048555475019384176 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_16-16-32/adapters_96_slots_64_rate_0.8-0.4-0.1_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_16-16-32/adapters_96_slots_64_rate_0.8-0.4-0.1_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 1080, 8640, 1080, 1080, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 1080, 8640, 4320, 1080, 1080, 4320, 8640, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 8640, 4320, 4320, 1080, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 1080, 8640, 4320, 4320, 4320, 8640, 8640, 1080, 1080, 4320, 1080, 8640, 1080, 1080, 8640, 1080, 4320, 4320, 1080, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 1080, 1080, 8640, 4320, 8640, 1080, 4320, 8640, 1080, 8640, 4320, 1080, 8640, 1080, 1080, 8640, 1080, 1080, 4320]
Prompts retrieved: 449280 . Total input tokens: 100180638 . Total output tokens: 89863988
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 28.401903113001026,
    "estimated_duration": 3600.0141818690886,
    "input_throughput": 6327.0103531020695,
    "output_throughput": 5635.354466705746,
    "total_throughput": 11962.364819807815,
    "itl": 152.90841242008858,
    "ttft": 1301694.6884800578,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 124,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.41721444740891417,
    "arrivals": 149510,
    "finished_requests": 92439,
    "scheduler_time": 98.69597649989399
}
#Debug simulation 
Total elapsed time: 28.402065259986557. Arrivals time: 0.36802952241851017 Scheduler time: 27.9075112354476 Scheduler overhead time: 0.04875151556916535 Adapter cache time: 0.009114219225011766 Engine time: 0.04905417189002037 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-8-8/adapters_96_slots_64_rate_0.8-0.4-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-8-8/adapters_96_slots_64_rate_0.8-0.4-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 540, 8640, 540, 540, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 540, 8640, 4320, 540, 540, 4320, 8640, 540, 4320, 540, 540, 4320, 4320, 4320, 540, 540, 8640, 4320, 4320, 540, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 540, 8640, 4320, 4320, 4320, 8640, 8640, 540, 540, 4320, 540, 8640, 540, 540, 8640, 540, 4320, 4320, 540, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 540, 540, 8640, 4320, 8640, 540, 4320, 8640, 540, 8640, 4320, 540, 8640, 540, 540, 8640, 540, 540, 4320]
Prompts retrieved: 432000 . Total input tokens: 96291061 . Total output tokens: 86418789
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 19.703754668997135,
    "estimated_duration": 3600.1371033600276,
    "input_throughput": 6386.930369551686,
    "output_throughput": 5631.258037667181,
    "total_throughput": 12018.188407218868,
    "itl": 152.0174540676191,
    "ttft": 1253060.1047882382,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 115,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3519560905522663,
    "arrivals": 143761,
    "finished_requests": 92511,
    "scheduler_time": 97.90476834735838
}
#Debug simulation 
Total elapsed time: 19.70387396600563. Arrivals time: 0.3346283750724979 Scheduler time: 19.254125266277697 Scheduler overhead time: 0.044195344438776374 Adapter cache time: 0.008196841517928988 Engine time: 0.044468435167800635 
