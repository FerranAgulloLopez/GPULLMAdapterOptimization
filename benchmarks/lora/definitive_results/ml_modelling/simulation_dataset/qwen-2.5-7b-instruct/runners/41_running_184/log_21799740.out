INFO 06-01 00:46:59 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 06-01 00:46:59 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-16/adapters_96_slots_64_rate_0.025-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-16/adapters_96_slots_64_rate_0.025-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 270, 135, 135, 135, 135, 270, 135, 270, 135, 33, 270, 33, 33, 270, 135, 270, 135, 270, 270, 135, 33, 270, 135, 33, 33, 135, 270, 33, 135, 33, 33, 135, 135, 135, 33, 33, 270, 135, 135, 33, 270, 270, 135, 270, 270, 135, 270, 33, 270, 135, 135, 135, 270, 270, 33, 33, 135, 33, 270, 33, 33, 270, 33, 135, 135, 33, 135, 270, 270, 270, 135, 270, 270, 33, 33, 270, 135, 270, 33, 135, 270, 33, 270, 135, 33, 270, 33, 33, 270, 33, 33, 135]
Prompts retrieved: 14016 . Total input tokens: 3078471 . Total output tokens: 2840300
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 0.8802555571310222,
    "estimated_duration": 3598.58207731049,
    "input_throughput": 324.56366838599865,
    "output_throughput": 281.96744667787436,
    "total_throughput": 606.531115063873,
    "itl": 18.70275552090398,
    "ttft": 6913.183252842853,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 768,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2963586264848264,
    "arrivals": 4708,
    "finished_requests": 4699,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8803888149559498. Arrivals time: 0.026056612376123667 Scheduler time: 0.42842219304293394 Scheduler overhead time: 0.1500927396118641 Adapter cache time: 0.045404696837067604 Engine time: 0.15433488925918937 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-32/adapters_96_slots_64_rate_0.025-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-32/adapters_96_slots_64_rate_0.025-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 270, 135, 135, 135, 135, 270, 135, 270, 135, 33, 270, 33, 33, 270, 135, 270, 135, 270, 270, 135, 33, 270, 135, 33, 33, 135, 270, 33, 135, 33, 33, 135, 135, 135, 33, 33, 270, 135, 135, 33, 270, 270, 135, 270, 270, 135, 270, 33, 270, 135, 135, 135, 270, 270, 33, 33, 135, 33, 270, 33, 33, 270, 33, 135, 135, 33, 135, 270, 270, 270, 135, 270, 270, 33, 33, 270, 135, 270, 33, 135, 270, 33, 270, 135, 33, 270, 33, 33, 270, 33, 33, 135]
Prompts retrieved: 14016 . Total input tokens: 3078471 . Total output tokens: 2840300
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 0.8603262910619378,
    "estimated_duration": 3598.5701317401595,
    "input_throughput": 324.56474578562836,
    "output_throughput": 281.9683826779638,
    "total_throughput": 606.5331284635922,
    "itl": 18.70428121022492,
    "ttft": 6913.336901609838,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 768,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.5740161304175997,
    "arrivals": 4708,
    "finished_requests": 4699,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8604222070425749. Arrivals time: 0.02527834987267852 Scheduler time: 0.41739843832328916 Scheduler overhead time: 0.1479011857882142 Adapter cache time: 0.04526605177670717 Engine time: 0.1498650759458542 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-8/adapters_96_slots_64_rate_0.025-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-8/adapters_96_slots_64_rate_0.025-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 270, 66, 66, 66, 66, 270, 66, 270, 66, 33, 270, 33, 33, 270, 66, 270, 66, 270, 270, 66, 33, 270, 66, 33, 33, 66, 270, 33, 66, 33, 33, 66, 66, 66, 33, 33, 270, 66, 66, 33, 270, 270, 66, 270, 270, 66, 270, 33, 270, 66, 66, 66, 270, 270, 33, 33, 66, 33, 270, 33, 33, 270, 33, 66, 66, 33, 66, 270, 270, 270, 66, 270, 270, 33, 33, 270, 66, 270, 33, 66, 270, 33, 270, 66, 33, 270, 33, 33, 270, 33, 33, 66]
Prompts retrieved: 11808 . Total input tokens: 2568820 . Total output tokens: 2402004
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 0.8087386982515454,
    "estimated_duration": 3599.5910342815228,
    "input_throughput": 265.7843601921739,
    "output_throughput": 238.59877186615668,
    "total_throughput": 504.38313205833055,
    "itl": 18.51705439919648,
    "ttft": 3697.7432183768633,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 607,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.85771606056721,
    "arrivals": 3927,
    "finished_requests": 3923,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8088395963422954. Arrivals time: 0.024899679701775312 Scheduler time: 0.37123109120875597 Scheduler overhead time: 0.14652785379439592 Adapter cache time: 0.04098159773275256 Engine time: 0.1507422486320138 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-16/adapters_96_slots_64_rate_0.025-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-16/adapters_96_slots_64_rate_0.025-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 270, 66, 66, 66, 66, 270, 66, 270, 66, 33, 270, 33, 33, 270, 66, 270, 66, 270, 270, 66, 33, 270, 66, 33, 33, 66, 270, 33, 66, 33, 33, 66, 66, 66, 33, 33, 270, 66, 66, 33, 270, 270, 66, 270, 270, 66, 270, 33, 270, 66, 66, 66, 270, 270, 33, 33, 66, 33, 270, 33, 33, 270, 33, 66, 66, 33, 66, 270, 270, 270, 66, 270, 270, 33, 33, 270, 66, 270, 33, 66, 270, 33, 270, 66, 33, 270, 33, 33, 270, 33, 33, 66]
Prompts retrieved: 11808 . Total input tokens: 2568820 . Total output tokens: 2402004
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 0.8092409572564065,
    "estimated_duration": 3599.5823011218313,
    "input_throughput": 265.7850050273428,
    "output_throughput": 238.59935074476053,
    "total_throughput": 504.3843557721033,
    "itl": 18.518351771287243,
    "ttft": 3697.649824799034,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 607,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9800330376555269,
    "arrivals": 3927,
    "finished_requests": 3923,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8092982750386. Arrivals time: 0.02404970210045576 Scheduler time: 0.37198093067854643 Scheduler overhead time: 0.14702562894672155 Adapter cache time: 0.04122581705451012 Engine time: 0.15065469359979033 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-32/adapters_96_slots_64_rate_0.025-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-32/adapters_96_slots_64_rate_0.025-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 270, 66, 66, 66, 66, 270, 66, 270, 66, 33, 270, 33, 33, 270, 66, 270, 66, 270, 270, 66, 33, 270, 66, 33, 33, 66, 270, 33, 66, 33, 33, 66, 66, 66, 33, 33, 270, 66, 66, 33, 270, 270, 66, 270, 270, 66, 270, 33, 270, 66, 66, 66, 270, 270, 33, 33, 66, 33, 270, 33, 33, 270, 33, 66, 66, 33, 66, 270, 270, 270, 66, 270, 270, 33, 33, 270, 66, 270, 33, 66, 270, 33, 270, 66, 33, 270, 33, 33, 270, 33, 33, 66]
Prompts retrieved: 11808 . Total input tokens: 2568820 . Total output tokens: 2402004
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 0.8156142770312726,
    "estimated_duration": 3599.5825108404383,
    "input_throughput": 265.7849895421967,
    "output_throughput": 238.59933684350298,
    "total_throughput": 504.3843263856997,
    "itl": 18.518378790728683,
    "ttft": 3697.6753082008286,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 607,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9836639289930587,
    "arrivals": 3927,
    "finished_requests": 3923,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8156786640174687. Arrivals time: 0.023756676353514194 Scheduler time: 0.3773447754792869 Scheduler overhead time: 0.14763187151402235 Adapter cache time: 0.041419338434934616 Engine time: 0.15084782056510448 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-16/adapters_96_slots_64_rate_0.025-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-16/adapters_96_slots_64_rate_0.025-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 270, 66, 66, 66, 66, 270, 66, 270, 66, 33, 270, 33, 33, 270, 66, 270, 66, 270, 270, 66, 33, 270, 66, 33, 33, 66, 270, 33, 66, 33, 33, 66, 66, 66, 33, 33, 270, 66, 66, 33, 270, 270, 66, 270, 270, 66, 270, 33, 270, 66, 66, 66, 270, 270, 33, 33, 66, 33, 270, 33, 33, 270, 33, 66, 66, 33, 66, 270, 270, 270, 66, 270, 270, 33, 33, 270, 66, 270, 33, 66, 270, 33, 270, 66, 33, 270, 33, 33, 270, 33, 33, 66]
Prompts retrieved: 11808 . Total input tokens: 2568820 . Total output tokens: 2402004
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 0.8142600366845727,
    "estimated_duration": 3599.594662547308,
    "input_throughput": 265.78409229081535,
    "output_throughput": 238.59853136692232,
    "total_throughput": 504.38262365773767,
    "itl": 18.51730499728013,
    "ttft": 3697.727289176918,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 607,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.897088188012118,
    "arrivals": 3927,
    "finished_requests": 3923,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8143370999023318. Arrivals time: 0.02437914116308093 Scheduler time: 0.3716523554176092 Scheduler overhead time: 0.14819244295358658 Adapter cache time: 0.04189404705539346 Engine time: 0.15344727830961347 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-32/adapters_96_slots_64_rate_0.025-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-32/adapters_96_slots_64_rate_0.025-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 270, 66, 66, 66, 66, 270, 66, 270, 66, 33, 270, 33, 33, 270, 66, 270, 66, 270, 270, 66, 33, 270, 66, 33, 33, 66, 270, 33, 66, 33, 33, 66, 66, 66, 33, 33, 270, 66, 66, 33, 270, 270, 66, 270, 270, 66, 270, 33, 270, 66, 66, 66, 270, 270, 33, 33, 66, 33, 270, 33, 33, 270, 33, 66, 66, 33, 66, 270, 270, 270, 66, 270, 270, 33, 33, 270, 66, 270, 33, 66, 270, 33, 270, 66, 33, 270, 33, 33, 270, 33, 33, 66]
Prompts retrieved: 11808 . Total input tokens: 2568820 . Total output tokens: 2402004
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 0.8141749710775912,
    "estimated_duration": 3599.584833147539,
    "input_throughput": 265.7848180684304,
    "output_throughput": 238.59918290882445,
    "total_throughput": 504.38400097725486,
    "itl": 18.518006596972004,
    "ttft": 3697.695691033153,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 607,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.009191947635266,
    "arrivals": 3927,
    "finished_requests": 3923,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8142486261203885. Arrivals time: 0.023683296516537666 Scheduler time: 0.3760062572546303 Scheduler overhead time: 0.14724453957751393 Adapter cache time: 0.041523344814777374 Engine time: 0.15134881436824799 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-16/adapters_96_slots_64_rate_0.025-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-16/adapters_96_slots_64_rate_0.025-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 270, 66, 66, 66, 66, 270, 66, 270, 66, 33, 270, 33, 33, 270, 66, 270, 66, 270, 270, 66, 33, 270, 66, 33, 33, 66, 270, 33, 66, 33, 33, 66, 66, 66, 33, 33, 270, 66, 66, 33, 270, 270, 66, 270, 270, 66, 270, 33, 270, 66, 66, 66, 270, 270, 33, 33, 66, 33, 270, 33, 33, 270, 33, 66, 66, 33, 66, 270, 270, 270, 66, 270, 270, 33, 33, 270, 66, 270, 33, 66, 270, 33, 270, 66, 33, 270, 33, 33, 270, 33, 33, 66]
Prompts retrieved: 11808 . Total input tokens: 2568820 . Total output tokens: 2402004
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 0.8332003313116729,
    "estimated_duration": 3599.5873249132824,
    "input_throughput": 265.7846340824773,
    "output_throughput": 238.59901774176038,
    "total_throughput": 504.38365182423763,
    "itl": 18.516924605580638,
    "ttft": 3697.8023770582904,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 607,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.814960529005593,
    "arrivals": 3927,
    "finished_requests": 3923,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.833322430960834. Arrivals time: 0.024925686419010162 Scheduler time: 0.39063605992123485 Scheduler overhead time: 0.14861921314150095 Adapter cache time: 0.04368822369724512 Engine time: 0.15040136082097888 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-32/adapters_96_slots_64_rate_0.025-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-32/adapters_96_slots_64_rate_0.025-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 270, 66, 66, 66, 66, 270, 66, 270, 66, 33, 270, 33, 33, 270, 66, 270, 66, 270, 270, 66, 33, 270, 66, 33, 33, 66, 270, 33, 66, 33, 33, 66, 66, 66, 33, 33, 270, 66, 66, 33, 270, 270, 66, 270, 270, 66, 270, 33, 270, 66, 66, 66, 270, 270, 33, 33, 66, 33, 270, 33, 33, 270, 33, 66, 66, 33, 66, 270, 270, 270, 66, 270, 270, 33, 33, 270, 66, 270, 33, 66, 270, 33, 270, 66, 33, 270, 33, 33, 270, 33, 33, 66]
Prompts retrieved: 11808 . Total input tokens: 2568820 . Total output tokens: 2402004
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 0.8124002180993557,
    "estimated_duration": 3599.5875583898655,
    "input_throughput": 265.78461684314436,
    "output_throughput": 238.59900226574194,
    "total_throughput": 504.3836191088863,
    "itl": 18.518320295035764,
    "ttft": 3697.768594126616,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 607,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.034468458704646,
    "arrivals": 3927,
    "finished_requests": 3923,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8126576258800924. Arrivals time: 0.024257051292806864 Scheduler time: 0.3736034194007516 Scheduler overhead time: 0.14689690805971622 Adapter cache time: 0.041868242900818586 Engine time: 0.15144459903240204 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-8/adapters_96_slots_64_rate_0.0125-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-8/adapters_96_slots_64_rate_0.0125-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 135, 66, 66, 66, 66, 135, 66, 135, 66, 33, 135, 33, 33, 135, 66, 135, 66, 135, 135, 66, 33, 135, 66, 33, 33, 66, 135, 33, 66, 33, 33, 66, 66, 66, 33, 33, 135, 66, 66, 33, 135, 135, 66, 135, 135, 66, 135, 33, 135, 66, 66, 66, 135, 135, 33, 33, 66, 33, 135, 33, 33, 135, 33, 66, 66, 33, 66, 135, 135, 135, 66, 135, 135, 33, 33, 135, 66, 135, 33, 66, 135, 33, 135, 66, 33, 135, 33, 33, 135, 33, 33, 66]
Prompts retrieved: 7488 . Total input tokens: 1626076 . Total output tokens: 1517852
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 0.6931551340967417,
    "estimated_duration": 3599.017704460047,
    "input_throughput": 161.6349370215936,
    "output_throughput": 147.42328145329355,
    "total_throughput": 309.05821847488716,
    "itl": 17.964350261200217,
    "ttft": 8937.134288047928,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 580,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7750828914810228,
    "arrivals": 2425,
    "finished_requests": 2419,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6932128448970616. Arrivals time: 0.020116083789616823 Scheduler time: 0.2748483936302364 Scheduler overhead time: 0.14436383824795485 Adapter cache time: 0.034386841114610434 Engine time: 0.14682829286903143 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-16/adapters_96_slots_64_rate_0.0125-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-16/adapters_96_slots_64_rate_0.0125-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 135, 66, 66, 66, 66, 135, 66, 135, 66, 33, 135, 33, 33, 135, 66, 135, 66, 135, 135, 66, 33, 135, 66, 33, 33, 66, 135, 33, 66, 33, 33, 66, 66, 66, 33, 33, 135, 66, 66, 33, 135, 135, 66, 135, 135, 66, 135, 33, 135, 66, 66, 66, 135, 135, 33, 33, 66, 33, 135, 33, 33, 135, 33, 66, 66, 33, 66, 135, 135, 135, 66, 135, 135, 33, 33, 135, 66, 135, 33, 66, 135, 33, 135, 66, 33, 135, 33, 33, 135, 33, 33, 66]
Prompts retrieved: 7488 . Total input tokens: 1626076 . Total output tokens: 1517852
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 0.6938354503363371,
    "estimated_duration": 3599.0195258393633,
    "input_throughput": 161.63485522194537,
    "output_throughput": 147.42320684583072,
    "total_throughput": 309.05806206777606,
    "itl": 17.96504214426858,
    "ttft": 8937.074041300393,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 580,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8911297733243622,
    "arrivals": 2425,
    "finished_requests": 2419,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6938930121250451. Arrivals time: 0.019848845899105072 Scheduler time: 0.2772899381816387 Scheduler overhead time: 0.1429303139448166 Adapter cache time: 0.034352509304881096 Engine time: 0.14661586564034224 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-32/adapters_96_slots_64_rate_0.0125-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-32/adapters_96_slots_64_rate_0.0125-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 135, 66, 66, 66, 66, 135, 66, 135, 66, 33, 135, 33, 33, 135, 66, 135, 66, 135, 135, 66, 33, 135, 66, 33, 33, 66, 135, 33, 66, 33, 33, 66, 66, 66, 33, 33, 135, 66, 66, 33, 135, 135, 66, 135, 135, 66, 135, 33, 135, 66, 66, 66, 135, 135, 33, 33, 66, 33, 135, 33, 33, 135, 33, 66, 66, 33, 66, 135, 135, 135, 66, 135, 135, 33, 33, 135, 66, 135, 33, 66, 135, 33, 135, 66, 33, 135, 33, 33, 135, 33, 33, 66]
Prompts retrieved: 7488 . Total input tokens: 1626076 . Total output tokens: 1517852
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 0.6944143380969763,
    "estimated_duration": 3599.019543380122,
    "input_throughput": 161.63485443417585,
    "output_throughput": 147.42320612732533,
    "total_throughput": 309.0580605615012,
    "itl": 17.965053417925525,
    "ttft": 8937.115682398437,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 580,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.89474397018553,
    "arrivals": 2425,
    "finished_requests": 2419,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6944776768796146. Arrivals time: 0.019743033684790134 Scheduler time: 0.27558673452585936 Scheduler overhead time: 0.14312858833000064 Adapter cache time: 0.03432925743982196 Engine time: 0.14867967506870627 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-16/adapters_96_slots_64_rate_0.0125-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-16/adapters_96_slots_64_rate_0.0125-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 135, 66, 66, 66, 66, 135, 66, 135, 66, 33, 135, 33, 33, 135, 66, 135, 66, 135, 135, 66, 33, 135, 66, 33, 33, 66, 135, 33, 66, 33, 33, 66, 66, 66, 33, 33, 135, 66, 66, 33, 135, 135, 66, 135, 135, 66, 135, 33, 135, 66, 66, 66, 135, 135, 33, 33, 66, 33, 135, 33, 33, 135, 33, 66, 66, 33, 66, 135, 135, 135, 66, 135, 135, 33, 33, 135, 66, 135, 33, 66, 135, 33, 135, 66, 33, 135, 33, 33, 135, 33, 33, 66]
Prompts retrieved: 7488 . Total input tokens: 1626076 . Total output tokens: 1517852
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 0.691222476772964,
    "estimated_duration": 3599.0195258393633,
    "input_throughput": 161.63485522194537,
    "output_throughput": 147.42320684583072,
    "total_throughput": 309.05806206777606,
    "itl": 17.964528944920463,
    "ttft": 8937.144307911158,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 580,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8118622815469176,
    "arrivals": 2425,
    "finished_requests": 2419,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6913115889765322. Arrivals time: 0.01982797821983695 Scheduler time: 0.2750840703956783 Scheduler overhead time: 0.14413630310446024 Adapter cache time: 0.034201384987682104 Engine time: 0.14496853109449148 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-32/adapters_96_slots_64_rate_0.0125-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-32/adapters_96_slots_64_rate_0.0125-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 135, 66, 66, 66, 66, 135, 66, 135, 66, 33, 135, 33, 33, 135, 66, 135, 66, 135, 135, 66, 33, 135, 66, 33, 33, 66, 135, 33, 66, 33, 33, 66, 66, 66, 33, 33, 135, 66, 66, 33, 135, 135, 66, 135, 135, 66, 135, 33, 135, 66, 66, 66, 135, 135, 33, 33, 66, 33, 135, 33, 33, 135, 33, 66, 66, 33, 66, 135, 135, 135, 66, 135, 135, 33, 33, 135, 66, 135, 33, 66, 135, 33, 135, 66, 33, 135, 33, 33, 135, 33, 33, 66]
Prompts retrieved: 7488 . Total input tokens: 1626076 . Total output tokens: 1517852
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 0.6941735902801156,
    "estimated_duration": 3599.019543380122,
    "input_throughput": 161.63485443417585,
    "output_throughput": 147.42320612732533,
    "total_throughput": 309.0580605615012,
    "itl": 17.965203072740692,
    "ttft": 8937.12488486146,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 580,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9191402047500046,
    "arrivals": 2425,
    "finished_requests": 2419,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6942418082617223. Arrivals time: 0.0203749667853117 Scheduler time: 0.27556838374584913 Scheduler overhead time: 0.1434085643850267 Adapter cache time: 0.03472927771508694 Engine time: 0.14747515600174665 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-16/adapters_96_slots_64_rate_0.0125-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-16/adapters_96_slots_64_rate_0.0125-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 135, 66, 66, 66, 66, 135, 66, 135, 66, 33, 135, 33, 33, 135, 66, 135, 66, 135, 135, 66, 33, 135, 66, 33, 33, 66, 135, 33, 66, 33, 33, 66, 66, 66, 33, 33, 135, 66, 66, 33, 135, 135, 66, 135, 135, 66, 135, 33, 135, 66, 66, 66, 135, 135, 33, 33, 66, 33, 135, 33, 33, 135, 33, 66, 66, 33, 66, 135, 135, 135, 66, 135, 135, 33, 33, 135, 66, 135, 33, 66, 135, 33, 135, 66, 33, 135, 33, 33, 135, 33, 33, 66]
Prompts retrieved: 7488 . Total input tokens: 1626076 . Total output tokens: 1517852
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 0.6928641381673515,
    "estimated_duration": 3599.017211397905,
    "input_throughput": 161.6349591654355,
    "output_throughput": 147.4233016501514,
    "total_throughput": 309.0582608155869,
    "itl": 17.96413828150637,
    "ttft": 8937.161827329177,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 580,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7342291710432371,
    "arrivals": 2425,
    "finished_requests": 2419,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6929196370765567. Arrivals time: 0.020320290699601173 Scheduler time: 0.27462061354890466 Scheduler overhead time: 0.1439705272205174 Adapter cache time: 0.0344161014072597 Engine time: 0.14664680091664195 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-32/adapters_96_slots_64_rate_0.0125-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-32/adapters_96_slots_64_rate_0.0125-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 135, 66, 66, 66, 66, 135, 66, 135, 66, 33, 135, 33, 33, 135, 66, 135, 66, 135, 135, 66, 33, 135, 66, 33, 33, 66, 135, 33, 66, 33, 33, 66, 66, 66, 33, 33, 135, 66, 66, 33, 135, 135, 66, 135, 135, 66, 135, 33, 135, 66, 66, 66, 135, 135, 33, 33, 66, 33, 135, 33, 33, 135, 33, 66, 66, 33, 66, 135, 135, 135, 66, 135, 135, 33, 33, 135, 66, 135, 33, 66, 135, 33, 135, 66, 33, 135, 33, 33, 135, 33, 33, 66]
Prompts retrieved: 7488 . Total input tokens: 1626076 . Total output tokens: 1517852
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 0.6890853871591389,
    "estimated_duration": 3599.020172149052,
    "input_throughput": 161.63482619566378,
    "output_throughput": 147.42318037166763,
    "total_throughput": 309.0580065673314,
    "itl": 17.965329884957328,
    "ttft": 8937.065628506636,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 580,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9430334241688199,
    "arrivals": 2425,
    "finished_requests": 2419,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6891909721307456. Arrivals time: 0.019891527015715837 Scheduler time: 0.27550145145505667 Scheduler overhead time: 0.14396119164302945 Adapter cache time: 0.034241792280226946 Engine time: 0.14260948868468404 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-8-8/adapters_96_slots_96_rate_3.2-1.6-0.8_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-8-8/adapters_96_slots_96_rate_3.2-1.6-0.8_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [32 32 32]
Adapter prompts. [8640, 8640, 8640, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 8640, 34560, 8640, 8640, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 8640, 34560, 17280, 8640, 8640, 17280, 34560, 8640, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 34560, 17280, 17280, 8640, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 8640, 34560, 17280, 17280, 17280, 34560, 34560, 8640, 8640, 17280, 8640, 34560, 8640, 8640, 34560, 8640, 17280, 17280, 8640, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 8640, 8640, 34560, 17280, 34560, 8640, 17280, 34560, 8640, 34560, 17280, 8640, 34560, 8640, 8640, 34560, 8640, 8640, 17280]
Prompts retrieved: 1935360 . Total input tokens: 431807893 . Total output tokens: 386940663
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 5.537377762142569,
    "estimated_duration": 3600.1864459494445,
    "input_throughput": 5490.04205663785,
    "output_throughput": 4821.019205693585,
    "total_throughput": 10311.061262331434,
    "itl": 177.45617885827355,
    "ttft": 2051348.8009131583,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.29380682341754405,
    "arrivals": 644954,
    "finished_requests": 79985,
    "scheduler_time": 48.75658512827748
}
#Debug simulation 
Total elapsed time: 5.537491434253752. Arrivals time: 0.25978090055286884 Scheduler time: 5.192152354400605 Scheduler overhead time: 0.03118341276422143 Adapter cache time: 0.008199366740882397 Engine time: 0.0316423368640244 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-8-16/adapters_96_slots_96_rate_3.2-1.6-0.8_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-8-16/adapters_96_slots_96_rate_3.2-1.6-0.8_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [32 32 32]
Adapter prompts. [8640, 8640, 8640, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 8640, 34560, 8640, 8640, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 8640, 34560, 17280, 8640, 8640, 17280, 34560, 8640, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 34560, 17280, 17280, 8640, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 8640, 34560, 17280, 17280, 17280, 34560, 34560, 8640, 8640, 17280, 8640, 34560, 8640, 8640, 34560, 8640, 17280, 17280, 8640, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 8640, 8640, 34560, 17280, 34560, 8640, 17280, 34560, 8640, 34560, 17280, 8640, 34560, 8640, 8640, 34560, 8640, 8640, 17280]
Prompts retrieved: 1935360 . Total input tokens: 431807893 . Total output tokens: 386940663
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.560615546070039,
    "estimated_duration": 3600.068521073429,
    "input_throughput": 5490.034671369765,
    "output_throughput": 4820.9724060543795,
    "total_throughput": 10311.007077424145,
    "itl": 177.45653326108564,
    "ttft": 2051363.969206246,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31319492869079113,
    "arrivals": 644954,
    "finished_requests": 79981,
    "scheduler_time": 48.75474296448593
}
#Debug simulation 
Total elapsed time: 5.560716278851032. Arrivals time: 0.3646491914987564 Scheduler time: 5.112137819174677 Scheduler overhead time: 0.030295376665890217 Adapter cache time: 0.008146047126501799 Engine time: 0.03138415142893791 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-8-32/adapters_96_slots_96_rate_3.2-1.6-0.8_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-8-32/adapters_96_slots_96_rate_3.2-1.6-0.8_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [32 32 32]
Adapter prompts. [8640, 8640, 8640, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 8640, 34560, 8640, 8640, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 8640, 34560, 17280, 8640, 8640, 17280, 34560, 8640, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 34560, 17280, 17280, 8640, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 8640, 34560, 17280, 17280, 17280, 34560, 34560, 8640, 8640, 17280, 8640, 34560, 8640, 8640, 34560, 8640, 17280, 17280, 8640, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 8640, 8640, 34560, 17280, 34560, 8640, 17280, 34560, 8640, 34560, 17280, 8640, 34560, 8640, 8640, 34560, 8640, 8640, 17280]
Prompts retrieved: 1935360 . Total input tokens: 431807893 . Total output tokens: 386940663
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.534586041234434,
    "estimated_duration": 3600.1660153083185,
    "input_throughput": 5478.126818635333,
    "output_throughput": 4810.3062265357485,
    "total_throughput": 10288.433045171081,
    "itl": 175.65444690685587,
    "ttft": 2053109.7513940653,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3137616491317753,
    "arrivals": 644954,
    "finished_requests": 79823,
    "scheduler_time": 48.389836692030684
}
#Debug simulation 
Total elapsed time: 5.534726155921817. Arrivals time: 0.3246719059534371 Scheduler time: 5.1248666937462986 Scheduler overhead time: 0.030644363723695278 Adapter cache time: 0.00841950997710228 Engine time: 0.03166934894397855 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-16-16/adapters_96_slots_96_rate_3.2-1.6-0.8_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-16-16/adapters_96_slots_96_rate_3.2-1.6-0.8_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [32 32 32]
Adapter prompts. [8640, 8640, 8640, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 8640, 34560, 8640, 8640, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 8640, 34560, 17280, 8640, 8640, 17280, 34560, 8640, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 34560, 17280, 17280, 8640, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 8640, 34560, 17280, 17280, 17280, 34560, 34560, 8640, 8640, 17280, 8640, 34560, 8640, 8640, 34560, 8640, 17280, 17280, 8640, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 8640, 8640, 34560, 17280, 34560, 8640, 17280, 34560, 8640, 34560, 17280, 8640, 34560, 8640, 8640, 34560, 8640, 8640, 17280]
Prompts retrieved: 1935360 . Total input tokens: 431807893 . Total output tokens: 386940663
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 5.5427553919143975,
    "estimated_duration": 3600.0087710339585,
    "input_throughput": 5490.110512792849,
    "output_throughput": 4820.959643110905,
    "total_throughput": 10311.070155903753,
    "itl": 177.4551339532079,
    "ttft": 2051356.3799345817,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.30011987850070015,
    "arrivals": 644954,
    "finished_requests": 79980,
    "scheduler_time": 48.7542264349943
}
#Debug simulation 
Total elapsed time: 5.54288036795333. Arrivals time: 0.2635105112567544 Scheduler time: 5.19530962780118 Scheduler overhead time: 0.030269909650087357 Adapter cache time: 0.008250841405242682 Engine time: 0.03136876272037625 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-16-32/adapters_96_slots_96_rate_3.2-1.6-0.8_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-16-32/adapters_96_slots_96_rate_3.2-1.6-0.8_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [32 32 32]
Adapter prompts. [8640, 8640, 8640, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 8640, 34560, 8640, 8640, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 8640, 34560, 17280, 8640, 8640, 17280, 34560, 8640, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 34560, 17280, 17280, 8640, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 8640, 34560, 17280, 17280, 17280, 34560, 34560, 8640, 8640, 17280, 8640, 34560, 8640, 8640, 34560, 8640, 17280, 17280, 8640, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 8640, 8640, 34560, 17280, 34560, 8640, 17280, 34560, 8640, 34560, 17280, 8640, 34560, 8640, 8640, 34560, 8640, 8640, 17280]
Prompts retrieved: 1935360 . Total input tokens: 431807893 . Total output tokens: 386940663
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 5.516411186661571,
    "estimated_duration": 3600.175866023313,
    "input_throughput": 5478.11182951591,
    "output_throughput": 4810.293064691039,
    "total_throughput": 10288.40489420695,
    "itl": 175.65323868931722,
    "ttft": 2053117.0972134082,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31778577029705046,
    "arrivals": 644954,
    "finished_requests": 79823,
    "scheduler_time": 48.38978664991104
}
#Debug simulation 
Total elapsed time: 5.51652960665524. Arrivals time: 0.25688015297055244 Scheduler time: 5.174866382963955 Scheduler overhead time: 0.030466757249087095 Adapter cache time: 0.008528082631528378 Engine time: 0.031434142496436834 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_16-16-16/adapters_96_slots_96_rate_3.2-1.6-0.8_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_16-16-16/adapters_96_slots_96_rate_3.2-1.6-0.8_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [32 32 32]
Adapter prompts. [8640, 8640, 8640, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 8640, 34560, 8640, 8640, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 8640, 34560, 17280, 8640, 8640, 17280, 34560, 8640, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 34560, 17280, 17280, 8640, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 8640, 34560, 17280, 17280, 17280, 34560, 34560, 8640, 8640, 17280, 8640, 34560, 8640, 8640, 34560, 8640, 17280, 17280, 8640, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 8640, 8640, 34560, 17280, 34560, 8640, 17280, 34560, 8640, 34560, 17280, 8640, 34560, 8640, 8640, 34560, 8640, 8640, 17280]
Prompts retrieved: 1935360 . Total input tokens: 431807893 . Total output tokens: 386940663
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 5.484557067975402,
    "estimated_duration": 3600.1727417964166,
    "input_throughput": 5490.027956307903,
    "output_throughput": 4820.965616038618,
    "total_throughput": 10310.99357234652,
    "itl": 177.45629919446782,
    "ttft": 2051352.812549784,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2870448283106092,
    "arrivals": 644954,
    "finished_requests": 79984,
    "scheduler_time": 48.75647029909637
}
#Debug simulation 
Total elapsed time: 5.484692857135087. Arrivals time: 0.24506829120218754 Scheduler time: 5.156971808988601 Scheduler overhead time: 0.029968009795993567 Adapter cache time: 0.008050046861171722 Engine time: 0.030556426383554935 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_16-16-32/adapters_96_slots_96_rate_3.2-1.6-0.8_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_16-16-32/adapters_96_slots_96_rate_3.2-1.6-0.8_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [32 32 32]
Adapter prompts. [8640, 8640, 8640, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 8640, 34560, 8640, 8640, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 8640, 34560, 17280, 8640, 8640, 17280, 34560, 8640, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 34560, 17280, 17280, 8640, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 8640, 34560, 17280, 17280, 17280, 34560, 34560, 8640, 8640, 17280, 8640, 34560, 8640, 8640, 34560, 8640, 17280, 17280, 8640, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 8640, 8640, 34560, 17280, 34560, 8640, 17280, 34560, 8640, 34560, 17280, 8640, 34560, 8640, 8640, 34560, 8640, 8640, 17280]
Prompts retrieved: 1935360 . Total input tokens: 431807893 . Total output tokens: 386940663
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.5174685483798385,
    "estimated_duration": 3600.1803586328456,
    "input_throughput": 5478.104993464665,
    "output_throughput": 4810.287062000529,
    "total_throughput": 10288.392055465194,
    "itl": 175.6534325521949,
    "ttft": 2053120.457684869,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3218098914623257,
    "arrivals": 644954,
    "finished_requests": 79823,
    "scheduler_time": 48.38977774078459
}
#Debug simulation 
Total elapsed time: 5.51756411511451. Arrivals time: 0.2575061027891934 Scheduler time: 5.175925259012729 Scheduler overhead time: 0.03037891909480095 Adapter cache time: 0.008438515942543745 Engine time: 0.031100823543965816 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-8-8/adapters_96_slots_96_rate_3.2-1.6-0.4_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-8-8/adapters_96_slots_96_rate_3.2-1.6-0.4_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [32 32 32]
Adapter prompts. [4320, 4320, 4320, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 4320, 34560, 4320, 4320, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 4320, 34560, 17280, 4320, 4320, 17280, 34560, 4320, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 4320, 34560, 17280, 17280, 4320, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 4320, 34560, 17280, 17280, 17280, 34560, 34560, 4320, 4320, 17280, 4320, 34560, 4320, 4320, 34560, 4320, 17280, 17280, 4320, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 4320, 4320, 34560, 17280, 34560, 4320, 17280, 34560, 4320, 34560, 17280, 4320, 34560, 4320, 4320, 34560, 4320, 4320, 17280]
Prompts retrieved: 1797120 . Total input tokens: 400994416 . Total output tokens: 359255850
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 5.93690445786342,
    "estimated_duration": 3600.0797732673027,
    "input_throughput": 5553.732766830962,
    "output_throughput": 4889.254435610833,
    "total_throughput": 10442.987202441795,
    "itl": 175.54193465130402,
    "ttft": 2035795.881176326,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.29380682341754405,
    "arrivals": 599169,
    "finished_requests": 80673,
    "scheduler_time": 49.51562084694195
}
#Debug simulation 
Total elapsed time: 5.93697954993695. Arrivals time: 0.25562039064243436 Scheduler time: 5.590920397546142 Scheduler overhead time: 0.030666367150843143 Adapter cache time: 0.013786965981125832 Engine time: 0.03163849748671055 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-8-16/adapters_96_slots_96_rate_3.2-1.6-0.4_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-8-16/adapters_96_slots_96_rate_3.2-1.6-0.4_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [32 32 32]
Adapter prompts. [4320, 4320, 4320, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 4320, 34560, 4320, 4320, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 4320, 34560, 17280, 4320, 4320, 17280, 34560, 4320, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 4320, 34560, 17280, 17280, 4320, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 4320, 34560, 17280, 17280, 17280, 34560, 34560, 4320, 4320, 17280, 4320, 34560, 4320, 4320, 34560, 4320, 17280, 17280, 4320, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 4320, 4320, 34560, 17280, 34560, 4320, 17280, 34560, 4320, 34560, 17280, 4320, 34560, 4320, 4320, 34560, 4320, 4320, 17280]
Prompts retrieved: 1797120 . Total input tokens: 400994416 . Total output tokens: 359255850
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.624887672252953,
    "estimated_duration": 3600.007899230526,
    "input_throughput": 5553.701147231768,
    "output_throughput": 4889.351493857063,
    "total_throughput": 10443.05264108883,
    "itl": 175.54430150220895,
    "ttft": 2035782.7256551096,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3131949286907911,
    "arrivals": 599169,
    "finished_requests": 80672,
    "scheduler_time": 49.51443840237417
}
#Debug simulation 
Total elapsed time: 5.6250341683626175. Arrivals time: 0.31557328533381224 Scheduler time: 5.219849368557334 Scheduler overhead time: 0.030386404134333134 Adapter cache time: 0.013617246877402067 Engine time: 0.03126308461651206 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-8-32/adapters_96_slots_96_rate_3.2-1.6-0.4_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-8-32/adapters_96_slots_96_rate_3.2-1.6-0.4_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [32 32 32]
Adapter prompts. [4320, 4320, 4320, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 4320, 34560, 4320, 4320, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 4320, 34560, 17280, 4320, 4320, 17280, 34560, 4320, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 4320, 34560, 17280, 17280, 4320, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 4320, 34560, 17280, 17280, 17280, 34560, 34560, 4320, 4320, 17280, 4320, 34560, 4320, 4320, 34560, 4320, 17280, 17280, 4320, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 4320, 4320, 34560, 17280, 34560, 4320, 17280, 34560, 4320, 34560, 17280, 4320, 34560, 4320, 4320, 34560, 4320, 4320, 17280]
Prompts retrieved: 1797120 . Total input tokens: 400994416 . Total output tokens: 359255850
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.596040076110512,
    "estimated_duration": 3600.0706068434292,
    "input_throughput": 5547.789802242793,
    "output_throughput": 4883.788658638566,
    "total_throughput": 10431.57846088136,
    "itl": 173.43475549176011,
    "ttft": 2036864.0001610941,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31376164913177523,
    "arrivals": 599169,
    "finished_requests": 80579,
    "scheduler_time": 49.1411126451565
}
#Debug simulation 
Total elapsed time: 5.596162588801235. Arrivals time: 0.3125171442516148 Scheduler time: 5.192330473102629 Scheduler overhead time: 0.030730940867215395 Adapter cache time: 0.014271979685872793 Engine time: 0.031831488478928804 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-16-16/adapters_96_slots_96_rate_3.2-1.6-0.4_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-16-16/adapters_96_slots_96_rate_3.2-1.6-0.4_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [32 32 32]
Adapter prompts. [4320, 4320, 4320, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 4320, 34560, 4320, 4320, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 4320, 34560, 17280, 4320, 4320, 17280, 34560, 4320, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 4320, 34560, 17280, 17280, 4320, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 4320, 34560, 17280, 17280, 17280, 34560, 34560, 4320, 4320, 17280, 4320, 34560, 4320, 4320, 34560, 4320, 17280, 17280, 4320, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 4320, 4320, 34560, 17280, 34560, 4320, 17280, 34560, 4320, 34560, 17280, 4320, 34560, 4320, 4320, 34560, 4320, 4320, 17280]
Prompts retrieved: 1797120 . Total input tokens: 400994416 . Total output tokens: 359255850
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 5.592786940280348,
    "estimated_duration": 3600.08788648659,
    "input_throughput": 5553.720250844347,
    "output_throughput": 4889.243417103886,
    "total_throughput": 10442.963667948232,
    "itl": 175.5420668898208,
    "ttft": 2035801.8887397447,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3001198785007001,
    "arrivals": 599169,
    "finished_requests": 80673,
    "scheduler_time": 49.515616702602806
}
#Debug simulation 
Total elapsed time: 5.592905024066567. Arrivals time: 0.3125942391343415 Scheduler time: 5.190535766072571 Scheduler overhead time: 0.030496708117425442 Adapter cache time: 0.01356368837878108 Engine time: 0.0313440659083426 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-16-32/adapters_96_slots_96_rate_3.2-1.6-0.4_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-16-32/adapters_96_slots_96_rate_3.2-1.6-0.4_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [32 32 32]
Adapter prompts. [4320, 4320, 4320, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 4320, 34560, 4320, 4320, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 4320, 34560, 17280, 4320, 4320, 17280, 34560, 4320, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 4320, 34560, 17280, 17280, 4320, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 4320, 34560, 17280, 17280, 17280, 34560, 34560, 4320, 4320, 17280, 4320, 34560, 4320, 4320, 34560, 4320, 17280, 17280, 4320, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 4320, 4320, 34560, 17280, 34560, 4320, 17280, 34560, 4320, 34560, 17280, 4320, 34560, 4320, 4320, 34560, 4320, 4320, 17280]
Prompts retrieved: 1797120 . Total input tokens: 400994416 . Total output tokens: 359255850
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 5.594318524003029,
    "estimated_duration": 3600.0755153546247,
    "input_throughput": 5547.782238126919,
    "output_throughput": 4883.781999852881,
    "total_throughput": 10431.5642379798,
    "itl": 173.43478294047478,
    "ttft": 2036867.707389363,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31778577029705046,
    "arrivals": 599169,
    "finished_requests": 80579,
    "scheduler_time": 49.14108015204657
}
#Debug simulation 
Total elapsed time: 5.5944540691562. Arrivals time: 0.3144744490273297 Scheduler time: 5.188576172571629 Scheduler overhead time: 0.030757288448512554 Adapter cache time: 0.0142701780423522 Engine time: 0.03189584659412503 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_16-16-16/adapters_96_slots_96_rate_3.2-1.6-0.4_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_16-16-16/adapters_96_slots_96_rate_3.2-1.6-0.4_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [32 32 32]
Adapter prompts. [4320, 4320, 4320, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 4320, 34560, 4320, 4320, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 4320, 34560, 17280, 4320, 4320, 17280, 34560, 4320, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 4320, 34560, 17280, 17280, 4320, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 4320, 34560, 17280, 17280, 17280, 34560, 34560, 4320, 4320, 17280, 4320, 34560, 4320, 4320, 34560, 4320, 17280, 17280, 4320, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 4320, 4320, 34560, 17280, 34560, 4320, 17280, 34560, 4320, 34560, 17280, 4320, 34560, 4320, 4320, 34560, 4320, 4320, 17280]
Prompts retrieved: 1797120 . Total input tokens: 400994416 . Total output tokens: 359255850
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 5.61348383827135,
    "estimated_duration": 3600.069294154478,
    "input_throughput": 5553.606435427154,
    "output_throughput": 4889.26811175005,
    "total_throughput": 10442.874547177204,
    "itl": 175.54394296400267,
    "ttft": 2035778.55818874,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2870448283106092,
    "arrivals": 599169,
    "finished_requests": 80672,
    "scheduler_time": 49.51509139278185
}
#Debug simulation 
Total elapsed time: 5.613574022892863. Arrivals time: 0.2520308066159487 Scheduler time: 5.271386208944023 Scheduler overhead time: 0.03068233886733651 Adapter cache time: 0.013918215874582529 Engine time: 0.031154660508036613 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_16-16-32/adapters_96_slots_96_rate_3.2-1.6-0.4_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_16-16-32/adapters_96_slots_96_rate_3.2-1.6-0.4_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [32 32 32]
Adapter prompts. [4320, 4320, 4320, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 4320, 34560, 4320, 4320, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 4320, 34560, 17280, 4320, 4320, 17280, 34560, 4320, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 4320, 34560, 17280, 17280, 4320, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 4320, 34560, 17280, 17280, 17280, 34560, 34560, 4320, 4320, 17280, 4320, 34560, 4320, 4320, 34560, 4320, 17280, 17280, 4320, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 4320, 4320, 34560, 17280, 34560, 4320, 17280, 34560, 4320, 34560, 17280, 4320, 34560, 4320, 4320, 34560, 4320, 4320, 17280]
Prompts retrieved: 1797120 . Total input tokens: 400994416 . Total output tokens: 359255850
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.641943576745689,
    "estimated_duration": 3600.0795131289174,
    "input_throughput": 5547.776077490429,
    "output_throughput": 4883.776576567629,
    "total_throughput": 10431.552654058058,
    "itl": 173.43486025779976,
    "ttft": 2036870.7095232455,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.32180989146232564,
    "arrivals": 599169,
    "finished_requests": 80579,
    "scheduler_time": 49.14105380517434
}
#Debug simulation 
Total elapsed time: 5.642033354844898. Arrivals time: 0.3151907082647085 Scheduler time: 5.234695866238326 Scheduler overhead time: 0.031138224061578512 Adapter cache time: 0.014285870362073183 Engine time: 0.03205781523138285 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-8-8/adapters_96_slots_96_rate_3.2-1.6-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-8-8/adapters_96_slots_96_rate_3.2-1.6-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 1080, 34560, 1080, 1080, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 1080, 34560, 17280, 1080, 1080, 17280, 34560, 1080, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 34560, 17280, 17280, 1080, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 1080, 34560, 17280, 17280, 17280, 34560, 34560, 1080, 1080, 17280, 1080, 34560, 1080, 1080, 34560, 1080, 17280, 17280, 1080, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 1080, 1080, 34560, 17280, 34560, 1080, 17280, 34560, 1080, 34560, 17280, 1080, 34560, 1080, 1080, 34560, 1080, 1080, 17280]
Prompts retrieved: 1693440 . Total input tokens: 377834478 . Total output tokens: 338505042
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.019771572668105,
    "estimated_duration": 3600.061739686618,
    "input_throughput": 5993.582766132861,
    "output_throughput": 5256.2195785140075,
    "total_throughput": 11249.802344646869,
    "itl": 162.94771740691746,
    "ttft": 1988000.5208228098,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.29380682341754405,
    "arrivals": 564644,
    "finished_requests": 86773,
    "scheduler_time": 53.19154691508244
}
#Debug simulation 
Total elapsed time: 6.019908801652491. Arrivals time: 0.32695703906938434 Scheduler time: 5.592386020813137 Scheduler overhead time: 0.03310431353747845 Adapter cache time: 0.017555647529661655 Engine time: 0.034425539430230856 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-8-16/adapters_96_slots_96_rate_3.2-1.6-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-8-16/adapters_96_slots_96_rate_3.2-1.6-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 1080, 34560, 1080, 1080, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 1080, 34560, 17280, 1080, 1080, 17280, 34560, 1080, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 34560, 17280, 17280, 1080, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 1080, 34560, 17280, 17280, 17280, 34560, 34560, 1080, 1080, 17280, 1080, 34560, 1080, 1080, 34560, 1080, 17280, 17280, 1080, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 1080, 1080, 34560, 17280, 34560, 1080, 17280, 34560, 1080, 34560, 17280, 1080, 34560, 1080, 1080, 34560, 1080, 1080, 17280]
Prompts retrieved: 1693440 . Total input tokens: 377834478 . Total output tokens: 338505042
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.982923142146319,
    "estimated_duration": 3600.1589781389407,
    "input_throughput": 5993.728924480631,
    "output_throughput": 5256.168717799802,
    "total_throughput": 11249.897642280432,
    "itl": 162.94872577864123,
    "ttft": 1988013.0698026654,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3131949286907911,
    "arrivals": 564644,
    "finished_requests": 86775,
    "scheduler_time": 53.193151714376036
}
#Debug simulation 
Total elapsed time: 5.983049508184195. Arrivals time: 0.3229598649777472 Scheduler time: 5.560632438864559 Scheduler overhead time: 0.03305896744132042 Adapter cache time: 0.017415750306099653 Engine time: 0.03361615212634206 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-8-32/adapters_96_slots_96_rate_3.2-1.6-0.1_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-8-32/adapters_96_slots_96_rate_3.2-1.6-0.1_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 1080, 34560, 1080, 1080, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 1080, 34560, 17280, 1080, 1080, 17280, 34560, 1080, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 34560, 17280, 17280, 1080, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 1080, 34560, 17280, 17280, 17280, 34560, 34560, 1080, 1080, 17280, 1080, 34560, 1080, 1080, 34560, 1080, 17280, 17280, 1080, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 1080, 1080, 34560, 17280, 34560, 1080, 17280, 34560, 1080, 34560, 17280, 1080, 34560, 1080, 1080, 34560, 1080, 1080, 17280]
Prompts retrieved: 1693440 . Total input tokens: 377834478 . Total output tokens: 338505042
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.9972339160740376,
    "estimated_duration": 3600.138241173705,
    "input_throughput": 5985.2512755107655,
    "output_throughput": 5250.465324864165,
    "total_throughput": 11235.71660037493,
    "itl": 161.1458334227026,
    "ttft": 1989026.0623326935,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31376164913177523,
    "arrivals": 564644,
    "finished_requests": 86645,
    "scheduler_time": 52.80048958162238
}
#Debug simulation 
Total elapsed time: 5.997350073885173. Arrivals time: 0.32333866134285927 Scheduler time: 5.57308760471642 Scheduler overhead time: 0.03349400730803609 Adapter cache time: 0.017877625301480293 Engine time: 0.0338825723156333 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-16-16/adapters_96_slots_96_rate_3.2-1.6-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-16-16/adapters_96_slots_96_rate_3.2-1.6-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 1080, 34560, 1080, 1080, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 1080, 34560, 17280, 1080, 1080, 17280, 34560, 1080, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 34560, 17280, 17280, 1080, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 1080, 34560, 17280, 17280, 17280, 34560, 34560, 1080, 1080, 17280, 1080, 34560, 1080, 1080, 34560, 1080, 17280, 17280, 1080, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 1080, 1080, 34560, 17280, 34560, 1080, 17280, 34560, 1080, 34560, 17280, 1080, 34560, 1080, 1080, 34560, 1080, 1080, 17280]
Prompts retrieved: 1693440 . Total input tokens: 377834478 . Total output tokens: 338505042
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 5.965842128265649,
    "estimated_duration": 3600.1161485564317,
    "input_throughput": 5993.492184592993,
    "output_throughput": 5256.140140808401,
    "total_throughput": 11249.632325401393,
    "itl": 162.9491918305871,
    "ttft": 1988017.6639935314,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.30011987850070015,
    "arrivals": 564644,
    "finished_requests": 86773,
    "scheduler_time": 53.191888253501865
}
#Debug simulation 
Total elapsed time: 5.965975536033511. Arrivals time: 0.26756975380703807 Scheduler time: 5.598743103444576 Scheduler overhead time: 0.03295696619898081 Adapter cache time: 0.017435903195291758 Engine time: 0.033852022141218185 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-16-32/adapters_96_slots_96_rate_3.2-1.6-0.1_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-16-32/adapters_96_slots_96_rate_3.2-1.6-0.1_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 1080, 34560, 1080, 1080, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 1080, 34560, 17280, 1080, 1080, 17280, 34560, 1080, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 34560, 17280, 17280, 1080, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 1080, 34560, 17280, 17280, 17280, 34560, 34560, 1080, 1080, 17280, 1080, 34560, 1080, 1080, 34560, 1080, 17280, 17280, 1080, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 1080, 1080, 34560, 17280, 34560, 1080, 17280, 34560, 1080, 34560, 17280, 1080, 34560, 1080, 1080, 34560, 1080, 1080, 17280]
Prompts retrieved: 1693440 . Total input tokens: 377834478 . Total output tokens: 338505042
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 5.974703770596534,
    "estimated_duration": 3600.118744047314,
    "input_throughput": 5985.2836897750985,
    "output_throughput": 5250.493759755714,
    "total_throughput": 11235.777449530811,
    "itl": 161.14420147767203,
    "ttft": 1989017.7747867831,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31778577029705046,
    "arrivals": 564644,
    "finished_requests": 86645,
    "scheduler_time": 52.800131273558385
}
#Debug simulation 
Total elapsed time: 5.974796254653484. Arrivals time: 0.3272473765537143 Scheduler time: 5.547317527700216 Scheduler overhead time: 0.03338891360908747 Adapter cache time: 0.017645501997321844 Engine time: 0.033762901555746794 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_16-16-16/adapters_96_slots_96_rate_3.2-1.6-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_16-16-16/adapters_96_slots_96_rate_3.2-1.6-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 1080, 34560, 1080, 1080, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 1080, 34560, 17280, 1080, 1080, 17280, 34560, 1080, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 34560, 17280, 17280, 1080, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 1080, 34560, 17280, 17280, 17280, 34560, 34560, 1080, 1080, 17280, 1080, 34560, 1080, 1080, 34560, 1080, 17280, 17280, 1080, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 1080, 1080, 34560, 17280, 34560, 1080, 17280, 34560, 1080, 34560, 17280, 1080, 34560, 1080, 1080, 34560, 1080, 1080, 17280]
Prompts retrieved: 1693440 . Total input tokens: 377834478 . Total output tokens: 338505042
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.043369153980166,
    "estimated_duration": 3600.0354572116435,
    "input_throughput": 5993.546801539601,
    "output_throughput": 5256.229341323277,
    "total_throughput": 11249.776142862878,
    "itl": 162.94735332714706,
    "ttft": 1988006.2971997962,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2870448283106092,
    "arrivals": 564644,
    "finished_requests": 86772,
    "scheduler_time": 53.19132479608056
}
#Debug simulation 
Total elapsed time: 6.043461960740387. Arrivals time: 0.2724735224619508 Scheduler time: 5.6706762332469225 Scheduler overhead time: 0.033141904044896364 Adapter cache time: 0.017695173155516386 Engine time: 0.033989110961556435 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_16-16-32/adapters_96_slots_96_rate_3.2-1.6-0.1_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_16-16-32/adapters_96_slots_96_rate_3.2-1.6-0.1_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 1080, 34560, 1080, 1080, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 1080, 34560, 17280, 1080, 1080, 17280, 34560, 1080, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 34560, 17280, 17280, 1080, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 1080, 34560, 17280, 17280, 17280, 34560, 34560, 1080, 1080, 17280, 1080, 34560, 1080, 1080, 34560, 1080, 17280, 17280, 1080, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 1080, 1080, 34560, 17280, 34560, 1080, 17280, 34560, 1080, 34560, 17280, 1080, 34560, 1080, 1080, 34560, 1080, 1080, 17280]
Prompts retrieved: 1693440 . Total input tokens: 377834478 . Total output tokens: 338505042
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.985567169263959,
    "estimated_duration": 3600.1223842130444,
    "input_throughput": 5985.277637918453,
    "output_throughput": 5250.488450861901,
    "total_throughput": 11235.766088780354,
    "itl": 161.1441349937076,
    "ttft": 1989020.568606602,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3218098914623257,
    "arrivals": 564644,
    "finished_requests": 86645,
    "scheduler_time": 52.80008473191203
}
#Debug simulation 
Total elapsed time: 5.985691647976637. Arrivals time: 0.3276483458466828 Scheduler time: 5.5580218830145895 Scheduler overhead time: 0.03316594660282135 Adapter cache time: 0.017644471023231745 Engine time: 0.033696571830660105 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-8-8/adapters_96_slots_96_rate_3.2-1.6-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-8-8/adapters_96_slots_96_rate_3.2-1.6-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 540, 34560, 540, 540, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 540, 34560, 17280, 540, 540, 17280, 34560, 540, 17280, 540, 540, 17280, 17280, 17280, 540, 540, 34560, 17280, 17280, 540, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 540, 34560, 17280, 17280, 17280, 34560, 34560, 540, 540, 17280, 540, 34560, 540, 540, 34560, 540, 17280, 17280, 540, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 540, 540, 34560, 17280, 34560, 540, 17280, 34560, 540, 34560, 17280, 540, 34560, 540, 540, 34560, 540, 540, 17280]
Prompts retrieved: 1676160 . Total input tokens: 373978445 . Total output tokens: 335072734
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.105033863801509,
    "estimated_duration": 3600.1316781662763,
    "input_throughput": 6166.022519294845,
    "output_throughput": 5442.38593238896,
    "total_throughput": 11608.408451683805,
    "itl": 158.24475665871583,
    "ttft": 1962118.8459329582,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.29380682341754405,
    "arrivals": 558915,
    "finished_requests": 89662,
    "scheduler_time": 55.148671992784955
}
#Debug simulation 
Total elapsed time: 6.105148878879845. Arrivals time: 0.27530395006760955 Scheduler time: 5.731596838217229 Scheduler overhead time: 0.03379091201350093 Adapter cache time: 0.013613132294267416 Engine time: 0.03504796326160431 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-8-16/adapters_96_slots_96_rate_3.2-1.6-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-8-16/adapters_96_slots_96_rate_3.2-1.6-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 540, 34560, 540, 540, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 540, 34560, 17280, 540, 540, 17280, 34560, 540, 17280, 540, 540, 17280, 17280, 17280, 540, 540, 34560, 17280, 17280, 540, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 540, 34560, 17280, 17280, 17280, 34560, 34560, 540, 540, 17280, 540, 34560, 540, 540, 34560, 540, 17280, 17280, 540, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 540, 540, 34560, 17280, 34560, 540, 17280, 34560, 540, 34560, 17280, 540, 34560, 540, 540, 34560, 540, 540, 17280]
Prompts retrieved: 1676160 . Total input tokens: 373978445 . Total output tokens: 335072734
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.188335747923702,
    "estimated_duration": 3600.0343364117102,
    "input_throughput": 6166.083410783714,
    "output_throughput": 5442.466701450728,
    "total_throughput": 11608.550112234441,
    "itl": 158.2472380479357,
    "ttft": 1962116.3845359662,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31319492869079113,
    "arrivals": 558915,
    "finished_requests": 89659,
    "scheduler_time": 55.14697673847743
}
#Debug simulation 
Total elapsed time: 6.188450465910137. Arrivals time: 0.30622836062684655 Scheduler time: 5.783147553447634 Scheduler overhead time: 0.03407320752739906 Adapter cache time: 0.01396014541387558 Engine time: 0.035040016286075115 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-8-32/adapters_96_slots_96_rate_3.2-1.6-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-8-32/adapters_96_slots_96_rate_3.2-1.6-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 540, 34560, 540, 540, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 540, 34560, 17280, 540, 540, 17280, 34560, 540, 17280, 540, 540, 17280, 17280, 17280, 540, 540, 34560, 17280, 17280, 540, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 540, 34560, 17280, 17280, 17280, 34560, 34560, 540, 540, 17280, 540, 34560, 540, 540, 34560, 540, 17280, 17280, 540, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 540, 540, 34560, 17280, 34560, 540, 17280, 34560, 540, 34560, 17280, 540, 34560, 540, 540, 34560, 540, 540, 17280]
Prompts retrieved: 1676160 . Total input tokens: 373978445 . Total output tokens: 335072734
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.1162104941904545,
    "estimated_duration": 3600.136424028446,
    "input_throughput": 6156.807239876103,
    "output_throughput": 5433.788250199218,
    "total_throughput": 11590.59549007532,
    "itl": 156.54575151946347,
    "ttft": 1963057.881540734,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3137616491317753,
    "arrivals": 558915,
    "finished_requests": 89514,
    "scheduler_time": 54.73516988063316
}
#Debug simulation 
Total elapsed time: 6.116332806181163. Arrivals time: 0.27637815941125154 Scheduler time: 5.740732610691339 Scheduler overhead time: 0.034132513217628 Adapter cache time: 0.014116973616182804 Engine time: 0.034902285784482956 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-16-16/adapters_96_slots_96_rate_3.2-1.6-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-16-16/adapters_96_slots_96_rate_3.2-1.6-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 540, 34560, 540, 540, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 540, 34560, 17280, 540, 540, 17280, 34560, 540, 17280, 540, 540, 17280, 17280, 17280, 540, 540, 34560, 17280, 17280, 540, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 540, 34560, 17280, 17280, 17280, 34560, 34560, 540, 540, 17280, 540, 34560, 540, 540, 34560, 540, 17280, 17280, 540, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 540, 540, 34560, 17280, 34560, 540, 17280, 34560, 540, 34560, 17280, 540, 34560, 540, 540, 34560, 540, 540, 17280]
Prompts retrieved: 1676160 . Total input tokens: 373978445 . Total output tokens: 335072734
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 6.15495707700029,
    "estimated_duration": 3600.1443429952324,
    "input_throughput": 6166.000828047743,
    "output_throughput": 5442.366786799123,
    "total_throughput": 11608.367614846866,
    "itl": 158.2448704445067,
    "ttft": 1962123.5691015134,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3001198785007001,
    "arrivals": 558915,
    "finished_requests": 89662,
    "scheduler_time": 55.148790392656494
}
#Debug simulation 
Total elapsed time: 6.15504414588213. Arrivals time: 0.28041872940957546 Scheduler time: 5.7760120197199285 Scheduler overhead time: 0.0338431466370821 Adapter cache time: 0.013870005495846272 Engine time: 0.035039468202739954 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-16-32/adapters_96_slots_96_rate_3.2-1.6-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-16-32/adapters_96_slots_96_rate_3.2-1.6-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 540, 34560, 540, 540, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 540, 34560, 17280, 540, 540, 17280, 34560, 540, 17280, 540, 540, 17280, 17280, 17280, 540, 540, 34560, 17280, 17280, 540, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 540, 34560, 17280, 17280, 17280, 34560, 34560, 540, 540, 17280, 540, 34560, 540, 540, 34560, 540, 17280, 17280, 540, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 540, 540, 34560, 17280, 34560, 540, 17280, 34560, 540, 34560, 17280, 540, 34560, 540, 540, 34560, 540, 540, 17280]
Prompts retrieved: 1676160 . Total input tokens: 373978445 . Total output tokens: 335072734
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 6.114545937161893,
    "estimated_duration": 3600.1399382278414,
    "input_throughput": 6156.801230040749,
    "output_throughput": 5433.782946123346,
    "total_throughput": 11590.584176164095,
    "itl": 156.54583206191472,
    "ttft": 1963060.547822809,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3177857702970505,
    "arrivals": 558915,
    "finished_requests": 89514,
    "scheduler_time": 54.73513402173154
}
#Debug simulation 
Total elapsed time: 6.11463729524985. Arrivals time: 0.27552052214741707 Scheduler time: 5.739661335013807 Scheduler overhead time: 0.03426945209503174 Adapter cache time: 0.013850014191120863 Engine time: 0.03526848694309592 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_16-16-16/adapters_96_slots_96_rate_3.2-1.6-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_16-16-16/adapters_96_slots_96_rate_3.2-1.6-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 540, 34560, 540, 540, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 540, 34560, 17280, 540, 540, 17280, 34560, 540, 17280, 540, 540, 17280, 17280, 17280, 540, 540, 34560, 17280, 17280, 540, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 540, 34560, 17280, 17280, 17280, 34560, 34560, 540, 540, 17280, 540, 34560, 540, 540, 34560, 540, 17280, 17280, 540, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 540, 540, 34560, 17280, 34560, 540, 17280, 34560, 540, 34560, 17280, 540, 34560, 540, 540, 34560, 540, 540, 17280]
Prompts retrieved: 1676160 . Total input tokens: 373978445 . Total output tokens: 335072734
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.086463584098965,
    "estimated_duration": 3600.12428214003,
    "input_throughput": 6166.035186653195,
    "output_throughput": 5442.397113122191,
    "total_throughput": 11608.432299775386,
    "itl": 158.24510896761925,
    "ttft": 1962115.4364800358,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2870448283106092,
    "arrivals": 558915,
    "finished_requests": 89662,
    "scheduler_time": 55.148688254002955
}
#Debug simulation 
Total elapsed time: 6.086578107904643. Arrivals time: 0.27300675585865974 Scheduler time: 5.71605267142877 Scheduler overhead time: 0.03371936455368996 Adapter cache time: 0.013772903941571712 Engine time: 0.03432650538161397 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_16-16-32/adapters_96_slots_96_rate_3.2-1.6-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_16-16-32/adapters_96_slots_96_rate_3.2-1.6-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 540, 34560, 540, 540, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 540, 34560, 17280, 540, 540, 17280, 34560, 540, 17280, 540, 540, 17280, 17280, 17280, 540, 540, 34560, 17280, 17280, 540, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 540, 34560, 17280, 17280, 17280, 34560, 34560, 540, 540, 17280, 540, 34560, 540, 540, 34560, 540, 17280, 17280, 540, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 540, 540, 34560, 17280, 34560, 540, 17280, 34560, 540, 34560, 17280, 540, 34560, 540, 540, 34560, 540, 540, 17280]
Prompts retrieved: 1676160 . Total input tokens: 373978445 . Total output tokens: 335072734
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.095515208784491,
    "estimated_duration": 3600.036288060151,
    "input_throughput": 6156.97849310947,
    "output_throughput": 5433.939392466797,
    "total_throughput": 11590.917885576268,
    "itl": 156.56370982063586,
    "ttft": 1963005.6161421088,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3218098914623257,
    "arrivals": 558915,
    "finished_requests": 89514,
    "scheduler_time": 54.737955634127275
}
#Debug simulation 
Total elapsed time: 6.095607755705714. Arrivals time: 0.2715276535600424 Scheduler time: 5.725661917123944 Scheduler overhead time: 0.03403330175206065 Adapter cache time: 0.013802757021039724 Engine time: 0.034766644705086946 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-8-8/adapters_96_slots_96_rate_3.2-1.6-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-8-8/adapters_96_slots_96_rate_3.2-1.6-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 270, 34560, 270, 270, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 270, 34560, 17280, 270, 270, 17280, 34560, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 270, 34560, 17280, 17280, 270, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 270, 34560, 17280, 17280, 17280, 34560, 34560, 270, 270, 17280, 270, 34560, 270, 270, 34560, 270, 17280, 17280, 270, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 270, 270, 34560, 17280, 34560, 270, 17280, 34560, 270, 34560, 17280, 270, 34560, 270, 270, 34560, 270, 270, 17280]
Prompts retrieved: 1667520 . Total input tokens: 372043367 . Total output tokens: 333338958
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.265714700333774,
    "estimated_duration": 3600.078034380552,
    "input_throughput": 6250.375071070309,
    "output_throughput": 5554.917090412731,
    "total_throughput": 11805.292161483041,
    "itl": 155.6029601689408,
    "ttft": 1951734.3804740168,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.29380682341754405,
    "arrivals": 556029,
    "finished_requests": 91226,
    "scheduler_time": 56.39864798750035
}
#Debug simulation 
Total elapsed time: 6.2658062893897295. Arrivals time: 0.2818176746368408 Scheduler time: 5.8869430855847895 Scheduler overhead time: 0.03430670313537121 Adapter cache time: 0.011252303142100573 Engine time: 0.03530641132965684 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-8-16/adapters_96_slots_96_rate_3.2-1.6-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-8-16/adapters_96_slots_96_rate_3.2-1.6-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 270, 34560, 270, 270, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 270, 34560, 17280, 270, 270, 17280, 34560, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 270, 34560, 17280, 17280, 270, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 270, 34560, 17280, 17280, 17280, 34560, 34560, 270, 270, 17280, 270, 34560, 270, 270, 34560, 270, 17280, 17280, 270, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 270, 270, 34560, 17280, 34560, 270, 17280, 34560, 270, 34560, 17280, 270, 34560, 270, 270, 34560, 270, 270, 17280]
Prompts retrieved: 1667520 . Total input tokens: 372043367 . Total output tokens: 333338958
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.245114409830421,
    "estimated_duration": 3600.1419028766927,
    "input_throughput": 6250.300573435677,
    "output_throughput": 5554.918816955577,
    "total_throughput": 11805.219390391254,
    "itl": 155.6032693358821,
    "ttft": 1951735.1101795046,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31319492869079113,
    "arrivals": 556029,
    "finished_requests": 91227,
    "scheduler_time": 56.399576791585346
}
#Debug simulation 
Total elapsed time: 6.245244999881834. Arrivals time: 0.2797590857371688 Scheduler time: 5.8684428366832435 Scheduler overhead time: 0.03432428976520896 Adapter cache time: 0.011335725896060467 Engine time: 0.03517193254083395 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-8-32/adapters_96_slots_96_rate_3.2-1.6-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-8-32/adapters_96_slots_96_rate_3.2-1.6-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 270, 34560, 270, 270, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 270, 34560, 17280, 270, 270, 17280, 34560, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 270, 34560, 17280, 17280, 270, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 270, 34560, 17280, 17280, 17280, 34560, 34560, 270, 270, 17280, 270, 34560, 270, 270, 34560, 270, 17280, 17280, 270, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 270, 270, 34560, 17280, 34560, 270, 17280, 34560, 270, 34560, 17280, 270, 34560, 270, 270, 34560, 270, 270, 17280]
Prompts retrieved: 1667520 . Total input tokens: 372043367 . Total output tokens: 333338958
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.2044765669852495,
    "estimated_duration": 3600.0457459670806,
    "input_throughput": 6236.1924220407645,
    "output_throughput": 5542.758178101903,
    "total_throughput": 11778.950600142667,
    "itl": 153.7786195187224,
    "ttft": 1952804.366353293,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31376164913177523,
    "arrivals": 556029,
    "finished_requests": 91013,
    "scheduler_time": 55.92287217812528
}
#Debug simulation 
Total elapsed time: 6.204559564124793. Arrivals time: 0.27870492404326797 Scheduler time: 5.828532183077186 Scheduler overhead time: 0.034487314987927675 Adapter cache time: 0.011340070515871048 Engine time: 0.03529131039977074 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-16-16/adapters_96_slots_96_rate_3.2-1.6-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-16-16/adapters_96_slots_96_rate_3.2-1.6-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 270, 34560, 270, 270, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 270, 34560, 17280, 270, 270, 17280, 34560, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 270, 34560, 17280, 17280, 270, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 270, 34560, 17280, 17280, 17280, 34560, 34560, 270, 270, 17280, 270, 34560, 270, 270, 34560, 270, 17280, 17280, 270, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 270, 270, 34560, 17280, 34560, 270, 17280, 34560, 270, 34560, 17280, 270, 34560, 270, 270, 34560, 270, 270, 17280]
Prompts retrieved: 1667520 . Total input tokens: 372043367 . Total output tokens: 333338958
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 6.263334318064153,
    "estimated_duration": 3600.1236352168007,
    "input_throughput": 6250.332288559008,
    "output_throughput": 5554.947003589693,
    "total_throughput": 11805.2792921487,
    "itl": 155.60318413605322,
    "ttft": 1951727.9265342113,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3001198785007001,
    "arrivals": 556029,
    "finished_requests": 91227,
    "scheduler_time": 56.39948660309659
}
#Debug simulation 
Total elapsed time: 6.263436540029943. Arrivals time: 0.3130175154656172 Scheduler time: 5.853342225775123 Scheduler overhead time: 0.034329178277403116 Adapter cache time: 0.011472012382000685 Engine time: 0.03515516920015216 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-16-32/adapters_96_slots_96_rate_3.2-1.6-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-16-32/adapters_96_slots_96_rate_3.2-1.6-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 270, 34560, 270, 270, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 270, 34560, 17280, 270, 270, 17280, 34560, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 270, 34560, 17280, 17280, 270, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 270, 34560, 17280, 17280, 17280, 34560, 34560, 270, 270, 17280, 270, 34560, 270, 270, 34560, 270, 17280, 17280, 270, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 270, 270, 34560, 17280, 34560, 270, 17280, 34560, 270, 34560, 17280, 270, 34560, 270, 270, 34560, 270, 270, 17280]
Prompts retrieved: 1667520 . Total input tokens: 372043367 . Total output tokens: 333338958
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 6.202989983838052,
    "estimated_duration": 3600.014957961097,
    "input_throughput": 6236.245755132945,
    "output_throughput": 5542.805580813821,
    "total_throughput": 11779.051335946766,
    "itl": 153.78277987545945,
    "ttft": 1952783.1592596883,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31778577029705046,
    "arrivals": 556029,
    "finished_requests": 91013,
    "scheduler_time": 55.923694787787
}
#Debug simulation 
Total elapsed time: 6.203129972796887. Arrivals time: 0.273765726480633 Scheduler time: 5.831697619985789 Scheduler overhead time: 0.03446961287409067 Adapter cache time: 0.011402871925383806 Engine time: 0.03550660563632846 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_16-16-16/adapters_96_slots_96_rate_3.2-1.6-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_16-16-16/adapters_96_slots_96_rate_3.2-1.6-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 270, 34560, 270, 270, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 270, 34560, 17280, 270, 270, 17280, 34560, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 270, 34560, 17280, 17280, 270, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 270, 34560, 17280, 17280, 17280, 34560, 34560, 270, 270, 17280, 270, 34560, 270, 270, 34560, 270, 17280, 17280, 270, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 270, 270, 34560, 17280, 34560, 270, 17280, 34560, 270, 34560, 17280, 270, 34560, 270, 270, 34560, 270, 270, 17280]
Prompts retrieved: 1667520 . Total input tokens: 372043367 . Total output tokens: 333338958
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.271788842976093,
    "estimated_duration": 3600.06782141386,
    "input_throughput": 6250.392802645262,
    "output_throughput": 5554.932849055633,
    "total_throughput": 11805.325651700894,
    "itl": 155.60271984508006,
    "ttft": 1951727.756205864,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2870448283106092,
    "arrivals": 556029,
    "finished_requests": 91226,
    "scheduler_time": 56.39867844943383
}
#Debug simulation 
Total elapsed time: 6.271901628933847. Arrivals time: 0.2794345929287374 Scheduler time: 5.894618866965175 Scheduler overhead time: 0.03472179686650634 Adapter cache time: 0.011283883359283209 Engine time: 0.03549939254298806 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_16-16-32/adapters_96_slots_96_rate_3.2-1.6-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_16-16-32/adapters_96_slots_96_rate_3.2-1.6-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 270, 34560, 270, 270, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 270, 34560, 17280, 270, 270, 17280, 34560, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 270, 34560, 17280, 17280, 270, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 270, 34560, 17280, 17280, 17280, 34560, 34560, 270, 270, 17280, 270, 34560, 270, 270, 34560, 270, 17280, 17280, 270, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 270, 270, 34560, 17280, 34560, 270, 17280, 34560, 270, 34560, 17280, 270, 34560, 270, 270, 34560, 270, 270, 17280]
Prompts retrieved: 1667520 . Total input tokens: 372043367 . Total output tokens: 333338958
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.2369623659178615,
    "estimated_duration": 3600.018930676372,
    "input_throughput": 6236.238873272254,
    "output_throughput": 5542.799464182542,
    "total_throughput": 11779.038337454795,
    "itl": 153.78285980025433,
    "ttft": 1952786.1503109161,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.32180989146232564,
    "arrivals": 556029,
    "finished_requests": 91013,
    "scheduler_time": 55.92367196475771
}
#Debug simulation 
Total elapsed time: 6.237075793091208. Arrivals time: 0.2762060360983014 Scheduler time: 5.863064540084451 Scheduler overhead time: 0.03470127144828439 Adapter cache time: 0.011407080572098494 Engine time: 0.03535526292398572 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-8/adapters_96_slots_96_rate_3.2-1.6-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-8/adapters_96_slots_96_rate_3.2-1.6-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 135, 34560, 135, 135, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 135, 34560, 17280, 135, 135, 17280, 34560, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 135, 34560, 17280, 17280, 135, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 135, 34560, 17280, 17280, 17280, 34560, 34560, 135, 135, 17280, 135, 34560, 135, 135, 34560, 135, 17280, 17280, 135, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 135, 135, 34560, 17280, 34560, 135, 17280, 34560, 135, 34560, 17280, 135, 34560, 135, 135, 34560, 135, 135, 17280]
Prompts retrieved: 1663200 . Total input tokens: 371069728 . Total output tokens: 332471114
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.379491897765547,
    "estimated_duration": 3600.0667159884156,
    "input_throughput": 6384.904729102794,
    "output_throughput": 5624.836592629736,
    "total_throughput": 12009.741321732528,
    "itl": 152.6758425322444,
    "ttft": 1938047.0139527845,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.29380682341754405,
    "arrivals": 554568,
    "finished_requests": 92761,
    "scheduler_time": 56.98922942876271
}
#Debug simulation 
Total elapsed time: 6.379612283781171. Arrivals time: 0.2855440261773765 Scheduler time: 5.997872953303158 Scheduler overhead time: 0.03496145410463214 Adapter cache time: 0.009180175140500069 Engine time: 0.03563839104026556 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-16/adapters_96_slots_96_rate_3.2-1.6-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-16/adapters_96_slots_96_rate_3.2-1.6-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 135, 34560, 135, 135, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 135, 34560, 17280, 135, 135, 17280, 34560, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 135, 34560, 17280, 17280, 135, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 135, 34560, 17280, 17280, 17280, 34560, 34560, 135, 135, 17280, 135, 34560, 135, 135, 34560, 135, 17280, 17280, 135, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 135, 135, 34560, 17280, 34560, 135, 17280, 34560, 135, 34560, 17280, 135, 34560, 135, 135, 34560, 135, 135, 17280]
Prompts retrieved: 1663200 . Total input tokens: 371069728 . Total output tokens: 332471114
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.650539887603372,
    "estimated_duration": 3600.0996949783344,
    "input_throughput": 6385.075677782956,
    "output_throughput": 5625.002837628881,
    "total_throughput": 12010.078515411837,
    "itl": 152.67616114290067,
    "ttft": 1938044.378792014,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31319492869079113,
    "arrivals": 554568,
    "finished_requests": 92763,
    "scheduler_time": 56.98939074685888
}
#Debug simulation 
Total elapsed time: 6.650635830592364. Arrivals time: 0.2847931641153991 Scheduler time: 6.269500529859215 Scheduler overhead time: 0.03488496504724026 Adapter cache time: 0.00912503944709897 Engine time: 0.035918356850743294 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-32/adapters_96_slots_96_rate_3.2-1.6-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-32/adapters_96_slots_96_rate_3.2-1.6-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 135, 34560, 135, 135, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 135, 34560, 17280, 135, 135, 17280, 34560, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 135, 34560, 17280, 17280, 135, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 135, 34560, 17280, 17280, 17280, 34560, 34560, 135, 135, 17280, 135, 34560, 135, 135, 34560, 135, 17280, 17280, 135, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 135, 135, 34560, 17280, 34560, 135, 17280, 34560, 135, 34560, 17280, 135, 34560, 135, 135, 34560, 135, 135, 17280]
Prompts retrieved: 1663200 . Total input tokens: 371069728 . Total output tokens: 332471114
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.388131702318788,
    "estimated_duration": 3600.0400424692843,
    "input_throughput": 6375.432697758896,
    "output_throughput": 5616.7105813997405,
    "total_throughput": 11992.143279158636,
    "itl": 151.2498351410277,
    "ttft": 1938672.0078922403,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3137616491317753,
    "arrivals": 554568,
    "finished_requests": 92611,
    "scheduler_time": 56.58927249388607
}
#Debug simulation 
Total elapsed time: 6.388250258285552. Arrivals time: 0.340119113214314 Scheduler time: 5.951088041532785 Scheduler overhead time: 0.035195833537727594 Adapter cache time: 0.009220093954354525 Engine time: 0.035993884317576885 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-16-16/adapters_96_slots_96_rate_3.2-1.6-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-16-16/adapters_96_slots_96_rate_3.2-1.6-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 135, 34560, 135, 135, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 135, 34560, 17280, 135, 135, 17280, 34560, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 135, 34560, 17280, 17280, 135, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 135, 34560, 17280, 17280, 17280, 34560, 34560, 135, 135, 17280, 135, 34560, 135, 135, 34560, 135, 17280, 17280, 135, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 135, 135, 34560, 17280, 34560, 135, 17280, 34560, 135, 34560, 17280, 135, 34560, 135, 135, 34560, 135, 135, 17280]
Prompts retrieved: 1663200 . Total input tokens: 371069728 . Total output tokens: 332471114
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 6.357667750213295,
    "estimated_duration": 3600.0750068053776,
    "input_throughput": 6384.890024943484,
    "output_throughput": 5624.823638874454,
    "total_throughput": 12009.713663817938,
    "itl": 152.6759310172741,
    "ttft": 1938052.295070399,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.30011987850070015,
    "arrivals": 554568,
    "finished_requests": 92761,
    "scheduler_time": 56.98919973950453
}
#Debug simulation 
Total elapsed time: 6.3577947383746505. Arrivals time: 0.28469253284856677 Scheduler time: 5.9768839362077415 Scheduler overhead time: 0.034957155119627714 Adapter cache time: 0.009157761465758085 Engine time: 0.03565548965707421 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-16-32/adapters_96_slots_96_rate_3.2-1.6-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-16-32/adapters_96_slots_96_rate_3.2-1.6-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 135, 34560, 135, 135, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 135, 34560, 17280, 135, 135, 17280, 34560, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 135, 34560, 17280, 17280, 135, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 135, 34560, 17280, 17280, 17280, 34560, 34560, 135, 135, 17280, 135, 34560, 135, 135, 34560, 135, 17280, 17280, 135, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 135, 135, 34560, 17280, 34560, 135, 17280, 34560, 135, 34560, 17280, 135, 34560, 135, 135, 34560, 135, 135, 17280]
Prompts retrieved: 1663200 . Total input tokens: 371069728 . Total output tokens: 332471114
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 6.596262004692107,
    "estimated_duration": 3600.029797700144,
    "input_throughput": 6375.450840618769,
    "output_throughput": 5616.72656512945,
    "total_throughput": 11992.177405748218,
    "itl": 151.25560001613405,
    "ttft": 1938658.0134328837,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31778577029705046,
    "arrivals": 554568,
    "finished_requests": 92611,
    "scheduler_time": 56.590664724979995
}
#Debug simulation 
Total elapsed time: 6.5963289006613195. Arrivals time: 0.33878925209864974 Scheduler time: 6.160905393771827 Scheduler overhead time: 0.03516515018418431 Adapter cache time: 0.009175615385174751 Engine time: 0.035813039634376764 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_16-16-16/adapters_96_slots_96_rate_3.2-1.6-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_16-16-16/adapters_96_slots_96_rate_3.2-1.6-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 135, 34560, 135, 135, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 135, 34560, 17280, 135, 135, 17280, 34560, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 135, 34560, 17280, 17280, 135, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 135, 34560, 17280, 17280, 17280, 34560, 34560, 135, 135, 17280, 135, 34560, 135, 135, 34560, 135, 17280, 17280, 135, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 135, 135, 34560, 17280, 34560, 135, 17280, 34560, 135, 34560, 17280, 135, 34560, 135, 135, 34560, 135, 135, 17280]
Prompts retrieved: 1663200 . Total input tokens: 371069728 . Total output tokens: 332471114
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.397737294901162,
    "estimated_duration": 3600.055606990415,
    "input_throughput": 6384.9244315467595,
    "output_throughput": 5624.85394966676,
    "total_throughput": 12009.778381213519,
    "itl": 152.6757030792657,
    "ttft": 1938042.558533261,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2870448283106092,
    "arrivals": 554568,
    "finished_requests": 92761,
    "scheduler_time": 56.9891558437304
}
#Debug simulation 
Total elapsed time: 6.3978451900184155. Arrivals time: 0.28649581084027886 Scheduler time: 6.015349818393588 Scheduler overhead time: 0.03478900296613574 Adapter cache time: 0.009110263083130121 Engine time: 0.03565190639346838 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_16-16-32/adapters_96_slots_96_rate_3.2-1.6-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_16-16-32/adapters_96_slots_96_rate_3.2-1.6-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 135, 34560, 135, 135, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 135, 34560, 17280, 135, 135, 17280, 34560, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 135, 34560, 17280, 17280, 135, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 135, 34560, 17280, 17280, 17280, 34560, 34560, 135, 135, 17280, 135, 34560, 135, 135, 34560, 135, 17280, 17280, 135, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 135, 135, 34560, 17280, 34560, 135, 17280, 34560, 135, 34560, 17280, 135, 34560, 135, 135, 34560, 135, 135, 17280]
Prompts retrieved: 1663200 . Total input tokens: 371069728 . Total output tokens: 332471114
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.366834633052349,
    "estimated_duration": 3600.0538271570385,
    "input_throughput": 6375.4082860825,
    "output_throughput": 5616.689074887536,
    "total_throughput": 11992.097360970036,
    "itl": 151.24868958329708,
    "ttft": 1938681.8214146718,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.32180989146232564,
    "arrivals": 554568,
    "finished_requests": 92611,
    "scheduler_time": 56.58911825842246
}
#Debug simulation 
Total elapsed time: 6.366947973147035. Arrivals time: 0.33772127190604806 Scheduler time: 5.932070414535701 Scheduler overhead time: 0.03520157653838396 Adapter cache time: 0.009140185546129942 Engine time: 0.036134723108261824 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-8/adapters_96_slots_96_rate_3.2-1.6-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-8/adapters_96_slots_96_rate_3.2-1.6-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 66, 34560, 66, 66, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 66, 34560, 17280, 66, 66, 17280, 34560, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 66, 34560, 17280, 17280, 66, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 66, 34560, 17280, 17280, 17280, 34560, 34560, 66, 66, 17280, 66, 34560, 66, 66, 34560, 66, 17280, 17280, 66, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 66, 66, 34560, 17280, 34560, 66, 17280, 34560, 66, 34560, 17280, 66, 34560, 66, 66, 34560, 66, 66, 17280]
Prompts retrieved: 1660992 . Total input tokens: 370572591 . Total output tokens: 332033415
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.404013413004577,
    "estimated_duration": 3600.0337379272555,
    "input_throughput": 6391.953152430423,
    "output_throughput": 5659.485294638007,
    "total_throughput": 12051.43844706843,
    "itl": 152.45069570994414,
    "ttft": 1937718.3139520201,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.29380682341754405,
    "arrivals": 553859,
    "finished_requests": 92917,
    "scheduler_time": 57.39990204530401
}
#Debug simulation 
Total elapsed time: 6.4041003081947565. Arrivals time: 0.31139502115547657 Scheduler time: 5.997890658210963 Scheduler overhead time: 0.034887317568063736 Adapter cache time: 0.008036626037210226 Engine time: 0.03557046828791499 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-16/adapters_96_slots_96_rate_3.2-1.6-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-16/adapters_96_slots_96_rate_3.2-1.6-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 66, 34560, 66, 66, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 66, 34560, 17280, 66, 66, 17280, 34560, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 66, 34560, 17280, 17280, 66, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 66, 34560, 17280, 17280, 17280, 34560, 34560, 66, 66, 17280, 66, 34560, 66, 66, 34560, 66, 17280, 17280, 66, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 66, 66, 34560, 17280, 34560, 66, 17280, 34560, 66, 34560, 17280, 66, 34560, 66, 66, 34560, 66, 66, 17280]
Prompts retrieved: 1660992 . Total input tokens: 370572591 . Total output tokens: 332033415
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.391619020141661,
    "estimated_duration": 3600.0599708164495,
    "input_throughput": 6391.9065755955535,
    "output_throughput": 5659.444055144268,
    "total_throughput": 12051.35063073982,
    "itl": 152.45113688226726,
    "ttft": 1937729.611684033,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31319492869079113,
    "arrivals": 553859,
    "finished_requests": 92917,
    "scheduler_time": 57.3999520756068
}
#Debug simulation 
Total elapsed time: 6.391706365160644. Arrivals time: 0.2849499029107392 Scheduler time: 6.011474606115371 Scheduler overhead time: 0.034978512674570084 Adapter cache time: 0.008117251098155975 Engine time: 0.035698373802006245 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-32/adapters_96_slots_96_rate_3.2-1.6-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-32/adapters_96_slots_96_rate_3.2-1.6-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 66, 34560, 66, 66, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 66, 34560, 17280, 66, 66, 17280, 34560, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 66, 34560, 17280, 17280, 66, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 66, 34560, 17280, 17280, 17280, 34560, 34560, 66, 66, 17280, 66, 34560, 66, 66, 34560, 66, 17280, 17280, 66, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 66, 66, 34560, 17280, 34560, 66, 17280, 34560, 66, 34560, 17280, 66, 34560, 66, 66, 34560, 66, 66, 17280]
Prompts retrieved: 1660992 . Total input tokens: 370572591 . Total output tokens: 332033415
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.364487236831337,
    "estimated_duration": 3600.104737515075,
    "input_throughput": 6376.705588806184,
    "output_throughput": 5647.66596597243,
    "total_throughput": 12024.371554778614,
    "itl": 150.7936971430151,
    "ttft": 1938765.4576323607,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3137616491317753,
    "arrivals": 553859,
    "finished_requests": 92708,
    "scheduler_time": 56.92690816579361
}
#Debug simulation 
Total elapsed time: 6.364602252840996. Arrivals time: 0.33765251701697707 Scheduler time: 5.930693326983601 Scheduler overhead time: 0.03550076298415661 Adapter cache time: 0.008200163953006268 Engine time: 0.03598899580538273 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-16-16/adapters_96_slots_96_rate_3.2-1.6-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-16-16/adapters_96_slots_96_rate_3.2-1.6-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 66, 34560, 66, 66, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 66, 34560, 17280, 66, 66, 17280, 34560, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 66, 34560, 17280, 17280, 66, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 66, 34560, 17280, 17280, 17280, 34560, 34560, 66, 66, 17280, 66, 34560, 66, 66, 34560, 66, 17280, 17280, 66, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 66, 66, 34560, 17280, 34560, 66, 17280, 34560, 66, 34560, 17280, 66, 34560, 66, 66, 34560, 66, 66, 17280]
Prompts retrieved: 1660992 . Total input tokens: 370572591 . Total output tokens: 332033415
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 6.4211158668622375,
    "estimated_duration": 3600.044546133068,
    "input_throughput": 6391.933962238655,
    "output_throughput": 5659.468303492184,
    "total_throughput": 12051.402265730838,
    "itl": 152.45088688842515,
    "ttft": 1937723.7753915465,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.30011987850070015,
    "arrivals": 553859,
    "finished_requests": 92917,
    "scheduler_time": 57.4000195203218
}
#Debug simulation 
Total elapsed time: 6.421232499647886. Arrivals time: 0.3387451693415642 Scheduler time: 5.986456505954266 Scheduler overhead time: 0.035275368485599756 Adapter cache time: 0.008151734713464975 Engine time: 0.03604612173512578 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-16-32/adapters_96_slots_96_rate_3.2-1.6-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-16-32/adapters_96_slots_96_rate_3.2-1.6-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 66, 34560, 66, 66, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 66, 34560, 17280, 66, 66, 17280, 34560, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 66, 34560, 17280, 17280, 66, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 66, 34560, 17280, 17280, 17280, 34560, 34560, 66, 66, 17280, 66, 34560, 66, 66, 34560, 66, 17280, 17280, 66, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 66, 66, 34560, 17280, 34560, 66, 17280, 34560, 66, 34560, 17280, 66, 34560, 66, 66, 34560, 66, 66, 17280]
Prompts retrieved: 1660992 . Total input tokens: 370572591 . Total output tokens: 332033415
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 6.414396828971803,
    "estimated_duration": 3600.0757611464905,
    "input_throughput": 6376.7569137737,
    "output_throughput": 5647.711423029873,
    "total_throughput": 12024.468336803573,
    "itl": 150.79794751760537,
    "ttft": 1938744.1940964388,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3177857702970504,
    "arrivals": 553859,
    "finished_requests": 92708,
    "scheduler_time": 56.92778716863916
}
#Debug simulation 
Total elapsed time: 6.414482657797635. Arrivals time: 0.31228155409917235 Scheduler time: 6.006087666377425 Scheduler overhead time: 0.03538693534210324 Adapter cache time: 0.008227281738072634 Engine time: 0.035902736242860556 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_16-16-16/adapters_96_slots_96_rate_3.2-1.6-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_16-16-16/adapters_96_slots_96_rate_3.2-1.6-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 66, 34560, 66, 66, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 66, 34560, 17280, 66, 66, 17280, 34560, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 66, 34560, 17280, 17280, 66, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 66, 34560, 17280, 17280, 17280, 34560, 34560, 66, 66, 17280, 66, 34560, 66, 66, 34560, 66, 17280, 17280, 66, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 66, 66, 34560, 17280, 34560, 66, 17280, 34560, 66, 34560, 17280, 66, 34560, 66, 66, 34560, 66, 66, 17280]
Prompts retrieved: 1660992 . Total input tokens: 370572591 . Total output tokens: 332033415
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.423401610925794,
    "estimated_duration": 3600.0315795919937,
    "input_throughput": 6391.956984612884,
    "output_throughput": 5659.488687682319,
    "total_throughput": 12051.445672295204,
    "itl": 152.4510179474535,
    "ttft": 1937716.7702164375,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2870448283106092,
    "arrivals": 553859,
    "finished_requests": 92917,
    "scheduler_time": 57.400008416166855
}
#Debug simulation 
Total elapsed time: 6.423517773859203. Arrivals time: 0.28441197657957673 Scheduler time: 6.043234948068857 Scheduler overhead time: 0.03521116729825735 Adapter cache time: 0.008228232618421316 Engine time: 0.03583361627534032 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_16-16-32/adapters_96_slots_96_rate_3.2-1.6-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_16-16-32/adapters_96_slots_96_rate_3.2-1.6-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 66, 34560, 66, 66, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 66, 34560, 17280, 66, 66, 17280, 34560, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 66, 34560, 17280, 17280, 66, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 66, 34560, 17280, 17280, 17280, 34560, 34560, 66, 66, 17280, 66, 34560, 66, 66, 34560, 66, 17280, 17280, 66, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 66, 66, 34560, 17280, 34560, 66, 17280, 34560, 66, 34560, 17280, 66, 34560, 66, 66, 34560, 66, 66, 17280]
Prompts retrieved: 1660992 . Total input tokens: 370572591 . Total output tokens: 332033415
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.434929506853223,
    "estimated_duration": 3600.0821786655038,
    "input_throughput": 6376.7455465446465,
    "output_throughput": 5647.701355399847,
    "total_throughput": 12024.446901944493,
    "itl": 150.79804290565082,
    "ttft": 1938748.9911817599,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3218098914623257,
    "arrivals": 553859,
    "finished_requests": 92708,
    "scheduler_time": 56.9277839901408
}
#Debug simulation 
Total elapsed time: 6.435014593880624. Arrivals time: 0.3593176626600325 Scheduler time: 5.978438192047179 Scheduler overhead time: 0.03574462700635195 Adapter cache time: 0.008366045076400042 Engine time: 0.03645204845815897 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-8-8/adapters_96_slots_96_rate_3.2-1.6-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-8-8/adapters_96_slots_96_rate_3.2-1.6-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 33, 34560, 33, 33, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 33, 34560, 17280, 33, 33, 17280, 34560, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 33, 34560, 17280, 17280, 33, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 33, 34560, 17280, 17280, 17280, 34560, 34560, 33, 33, 17280, 33, 34560, 33, 33, 34560, 33, 17280, 17280, 33, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 33, 33, 34560, 17280, 34560, 33, 17280, 34560, 33, 34560, 17280, 33, 34560, 33, 33, 34560, 33, 33, 17280]
Prompts retrieved: 1659936 . Total input tokens: 370337047 . Total output tokens: 331827132
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.469093326013535,
    "estimated_duration": 3600.079631954776,
    "input_throughput": 6458.97240538931,
    "output_throughput": 5692.267142677867,
    "total_throughput": 12151.239548067177,
    "itl": 150.9665922240699,
    "ttft": 1935509.7506108359,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 92,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.28156487244181305,
    "arrivals": 553508,
    "finished_requests": 93763,
    "scheduler_time": 57.646966683056235
}
#Debug simulation 
Total elapsed time: 6.469191753771156. Arrivals time: 0.2917228899896145 Scheduler time: 6.082115768454969 Scheduler overhead time: 0.035527128260582685 Adapter cache time: 0.006910533644258976 Engine time: 0.036229954566806555 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-8-16/adapters_96_slots_96_rate_3.2-1.6-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-8-16/adapters_96_slots_96_rate_3.2-1.6-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 33, 34560, 33, 33, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 33, 34560, 17280, 33, 33, 17280, 34560, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 33, 34560, 17280, 17280, 33, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 33, 34560, 17280, 17280, 17280, 34560, 34560, 33, 33, 17280, 33, 34560, 33, 33, 34560, 33, 17280, 17280, 33, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 33, 33, 34560, 17280, 34560, 33, 17280, 34560, 33, 34560, 17280, 33, 34560, 33, 33, 34560, 33, 33, 17280]
Prompts retrieved: 1659936 . Total input tokens: 370337047 . Total output tokens: 331827132
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.451883666217327,
    "estimated_duration": 3600.10141296022,
    "input_throughput": 6458.933327903154,
    "output_throughput": 5692.232703842012,
    "total_throughput": 12151.166031745166,
    "itl": 150.9670555489524,
    "ttft": 1935524.1333266774,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 92,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.29960034623742104,
    "arrivals": 553508,
    "finished_requests": 93763,
    "scheduler_time": 57.646946125320234
}
#Debug simulation 
Total elapsed time: 6.4520352948457. Arrivals time: 0.3406933122314513 Scheduler time: 6.016119276639074 Scheduler overhead time: 0.03560088621452451 Adapter cache time: 0.006878452841192484 Engine time: 0.03609370393678546 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-8-32/adapters_96_slots_96_rate_3.2-1.6-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-8-32/adapters_96_slots_96_rate_3.2-1.6-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 33, 34560, 33, 33, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 33, 34560, 17280, 33, 33, 17280, 34560, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 33, 34560, 17280, 17280, 33, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 33, 34560, 17280, 17280, 17280, 34560, 34560, 33, 33, 17280, 33, 34560, 33, 33, 34560, 33, 17280, 17280, 33, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 33, 33, 34560, 17280, 34560, 33, 17280, 34560, 33, 34560, 17280, 33, 34560, 33, 33, 34560, 33, 33, 17280]
Prompts retrieved: 1659936 . Total input tokens: 370337047 . Total output tokens: 331827132
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.448379954788834,
    "estimated_duration": 3600.1533222079233,
    "input_throughput": 6445.842141458596,
    "output_throughput": 5681.146653903191,
    "total_throughput": 12126.988795361787,
    "itl": 149.42910779973218,
    "ttft": 1936737.9218026071,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 92,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3002385837584737,
    "arrivals": 553508,
    "finished_requests": 93579,
    "scheduler_time": 57.200146385378986
}
#Debug simulation 
Total elapsed time: 6.448491581715643. Arrivals time: 0.37276919884607196 Scheduler time: 5.980060525704175 Scheduler overhead time: 0.03570056427270174 Adapter cache time: 0.006944433320313692 Engine time: 0.0362798972055316 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-16-16/adapters_96_slots_96_rate_3.2-1.6-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-16-16/adapters_96_slots_96_rate_3.2-1.6-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 33, 34560, 33, 33, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 33, 34560, 17280, 33, 33, 17280, 34560, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 33, 34560, 17280, 17280, 33, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 33, 34560, 17280, 17280, 17280, 34560, 34560, 33, 33, 17280, 33, 34560, 33, 33, 34560, 33, 17280, 17280, 33, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 33, 33, 34560, 17280, 34560, 33, 17280, 34560, 33, 34560, 17280, 33, 34560, 33, 33, 34560, 33, 33, 17280]
Prompts retrieved: 1659936 . Total input tokens: 370337047 . Total output tokens: 331827132
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 6.685175662860274,
    "estimated_duration": 3600.0890567132,
    "input_throughput": 6458.955496292443,
    "output_throughput": 5692.25224075687,
    "total_throughput": 12151.207737049313,
    "itl": 150.96677829303857,
    "ttft": 1935516.4148955077,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 92,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2877510820026511,
    "arrivals": 553508,
    "finished_requests": 93763,
    "scheduler_time": 57.64700902181928
}
#Debug simulation 
Total elapsed time: 6.685243125073612. Arrivals time: 0.541505906265229 Scheduler time: 6.048732424620539 Scheduler overhead time: 0.03538992302492261 Adapter cache time: 0.00695775868371129 Engine time: 0.03610754944384098 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-16-32/adapters_96_slots_96_rate_3.2-1.6-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-16-32/adapters_96_slots_96_rate_3.2-1.6-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 33, 34560, 33, 33, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 33, 34560, 17280, 33, 33, 17280, 34560, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 33, 34560, 17280, 17280, 33, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 33, 34560, 17280, 17280, 17280, 34560, 34560, 33, 33, 17280, 33, 34560, 33, 33, 34560, 33, 17280, 17280, 33, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 33, 33, 34560, 17280, 34560, 33, 17280, 34560, 33, 34560, 17280, 33, 34560, 33, 33, 34560, 33, 33, 17280]
Prompts retrieved: 1659936 . Total input tokens: 370337047 . Total output tokens: 331827132
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 6.472043081652373,
    "estimated_duration": 3600.156951366563,
    "input_throughput": 6445.835643690856,
    "output_throughput": 5681.1409269910755,
    "total_throughput": 12126.97657068193,
    "itl": 149.4291906537613,
    "ttft": 1936740.2554155984,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 92,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.30388544356450437,
    "arrivals": 553508,
    "finished_requests": 93579,
    "scheduler_time": 57.20012868421444
}
#Debug simulation 
Total elapsed time: 6.472155044786632. Arrivals time: 0.3728601597249508 Scheduler time: 6.001749994233251 Scheduler overhead time: 0.03600506577640772 Adapter cache time: 0.006987356580793858 Engine time: 0.0377244264818728 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_16-16-16/adapters_96_slots_96_rate_3.2-1.6-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_16-16-16/adapters_96_slots_96_rate_3.2-1.6-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 33, 34560, 33, 33, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 33, 34560, 17280, 33, 33, 17280, 34560, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 33, 34560, 17280, 17280, 33, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 33, 34560, 17280, 17280, 17280, 34560, 34560, 33, 33, 17280, 33, 34560, 33, 33, 34560, 33, 17280, 17280, 33, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 33, 33, 34560, 17280, 34560, 33, 17280, 34560, 33, 34560, 17280, 33, 34560, 33, 33, 34560, 33, 33, 17280]
Prompts retrieved: 1659936 . Total input tokens: 370337047 . Total output tokens: 331827132
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.422538917977363,
    "estimated_duration": 3600.0699556803584,
    "input_throughput": 6458.989765826806,
    "output_throughput": 5692.2824423635975,
    "total_throughput": 12151.272208190405,
    "itl": 150.96671507446476,
    "ttft": 1935492.836787135,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 92,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.27508462713100046,
    "arrivals": 553508,
    "finished_requests": 93763,
    "scheduler_time": 57.646987152970084
}
#Debug simulation 
Total elapsed time: 6.422630385030061. Arrivals time: 0.29111706698313355 Scheduler time: 6.036406071390957 Scheduler overhead time: 0.03571695275604725 Adapter cache time: 0.006937643047422171 Engine time: 0.03589733503758907 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_16-16-32/adapters_96_slots_96_rate_3.2-1.6-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_16-16-32/adapters_96_slots_96_rate_3.2-1.6-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 33, 34560, 33, 33, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 33, 34560, 17280, 33, 33, 17280, 34560, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 33, 34560, 17280, 17280, 33, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 33, 34560, 17280, 17280, 17280, 34560, 34560, 33, 33, 17280, 33, 34560, 33, 33, 34560, 33, 17280, 17280, 33, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 33, 33, 34560, 17280, 34560, 33, 17280, 34560, 33, 34560, 17280, 33, 34560, 33, 33, 34560, 33, 33, 17280]
Prompts retrieved: 1659936 . Total input tokens: 370337047 . Total output tokens: 331827132
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.436559583991766,
    "estimated_duration": 3600.0045310668875,
    "input_throughput": 6446.107720070766,
    "output_throughput": 5681.196182811137,
    "total_throughput": 12127.303902881904,
    "itl": 149.4281859174322,
    "ttft": 1936718.7261809192,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 92,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.30778381094336477,
    "arrivals": 553508,
    "finished_requests": 93576,
    "scheduler_time": 57.19741812186168
}
#Debug simulation 
Total elapsed time: 6.436660788953304. Arrivals time: 0.3473417814821005 Scheduler time: 5.99354901490733 Scheduler overhead time: 0.03580527100712061 Adapter cache time: 0.006965650245547295 Engine time: 0.036287632305175066 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-8-8/adapters_96_slots_96_rate_3.2-0.8-0.4_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-8-8/adapters_96_slots_96_rate_3.2-0.8-0.4_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [32 32 32]
Adapter prompts. [4320, 4320, 4320, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 4320, 34560, 4320, 4320, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 4320, 34560, 8640, 4320, 4320, 8640, 34560, 4320, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 34560, 8640, 8640, 4320, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 4320, 34560, 8640, 8640, 8640, 34560, 34560, 4320, 4320, 8640, 4320, 34560, 4320, 4320, 34560, 4320, 8640, 8640, 4320, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 4320, 4320, 34560, 8640, 34560, 4320, 8640, 34560, 4320, 34560, 8640, 4320, 34560, 4320, 4320, 34560, 4320, 4320, 8640]
Prompts retrieved: 1520640 . Total input tokens: 339170557 . Total output tokens: 304105255
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 5.5671542710624635,
    "estimated_duration": 3600.075446590706,
    "input_throughput": 5507.492632904863,
    "output_throughput": 4867.716040950051,
    "total_throughput": 10375.208673854915,
    "itl": 176.68048062387894,
    "ttft": 2002749.2225980975,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.29380682341754405,
    "arrivals": 507133,
    "finished_requests": 80211,
    "scheduler_time": 49.46014257036643
}
#Debug simulation 
Total elapsed time: 5.567302363924682. Arrivals time: 0.254345026332885 Scheduler time: 5.224009765312076 Scheduler overhead time: 0.030342016369104385 Adapter cache time: 0.013234770391136408 Engine time: 0.03106909990310669 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-8-16/adapters_96_slots_96_rate_3.2-0.8-0.4_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-8-16/adapters_96_slots_96_rate_3.2-0.8-0.4_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [32 32 32]
Adapter prompts. [4320, 4320, 4320, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 4320, 34560, 4320, 4320, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 4320, 34560, 8640, 4320, 4320, 8640, 34560, 4320, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 34560, 8640, 8640, 4320, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 4320, 34560, 8640, 8640, 8640, 34560, 34560, 4320, 4320, 8640, 4320, 34560, 4320, 4320, 34560, 4320, 8640, 8640, 4320, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 4320, 4320, 34560, 8640, 34560, 4320, 8640, 34560, 4320, 34560, 8640, 4320, 34560, 4320, 4320, 34560, 4320, 4320, 8640]
Prompts retrieved: 1520640 . Total input tokens: 339170557 . Total output tokens: 304105255
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.551925211213529,
    "estimated_duration": 3600.1201063975423,
    "input_throughput": 5508.58788426491,
    "output_throughput": 4868.5447935065495,
    "total_throughput": 10377.13267777146,
    "itl": 176.6440509175068,
    "ttft": 2002735.1525710265,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31319492869079113,
    "arrivals": 507133,
    "finished_requests": 80227,
    "scheduler_time": 49.470824712903216
}
#Debug simulation 
Total elapsed time: 5.552037193905562. Arrivals time: 0.3041617199778557 Scheduler time: 5.1589732631109655 Scheduler overhead time: 0.030327335000038147 Adapter cache time: 0.013487978372722864 Engine time: 0.03091978980228305 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-8-32/adapters_96_slots_96_rate_3.2-0.8-0.4_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-8-32/adapters_96_slots_96_rate_3.2-0.8-0.4_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [32 32 32]
Adapter prompts. [4320, 4320, 4320, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 4320, 34560, 4320, 4320, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 4320, 34560, 8640, 4320, 4320, 8640, 34560, 4320, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 34560, 8640, 8640, 4320, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 4320, 34560, 8640, 8640, 8640, 34560, 34560, 4320, 4320, 8640, 4320, 34560, 4320, 4320, 34560, 4320, 8640, 8640, 4320, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 4320, 4320, 34560, 8640, 34560, 4320, 8640, 34560, 4320, 34560, 8640, 4320, 34560, 4320, 4320, 34560, 4320, 4320, 8640]
Prompts retrieved: 1520640 . Total input tokens: 339170557 . Total output tokens: 304105255
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.549801563844085,
    "estimated_duration": 3600.037224616954,
    "input_throughput": 5497.234546541583,
    "output_throughput": 4859.909747700336,
    "total_throughput": 10357.14429424192,
    "itl": 174.61189388370664,
    "ttft": 2003773.1998625153,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31376164913177523,
    "arrivals": 507133,
    "finished_requests": 80075,
    "scheduler_time": 49.073715811949214
}
#Debug simulation 
Total elapsed time: 5.549893871881068. Arrivals time: 0.3046590592712164 Scheduler time: 5.155620804056525 Scheduler overhead time: 0.030656625516712666 Adapter cache time: 0.013628332410007715 Engine time: 0.03104933863505721 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-16-16/adapters_96_slots_96_rate_3.2-0.8-0.4_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-16-16/adapters_96_slots_96_rate_3.2-0.8-0.4_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [32 32 32]
Adapter prompts. [4320, 4320, 4320, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 4320, 34560, 4320, 4320, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 4320, 34560, 8640, 4320, 4320, 8640, 34560, 4320, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 34560, 8640, 8640, 4320, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 4320, 34560, 8640, 8640, 8640, 34560, 34560, 4320, 4320, 8640, 4320, 34560, 4320, 4320, 34560, 4320, 8640, 8640, 4320, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 4320, 4320, 34560, 8640, 34560, 4320, 8640, 34560, 4320, 34560, 8640, 4320, 34560, 4320, 4320, 34560, 4320, 4320, 8640]
Prompts retrieved: 1520640 . Total input tokens: 339170557 . Total output tokens: 304105255
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 5.595992220100015,
    "estimated_duration": 3600.0826708134095,
    "input_throughput": 5507.48158111607,
    "output_throughput": 4867.706272989715,
    "total_throughput": 10375.187854105785,
    "itl": 176.6805926902306,
    "ttft": 2002754.6119960474,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3001198785007001,
    "arrivals": 507133,
    "finished_requests": 80211,
    "scheduler_time": 49.460109017757055
}
#Debug simulation 
Total elapsed time: 5.596110721118748. Arrivals time: 0.2815201603807509 Scheduler time: 5.225844484288245 Scheduler overhead time: 0.030276205856353045 Adapter cache time: 0.01314464770257473 Engine time: 0.031081486027687788 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-16-32/adapters_96_slots_96_rate_3.2-0.8-0.4_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-16-32/adapters_96_slots_96_rate_3.2-0.8-0.4_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [32 32 32]
Adapter prompts. [4320, 4320, 4320, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 4320, 34560, 4320, 4320, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 4320, 34560, 8640, 4320, 4320, 8640, 34560, 4320, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 34560, 8640, 8640, 4320, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 4320, 34560, 8640, 8640, 8640, 34560, 34560, 4320, 4320, 8640, 4320, 34560, 4320, 4320, 34560, 4320, 8640, 8640, 4320, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 4320, 4320, 34560, 8640, 34560, 4320, 8640, 34560, 4320, 34560, 8640, 4320, 34560, 4320, 4320, 34560, 4320, 4320, 8640]
Prompts retrieved: 1520640 . Total input tokens: 339170557 . Total output tokens: 304105255
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 5.589492675848305,
    "estimated_duration": 3600.039535113818,
    "input_throughput": 5497.6443472236115,
    "output_throughput": 4860.0619046942875,
    "total_throughput": 10357.706251917898,
    "itl": 174.6099965793847,
    "ttft": 2003746.9557103224,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31778577029705063,
    "arrivals": 507133,
    "finished_requests": 80078,
    "scheduler_time": 49.07845139229412
}
#Debug simulation 
Total elapsed time: 5.589576453901827. Arrivals time: 0.2544758799485862 Scheduler time: 5.2443595989607275 Scheduler overhead time: 0.030795649625360966 Adapter cache time: 0.013667074963450432 Engine time: 0.031759706791490316 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_16-16-16/adapters_96_slots_96_rate_3.2-0.8-0.4_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_16-16-16/adapters_96_slots_96_rate_3.2-0.8-0.4_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [32 32 32]
Adapter prompts. [4320, 4320, 4320, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 4320, 34560, 4320, 4320, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 4320, 34560, 8640, 4320, 4320, 8640, 34560, 4320, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 34560, 8640, 8640, 4320, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 4320, 34560, 8640, 8640, 8640, 34560, 34560, 4320, 4320, 8640, 4320, 34560, 4320, 4320, 34560, 4320, 8640, 8640, 4320, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 4320, 4320, 34560, 8640, 34560, 4320, 8640, 34560, 4320, 34560, 8640, 4320, 34560, 4320, 4320, 34560, 4320, 4320, 8640]
Prompts retrieved: 1520640 . Total input tokens: 339170557 . Total output tokens: 304105255
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 5.560735533945262,
    "estimated_duration": 3600.0652272359753,
    "input_throughput": 5507.508266794069,
    "output_throughput": 4867.7298587321775,
    "total_throughput": 10375.238125526246,
    "itl": 176.68092459441726,
    "ttft": 2002737.1619016558,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2870448283106092,
    "arrivals": 507133,
    "finished_requests": 80211,
    "scheduler_time": 49.45996343400551
}
#Debug simulation 
Total elapsed time: 5.560823479201645. Arrivals time: 0.3021081257611513 Scheduler time: 5.170168903190643 Scheduler overhead time: 0.030247053131461143 Adapter cache time: 0.013182807713747025 Engine time: 0.030997508205473423 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_16-16-32/adapters_96_slots_96_rate_3.2-0.8-0.4_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_16-16-32/adapters_96_slots_96_rate_3.2-0.8-0.4_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [32 32 32]
Adapter prompts. [4320, 4320, 4320, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 4320, 34560, 4320, 4320, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 4320, 34560, 8640, 4320, 4320, 8640, 34560, 4320, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 34560, 8640, 8640, 4320, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 4320, 34560, 8640, 8640, 8640, 34560, 34560, 4320, 4320, 8640, 4320, 34560, 4320, 4320, 34560, 4320, 8640, 8640, 4320, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 4320, 4320, 34560, 8640, 34560, 4320, 8640, 34560, 4320, 34560, 8640, 4320, 34560, 4320, 4320, 34560, 4320, 4320, 8640]
Prompts retrieved: 1520640 . Total input tokens: 339170557 . Total output tokens: 304105255
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.579057964961976,
    "estimated_duration": 3600.1554600340746,
    "input_throughput": 5497.315107557239,
    "output_throughput": 4859.904855284888,
    "total_throughput": 10357.219962842128,
    "itl": 174.62309772856204,
    "ttft": 2003837.511498372,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.32180989146232575,
    "arrivals": 507133,
    "finished_requests": 80077,
    "scheduler_time": 49.077387985711624
}
#Debug simulation 
Total elapsed time: 5.57919177878648. Arrivals time: 0.306071731261909 Scheduler time: 5.182967015076429 Scheduler overhead time: 0.030789463315159082 Adapter cache time: 0.013653996400535107 Engine time: 0.03131705801934004 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-8-8/adapters_96_slots_96_rate_3.2-0.8-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-8-8/adapters_96_slots_96_rate_3.2-0.8-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 1080, 34560, 1080, 1080, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 1080, 34560, 8640, 1080, 1080, 8640, 34560, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 34560, 8640, 8640, 1080, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 1080, 34560, 8640, 8640, 8640, 34560, 34560, 1080, 1080, 8640, 1080, 34560, 1080, 1080, 34560, 1080, 8640, 8640, 1080, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 1080, 1080, 34560, 8640, 34560, 1080, 8640, 34560, 1080, 34560, 8640, 1080, 34560, 1080, 1080, 34560, 1080, 1080, 8640]
Prompts retrieved: 1416960 . Total input tokens: 316002805 . Total output tokens: 283393833
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 5.954579730052501,
    "estimated_duration": 3600.16940874274,
    "input_throughput": 5909.645515106457,
    "output_throughput": 5212.559985212903,
    "total_throughput": 11122.20550031936,
    "itl": 164.9771958327064,
    "ttft": 1949602.4984081676,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.29380682341754405,
    "arrivals": 472666,
    "finished_requests": 85829,
    "scheduler_time": 52.972244432500815
}
#Debug simulation 
Total elapsed time: 5.9546692334115505. Arrivals time: 0.26676555816084146 Scheduler time: 5.587611587252468 Scheduler overhead time: 0.032695428002625704 Adapter cache time: 0.018817621283233166 Engine time: 0.03350931033492088 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-8-16/adapters_96_slots_96_rate_3.2-0.8-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-8-16/adapters_96_slots_96_rate_3.2-0.8-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 1080, 34560, 1080, 1080, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 1080, 34560, 8640, 1080, 1080, 8640, 34560, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 34560, 8640, 8640, 1080, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 1080, 34560, 8640, 8640, 8640, 34560, 34560, 1080, 1080, 8640, 1080, 34560, 1080, 1080, 34560, 1080, 8640, 8640, 1080, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 1080, 1080, 34560, 8640, 34560, 1080, 8640, 34560, 1080, 34560, 8640, 1080, 34560, 1080, 1080, 34560, 1080, 1080, 8640]
Prompts retrieved: 1416960 . Total input tokens: 316002805 . Total output tokens: 283393833
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.933481304906309,
    "estimated_duration": 3600.0658625144956,
    "input_throughput": 5909.221334395613,
    "output_throughput": 5212.334639592846,
    "total_throughput": 11121.555973988457,
    "itl": 164.97801672409008,
    "ttft": 1949611.528722024,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31319492869079113,
    "arrivals": 472666,
    "finished_requests": 85823,
    "scheduler_time": 52.970662769523884
}
#Debug simulation 
Total elapsed time: 5.933594344183803. Arrivals time: 0.31052857730537653 Scheduler time: 5.523208581842482 Scheduler overhead time: 0.03242598148062825 Adapter cache time: 0.018705434165894985 Engine time: 0.03336902987211943 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-8-32/adapters_96_slots_96_rate_3.2-0.8-0.1_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-8-32/adapters_96_slots_96_rate_3.2-0.8-0.1_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 1080, 34560, 1080, 1080, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 1080, 34560, 8640, 1080, 1080, 8640, 34560, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 34560, 8640, 8640, 1080, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 1080, 34560, 8640, 8640, 8640, 34560, 34560, 1080, 1080, 8640, 1080, 34560, 1080, 1080, 34560, 1080, 8640, 8640, 1080, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 1080, 1080, 34560, 8640, 34560, 1080, 8640, 34560, 1080, 34560, 8640, 1080, 34560, 1080, 1080, 34560, 1080, 1080, 8640]
Prompts retrieved: 1416960 . Total input tokens: 316002805 . Total output tokens: 283393833
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.965054073836654,
    "estimated_duration": 3600.163523691798,
    "input_throughput": 5900.940015695432,
    "output_throughput": 5204.189719912272,
    "total_throughput": 11105.129735607705,
    "itl": 163.05115164797147,
    "ttft": 1950963.192454342,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3137616491317753,
    "arrivals": 472666,
    "finished_requests": 85684,
    "scheduler_time": 52.57758335865832
}
#Debug simulation 
Total elapsed time: 5.965169964823872. Arrivals time: 0.3132147057913244 Scheduler time: 5.550042876508087 Scheduler overhead time: 0.03318576607853174 Adapter cache time: 0.01922285882756114 Engine time: 0.03398523712530732 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-16-16/adapters_96_slots_96_rate_3.2-0.8-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-16-16/adapters_96_slots_96_rate_3.2-0.8-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 1080, 34560, 1080, 1080, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 1080, 34560, 8640, 1080, 1080, 8640, 34560, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 34560, 8640, 8640, 1080, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 1080, 34560, 8640, 8640, 8640, 34560, 34560, 1080, 1080, 8640, 1080, 34560, 1080, 1080, 34560, 1080, 8640, 8640, 1080, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 1080, 1080, 34560, 8640, 34560, 1080, 8640, 34560, 1080, 34560, 8640, 1080, 34560, 1080, 1080, 34560, 1080, 1080, 8640]
Prompts retrieved: 1416960 . Total input tokens: 316002805 . Total output tokens: 283393833
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 5.97360908286646,
    "estimated_duration": 3600.039278553989,
    "input_throughput": 5909.232748300684,
    "output_throughput": 5212.320352109345,
    "total_throughput": 11121.553100410028,
    "itl": 164.97850292459935,
    "ttft": 1949607.1051844184,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.30011987850070015,
    "arrivals": 472666,
    "finished_requests": 85822,
    "scheduler_time": 52.97007084038276
}
#Debug simulation 
Total elapsed time: 5.973694845102727. Arrivals time: 0.3138490398414433 Scheduler time: 5.559063340071589 Scheduler overhead time: 0.032873646821826696 Adapter cache time: 0.018907001707702875 Engine time: 0.03377221105620265 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-16-32/adapters_96_slots_96_rate_3.2-0.8-0.1_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-16-32/adapters_96_slots_96_rate_3.2-0.8-0.1_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 1080, 34560, 1080, 1080, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 1080, 34560, 8640, 1080, 1080, 8640, 34560, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 34560, 8640, 8640, 1080, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 1080, 34560, 8640, 8640, 8640, 34560, 34560, 1080, 1080, 8640, 1080, 34560, 1080, 1080, 34560, 1080, 8640, 8640, 1080, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 1080, 1080, 34560, 8640, 34560, 1080, 8640, 34560, 1080, 34560, 8640, 1080, 34560, 1080, 1080, 34560, 1080, 1080, 8640]
Prompts retrieved: 1416960 . Total input tokens: 316002805 . Total output tokens: 283393833
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 5.944269340950996,
    "estimated_duration": 3600.168105301976,
    "input_throughput": 5900.932506099756,
    "output_throughput": 5204.183097008038,
    "total_throughput": 11105.115603107795,
    "itl": 163.0510739566646,
    "ttft": 1950966.6753013036,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31778577029705046,
    "arrivals": 472666,
    "finished_requests": 85684,
    "scheduler_time": 52.57754007158774
}
#Debug simulation 
Total elapsed time: 5.944356312975287. Arrivals time: 0.31172121223062277 Scheduler time: 5.531499256379902 Scheduler overhead time: 0.0328385871835053 Adapter cache time: 0.019426393322646618 Engine time: 0.03353069396689534 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_16-16-16/adapters_96_slots_96_rate_3.2-0.8-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_16-16-16/adapters_96_slots_96_rate_3.2-0.8-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 1080, 34560, 1080, 1080, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 1080, 34560, 8640, 1080, 1080, 8640, 34560, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 34560, 8640, 8640, 1080, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 1080, 34560, 8640, 8640, 8640, 34560, 34560, 1080, 1080, 8640, 1080, 34560, 1080, 1080, 34560, 1080, 8640, 8640, 1080, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 1080, 1080, 34560, 8640, 34560, 1080, 8640, 34560, 1080, 34560, 8640, 1080, 34560, 1080, 1080, 34560, 1080, 1080, 8640]
Prompts retrieved: 1416960 . Total input tokens: 316002805 . Total output tokens: 283393833
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.198968267999589,
    "estimated_duration": 3600.159872260932,
    "input_throughput": 5909.661169196538,
    "output_throughput": 5212.573792789575,
    "total_throughput": 11122.234961986114,
    "itl": 164.97712945743996,
    "ttft": 1949595.6302035209,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2870448283106092,
    "arrivals": 472666,
    "finished_requests": 85829,
    "scheduler_time": 52.972294866776345
}
#Debug simulation 
Total elapsed time: 6.1990876798518. Arrivals time: 0.26728147780522704 Scheduler time: 5.831927936989814 Scheduler overhead time: 0.032622918020933867 Adapter cache time: 0.018790080212056637 Engine time: 0.03315797867253423 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_16-16-32/adapters_96_slots_96_rate_3.2-0.8-0.1_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_16-16-32/adapters_96_slots_96_rate_3.2-0.8-0.1_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 1080, 34560, 1080, 1080, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 1080, 34560, 8640, 1080, 1080, 8640, 34560, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 34560, 8640, 8640, 1080, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 1080, 34560, 8640, 8640, 8640, 34560, 34560, 1080, 1080, 8640, 1080, 34560, 1080, 1080, 34560, 1080, 8640, 8640, 1080, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 1080, 1080, 34560, 8640, 34560, 1080, 8640, 34560, 1080, 34560, 8640, 1080, 34560, 1080, 1080, 34560, 1080, 1080, 8640]
Prompts retrieved: 1416960 . Total input tokens: 316002805 . Total output tokens: 283393833
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.948465494904667,
    "estimated_duration": 3600.1722828197617,
    "input_throughput": 5900.925658857857,
    "output_throughput": 5204.177058250518,
    "total_throughput": 11105.102717108375,
    "itl": 163.0511004620516,
    "ttft": 1950969.842114231,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.32180989146232564,
    "arrivals": 472666,
    "finished_requests": 85684,
    "scheduler_time": 52.577493529941385
}
#Debug simulation 
Total elapsed time: 5.948579901363701. Arrivals time: 0.3138590562157333 Scheduler time: 5.533408347517252 Scheduler overhead time: 0.03289184998720884 Adapter cache time: 0.019312656484544277 Engine time: 0.03373247291892767 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-8-8/adapters_96_slots_96_rate_3.2-0.8-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-8-8/adapters_96_slots_96_rate_3.2-0.8-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 540, 34560, 540, 540, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 540, 34560, 8640, 540, 540, 8640, 34560, 540, 8640, 540, 540, 8640, 8640, 8640, 540, 540, 34560, 8640, 8640, 540, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 540, 34560, 8640, 8640, 8640, 34560, 34560, 540, 540, 8640, 540, 34560, 540, 540, 34560, 540, 8640, 8640, 540, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 540, 540, 34560, 8640, 34560, 540, 8640, 34560, 540, 34560, 8640, 540, 34560, 540, 540, 34560, 540, 540, 8640]
Prompts retrieved: 1399680 . Total input tokens: 312160527 . Total output tokens: 279955315
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.106553226243705,
    "estimated_duration": 3600.0719676833105,
    "input_throughput": 6098.100870502154,
    "output_throughput": 5398.297360290322,
    "total_throughput": 11496.398230792476,
    "itl": 159.41235194415415,
    "ttft": 1918096.9721259584,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.29380682341754405,
    "arrivals": 466828,
    "finished_requests": 88820,
    "scheduler_time": 54.94653158643487
}
#Debug simulation 
Total elapsed time: 6.106664534192532. Arrivals time: 0.31450496800243855 Scheduler time: 5.6936946818605065 Scheduler overhead time: 0.03341646259650588 Adapter cache time: 0.015274414326995611 Engine time: 0.034160081297159195 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-8-16/adapters_96_slots_96_rate_3.2-0.8-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-8-16/adapters_96_slots_96_rate_3.2-0.8-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 540, 34560, 540, 540, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 540, 34560, 8640, 540, 540, 8640, 34560, 540, 8640, 540, 540, 8640, 8640, 8640, 540, 540, 34560, 8640, 8640, 540, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 540, 34560, 8640, 8640, 8640, 34560, 34560, 540, 540, 8640, 540, 34560, 540, 540, 34560, 540, 8640, 8640, 540, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 540, 540, 34560, 8640, 34560, 540, 8640, 34560, 540, 34560, 8640, 540, 34560, 540, 540, 34560, 540, 540, 8640]
Prompts retrieved: 1399680 . Total input tokens: 312160527 . Total output tokens: 279955315
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.174212699756026,
    "estimated_duration": 3600.156251755278,
    "input_throughput": 6097.997549216459,
    "output_throughput": 5398.203478119777,
    "total_throughput": 11496.201027336236,
    "itl": 159.41378346640664,
    "ttft": 1918113.7482172793,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31319492869079113,
    "arrivals": 466828,
    "finished_requests": 88822,
    "scheduler_time": 54.947585802987014
}
#Debug simulation 
Total elapsed time: 6.1743356310762465. Arrivals time: 0.29553403053432703 Scheduler time: 5.779614914674312 Scheduler overhead time: 0.033590356819331646 Adapter cache time: 0.01538855955004692 Engine time: 0.034373062197119 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-8-32/adapters_96_slots_96_rate_3.2-0.8-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-8-32/adapters_96_slots_96_rate_3.2-0.8-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 540, 34560, 540, 540, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 540, 34560, 8640, 540, 540, 8640, 34560, 540, 8640, 540, 540, 8640, 8640, 8640, 540, 540, 34560, 8640, 8640, 540, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 540, 34560, 8640, 8640, 8640, 34560, 34560, 540, 540, 8640, 540, 34560, 540, 540, 34560, 540, 8640, 8640, 540, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 540, 540, 34560, 8640, 34560, 540, 8640, 34560, 540, 34560, 8640, 540, 34560, 540, 540, 34560, 540, 540, 8640]
Prompts retrieved: 1399680 . Total input tokens: 312160527 . Total output tokens: 279955315
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.15122459596023,
    "estimated_duration": 3600.091277450906,
    "input_throughput": 6088.798674993852,
    "output_throughput": 5389.8769516031,
    "total_throughput": 11478.675626596952,
    "itl": 157.53728210658429,
    "ttft": 1919108.17926543,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31376164913177523,
    "arrivals": 466828,
    "finished_requests": 88677,
    "scheduler_time": 54.50814148062366
}
#Debug simulation 
Total elapsed time: 6.1513119619339705. Arrivals time: 0.2737769354134798 Scheduler time: 5.777350157964975 Scheduler overhead time: 0.03399000223726034 Adapter cache time: 0.015411817003041506 Engine time: 0.0347585161216557 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-16-16/adapters_96_slots_96_rate_3.2-0.8-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-16-16/adapters_96_slots_96_rate_3.2-0.8-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 540, 34560, 540, 540, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 540, 34560, 8640, 540, 540, 8640, 34560, 540, 8640, 540, 540, 8640, 8640, 8640, 540, 540, 34560, 8640, 8640, 540, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 540, 34560, 8640, 8640, 8640, 34560, 34560, 540, 540, 8640, 540, 34560, 540, 540, 34560, 540, 8640, 8640, 540, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 540, 540, 34560, 8640, 34560, 540, 8640, 34560, 540, 34560, 8640, 540, 34560, 540, 540, 34560, 540, 540, 8640]
Prompts retrieved: 1399680 . Total input tokens: 312160527 . Total output tokens: 279955315
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 6.385456308256835,
    "estimated_duration": 3600.0775668785177,
    "input_throughput": 6098.091386135073,
    "output_throughput": 5398.2889643265835,
    "total_throughput": 11496.380350461657,
    "itl": 159.4123447019799,
    "ttft": 1918099.5684933176,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.30011987850070015,
    "arrivals": 466828,
    "finished_requests": 88820,
    "scheduler_time": 54.946460087994
}
#Debug simulation 
Total elapsed time: 6.385531004983932. Arrivals time: 0.5646445252932608 Scheduler time: 5.722147460095584 Scheduler overhead time: 0.03337391838431358 Adapter cache time: 0.015348568558692932 Engine time: 0.03427939675748348 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-16-32/adapters_96_slots_96_rate_3.2-0.8-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-16-32/adapters_96_slots_96_rate_3.2-0.8-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 540, 34560, 540, 540, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 540, 34560, 8640, 540, 540, 8640, 34560, 540, 8640, 540, 540, 8640, 8640, 8640, 540, 540, 34560, 8640, 8640, 540, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 540, 34560, 8640, 8640, 8640, 34560, 34560, 540, 540, 8640, 540, 34560, 540, 540, 34560, 540, 8640, 8640, 540, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 540, 540, 34560, 8640, 34560, 540, 8640, 34560, 540, 34560, 8640, 540, 34560, 540, 540, 34560, 540, 540, 8640]
Prompts retrieved: 1399680 . Total input tokens: 312160527 . Total output tokens: 279955315
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 6.13972865883261,
    "estimated_duration": 3600.095209155763,
    "input_throughput": 6088.7920253476805,
    "output_throughput": 5389.87106525728,
    "total_throughput": 11478.66309060496,
    "itl": 157.53732662899452,
    "ttft": 1919111.1827861057,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31778577029705046,
    "arrivals": 466828,
    "finished_requests": 88677,
    "scheduler_time": 54.50810384809175
}
#Debug simulation 
Total elapsed time: 6.139858989045024. Arrivals time: 0.27606117026880383 Scheduler time: 5.763065009377897 Scheduler overhead time: 0.03378063067793846 Adapter cache time: 0.015800473280251026 Engine time: 0.03515146113932133 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_16-16-16/adapters_96_slots_96_rate_3.2-0.8-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_16-16-16/adapters_96_slots_96_rate_3.2-0.8-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 540, 34560, 540, 540, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 540, 34560, 8640, 540, 540, 8640, 34560, 540, 8640, 540, 540, 8640, 8640, 8640, 540, 540, 34560, 8640, 8640, 540, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 540, 34560, 8640, 8640, 8640, 34560, 34560, 540, 540, 8640, 540, 34560, 540, 540, 34560, 540, 8640, 8640, 540, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 540, 540, 34560, 8640, 34560, 540, 8640, 34560, 540, 34560, 8640, 540, 34560, 540, 540, 34560, 540, 540, 8640]
Prompts retrieved: 1399680 . Total input tokens: 312160527 . Total output tokens: 279955315
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.147741807159036,
    "estimated_duration": 3600.0580608626015,
    "input_throughput": 6098.124427120975,
    "output_throughput": 5398.318213607756,
    "total_throughput": 11496.44264072873,
    "itl": 159.41224351490342,
    "ttft": 1918093.9979222366,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2870448283106092,
    "arrivals": 466828,
    "finished_requests": 88820,
    "scheduler_time": 54.9464307296887
}
#Debug simulation 
Total elapsed time: 6.147855279035866. Arrivals time: 0.34284509904682636 Scheduler time: 5.706021061632782 Scheduler overhead time: 0.033400914166122675 Adapter cache time: 0.015479001216590405 Engine time: 0.03434152901172638 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_16-16-32/adapters_96_slots_96_rate_3.2-0.8-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_16-16-32/adapters_96_slots_96_rate_3.2-0.8-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 540, 34560, 540, 540, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 540, 34560, 8640, 540, 540, 8640, 34560, 540, 8640, 540, 540, 8640, 8640, 8640, 540, 540, 34560, 8640, 8640, 540, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 540, 34560, 8640, 8640, 8640, 34560, 34560, 540, 540, 8640, 540, 34560, 540, 540, 34560, 540, 8640, 8640, 540, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 540, 540, 34560, 8640, 34560, 540, 8640, 34560, 540, 34560, 8640, 540, 34560, 540, 540, 34560, 540, 540, 8640]
Prompts retrieved: 1399680 . Total input tokens: 312160527 . Total output tokens: 279955315
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.124879507813603,
    "estimated_duration": 3600.099023552533,
    "input_throughput": 6088.785574117178,
    "output_throughput": 5389.865354551366,
    "total_throughput": 11478.650928668545,
    "itl": 157.53739643136566,
    "ttft": 1919114.0881975943,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.32180989146232564,
    "arrivals": 466828,
    "finished_requests": 88677,
    "scheduler_time": 54.50807092767539
}
#Debug simulation 
Total elapsed time: 6.124988886993378. Arrivals time: 0.2745075817219913 Scheduler time: 5.750348821748048 Scheduler overhead time: 0.033801271580159664 Adapter cache time: 0.015658352989703417 Engine time: 0.03472190396860242 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-8-8/adapters_96_slots_96_rate_3.2-0.8-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-8-8/adapters_96_slots_96_rate_3.2-0.8-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 270, 34560, 270, 270, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 270, 34560, 8640, 270, 270, 8640, 34560, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 270, 34560, 8640, 8640, 270, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 270, 34560, 8640, 8640, 8640, 34560, 34560, 270, 270, 8640, 270, 34560, 270, 270, 34560, 270, 8640, 8640, 270, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 270, 270, 34560, 8640, 34560, 270, 8640, 34560, 270, 34560, 8640, 270, 34560, 270, 270, 34560, 270, 270, 8640]
Prompts retrieved: 1391040 . Total input tokens: 310246563 . Total output tokens: 278256734
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.254424259066582,
    "estimated_duration": 3600.141499107976,
    "input_throughput": 6231.490069364951,
    "output_throughput": 5525.154498768609,
    "total_throughput": 11756.64456813356,
    "itl": 156.1958950376012,
    "ttft": 1910313.3955832433,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.29380682341754405,
    "arrivals": 463915,
    "finished_requests": 90916,
    "scheduler_time": 56.1994055971435
}
#Debug simulation 
Total elapsed time: 6.2545397616922855. Arrivals time: 0.3227169350720942 Scheduler time: 5.833259148988873 Scheduler overhead time: 0.03430614061653614 Adapter cache time: 0.012901402544230223 Engine time: 0.0351899191737175 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-8-16/adapters_96_slots_96_rate_3.2-0.8-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-8-16/adapters_96_slots_96_rate_3.2-0.8-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 270, 34560, 270, 270, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 270, 34560, 8640, 270, 270, 8640, 34560, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 270, 34560, 8640, 8640, 270, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 270, 34560, 8640, 8640, 8640, 34560, 34560, 270, 270, 8640, 270, 34560, 270, 270, 34560, 270, 8640, 8640, 270, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 270, 270, 34560, 8640, 34560, 270, 8640, 34560, 270, 34560, 8640, 270, 34560, 270, 270, 34560, 270, 270, 8640]
Prompts retrieved: 1391040 . Total input tokens: 310246563 . Total output tokens: 278256734
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.217030787840486,
    "estimated_duration": 3600.075980018991,
    "input_throughput": 6231.328484317618,
    "output_throughput": 5524.974225653726,
    "total_throughput": 11756.302709971344,
    "itl": 156.19654789208388,
    "ttft": 1910330.0139941215,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31319492869079113,
    "arrivals": 463915,
    "finished_requests": 90913,
    "scheduler_time": 56.198241790315144
}
#Debug simulation 
Total elapsed time: 6.2171202856116. Arrivals time: 0.26872525457292795 Scheduler time: 5.850451732985675 Scheduler overhead time: 0.03421487286686897 Adapter cache time: 0.012773835565894842 Engine time: 0.03489272156730294 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-8-32/adapters_96_slots_96_rate_3.2-0.8-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-8-32/adapters_96_slots_96_rate_3.2-0.8-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 270, 34560, 270, 270, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 270, 34560, 8640, 270, 270, 8640, 34560, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 270, 34560, 8640, 8640, 270, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 270, 34560, 8640, 8640, 8640, 34560, 34560, 270, 270, 8640, 270, 34560, 270, 270, 34560, 270, 8640, 8640, 270, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 270, 270, 34560, 8640, 34560, 270, 8640, 34560, 270, 34560, 8640, 270, 34560, 270, 270, 34560, 270, 270, 8640]
Prompts retrieved: 1391040 . Total input tokens: 310246563 . Total output tokens: 278256734
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.286025915294886,
    "estimated_duration": 3600.080097282663,
    "input_throughput": 6220.725204670809,
    "output_throughput": 5515.47645147879,
    "total_throughput": 11736.2016561496,
    "itl": 154.5553407524733,
    "ttft": 1911628.3228927222,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31376164913177523,
    "arrivals": 463915,
    "finished_requests": 90738,
    "scheduler_time": 55.78389488577856
}
#Debug simulation 
Total elapsed time: 6.286118541378528. Arrivals time: 0.28061441285535693 Scheduler time: 5.905878027435392 Scheduler overhead time: 0.034828610718250275 Adapter cache time: 0.013073520734906197 Engine time: 0.03544356394559145 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-16-16/adapters_96_slots_96_rate_3.2-0.8-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-16-16/adapters_96_slots_96_rate_3.2-0.8-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 270, 34560, 270, 270, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 270, 34560, 8640, 270, 270, 8640, 34560, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 270, 34560, 8640, 8640, 270, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 270, 34560, 8640, 8640, 8640, 34560, 34560, 270, 270, 8640, 270, 34560, 270, 270, 34560, 270, 8640, 8640, 270, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 270, 270, 34560, 8640, 34560, 270, 8640, 34560, 270, 34560, 8640, 270, 34560, 270, 270, 34560, 270, 270, 8640]
Prompts retrieved: 1391040 . Total input tokens: 310246563 . Total output tokens: 278256734
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 6.329518163111061,
    "estimated_duration": 3600.155396331448,
    "input_throughput": 6231.466014733824,
    "output_throughput": 5525.133170715141,
    "total_throughput": 11756.599185448966,
    "itl": 156.1962759500309,
    "ttft": 1910320.9855523752,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3001198785007001,
    "arrivals": 463915,
    "finished_requests": 90916,
    "scheduler_time": 56.199451699738546
}
#Debug simulation 
Total elapsed time: 6.3296356978826225. Arrivals time: 0.3805539892055094 Scheduler time: 5.850367949809879 Scheduler overhead time: 0.0343702114187181 Adapter cache time: 0.013252522330731153 Engine time: 0.0349300061352551 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-16-32/adapters_96_slots_96_rate_3.2-0.8-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-16-32/adapters_96_slots_96_rate_3.2-0.8-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 270, 34560, 270, 270, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 270, 34560, 8640, 270, 270, 8640, 34560, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 270, 34560, 8640, 8640, 270, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 270, 34560, 8640, 8640, 8640, 34560, 34560, 270, 270, 8640, 270, 34560, 270, 270, 34560, 270, 8640, 8640, 270, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 270, 270, 34560, 8640, 34560, 270, 8640, 34560, 270, 34560, 8640, 270, 34560, 270, 270, 34560, 270, 270, 8640]
Prompts retrieved: 1391040 . Total input tokens: 310246563 . Total output tokens: 278256734
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 6.305046617984772,
    "estimated_duration": 3600.0725312142076,
    "input_throughput": 6220.738278416499,
    "output_throughput": 5515.488043043136,
    "total_throughput": 11736.226321459635,
    "itl": 154.55488488129626,
    "ttft": 1911624.1152035717,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31778577029705035,
    "arrivals": 463915,
    "finished_requests": 90738,
    "scheduler_time": 55.78378133846856
}
#Debug simulation 
Total elapsed time: 6.305141345132142. Arrivals time: 0.2901974208652973 Scheduler time: 5.915158597752452 Scheduler overhead time: 0.034665126353502274 Adapter cache time: 0.013287199195474386 Engine time: 0.03547833487391472 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_16-16-16/adapters_96_slots_96_rate_3.2-0.8-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_16-16-16/adapters_96_slots_96_rate_3.2-0.8-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 270, 34560, 270, 270, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 270, 34560, 8640, 270, 270, 8640, 34560, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 270, 34560, 8640, 8640, 270, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 270, 34560, 8640, 8640, 8640, 34560, 34560, 270, 270, 8640, 270, 34560, 270, 270, 34560, 270, 8640, 8640, 270, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 270, 270, 34560, 8640, 34560, 270, 8640, 34560, 270, 34560, 8640, 270, 34560, 270, 270, 34560, 270, 270, 8640]
Prompts retrieved: 1391040 . Total input tokens: 310246563 . Total output tokens: 278256734
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.347215463872999,
    "estimated_duration": 3600.1115931955196,
    "input_throughput": 6231.535723059908,
    "output_throughput": 5525.054289315676,
    "total_throughput": 11756.590012375586,
    "itl": 156.1957617705916,
    "ttft": 1910311.5606666238,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2870448283106092,
    "arrivals": 463915,
    "finished_requests": 90915,
    "scheduler_time": 56.19914452855191
}
#Debug simulation 
Total elapsed time: 6.347307133954018. Arrivals time: 0.2969303550198674 Scheduler time: 5.951576542109251 Scheduler overhead time: 0.03445082902908325 Adapter cache time: 0.013137993402779102 Engine time: 0.035034578293561935 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_16-16-32/adapters_96_slots_96_rate_3.2-0.8-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_16-16-32/adapters_96_slots_96_rate_3.2-0.8-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 270, 34560, 270, 270, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 270, 34560, 8640, 270, 270, 8640, 34560, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 270, 34560, 8640, 8640, 270, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 270, 34560, 8640, 8640, 8640, 34560, 34560, 270, 270, 8640, 270, 34560, 270, 270, 34560, 270, 8640, 8640, 270, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 270, 270, 34560, 8640, 34560, 270, 8640, 34560, 270, 34560, 8640, 270, 34560, 270, 270, 34560, 270, 270, 8640]
Prompts retrieved: 1391040 . Total input tokens: 310246563 . Total output tokens: 278256734
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.290102581959218,
    "estimated_duration": 3600.0765038389973,
    "input_throughput": 6220.731413934851,
    "output_throughput": 5515.48195679344,
    "total_throughput": 11736.213370728292,
    "itl": 154.55497025111887,
    "ttft": 1911627.1139501245,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3218098914623256,
    "arrivals": 463915,
    "finished_requests": 90738,
    "scheduler_time": 55.78375597499435
}
#Debug simulation 
Total elapsed time: 6.29024667525664. Arrivals time: 0.2933124196715653 Scheduler time: 5.897591191343963 Scheduler overhead time: 0.03459289716556668 Adapter cache time: 0.013137114234268665 Engine time: 0.03524797735735774 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-8-8/adapters_96_slots_96_rate_3.2-0.8-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-8-8/adapters_96_slots_96_rate_3.2-0.8-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 135, 34560, 135, 135, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 135, 34560, 8640, 135, 135, 8640, 34560, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 135, 34560, 8640, 8640, 135, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 135, 34560, 8640, 8640, 8640, 34560, 34560, 135, 135, 8640, 135, 34560, 135, 135, 34560, 135, 8640, 8640, 135, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 135, 135, 34560, 8640, 34560, 135, 8640, 34560, 135, 34560, 8640, 135, 34560, 135, 135, 34560, 135, 135, 8640]
Prompts retrieved: 1386720 . Total input tokens: 309283426 . Total output tokens: 277385822
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.396282215137035,
    "estimated_duration": 3600.138457255395,
    "input_throughput": 6349.42885430764,
    "output_throughput": 5622.5429217052,
    "total_throughput": 11971.97177601284,
    "itl": 153.4358729136869,
    "ttft": 1894834.1630581282,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.29380682341754405,
    "arrivals": 462529,
    "finished_requests": 92472,
    "scheduler_time": 57.148025355063815
}
#Debug simulation 
Total elapsed time: 6.396401340141892. Arrivals time: 0.376680008135736 Scheduler time: 5.922703756019473 Scheduler overhead time: 0.03451808588579297 Adapter cache time: 0.010821488220244646 Engine time: 0.03532134648412466 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-8-16/adapters_96_slots_96_rate_3.2-0.8-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-8-16/adapters_96_slots_96_rate_3.2-0.8-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 135, 34560, 135, 135, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 135, 34560, 8640, 135, 135, 8640, 34560, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 135, 34560, 8640, 8640, 135, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 135, 34560, 8640, 8640, 8640, 34560, 34560, 135, 135, 8640, 135, 34560, 135, 135, 34560, 135, 8640, 8640, 135, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 135, 135, 34560, 8640, 34560, 135, 8640, 34560, 135, 34560, 8640, 135, 34560, 135, 135, 34560, 135, 135, 8640]
Prompts retrieved: 1386720 . Total input tokens: 309283426 . Total output tokens: 277385822
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.367823088075966,
    "estimated_duration": 3600.0676189285728,
    "input_throughput": 6349.0576898671015,
    "output_throughput": 5622.067456061738,
    "total_throughput": 11971.12514592884,
    "itl": 153.43727405031711,
    "ttft": 1894860.6224039372,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31319492869079113,
    "arrivals": 462529,
    "finished_requests": 92467,
    "scheduler_time": 57.14611544221125
}
#Debug simulation 
Total elapsed time: 6.367922586854547. Arrivals time: 0.2955178050324321 Scheduler time: 5.974412157200277 Scheduler overhead time: 0.034740705974400043 Adapter cache time: 0.011193401645869017 Engine time: 0.03559185890480876 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-8-32/adapters_96_slots_96_rate_3.2-0.8-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-8-32/adapters_96_slots_96_rate_3.2-0.8-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 135, 34560, 135, 135, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 135, 34560, 8640, 135, 135, 8640, 34560, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 135, 34560, 8640, 8640, 135, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 135, 34560, 8640, 8640, 8640, 34560, 34560, 135, 135, 8640, 135, 34560, 135, 135, 34560, 135, 8640, 8640, 135, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 135, 135, 34560, 8640, 34560, 135, 8640, 34560, 135, 34560, 8640, 135, 34560, 135, 135, 34560, 135, 135, 8640]
Prompts retrieved: 1386720 . Total input tokens: 309283426 . Total output tokens: 277385822
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.401880485005677,
    "estimated_duration": 3600.1062424963457,
    "input_throughput": 6338.343221831505,
    "output_throughput": 5612.341036354987,
    "total_throughput": 11950.684258186491,
    "itl": 151.94276767676695,
    "ttft": 1895920.8622091028,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31376164913177523,
    "arrivals": 462529,
    "finished_requests": 92295,
    "scheduler_time": 56.7423437954827
}
#Debug simulation 
Total elapsed time: 6.401995327789336. Arrivals time: 0.3841418488882482 Scheduler time: 5.919297617860138 Scheduler overhead time: 0.035193344578146935 Adapter cache time: 0.01111253397539258 Engine time: 0.03575424151495099 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-16-16/adapters_96_slots_96_rate_3.2-0.8-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-16-16/adapters_96_slots_96_rate_3.2-0.8-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 135, 34560, 135, 135, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 135, 34560, 8640, 135, 135, 8640, 34560, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 135, 34560, 8640, 8640, 135, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 135, 34560, 8640, 8640, 8640, 34560, 34560, 135, 135, 8640, 135, 34560, 135, 135, 34560, 135, 8640, 8640, 135, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 135, 135, 34560, 8640, 34560, 135, 8640, 34560, 135, 34560, 8640, 135, 34560, 135, 135, 34560, 135, 135, 8640]
Prompts retrieved: 1386720 . Total input tokens: 309283426 . Total output tokens: 277385822
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 6.377371582668275,
    "estimated_duration": 3600.1444658361866,
    "input_throughput": 6349.41825721727,
    "output_throughput": 5622.533537775272,
    "total_throughput": 11971.951794992541,
    "itl": 153.43584873191054,
    "ttft": 1894838.8254654638,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3001198785007001,
    "arrivals": 462529,
    "finished_requests": 92472,
    "scheduler_time": 57.147916660339455
}
#Debug simulation 
Total elapsed time: 6.377489530015737. Arrivals time: 0.29988606041297317 Scheduler time: 5.979089510627091 Scheduler overhead time: 0.03507811343297362 Adapter cache time: 0.011163265444338322 Engine time: 0.03586960770189762 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-16-32/adapters_96_slots_96_rate_3.2-0.8-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-16-32/adapters_96_slots_96_rate_3.2-0.8-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 135, 34560, 135, 135, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 135, 34560, 8640, 135, 135, 8640, 34560, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 135, 34560, 8640, 8640, 135, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 135, 34560, 8640, 8640, 8640, 34560, 34560, 135, 135, 8640, 135, 34560, 135, 135, 34560, 135, 8640, 8640, 135, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 135, 135, 34560, 8640, 34560, 135, 8640, 34560, 135, 34560, 8640, 135, 34560, 135, 135, 34560, 135, 135, 8640]
Prompts retrieved: 1386720 . Total input tokens: 309283426 . Total output tokens: 277385822
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 6.406440403778106,
    "estimated_duration": 3600.109457367732,
    "input_throughput": 6338.337561737416,
    "output_throughput": 5612.336024575534,
    "total_throughput": 11950.673586312949,
    "itl": 151.9427123720848,
    "ttft": 1895923.2525661162,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3177857702970504,
    "arrivals": 462529,
    "finished_requests": 92295,
    "scheduler_time": 56.74229817870221
}
#Debug simulation 
Total elapsed time: 6.406532575841993. Arrivals time: 0.3714537275955081 Scheduler time: 5.936540047638118 Scheduler overhead time: 0.03517018351703882 Adapter cache time: 0.010859602596610785 Engine time: 0.035951870027929544 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_16-16-16/adapters_96_slots_96_rate_3.2-0.8-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_16-16-16/adapters_96_slots_96_rate_3.2-0.8-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 135, 34560, 135, 135, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 135, 34560, 8640, 135, 135, 8640, 34560, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 135, 34560, 8640, 8640, 135, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 135, 34560, 8640, 8640, 8640, 34560, 34560, 135, 135, 8640, 135, 34560, 135, 135, 34560, 135, 8640, 8640, 135, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 135, 135, 34560, 8640, 34560, 135, 8640, 34560, 135, 34560, 8640, 135, 34560, 135, 135, 34560, 135, 135, 8640]
Prompts retrieved: 1386720 . Total input tokens: 309283426 . Total output tokens: 277385822
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.387833619024605,
    "estimated_duration": 3600.1172782663743,
    "input_throughput": 6349.466207114118,
    "output_throughput": 5622.575998342877,
    "total_throughput": 11972.042205456995,
    "itl": 153.43551518916036,
    "ttft": 1894833.02165602,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2870448283106092,
    "arrivals": 462529,
    "finished_requests": 92472,
    "scheduler_time": 57.14775706316585
}
#Debug simulation 
Total elapsed time: 6.38796296576038. Arrivals time: 0.29835389787331223 Scheduler time: 5.991414722520858 Scheduler overhead time: 0.03482355223968625 Adapter cache time: 0.011389357503503561 Engine time: 0.0356107191182673 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_16-16-32/adapters_96_slots_96_rate_3.2-0.8-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_16-16-32/adapters_96_slots_96_rate_3.2-0.8-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 135, 34560, 135, 135, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 135, 34560, 8640, 135, 135, 8640, 34560, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 135, 34560, 8640, 8640, 135, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 135, 34560, 8640, 8640, 8640, 34560, 34560, 135, 135, 8640, 135, 34560, 135, 135, 34560, 135, 8640, 8640, 135, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 135, 135, 34560, 8640, 34560, 135, 8640, 34560, 135, 34560, 8640, 135, 34560, 135, 135, 34560, 135, 135, 8640]
Prompts retrieved: 1386720 . Total input tokens: 309283426 . Total output tokens: 277385822
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.442834236193448,
    "estimated_duration": 3600.0930460188633,
    "input_throughput": 6338.366455620891,
    "output_throughput": 5612.361608915519,
    "total_throughput": 11950.72806453641,
    "itl": 151.94821273888735,
    "ttft": 1895911.655158955,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.32180989146232564,
    "arrivals": 462529,
    "finished_requests": 92295,
    "scheduler_time": 56.74347947685095
}
#Debug simulation 
Total elapsed time: 6.442932545207441. Arrivals time: 0.38208222575485706 Scheduler time: 5.96151107409969 Scheduler overhead time: 0.03538296464830637 Adapter cache time: 0.011084241792559624 Engine time: 0.03617607522755861 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-8/adapters_96_slots_96_rate_3.2-0.8-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-8/adapters_96_slots_96_rate_3.2-0.8-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 66, 34560, 66, 66, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 66, 34560, 8640, 66, 66, 8640, 34560, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 66, 34560, 8640, 8640, 66, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 66, 34560, 8640, 8640, 8640, 34560, 34560, 66, 66, 8640, 66, 34560, 66, 66, 34560, 66, 8640, 8640, 66, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 66, 66, 34560, 8640, 34560, 66, 8640, 34560, 66, 34560, 8640, 66, 34560, 66, 66, 34560, 66, 66, 8640]
Prompts retrieved: 1384512 . Total input tokens: 308764717 . Total output tokens: 276957540
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.428914671763778,
    "estimated_duration": 3600.160116798912,
    "input_throughput": 6426.924150410608,
    "output_throughput": 5661.894009904266,
    "total_throughput": 12088.818160314873,
    "itl": 151.58510676715335,
    "ttft": 1887588.1916588957,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.29380682341754405,
    "arrivals": 461810,
    "finished_requests": 93291,
    "scheduler_time": 57.48690315163425
}
#Debug simulation 
Total elapsed time: 6.429036860819906. Arrivals time: 0.3465755791403353 Scheduler time: 5.984877680893987 Scheduler overhead time: 0.035130738746374846 Adapter cache time: 0.00962449936196208 Engine time: 0.036114273592829704 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-16/adapters_96_slots_96_rate_3.2-0.8-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-16/adapters_96_slots_96_rate_3.2-0.8-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 66, 34560, 66, 66, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 66, 34560, 8640, 66, 66, 8640, 34560, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 66, 34560, 8640, 8640, 66, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 66, 34560, 8640, 8640, 8640, 34560, 34560, 66, 66, 8640, 66, 34560, 66, 66, 34560, 66, 8640, 8640, 66, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 66, 66, 34560, 8640, 34560, 66, 8640, 34560, 66, 34560, 8640, 66, 34560, 66, 66, 34560, 66, 66, 8640]
Prompts retrieved: 1384512 . Total input tokens: 308764717 . Total output tokens: 276957540
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.427471498027444,
    "estimated_duration": 3600.092575179955,
    "input_throughput": 6426.828898655046,
    "output_throughput": 5661.726073524968,
    "total_throughput": 12088.554972180014,
    "itl": 151.58541348016462,
    "ttft": 1887583.163137247,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3131949286907911,
    "arrivals": 461810,
    "finished_requests": 93287,
    "scheduler_time": 57.48601603658661
}
#Debug simulation 
Total elapsed time: 6.427607047837228. Arrivals time: 0.29955730866640806 Scheduler time: 6.030971316155046 Scheduler overhead time: 0.035024224780499935 Adapter cache time: 0.009529397822916508 Engine time: 0.036042798310518265 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-32/adapters_96_slots_96_rate_3.2-0.8-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-32/adapters_96_slots_96_rate_3.2-0.8-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 66, 34560, 66, 66, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 66, 34560, 8640, 66, 66, 8640, 34560, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 66, 34560, 8640, 8640, 66, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 66, 34560, 8640, 8640, 8640, 34560, 34560, 66, 66, 8640, 66, 34560, 66, 66, 34560, 66, 8640, 8640, 66, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 66, 66, 34560, 8640, 34560, 66, 8640, 34560, 66, 34560, 8640, 66, 34560, 66, 66, 34560, 66, 66, 8640]
Prompts retrieved: 1384512 . Total input tokens: 308764717 . Total output tokens: 276957540
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.466991593129933,
    "estimated_duration": 3600.0601024521993,
    "input_throughput": 6412.605996292954,
    "output_throughput": 5649.33207258032,
    "total_throughput": 12061.938068873273,
    "itl": 149.87775178764198,
    "ttft": 1889073.0706746168,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3137616491317752,
    "arrivals": 461810,
    "finished_requests": 93073,
    "scheduler_time": 57.00869800172939
}
#Debug simulation 
Total elapsed time: 6.467085217125714. Arrivals time: 0.38199492264539003 Scheduler time: 5.986533888615668 Scheduler overhead time: 0.035967984702438116 Adapter cache time: 0.009573605842888355 Engine time: 0.03626853972673416 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-16-16/adapters_96_slots_96_rate_3.2-0.8-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-16-16/adapters_96_slots_96_rate_3.2-0.8-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 66, 34560, 66, 66, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 66, 34560, 8640, 66, 66, 8640, 34560, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 66, 34560, 8640, 8640, 66, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 66, 34560, 8640, 8640, 8640, 34560, 34560, 66, 66, 8640, 66, 34560, 66, 66, 34560, 66, 8640, 8640, 66, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 66, 66, 34560, 8640, 34560, 66, 8640, 34560, 66, 34560, 8640, 66, 34560, 66, 66, 34560, 66, 66, 8640]
Prompts retrieved: 1384512 . Total input tokens: 308764717 . Total output tokens: 276957540
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 6.450112132821232,
    "estimated_duration": 3600.0339945910805,
    "input_throughput": 6426.839589504504,
    "output_throughput": 5661.759591888299,
    "total_throughput": 12088.599181392803,
    "itl": 151.58507922528386,
    "ttft": 1887578.755787662,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.30011987850070015,
    "arrivals": 461810,
    "finished_requests": 93286,
    "scheduler_time": 57.48472487666726
}
#Debug simulation 
Total elapsed time: 6.4502051318995655. Arrivals time: 0.30220043659210205 Scheduler time: 6.0500635132193565 Scheduler overhead time: 0.03510391339659691 Adapter cache time: 0.01011631591245532 Engine time: 0.03612364595755935 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-16-32/adapters_96_slots_96_rate_3.2-0.8-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-16-32/adapters_96_slots_96_rate_3.2-0.8-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 66, 34560, 66, 66, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 66, 34560, 8640, 66, 66, 8640, 34560, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 66, 34560, 8640, 8640, 66, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 66, 34560, 8640, 8640, 8640, 34560, 34560, 66, 66, 8640, 66, 34560, 66, 66, 34560, 66, 8640, 8640, 66, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 66, 66, 34560, 8640, 34560, 66, 8640, 34560, 66, 34560, 8640, 66, 34560, 66, 66, 34560, 66, 66, 8640]
Prompts retrieved: 1384512 . Total input tokens: 308764717 . Total output tokens: 276957540
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 6.451452632434666,
    "estimated_duration": 3600.065423172376,
    "input_throughput": 6412.596518775715,
    "output_throughput": 5649.323723144515,
    "total_throughput": 12061.92024192023,
    "itl": 149.87775852489742,
    "ttft": 1889076.8331563065,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31778577029705035,
    "arrivals": 461810,
    "finished_requests": 93073,
    "scheduler_time": 57.008690965740335
}
#Debug simulation 
Total elapsed time: 6.451575079001486. Arrivals time: 0.35522968601435423 Scheduler time: 5.997628094628453 Scheduler overhead time: 0.03562862379476428 Adapter cache time: 0.009641788899898529 Engine time: 0.03671014355495572 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_16-16-16/adapters_96_slots_96_rate_3.2-0.8-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_16-16-16/adapters_96_slots_96_rate_3.2-0.8-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 66, 34560, 66, 66, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 66, 34560, 8640, 66, 66, 8640, 34560, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 66, 34560, 8640, 8640, 66, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 66, 34560, 8640, 8640, 8640, 34560, 34560, 66, 66, 8640, 66, 34560, 66, 66, 34560, 66, 8640, 8640, 66, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 66, 66, 34560, 8640, 34560, 66, 8640, 34560, 66, 34560, 8640, 66, 34560, 66, 66, 34560, 66, 66, 8640]
Prompts retrieved: 1384512 . Total input tokens: 308764717 . Total output tokens: 276957540
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.464228463359177,
    "estimated_duration": 3600.1469124967634,
    "input_throughput": 6426.893280294933,
    "output_throughput": 5661.744227505417,
    "total_throughput": 12088.637507800351,
    "itl": 151.58456624102,
    "ttft": 1887589.583852316,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2870448283106092,
    "arrivals": 461810,
    "finished_requests": 93290,
    "scheduler_time": 57.48686906639904
}
#Debug simulation 
Total elapsed time: 6.464327113237232. Arrivals time: 0.3466810383833945 Scheduler time: 6.020076063927263 Scheduler overhead time: 0.03550487803295255 Adapter cache time: 0.00963045610114932 Engine time: 0.036019638646394014 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_16-16-32/adapters_96_slots_96_rate_3.2-0.8-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_16-16-32/adapters_96_slots_96_rate_3.2-0.8-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 66, 34560, 66, 66, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 66, 34560, 8640, 66, 66, 8640, 34560, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 66, 34560, 8640, 8640, 66, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 66, 34560, 8640, 8640, 8640, 34560, 34560, 66, 66, 8640, 66, 34560, 66, 66, 34560, 66, 8640, 8640, 66, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 66, 66, 34560, 8640, 34560, 66, 8640, 34560, 66, 34560, 8640, 66, 34560, 66, 66, 34560, 66, 66, 8640]
Prompts retrieved: 1384512 . Total input tokens: 308764717 . Total output tokens: 276957540
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.440408568829298,
    "estimated_duration": 3600.070658130307,
    "input_throughput": 6412.587194049566,
    "output_throughput": 5649.315508313519,
    "total_throughput": 12061.902702363084,
    "itl": 149.877725019946,
    "ttft": 1889080.6734512926,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3218098914623256,
    "arrivals": 461810,
    "finished_requests": 93073,
    "scheduler_time": 57.00862988382251
}
#Debug simulation 
Total elapsed time: 6.440522608812898. Arrivals time: 0.35305807646363974 Scheduler time: 5.988485251087695 Scheduler overhead time: 0.035783128812909126 Adapter cache time: 0.009556818287819624 Engine time: 0.036838109605014324 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-8-8/adapters_96_slots_96_rate_3.2-0.8-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-8-8/adapters_96_slots_96_rate_3.2-0.8-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 33, 34560, 33, 33, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 33, 34560, 8640, 33, 33, 8640, 34560, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 33, 34560, 8640, 8640, 33, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 33, 34560, 8640, 8640, 8640, 34560, 34560, 33, 33, 8640, 33, 34560, 33, 33, 34560, 33, 8640, 8640, 33, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 33, 33, 34560, 8640, 34560, 33, 8640, 34560, 33, 34560, 8640, 33, 34560, 33, 33, 34560, 33, 33, 8640]
Prompts retrieved: 1383456 . Total input tokens: 308511644 . Total output tokens: 276741490
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.467428653035313,
    "estimated_duration": 3600.1101213833795,
    "input_throughput": 6444.168433127059,
    "output_throughput": 5677.723267016498,
    "total_throughput": 12121.891700143557,
    "itl": 151.07055329145336,
    "ttft": 1886862.7667860682,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.29380682341754405,
    "arrivals": 461464,
    "finished_requests": 93509,
    "scheduler_time": 57.694198532718936
}
#Debug simulation 
Total elapsed time: 6.467558143194765. Arrivals time: 0.351199371740222 Scheduler time: 6.0197769165970385 Scheduler overhead time: 0.035342798102647066 Adapter cache time: 0.008366172201931477 Engine time: 0.036291754338890314 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-8-16/adapters_96_slots_96_rate_3.2-0.8-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-8-16/adapters_96_slots_96_rate_3.2-0.8-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 33, 34560, 33, 33, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 33, 34560, 8640, 33, 33, 8640, 34560, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 33, 34560, 8640, 8640, 33, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 33, 34560, 8640, 8640, 8640, 34560, 34560, 33, 33, 8640, 33, 34560, 33, 33, 34560, 33, 8640, 8640, 33, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 33, 33, 34560, 8640, 34560, 33, 8640, 34560, 33, 34560, 8640, 33, 34560, 33, 33, 34560, 33, 33, 8640]
Prompts retrieved: 1383456 . Total input tokens: 308511644 . Total output tokens: 276741490
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.456423070747405,
    "estimated_duration": 3600.134225359444,
    "input_throughput": 6444.12528749083,
    "output_throughput": 5677.685252960031,
    "total_throughput": 12121.81054045086,
    "itl": 151.07053633448598,
    "ttft": 1886875.213967258,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31319492869079113,
    "arrivals": 461464,
    "finished_requests": 93509,
    "scheduler_time": 57.69412041694421
}
#Debug simulation 
Total elapsed time: 6.456516126170754. Arrivals time: 0.3013475574553013 Scheduler time: 6.058053851593286 Scheduler overhead time: 0.03568243654444814 Adapter cache time: 0.008637652732431889 Engine time: 0.03619679622352123 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-8-32/adapters_96_slots_96_rate_3.2-0.8-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-8-32/adapters_96_slots_96_rate_3.2-0.8-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 33, 34560, 33, 33, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 33, 34560, 8640, 33, 33, 8640, 34560, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 33, 34560, 8640, 8640, 33, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 33, 34560, 8640, 8640, 8640, 34560, 34560, 33, 33, 8640, 33, 34560, 33, 33, 34560, 33, 8640, 8640, 33, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 33, 33, 34560, 8640, 34560, 33, 8640, 34560, 33, 34560, 8640, 33, 34560, 33, 33, 34560, 33, 33, 8640]
Prompts retrieved: 1383456 . Total input tokens: 308511644 . Total output tokens: 276741490
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.738932863809168,
    "estimated_duration": 3600.08563976238,
    "input_throughput": 6430.118423940583,
    "output_throughput": 5667.217405791114,
    "total_throughput": 12097.335829731697,
    "itl": 149.35769906223896,
    "ttft": 1888665.889482725,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31376164913177523,
    "arrivals": 461464,
    "finished_requests": 93303,
    "scheduler_time": 57.2098042545046
}
#Debug simulation 
Total elapsed time: 6.739039839245379. Arrivals time: 0.6236851583234966 Scheduler time: 6.017390890978277 Scheduler overhead time: 0.03589021600782871 Adapter cache time: 0.008651491720229387 Engine time: 0.036538027226924896 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-16-16/adapters_96_slots_96_rate_3.2-0.8-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-16-16/adapters_96_slots_96_rate_3.2-0.8-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 33, 34560, 33, 33, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 33, 34560, 8640, 33, 33, 8640, 34560, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 33, 34560, 8640, 8640, 33, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 33, 34560, 8640, 8640, 8640, 34560, 34560, 33, 33, 8640, 33, 34560, 33, 33, 34560, 33, 8640, 8640, 33, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 33, 33, 34560, 8640, 34560, 33, 8640, 34560, 33, 34560, 8640, 33, 34560, 33, 33, 34560, 33, 33, 8640]
Prompts retrieved: 1383456 . Total input tokens: 308511644 . Total output tokens: 276741490
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 6.477928986307234,
    "estimated_duration": 3600.1140642142354,
    "input_throughput": 6444.161375498971,
    "output_throughput": 5677.71704879616,
    "total_throughput": 12121.878424295131,
    "itl": 151.07047456348815,
    "ttft": 1886865.767540942,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.30011987850070015,
    "arrivals": 461464,
    "finished_requests": 93509,
    "scheduler_time": 57.694111724449115
}
#Debug simulation 
Total elapsed time: 6.478049646131694. Arrivals time: 0.29483464919030666 Scheduler time: 6.086440101265907 Scheduler overhead time: 0.03546822117641568 Adapter cache time: 0.008285525254905224 Engine time: 0.036304202396422625 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-16-32/adapters_96_slots_96_rate_3.2-0.8-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-16-32/adapters_96_slots_96_rate_3.2-0.8-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 33, 34560, 33, 33, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 33, 34560, 8640, 33, 33, 8640, 34560, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 33, 34560, 8640, 8640, 33, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 33, 34560, 8640, 8640, 8640, 34560, 34560, 33, 33, 8640, 33, 34560, 33, 33, 34560, 33, 8640, 8640, 33, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 33, 33, 34560, 8640, 34560, 33, 8640, 34560, 33, 34560, 8640, 33, 34560, 33, 33, 34560, 33, 33, 8640]
Prompts retrieved: 1383456 . Total input tokens: 308511644 . Total output tokens: 276741490
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 6.425178052391857,
    "estimated_duration": 3600.065844729185,
    "input_throughput": 6430.153780073815,
    "output_throughput": 5667.248567098021,
    "total_throughput": 12097.402347171836,
    "itl": 149.36225052246147,
    "ttft": 1888649.2826922713,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31778577029705035,
    "arrivals": 461464,
    "finished_requests": 93303,
    "scheduler_time": 57.21050369932732
}
#Debug simulation 
Total elapsed time: 6.425268697086722. Arrivals time: 0.34374334942549467 Scheduler time: 5.984250100329518 Scheduler overhead time: 0.035493481904268265 Adapter cache time: 0.008907848503440619 Engine time: 0.03618931397795677 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_16-16-16/adapters_96_slots_96_rate_3.2-0.8-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_16-16-16/adapters_96_slots_96_rate_3.2-0.8-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 33, 34560, 33, 33, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 33, 34560, 8640, 33, 33, 8640, 34560, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 33, 34560, 8640, 8640, 33, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 33, 34560, 8640, 8640, 8640, 34560, 34560, 33, 33, 8640, 33, 34560, 33, 33, 34560, 33, 8640, 8640, 33, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 33, 33, 34560, 8640, 34560, 33, 8640, 34560, 33, 34560, 8640, 33, 34560, 33, 33, 34560, 33, 33, 8640]
Prompts retrieved: 1383456 . Total input tokens: 308511644 . Total output tokens: 276741490
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.460620602127165,
    "estimated_duration": 3600.0756333044583,
    "input_throughput": 6444.229889332994,
    "output_throughput": 5677.747936989345,
    "total_throughput": 12121.97782632234,
    "itl": 151.07038930746222,
    "ttft": 1886859.5484190437,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2870448283106092,
    "arrivals": 461464,
    "finished_requests": 93508,
    "scheduler_time": 57.69332034704905
}
#Debug simulation 
Total elapsed time: 6.460707033984363. Arrivals time: 0.29877837700769305 Scheduler time: 6.064803788438439 Scheduler overhead time: 0.03561305068433285 Adapter cache time: 0.008444992359727621 Engine time: 0.03636508109048009 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_16-16-32/adapters_96_slots_96_rate_3.2-0.8-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_16-16-32/adapters_96_slots_96_rate_3.2-0.8-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 33, 34560, 33, 33, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 33, 34560, 8640, 33, 33, 8640, 34560, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 33, 34560, 8640, 8640, 33, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 33, 34560, 8640, 8640, 8640, 34560, 34560, 33, 33, 8640, 33, 34560, 33, 33, 34560, 33, 8640, 8640, 33, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 33, 33, 34560, 8640, 34560, 33, 8640, 34560, 33, 34560, 8640, 33, 34560, 33, 33, 34560, 33, 33, 8640]
Prompts retrieved: 1383456 . Total input tokens: 308511644 . Total output tokens: 276741490
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.451208204030991,
    "estimated_duration": 3600.070672373063,
    "input_throughput": 6430.145157328498,
    "output_throughput": 5667.240967397809,
    "total_throughput": 12097.386124726307,
    "itl": 149.3622811582518,
    "ttft": 1888653.191342629,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.32180989146232564,
    "arrivals": 461464,
    "finished_requests": 93303,
    "scheduler_time": 57.210538961174386
}
#Debug simulation 
Total elapsed time: 6.451349825132638. Arrivals time: 0.29741270653903484 Scheduler time: 6.056608401238918 Scheduler overhead time: 0.03572333883494139 Adapter cache time: 0.008487887680530548 Engine time: 0.03634193213656545 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-8-8/adapters_96_slots_96_rate_3.2-0.4-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-8-8/adapters_96_slots_96_rate_3.2-0.4-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 3.2]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 4320, 34560, 4320, 1080, 34560, 1080, 1080, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 1080, 34560, 4320, 1080, 1080, 4320, 34560, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 34560, 4320, 4320, 1080, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 1080, 34560, 4320, 4320, 4320, 34560, 34560, 1080, 1080, 4320, 1080, 34560, 1080, 1080, 34560, 1080, 4320, 4320, 1080, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 1080, 1080, 34560, 4320, 34560, 1080, 4320, 34560, 1080, 34560, 4320, 1080, 34560, 1080, 1080, 34560, 1080, 1080, 4320]
Prompts retrieved: 1278720 . Total input tokens: 285237011 . Total output tokens: 255753449
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 5.959575883112848,
    "estimated_duration": 3600.1580496100205,
    "input_throughput": 5896.073091096472,
    "output_throughput": 5188.403881886066,
    "total_throughput": 11084.476972982538,
    "itl": 165.26856473137198,
    "ttft": 1920552.95491288,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.29380682341754405,
    "arrivals": 426676,
    "finished_requests": 85479,
    "scheduler_time": 52.770335312633925
}
#Debug simulation 
Total elapsed time: 5.959672877099365. Arrivals time: 0.2810397604480386 Scheduler time: 5.575078667607158 Scheduler overhead time: 0.03268959233537316 Adapter cache time: 0.022372636944055557 Engine time: 0.03327821707352996 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-8-16/adapters_96_slots_96_rate_3.2-0.4-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-8-16/adapters_96_slots_96_rate_3.2-0.4-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 3.2]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 4320, 34560, 4320, 1080, 34560, 1080, 1080, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 1080, 34560, 4320, 1080, 1080, 4320, 34560, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 34560, 4320, 4320, 1080, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 1080, 34560, 4320, 4320, 4320, 34560, 34560, 1080, 1080, 4320, 1080, 34560, 1080, 1080, 34560, 1080, 4320, 4320, 1080, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 1080, 1080, 34560, 4320, 34560, 1080, 4320, 34560, 1080, 34560, 4320, 1080, 34560, 1080, 1080, 34560, 1080, 1080, 4320]
Prompts retrieved: 1278720 . Total input tokens: 285237011 . Total output tokens: 255753449
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.975108685903251,
    "estimated_duration": 3600.101872542943,
    "input_throughput": 5895.873714542175,
    "output_throughput": 5188.37345755615,
    "total_throughput": 11084.247172098325,
    "itl": 165.2701360417005,
    "ttft": 1920556.0713120205,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31319492869079113,
    "arrivals": 426676,
    "finished_requests": 85477,
    "scheduler_time": 52.76935845667899
}
#Debug simulation 
Total elapsed time: 5.975210733246058. Arrivals time: 0.3237283267080784 Scheduler time: 5.547762971837074 Scheduler overhead time: 0.032795918174088 Adapter cache time: 0.022073976695537567 Engine time: 0.033582888543605804 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-8-32/adapters_96_slots_96_rate_3.2-0.4-0.1_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-8-32/adapters_96_slots_96_rate_3.2-0.4-0.1_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 3.2]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 4320, 34560, 4320, 1080, 34560, 1080, 1080, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 1080, 34560, 4320, 1080, 1080, 4320, 34560, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 34560, 4320, 4320, 1080, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 1080, 34560, 4320, 4320, 4320, 34560, 34560, 1080, 1080, 4320, 1080, 34560, 1080, 1080, 34560, 1080, 4320, 4320, 1080, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 1080, 1080, 34560, 4320, 34560, 1080, 4320, 34560, 1080, 34560, 4320, 1080, 34560, 1080, 1080, 34560, 1080, 1080, 4320]
Prompts retrieved: 1278720 . Total input tokens: 285237011 . Total output tokens: 255753449
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.984432355035096,
    "estimated_duration": 3600.0613336293027,
    "input_throughput": 5888.799671817747,
    "output_throughput": 5181.828383238564,
    "total_throughput": 11070.628055056311,
    "itl": 163.07623124482055,
    "ttft": 1921579.6269138446,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31376164913177523,
    "arrivals": 426676,
    "finished_requests": 85364,
    "scheduler_time": 52.355531966354306
}
#Debug simulation 
Total elapsed time: 5.9845692329108715. Arrivals time: 0.3416322856210172 Scheduler time: 5.538174528162926 Scheduler overhead time: 0.03305472666397691 Adapter cache time: 0.022621490992605686 Engine time: 0.03361643152311444 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-16-16/adapters_96_slots_96_rate_3.2-0.4-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-16-16/adapters_96_slots_96_rate_3.2-0.4-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 3.2]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 4320, 34560, 4320, 1080, 34560, 1080, 1080, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 1080, 34560, 4320, 1080, 1080, 4320, 34560, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 34560, 4320, 4320, 1080, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 1080, 34560, 4320, 4320, 4320, 34560, 34560, 1080, 1080, 4320, 1080, 34560, 1080, 1080, 34560, 1080, 4320, 4320, 1080, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 1080, 1080, 34560, 4320, 34560, 1080, 4320, 34560, 1080, 34560, 4320, 1080, 34560, 1080, 1080, 34560, 1080, 1080, 4320]
Prompts retrieved: 1278720 . Total input tokens: 285237011 . Total output tokens: 255753449
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 5.984854868147522,
    "estimated_duration": 3600.0461386519073,
    "input_throughput": 5895.9063807855055,
    "output_throughput": 5188.371004321185,
    "total_throughput": 11084.27738510669,
    "itl": 165.26929864237601,
    "ttft": 1920557.4802998754,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.30011987850070015,
    "arrivals": 426676,
    "finished_requests": 85476,
    "scheduler_time": 52.76890469486539
}
#Debug simulation 
Total elapsed time: 5.9849508800543845. Arrivals time: 0.3181602521799505 Scheduler time: 5.562758718151599 Scheduler overhead time: 0.03275969484820962 Adapter cache time: 0.02240053564310074 Engine time: 0.033528140746057034 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-16-32/adapters_96_slots_96_rate_3.2-0.4-0.1_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-16-32/adapters_96_slots_96_rate_3.2-0.4-0.1_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 3.2]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 4320, 34560, 4320, 1080, 34560, 1080, 1080, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 1080, 34560, 4320, 1080, 1080, 4320, 34560, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 34560, 4320, 4320, 1080, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 1080, 34560, 4320, 4320, 4320, 34560, 34560, 1080, 1080, 4320, 1080, 34560, 1080, 1080, 34560, 1080, 4320, 4320, 1080, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 1080, 1080, 34560, 4320, 34560, 1080, 4320, 34560, 1080, 34560, 4320, 1080, 34560, 1080, 1080, 34560, 1080, 1080, 4320]
Prompts retrieved: 1278720 . Total input tokens: 285237011 . Total output tokens: 255753449
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 5.947476843371987,
    "estimated_duration": 3600.067629079617,
    "input_throughput": 5888.7893740540485,
    "output_throughput": 5181.819321757925,
    "total_throughput": 11070.608695811974,
    "itl": 163.0761996992651,
    "ttft": 1921584.3430659343,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31778577029705046,
    "arrivals": 426676,
    "finished_requests": 85364,
    "scheduler_time": 52.35552131286364
}
#Debug simulation 
Total elapsed time: 5.9475725260563195. Arrivals time: 0.3335467600263655 Scheduler time: 5.509566676337272 Scheduler overhead time: 0.032867899630218744 Adapter cache time: 0.022411628626286983 Engine time: 0.033722651191055775 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_16-16-16/adapters_96_slots_96_rate_3.2-0.4-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_16-16-16/adapters_96_slots_96_rate_3.2-0.4-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 3.2]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 4320, 34560, 4320, 1080, 34560, 1080, 1080, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 1080, 34560, 4320, 1080, 1080, 4320, 34560, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 34560, 4320, 4320, 1080, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 1080, 34560, 4320, 4320, 4320, 34560, 34560, 1080, 1080, 4320, 1080, 34560, 1080, 1080, 34560, 1080, 4320, 4320, 1080, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 1080, 1080, 34560, 4320, 34560, 1080, 4320, 34560, 1080, 34560, 4320, 1080, 34560, 1080, 1080, 34560, 1080, 1080, 4320]
Prompts retrieved: 1278720 . Total input tokens: 285237011 . Total output tokens: 255753449
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 5.993201641831547,
    "estimated_duration": 3600.11106811712,
    "input_throughput": 5896.088647926528,
    "output_throughput": 5188.360760705381,
    "total_throughput": 11084.449408631908,
    "itl": 165.26768979347992,
    "ttft": 1920560.7427007703,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2870448283106092,
    "arrivals": 426676,
    "finished_requests": 85478,
    "scheduler_time": 52.76927595941471
}
#Debug simulation 
Total elapsed time: 5.993315455969423. Arrivals time: 0.33239617152139544 Scheduler time: 5.557402644306421 Scheduler overhead time: 0.03278516326099634 Adapter cache time: 0.021933645475655794 Engine time: 0.03342770226299763 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_16-16-32/adapters_96_slots_96_rate_3.2-0.4-0.1_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_16-16-32/adapters_96_slots_96_rate_3.2-0.4-0.1_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 3.2]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 4320, 34560, 4320, 1080, 34560, 1080, 1080, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 1080, 34560, 4320, 1080, 1080, 4320, 34560, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 34560, 4320, 4320, 1080, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 1080, 34560, 4320, 4320, 4320, 34560, 34560, 1080, 1080, 4320, 1080, 34560, 1080, 1080, 34560, 1080, 4320, 4320, 1080, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 1080, 1080, 34560, 4320, 34560, 1080, 4320, 34560, 1080, 34560, 4320, 1080, 34560, 1080, 1080, 34560, 1080, 1080, 4320]
Prompts retrieved: 1278720 . Total input tokens: 285237011 . Total output tokens: 255753449
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.998086730949581,
    "estimated_duration": 3600.070798440115,
    "input_throughput": 5888.784189795885,
    "output_throughput": 5181.814759888342,
    "total_throughput": 11070.598949684229,
    "itl": 163.07616269966405,
    "ttft": 1921586.7766156634,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3218098914623257,
    "arrivals": 426676,
    "finished_requests": 85364,
    "scheduler_time": 52.355491371907455
}
#Debug simulation 
Total elapsed time: 5.998177127912641. Arrivals time: 0.320287995506078 Scheduler time: 5.573229257483035 Scheduler overhead time: 0.032984198071062565 Adapter cache time: 0.02258374961093068 Engine time: 0.0336999436840415 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-8-8/adapters_96_slots_96_rate_3.2-0.4-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-8-8/adapters_96_slots_96_rate_3.2-0.4-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 4320, 34560, 4320, 540, 34560, 540, 540, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 540, 34560, 4320, 540, 540, 4320, 34560, 540, 4320, 540, 540, 4320, 4320, 4320, 540, 540, 34560, 4320, 4320, 540, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 540, 34560, 4320, 4320, 4320, 34560, 34560, 540, 540, 4320, 540, 34560, 540, 540, 34560, 540, 4320, 4320, 540, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 540, 540, 34560, 4320, 34560, 540, 4320, 34560, 540, 34560, 4320, 540, 34560, 540, 540, 34560, 540, 540, 4320]
Prompts retrieved: 1261440 . Total input tokens: 281402058 . Total output tokens: 252328489
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.189700141083449,
    "estimated_duration": 3600.0062137159384,
    "input_throughput": 6147.341889489923,
    "output_throughput": 5411.305659912159,
    "total_throughput": 11558.647549402081,
    "itl": 158.59180133394565,
    "ttft": 1892077.93735761,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.29380682341754405,
    "arrivals": 420888,
    "finished_requests": 89139,
    "scheduler_time": 55.051792164887914
}
#Debug simulation 
Total elapsed time: 6.189794474281371. Arrivals time: 0.2892872607335448 Scheduler time: 5.796266057062894 Scheduler overhead time: 0.03393183648586273 Adapter cache time: 0.019731823354959488 Engine time: 0.03470444306731224 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-8-16/adapters_96_slots_96_rate_3.2-0.4-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-8-16/adapters_96_slots_96_rate_3.2-0.4-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 4320, 34560, 4320, 540, 34560, 540, 540, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 540, 34560, 4320, 540, 540, 4320, 34560, 540, 4320, 540, 540, 4320, 4320, 4320, 540, 540, 34560, 4320, 4320, 540, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 540, 34560, 4320, 4320, 4320, 34560, 34560, 540, 540, 4320, 540, 34560, 540, 540, 34560, 540, 4320, 4320, 540, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 540, 540, 34560, 4320, 34560, 540, 4320, 34560, 540, 34560, 4320, 540, 34560, 540, 540, 34560, 540, 540, 4320]
Prompts retrieved: 1261440 . Total input tokens: 281402058 . Total output tokens: 252328489
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.207936943974346,
    "estimated_duration": 3600.098512081632,
    "input_throughput": 6147.184563347913,
    "output_throughput": 5411.283312004621,
    "total_throughput": 11558.467875352533,
    "itl": 158.59381682619994,
    "ttft": 1892111.3168405686,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31319492869079113,
    "arrivals": 420888,
    "finished_requests": 89140,
    "scheduler_time": 55.05255910364362
}
#Debug simulation 
Total elapsed time: 6.208053714130074. Arrivals time: 0.2868498438037932 Scheduler time: 5.816826791502535 Scheduler overhead time: 0.033931081648916006 Adapter cache time: 0.01967239286750555 Engine time: 0.03483725478872657 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-8-32/adapters_96_slots_96_rate_3.2-0.4-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-8-32/adapters_96_slots_96_rate_3.2-0.4-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 4320, 34560, 4320, 540, 34560, 540, 540, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 540, 34560, 4320, 540, 540, 4320, 34560, 540, 4320, 540, 540, 4320, 4320, 4320, 540, 540, 34560, 4320, 4320, 540, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 540, 34560, 4320, 4320, 4320, 34560, 34560, 540, 540, 4320, 540, 34560, 540, 540, 34560, 540, 4320, 4320, 540, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 540, 540, 34560, 4320, 34560, 540, 4320, 34560, 540, 34560, 4320, 540, 34560, 540, 540, 34560, 540, 540, 4320]
Prompts retrieved: 1261440 . Total input tokens: 281402058 . Total output tokens: 252328489
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.179570883046836,
    "estimated_duration": 3600.1019513082692,
    "input_throughput": 6139.32224668474,
    "output_throughput": 5405.52636097656,
    "total_throughput": 11544.848607661299,
    "itl": 156.7888106099591,
    "ttft": 1892893.6300901007,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3137616491317752,
    "arrivals": 420888,
    "finished_requests": 89026,
    "scheduler_time": 54.66511649303156
}
#Debug simulation 
Total elapsed time: 6.1796617060899734. Arrivals time: 0.33594096126034856 Scheduler time: 5.7386971595697105 Scheduler overhead time: 0.03402127930894494 Adapter cache time: 0.019843843765556812 Engine time: 0.035215385258197784 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-16-16/adapters_96_slots_96_rate_3.2-0.4-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-16-16/adapters_96_slots_96_rate_3.2-0.4-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 4320, 34560, 4320, 540, 34560, 540, 540, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 540, 34560, 4320, 540, 540, 4320, 34560, 540, 4320, 540, 540, 4320, 4320, 4320, 540, 540, 34560, 4320, 4320, 540, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 540, 34560, 4320, 4320, 4320, 34560, 34560, 540, 540, 4320, 540, 34560, 540, 540, 34560, 540, 4320, 4320, 540, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 540, 540, 34560, 4320, 34560, 540, 4320, 34560, 540, 34560, 4320, 540, 34560, 540, 540, 34560, 540, 540, 4320]
Prompts retrieved: 1261440 . Total input tokens: 281402058 . Total output tokens: 252328489
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 6.160538281314075,
    "estimated_duration": 3600.049122529087,
    "input_throughput": 6147.268619616229,
    "output_throughput": 5411.24116281905,
    "total_throughput": 11558.50978243528,
    "itl": 158.5928421173462,
    "ttft": 1892106.8131612455,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.30011987850070015,
    "arrivals": 420888,
    "finished_requests": 89139,
    "scheduler_time": 55.05216867733183
}
#Debug simulation 
Total elapsed time: 6.160658534150571. Arrivals time: 0.2835326143540442 Scheduler time: 5.7725975308567286 Scheduler overhead time: 0.033820196986198425 Adapter cache time: 0.019975722301751375 Engine time: 0.03480460308492184 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-16-32/adapters_96_slots_96_rate_3.2-0.4-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-16-32/adapters_96_slots_96_rate_3.2-0.4-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 4320, 34560, 4320, 540, 34560, 540, 540, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 540, 34560, 4320, 540, 540, 4320, 34560, 540, 4320, 540, 540, 4320, 4320, 4320, 540, 540, 34560, 4320, 4320, 540, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 540, 34560, 4320, 4320, 4320, 34560, 34560, 540, 540, 4320, 540, 34560, 540, 540, 34560, 540, 4320, 4320, 540, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 540, 540, 34560, 4320, 34560, 540, 4320, 34560, 540, 34560, 4320, 540, 34560, 540, 540, 34560, 540, 540, 4320]
Prompts retrieved: 1261440 . Total input tokens: 281402058 . Total output tokens: 252328489
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 6.206456932704896,
    "estimated_duration": 3600.1068892670946,
    "input_throughput": 6139.313825901301,
    "output_throughput": 5405.518946678201,
    "total_throughput": 11544.832772579502,
    "itl": 156.78886896902205,
    "ttft": 1892897.3840397198,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31778577029705035,
    "arrivals": 420888,
    "finished_requests": 89026,
    "scheduler_time": 54.66508349651378
}
#Debug simulation 
Total elapsed time: 6.206575371790677. Arrivals time: 0.29078866774216294 Scheduler time: 5.81007002806291 Scheduler overhead time: 0.03435259219259024 Adapter cache time: 0.019974586088210344 Engine time: 0.03530048159882426 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_16-16-16/adapters_96_slots_96_rate_3.2-0.4-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_16-16-16/adapters_96_slots_96_rate_3.2-0.4-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 4320, 34560, 4320, 540, 34560, 540, 540, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 540, 34560, 4320, 540, 540, 4320, 34560, 540, 4320, 540, 540, 4320, 4320, 4320, 540, 540, 34560, 4320, 4320, 540, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 540, 34560, 4320, 4320, 4320, 34560, 34560, 540, 540, 4320, 540, 34560, 540, 540, 34560, 540, 4320, 4320, 540, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 540, 540, 34560, 4320, 34560, 540, 4320, 34560, 540, 34560, 4320, 540, 34560, 540, 540, 34560, 540, 540, 4320]
Prompts retrieved: 1261440 . Total input tokens: 281402058 . Total output tokens: 252328489
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.175317962188274,
    "estimated_duration": 3600.115371964556,
    "input_throughput": 6147.155775156052,
    "output_throughput": 5411.2579701492405,
    "total_throughput": 11558.413745305294,
    "itl": 158.590718276251,
    "ttft": 1892108.1449526874,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2870448283106092,
    "arrivals": 420888,
    "finished_requests": 89140,
    "scheduler_time": 55.0537480105627
}
#Debug simulation 
Total elapsed time: 6.175407323986292. Arrivals time: 0.3288440369069576 Scheduler time: 5.742383133154362 Scheduler overhead time: 0.033884511794894934 Adapter cache time: 0.01972951367497444 Engine time: 0.03470662049949169 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_16-16-32/adapters_96_slots_96_rate_3.2-0.4-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_16-16-32/adapters_96_slots_96_rate_3.2-0.4-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 4320, 34560, 4320, 540, 34560, 540, 540, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 540, 34560, 4320, 540, 540, 4320, 34560, 540, 4320, 540, 540, 4320, 4320, 4320, 540, 540, 34560, 4320, 4320, 540, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 540, 34560, 4320, 4320, 4320, 34560, 34560, 540, 540, 4320, 540, 34560, 540, 540, 34560, 540, 4320, 4320, 540, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 540, 540, 34560, 4320, 34560, 540, 4320, 34560, 540, 34560, 4320, 540, 34560, 540, 540, 34560, 540, 540, 4320]
Prompts retrieved: 1261440 . Total input tokens: 281402058 . Total output tokens: 252328489
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.1862485078163445,
    "estimated_duration": 3600.110976530873,
    "input_throughput": 6139.306855839771,
    "output_throughput": 5405.512809705775,
    "total_throughput": 11544.819665545545,
    "itl": 156.78894918587804,
    "ttft": 1892900.491907599,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3218098914623256,
    "arrivals": 420888,
    "finished_requests": 89026,
    "scheduler_time": 54.66505640038419
}
#Debug simulation 
Total elapsed time: 6.186342326924205. Arrivals time: 0.28555303206667304 Scheduler time: 5.795696648303419 Scheduler overhead time: 0.03419066080823541 Adapter cache time: 0.01956365117803216 Engine time: 0.03523959778249264 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-8-8/adapters_96_slots_96_rate_3.2-0.4-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-8-8/adapters_96_slots_96_rate_3.2-0.4-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 4320, 34560, 4320, 270, 34560, 270, 270, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 270, 34560, 4320, 270, 270, 4320, 34560, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 270, 34560, 4320, 4320, 270, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 270, 34560, 4320, 4320, 4320, 34560, 34560, 270, 270, 4320, 270, 34560, 270, 270, 34560, 270, 4320, 4320, 270, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 270, 270, 34560, 4320, 34560, 270, 4320, 34560, 270, 34560, 4320, 270, 34560, 270, 270, 34560, 270, 270, 4320]
Prompts retrieved: 1252800 . Total input tokens: 279478636 . Total output tokens: 250588953
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.33711816277355,
    "estimated_duration": 3600.0252058954293,
    "input_throughput": 6280.129917695003,
    "output_throughput": 5546.062835144481,
    "total_throughput": 11826.192752839484,
    "itl": 154.98484407947095,
    "ttft": 1872826.1961671228,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.29380682341754405,
    "arrivals": 418034,
    "finished_requests": 91208,
    "scheduler_time": 56.52047206136659
}
#Debug simulation 
Total elapsed time: 6.337241922039539. Arrivals time: 0.34549119882285595 Scheduler time: 5.889493614435196 Scheduler overhead time: 0.03446252131834626 Adapter cache time: 0.016295677050948143 Engine time: 0.03526286734268069 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-8-16/adapters_96_slots_96_rate_3.2-0.4-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-8-16/adapters_96_slots_96_rate_3.2-0.4-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 4320, 34560, 4320, 270, 34560, 270, 270, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 270, 34560, 4320, 270, 270, 4320, 34560, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 270, 34560, 4320, 4320, 270, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 270, 34560, 4320, 4320, 4320, 34560, 34560, 270, 270, 4320, 270, 34560, 270, 270, 34560, 270, 4320, 4320, 270, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 270, 270, 34560, 4320, 34560, 270, 4320, 34560, 270, 34560, 4320, 270, 34560, 270, 270, 34560, 270, 270, 4320]
Prompts retrieved: 1252800 . Total input tokens: 279478636 . Total output tokens: 250588953
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.311423724051565,
    "estimated_duration": 3600.04990870254,
    "input_throughput": 6280.086824726316,
    "output_throughput": 5546.024779194171,
    "total_throughput": 11826.111603920488,
    "itl": 154.98519061782326,
    "ttft": 1872839.2154598278,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31319492869079113,
    "arrivals": 418034,
    "finished_requests": 91208,
    "scheduler_time": 56.520498885075796
}
#Debug simulation 
Total elapsed time: 6.31151529494673. Arrivals time: 0.28995161782950163 Scheduler time: 5.919273218140006 Scheduler overhead time: 0.03440067218616605 Adapter cache time: 0.016556850168853998 Engine time: 0.03518712520599365 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-8-32/adapters_96_slots_96_rate_3.2-0.4-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-8-32/adapters_96_slots_96_rate_3.2-0.4-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 4320, 34560, 4320, 270, 34560, 270, 270, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 270, 34560, 4320, 270, 270, 4320, 34560, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 270, 34560, 4320, 4320, 270, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 270, 34560, 4320, 4320, 4320, 34560, 34560, 270, 270, 4320, 270, 34560, 270, 270, 34560, 270, 4320, 4320, 270, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 270, 270, 34560, 4320, 34560, 270, 4320, 34560, 270, 34560, 4320, 270, 34560, 270, 270, 34560, 270, 270, 4320]
Prompts retrieved: 1252800 . Total input tokens: 279478636 . Total output tokens: 250588953
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.3131244159303606,
    "estimated_duration": 3600.1211262866773,
    "input_throughput": 6268.971295218256,
    "output_throughput": 5538.685033235792,
    "total_throughput": 11807.656328454048,
    "itl": 152.99491169650133,
    "ttft": 1873768.1501833021,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31376164913177523,
    "arrivals": 418034,
    "finished_requests": 91051,
    "scheduler_time": 56.0409051309164
}
#Debug simulation 
Total elapsed time: 6.313217654824257. Arrivals time: 0.29321264708414674 Scheduler time: 5.916117256041616 Scheduler overhead time: 0.03500726260244846 Adapter cache time: 0.016802900936454535 Engine time: 0.035670187789946795 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-16-16/adapters_96_slots_96_rate_3.2-0.4-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-16-16/adapters_96_slots_96_rate_3.2-0.4-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 4320, 34560, 4320, 270, 34560, 270, 270, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 270, 34560, 4320, 270, 270, 4320, 34560, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 270, 34560, 4320, 4320, 270, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 270, 34560, 4320, 4320, 4320, 34560, 34560, 270, 270, 4320, 270, 34560, 270, 270, 34560, 270, 4320, 4320, 270, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 270, 270, 34560, 4320, 34560, 270, 4320, 34560, 270, 34560, 4320, 270, 34560, 270, 270, 34560, 270, 270, 4320]
Prompts retrieved: 1252800 . Total input tokens: 279478636 . Total output tokens: 250588953
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 6.343744462355971,
    "estimated_duration": 3600.033997413956,
    "input_throughput": 6280.114581206914,
    "output_throughput": 5546.049291296229,
    "total_throughput": 11826.163872503143,
    "itl": 154.98516339174498,
    "ttft": 1872830.3442928747,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3001198785007001,
    "arrivals": 418034,
    "finished_requests": 91208,
    "scheduler_time": 56.52050549101532
}
#Debug simulation 
Total elapsed time: 6.343886013142765. Arrivals time: 0.34737549675628543 Scheduler time: 5.8941406779922545 Scheduler overhead time: 0.03441139776259661 Adapter cache time: 0.016385641414672136 Engine time: 0.03528773644939065 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-16-32/adapters_96_slots_96_rate_3.2-0.4-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-16-32/adapters_96_slots_96_rate_3.2-0.4-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 4320, 34560, 4320, 270, 34560, 270, 270, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 270, 34560, 4320, 270, 270, 4320, 34560, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 270, 34560, 4320, 4320, 270, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 270, 34560, 4320, 4320, 4320, 34560, 34560, 270, 270, 4320, 270, 34560, 270, 270, 34560, 270, 4320, 4320, 270, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 270, 270, 34560, 4320, 34560, 270, 4320, 34560, 270, 34560, 4320, 270, 34560, 270, 270, 34560, 270, 270, 4320]
Prompts retrieved: 1252800 . Total input tokens: 279478636 . Total output tokens: 250588953
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 6.291302539873868,
    "estimated_duration": 3600.124728080354,
    "input_throughput": 6268.9650233407865,
    "output_throughput": 5538.67949198313,
    "total_throughput": 11807.644515323916,
    "itl": 152.99453012378314,
    "ttft": 1873771.0838029028,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3177857702970505,
    "arrivals": 418034,
    "finished_requests": 91051,
    "scheduler_time": 56.04049345015156
}
#Debug simulation 
Total elapsed time: 6.29140661098063. Arrivals time: 0.28742282930761576 Scheduler time: 5.900000331457704 Scheduler overhead time: 0.0349913127720356 Adapter cache time: 0.01703668851405382 Engine time: 0.035565413534641266 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_16-16-16/adapters_96_slots_96_rate_3.2-0.4-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_16-16-16/adapters_96_slots_96_rate_3.2-0.4-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 4320, 34560, 4320, 270, 34560, 270, 270, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 270, 34560, 4320, 270, 270, 4320, 34560, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 270, 34560, 4320, 4320, 270, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 270, 34560, 4320, 4320, 4320, 34560, 34560, 270, 270, 4320, 270, 34560, 270, 270, 34560, 270, 4320, 4320, 270, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 270, 270, 34560, 4320, 34560, 270, 4320, 34560, 270, 34560, 4320, 270, 34560, 270, 270, 34560, 270, 270, 4320]
Prompts retrieved: 1252800 . Total input tokens: 279478636 . Total output tokens: 250588953
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.310381796211004,
    "estimated_duration": 3600.0158270753573,
    "input_throughput": 6280.146278792108,
    "output_throughput": 5546.077283838025,
    "total_throughput": 11826.223562630134,
    "itl": 154.98478359264402,
    "ttft": 1872819.4582401416,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2870448283106092,
    "arrivals": 418034,
    "finished_requests": 91208,
    "scheduler_time": 56.520513557261694
}
#Debug simulation 
Total elapsed time: 6.310477687977254. Arrivals time: 0.28846342768520117 Scheduler time: 5.919501042924821 Scheduler overhead time: 0.03454981418326497 Adapter cache time: 0.01631753146648407 Engine time: 0.03545654797926545 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_16-16-32/adapters_96_slots_96_rate_3.2-0.4-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_16-16-32/adapters_96_slots_96_rate_3.2-0.4-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 4320, 34560, 4320, 270, 34560, 270, 270, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 270, 34560, 4320, 270, 270, 4320, 34560, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 270, 34560, 4320, 4320, 270, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 270, 34560, 4320, 4320, 4320, 34560, 34560, 270, 270, 4320, 270, 34560, 270, 270, 34560, 270, 4320, 4320, 270, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 270, 270, 34560, 4320, 34560, 270, 4320, 34560, 270, 34560, 4320, 270, 34560, 270, 270, 34560, 270, 270, 4320]
Prompts retrieved: 1252800 . Total input tokens: 279478636 . Total output tokens: 250588953
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.3277901210822165,
    "estimated_duration": 3600.1286114794098,
    "input_throughput": 6268.958261112133,
    "output_throughput": 5538.673517501374,
    "total_throughput": 11807.631778613508,
    "itl": 152.99444527529903,
    "ttft": 1873774.0367045898,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3218098914623256,
    "arrivals": 418034,
    "finished_requests": 91051,
    "scheduler_time": 56.040459370728676
}
#Debug simulation 
Total elapsed time: 6.3279125932604074. Arrivals time: 0.336988243740052 Scheduler time: 5.886789215728641 Scheduler overhead time: 0.03486555302515626 Adapter cache time: 0.01697274949401617 Engine time: 0.035853609442710876 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-8-8/adapters_96_slots_96_rate_3.2-0.4-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-8-8/adapters_96_slots_96_rate_3.2-0.4-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 4320, 34560, 4320, 135, 34560, 135, 135, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 135, 34560, 4320, 135, 135, 4320, 34560, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 135, 34560, 4320, 4320, 135, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 135, 34560, 4320, 4320, 4320, 34560, 34560, 135, 135, 4320, 135, 34560, 135, 135, 34560, 135, 4320, 4320, 135, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 135, 135, 34560, 4320, 34560, 135, 4320, 34560, 135, 34560, 4320, 135, 34560, 135, 135, 34560, 135, 135, 4320]
Prompts retrieved: 1248480 . Total input tokens: 278514064 . Total output tokens: 249725487
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.446038506925106,
    "estimated_duration": 3600.0415620531594,
    "input_throughput": 6365.44428862947,
    "output_throughput": 5635.573826105849,
    "total_throughput": 12001.01811473532,
    "itl": 152.9105982064376,
    "ttft": 1862877.2188388212,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.29380682341754405,
    "arrivals": 416602,
    "finished_requests": 92559,
    "scheduler_time": 57.39484147600005
}
#Debug simulation 
Total elapsed time: 6.446145671885461. Arrivals time: 0.29980144184082747 Scheduler time: 6.043848511762917 Scheduler overhead time: 0.035029629711061716 Adapter cache time: 0.014863698277622461 Engine time: 0.036219298373907804 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-8-16/adapters_96_slots_96_rate_3.2-0.4-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-8-16/adapters_96_slots_96_rate_3.2-0.4-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 4320, 34560, 4320, 135, 34560, 135, 135, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 135, 34560, 4320, 135, 135, 4320, 34560, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 135, 34560, 4320, 4320, 135, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 135, 34560, 4320, 4320, 4320, 34560, 34560, 135, 135, 4320, 135, 34560, 135, 135, 34560, 135, 4320, 4320, 135, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 135, 135, 34560, 4320, 34560, 135, 4320, 34560, 135, 34560, 4320, 135, 34560, 135, 135, 34560, 135, 135, 4320]
Prompts retrieved: 1248480 . Total input tokens: 278514064 . Total output tokens: 249725487
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.424493353813887,
    "estimated_duration": 3600.163729676536,
    "input_throughput": 6365.322168850068,
    "output_throughput": 5635.425642661773,
    "total_throughput": 12000.747811511841,
    "itl": 152.91324316803744,
    "ttft": 1862923.3930711586,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31319492869079113,
    "arrivals": 416602,
    "finished_requests": 92560,
    "scheduler_time": 57.39585549921513
}
#Debug simulation 
Total elapsed time: 6.4246070478111506. Arrivals time: 0.2911365474574268 Scheduler time: 6.029807690531015 Scheduler overhead time: 0.0352322687394917 Adapter cache time: 0.0147794084623456 Engine time: 0.037121564615517855 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-8-32/adapters_96_slots_96_rate_3.2-0.4-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-8-32/adapters_96_slots_96_rate_3.2-0.4-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 4320, 34560, 4320, 135, 34560, 135, 135, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 135, 34560, 4320, 135, 135, 4320, 34560, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 135, 34560, 4320, 4320, 135, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 135, 34560, 4320, 4320, 4320, 34560, 34560, 135, 135, 4320, 135, 34560, 135, 135, 34560, 135, 4320, 4320, 135, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 135, 135, 34560, 4320, 34560, 135, 4320, 34560, 135, 34560, 4320, 135, 34560, 135, 135, 34560, 135, 135, 4320]
Prompts retrieved: 1248480 . Total input tokens: 278514064 . Total output tokens: 249725487
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.399188395123929,
    "estimated_duration": 3600.111537138084,
    "input_throughput": 6352.078474262805,
    "output_throughput": 5625.724311891834,
    "total_throughput": 11977.80278615464,
    "itl": 151.12811061768573,
    "ttft": 1864164.5615236664,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31376164913177523,
    "arrivals": 416602,
    "finished_requests": 92382,
    "scheduler_time": 56.945352939458814
}
#Debug simulation 
Total elapsed time: 6.399316596798599. Arrivals time: 0.29309894097968936 Scheduler time: 6.002953850198537 Scheduler overhead time: 0.03534970758482814 Adapter cache time: 0.014983253087848425 Engine time: 0.03627164289355278 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-16-16/adapters_96_slots_96_rate_3.2-0.4-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-16-16/adapters_96_slots_96_rate_3.2-0.4-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 4320, 34560, 4320, 135, 34560, 135, 135, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 135, 34560, 4320, 135, 135, 4320, 34560, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 135, 34560, 4320, 4320, 135, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 135, 34560, 4320, 4320, 4320, 34560, 34560, 135, 135, 4320, 135, 34560, 135, 135, 34560, 135, 4320, 4320, 135, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 135, 135, 34560, 4320, 34560, 135, 4320, 34560, 135, 34560, 4320, 135, 34560, 135, 135, 34560, 135, 135, 4320]
Prompts retrieved: 1248480 . Total input tokens: 278514064 . Total output tokens: 249725487
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 6.430495876818895,
    "estimated_duration": 3600.049710862091,
    "input_throughput": 6365.429880275853,
    "output_throughput": 5635.5610698335695,
    "total_throughput": 12000.990950109423,
    "itl": 152.91064593438873,
    "ttft": 1862882.58880956,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.30011987850070015,
    "arrivals": 416602,
    "finished_requests": 92559,
    "scheduler_time": 57.39482413188894
}
#Debug simulation 
Total elapsed time: 6.430590670090169. Arrivals time: 0.3002144293859601 Scheduler time: 6.027787571307272 Scheduler overhead time: 0.035073955077677965 Adapter cache time: 0.015037191100418568 Engine time: 0.036025906912982464 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-16-32/adapters_96_slots_96_rate_3.2-0.4-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-16-32/adapters_96_slots_96_rate_3.2-0.4-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 4320, 34560, 4320, 135, 34560, 135, 135, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 135, 34560, 4320, 135, 135, 4320, 34560, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 135, 34560, 4320, 4320, 135, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 135, 34560, 4320, 4320, 4320, 34560, 34560, 135, 135, 4320, 135, 34560, 135, 135, 34560, 135, 4320, 4320, 135, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 135, 135, 34560, 4320, 34560, 135, 4320, 34560, 135, 34560, 4320, 135, 34560, 135, 135, 34560, 135, 135, 4320]
Prompts retrieved: 1248480 . Total input tokens: 278514064 . Total output tokens: 249725487
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 6.455863411072642,
    "estimated_duration": 3600.1156583146517,
    "input_throughput": 6352.071202819482,
    "output_throughput": 5625.717871931174,
    "total_throughput": 11977.789074750655,
    "itl": 151.12808325954614,
    "ttft": 1864167.668509302,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3177857702970504,
    "arrivals": 416602,
    "finished_requests": 92382,
    "scheduler_time": 56.94532226095412
}
#Debug simulation 
Total elapsed time: 6.455970996059477. Arrivals time: 0.29898891504853964 Scheduler time: 6.052554802503437 Scheduler overhead time: 0.035604968667030334 Adapter cache time: 0.015092391055077314 Engine time: 0.03701871633529663 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_16-16-16/adapters_96_slots_96_rate_3.2-0.4-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_16-16-16/adapters_96_slots_96_rate_3.2-0.4-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 4320, 34560, 4320, 135, 34560, 135, 135, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 135, 34560, 4320, 135, 135, 4320, 34560, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 135, 34560, 4320, 4320, 135, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 135, 34560, 4320, 4320, 4320, 34560, 34560, 135, 135, 4320, 135, 34560, 135, 135, 34560, 135, 4320, 4320, 135, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 135, 135, 34560, 4320, 34560, 135, 4320, 34560, 135, 34560, 4320, 135, 34560, 135, 135, 34560, 135, 135, 4320]
Prompts retrieved: 1248480 . Total input tokens: 278514064 . Total output tokens: 249725487
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.684424159117043,
    "estimated_duration": 3600.0111445911148,
    "input_throughput": 6365.395294520044,
    "output_throughput": 5635.4700541640295,
    "total_throughput": 12000.865348684074,
    "itl": 152.91088705887083,
    "ttft": 1862871.704420058,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2870448283106092,
    "arrivals": 416602,
    "finished_requests": 92557,
    "scheduler_time": 57.39455345485467
}
#Debug simulation 
Total elapsed time: 6.684552934020758. Arrivals time: 0.2950407415628433 Scheduler time: 6.286899244878441 Scheduler overhead time: 0.03513068938627839 Adapter cache time: 0.015124605037271976 Engine time: 0.03594982996582985 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_16-16-32/adapters_96_slots_96_rate_3.2-0.4-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_16-16-32/adapters_96_slots_96_rate_3.2-0.4-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 4320, 34560, 4320, 135, 34560, 135, 135, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 135, 34560, 4320, 135, 135, 4320, 34560, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 135, 34560, 4320, 4320, 135, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 135, 34560, 4320, 4320, 4320, 34560, 34560, 135, 135, 4320, 135, 34560, 135, 135, 34560, 135, 4320, 4320, 135, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 135, 135, 34560, 4320, 34560, 135, 4320, 34560, 135, 34560, 4320, 135, 34560, 135, 135, 34560, 135, 135, 4320]
Prompts retrieved: 1248480 . Total input tokens: 278514064 . Total output tokens: 249725487
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.458548565860838,
    "estimated_duration": 3600.123023438295,
    "input_throughput": 6352.058207766398,
    "output_throughput": 5625.706362850112,
    "total_throughput": 11977.76457061651,
    "itl": 151.12737689552654,
    "ttft": 1864173.3787493217,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3218098914623256,
    "arrivals": 416602,
    "finished_requests": 92382,
    "scheduler_time": 56.945316460060994
}
#Debug simulation 
Total elapsed time: 6.458646233193576. Arrivals time: 0.2990594864822924 Scheduler time: 6.055018897634 Scheduler overhead time: 0.03558739135041833 Adapter cache time: 0.015403831377625465 Engine time: 0.03689097659662366 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-8-8/adapters_96_slots_96_rate_3.2-0.4-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-8-8/adapters_96_slots_96_rate_3.2-0.4-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 4320, 34560, 4320, 66, 34560, 66, 66, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 66, 34560, 4320, 66, 66, 4320, 34560, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 66, 34560, 4320, 4320, 66, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 66, 34560, 4320, 4320, 4320, 34560, 34560, 66, 66, 4320, 66, 34560, 66, 66, 34560, 66, 4320, 4320, 66, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 66, 66, 34560, 4320, 34560, 66, 4320, 34560, 66, 34560, 4320, 66, 34560, 66, 66, 34560, 66, 66, 4320]
Prompts retrieved: 1246272 . Total input tokens: 278025448 . Total output tokens: 249286206
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.474540872965008,
    "estimated_duration": 3600.106881509406,
    "input_throughput": 6419.465799390495,
    "output_throughput": 5697.535844102525,
    "total_throughput": 12117.00164349302,
    "itl": 151.32425707143045,
    "ttft": 1851526.8002391176,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.29380682341754405,
    "arrivals": 415862,
    "finished_requests": 93633,
    "scheduler_time": 58.12229543279522
}
#Debug simulation 
Total elapsed time: 6.47463175887242. Arrivals time: 0.3523942017927766 Scheduler time: 6.021337359212339 Scheduler overhead time: 0.03526387317106128 Adapter cache time: 0.012899983208626509 Engine time: 0.036272716242820024 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-8-16/adapters_96_slots_96_rate_3.2-0.4-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-8-16/adapters_96_slots_96_rate_3.2-0.4-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 4320, 34560, 4320, 66, 34560, 66, 66, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 66, 34560, 4320, 66, 66, 4320, 34560, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 66, 34560, 4320, 4320, 66, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 66, 34560, 4320, 4320, 4320, 34560, 34560, 66, 66, 4320, 66, 34560, 66, 66, 34560, 66, 4320, 4320, 66, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 66, 66, 34560, 4320, 34560, 66, 4320, 34560, 66, 34560, 4320, 66, 34560, 66, 66, 34560, 66, 66, 4320]
Prompts retrieved: 1246272 . Total input tokens: 278025448 . Total output tokens: 249286206
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.474742671009153,
    "estimated_duration": 3600.0785776402417,
    "input_throughput": 6419.464881554998,
    "output_throughput": 5697.497584467925,
    "total_throughput": 12116.962466022922,
    "itl": 151.32613002719268,
    "ttft": 1851524.261126372,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31319492869079113,
    "arrivals": 415862,
    "finished_requests": 93632,
    "scheduler_time": 58.12182704606542
}
#Debug simulation 
Total elapsed time: 6.474881890229881. Arrivals time: 0.33992264373227954 Scheduler time: 6.034040620084852 Scheduler overhead time: 0.03522698674350977 Adapter cache time: 0.01321965316310525 Engine time: 0.03601593105122447 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-8-32/adapters_96_slots_96_rate_3.2-0.4-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-8-32/adapters_96_slots_96_rate_3.2-0.4-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 4320, 34560, 4320, 66, 34560, 66, 66, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 66, 34560, 4320, 66, 66, 4320, 34560, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 66, 34560, 4320, 4320, 66, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 66, 34560, 4320, 4320, 4320, 34560, 34560, 66, 66, 4320, 66, 34560, 66, 66, 34560, 66, 4320, 4320, 66, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 66, 66, 34560, 4320, 34560, 66, 4320, 34560, 66, 34560, 4320, 66, 34560, 66, 66, 34560, 66, 66, 4320]
Prompts retrieved: 1246272 . Total input tokens: 278025448 . Total output tokens: 249286206
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.440458718221635,
    "estimated_duration": 3600.1397557995483,
    "input_throughput": 6404.002223208052,
    "output_throughput": 5688.187234123643,
    "total_throughput": 12092.189457331695,
    "itl": 149.38447595181734,
    "ttft": 1853184.7356322487,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31376164913177523,
    "arrivals": 415862,
    "finished_requests": 93430,
    "scheduler_time": 57.60412355361119
}
#Debug simulation 
Total elapsed time: 6.440572285093367. Arrivals time: 0.2929549948312342 Scheduler time: 6.044844729360193 Scheduler overhead time: 0.036022293381392956 Adapter cache time: 0.013336350675672293 Engine time: 0.036647805478423834 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-16-16/adapters_96_slots_96_rate_3.2-0.4-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-16-16/adapters_96_slots_96_rate_3.2-0.4-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 4320, 34560, 4320, 66, 34560, 66, 66, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 66, 34560, 4320, 66, 66, 4320, 34560, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 66, 34560, 4320, 4320, 66, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 66, 34560, 4320, 4320, 4320, 34560, 34560, 66, 66, 4320, 66, 34560, 66, 66, 34560, 66, 4320, 4320, 66, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 66, 66, 34560, 4320, 34560, 66, 4320, 34560, 66, 34560, 4320, 66, 34560, 66, 66, 34560, 66, 66, 4320]
Prompts retrieved: 1246272 . Total input tokens: 278025448 . Total output tokens: 249286206
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 6.496174329891801,
    "estimated_duration": 3600.0015610879423,
    "input_throughput": 6419.380827439442,
    "output_throughput": 5697.493640475383,
    "total_throughput": 12116.874467914826,
    "itl": 151.32540040982843,
    "ttft": 1851503.7414842579,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3001198785007001,
    "arrivals": 415862,
    "finished_requests": 93629,
    "scheduler_time": 58.12080592828099
}
#Debug simulation 
Total elapsed time: 6.496268074028194. Arrivals time: 0.34605102939531207 Scheduler time: 6.048533549066633 Scheduler overhead time: 0.035432114731520414 Adapter cache time: 0.013150311540812254 Engine time: 0.03651080559939146 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-16-32/adapters_96_slots_96_rate_3.2-0.4-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-16-32/adapters_96_slots_96_rate_3.2-0.4-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 4320, 34560, 4320, 66, 34560, 66, 66, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 66, 34560, 4320, 66, 66, 4320, 34560, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 66, 34560, 4320, 4320, 66, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 66, 34560, 4320, 4320, 4320, 34560, 34560, 66, 66, 4320, 66, 34560, 66, 66, 34560, 66, 4320, 4320, 66, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 66, 66, 34560, 4320, 34560, 66, 4320, 34560, 66, 34560, 4320, 66, 34560, 66, 66, 34560, 66, 66, 4320]
Prompts retrieved: 1246272 . Total input tokens: 278025448 . Total output tokens: 249286206
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 6.493205552920699,
    "estimated_duration": 3600.1439788960256,
    "input_throughput": 6403.994711086484,
    "output_throughput": 5688.180561678427,
    "total_throughput": 12092.175272764911,
    "itl": 149.38454841992674,
    "ttft": 1853187.8073161016,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31778577029705035,
    "arrivals": 415862,
    "finished_requests": 93430,
    "scheduler_time": 57.60410693535175
}
#Debug simulation 
Total elapsed time: 6.493322330992669. Arrivals time: 0.33912408305332065 Scheduler time: 6.0514229708351195 Scheduler overhead time: 0.0357265854254365 Adapter cache time: 0.01336348196491599 Engine time: 0.03682011179625988 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_16-16-16/adapters_96_slots_96_rate_3.2-0.4-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_16-16-16/adapters_96_slots_96_rate_3.2-0.4-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 4320, 34560, 4320, 66, 34560, 66, 66, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 66, 34560, 4320, 66, 66, 4320, 34560, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 66, 34560, 4320, 4320, 66, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 66, 34560, 4320, 4320, 4320, 34560, 34560, 66, 66, 4320, 66, 34560, 66, 66, 34560, 66, 4320, 4320, 66, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 66, 66, 34560, 4320, 34560, 66, 4320, 34560, 66, 34560, 4320, 66, 34560, 66, 66, 34560, 66, 66, 4320]
Prompts retrieved: 1246272 . Total input tokens: 278025448 . Total output tokens: 249286206
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.502576761879027,
    "estimated_duration": 3600.0987074394193,
    "input_throughput": 6419.480374869388,
    "output_throughput": 5697.548780430255,
    "total_throughput": 12117.029155299642,
    "itl": 151.32421964716522,
    "ttft": 1851521.2504103684,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2870448283106092,
    "arrivals": 415862,
    "finished_requests": 93633,
    "scheduler_time": 58.12225530082942
}
#Debug simulation 
Total elapsed time: 6.502674242947251. Arrivals time: 0.35082345036789775 Scheduler time: 6.050568821374327 Scheduler overhead time: 0.035562661942094564 Adapter cache time: 0.013280877843499184 Engine time: 0.035956405103206635 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_16-16-32/adapters_96_slots_96_rate_3.2-0.4-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_16-16-32/adapters_96_slots_96_rate_3.2-0.4-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 4320, 34560, 4320, 66, 34560, 66, 66, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 66, 34560, 4320, 66, 66, 4320, 34560, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 66, 34560, 4320, 4320, 66, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 66, 34560, 4320, 4320, 4320, 34560, 34560, 66, 66, 4320, 66, 34560, 66, 66, 34560, 66, 4320, 4320, 66, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 66, 66, 34560, 4320, 34560, 66, 4320, 34560, 66, 34560, 4320, 66, 34560, 66, 66, 34560, 66, 66, 4320]
Prompts retrieved: 1246272 . Total input tokens: 278025448 . Total output tokens: 249286206
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.525880263186991,
    "estimated_duration": 3600.1426853500707,
    "input_throughput": 6403.997012067912,
    "output_throughput": 5688.182605464909,
    "total_throughput": 12092.17961753282,
    "itl": 149.38382291326613,
    "ttft": 1853186.3446276626,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3218098914623256,
    "arrivals": 415862,
    "finished_requests": 93430,
    "scheduler_time": 57.6038801567262
}
#Debug simulation 
Total elapsed time: 6.5259690042585135. Arrivals time: 0.3468685313127935 Scheduler time: 6.074641820043325 Scheduler overhead time: 0.036645867861807346 Adapter cache time: 0.013392786029726267 Engine time: 0.03745638020336628 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-8-8/adapters_96_slots_96_rate_3.2-0.4-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-8-8/adapters_96_slots_96_rate_3.2-0.4-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 4320, 34560, 4320, 33, 34560, 33, 33, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 33, 34560, 4320, 33, 33, 4320, 34560, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 33, 34560, 4320, 4320, 33, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 33, 34560, 4320, 4320, 4320, 34560, 34560, 33, 33, 4320, 33, 34560, 33, 33, 34560, 33, 4320, 4320, 33, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 33, 33, 34560, 4320, 34560, 33, 4320, 34560, 33, 34560, 4320, 33, 34560, 33, 33, 34560, 33, 33, 4320]
Prompts retrieved: 1245216 . Total input tokens: 277791658 . Total output tokens: 249075857
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.527559624053538,
    "estimated_duration": 3600.1514625217555,
    "input_throughput": 6468.0853687441995,
    "output_throughput": 5723.0397705456235,
    "total_throughput": 12191.125139289823,
    "itl": 150.5456703985121,
    "ttft": 1847837.049044413,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 92,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.28156487244181305,
    "arrivals": 415494,
    "finished_requests": 94358,
    "scheduler_time": 58.28127906605932
}
#Debug simulation 
Total elapsed time: 6.527676367200911. Arrivals time: 0.30384729616343975 Scheduler time: 6.121744542848319 Scheduler overhead time: 0.03638097923249006 Adapter cache time: 0.012290996499359608 Engine time: 0.03665837645530701 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-8-16/adapters_96_slots_96_rate_3.2-0.4-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-8-16/adapters_96_slots_96_rate_3.2-0.4-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 4320, 34560, 4320, 33, 34560, 33, 33, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 33, 34560, 4320, 33, 33, 4320, 34560, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 33, 34560, 4320, 4320, 33, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 33, 34560, 4320, 4320, 4320, 34560, 34560, 33, 33, 4320, 33, 34560, 33, 33, 34560, 33, 4320, 4320, 33, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 33, 33, 34560, 4320, 34560, 33, 4320, 34560, 33, 34560, 4320, 33, 34560, 33, 33, 34560, 33, 33, 4320]
Prompts retrieved: 1245216 . Total input tokens: 277791658 . Total output tokens: 249075857
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.773621242959052,
    "estimated_duration": 3600.0647775285834,
    "input_throughput": 6468.001116353558,
    "output_throughput": 5722.736470909634,
    "total_throughput": 12190.737587263191,
    "itl": 150.54642594318636,
    "ttft": 1847822.4077441483,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 92,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.29960034623742104,
    "arrivals": 415494,
    "finished_requests": 94353,
    "scheduler_time": 58.27974166770247
}
#Debug simulation 
Total elapsed time: 6.773718695156276. Arrivals time: 0.3463584817945957 Scheduler time: 6.325776380952448 Scheduler overhead time: 0.03628556104376912 Adapter cache time: 0.012076587416231632 Engine time: 0.03642576327547431 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-8-32/adapters_96_slots_96_rate_3.2-0.4-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-8-32/adapters_96_slots_96_rate_3.2-0.4-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 4320, 34560, 4320, 33, 34560, 33, 33, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 33, 34560, 4320, 33, 33, 4320, 34560, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 33, 34560, 4320, 4320, 33, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 33, 34560, 4320, 4320, 4320, 34560, 34560, 33, 33, 4320, 33, 34560, 33, 33, 34560, 33, 4320, 4320, 33, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 33, 33, 34560, 4320, 34560, 33, 4320, 34560, 33, 34560, 4320, 33, 34560, 33, 33, 34560, 33, 33, 4320]
Prompts retrieved: 1245216 . Total input tokens: 277791658 . Total output tokens: 249075857
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.526018444914371,
    "estimated_duration": 3600.035212048321,
    "input_throughput": 6455.73713340892,
    "output_throughput": 5710.293313576643,
    "total_throughput": 12166.030446985564,
    "itl": 148.8550802266935,
    "ttft": 1849568.8460152077,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 92,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3002385837584736,
    "arrivals": 415494,
    "finished_requests": 94152,
    "scheduler_time": 57.825755201619366
}
#Debug simulation 
Total elapsed time: 6.526130659040064. Arrivals time: 0.3489699652418494 Scheduler time: 6.074502170551568 Scheduler overhead time: 0.036707823630422354 Adapter cache time: 0.012233433313667774 Engine time: 0.036742464173585176 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-16-16/adapters_96_slots_96_rate_3.2-0.4-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-16-16/adapters_96_slots_96_rate_3.2-0.4-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 4320, 34560, 4320, 33, 34560, 33, 33, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 33, 34560, 4320, 33, 33, 4320, 34560, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 33, 34560, 4320, 4320, 33, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 33, 34560, 4320, 4320, 4320, 34560, 34560, 33, 33, 4320, 33, 34560, 33, 33, 34560, 33, 4320, 4320, 33, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 33, 33, 34560, 4320, 34560, 33, 4320, 34560, 33, 34560, 4320, 33, 34560, 33, 33, 34560, 33, 33, 4320]
Prompts retrieved: 1245216 . Total input tokens: 277791658 . Total output tokens: 249075857
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 6.486217182595283,
    "estimated_duration": 3600.019959633725,
    "input_throughput": 6468.0121946793515,
    "output_throughput": 5722.698549175844,
    "total_throughput": 12190.710743855196,
    "itl": 150.54583379425432,
    "ttft": 1847820.4930197303,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 92,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.28734248668421075,
    "arrivals": 415494,
    "finished_requests": 94352,
    "scheduler_time": 58.27927369347686
}
#Debug simulation 
Total elapsed time: 6.486343661788851. Arrivals time: 0.2964718732982874 Scheduler time: 6.088567798491567 Scheduler overhead time: 0.03603335237130523 Adapter cache time: 0.012112598400563002 Engine time: 0.03643658850342035 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-16-32/adapters_96_slots_96_rate_3.2-0.4-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-16-32/adapters_96_slots_96_rate_3.2-0.4-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 4320, 34560, 4320, 33, 34560, 33, 33, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 33, 34560, 4320, 33, 33, 4320, 34560, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 33, 34560, 4320, 4320, 33, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 33, 34560, 4320, 4320, 4320, 34560, 34560, 33, 33, 4320, 33, 34560, 33, 33, 34560, 33, 4320, 4320, 33, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 33, 33, 34560, 4320, 34560, 33, 4320, 34560, 33, 34560, 4320, 33, 34560, 33, 33, 34560, 33, 33, 4320]
Prompts retrieved: 1245216 . Total input tokens: 277791658 . Total output tokens: 249075857
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 6.540713836904615,
    "estimated_duration": 3600.0384914669467,
    "input_throughput": 6455.7312526205205,
    "output_throughput": 5710.288111842747,
    "total_throughput": 12166.019364463267,
    "itl": 148.85498786925726,
    "ttft": 1849571.0350215451,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 92,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.30401119735091914,
    "arrivals": 415494,
    "finished_requests": 94152,
    "scheduler_time": 57.82576466959222
}
#Debug simulation 
Total elapsed time: 6.54080567182973. Arrivals time: 0.3010224006138742 Scheduler time: 6.136779354419559 Scheduler overhead time: 0.03670683782547712 Adapter cache time: 0.01235861424356699 Engine time: 0.03708389028906822 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_16-16-16/adapters_96_slots_96_rate_3.2-0.4-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_16-16-16/adapters_96_slots_96_rate_3.2-0.4-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 4320, 34560, 4320, 33, 34560, 33, 33, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 33, 34560, 4320, 33, 33, 4320, 34560, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 33, 34560, 4320, 4320, 33, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 33, 34560, 4320, 4320, 4320, 34560, 34560, 33, 33, 4320, 33, 34560, 33, 33, 34560, 33, 4320, 4320, 33, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 33, 33, 34560, 4320, 34560, 33, 4320, 34560, 33, 34560, 4320, 33, 34560, 33, 33, 34560, 33, 33, 4320]
Prompts retrieved: 1245216 . Total input tokens: 277791658 . Total output tokens: 249075857
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.527392623946071,
    "estimated_duration": 3600.1424664760066,
    "input_throughput": 6468.101531213443,
    "output_throughput": 5723.054071292908,
    "total_throughput": 12191.155602506351,
    "itl": 150.54565062873343,
    "ttft": 1847831.2842873577,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 92,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.27508462713100046,
    "arrivals": 415494,
    "finished_requests": 94358,
    "scheduler_time": 58.28128166506036
}
#Debug simulation 
Total elapsed time: 6.527477329596877. Arrivals time: 0.34892385406419635 Scheduler time: 6.077118112239987 Scheduler overhead time: 0.03629744425415993 Adapter cache time: 0.011775670573115349 Engine time: 0.03655953425914049 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_16-16-32/adapters_96_slots_96_rate_3.2-0.4-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_16-16-32/adapters_96_slots_96_rate_3.2-0.4-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 4320, 34560, 4320, 33, 34560, 33, 33, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 33, 34560, 4320, 33, 33, 4320, 34560, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 33, 34560, 4320, 4320, 33, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 33, 34560, 4320, 4320, 4320, 34560, 34560, 33, 33, 4320, 33, 34560, 33, 33, 34560, 33, 4320, 4320, 33, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 33, 33, 34560, 4320, 34560, 33, 4320, 34560, 33, 34560, 4320, 33, 34560, 33, 33, 34560, 33, 33, 4320]
Prompts retrieved: 1245216 . Total input tokens: 277791658 . Total output tokens: 249075857
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.53893197607249,
    "estimated_duration": 3600.043296471111,
    "input_throughput": 6455.722636108719,
    "output_throughput": 5710.280490279366,
    "total_throughput": 12166.003126388085,
    "itl": 148.85469941741422,
    "ttft": 1849574.6915606083,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 92,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3077838109433647,
    "arrivals": 415494,
    "finished_requests": 94152,
    "scheduler_time": 57.825583320477854
}
#Debug simulation 
Total elapsed time: 6.539074334781617. Arrivals time: 0.354030120652169 Scheduler time: 6.082024882547557 Scheduler overhead time: 0.036479849833995104 Adapter cache time: 0.012449385598301888 Engine time: 0.03709778096526861 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-8-8/adapters_96_slots_96_rate_3.2-0.1-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-8-8/adapters_96_slots_96_rate_3.2-0.1-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 1080, 34560, 1080, 540, 34560, 540, 540, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 540, 34560, 1080, 540, 540, 1080, 34560, 540, 1080, 540, 540, 1080, 1080, 1080, 540, 540, 34560, 1080, 1080, 540, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 540, 34560, 1080, 1080, 1080, 34560, 34560, 540, 540, 1080, 540, 34560, 540, 540, 34560, 540, 1080, 1080, 540, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 540, 540, 34560, 1080, 34560, 540, 1080, 34560, 540, 34560, 1080, 540, 34560, 540, 540, 34560, 540, 540, 1080]
Prompts retrieved: 1157760 . Total input tokens: 258284770 . Total output tokens: 231619030
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.511446665972471,
    "estimated_duration": 3600.1503753559914,
    "input_throughput": 6429.769200324322,
    "output_throughput": 5733.199130038847,
    "total_throughput": 12162.96833036317,
    "itl": 151.0957118133391,
    "ttft": 1821518.6798442863,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.29380682341754405,
    "arrivals": 386239,
    "finished_requests": 93788,
    "scheduler_time": 58.63196137289564
}
#Debug simulation 
Total elapsed time: 6.511542475782335. Arrivals time: 0.3214573981240392 Scheduler time: 6.072045752778649 Scheduler overhead time: 0.036585218738764524 Adapter cache time: 0.02821270376443863 Engine time: 0.03658741060644388 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-8-16/adapters_96_slots_96_rate_3.2-0.1-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-8-16/adapters_96_slots_96_rate_3.2-0.1-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 1080, 34560, 1080, 540, 34560, 540, 540, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 540, 34560, 1080, 540, 540, 1080, 34560, 540, 1080, 540, 540, 1080, 1080, 1080, 540, 540, 34560, 1080, 1080, 540, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 540, 34560, 1080, 1080, 1080, 34560, 34560, 540, 540, 1080, 540, 34560, 540, 540, 34560, 540, 1080, 1080, 540, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 540, 540, 34560, 1080, 34560, 540, 1080, 34560, 540, 34560, 1080, 540, 34560, 540, 540, 34560, 540, 540, 1080]
Prompts retrieved: 1157760 . Total input tokens: 258284770 . Total output tokens: 231619030
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.487912757322192,
    "estimated_duration": 3600.0254605515993,
    "input_throughput": 6429.774248444715,
    "output_throughput": 5733.3061185732595,
    "total_throughput": 12163.080367017974,
    "itl": 151.09722966071809,
    "ttft": 1821475.6919291092,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3131949286907911,
    "arrivals": 386239,
    "finished_requests": 93786,
    "scheduler_time": 58.62949680041235
}
#Debug simulation 
Total elapsed time: 6.488002866040915. Arrivals time: 0.2949462831020355 Scheduler time: 6.07567626144737 Scheduler overhead time: 0.03616920532658696 Adapter cache time: 0.02787031978368759 Engine time: 0.03658114653080702 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-8-32/adapters_96_slots_96_rate_3.2-0.1-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-8-32/adapters_96_slots_96_rate_3.2-0.1-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 1080, 34560, 1080, 540, 34560, 540, 540, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 540, 34560, 1080, 540, 540, 1080, 34560, 540, 1080, 540, 540, 1080, 1080, 1080, 540, 540, 34560, 1080, 1080, 540, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 540, 34560, 1080, 1080, 1080, 34560, 34560, 540, 540, 1080, 540, 34560, 540, 540, 34560, 540, 1080, 1080, 540, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 540, 540, 34560, 1080, 34560, 540, 1080, 34560, 540, 34560, 1080, 540, 34560, 540, 540, 34560, 540, 540, 1080]
Prompts retrieved: 1157760 . Total input tokens: 258284770 . Total output tokens: 231619030
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.518649060744792,
    "estimated_duration": 3600.0411545375173,
    "input_throughput": 6424.887107428471,
    "output_throughput": 5730.079772560284,
    "total_throughput": 12154.966879988755,
    "itl": 148.92448063576558,
    "ttft": 1822250.2712409867,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31376164913177523,
    "arrivals": 386239,
    "finished_requests": 93723,
    "scheduler_time": 58.18496906341419
}
#Debug simulation 
Total elapsed time: 6.518780414015055. Arrivals time: 0.29656498692929745 Scheduler time: 6.102148929145187 Scheduler overhead time: 0.03684264188632369 Adapter cache time: 0.028550320770591497 Engine time: 0.037668948993086815 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-16-16/adapters_96_slots_96_rate_3.2-0.1-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-16-16/adapters_96_slots_96_rate_3.2-0.1-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 1080, 34560, 1080, 540, 34560, 540, 540, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 540, 34560, 1080, 540, 540, 1080, 34560, 540, 1080, 540, 540, 1080, 1080, 1080, 540, 540, 34560, 1080, 1080, 540, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 540, 34560, 1080, 1080, 1080, 34560, 34560, 540, 540, 1080, 540, 34560, 540, 540, 34560, 540, 1080, 1080, 540, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 540, 540, 34560, 1080, 34560, 540, 1080, 34560, 540, 34560, 1080, 540, 34560, 540, 540, 34560, 540, 540, 1080]
Prompts retrieved: 1157760 . Total input tokens: 258284770 . Total output tokens: 231619030
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 6.473659702111036,
    "estimated_duration": 3600.1694243293623,
    "input_throughput": 6429.735179563673,
    "output_throughput": 5733.168794922722,
    "total_throughput": 12162.903974486395,
    "itl": 151.09628038445928,
    "ttft": 1821528.9141599915,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.30011987850070015,
    "arrivals": 386239,
    "finished_requests": 93788,
    "scheduler_time": 58.631838231582265
}
#Debug simulation 
Total elapsed time: 6.473753062076867. Arrivals time: 0.2891468801535666 Scheduler time: 6.067617343738675 Scheduler overhead time: 0.03603570768609643 Adapter cache time: 0.027475634589791298 Engine time: 0.03677715454250574 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-16-32/adapters_96_slots_96_rate_3.2-0.1-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-16-32/adapters_96_slots_96_rate_3.2-0.1-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 1080, 34560, 1080, 540, 34560, 540, 540, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 540, 34560, 1080, 540, 540, 1080, 34560, 540, 1080, 540, 540, 1080, 1080, 1080, 540, 540, 34560, 1080, 1080, 540, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 540, 34560, 1080, 1080, 1080, 34560, 34560, 540, 540, 1080, 540, 34560, 540, 540, 34560, 540, 1080, 1080, 540, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 540, 540, 34560, 1080, 34560, 540, 1080, 34560, 540, 34560, 1080, 540, 34560, 540, 540, 34560, 540, 540, 1080]
Prompts retrieved: 1157760 . Total input tokens: 258284770 . Total output tokens: 231619030
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 6.491656085010618,
    "estimated_duration": 3600.0458892680776,
    "input_throughput": 6424.878657505811,
    "output_throughput": 5730.072236438622,
    "total_throughput": 12154.950893944433,
    "itl": 148.92455469602447,
    "ttft": 1822253.9141532232,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3177857702970505,
    "arrivals": 386239,
    "finished_requests": 93723,
    "scheduler_time": 58.18495980307074
}
#Debug simulation 
Total elapsed time: 6.49174749199301. Arrivals time: 0.2965608607046306 Scheduler time: 6.076604876667261 Scheduler overhead time: 0.036657536402344704 Adapter cache time: 0.028060007840394974 Engine time: 0.0370489745400846 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_16-16-16/adapters_96_slots_96_rate_3.2-0.1-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_16-16-16/adapters_96_slots_96_rate_3.2-0.1-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 1080, 34560, 1080, 540, 34560, 540, 540, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 540, 34560, 1080, 540, 540, 1080, 34560, 540, 1080, 540, 540, 1080, 1080, 1080, 540, 540, 34560, 1080, 1080, 540, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 540, 34560, 1080, 1080, 1080, 34560, 34560, 540, 540, 1080, 540, 34560, 540, 540, 34560, 540, 1080, 1080, 540, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 540, 540, 34560, 1080, 34560, 540, 1080, 34560, 540, 34560, 1080, 540, 34560, 540, 540, 34560, 540, 540, 1080]
Prompts retrieved: 1157760 . Total input tokens: 258284770 . Total output tokens: 231619030
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.568468358833343,
    "estimated_duration": 3600.14429300699,
    "input_throughput": 6429.780063250108,
    "output_throughput": 5733.208816127838,
    "total_throughput": 12162.988879377946,
    "itl": 151.095689248322,
    "ttft": 1821513.4928717958,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2870448283106092,
    "arrivals": 386239,
    "finished_requests": 93788,
    "scheduler_time": 58.63204568170758
}
#Debug simulation 
Total elapsed time: 6.568609673995525. Arrivals time: 0.32640199176967144 Scheduler time: 6.124357544351369 Scheduler overhead time: 0.03631982859224081 Adapter cache time: 0.027848040219396353 Engine time: 0.03686355706304312 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_16-16-32/adapters_96_slots_96_rate_3.2-0.1-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_16-16-32/adapters_96_slots_96_rate_3.2-0.1-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 1080, 34560, 1080, 540, 34560, 540, 540, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 540, 34560, 1080, 540, 540, 1080, 34560, 540, 1080, 540, 540, 1080, 1080, 1080, 540, 540, 34560, 1080, 1080, 540, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 540, 34560, 1080, 1080, 1080, 34560, 34560, 540, 540, 1080, 540, 34560, 540, 540, 34560, 540, 1080, 1080, 540, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 540, 540, 34560, 1080, 34560, 540, 1080, 34560, 540, 34560, 1080, 540, 34560, 540, 540, 34560, 540, 540, 1080]
Prompts retrieved: 1157760 . Total input tokens: 258284770 . Total output tokens: 231619030
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.4730258928611875,
    "estimated_duration": 3600.049755410755,
    "input_throughput": 6424.871757740734,
    "output_throughput": 5730.066082835665,
    "total_throughput": 12154.9378405764,
    "itl": 148.92460777589574,
    "ttft": 1822256.7937247353,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3218098914623258,
    "arrivals": 386239,
    "finished_requests": 93723,
    "scheduler_time": 58.184907642012206
}
#Debug simulation 
Total elapsed time: 6.473119809757918. Arrivals time: 0.2918228888884187 Scheduler time: 6.062892262358218 Scheduler overhead time: 0.036751811392605305 Adapter cache time: 0.02771960012614727 Engine time: 0.03704050835222006 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-8-8/adapters_96_slots_96_rate_3.2-0.1-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-8-8/adapters_96_slots_96_rate_3.2-0.1-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 1080, 34560, 1080, 270, 34560, 270, 270, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 270, 34560, 1080, 270, 270, 1080, 34560, 270, 1080, 270, 270, 1080, 1080, 1080, 270, 270, 34560, 1080, 1080, 270, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 270, 34560, 1080, 1080, 1080, 34560, 34560, 270, 270, 1080, 270, 34560, 270, 270, 34560, 270, 1080, 1080, 270, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 270, 270, 34560, 1080, 34560, 270, 1080, 34560, 270, 34560, 1080, 270, 34560, 270, 270, 34560, 270, 270, 1080]
Prompts retrieved: 1149120 . Total input tokens: 256368494 . Total output tokens: 229882831
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.70226248819381,
    "estimated_duration": 3600.0252857054093,
    "input_throughput": 6743.452913065611,
    "output_throughput": 5946.20573499819,
    "total_throughput": 12689.6586480638,
    "itl": 144.56083386961544,
    "ttft": 1791933.1663494867,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.29380682341754405,
    "arrivals": 383390,
    "finished_requests": 97969,
    "scheduler_time": 60.58013859686851
}
#Debug simulation 
Total elapsed time: 6.702352832071483. Arrivals time: 0.3063160600140691 Scheduler time: 6.278588843531907 Scheduler overhead time: 0.0375100770033896 Adapter cache time: 0.024363269098103046 Engine time: 0.03820802178233862 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-8-16/adapters_96_slots_96_rate_3.2-0.1-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-8-16/adapters_96_slots_96_rate_3.2-0.1-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 1080, 34560, 1080, 270, 34560, 270, 270, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 270, 34560, 1080, 270, 270, 1080, 34560, 270, 1080, 270, 270, 1080, 1080, 1080, 270, 270, 34560, 1080, 1080, 270, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 270, 34560, 1080, 1080, 1080, 34560, 34560, 270, 270, 1080, 270, 34560, 270, 270, 34560, 270, 1080, 1080, 270, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 270, 270, 34560, 1080, 34560, 270, 1080, 34560, 270, 34560, 1080, 270, 34560, 270, 270, 34560, 270, 270, 1080]
Prompts retrieved: 1149120 . Total input tokens: 256368494 . Total output tokens: 229882831
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.72755494620651,
    "estimated_duration": 3600.08398570732,
    "input_throughput": 6743.373236952491,
    "output_throughput": 5946.2498888881055,
    "total_throughput": 12689.623125840597,
    "itl": 144.5614970610632,
    "ttft": 1791944.503629408,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31319492869079113,
    "arrivals": 383390,
    "finished_requests": 97970,
    "scheduler_time": 60.58066433980834
}
#Debug simulation 
Total elapsed time: 6.727674849331379. Arrivals time: 0.33266286877915263 Scheduler time: 6.277885091025382 Scheduler overhead time: 0.037606741301715374 Adapter cache time: 0.02417850261554122 Engine time: 0.0379913654178381 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-8-32/adapters_96_slots_96_rate_3.2-0.1-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-8-32/adapters_96_slots_96_rate_3.2-0.1-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 1080, 34560, 1080, 270, 34560, 270, 270, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 270, 34560, 1080, 270, 270, 1080, 34560, 270, 1080, 270, 270, 1080, 1080, 1080, 270, 270, 34560, 1080, 1080, 270, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 270, 34560, 1080, 1080, 1080, 34560, 34560, 270, 270, 1080, 270, 34560, 270, 270, 34560, 270, 1080, 1080, 270, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 270, 270, 34560, 1080, 34560, 270, 1080, 34560, 270, 34560, 1080, 270, 34560, 270, 270, 34560, 270, 270, 1080]
Prompts retrieved: 1149120 . Total input tokens: 256368494 . Total output tokens: 229882831
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.757739488966763,
    "estimated_duration": 3600.0974751107456,
    "input_throughput": 6736.822313194152,
    "output_throughput": 5940.2886026973865,
    "total_throughput": 12677.110915891539,
    "itl": 142.68097097056622,
    "ttft": 1792798.630162503,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3137616491317753,
    "arrivals": 383390,
    "finished_requests": 97873,
    "scheduler_time": 60.15029714454083
}
#Debug simulation 
Total elapsed time: 6.757831117138267. Arrivals time: 0.30553497839719057 Scheduler time: 6.33223238075152 Scheduler overhead time: 0.03871451038867235 Adapter cache time: 0.024675491265952587 Engine time: 0.03896189760416746 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-16-16/adapters_96_slots_96_rate_3.2-0.1-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-16-16/adapters_96_slots_96_rate_3.2-0.1-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 1080, 34560, 1080, 270, 34560, 270, 270, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 270, 34560, 1080, 270, 270, 1080, 34560, 270, 1080, 270, 270, 1080, 1080, 1080, 270, 270, 34560, 1080, 1080, 270, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 270, 34560, 1080, 1080, 1080, 34560, 34560, 270, 270, 1080, 270, 34560, 270, 270, 34560, 270, 1080, 1080, 270, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 270, 270, 34560, 1080, 34560, 270, 1080, 34560, 270, 34560, 1080, 270, 34560, 270, 270, 34560, 270, 270, 1080]
Prompts retrieved: 1149120 . Total input tokens: 256368494 . Total output tokens: 229882831
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 6.735592987388372,
    "estimated_duration": 3600.035727017696,
    "input_throughput": 6743.4333547881115,
    "output_throughput": 5946.188489005175,
    "total_throughput": 12689.621843793286,
    "itl": 144.56084749398482,
    "ttft": 1791939.1617417196,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.30011987850070015,
    "arrivals": 383390,
    "finished_requests": 97969,
    "scheduler_time": 60.580086769445984
}
#Debug simulation 
Total elapsed time: 6.73570067808032. Arrivals time: 0.3057407536543906 Scheduler time: 6.31210262933746 Scheduler overhead time: 0.03780255699530244 Adapter cache time: 0.024168367497622967 Engine time: 0.03844007709994912 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-16-32/adapters_96_slots_96_rate_3.2-0.1-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-16-32/adapters_96_slots_96_rate_3.2-0.1-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 1080, 34560, 1080, 270, 34560, 270, 270, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 270, 34560, 1080, 270, 270, 1080, 34560, 270, 1080, 270, 270, 1080, 1080, 1080, 270, 270, 34560, 1080, 1080, 270, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 270, 34560, 1080, 1080, 1080, 34560, 34560, 270, 270, 1080, 270, 34560, 270, 270, 34560, 270, 1080, 1080, 270, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 270, 270, 34560, 1080, 34560, 270, 1080, 34560, 270, 34560, 1080, 270, 34560, 270, 270, 34560, 270, 270, 1080]
Prompts retrieved: 1149120 . Total input tokens: 256368494 . Total output tokens: 229882831
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 6.717756769154221,
    "estimated_duration": 3600.1010730247835,
    "input_throughput": 6736.815580464409,
    "output_throughput": 5940.282666017466,
    "total_throughput": 12677.098246481875,
    "itl": 142.68093952968013,
    "ttft": 1792801.3772922875,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31778577029705046,
    "arrivals": 383390,
    "finished_requests": 97873,
    "scheduler_time": 60.150256394845556
}
#Debug simulation 
Total elapsed time: 6.71790830232203. Arrivals time: 0.3031327398493886 Scheduler time: 6.295303704682738 Scheduler overhead time: 0.03804637910798192 Adapter cache time: 0.024723828304558992 Engine time: 0.03895043954253197 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_16-16-16/adapters_96_slots_96_rate_3.2-0.1-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_16-16-16/adapters_96_slots_96_rate_3.2-0.1-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 1080, 34560, 1080, 270, 34560, 270, 270, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 270, 34560, 1080, 270, 270, 1080, 34560, 270, 1080, 270, 270, 1080, 1080, 1080, 270, 270, 34560, 1080, 1080, 270, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 270, 34560, 1080, 1080, 1080, 34560, 34560, 270, 270, 1080, 270, 34560, 270, 270, 34560, 270, 1080, 1080, 270, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 270, 270, 34560, 1080, 34560, 270, 1080, 34560, 270, 34560, 1080, 270, 34560, 270, 270, 34560, 270, 270, 1080]
Prompts retrieved: 1149120 . Total input tokens: 256368494 . Total output tokens: 229882831
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.732006402220577,
    "estimated_duration": 3600.1162867059575,
    "input_throughput": 6743.327177970911,
    "output_throughput": 5946.3048677206425,
    "total_throughput": 12689.632045691555,
    "itl": 144.5595147742049,
    "ttft": 1791939.4825428505,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2870448283106092,
    "arrivals": 383390,
    "finished_requests": 97972,
    "scheduler_time": 60.58186309240475
}
#Debug simulation 
Total elapsed time: 6.732095900923014. Arrivals time: 0.3006490832194686 Scheduler time: 6.314324257429689 Scheduler overhead time: 0.03747082035988569 Adapter cache time: 0.024053233209997416 Engine time: 0.03820594120770693 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_16-16-32/adapters_96_slots_96_rate_3.2-0.1-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_16-16-32/adapters_96_slots_96_rate_3.2-0.1-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 1080, 34560, 1080, 270, 34560, 270, 270, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 270, 34560, 1080, 270, 270, 1080, 34560, 270, 1080, 270, 270, 1080, 1080, 1080, 270, 270, 34560, 1080, 1080, 270, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 270, 34560, 1080, 1080, 1080, 34560, 34560, 270, 270, 1080, 270, 34560, 270, 270, 34560, 270, 1080, 1080, 270, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 270, 270, 34560, 1080, 34560, 270, 1080, 34560, 270, 34560, 1080, 270, 34560, 270, 270, 34560, 270, 270, 1080]
Prompts retrieved: 1149120 . Total input tokens: 256368494 . Total output tokens: 229882831
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.70751450303942,
    "estimated_duration": 3600.095972740063,
    "input_throughput": 6736.825124564853,
    "output_throughput": 5940.291081663367,
    "total_throughput": 12677.116206228218,
    "itl": 142.68049471151224,
    "ttft": 1792797.8796365783,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3218098914623257,
    "arrivals": 383390,
    "finished_requests": 97873,
    "scheduler_time": 60.150312296354514
}
#Debug simulation 
Total elapsed time: 6.707606100011617. Arrivals time: 0.3030555690638721 Scheduler time: 6.286096832714975 Scheduler overhead time: 0.03786140959709883 Adapter cache time: 0.02455449290573597 Engine time: 0.038424701895564795 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-8/adapters_96_slots_96_rate_3.2-0.1-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-8/adapters_96_slots_96_rate_3.2-0.1-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 1080, 34560, 1080, 135, 34560, 135, 135, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 135, 34560, 1080, 135, 135, 1080, 34560, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 135, 34560, 1080, 1080, 135, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 135, 34560, 1080, 1080, 1080, 34560, 34560, 135, 135, 1080, 135, 34560, 135, 135, 34560, 135, 1080, 1080, 135, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 135, 135, 34560, 1080, 34560, 135, 1080, 34560, 135, 34560, 1080, 135, 34560, 135, 135, 34560, 135, 135, 1080]
Prompts retrieved: 1144800 . Total input tokens: 255374334 . Total output tokens: 229044749
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 7.0028368453495204,
    "estimated_duration": 3600.1055417140037,
    "input_throughput": 6851.113867138785,
    "output_throughput": 6022.729264119579,
    "total_throughput": 12873.843131258365,
    "itl": 142.5712025536351,
    "ttft": 1780836.4391470577,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.29380682341754405,
    "arrivals": 381970,
    "finished_requests": 99317,
    "scheduler_time": 61.4026822339465
}
#Debug simulation 
Total elapsed time: 7.002947111148387. Arrivals time: 0.5287560881115496 Scheduler time: 6.357864825986326 Scheduler overhead time: 0.03803050750866532 Adapter cache time: 0.021705723367631435 Engine time: 0.03895516414195299 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-16/adapters_96_slots_96_rate_3.2-0.1-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-16/adapters_96_slots_96_rate_3.2-0.1-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 1080, 34560, 1080, 135, 34560, 135, 135, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 135, 34560, 1080, 135, 135, 1080, 34560, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 135, 34560, 1080, 1080, 135, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 135, 34560, 1080, 1080, 1080, 34560, 34560, 135, 135, 1080, 135, 34560, 135, 135, 34560, 135, 1080, 1080, 135, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 135, 135, 34560, 1080, 34560, 135, 1080, 34560, 135, 34560, 1080, 135, 34560, 135, 135, 34560, 135, 135, 1080]
Prompts retrieved: 1144800 . Total input tokens: 255374334 . Total output tokens: 229044749
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.85561869898811,
    "estimated_duration": 3600.1306191812464,
    "input_throughput": 6851.06614426377,
    "output_throughput": 6022.687311531796,
    "total_throughput": 12873.753455795566,
    "itl": 142.570391283513,
    "ttft": 1780833.6930197852,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31319492869079113,
    "arrivals": 381970,
    "finished_requests": 99317,
    "scheduler_time": 61.40329004071595
}
#Debug simulation 
Total elapsed time: 6.855724890716374. Arrivals time: 0.3128451183438301 Scheduler time: 6.426891491748393 Scheduler overhead time: 0.037922180723398924 Adapter cache time: 0.021624987479299307 Engine time: 0.03877049358561635 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-32/adapters_96_slots_96_rate_3.2-0.1-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-32/adapters_96_slots_96_rate_3.2-0.1-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 1080, 34560, 1080, 135, 34560, 135, 135, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 135, 34560, 1080, 135, 135, 1080, 34560, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 135, 34560, 1080, 1080, 135, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 135, 34560, 1080, 1080, 1080, 34560, 34560, 135, 135, 1080, 135, 34560, 135, 135, 34560, 135, 1080, 1080, 135, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 135, 135, 34560, 1080, 34560, 135, 1080, 34560, 135, 34560, 1080, 135, 34560, 135, 135, 34560, 135, 135, 1080]
Prompts retrieved: 1144800 . Total input tokens: 255374334 . Total output tokens: 229044749
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.8426854610443115,
    "estimated_duration": 3600.0582822454307,
    "input_throughput": 6844.6505773319905,
    "output_throughput": 6017.966738718205,
    "total_throughput": 12862.617316050195,
    "itl": 140.78297343163047,
    "ttft": 1781907.9112181487,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31376164913177523,
    "arrivals": 381970,
    "finished_requests": 99219,
    "scheduler_time": 60.958980219719955
}
#Debug simulation 
Total elapsed time: 6.842805984895676. Arrivals time: 0.3063974673859775 Scheduler time: 6.418365710414946 Scheduler overhead time: 0.038682689890265465 Adapter cache time: 0.022135272156447172 Engine time: 0.03934565791860223 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-16-16/adapters_96_slots_96_rate_3.2-0.1-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-16-16/adapters_96_slots_96_rate_3.2-0.1-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 1080, 34560, 1080, 135, 34560, 135, 135, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 135, 34560, 1080, 135, 135, 1080, 34560, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 135, 34560, 1080, 1080, 135, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 135, 34560, 1080, 1080, 1080, 34560, 34560, 135, 135, 1080, 135, 34560, 135, 135, 34560, 135, 1080, 1080, 135, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 135, 135, 34560, 1080, 34560, 135, 1080, 34560, 135, 34560, 1080, 135, 34560, 135, 135, 34560, 135, 135, 1080]
Prompts retrieved: 1144800 . Total input tokens: 255374334 . Total output tokens: 229044749
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 7.05386326322332,
    "estimated_duration": 3600.0999491837492,
    "input_throughput": 6851.124509915964,
    "output_throughput": 6022.738620053053,
    "total_throughput": 12873.863129969017,
    "itl": 142.56994257744478,
    "ttft": 1780818.8727615424,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.30011987850070015,
    "arrivals": 381970,
    "finished_requests": 99317,
    "scheduler_time": 61.403226468377866
}
#Debug simulation 
Total elapsed time: 7.053970453329384. Arrivals time: 0.30824886402115226 Scheduler time: 6.629488454200327 Scheduler overhead time: 0.038158231880515814 Adapter cache time: 0.02179620275273919 Engine time: 0.03867945447564125 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-16-32/adapters_96_slots_96_rate_3.2-0.1-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-16-32/adapters_96_slots_96_rate_3.2-0.1-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 1080, 34560, 1080, 135, 34560, 135, 135, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 135, 34560, 1080, 135, 135, 1080, 34560, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 135, 34560, 1080, 1080, 135, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 135, 34560, 1080, 1080, 1080, 34560, 34560, 135, 135, 1080, 135, 34560, 135, 135, 34560, 135, 1080, 1080, 135, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 135, 135, 34560, 1080, 34560, 135, 1080, 34560, 135, 34560, 1080, 135, 34560, 135, 135, 34560, 135, 135, 1080]
Prompts retrieved: 1144800 . Total input tokens: 255374334 . Total output tokens: 229044749
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 6.823666237760335,
    "estimated_duration": 3600.062075561069,
    "input_throughput": 6844.643365256329,
    "output_throughput": 6017.960397703284,
    "total_throughput": 12862.603762959614,
    "itl": 140.78293095534772,
    "ttft": 1781910.773504258,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31778577029705046,
    "arrivals": 381970,
    "finished_requests": 99219,
    "scheduler_time": 60.95895112752822
}
#Debug simulation 
Total elapsed time: 6.823757026810199. Arrivals time: 0.30600089160725474 Scheduler time: 6.399387190118432 Scheduler overhead time: 0.03882418293505907 Adapter cache time: 0.022423312067985535 Engine time: 0.03931722231209278 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_16-16-16/adapters_96_slots_96_rate_3.2-0.1-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_16-16-16/adapters_96_slots_96_rate_3.2-0.1-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 1080, 34560, 1080, 135, 34560, 135, 135, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 135, 34560, 1080, 135, 135, 1080, 34560, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 135, 34560, 1080, 1080, 135, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 135, 34560, 1080, 1080, 1080, 34560, 34560, 135, 135, 1080, 135, 34560, 135, 135, 34560, 135, 1080, 1080, 135, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 135, 135, 34560, 1080, 34560, 135, 1080, 34560, 135, 34560, 1080, 135, 34560, 135, 135, 34560, 135, 135, 1080]
Prompts retrieved: 1144800 . Total input tokens: 255374334 . Total output tokens: 229044749
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.835391783155501,
    "estimated_duration": 3600.0743408728035,
    "input_throughput": 6851.114911704941,
    "output_throughput": 6022.742295578077,
    "total_throughput": 12873.857207283017,
    "itl": 142.57059958135238,
    "ttft": 1780844.188604483,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2870448283106092,
    "arrivals": 381970,
    "finished_requests": 99316,
    "scheduler_time": 61.40217467791396
}
#Debug simulation 
Total elapsed time: 6.835485581308603. Arrivals time: 0.3086577872745693 Scheduler time: 6.409939385950565 Scheduler overhead time: 0.038094756193459034 Adapter cache time: 0.021939773578196764 Engine time: 0.039010708685964346 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_16-16-32/adapters_96_slots_96_rate_3.2-0.1-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_16-16-32/adapters_96_slots_96_rate_3.2-0.1-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 1080, 34560, 1080, 135, 34560, 135, 135, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 135, 34560, 1080, 135, 135, 1080, 34560, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 135, 34560, 1080, 1080, 135, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 135, 34560, 1080, 1080, 1080, 34560, 34560, 135, 135, 1080, 135, 34560, 135, 135, 34560, 135, 1080, 1080, 135, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 135, 135, 34560, 1080, 34560, 135, 1080, 34560, 135, 34560, 1080, 135, 34560, 135, 135, 34560, 135, 135, 1080]
Prompts retrieved: 1144800 . Total input tokens: 255374334 . Total output tokens: 229044749
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.093400600831956,
    "estimated_duration": 3600.073834089676,
    "input_throughput": 6844.621009344055,
    "output_throughput": 6017.940741895444,
    "total_throughput": 12862.561751239498,
    "itl": 140.78325050590385,
    "ttft": 1781918.9771186744,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.32180989146232564,
    "arrivals": 381970,
    "finished_requests": 99219,
    "scheduler_time": 60.958887007618046
}
#Debug simulation 
Total elapsed time: 7.093524903990328. Arrivals time: 0.3104775696992874 Scheduler time: 6.664579626638442 Scheduler overhead time: 0.038708813954144716 Adapter cache time: 0.02238794742152095 Engine time: 0.03941425867378712 
