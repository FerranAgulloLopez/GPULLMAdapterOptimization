INFO 06-01 00:47:13 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 06-01 00:47:14 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_16-16-32/adapters_256_slots_192_rate_1.6-0.4-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_16-16-32/adapters_256_slots_192_rate_1.6-0.4-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 135, 17280, 17280, 135, 17280, 4320, 17280, 135, 4320, 135, 17280, 4320, 4320, 4320, 4320, 17280, 135, 135, 135, 4320, 17280, 135, 17280, 17280, 4320, 4320, 4320, 135, 17280, 135, 4320, 4320, 135, 4320, 135, 135, 4320, 4320, 17280, 4320, 135, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 135, 17280, 17280, 4320, 135, 135, 17280, 4320, 135, 4320, 4320, 17280, 4320, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 4320, 135, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 135, 17280, 17280, 135, 17280, 135, 4320, 17280, 17280, 17280, 4320, 135, 17280, 4320, 135, 135, 135, 135, 135, 17280, 4320, 135, 17280, 135, 17280, 135, 135, 4320, 4320, 17280, 4320, 17280, 135, 4320, 135, 17280, 17280, 135, 17280, 4320, 135, 17280, 135, 135, 17280, 17280, 4320, 17280, 17280, 135, 17280, 4320, 4320, 135, 4320, 17280, 17280, 135, 17280, 4320, 135, 4320, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 4320, 17280, 17280, 4320, 135, 17280, 135, 4320, 4320, 135, 4320, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 4320, 17280, 4320, 135, 4320, 17280, 4320, 17280, 135, 17280, 135, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 135, 17280, 135, 17280, 4320, 4320, 135, 4320, 17280, 4320, 4320, 17280, 135, 17280, 17280, 4320, 135, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 135, 17280, 4320, 17280, 17280, 135, 17280, 4320, 4320, 17280, 135, 4320, 135, 135, 135, 135, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 135, 135, 135, 135]
Prompts retrieved: 1864755 . Total input tokens: 415800092 . Total output tokens: 372975680
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.13025124091655,
    "estimated_duration": 3600.0065377977107,
    "input_throughput": 3543.9685639584545,
    "output_throughput": 3128.5304295280334,
    "total_throughput": 6672.498993486488,
    "itl": 108.07731754736768,
    "ttft": 2285427.3800626686,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 421,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4118877965584409,
    "arrivals": 621618,
    "finished_requests": 51635,
    "scheduler_time": 59.62559751587265
}
#Debug simulation 
Total elapsed time: 4.1303731868974864. Arrivals time: 0.20134297478944063 Scheduler time: 3.677046500146389 Scheduler overhead time: 0.04687636625021696 Adapter cache time: 0.13367423368617892 Engine time: 0.0493333269841969 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-8/adapters_256_slots_192_rate_1.6-0.4-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-8/adapters_256_slots_192_rate_1.6-0.4-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 66, 17280, 17280, 66, 17280, 4320, 17280, 66, 4320, 66, 17280, 4320, 4320, 4320, 4320, 17280, 66, 66, 66, 4320, 17280, 66, 17280, 17280, 4320, 4320, 4320, 66, 17280, 66, 4320, 4320, 66, 4320, 66, 66, 4320, 4320, 17280, 4320, 66, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 66, 17280, 17280, 4320, 66, 66, 17280, 4320, 66, 4320, 4320, 17280, 4320, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 4320, 66, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 66, 17280, 17280, 66, 17280, 66, 4320, 17280, 17280, 17280, 4320, 66, 17280, 4320, 66, 66, 66, 66, 66, 17280, 4320, 66, 17280, 66, 17280, 66, 66, 4320, 4320, 17280, 4320, 17280, 66, 4320, 66, 17280, 17280, 66, 17280, 4320, 66, 17280, 66, 66, 17280, 17280, 4320, 17280, 17280, 66, 17280, 4320, 4320, 66, 4320, 17280, 17280, 66, 17280, 4320, 66, 4320, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 4320, 17280, 17280, 4320, 66, 17280, 66, 4320, 4320, 66, 4320, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 4320, 17280, 4320, 66, 4320, 17280, 4320, 17280, 66, 17280, 66, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 66, 17280, 66, 17280, 4320, 4320, 66, 4320, 17280, 4320, 4320, 17280, 66, 17280, 17280, 4320, 66, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 66, 17280, 4320, 17280, 17280, 66, 17280, 4320, 4320, 17280, 66, 4320, 66, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 66, 66, 66, 66]
Prompts retrieved: 1858890 . Total input tokens: 414477948 . Total output tokens: 371780131
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.32221206324175,
    "estimated_duration": 3600.170628361242,
    "input_throughput": 4077.4820183125616,
    "output_throughput": 3571.324064118743,
    "total_throughput": 7648.806082431304,
    "itl": 238.6865668511457,
    "ttft": 2206656.5356480656,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 304,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9303882741555559,
    "arrivals": 619780,
    "finished_requests": 59152,
    "scheduler_time": 58.86985486018973
}
#Debug simulation 
Total elapsed time: 4.322326886001974. Arrivals time: 0.21829427033662796 Scheduler time: 4.0070110517553985 Scheduler overhead time: 0.023676138371229172 Adapter cache time: 0.03813211573287845 Engine time: 0.024327995255589485 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-16/adapters_256_slots_192_rate_1.6-0.4-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-16/adapters_256_slots_192_rate_1.6-0.4-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 66, 17280, 17280, 66, 17280, 4320, 17280, 66, 4320, 66, 17280, 4320, 4320, 4320, 4320, 17280, 66, 66, 66, 4320, 17280, 66, 17280, 17280, 4320, 4320, 4320, 66, 17280, 66, 4320, 4320, 66, 4320, 66, 66, 4320, 4320, 17280, 4320, 66, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 66, 17280, 17280, 4320, 66, 66, 17280, 4320, 66, 4320, 4320, 17280, 4320, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 4320, 66, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 66, 17280, 17280, 66, 17280, 66, 4320, 17280, 17280, 17280, 4320, 66, 17280, 4320, 66, 66, 66, 66, 66, 17280, 4320, 66, 17280, 66, 17280, 66, 66, 4320, 4320, 17280, 4320, 17280, 66, 4320, 66, 17280, 17280, 66, 17280, 4320, 66, 17280, 66, 66, 17280, 17280, 4320, 17280, 17280, 66, 17280, 4320, 4320, 66, 4320, 17280, 17280, 66, 17280, 4320, 66, 4320, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 4320, 17280, 17280, 4320, 66, 17280, 66, 4320, 4320, 66, 4320, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 4320, 17280, 4320, 66, 4320, 17280, 4320, 17280, 66, 17280, 66, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 66, 17280, 66, 17280, 4320, 4320, 66, 4320, 17280, 4320, 4320, 17280, 66, 17280, 17280, 4320, 66, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 66, 17280, 4320, 17280, 17280, 66, 17280, 4320, 4320, 17280, 66, 4320, 66, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 66, 66, 66, 66]
Prompts retrieved: 1858890 . Total input tokens: 414477948 . Total output tokens: 371780131
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.35615146625787,
    "estimated_duration": 3600.2078776512935,
    "input_throughput": 4072.310404910469,
    "output_throughput": 3566.0963022989977,
    "total_throughput": 7638.406707209467,
    "itl": 236.30763367572186,
    "ttft": 2207828.931804297,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 304,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9919201392936576,
    "arrivals": 619780,
    "finished_requests": 59073,
    "scheduler_time": 58.872191330691756
}
#Debug simulation 
Total elapsed time: 4.356252897065133. Arrivals time: 0.2150256191380322 Scheduler time: 4.0421125194989145 Scheduler overhead time: 0.02401987463235855 Adapter cache time: 0.03948017442598939 Engine time: 0.02457809215411544 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-32/adapters_256_slots_192_rate_1.6-0.4-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-32/adapters_256_slots_192_rate_1.6-0.4-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 66, 17280, 17280, 66, 17280, 4320, 17280, 66, 4320, 66, 17280, 4320, 4320, 4320, 4320, 17280, 66, 66, 66, 4320, 17280, 66, 17280, 17280, 4320, 4320, 4320, 66, 17280, 66, 4320, 4320, 66, 4320, 66, 66, 4320, 4320, 17280, 4320, 66, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 66, 17280, 17280, 4320, 66, 66, 17280, 4320, 66, 4320, 4320, 17280, 4320, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 4320, 66, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 66, 17280, 17280, 66, 17280, 66, 4320, 17280, 17280, 17280, 4320, 66, 17280, 4320, 66, 66, 66, 66, 66, 17280, 4320, 66, 17280, 66, 17280, 66, 66, 4320, 4320, 17280, 4320, 17280, 66, 4320, 66, 17280, 17280, 66, 17280, 4320, 66, 17280, 66, 66, 17280, 17280, 4320, 17280, 17280, 66, 17280, 4320, 4320, 66, 4320, 17280, 17280, 66, 17280, 4320, 66, 4320, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 4320, 17280, 17280, 4320, 66, 17280, 66, 4320, 4320, 66, 4320, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 4320, 17280, 4320, 66, 4320, 17280, 4320, 17280, 66, 17280, 66, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 66, 17280, 66, 17280, 4320, 4320, 66, 4320, 17280, 4320, 4320, 17280, 66, 17280, 17280, 4320, 66, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 66, 17280, 4320, 17280, 17280, 66, 17280, 4320, 4320, 17280, 66, 4320, 66, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 66, 66, 66, 66]
Prompts retrieved: 1858890 . Total input tokens: 414477948 . Total output tokens: 371780131
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.122895271051675,
    "estimated_duration": 3600.0103074238455,
    "input_throughput": 3562.833410101653,
    "output_throughput": 3140.7521185935334,
    "total_throughput": 6703.585528695186,
    "itl": 106.91558835018311,
    "ttft": 2287232.9729377213,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 290,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9477092325873722,
    "arrivals": 619780,
    "finished_requests": 51606,
    "scheduler_time": 59.98076824806202
}
#Debug simulation 
Total elapsed time: 4.123000946827233. Arrivals time: 0.20194468181580305 Scheduler time: 3.666522962041199 Scheduler overhead time: 0.04725043335929513 Adapter cache time: 0.13620881736278534 Engine time: 0.04895804449915886 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-16-16/adapters_256_slots_192_rate_1.6-0.4-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-16-16/adapters_256_slots_192_rate_1.6-0.4-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 66, 17280, 17280, 66, 17280, 4320, 17280, 66, 4320, 66, 17280, 4320, 4320, 4320, 4320, 17280, 66, 66, 66, 4320, 17280, 66, 17280, 17280, 4320, 4320, 4320, 66, 17280, 66, 4320, 4320, 66, 4320, 66, 66, 4320, 4320, 17280, 4320, 66, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 66, 17280, 17280, 4320, 66, 66, 17280, 4320, 66, 4320, 4320, 17280, 4320, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 4320, 66, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 66, 17280, 17280, 66, 17280, 66, 4320, 17280, 17280, 17280, 4320, 66, 17280, 4320, 66, 66, 66, 66, 66, 17280, 4320, 66, 17280, 66, 17280, 66, 66, 4320, 4320, 17280, 4320, 17280, 66, 4320, 66, 17280, 17280, 66, 17280, 4320, 66, 17280, 66, 66, 17280, 17280, 4320, 17280, 17280, 66, 17280, 4320, 4320, 66, 4320, 17280, 17280, 66, 17280, 4320, 66, 4320, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 4320, 17280, 17280, 4320, 66, 17280, 66, 4320, 4320, 66, 4320, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 4320, 17280, 4320, 66, 4320, 17280, 4320, 17280, 66, 17280, 66, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 66, 17280, 66, 17280, 4320, 4320, 66, 4320, 17280, 4320, 4320, 17280, 66, 17280, 17280, 4320, 66, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 66, 17280, 4320, 17280, 17280, 66, 17280, 4320, 4320, 17280, 66, 4320, 66, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 66, 66, 66, 66]
Prompts retrieved: 1858890 . Total input tokens: 414477948 . Total output tokens: 371780131
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 4.336254705674946,
    "estimated_duration": 3600.1681685389676,
    "input_throughput": 4072.3553216542778,
    "output_throughput": 3566.1356356056667,
    "total_throughput": 7638.4909572599445,
    "itl": 236.3059297926294,
    "ttft": 2207806.389137136,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 304,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9522863934049418,
    "arrivals": 619780,
    "finished_requests": 59073,
    "scheduler_time": 58.872115964250156
}
#Debug simulation 
Total elapsed time: 4.336360086686909. Arrivals time: 0.21873899269849062 Scheduler time: 4.018508814740926 Scheduler overhead time: 0.024002787191420794 Adapter cache time: 0.03941369662061334 Engine time: 0.024626838508993387 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-16-32/adapters_256_slots_192_rate_1.6-0.4-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-16-32/adapters_256_slots_192_rate_1.6-0.4-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 66, 17280, 17280, 66, 17280, 4320, 17280, 66, 4320, 66, 17280, 4320, 4320, 4320, 4320, 17280, 66, 66, 66, 4320, 17280, 66, 17280, 17280, 4320, 4320, 4320, 66, 17280, 66, 4320, 4320, 66, 4320, 66, 66, 4320, 4320, 17280, 4320, 66, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 66, 17280, 17280, 4320, 66, 66, 17280, 4320, 66, 4320, 4320, 17280, 4320, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 4320, 66, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 66, 17280, 17280, 66, 17280, 66, 4320, 17280, 17280, 17280, 4320, 66, 17280, 4320, 66, 66, 66, 66, 66, 17280, 4320, 66, 17280, 66, 17280, 66, 66, 4320, 4320, 17280, 4320, 17280, 66, 4320, 66, 17280, 17280, 66, 17280, 4320, 66, 17280, 66, 66, 17280, 17280, 4320, 17280, 17280, 66, 17280, 4320, 4320, 66, 4320, 17280, 17280, 66, 17280, 4320, 66, 4320, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 4320, 17280, 17280, 4320, 66, 17280, 66, 4320, 4320, 66, 4320, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 4320, 17280, 4320, 66, 4320, 17280, 4320, 17280, 66, 17280, 66, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 66, 17280, 66, 17280, 4320, 4320, 66, 4320, 17280, 4320, 4320, 17280, 66, 17280, 17280, 4320, 66, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 66, 17280, 4320, 17280, 17280, 66, 17280, 4320, 4320, 17280, 66, 4320, 66, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 66, 66, 66, 66]
Prompts retrieved: 1858890 . Total input tokens: 414477948 . Total output tokens: 371780131
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 4.154810798820108,
    "estimated_duration": 3600.047831396219,
    "input_throughput": 3562.3982237552973,
    "output_throughput": 3140.3671644038573,
    "total_throughput": 6702.765388159154,
    "itl": 106.918093070217,
    "ttft": 2287271.378261573,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 290,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9596558422967841,
    "arrivals": 619780,
    "finished_requests": 51602,
    "scheduler_time": 59.979528977715844
}
#Debug simulation 
Total elapsed time: 4.154910795856267. Arrivals time: 0.20474743423983455 Scheduler time: 3.692928268574178 Scheduler overhead time: 0.047514140605926514 Adapter cache time: 0.1382102477364242 Engine time: 0.049251335207372904 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_16-16-16/adapters_256_slots_192_rate_1.6-0.4-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_16-16-16/adapters_256_slots_192_rate_1.6-0.4-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 66, 17280, 17280, 66, 17280, 4320, 17280, 66, 4320, 66, 17280, 4320, 4320, 4320, 4320, 17280, 66, 66, 66, 4320, 17280, 66, 17280, 17280, 4320, 4320, 4320, 66, 17280, 66, 4320, 4320, 66, 4320, 66, 66, 4320, 4320, 17280, 4320, 66, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 66, 17280, 17280, 4320, 66, 66, 17280, 4320, 66, 4320, 4320, 17280, 4320, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 4320, 66, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 66, 17280, 17280, 66, 17280, 66, 4320, 17280, 17280, 17280, 4320, 66, 17280, 4320, 66, 66, 66, 66, 66, 17280, 4320, 66, 17280, 66, 17280, 66, 66, 4320, 4320, 17280, 4320, 17280, 66, 4320, 66, 17280, 17280, 66, 17280, 4320, 66, 17280, 66, 66, 17280, 17280, 4320, 17280, 17280, 66, 17280, 4320, 4320, 66, 4320, 17280, 17280, 66, 17280, 4320, 66, 4320, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 4320, 17280, 17280, 4320, 66, 17280, 66, 4320, 4320, 66, 4320, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 4320, 17280, 4320, 66, 4320, 17280, 4320, 17280, 66, 17280, 66, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 66, 17280, 66, 17280, 4320, 4320, 66, 4320, 17280, 4320, 4320, 17280, 66, 17280, 17280, 4320, 66, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 66, 17280, 4320, 17280, 17280, 66, 17280, 4320, 4320, 17280, 66, 4320, 66, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 66, 66, 66, 66]
Prompts retrieved: 1858890 . Total input tokens: 414477948 . Total output tokens: 371780131
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.3713970188982785,
    "estimated_duration": 3600.124740849701,
    "input_throughput": 4072.4044457803075,
    "output_throughput": 3566.1786532901674,
    "total_throughput": 7638.583099070475,
    "itl": 236.32345206791533,
    "ttft": 2207783.2946026106,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 304,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9089752896502626,
    "arrivals": 619780,
    "finished_requests": 59073,
    "scheduler_time": 58.87179500703628
}
#Debug simulation 
Total elapsed time: 4.3715005330741405. Arrivals time: 0.2204718985594809 Scheduler time: 4.051923831924796 Scheduler overhead time: 0.02397640235722065 Adapter cache time: 0.039551820140331984 Engine time: 0.024530974682420492 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_16-16-32/adapters_256_slots_192_rate_1.6-0.4-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_16-16-32/adapters_256_slots_192_rate_1.6-0.4-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 66, 17280, 17280, 66, 17280, 4320, 17280, 66, 4320, 66, 17280, 4320, 4320, 4320, 4320, 17280, 66, 66, 66, 4320, 17280, 66, 17280, 17280, 4320, 4320, 4320, 66, 17280, 66, 4320, 4320, 66, 4320, 66, 66, 4320, 4320, 17280, 4320, 66, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 66, 17280, 17280, 4320, 66, 66, 17280, 4320, 66, 4320, 4320, 17280, 4320, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 4320, 66, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 66, 17280, 17280, 66, 17280, 66, 4320, 17280, 17280, 17280, 4320, 66, 17280, 4320, 66, 66, 66, 66, 66, 17280, 4320, 66, 17280, 66, 17280, 66, 66, 4320, 4320, 17280, 4320, 17280, 66, 4320, 66, 17280, 17280, 66, 17280, 4320, 66, 17280, 66, 66, 17280, 17280, 4320, 17280, 17280, 66, 17280, 4320, 4320, 66, 4320, 17280, 17280, 66, 17280, 4320, 66, 4320, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 4320, 17280, 17280, 4320, 66, 17280, 66, 4320, 4320, 66, 4320, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 4320, 17280, 4320, 66, 4320, 17280, 4320, 17280, 66, 17280, 66, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 66, 17280, 66, 17280, 4320, 4320, 66, 4320, 17280, 4320, 4320, 17280, 66, 17280, 17280, 4320, 66, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 66, 17280, 4320, 17280, 17280, 66, 17280, 4320, 4320, 17280, 66, 4320, 66, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 66, 66, 66, 66]
Prompts retrieved: 1858890 . Total input tokens: 414477948 . Total output tokens: 371780131
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.139176333788782,
    "estimated_duration": 3600.0601983748006,
    "input_throughput": 3562.3859861536725,
    "output_throughput": 3140.356376569399,
    "total_throughput": 6702.742362723071,
    "itl": 106.91848824287494,
    "ttft": 2287277.928402668,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 290,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9719797133654409,
    "arrivals": 619780,
    "finished_requests": 51602,
    "scheduler_time": 59.979572085234174
}
#Debug simulation 
Total elapsed time: 4.139293945860118. Arrivals time: 0.20248092338442802 Scheduler time: 3.679746917914599 Scheduler overhead time: 0.04744859132915735 Adapter cache time: 0.13781315553933382 Engine time: 0.04960757726803422 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-8/adapters_256_slots_192_rate_1.6-0.4-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-8/adapters_256_slots_192_rate_1.6-0.4-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 33, 17280, 17280, 33, 17280, 4320, 17280, 33, 4320, 33, 17280, 4320, 4320, 4320, 4320, 17280, 33, 33, 33, 4320, 17280, 33, 17280, 17280, 4320, 4320, 4320, 33, 17280, 33, 4320, 4320, 33, 4320, 33, 33, 4320, 4320, 17280, 4320, 33, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 33, 17280, 17280, 4320, 33, 33, 17280, 4320, 33, 4320, 4320, 17280, 4320, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 4320, 33, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 33, 17280, 17280, 33, 17280, 33, 4320, 17280, 17280, 17280, 4320, 33, 17280, 4320, 33, 33, 33, 33, 33, 17280, 4320, 33, 17280, 33, 17280, 33, 33, 4320, 4320, 17280, 4320, 17280, 33, 4320, 33, 17280, 17280, 33, 17280, 4320, 33, 17280, 33, 33, 17280, 17280, 4320, 17280, 17280, 33, 17280, 4320, 4320, 33, 4320, 17280, 17280, 33, 17280, 4320, 33, 4320, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 4320, 17280, 17280, 4320, 33, 17280, 33, 4320, 4320, 33, 4320, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 4320, 17280, 4320, 33, 4320, 17280, 4320, 17280, 33, 17280, 33, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 33, 17280, 33, 17280, 4320, 4320, 33, 4320, 17280, 4320, 4320, 17280, 33, 17280, 17280, 4320, 33, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 33, 17280, 4320, 17280, 17280, 33, 17280, 4320, 4320, 17280, 33, 4320, 33, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 33, 33, 33, 33]
Prompts retrieved: 1856085 . Total input tokens: 413843494 . Total output tokens: 371231399
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.406782802194357,
    "estimated_duration": 3600.2057516147797,
    "input_throughput": 4072.0469915988942,
    "output_throughput": 3581.9852779847047,
    "total_throughput": 7654.032269583599,
    "itl": 238.8574331719499,
    "ttft": 2199161.451676074,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 244,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.746759009519591,
    "arrivals": 618816,
    "finished_requests": 59307,
    "scheduler_time": 59.02894351975587
}
#Debug simulation 
Total elapsed time: 4.406881932169199. Arrivals time: 0.22444026125594974 Scheduler time: 4.086448765359819 Scheduler overhead time: 0.023722293321043253 Adapter cache time: 0.0368773527443409 Engine time: 0.024488787166774273 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-16/adapters_256_slots_192_rate_1.6-0.4-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-16/adapters_256_slots_192_rate_1.6-0.4-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 33, 17280, 17280, 33, 17280, 4320, 17280, 33, 4320, 33, 17280, 4320, 4320, 4320, 4320, 17280, 33, 33, 33, 4320, 17280, 33, 17280, 17280, 4320, 4320, 4320, 33, 17280, 33, 4320, 4320, 33, 4320, 33, 33, 4320, 4320, 17280, 4320, 33, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 33, 17280, 17280, 4320, 33, 33, 17280, 4320, 33, 4320, 4320, 17280, 4320, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 4320, 33, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 33, 17280, 17280, 33, 17280, 33, 4320, 17280, 17280, 17280, 4320, 33, 17280, 4320, 33, 33, 33, 33, 33, 17280, 4320, 33, 17280, 33, 17280, 33, 33, 4320, 4320, 17280, 4320, 17280, 33, 4320, 33, 17280, 17280, 33, 17280, 4320, 33, 17280, 33, 33, 17280, 17280, 4320, 17280, 17280, 33, 17280, 4320, 4320, 33, 4320, 17280, 17280, 33, 17280, 4320, 33, 4320, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 4320, 17280, 17280, 4320, 33, 17280, 33, 4320, 4320, 33, 4320, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 4320, 17280, 4320, 33, 4320, 17280, 4320, 17280, 33, 17280, 33, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 33, 17280, 33, 17280, 4320, 4320, 33, 4320, 17280, 4320, 4320, 17280, 33, 17280, 17280, 4320, 33, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 33, 17280, 4320, 17280, 17280, 33, 17280, 4320, 4320, 17280, 33, 4320, 33, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 33, 33, 33, 33]
Prompts retrieved: 1856085 . Total input tokens: 413843494 . Total output tokens: 371231399
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.346762757282704,
    "estimated_duration": 3600.2103128528133,
    "input_throughput": 4065.4030537460917,
    "output_throughput": 3576.454951543384,
    "total_throughput": 7641.858005289476,
    "itl": 235.5873540486402,
    "ttft": 2200291.7234575325,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 244,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.796173308861911,
    "arrivals": 618816,
    "finished_requests": 59204,
    "scheduler_time": 59.030461229788436
}
#Debug simulation 
Total elapsed time: 4.3468634290620685. Arrivals time: 0.22081578895449638 Scheduler time: 4.030823873355985 Scheduler overhead time: 0.024043112061917782 Adapter cache time: 0.03546041063964367 Engine time: 0.0246770940721035 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-32/adapters_256_slots_192_rate_1.6-0.4-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-32/adapters_256_slots_192_rate_1.6-0.4-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 33, 17280, 17280, 33, 17280, 4320, 17280, 33, 4320, 33, 17280, 4320, 4320, 4320, 4320, 17280, 33, 33, 33, 4320, 17280, 33, 17280, 17280, 4320, 4320, 4320, 33, 17280, 33, 4320, 4320, 33, 4320, 33, 33, 4320, 4320, 17280, 4320, 33, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 33, 17280, 17280, 4320, 33, 33, 17280, 4320, 33, 4320, 4320, 17280, 4320, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 4320, 33, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 33, 17280, 17280, 33, 17280, 33, 4320, 17280, 17280, 17280, 4320, 33, 17280, 4320, 33, 33, 33, 33, 33, 17280, 4320, 33, 17280, 33, 17280, 33, 33, 4320, 4320, 17280, 4320, 17280, 33, 4320, 33, 17280, 17280, 33, 17280, 4320, 33, 17280, 33, 33, 17280, 17280, 4320, 17280, 17280, 33, 17280, 4320, 4320, 33, 4320, 17280, 17280, 33, 17280, 4320, 33, 4320, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 4320, 17280, 17280, 4320, 33, 17280, 33, 4320, 4320, 33, 4320, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 4320, 17280, 4320, 33, 4320, 17280, 4320, 17280, 33, 17280, 33, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 33, 17280, 33, 17280, 4320, 4320, 33, 4320, 17280, 4320, 4320, 17280, 33, 17280, 17280, 4320, 33, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 33, 17280, 4320, 17280, 17280, 33, 17280, 4320, 4320, 17280, 33, 4320, 33, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 33, 33, 33, 33]
Prompts retrieved: 1856085 . Total input tokens: 413843494 . Total output tokens: 371231399
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.138135016895831,
    "estimated_duration": 3600.097312128034,
    "input_throughput": 3552.932015729108,
    "output_throughput": 3143.2100354284985,
    "total_throughput": 6696.142051157607,
    "itl": 107.42454463417818,
    "ttft": 2283541.5023942078,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 237,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7742618237994647,
    "arrivals": 618816,
    "finished_requests": 51780,
    "scheduler_time": 59.92401262026863
}
#Debug simulation 
Total elapsed time: 4.138235502876341. Arrivals time: 0.20499550132080913 Scheduler time: 3.6851746421307325 Scheduler overhead time: 0.04719909094274044 Adapter cache time: 0.13002015184611082 Engine time: 0.04871286638081074 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-16-16/adapters_256_slots_192_rate_1.6-0.4-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-16-16/adapters_256_slots_192_rate_1.6-0.4-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 33, 17280, 17280, 33, 17280, 4320, 17280, 33, 4320, 33, 17280, 4320, 4320, 4320, 4320, 17280, 33, 33, 33, 4320, 17280, 33, 17280, 17280, 4320, 4320, 4320, 33, 17280, 33, 4320, 4320, 33, 4320, 33, 33, 4320, 4320, 17280, 4320, 33, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 33, 17280, 17280, 4320, 33, 33, 17280, 4320, 33, 4320, 4320, 17280, 4320, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 4320, 33, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 33, 17280, 17280, 33, 17280, 33, 4320, 17280, 17280, 17280, 4320, 33, 17280, 4320, 33, 33, 33, 33, 33, 17280, 4320, 33, 17280, 33, 17280, 33, 33, 4320, 4320, 17280, 4320, 17280, 33, 4320, 33, 17280, 17280, 33, 17280, 4320, 33, 17280, 33, 33, 17280, 17280, 4320, 17280, 17280, 33, 17280, 4320, 4320, 33, 4320, 17280, 17280, 33, 17280, 4320, 33, 4320, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 4320, 17280, 17280, 4320, 33, 17280, 33, 4320, 4320, 33, 4320, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 4320, 17280, 4320, 33, 4320, 17280, 4320, 17280, 33, 17280, 33, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 33, 17280, 33, 17280, 4320, 4320, 33, 4320, 17280, 4320, 4320, 17280, 33, 17280, 17280, 4320, 33, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 33, 17280, 4320, 17280, 17280, 33, 17280, 4320, 4320, 17280, 33, 4320, 33, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 33, 33, 33, 33]
Prompts retrieved: 1856085 . Total input tokens: 413843494 . Total output tokens: 371231399
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 4.42180484207347,
    "estimated_duration": 3600.1991728554285,
    "input_throughput": 4065.415633211064,
    "output_throughput": 3576.4660180696774,
    "total_throughput": 7641.881651280741,
    "itl": 235.55757419321682,
    "ttft": 2200285.115941974,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 244,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7643028740235626,
    "arrivals": 618816,
    "finished_requests": 59204,
    "scheduler_time": 59.03087304868372
}
#Debug simulation 
Total elapsed time: 4.42190555203706. Arrivals time: 0.26206021569669247 Scheduler time: 4.064630570821464 Scheduler overhead time: 0.02412758255377412 Adapter cache time: 0.03514798590913415 Engine time: 0.02476581884548068 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-16-32/adapters_256_slots_192_rate_1.6-0.4-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-16-32/adapters_256_slots_192_rate_1.6-0.4-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 33, 17280, 17280, 33, 17280, 4320, 17280, 33, 4320, 33, 17280, 4320, 4320, 4320, 4320, 17280, 33, 33, 33, 4320, 17280, 33, 17280, 17280, 4320, 4320, 4320, 33, 17280, 33, 4320, 4320, 33, 4320, 33, 33, 4320, 4320, 17280, 4320, 33, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 33, 17280, 17280, 4320, 33, 33, 17280, 4320, 33, 4320, 4320, 17280, 4320, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 4320, 33, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 33, 17280, 17280, 33, 17280, 33, 4320, 17280, 17280, 17280, 4320, 33, 17280, 4320, 33, 33, 33, 33, 33, 17280, 4320, 33, 17280, 33, 17280, 33, 33, 4320, 4320, 17280, 4320, 17280, 33, 4320, 33, 17280, 17280, 33, 17280, 4320, 33, 17280, 33, 33, 17280, 17280, 4320, 17280, 17280, 33, 17280, 4320, 4320, 33, 4320, 17280, 17280, 33, 17280, 4320, 33, 4320, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 4320, 17280, 17280, 4320, 33, 17280, 33, 4320, 4320, 33, 4320, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 4320, 17280, 4320, 33, 4320, 17280, 4320, 17280, 33, 17280, 33, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 33, 17280, 33, 17280, 4320, 4320, 33, 4320, 17280, 4320, 4320, 17280, 33, 17280, 17280, 4320, 33, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 33, 17280, 4320, 17280, 17280, 33, 17280, 4320, 4320, 17280, 33, 4320, 33, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 33, 33, 33, 33]
Prompts retrieved: 1856085 . Total input tokens: 413843494 . Total output tokens: 371231399
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 4.174627739004791,
    "estimated_duration": 3600.106911740967,
    "input_throughput": 3552.92254190709,
    "output_throughput": 3143.20165412193,
    "total_throughput": 6696.12419602902,
    "itl": 107.42482557322356,
    "ttft": 2283547.044770896,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 237,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7838191115669939,
    "arrivals": 618816,
    "finished_requests": 51780,
    "scheduler_time": 59.924054945436346
}
#Debug simulation 
Total elapsed time: 4.174739194102585. Arrivals time: 0.21083972277119756 Scheduler time: 3.714852511882782 Scheduler overhead time: 0.04747810214757919 Adapter cache time: 0.12997152376919985 Engine time: 0.04933854239061475 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_16-16-16/adapters_256_slots_192_rate_1.6-0.4-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_16-16-16/adapters_256_slots_192_rate_1.6-0.4-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 33, 17280, 17280, 33, 17280, 4320, 17280, 33, 4320, 33, 17280, 4320, 4320, 4320, 4320, 17280, 33, 33, 33, 4320, 17280, 33, 17280, 17280, 4320, 4320, 4320, 33, 17280, 33, 4320, 4320, 33, 4320, 33, 33, 4320, 4320, 17280, 4320, 33, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 33, 17280, 17280, 4320, 33, 33, 17280, 4320, 33, 4320, 4320, 17280, 4320, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 4320, 33, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 33, 17280, 17280, 33, 17280, 33, 4320, 17280, 17280, 17280, 4320, 33, 17280, 4320, 33, 33, 33, 33, 33, 17280, 4320, 33, 17280, 33, 17280, 33, 33, 4320, 4320, 17280, 4320, 17280, 33, 4320, 33, 17280, 17280, 33, 17280, 4320, 33, 17280, 33, 33, 17280, 17280, 4320, 17280, 17280, 33, 17280, 4320, 4320, 33, 4320, 17280, 17280, 33, 17280, 4320, 33, 4320, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 4320, 17280, 17280, 4320, 33, 17280, 33, 4320, 4320, 33, 4320, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 4320, 17280, 4320, 33, 4320, 17280, 4320, 17280, 33, 17280, 33, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 33, 17280, 33, 17280, 4320, 4320, 33, 4320, 17280, 4320, 4320, 17280, 33, 17280, 17280, 4320, 33, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 33, 17280, 4320, 17280, 17280, 33, 17280, 4320, 4320, 17280, 33, 4320, 33, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 33, 33, 33, 33]
Prompts retrieved: 1856085 . Total input tokens: 413843494 . Total output tokens: 371231399
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.32881242595613,
    "estimated_duration": 3600.164246348356,
    "input_throughput": 4065.455073291613,
    "output_throughput": 3576.50071467159,
    "total_throughput": 7641.955787963203,
    "itl": 235.55616918464983,
    "ttft": 2200264.852314801,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 244,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7295722719561318,
    "arrivals": 618816,
    "finished_requests": 59204,
    "scheduler_time": 59.03079875411786
}
#Debug simulation 
Total elapsed time: 4.328938373830169. Arrivals time: 0.22212155861780047 Scheduler time: 4.011905516497791 Scheduler overhead time: 0.023970293812453747 Adapter cache time: 0.035082499496638775 Engine time: 0.024776167701929808 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_16-16-32/adapters_256_slots_192_rate_1.6-0.4-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_16-16-32/adapters_256_slots_192_rate_1.6-0.4-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 33, 17280, 17280, 33, 17280, 4320, 17280, 33, 4320, 33, 17280, 4320, 4320, 4320, 4320, 17280, 33, 33, 33, 4320, 17280, 33, 17280, 17280, 4320, 4320, 4320, 33, 17280, 33, 4320, 4320, 33, 4320, 33, 33, 4320, 4320, 17280, 4320, 33, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 33, 17280, 17280, 4320, 33, 33, 17280, 4320, 33, 4320, 4320, 17280, 4320, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 4320, 33, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 33, 17280, 17280, 33, 17280, 33, 4320, 17280, 17280, 17280, 4320, 33, 17280, 4320, 33, 33, 33, 33, 33, 17280, 4320, 33, 17280, 33, 17280, 33, 33, 4320, 4320, 17280, 4320, 17280, 33, 4320, 33, 17280, 17280, 33, 17280, 4320, 33, 17280, 33, 33, 17280, 17280, 4320, 17280, 17280, 33, 17280, 4320, 4320, 33, 4320, 17280, 17280, 33, 17280, 4320, 33, 4320, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 4320, 17280, 17280, 4320, 33, 17280, 33, 4320, 4320, 33, 4320, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 4320, 17280, 4320, 33, 4320, 17280, 4320, 17280, 33, 17280, 33, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 33, 17280, 33, 17280, 4320, 4320, 33, 4320, 17280, 4320, 4320, 17280, 33, 17280, 17280, 4320, 33, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 33, 17280, 4320, 17280, 17280, 33, 17280, 4320, 4320, 17280, 33, 4320, 33, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 33, 33, 33, 33]
Prompts retrieved: 1856085 . Total input tokens: 413843494 . Total output tokens: 371231399
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.169953915756196,
    "estimated_duration": 3600.117474958662,
    "input_throughput": 3552.9121171655293,
    "output_throughput": 3143.192431555288,
    "total_throughput": 6696.104548720818,
    "itl": 107.42520102034133,
    "ttft": 2283553.1402035975,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 237,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7940051682665975,
    "arrivals": 618816,
    "finished_requests": 51780,
    "scheduler_time": 59.924101025886976
}
#Debug simulation 
Total elapsed time: 4.170051916036755. Arrivals time: 0.2427447703666985 Scheduler time: 3.6786077739670873 Scheduler overhead time: 0.04737430438399315 Adapter cache time: 0.13018466206267476 Engine time: 0.04894350841641426 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-8-8/adapters_256_slots_192_rate_1.6-0.1-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-8-8/adapters_256_slots_192_rate_1.6-0.1-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 540, 17280, 17280, 540, 17280, 1080, 17280, 540, 1080, 540, 17280, 1080, 1080, 1080, 1080, 17280, 540, 540, 540, 1080, 17280, 540, 17280, 17280, 1080, 1080, 1080, 540, 17280, 540, 1080, 1080, 540, 1080, 540, 540, 1080, 1080, 17280, 1080, 540, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 540, 17280, 17280, 1080, 540, 540, 17280, 1080, 540, 1080, 1080, 17280, 1080, 540, 540, 17280, 17280, 17280, 17280, 17280, 17280, 540, 1080, 540, 1080, 540, 540, 540, 1080, 1080, 1080, 540, 540, 17280, 17280, 540, 17280, 540, 1080, 17280, 17280, 17280, 1080, 540, 17280, 1080, 540, 540, 540, 540, 540, 17280, 1080, 540, 17280, 540, 17280, 540, 540, 1080, 1080, 17280, 1080, 17280, 540, 1080, 540, 17280, 17280, 540, 17280, 1080, 540, 17280, 540, 540, 17280, 17280, 1080, 17280, 17280, 540, 17280, 1080, 1080, 540, 1080, 17280, 17280, 540, 17280, 1080, 540, 1080, 17280, 540, 540, 540, 540, 540, 540, 17280, 540, 540, 540, 17280, 540, 1080, 17280, 17280, 1080, 540, 17280, 540, 1080, 1080, 540, 1080, 540, 17280, 540, 540, 17280, 540, 17280, 17280, 1080, 17280, 1080, 540, 1080, 17280, 1080, 17280, 540, 17280, 540, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 540, 17280, 540, 17280, 1080, 1080, 540, 1080, 17280, 1080, 1080, 17280, 540, 17280, 17280, 1080, 540, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 540, 17280, 1080, 17280, 17280, 540, 17280, 1080, 1080, 17280, 540, 1080, 540, 540, 540, 540, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 540, 540, 540, 540]
Prompts retrieved: 1623780 . Total input tokens: 362007641 . Total output tokens: 324668356
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.6769907041452825,
    "estimated_duration": 3600.131152791803,
    "input_throughput": 4299.211429560684,
    "output_throughput": 3791.5963115439868,
    "total_throughput": 8090.807741104671,
    "itl": 226.20343315400876,
    "ttft": 2148286.1233219886,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1887,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.775140372801271,
    "arrivals": 541365,
    "finished_requests": 62610,
    "scheduler_time": 62.35449524889775
}
#Debug simulation 
Total elapsed time: 4.677091719117016. Arrivals time: 0.28249128302559257 Scheduler time: 4.261818774044514 Scheduler overhead time: 0.025184812489897013 Adapter cache time: 0.07025986723601818 Engine time: 0.025720888283103704 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-8-16/adapters_256_slots_192_rate_1.6-0.1-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-8-16/adapters_256_slots_192_rate_1.6-0.1-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 540, 17280, 17280, 540, 17280, 1080, 17280, 540, 1080, 540, 17280, 1080, 1080, 1080, 1080, 17280, 540, 540, 540, 1080, 17280, 540, 17280, 17280, 1080, 1080, 1080, 540, 17280, 540, 1080, 1080, 540, 1080, 540, 540, 1080, 1080, 17280, 1080, 540, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 540, 17280, 17280, 1080, 540, 540, 17280, 1080, 540, 1080, 1080, 17280, 1080, 540, 540, 17280, 17280, 17280, 17280, 17280, 17280, 540, 1080, 540, 1080, 540, 540, 540, 1080, 1080, 1080, 540, 540, 17280, 17280, 540, 17280, 540, 1080, 17280, 17280, 17280, 1080, 540, 17280, 1080, 540, 540, 540, 540, 540, 17280, 1080, 540, 17280, 540, 17280, 540, 540, 1080, 1080, 17280, 1080, 17280, 540, 1080, 540, 17280, 17280, 540, 17280, 1080, 540, 17280, 540, 540, 17280, 17280, 1080, 17280, 17280, 540, 17280, 1080, 1080, 540, 1080, 17280, 17280, 540, 17280, 1080, 540, 1080, 17280, 540, 540, 540, 540, 540, 540, 17280, 540, 540, 540, 17280, 540, 1080, 17280, 17280, 1080, 540, 17280, 540, 1080, 1080, 540, 1080, 540, 17280, 540, 540, 17280, 540, 17280, 17280, 1080, 17280, 1080, 540, 1080, 17280, 1080, 17280, 540, 17280, 540, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 540, 17280, 540, 17280, 1080, 1080, 540, 1080, 17280, 1080, 1080, 17280, 540, 17280, 17280, 1080, 540, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 540, 17280, 1080, 17280, 17280, 540, 17280, 1080, 1080, 17280, 540, 1080, 540, 540, 540, 540, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 540, 540, 540, 540]
Prompts retrieved: 1623780 . Total input tokens: 362007641 . Total output tokens: 324668356
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.677994559053332,
    "estimated_duration": 3600.132173021613,
    "input_throughput": 4299.292152657052,
    "output_throughput": 3792.064942032905,
    "total_throughput": 8091.357094689956,
    "itl": 223.19634875997767,
    "ttft": 2148693.325346115,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1891,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.170649590168423,
    "arrivals": 541365,
    "finished_requests": 62608,
    "scheduler_time": 62.439459600889414
}
#Debug simulation 
Total elapsed time: 4.678090700879693. Arrivals time: 0.2829268928617239 Scheduler time: 4.261013860348612 Scheduler overhead time: 0.02557164942845702 Adapter cache time: 0.07076565828174353 Engine time: 0.026012673042714596 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-8-32/adapters_256_slots_192_rate_1.6-0.1-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-8-32/adapters_256_slots_192_rate_1.6-0.1-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 540, 17280, 17280, 540, 17280, 1080, 17280, 540, 1080, 540, 17280, 1080, 1080, 1080, 1080, 17280, 540, 540, 540, 1080, 17280, 540, 17280, 17280, 1080, 1080, 1080, 540, 17280, 540, 1080, 1080, 540, 1080, 540, 540, 1080, 1080, 17280, 1080, 540, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 540, 17280, 17280, 1080, 540, 540, 17280, 1080, 540, 1080, 1080, 17280, 1080, 540, 540, 17280, 17280, 17280, 17280, 17280, 17280, 540, 1080, 540, 1080, 540, 540, 540, 1080, 1080, 1080, 540, 540, 17280, 17280, 540, 17280, 540, 1080, 17280, 17280, 17280, 1080, 540, 17280, 1080, 540, 540, 540, 540, 540, 17280, 1080, 540, 17280, 540, 17280, 540, 540, 1080, 1080, 17280, 1080, 17280, 540, 1080, 540, 17280, 17280, 540, 17280, 1080, 540, 17280, 540, 540, 17280, 17280, 1080, 17280, 17280, 540, 17280, 1080, 1080, 540, 1080, 17280, 17280, 540, 17280, 1080, 540, 1080, 17280, 540, 540, 540, 540, 540, 540, 17280, 540, 540, 540, 17280, 540, 1080, 17280, 17280, 1080, 540, 17280, 540, 1080, 1080, 540, 1080, 540, 17280, 540, 540, 17280, 540, 17280, 17280, 1080, 17280, 1080, 540, 1080, 17280, 1080, 17280, 540, 17280, 540, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 540, 17280, 540, 17280, 1080, 1080, 540, 1080, 17280, 1080, 1080, 17280, 540, 17280, 17280, 1080, 540, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 540, 17280, 1080, 17280, 17280, 540, 17280, 1080, 1080, 17280, 540, 1080, 540, 540, 540, 540, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 540, 540, 540, 540]
Prompts retrieved: 1623780 . Total input tokens: 362007641 . Total output tokens: 324668356
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.5202326201833785,
    "estimated_duration": 3600.0224896539257,
    "input_throughput": 3890.837082339038,
    "output_throughput": 3443.789319547225,
    "total_throughput": 7334.626401886263,
    "itl": 98.05848840635275,
    "ttft": 2218387.7498393585,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1711,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.591922894008409,
    "arrivals": 541365,
    "finished_requests": 56561,
    "scheduler_time": 65.562521788112
}
#Debug simulation 
Total elapsed time: 4.520333702210337. Arrivals time: 0.2672793362289667 Scheduler time: 4.008381505962461 Scheduler overhead time: 0.0514892372302711 Adapter cache time: 0.11519263265654445 Engine time: 0.053722672164440155 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-16-16/adapters_256_slots_192_rate_1.6-0.1-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-16-16/adapters_256_slots_192_rate_1.6-0.1-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 540, 17280, 17280, 540, 17280, 1080, 17280, 540, 1080, 540, 17280, 1080, 1080, 1080, 1080, 17280, 540, 540, 540, 1080, 17280, 540, 17280, 17280, 1080, 1080, 1080, 540, 17280, 540, 1080, 1080, 540, 1080, 540, 540, 1080, 1080, 17280, 1080, 540, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 540, 17280, 17280, 1080, 540, 540, 17280, 1080, 540, 1080, 1080, 17280, 1080, 540, 540, 17280, 17280, 17280, 17280, 17280, 17280, 540, 1080, 540, 1080, 540, 540, 540, 1080, 1080, 1080, 540, 540, 17280, 17280, 540, 17280, 540, 1080, 17280, 17280, 17280, 1080, 540, 17280, 1080, 540, 540, 540, 540, 540, 17280, 1080, 540, 17280, 540, 17280, 540, 540, 1080, 1080, 17280, 1080, 17280, 540, 1080, 540, 17280, 17280, 540, 17280, 1080, 540, 17280, 540, 540, 17280, 17280, 1080, 17280, 17280, 540, 17280, 1080, 1080, 540, 1080, 17280, 17280, 540, 17280, 1080, 540, 1080, 17280, 540, 540, 540, 540, 540, 540, 17280, 540, 540, 540, 17280, 540, 1080, 17280, 17280, 1080, 540, 17280, 540, 1080, 1080, 540, 1080, 540, 17280, 540, 540, 17280, 540, 17280, 17280, 1080, 17280, 1080, 540, 1080, 17280, 1080, 17280, 540, 17280, 540, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 540, 17280, 540, 17280, 1080, 1080, 540, 1080, 17280, 1080, 1080, 17280, 540, 17280, 17280, 1080, 540, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 540, 17280, 1080, 17280, 17280, 540, 17280, 1080, 1080, 17280, 540, 1080, 540, 540, 540, 540, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 540, 540, 540, 540]
Prompts retrieved: 1623780 . Total input tokens: 362007641 . Total output tokens: 324668356
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 4.704659012146294,
    "estimated_duration": 3600.1942919399166,
    "input_throughput": 4299.452680832795,
    "output_throughput": 3792.3033850051597,
    "total_throughput": 8091.756065837954,
    "itl": 223.19234744452885,
    "ttft": 2148735.0298697106,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1892,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.931751211946656,
    "arrivals": 541365,
    "finished_requests": 62613,
    "scheduler_time": 62.44344067747075
}
#Debug simulation 
Total elapsed time: 4.704786761198193. Arrivals time: 0.3111411025747657 Scheduler time: 4.259579276666045 Scheduler overhead time: 0.025413804221898317 Adapter cache time: 0.07071326719596982 Engine time: 0.02608578186482191 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-16-32/adapters_256_slots_192_rate_1.6-0.1-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-16-32/adapters_256_slots_192_rate_1.6-0.1-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 540, 17280, 17280, 540, 17280, 1080, 17280, 540, 1080, 540, 17280, 1080, 1080, 1080, 1080, 17280, 540, 540, 540, 1080, 17280, 540, 17280, 17280, 1080, 1080, 1080, 540, 17280, 540, 1080, 1080, 540, 1080, 540, 540, 1080, 1080, 17280, 1080, 540, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 540, 17280, 17280, 1080, 540, 540, 17280, 1080, 540, 1080, 1080, 17280, 1080, 540, 540, 17280, 17280, 17280, 17280, 17280, 17280, 540, 1080, 540, 1080, 540, 540, 540, 1080, 1080, 1080, 540, 540, 17280, 17280, 540, 17280, 540, 1080, 17280, 17280, 17280, 1080, 540, 17280, 1080, 540, 540, 540, 540, 540, 17280, 1080, 540, 17280, 540, 17280, 540, 540, 1080, 1080, 17280, 1080, 17280, 540, 1080, 540, 17280, 17280, 540, 17280, 1080, 540, 17280, 540, 540, 17280, 17280, 1080, 17280, 17280, 540, 17280, 1080, 1080, 540, 1080, 17280, 17280, 540, 17280, 1080, 540, 1080, 17280, 540, 540, 540, 540, 540, 540, 17280, 540, 540, 540, 17280, 540, 1080, 17280, 17280, 1080, 540, 17280, 540, 1080, 1080, 540, 1080, 540, 17280, 540, 540, 17280, 540, 17280, 17280, 1080, 17280, 1080, 540, 1080, 17280, 1080, 17280, 540, 17280, 540, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 540, 17280, 540, 17280, 1080, 1080, 540, 1080, 17280, 1080, 1080, 17280, 540, 17280, 17280, 1080, 540, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 540, 17280, 1080, 17280, 17280, 540, 17280, 1080, 1080, 17280, 540, 1080, 540, 540, 540, 540, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 540, 540, 540, 540]
Prompts retrieved: 1623780 . Total input tokens: 362007641 . Total output tokens: 324668356
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 4.523552557919174,
    "estimated_duration": 3600.0937447364577,
    "input_throughput": 3890.993399958101,
    "output_throughput": 3443.883653898465,
    "total_throughput": 7334.877053856566,
    "itl": 98.05677030812794,
    "ttft": 2218518.6361004133,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1712,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.66325071888037,
    "arrivals": 541365,
    "finished_requests": 56565,
    "scheduler_time": 65.56081018183052
}
#Debug simulation 
Total elapsed time: 4.523648862261325. Arrivals time: 0.26795803708955646 Scheduler time: 4.009509980678558 Scheduler overhead time: 0.054312537889927626 Adapter cache time: 0.11460981518030167 Engine time: 0.053138080053031445 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_16-16-16/adapters_256_slots_192_rate_1.6-0.1-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_16-16-16/adapters_256_slots_192_rate_1.6-0.1-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 540, 17280, 17280, 540, 17280, 1080, 17280, 540, 1080, 540, 17280, 1080, 1080, 1080, 1080, 17280, 540, 540, 540, 1080, 17280, 540, 17280, 17280, 1080, 1080, 1080, 540, 17280, 540, 1080, 1080, 540, 1080, 540, 540, 1080, 1080, 17280, 1080, 540, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 540, 17280, 17280, 1080, 540, 540, 17280, 1080, 540, 1080, 1080, 17280, 1080, 540, 540, 17280, 17280, 17280, 17280, 17280, 17280, 540, 1080, 540, 1080, 540, 540, 540, 1080, 1080, 1080, 540, 540, 17280, 17280, 540, 17280, 540, 1080, 17280, 17280, 17280, 1080, 540, 17280, 1080, 540, 540, 540, 540, 540, 17280, 1080, 540, 17280, 540, 17280, 540, 540, 1080, 1080, 17280, 1080, 17280, 540, 1080, 540, 17280, 17280, 540, 17280, 1080, 540, 17280, 540, 540, 17280, 17280, 1080, 17280, 17280, 540, 17280, 1080, 1080, 540, 1080, 17280, 17280, 540, 17280, 1080, 540, 1080, 17280, 540, 540, 540, 540, 540, 540, 17280, 540, 540, 540, 17280, 540, 1080, 17280, 17280, 1080, 540, 17280, 540, 1080, 1080, 540, 1080, 540, 17280, 540, 540, 17280, 540, 17280, 17280, 1080, 17280, 1080, 540, 1080, 17280, 1080, 17280, 540, 17280, 540, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 540, 17280, 540, 17280, 1080, 1080, 540, 1080, 17280, 1080, 1080, 17280, 540, 17280, 17280, 1080, 540, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 540, 17280, 1080, 17280, 17280, 540, 17280, 1080, 1080, 17280, 540, 1080, 540, 540, 540, 540, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 540, 540, 540, 540]
Prompts retrieved: 1623780 . Total input tokens: 362007641 . Total output tokens: 324668356
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.723361625801772,
    "estimated_duration": 3600.175534439953,
    "input_throughput": 4299.743124166322,
    "output_throughput": 3792.7511782072365,
    "total_throughput": 8092.494302373559,
    "itl": 223.1772597579597,
    "ttft": 2148682.1000658264,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1892,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.657175157954752,
    "arrivals": 541365,
    "finished_requests": 62620,
    "scheduler_time": 62.44763598772616
}
#Debug simulation 
Total elapsed time: 4.723508385941386. Arrivals time: 0.29005818720906973 Scheduler time: 4.298997205216438 Scheduler overhead time: 0.025521299336105585 Adapter cache time: 0.0707664773799479 Engine time: 0.026277925819158554 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_16-16-32/adapters_256_slots_192_rate_1.6-0.1-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_16-16-32/adapters_256_slots_192_rate_1.6-0.1-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 540, 17280, 17280, 540, 17280, 1080, 17280, 540, 1080, 540, 17280, 1080, 1080, 1080, 1080, 17280, 540, 540, 540, 1080, 17280, 540, 17280, 17280, 1080, 1080, 1080, 540, 17280, 540, 1080, 1080, 540, 1080, 540, 540, 1080, 1080, 17280, 1080, 540, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 540, 17280, 17280, 1080, 540, 540, 17280, 1080, 540, 1080, 1080, 17280, 1080, 540, 540, 17280, 17280, 17280, 17280, 17280, 17280, 540, 1080, 540, 1080, 540, 540, 540, 1080, 1080, 1080, 540, 540, 17280, 17280, 540, 17280, 540, 1080, 17280, 17280, 17280, 1080, 540, 17280, 1080, 540, 540, 540, 540, 540, 17280, 1080, 540, 17280, 540, 17280, 540, 540, 1080, 1080, 17280, 1080, 17280, 540, 1080, 540, 17280, 17280, 540, 17280, 1080, 540, 17280, 540, 540, 17280, 17280, 1080, 17280, 17280, 540, 17280, 1080, 1080, 540, 1080, 17280, 17280, 540, 17280, 1080, 540, 1080, 17280, 540, 540, 540, 540, 540, 540, 17280, 540, 540, 540, 17280, 540, 1080, 17280, 17280, 1080, 540, 17280, 540, 1080, 1080, 540, 1080, 540, 17280, 540, 540, 17280, 540, 17280, 17280, 1080, 17280, 1080, 540, 1080, 17280, 1080, 17280, 540, 17280, 540, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 540, 17280, 540, 17280, 1080, 1080, 540, 1080, 17280, 1080, 1080, 17280, 540, 17280, 17280, 1080, 540, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 540, 17280, 1080, 17280, 17280, 540, 17280, 1080, 1080, 17280, 540, 1080, 540, 540, 540, 540, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 540, 540, 540, 540]
Prompts retrieved: 1623780 . Total input tokens: 362007641 . Total output tokens: 324668356
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.518744515255094,
    "estimated_duration": 3600.01784370087,
    "input_throughput": 3886.85906779152,
    "output_throughput": 3440.205170557779,
    "total_throughput": 7327.064238349299,
    "itl": 97.78528991077548,
    "ttft": 2218624.7798476173,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1704,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.71212557345618,
    "arrivals": 541365,
    "finished_requests": 56505,
    "scheduler_time": 65.55972752757884
}
#Debug simulation 
Total elapsed time: 4.518843031022698. Arrivals time: 0.2657816172577441 Scheduler time: 4.008268168196082 Scheduler overhead time: 0.05180593021214008 Adapter cache time: 0.11534931743517518 Engine time: 0.05338628450408578 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-8-8/adapters_256_slots_192_rate_1.6-0.1-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-8-8/adapters_256_slots_192_rate_1.6-0.1-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 270, 17280, 17280, 270, 17280, 1080, 17280, 270, 1080, 270, 17280, 1080, 1080, 1080, 1080, 17280, 270, 270, 270, 1080, 17280, 270, 17280, 17280, 1080, 1080, 1080, 270, 17280, 270, 1080, 1080, 270, 1080, 270, 270, 1080, 1080, 17280, 1080, 270, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 270, 17280, 17280, 1080, 270, 270, 17280, 1080, 270, 1080, 1080, 17280, 1080, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 1080, 270, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 270, 17280, 17280, 270, 17280, 270, 1080, 17280, 17280, 17280, 1080, 270, 17280, 1080, 270, 270, 270, 270, 270, 17280, 1080, 270, 17280, 270, 17280, 270, 270, 1080, 1080, 17280, 1080, 17280, 270, 1080, 270, 17280, 17280, 270, 17280, 1080, 270, 17280, 270, 270, 17280, 17280, 1080, 17280, 17280, 270, 17280, 1080, 1080, 270, 1080, 17280, 17280, 270, 17280, 1080, 270, 1080, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 1080, 17280, 17280, 1080, 270, 17280, 270, 1080, 1080, 270, 1080, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 1080, 17280, 1080, 270, 1080, 17280, 1080, 17280, 270, 17280, 270, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 270, 17280, 270, 17280, 1080, 1080, 270, 1080, 17280, 1080, 1080, 17280, 270, 17280, 17280, 1080, 270, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 270, 17280, 1080, 17280, 17280, 270, 17280, 1080, 1080, 17280, 270, 1080, 270, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 270, 270, 270, 270]
Prompts retrieved: 1600830 . Total input tokens: 356917788 . Total output tokens: 320016626
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.793013041839004,
    "estimated_duration": 3600.1583008833427,
    "input_throughput": 4492.353571239274,
    "output_throughput": 3941.989994306048,
    "total_throughput": 8434.343565545321,
    "itl": 217.2296369028619,
    "ttft": 2125447.822444016,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1238,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.7888838269888447,
    "arrivals": 533687,
    "finished_requests": 65171,
    "scheduler_time": 64.81262112593127
}
#Debug simulation 
Total elapsed time: 4.793111982755363. Arrivals time: 0.2368656462058425 Scheduler time: 4.429631208535284 Scheduler overhead time: 0.026132555212825537 Adapter cache time: 0.06155910063534975 Engine time: 0.026842529885470867 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-8-16/adapters_256_slots_192_rate_1.6-0.1-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-8-16/adapters_256_slots_192_rate_1.6-0.1-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 270, 17280, 17280, 270, 17280, 1080, 17280, 270, 1080, 270, 17280, 1080, 1080, 1080, 1080, 17280, 270, 270, 270, 1080, 17280, 270, 17280, 17280, 1080, 1080, 1080, 270, 17280, 270, 1080, 1080, 270, 1080, 270, 270, 1080, 1080, 17280, 1080, 270, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 270, 17280, 17280, 1080, 270, 270, 17280, 1080, 270, 1080, 1080, 17280, 1080, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 1080, 270, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 270, 17280, 17280, 270, 17280, 270, 1080, 17280, 17280, 17280, 1080, 270, 17280, 1080, 270, 270, 270, 270, 270, 17280, 1080, 270, 17280, 270, 17280, 270, 270, 1080, 1080, 17280, 1080, 17280, 270, 1080, 270, 17280, 17280, 270, 17280, 1080, 270, 17280, 270, 270, 17280, 17280, 1080, 17280, 17280, 270, 17280, 1080, 1080, 270, 1080, 17280, 17280, 270, 17280, 1080, 270, 1080, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 1080, 17280, 17280, 1080, 270, 17280, 270, 1080, 1080, 270, 1080, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 1080, 17280, 1080, 270, 1080, 17280, 1080, 17280, 270, 17280, 270, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 270, 17280, 270, 17280, 1080, 1080, 270, 1080, 17280, 1080, 1080, 17280, 270, 17280, 17280, 1080, 270, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 270, 17280, 1080, 17280, 17280, 270, 17280, 1080, 1080, 17280, 270, 1080, 270, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 270, 270, 270, 270]
Prompts retrieved: 1600830 . Total input tokens: 356917788 . Total output tokens: 320016626
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.814968471415341,
    "estimated_duration": 3600.207961762191,
    "input_throughput": 4490.492541460548,
    "output_throughput": 3940.6106954599063,
    "total_throughput": 8431.103236920453,
    "itl": 214.23816294082175,
    "ttft": 2126196.500199776,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1239,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.045032215644607,
    "arrivals": 533687,
    "finished_requests": 65147,
    "scheduler_time": 64.88636365486205
}
#Debug simulation 
Total elapsed time: 4.815081849228591. Arrivals time: 0.24300842778757215 Scheduler time: 4.4431788376532495 Scheduler overhead time: 0.026597789954394102 Adapter cache time: 0.06251158006489277 Engine time: 0.02745022065937519 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-8-32/adapters_256_slots_192_rate_1.6-0.1-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-8-32/adapters_256_slots_192_rate_1.6-0.1-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 270, 17280, 17280, 270, 17280, 1080, 17280, 270, 1080, 270, 17280, 1080, 1080, 1080, 1080, 17280, 270, 270, 270, 1080, 17280, 270, 17280, 17280, 1080, 1080, 1080, 270, 17280, 270, 1080, 1080, 270, 1080, 270, 270, 1080, 1080, 17280, 1080, 270, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 270, 17280, 17280, 1080, 270, 270, 17280, 1080, 270, 1080, 1080, 17280, 1080, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 1080, 270, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 270, 17280, 17280, 270, 17280, 270, 1080, 17280, 17280, 17280, 1080, 270, 17280, 1080, 270, 270, 270, 270, 270, 17280, 1080, 270, 17280, 270, 17280, 270, 270, 1080, 1080, 17280, 1080, 17280, 270, 1080, 270, 17280, 17280, 270, 17280, 1080, 270, 17280, 270, 270, 17280, 17280, 1080, 17280, 17280, 270, 17280, 1080, 1080, 270, 1080, 17280, 17280, 270, 17280, 1080, 270, 1080, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 1080, 17280, 17280, 1080, 270, 17280, 270, 1080, 1080, 270, 1080, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 1080, 17280, 1080, 270, 1080, 17280, 1080, 17280, 270, 17280, 270, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 270, 17280, 270, 17280, 1080, 1080, 270, 1080, 17280, 1080, 1080, 17280, 270, 17280, 17280, 1080, 270, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 270, 17280, 1080, 17280, 17280, 270, 17280, 1080, 1080, 17280, 270, 1080, 270, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 270, 270, 270, 270]
Prompts retrieved: 1600830 . Total input tokens: 356917788 . Total output tokens: 320016626
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.5075736083090305,
    "estimated_duration": 3600.0851657520952,
    "input_throughput": 3965.9475658591064,
    "output_throughput": 3501.9571536625563,
    "total_throughput": 7467.904719521663,
    "itl": 95.95486611542117,
    "ttft": 2204703.000728045,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1124,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.6738508069142206,
    "arrivals": 533687,
    "finished_requests": 57509,
    "scheduler_time": 66.73466954421403
}
#Debug simulation 
Total elapsed time: 4.5077069089747965. Arrivals time: 0.2145124771632254 Scheduler time: 4.05919639300555 Scheduler overhead time: 0.052472096867859364 Adapter cache time: 0.10291793709620833 Engine time: 0.05402861908078194 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-16-16/adapters_256_slots_192_rate_1.6-0.1-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-16-16/adapters_256_slots_192_rate_1.6-0.1-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 270, 17280, 17280, 270, 17280, 1080, 17280, 270, 1080, 270, 17280, 1080, 1080, 1080, 1080, 17280, 270, 270, 270, 1080, 17280, 270, 17280, 17280, 1080, 1080, 1080, 270, 17280, 270, 1080, 1080, 270, 1080, 270, 270, 1080, 1080, 17280, 1080, 270, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 270, 17280, 17280, 1080, 270, 270, 17280, 1080, 270, 1080, 1080, 17280, 1080, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 1080, 270, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 270, 17280, 17280, 270, 17280, 270, 1080, 17280, 17280, 17280, 1080, 270, 17280, 1080, 270, 270, 270, 270, 270, 17280, 1080, 270, 17280, 270, 17280, 270, 270, 1080, 1080, 17280, 1080, 17280, 270, 1080, 270, 17280, 17280, 270, 17280, 1080, 270, 17280, 270, 270, 17280, 17280, 1080, 17280, 17280, 270, 17280, 1080, 1080, 270, 1080, 17280, 17280, 270, 17280, 1080, 270, 1080, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 1080, 17280, 17280, 1080, 270, 17280, 270, 1080, 1080, 270, 1080, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 1080, 17280, 1080, 270, 1080, 17280, 1080, 17280, 270, 17280, 270, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 270, 17280, 270, 17280, 1080, 1080, 270, 1080, 17280, 1080, 1080, 17280, 270, 17280, 17280, 1080, 270, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 270, 17280, 1080, 17280, 17280, 270, 17280, 1080, 1080, 17280, 270, 1080, 270, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 270, 270, 270, 270]
Prompts retrieved: 1600830 . Total input tokens: 356917788 . Total output tokens: 320016626
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 4.801282826811075,
    "estimated_duration": 3600.0739093008524,
    "input_throughput": 4490.8114131300545,
    "output_throughput": 3940.863537092005,
    "total_throughput": 8431.67495022206,
    "itl": 214.44342962243053,
    "ttft": 2126079.914915971,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1239,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.8840456601790674,
    "arrivals": 533687,
    "finished_requests": 65149,
    "scheduler_time": 64.88072845955817
}
#Debug simulation 
Total elapsed time: 4.801384579855949. Arrivals time: 0.23641667608171701 Scheduler time: 4.4358361954800785 Scheduler overhead time: 0.02668282389640808 Adapter cache time: 0.0626123072579503 Engine time: 0.027514338959008455 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-16-32/adapters_256_slots_192_rate_1.6-0.1-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-16-32/adapters_256_slots_192_rate_1.6-0.1-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 270, 17280, 17280, 270, 17280, 1080, 17280, 270, 1080, 270, 17280, 1080, 1080, 1080, 1080, 17280, 270, 270, 270, 1080, 17280, 270, 17280, 17280, 1080, 1080, 1080, 270, 17280, 270, 1080, 1080, 270, 1080, 270, 270, 1080, 1080, 17280, 1080, 270, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 270, 17280, 17280, 1080, 270, 270, 17280, 1080, 270, 1080, 1080, 17280, 1080, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 1080, 270, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 270, 17280, 17280, 270, 17280, 270, 1080, 17280, 17280, 17280, 1080, 270, 17280, 1080, 270, 270, 270, 270, 270, 17280, 1080, 270, 17280, 270, 17280, 270, 270, 1080, 1080, 17280, 1080, 17280, 270, 1080, 270, 17280, 17280, 270, 17280, 1080, 270, 17280, 270, 270, 17280, 17280, 1080, 17280, 17280, 270, 17280, 1080, 1080, 270, 1080, 17280, 17280, 270, 17280, 1080, 270, 1080, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 1080, 17280, 17280, 1080, 270, 17280, 270, 1080, 1080, 270, 1080, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 1080, 17280, 1080, 270, 1080, 17280, 1080, 17280, 270, 17280, 270, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 270, 17280, 270, 17280, 1080, 1080, 270, 1080, 17280, 1080, 1080, 17280, 270, 17280, 17280, 1080, 270, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 270, 17280, 1080, 17280, 17280, 270, 17280, 1080, 1080, 17280, 270, 1080, 270, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 270, 270, 270, 270]
Prompts retrieved: 1600830 . Total input tokens: 356917788 . Total output tokens: 320016626
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 4.537694609258324,
    "estimated_duration": 3600.0288733878815,
    "input_throughput": 3965.783470665444,
    "output_throughput": 3501.9246909916847,
    "total_throughput": 7467.708161657129,
    "itl": 95.9600055149731,
    "ttft": 2204762.178953395,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1125,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.720782397221767,
    "arrivals": 533687,
    "finished_requests": 57506,
    "scheduler_time": 66.73186529754196
}
#Debug simulation 
Total elapsed time: 4.537812313996255. Arrivals time: 0.22395022306591272 Scheduler time: 4.079565498512238 Scheduler overhead time: 0.05254104267805815 Adapter cache time: 0.10285652475431561 Engine time: 0.05435283621773124 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_16-16-16/adapters_256_slots_192_rate_1.6-0.1-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_16-16-16/adapters_256_slots_192_rate_1.6-0.1-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 270, 17280, 17280, 270, 17280, 1080, 17280, 270, 1080, 270, 17280, 1080, 1080, 1080, 1080, 17280, 270, 270, 270, 1080, 17280, 270, 17280, 17280, 1080, 1080, 1080, 270, 17280, 270, 1080, 1080, 270, 1080, 270, 270, 1080, 1080, 17280, 1080, 270, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 270, 17280, 17280, 1080, 270, 270, 17280, 1080, 270, 1080, 1080, 17280, 1080, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 1080, 270, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 270, 17280, 17280, 270, 17280, 270, 1080, 17280, 17280, 17280, 1080, 270, 17280, 1080, 270, 270, 270, 270, 270, 17280, 1080, 270, 17280, 270, 17280, 270, 270, 1080, 1080, 17280, 1080, 17280, 270, 1080, 270, 17280, 17280, 270, 17280, 1080, 270, 17280, 270, 270, 17280, 17280, 1080, 17280, 17280, 270, 17280, 1080, 1080, 270, 1080, 17280, 17280, 270, 17280, 1080, 270, 1080, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 1080, 17280, 17280, 1080, 270, 17280, 270, 1080, 1080, 270, 1080, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 1080, 17280, 1080, 270, 1080, 17280, 1080, 17280, 270, 17280, 270, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 270, 17280, 270, 17280, 1080, 1080, 270, 1080, 17280, 1080, 1080, 17280, 270, 17280, 17280, 1080, 270, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 270, 17280, 1080, 17280, 17280, 270, 17280, 1080, 1080, 17280, 270, 1080, 270, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 270, 270, 270, 270]
Prompts retrieved: 1600830 . Total input tokens: 356917788 . Total output tokens: 320016626
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.801206761971116,
    "estimated_duration": 3600.1895223352735,
    "input_throughput": 4490.911908857646,
    "output_throughput": 3941.0586337123027,
    "total_throughput": 8431.970542569949,
    "itl": 214.43300248963857,
    "ttft": 2126092.4644567063,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1239,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.704672315383701,
    "arrivals": 533687,
    "finished_requests": 65155,
    "scheduler_time": 64.88522475928812
}
#Debug simulation 
Total elapsed time: 4.80135199194774. Arrivals time: 0.23507307283580303 Scheduler time: 4.437814553268254 Scheduler overhead time: 0.026515697594732046 Adapter cache time: 0.06237513851374388 Engine time: 0.027269592974334955 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_16-16-32/adapters_256_slots_192_rate_1.6-0.1-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_16-16-32/adapters_256_slots_192_rate_1.6-0.1-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 270, 17280, 17280, 270, 17280, 1080, 17280, 270, 1080, 270, 17280, 1080, 1080, 1080, 1080, 17280, 270, 270, 270, 1080, 17280, 270, 17280, 17280, 1080, 1080, 1080, 270, 17280, 270, 1080, 1080, 270, 1080, 270, 270, 1080, 1080, 17280, 1080, 270, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 270, 17280, 17280, 1080, 270, 270, 17280, 1080, 270, 1080, 1080, 17280, 1080, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 1080, 270, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 270, 17280, 17280, 270, 17280, 270, 1080, 17280, 17280, 17280, 1080, 270, 17280, 1080, 270, 270, 270, 270, 270, 17280, 1080, 270, 17280, 270, 17280, 270, 270, 1080, 1080, 17280, 1080, 17280, 270, 1080, 270, 17280, 17280, 270, 17280, 1080, 270, 17280, 270, 270, 17280, 17280, 1080, 17280, 17280, 270, 17280, 1080, 1080, 270, 1080, 17280, 17280, 270, 17280, 1080, 270, 1080, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 1080, 17280, 17280, 1080, 270, 17280, 270, 1080, 1080, 270, 1080, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 1080, 17280, 1080, 270, 1080, 17280, 1080, 17280, 270, 17280, 270, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 270, 17280, 270, 17280, 1080, 1080, 270, 1080, 17280, 1080, 1080, 17280, 270, 17280, 17280, 1080, 270, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 270, 17280, 1080, 17280, 17280, 270, 17280, 1080, 1080, 17280, 270, 1080, 270, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 270, 270, 270, 270]
Prompts retrieved: 1600830 . Total input tokens: 356917788 . Total output tokens: 320016626
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.523952044080943,
    "estimated_duration": 3600.0586852820807,
    "input_throughput": 3962.463183813979,
    "output_throughput": 3499.271012303768,
    "total_throughput": 7461.734196117747,
    "itl": 95.7406678824165,
    "ttft": 2205312.3254800886,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1126,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.7747161857039258,
    "arrivals": 533687,
    "finished_requests": 57462,
    "scheduler_time": 66.72351150466932
}
#Debug simulation 
Total elapsed time: 4.5240525170229375. Arrivals time: 0.2159551433287561 Scheduler time: 4.071374464780092 Scheduler overhead time: 0.05263275699689984 Adapter cache time: 0.1049968977458775 Engine time: 0.05442201113328338 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-8/adapters_256_slots_192_rate_1.6-0.1-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-8/adapters_256_slots_192_rate_1.6-0.1-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 135, 17280, 17280, 135, 17280, 1080, 17280, 135, 1080, 135, 17280, 1080, 1080, 1080, 1080, 17280, 135, 135, 135, 1080, 17280, 135, 17280, 17280, 1080, 1080, 1080, 135, 17280, 135, 1080, 1080, 135, 1080, 135, 135, 1080, 1080, 17280, 1080, 135, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 135, 17280, 17280, 1080, 135, 135, 17280, 1080, 135, 1080, 1080, 17280, 1080, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 1080, 135, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 135, 17280, 17280, 135, 17280, 135, 1080, 17280, 17280, 17280, 1080, 135, 17280, 1080, 135, 135, 135, 135, 135, 17280, 1080, 135, 17280, 135, 17280, 135, 135, 1080, 1080, 17280, 1080, 17280, 135, 1080, 135, 17280, 17280, 135, 17280, 1080, 135, 17280, 135, 135, 17280, 17280, 1080, 17280, 17280, 135, 17280, 1080, 1080, 135, 1080, 17280, 17280, 135, 17280, 1080, 135, 1080, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 1080, 17280, 17280, 1080, 135, 17280, 135, 1080, 1080, 135, 1080, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 1080, 17280, 1080, 135, 1080, 17280, 1080, 17280, 135, 17280, 135, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 135, 17280, 135, 17280, 1080, 1080, 135, 1080, 17280, 1080, 1080, 17280, 135, 17280, 17280, 1080, 135, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 135, 17280, 1080, 17280, 17280, 135, 17280, 1080, 1080, 17280, 135, 1080, 135, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 135, 135, 135, 135]
Prompts retrieved: 1589355 . Total input tokens: 354333746 . Total output tokens: 317709364
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.890196558088064,
    "estimated_duration": 3600.0122941637924,
    "input_throughput": 4602.968725096823,
    "output_throughput": 4039.7487040743754,
    "total_throughput": 8642.717429171198,
    "itl": 211.2556748782425,
    "ttft": 2115976.4359543375,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 732,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2402770285588174,
    "arrivals": 529924,
    "finished_requests": 67080,
    "scheduler_time": 66.41766051984054
}
#Debug simulation 
Total elapsed time: 4.8902935879305005. Arrivals time: 0.2411877904087305 Scheduler time: 4.528514394536614 Scheduler overhead time: 0.02690161671489477 Adapter cache time: 0.0538368821144104 Engine time: 0.02750838128849864 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-16/adapters_256_slots_192_rate_1.6-0.1-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-16/adapters_256_slots_192_rate_1.6-0.1-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 135, 17280, 17280, 135, 17280, 1080, 17280, 135, 1080, 135, 17280, 1080, 1080, 1080, 1080, 17280, 135, 135, 135, 1080, 17280, 135, 17280, 17280, 1080, 1080, 1080, 135, 17280, 135, 1080, 1080, 135, 1080, 135, 135, 1080, 1080, 17280, 1080, 135, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 135, 17280, 17280, 1080, 135, 135, 17280, 1080, 135, 1080, 1080, 17280, 1080, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 1080, 135, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 135, 17280, 17280, 135, 17280, 135, 1080, 17280, 17280, 17280, 1080, 135, 17280, 1080, 135, 135, 135, 135, 135, 17280, 1080, 135, 17280, 135, 17280, 135, 135, 1080, 1080, 17280, 1080, 17280, 135, 1080, 135, 17280, 17280, 135, 17280, 1080, 135, 17280, 135, 135, 17280, 17280, 1080, 17280, 17280, 135, 17280, 1080, 1080, 135, 1080, 17280, 17280, 135, 17280, 1080, 135, 1080, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 1080, 17280, 17280, 1080, 135, 17280, 135, 1080, 1080, 135, 1080, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 1080, 17280, 1080, 135, 1080, 17280, 1080, 17280, 135, 17280, 135, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 135, 17280, 135, 17280, 1080, 1080, 135, 1080, 17280, 1080, 1080, 17280, 135, 17280, 17280, 1080, 135, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 135, 17280, 1080, 17280, 17280, 135, 17280, 1080, 1080, 17280, 135, 1080, 135, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 135, 135, 135, 135]
Prompts retrieved: 1589355 . Total input tokens: 354333746 . Total output tokens: 317709364
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.930805597919971,
    "estimated_duration": 3600.088074768331,
    "input_throughput": 4600.57383486814,
    "output_throughput": 4038.305090892964,
    "total_throughput": 8638.878925761104,
    "itl": 209.11373887858923,
    "ttft": 2116435.14025072,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 731,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3867556622461477,
    "arrivals": 529924,
    "finished_requests": 67050,
    "scheduler_time": 66.46508318113045
}
#Debug simulation 
Total elapsed time: 4.930930642876774. Arrivals time: 0.23890313925221562 Scheduler time: 4.570081400219351 Scheduler overhead time: 0.027055012062191963 Adapter cache time: 0.05448124837130308 Engine time: 0.02784538734704256 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-32/adapters_256_slots_192_rate_1.6-0.1-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-32/adapters_256_slots_192_rate_1.6-0.1-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 135, 17280, 17280, 135, 17280, 1080, 17280, 135, 1080, 135, 17280, 1080, 1080, 1080, 1080, 17280, 135, 135, 135, 1080, 17280, 135, 17280, 17280, 1080, 1080, 1080, 135, 17280, 135, 1080, 1080, 135, 1080, 135, 135, 1080, 1080, 17280, 1080, 135, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 135, 17280, 17280, 1080, 135, 135, 17280, 1080, 135, 1080, 1080, 17280, 1080, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 1080, 135, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 135, 17280, 17280, 135, 17280, 135, 1080, 17280, 17280, 17280, 1080, 135, 17280, 1080, 135, 135, 135, 135, 135, 17280, 1080, 135, 17280, 135, 17280, 135, 135, 1080, 1080, 17280, 1080, 17280, 135, 1080, 135, 17280, 17280, 135, 17280, 1080, 135, 17280, 135, 135, 17280, 17280, 1080, 17280, 17280, 135, 17280, 1080, 1080, 135, 1080, 17280, 17280, 135, 17280, 1080, 135, 1080, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 1080, 17280, 17280, 1080, 135, 17280, 135, 1080, 1080, 135, 1080, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 1080, 17280, 1080, 135, 1080, 17280, 1080, 17280, 135, 17280, 135, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 135, 17280, 135, 17280, 1080, 1080, 135, 1080, 17280, 1080, 1080, 17280, 135, 17280, 17280, 1080, 135, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 135, 17280, 1080, 17280, 17280, 135, 17280, 1080, 1080, 17280, 135, 1080, 135, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 135, 135, 135, 135]
Prompts retrieved: 1589355 . Total input tokens: 354333746 . Total output tokens: 317709364
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.568477030377835,
    "estimated_duration": 3600.0355958760574,
    "input_throughput": 4014.0333658238387,
    "output_throughput": 3537.7136311066834,
    "total_throughput": 7551.746996930522,
    "itl": 94.63783614266092,
    "ttft": 2200824.2525369967,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 684,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2369007400423335,
    "arrivals": 529924,
    "finished_requests": 58565,
    "scheduler_time": 67.4131380734407
}
#Debug simulation 
Total elapsed time: 4.568577062338591. Arrivals time: 0.24651076830923557 Scheduler time: 4.093679036479443 Scheduler overhead time: 0.052891632076352835 Adapter cache time: 0.09599091624841094 Engine time: 0.05461429478600621 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-16-16/adapters_256_slots_192_rate_1.6-0.1-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-16-16/adapters_256_slots_192_rate_1.6-0.1-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 135, 17280, 17280, 135, 17280, 1080, 17280, 135, 1080, 135, 17280, 1080, 1080, 1080, 1080, 17280, 135, 135, 135, 1080, 17280, 135, 17280, 17280, 1080, 1080, 1080, 135, 17280, 135, 1080, 1080, 135, 1080, 135, 135, 1080, 1080, 17280, 1080, 135, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 135, 17280, 17280, 1080, 135, 135, 17280, 1080, 135, 1080, 1080, 17280, 1080, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 1080, 135, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 135, 17280, 17280, 135, 17280, 135, 1080, 17280, 17280, 17280, 1080, 135, 17280, 1080, 135, 135, 135, 135, 135, 17280, 1080, 135, 17280, 135, 17280, 135, 135, 1080, 1080, 17280, 1080, 17280, 135, 1080, 135, 17280, 17280, 135, 17280, 1080, 135, 17280, 135, 135, 17280, 17280, 1080, 17280, 17280, 135, 17280, 1080, 1080, 135, 1080, 17280, 17280, 135, 17280, 1080, 135, 1080, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 1080, 17280, 17280, 1080, 135, 17280, 135, 1080, 1080, 135, 1080, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 1080, 17280, 1080, 135, 1080, 17280, 1080, 17280, 135, 17280, 135, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 135, 17280, 135, 17280, 1080, 1080, 135, 1080, 17280, 1080, 1080, 17280, 135, 17280, 17280, 1080, 135, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 135, 17280, 1080, 17280, 17280, 135, 17280, 1080, 1080, 17280, 135, 1080, 135, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 135, 135, 135, 135]
Prompts retrieved: 1589355 . Total input tokens: 354333746 . Total output tokens: 317709364
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 4.941600814927369,
    "estimated_duration": 3600.096714163922,
    "input_throughput": 4600.743900805615,
    "output_throughput": 4038.3395653792504,
    "total_throughput": 8639.083466184866,
    "itl": 209.0902779351122,
    "ttft": 2116445.743029411,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 732,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.296177384618189,
    "arrivals": 529924,
    "finished_requests": 67051,
    "scheduler_time": 66.46707261250987
}
#Debug simulation 
Total elapsed time: 4.941717134322971. Arrivals time: 0.24775433260947466 Scheduler time: 4.572491235565394 Scheduler overhead time: 0.02705194801092148 Adapter cache time: 0.0538254464045167 Engine time: 0.02809983864426613 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-16-32/adapters_256_slots_192_rate_1.6-0.1-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-16-32/adapters_256_slots_192_rate_1.6-0.1-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 135, 17280, 17280, 135, 17280, 1080, 17280, 135, 1080, 135, 17280, 1080, 1080, 1080, 1080, 17280, 135, 135, 135, 1080, 17280, 135, 17280, 17280, 1080, 1080, 1080, 135, 17280, 135, 1080, 1080, 135, 1080, 135, 135, 1080, 1080, 17280, 1080, 135, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 135, 17280, 17280, 1080, 135, 135, 17280, 1080, 135, 1080, 1080, 17280, 1080, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 1080, 135, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 135, 17280, 17280, 135, 17280, 135, 1080, 17280, 17280, 17280, 1080, 135, 17280, 1080, 135, 135, 135, 135, 135, 17280, 1080, 135, 17280, 135, 17280, 135, 135, 1080, 1080, 17280, 1080, 17280, 135, 1080, 135, 17280, 17280, 135, 17280, 1080, 135, 17280, 135, 135, 17280, 17280, 1080, 17280, 17280, 135, 17280, 1080, 1080, 135, 1080, 17280, 17280, 135, 17280, 1080, 135, 1080, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 1080, 17280, 17280, 1080, 135, 17280, 135, 1080, 1080, 135, 1080, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 1080, 17280, 1080, 135, 1080, 17280, 1080, 17280, 135, 17280, 135, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 135, 17280, 135, 17280, 1080, 1080, 135, 1080, 17280, 1080, 1080, 17280, 135, 17280, 17280, 1080, 135, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 135, 17280, 1080, 17280, 17280, 135, 17280, 1080, 1080, 17280, 135, 1080, 135, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 135, 135, 135, 135]
Prompts retrieved: 1589355 . Total input tokens: 354333746 . Total output tokens: 317709364
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 4.852509711869061,
    "estimated_duration": 3600.0852538540726,
    "input_throughput": 4021.723092390656,
    "output_throughput": 3544.5224488334416,
    "total_throughput": 7566.245541224098,
    "itl": 95.22093875384839,
    "ttft": 2199682.644701845,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 681,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2530809962376965,
    "arrivals": 529924,
    "finished_requests": 58679,
    "scheduler_time": 67.42787550701215
}
#Debug simulation 
Total elapsed time: 4.852587015833706. Arrivals time: 0.22138080606237054 Scheduler time: 4.403936638031155 Scheduler overhead time: 0.05276550445705652 Adapter cache time: 0.09578456357121468 Engine time: 0.054112807381898165 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_16-16-16/adapters_256_slots_192_rate_1.6-0.1-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_16-16-16/adapters_256_slots_192_rate_1.6-0.1-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 135, 17280, 17280, 135, 17280, 1080, 17280, 135, 1080, 135, 17280, 1080, 1080, 1080, 1080, 17280, 135, 135, 135, 1080, 17280, 135, 17280, 17280, 1080, 1080, 1080, 135, 17280, 135, 1080, 1080, 135, 1080, 135, 135, 1080, 1080, 17280, 1080, 135, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 135, 17280, 17280, 1080, 135, 135, 17280, 1080, 135, 1080, 1080, 17280, 1080, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 1080, 135, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 135, 17280, 17280, 135, 17280, 135, 1080, 17280, 17280, 17280, 1080, 135, 17280, 1080, 135, 135, 135, 135, 135, 17280, 1080, 135, 17280, 135, 17280, 135, 135, 1080, 1080, 17280, 1080, 17280, 135, 1080, 135, 17280, 17280, 135, 17280, 1080, 135, 17280, 135, 135, 17280, 17280, 1080, 17280, 17280, 135, 17280, 1080, 1080, 135, 1080, 17280, 17280, 135, 17280, 1080, 135, 1080, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 1080, 17280, 17280, 1080, 135, 17280, 135, 1080, 1080, 135, 1080, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 1080, 17280, 1080, 135, 1080, 17280, 1080, 17280, 135, 17280, 135, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 135, 17280, 135, 17280, 1080, 1080, 135, 1080, 17280, 1080, 1080, 17280, 135, 17280, 17280, 1080, 135, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 135, 17280, 1080, 17280, 17280, 135, 17280, 1080, 1080, 17280, 135, 1080, 135, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 135, 135, 135, 135]
Prompts retrieved: 1589355 . Total input tokens: 354333746 . Total output tokens: 317709364
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.912273650988936,
    "estimated_duration": 3600.1442918585135,
    "input_throughput": 4600.7258757535765,
    "output_throughput": 4038.4206357725016,
    "total_throughput": 8639.146511526078,
    "itl": 209.08850724950798,
    "ttft": 2116418.350982392,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 731,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.18572676557345,
    "arrivals": 529924,
    "finished_requests": 67052,
    "scheduler_time": 66.46950677467538
}
#Debug simulation 
Total elapsed time: 4.912425620947033. Arrivals time: 0.2401129943318665 Scheduler time: 4.54813793906942 Scheduler overhead time: 0.027310389559715986 Adapter cache time: 0.056313930079340935 Engine time: 0.027973802760243416 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_16-16-32/adapters_256_slots_192_rate_1.6-0.1-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_16-16-32/adapters_256_slots_192_rate_1.6-0.1-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 135, 17280, 17280, 135, 17280, 1080, 17280, 135, 1080, 135, 17280, 1080, 1080, 1080, 1080, 17280, 135, 135, 135, 1080, 17280, 135, 17280, 17280, 1080, 1080, 1080, 135, 17280, 135, 1080, 1080, 135, 1080, 135, 135, 1080, 1080, 17280, 1080, 135, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 135, 17280, 17280, 1080, 135, 135, 17280, 1080, 135, 1080, 1080, 17280, 1080, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 1080, 135, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 135, 17280, 17280, 135, 17280, 135, 1080, 17280, 17280, 17280, 1080, 135, 17280, 1080, 135, 135, 135, 135, 135, 17280, 1080, 135, 17280, 135, 17280, 135, 135, 1080, 1080, 17280, 1080, 17280, 135, 1080, 135, 17280, 17280, 135, 17280, 1080, 135, 17280, 135, 135, 17280, 17280, 1080, 17280, 17280, 135, 17280, 1080, 1080, 135, 1080, 17280, 17280, 135, 17280, 1080, 135, 1080, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 1080, 17280, 17280, 1080, 135, 17280, 135, 1080, 1080, 135, 1080, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 1080, 17280, 1080, 135, 1080, 17280, 1080, 17280, 135, 17280, 135, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 135, 17280, 135, 17280, 1080, 1080, 135, 1080, 17280, 1080, 1080, 17280, 135, 17280, 17280, 1080, 135, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 135, 17280, 1080, 17280, 17280, 135, 17280, 1080, 1080, 17280, 135, 1080, 135, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 135, 135, 135, 135]
Prompts retrieved: 1589355 . Total input tokens: 354333746 . Total output tokens: 317709364
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.550353461876512,
    "estimated_duration": 3600.0438975411935,
    "input_throughput": 4022.800391376141,
    "output_throughput": 3545.5259333692466,
    "total_throughput": 7568.326324745387,
    "itl": 95.31977890483968,
    "ttft": 2199479.70215008,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 683,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.290777960382406,
    "arrivals": 529924,
    "finished_requests": 58698,
    "scheduler_time": 67.43111017173949
}
#Debug simulation 
Total elapsed time: 4.550481833983213. Arrivals time: 0.21794298430904746 Scheduler time: 4.105854879599065 Scheduler overhead time: 0.0525046088732779 Adapter cache time: 0.09584691654890776 Engine time: 0.05382947018370032 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-8/adapters_256_slots_192_rate_1.6-0.1-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-8/adapters_256_slots_192_rate_1.6-0.1-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 66, 17280, 17280, 66, 17280, 1080, 17280, 66, 1080, 66, 17280, 1080, 1080, 1080, 1080, 17280, 66, 66, 66, 1080, 17280, 66, 17280, 17280, 1080, 1080, 1080, 66, 17280, 66, 1080, 1080, 66, 1080, 66, 66, 1080, 1080, 17280, 1080, 66, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 66, 17280, 17280, 1080, 66, 66, 17280, 1080, 66, 1080, 1080, 17280, 1080, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 1080, 66, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 66, 17280, 17280, 66, 17280, 66, 1080, 17280, 17280, 17280, 1080, 66, 17280, 1080, 66, 66, 66, 66, 66, 17280, 1080, 66, 17280, 66, 17280, 66, 66, 1080, 1080, 17280, 1080, 17280, 66, 1080, 66, 17280, 17280, 66, 17280, 1080, 66, 17280, 66, 66, 17280, 17280, 1080, 17280, 17280, 66, 17280, 1080, 1080, 66, 1080, 17280, 17280, 66, 17280, 1080, 66, 1080, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 1080, 17280, 17280, 1080, 66, 17280, 66, 1080, 1080, 66, 1080, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 1080, 17280, 1080, 66, 1080, 17280, 1080, 17280, 66, 17280, 66, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 66, 17280, 66, 17280, 1080, 1080, 66, 1080, 17280, 1080, 1080, 17280, 66, 17280, 17280, 1080, 66, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 66, 17280, 1080, 17280, 17280, 66, 17280, 1080, 1080, 17280, 66, 1080, 66, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 66, 66, 66, 66]
Prompts retrieved: 1583490 . Total input tokens: 353008931 . Total output tokens: 316540482
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.052286798134446,
    "estimated_duration": 3600.183068313739,
    "input_throughput": 4643.336097858456,
    "output_throughput": 4087.3015957192024,
    "total_throughput": 8730.637693577659,
    "itl": 209.50680563948882,
    "ttft": 2107106.061496535,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 399,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.221134609829175,
    "arrivals": 527992,
    "finished_requests": 67410,
    "scheduler_time": 67.22585601018834
}
#Debug simulation 
Total elapsed time: 5.052390567027032. Arrivals time: 0.24958174815401435 Scheduler time: 4.6849621259607375 Scheduler overhead time: 0.027223876677453518 Adapter cache time: 0.05006124824285507 Engine time: 0.028138346038758755 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-16/adapters_256_slots_192_rate_1.6-0.1-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-16/adapters_256_slots_192_rate_1.6-0.1-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 66, 17280, 17280, 66, 17280, 1080, 17280, 66, 1080, 66, 17280, 1080, 1080, 1080, 1080, 17280, 66, 66, 66, 1080, 17280, 66, 17280, 17280, 1080, 1080, 1080, 66, 17280, 66, 1080, 1080, 66, 1080, 66, 66, 1080, 1080, 17280, 1080, 66, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 66, 17280, 17280, 1080, 66, 66, 17280, 1080, 66, 1080, 1080, 17280, 1080, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 1080, 66, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 66, 17280, 17280, 66, 17280, 66, 1080, 17280, 17280, 17280, 1080, 66, 17280, 1080, 66, 66, 66, 66, 66, 17280, 1080, 66, 17280, 66, 17280, 66, 66, 1080, 1080, 17280, 1080, 17280, 66, 1080, 66, 17280, 17280, 66, 17280, 1080, 66, 17280, 66, 66, 17280, 17280, 1080, 17280, 17280, 66, 17280, 1080, 1080, 66, 1080, 17280, 17280, 66, 17280, 1080, 66, 1080, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 1080, 17280, 17280, 1080, 66, 17280, 66, 1080, 1080, 66, 1080, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 1080, 17280, 1080, 66, 1080, 17280, 1080, 17280, 66, 17280, 66, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 66, 17280, 66, 17280, 1080, 1080, 66, 1080, 17280, 1080, 1080, 17280, 66, 17280, 17280, 1080, 66, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 66, 17280, 1080, 17280, 17280, 66, 17280, 1080, 1080, 17280, 66, 1080, 66, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 66, 66, 66, 66]
Prompts retrieved: 1583490 . Total input tokens: 353008931 . Total output tokens: 316540482
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.013834792654961,
    "estimated_duration": 3600.146792972621,
    "input_throughput": 4641.478517658621,
    "output_throughput": 4086.3397650107654,
    "total_throughput": 8727.818282669386,
    "itl": 207.4072992327918,
    "ttft": 2107656.13397805,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 398,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2991349673946444,
    "arrivals": 527992,
    "finished_requests": 67374,
    "scheduler_time": 67.2621256776445
}
#Debug simulation 
Total elapsed time: 5.013933212962002. Arrivals time: 0.29547510715201497 Scheduler time: 4.5984979956410825 Scheduler overhead time: 0.02730194805189967 Adapter cache time: 0.051797749008983374 Engine time: 0.028240055311471224 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-32/adapters_256_slots_192_rate_1.6-0.1-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-32/adapters_256_slots_192_rate_1.6-0.1-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 66, 17280, 17280, 66, 17280, 1080, 17280, 66, 1080, 66, 17280, 1080, 1080, 1080, 1080, 17280, 66, 66, 66, 1080, 17280, 66, 17280, 17280, 1080, 1080, 1080, 66, 17280, 66, 1080, 1080, 66, 1080, 66, 66, 1080, 1080, 17280, 1080, 66, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 66, 17280, 17280, 1080, 66, 66, 17280, 1080, 66, 1080, 1080, 17280, 1080, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 1080, 66, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 66, 17280, 17280, 66, 17280, 66, 1080, 17280, 17280, 17280, 1080, 66, 17280, 1080, 66, 66, 66, 66, 66, 17280, 1080, 66, 17280, 66, 17280, 66, 66, 1080, 1080, 17280, 1080, 17280, 66, 1080, 66, 17280, 17280, 66, 17280, 1080, 66, 17280, 66, 66, 17280, 17280, 1080, 17280, 17280, 66, 17280, 1080, 1080, 66, 1080, 17280, 17280, 66, 17280, 1080, 66, 1080, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 1080, 17280, 17280, 1080, 66, 17280, 66, 1080, 1080, 66, 1080, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 1080, 17280, 1080, 66, 1080, 17280, 1080, 17280, 66, 17280, 66, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 66, 17280, 66, 17280, 1080, 1080, 66, 1080, 17280, 1080, 1080, 17280, 66, 17280, 17280, 1080, 66, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 66, 17280, 1080, 17280, 17280, 66, 17280, 1080, 1080, 17280, 66, 1080, 66, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 66, 66, 66, 66]
Prompts retrieved: 1583490 . Total input tokens: 353008931 . Total output tokens: 316540482
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.6554291397333145,
    "estimated_duration": 3600.0170914435366,
    "input_throughput": 4032.5516882973643,
    "output_throughput": 3572.533038959245,
    "total_throughput": 7605.084727256609,
    "itl": 94.81587607028328,
    "ttft": 2198493.498420693,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 360,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1769434317387706,
    "arrivals": 527992,
    "finished_requests": 58602,
    "scheduler_time": 67.92801634470312
}
#Debug simulation 
Total elapsed time: 4.655530306976289. Arrivals time: 0.27130799274891615 Scheduler time: 4.15941883251071 Scheduler overhead time: 0.05314320186153054 Adapter cache time: 0.09205305390059948 Engine time: 0.054749150294810534 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-16-16/adapters_256_slots_192_rate_1.6-0.1-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-16-16/adapters_256_slots_192_rate_1.6-0.1-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 66, 17280, 17280, 66, 17280, 1080, 17280, 66, 1080, 66, 17280, 1080, 1080, 1080, 1080, 17280, 66, 66, 66, 1080, 17280, 66, 17280, 17280, 1080, 1080, 1080, 66, 17280, 66, 1080, 1080, 66, 1080, 66, 66, 1080, 1080, 17280, 1080, 66, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 66, 17280, 17280, 1080, 66, 66, 17280, 1080, 66, 1080, 1080, 17280, 1080, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 1080, 66, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 66, 17280, 17280, 66, 17280, 66, 1080, 17280, 17280, 17280, 1080, 66, 17280, 1080, 66, 66, 66, 66, 66, 17280, 1080, 66, 17280, 66, 17280, 66, 66, 1080, 1080, 17280, 1080, 17280, 66, 1080, 66, 17280, 17280, 66, 17280, 1080, 66, 17280, 66, 66, 17280, 17280, 1080, 17280, 17280, 66, 17280, 1080, 1080, 66, 1080, 17280, 17280, 66, 17280, 1080, 66, 1080, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 1080, 17280, 17280, 1080, 66, 17280, 66, 1080, 1080, 66, 1080, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 1080, 17280, 1080, 66, 1080, 17280, 1080, 17280, 66, 17280, 66, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 66, 17280, 66, 17280, 1080, 1080, 66, 1080, 17280, 1080, 1080, 17280, 66, 17280, 17280, 1080, 66, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 66, 17280, 1080, 17280, 17280, 66, 17280, 1080, 1080, 17280, 66, 1080, 66, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 66, 66, 66, 66]
Prompts retrieved: 1583490 . Total input tokens: 353008931 . Total output tokens: 316540482
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 5.005589107051492,
    "estimated_duration": 3600.128030996009,
    "input_throughput": 4641.502706607082,
    "output_throughput": 4086.3610608675904,
    "total_throughput": 8727.863767474671,
    "itl": 207.40014132923838,
    "ttft": 2107652.3141659466,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 398,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2464261713158333,
    "arrivals": 527992,
    "finished_requests": 67374,
    "scheduler_time": 67.26209802164578
}
#Debug simulation 
Total elapsed time: 5.00568716507405. Arrivals time: 0.24272007402032614 Scheduler time: 4.645365127362311 Scheduler overhead time: 0.027231593616306782 Adapter cache time: 0.04978610947728157 Engine time: 0.02796358661726117 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-16-32/adapters_256_slots_192_rate_1.6-0.1-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-16-32/adapters_256_slots_192_rate_1.6-0.1-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 66, 17280, 17280, 66, 17280, 1080, 17280, 66, 1080, 66, 17280, 1080, 1080, 1080, 1080, 17280, 66, 66, 66, 1080, 17280, 66, 17280, 17280, 1080, 1080, 1080, 66, 17280, 66, 1080, 1080, 66, 1080, 66, 66, 1080, 1080, 17280, 1080, 66, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 66, 17280, 17280, 1080, 66, 66, 17280, 1080, 66, 1080, 1080, 17280, 1080, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 1080, 66, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 66, 17280, 17280, 66, 17280, 66, 1080, 17280, 17280, 17280, 1080, 66, 17280, 1080, 66, 66, 66, 66, 66, 17280, 1080, 66, 17280, 66, 17280, 66, 66, 1080, 1080, 17280, 1080, 17280, 66, 1080, 66, 17280, 17280, 66, 17280, 1080, 66, 17280, 66, 66, 17280, 17280, 1080, 17280, 17280, 66, 17280, 1080, 1080, 66, 1080, 17280, 17280, 66, 17280, 1080, 66, 1080, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 1080, 17280, 17280, 1080, 66, 17280, 66, 1080, 1080, 66, 1080, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 1080, 17280, 1080, 66, 1080, 17280, 1080, 17280, 66, 17280, 66, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 66, 17280, 66, 17280, 1080, 1080, 66, 1080, 17280, 1080, 1080, 17280, 66, 17280, 17280, 1080, 66, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 66, 17280, 1080, 17280, 17280, 66, 17280, 1080, 1080, 17280, 66, 1080, 66, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 66, 66, 66, 66]
Prompts retrieved: 1583490 . Total input tokens: 353008931 . Total output tokens: 316540482
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 4.600371232721955,
    "estimated_duration": 3600.007349616939,
    "input_throughput": 4032.5626006137786,
    "output_throughput": 3572.5427064387804,
    "total_throughput": 7605.1053070525595,
    "itl": 94.81303448609685,
    "ttft": 2198393.3210869124,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 360,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1914051171764781,
    "arrivals": 527992,
    "finished_requests": 58602,
    "scheduler_time": 67.92774014442801
}
#Debug simulation 
Total elapsed time: 4.600468170829117. Arrivals time: 0.2650269167497754 Scheduler time: 4.111835854593664 Scheduler overhead time: 0.05307075893506408 Adapter cache time: 0.09099457273259759 Engine time: 0.05478882044553757 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_16-16-16/adapters_256_slots_192_rate_1.6-0.1-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_16-16-16/adapters_256_slots_192_rate_1.6-0.1-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 66, 17280, 17280, 66, 17280, 1080, 17280, 66, 1080, 66, 17280, 1080, 1080, 1080, 1080, 17280, 66, 66, 66, 1080, 17280, 66, 17280, 17280, 1080, 1080, 1080, 66, 17280, 66, 1080, 1080, 66, 1080, 66, 66, 1080, 1080, 17280, 1080, 66, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 66, 17280, 17280, 1080, 66, 66, 17280, 1080, 66, 1080, 1080, 17280, 1080, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 1080, 66, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 66, 17280, 17280, 66, 17280, 66, 1080, 17280, 17280, 17280, 1080, 66, 17280, 1080, 66, 66, 66, 66, 66, 17280, 1080, 66, 17280, 66, 17280, 66, 66, 1080, 1080, 17280, 1080, 17280, 66, 1080, 66, 17280, 17280, 66, 17280, 1080, 66, 17280, 66, 66, 17280, 17280, 1080, 17280, 17280, 66, 17280, 1080, 1080, 66, 1080, 17280, 17280, 66, 17280, 1080, 66, 1080, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 1080, 17280, 17280, 1080, 66, 17280, 66, 1080, 1080, 66, 1080, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 1080, 17280, 1080, 66, 1080, 17280, 1080, 17280, 66, 17280, 66, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 66, 17280, 66, 17280, 1080, 1080, 66, 1080, 17280, 1080, 1080, 17280, 66, 17280, 17280, 1080, 66, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 66, 17280, 1080, 17280, 17280, 66, 17280, 1080, 1080, 17280, 66, 1080, 66, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 66, 66, 66, 66]
Prompts retrieved: 1583490 . Total input tokens: 353008931 . Total output tokens: 316540482
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.970031682867557,
    "estimated_duration": 3600.0693336160994,
    "input_throughput": 4641.578384051729,
    "output_throughput": 4086.427686997648,
    "total_throughput": 8728.006071049376,
    "itl": 207.3981596850795,
    "ttft": 2107622.284638834,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 398,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1900400173710606,
    "arrivals": 527992,
    "finished_requests": 67374,
    "scheduler_time": 67.26199193224052
}
#Debug simulation 
Total elapsed time: 4.970155159942806. Arrivals time: 0.2402807902544737 Scheduler time: 4.611050327774137 Scheduler overhead time: 0.027281589340418577 Adapter cache time: 0.050959544256329536 Engine time: 0.028019641060382128 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_16-16-32/adapters_256_slots_192_rate_1.6-0.1-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_16-16-32/adapters_256_slots_192_rate_1.6-0.1-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 66, 17280, 17280, 66, 17280, 1080, 17280, 66, 1080, 66, 17280, 1080, 1080, 1080, 1080, 17280, 66, 66, 66, 1080, 17280, 66, 17280, 17280, 1080, 1080, 1080, 66, 17280, 66, 1080, 1080, 66, 1080, 66, 66, 1080, 1080, 17280, 1080, 66, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 66, 17280, 17280, 1080, 66, 66, 17280, 1080, 66, 1080, 1080, 17280, 1080, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 1080, 66, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 66, 17280, 17280, 66, 17280, 66, 1080, 17280, 17280, 17280, 1080, 66, 17280, 1080, 66, 66, 66, 66, 66, 17280, 1080, 66, 17280, 66, 17280, 66, 66, 1080, 1080, 17280, 1080, 17280, 66, 1080, 66, 17280, 17280, 66, 17280, 1080, 66, 17280, 66, 66, 17280, 17280, 1080, 17280, 17280, 66, 17280, 1080, 1080, 66, 1080, 17280, 17280, 66, 17280, 1080, 66, 1080, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 1080, 17280, 17280, 1080, 66, 17280, 66, 1080, 1080, 66, 1080, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 1080, 17280, 1080, 66, 1080, 17280, 1080, 17280, 66, 17280, 66, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 66, 17280, 66, 17280, 1080, 1080, 66, 1080, 17280, 1080, 1080, 17280, 66, 17280, 17280, 1080, 66, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 66, 17280, 1080, 17280, 17280, 66, 17280, 1080, 1080, 17280, 66, 1080, 66, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 66, 66, 66, 66]
Prompts retrieved: 1583490 . Total input tokens: 353008931 . Total output tokens: 316540482
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.633575466927141,
    "estimated_duration": 3600.0068660983907,
    "input_throughput": 4028.867871499109,
    "output_throughput": 3569.1759704685037,
    "total_throughput": 7598.043841967612,
    "itl": 94.60682688135584,
    "ttft": 2199378.042842673,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 360,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2072500942647488,
    "arrivals": 527992,
    "finished_requests": 58541,
    "scheduler_time": 67.90319707771968
}
#Debug simulation 
Total elapsed time: 4.6336718439124525. Arrivals time: 0.26688292529433966 Scheduler time: 4.142676948104054 Scheduler overhead time: 0.05299151921644807 Adapter cache time: 0.0919240121729672 Engine time: 0.05441978108137846 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-8/adapters_256_slots_192_rate_1.6-0.1-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-8/adapters_256_slots_192_rate_1.6-0.1-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 33, 17280, 17280, 33, 17280, 1080, 17280, 33, 1080, 33, 17280, 1080, 1080, 1080, 1080, 17280, 33, 33, 33, 1080, 17280, 33, 17280, 17280, 1080, 1080, 1080, 33, 17280, 33, 1080, 1080, 33, 1080, 33, 33, 1080, 1080, 17280, 1080, 33, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 33, 17280, 17280, 1080, 33, 33, 17280, 1080, 33, 1080, 1080, 17280, 1080, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 1080, 33, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 33, 17280, 17280, 33, 17280, 33, 1080, 17280, 17280, 17280, 1080, 33, 17280, 1080, 33, 33, 33, 33, 33, 17280, 1080, 33, 17280, 33, 17280, 33, 33, 1080, 1080, 17280, 1080, 17280, 33, 1080, 33, 17280, 17280, 33, 17280, 1080, 33, 17280, 33, 33, 17280, 17280, 1080, 17280, 17280, 33, 17280, 1080, 1080, 33, 1080, 17280, 17280, 33, 17280, 1080, 33, 1080, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 1080, 17280, 17280, 1080, 33, 17280, 33, 1080, 1080, 33, 1080, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 1080, 17280, 1080, 33, 1080, 17280, 1080, 17280, 33, 17280, 33, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 33, 17280, 33, 17280, 1080, 1080, 33, 1080, 17280, 1080, 1080, 17280, 33, 17280, 17280, 1080, 33, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 33, 17280, 1080, 17280, 17280, 33, 17280, 1080, 1080, 17280, 33, 1080, 33, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 33, 33, 33, 33]
Prompts retrieved: 1580685 . Total input tokens: 352385458 . Total output tokens: 315982175
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.084719259291887,
    "estimated_duration": 3600.037966100984,
    "input_throughput": 4689.257768657227,
    "output_throughput": 4117.976849020862,
    "total_throughput": 8807.234617678088,
    "itl": 207.24113329548524,
    "ttft": 2106056.62257606,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 266,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8140897398861114,
    "arrivals": 526966,
    "finished_requests": 68172,
    "scheduler_time": 67.74956085054859
}
#Debug simulation 
Total elapsed time: 5.084835531190038. Arrivals time: 0.3044240181334317 Scheduler time: 4.664449391886592 Scheduler overhead time: 0.027270483318716288 Adapter cache time: 0.04793855361640453 Engine time: 0.028126539662480354 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-16/adapters_256_slots_192_rate_1.6-0.1-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-16/adapters_256_slots_192_rate_1.6-0.1-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 33, 17280, 17280, 33, 17280, 1080, 17280, 33, 1080, 33, 17280, 1080, 1080, 1080, 1080, 17280, 33, 33, 33, 1080, 17280, 33, 17280, 17280, 1080, 1080, 1080, 33, 17280, 33, 1080, 1080, 33, 1080, 33, 33, 1080, 1080, 17280, 1080, 33, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 33, 17280, 17280, 1080, 33, 33, 17280, 1080, 33, 1080, 1080, 17280, 1080, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 1080, 33, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 33, 17280, 17280, 33, 17280, 33, 1080, 17280, 17280, 17280, 1080, 33, 17280, 1080, 33, 33, 33, 33, 33, 17280, 1080, 33, 17280, 33, 17280, 33, 33, 1080, 1080, 17280, 1080, 17280, 33, 1080, 33, 17280, 17280, 33, 17280, 1080, 33, 17280, 33, 33, 17280, 17280, 1080, 17280, 17280, 33, 17280, 1080, 1080, 33, 1080, 17280, 17280, 33, 17280, 1080, 33, 1080, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 1080, 17280, 17280, 1080, 33, 17280, 33, 1080, 1080, 33, 1080, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 1080, 17280, 1080, 33, 1080, 17280, 1080, 17280, 33, 17280, 33, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 33, 17280, 33, 17280, 1080, 1080, 33, 1080, 17280, 1080, 1080, 17280, 33, 17280, 17280, 1080, 33, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 33, 17280, 1080, 17280, 17280, 33, 17280, 1080, 1080, 17280, 33, 1080, 33, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 33, 33, 33, 33]
Prompts retrieved: 1580685 . Total input tokens: 352385458 . Total output tokens: 315982175
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.052337537985295,
    "estimated_duration": 3600.1953321394158,
    "input_throughput": 4686.615987020176,
    "output_throughput": 4116.795238216273,
    "total_throughput": 8803.41122523645,
    "itl": 205.00046137767316,
    "ttft": 2106640.1189752677,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 265,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8610073416470586,
    "arrivals": 526966,
    "finished_requests": 68135,
    "scheduler_time": 67.79028017924225
}
#Debug simulation 
Total elapsed time: 5.0524559752084315. Arrivals time: 0.2995038856752217 Scheduler time: 4.636085246689618 Scheduler overhead time: 0.027712191455066204 Adapter cache time: 0.048018611036241055 Engine time: 0.028361566364765167 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-32/adapters_256_slots_192_rate_1.6-0.1-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-32/adapters_256_slots_192_rate_1.6-0.1-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 33, 17280, 17280, 33, 17280, 1080, 17280, 33, 1080, 33, 17280, 1080, 1080, 1080, 1080, 17280, 33, 33, 33, 1080, 17280, 33, 17280, 17280, 1080, 1080, 1080, 33, 17280, 33, 1080, 1080, 33, 1080, 33, 33, 1080, 1080, 17280, 1080, 33, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 33, 17280, 17280, 1080, 33, 33, 17280, 1080, 33, 1080, 1080, 17280, 1080, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 1080, 33, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 33, 17280, 17280, 33, 17280, 33, 1080, 17280, 17280, 17280, 1080, 33, 17280, 1080, 33, 33, 33, 33, 33, 17280, 1080, 33, 17280, 33, 17280, 33, 33, 1080, 1080, 17280, 1080, 17280, 33, 1080, 33, 17280, 17280, 33, 17280, 1080, 33, 17280, 33, 33, 17280, 17280, 1080, 17280, 17280, 33, 17280, 1080, 1080, 33, 1080, 17280, 17280, 33, 17280, 1080, 33, 1080, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 1080, 17280, 17280, 1080, 33, 17280, 33, 1080, 1080, 33, 1080, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 1080, 17280, 1080, 33, 1080, 17280, 1080, 17280, 33, 17280, 33, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 33, 17280, 33, 17280, 1080, 1080, 33, 1080, 17280, 1080, 1080, 17280, 33, 17280, 17280, 1080, 33, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 33, 17280, 1080, 17280, 17280, 33, 17280, 1080, 1080, 17280, 33, 1080, 33, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 33, 33, 33, 33]
Prompts retrieved: 1580685 . Total input tokens: 352385458 . Total output tokens: 315982175
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.622538834344596,
    "estimated_duration": 3600.0486078825934,
    "input_throughput": 4051.898901603864,
    "output_throughput": 3580.054161429901,
    "total_throughput": 7631.953063033765,
    "itl": 94.23954413856265,
    "ttft": 2194454.9217681065,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 250,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8155138063058295,
    "arrivals": 526966,
    "finished_requests": 58847,
    "scheduler_time": 68.09734989993304
}
#Debug simulation 
Total elapsed time: 4.622641795314848. Arrivals time: 0.21747468039393425 Scheduler time: 4.185460712760687 Scheduler overhead time: 0.05331881111487746 Adapter cache time: 0.08666232880204916 Engine time: 0.054780539590865374 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-16-16/adapters_256_slots_192_rate_1.6-0.1-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-16-16/adapters_256_slots_192_rate_1.6-0.1-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 33, 17280, 17280, 33, 17280, 1080, 17280, 33, 1080, 33, 17280, 1080, 1080, 1080, 1080, 17280, 33, 33, 33, 1080, 17280, 33, 17280, 17280, 1080, 1080, 1080, 33, 17280, 33, 1080, 1080, 33, 1080, 33, 33, 1080, 1080, 17280, 1080, 33, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 33, 17280, 17280, 1080, 33, 33, 17280, 1080, 33, 1080, 1080, 17280, 1080, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 1080, 33, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 33, 17280, 17280, 33, 17280, 33, 1080, 17280, 17280, 17280, 1080, 33, 17280, 1080, 33, 33, 33, 33, 33, 17280, 1080, 33, 17280, 33, 17280, 33, 33, 1080, 1080, 17280, 1080, 17280, 33, 1080, 33, 17280, 17280, 33, 17280, 1080, 33, 17280, 33, 33, 17280, 17280, 1080, 17280, 17280, 33, 17280, 1080, 1080, 33, 1080, 17280, 17280, 33, 17280, 1080, 33, 1080, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 1080, 17280, 17280, 1080, 33, 17280, 33, 1080, 1080, 33, 1080, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 1080, 17280, 1080, 33, 1080, 17280, 1080, 17280, 33, 17280, 33, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 33, 17280, 33, 17280, 1080, 1080, 33, 1080, 17280, 1080, 1080, 17280, 33, 17280, 17280, 1080, 33, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 33, 17280, 1080, 17280, 17280, 33, 17280, 1080, 1080, 17280, 33, 1080, 33, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 33, 33, 33, 33]
Prompts retrieved: 1580685 . Total input tokens: 352385458 . Total output tokens: 315982175
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 5.071660882793367,
    "estimated_duration": 3600.049207060797,
    "input_throughput": 4686.71816121514,
    "output_throughput": 4116.886783361599,
    "total_throughput": 8803.604944576738,
    "itl": 204.98010491581425,
    "ttft": 2106612.664002626,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 265,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8279111208533894,
    "arrivals": 526966,
    "finished_requests": 68134,
    "scheduler_time": 67.78852114043882
}
#Debug simulation 
Total elapsed time: 5.071761119645089. Arrivals time: 0.29109761165454984 Scheduler time: 4.664567923173308 Scheduler overhead time: 0.02748511778190732 Adapter cache time: 0.04771841084584594 Engine time: 0.028198425192385912 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-16-32/adapters_256_slots_192_rate_1.6-0.1-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-16-32/adapters_256_slots_192_rate_1.6-0.1-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 33, 17280, 17280, 33, 17280, 1080, 17280, 33, 1080, 33, 17280, 1080, 1080, 1080, 1080, 17280, 33, 33, 33, 1080, 17280, 33, 17280, 17280, 1080, 1080, 1080, 33, 17280, 33, 1080, 1080, 33, 1080, 33, 33, 1080, 1080, 17280, 1080, 33, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 33, 17280, 17280, 1080, 33, 33, 17280, 1080, 33, 1080, 1080, 17280, 1080, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 1080, 33, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 33, 17280, 17280, 33, 17280, 33, 1080, 17280, 17280, 17280, 1080, 33, 17280, 1080, 33, 33, 33, 33, 33, 17280, 1080, 33, 17280, 33, 17280, 33, 33, 1080, 1080, 17280, 1080, 17280, 33, 1080, 33, 17280, 17280, 33, 17280, 1080, 33, 17280, 33, 33, 17280, 17280, 1080, 17280, 17280, 33, 17280, 1080, 1080, 33, 1080, 17280, 17280, 33, 17280, 1080, 33, 1080, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 1080, 17280, 17280, 1080, 33, 17280, 33, 1080, 1080, 33, 1080, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 1080, 17280, 1080, 33, 1080, 17280, 1080, 17280, 33, 17280, 33, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 33, 17280, 33, 17280, 1080, 1080, 33, 1080, 17280, 1080, 1080, 17280, 33, 17280, 17280, 1080, 33, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 33, 17280, 1080, 17280, 17280, 33, 17280, 1080, 1080, 17280, 33, 1080, 33, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 33, 33, 33, 33]
Prompts retrieved: 1580685 . Total input tokens: 352385458 . Total output tokens: 315982175
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 4.698995936196297,
    "estimated_duration": 3600.016638143061,
    "input_throughput": 4051.9348842577006,
    "output_throughput": 3580.0859538938134,
    "total_throughput": 7632.020838151514,
    "itl": 94.23769318047673,
    "ttft": 2194508.7692051935,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 250,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8255741092190183,
    "arrivals": 526966,
    "finished_requests": 58847,
    "scheduler_time": 68.09525355938044
}
#Debug simulation 
Total elapsed time: 4.6991087212227285. Arrivals time: 0.2804219429381192 Scheduler time: 4.1965074157342315 Scheduler overhead time: 0.053311537485569715 Adapter cache time: 0.08872055448591709 Engine time: 0.05519754812121391 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_16-16-16/adapters_256_slots_192_rate_1.6-0.1-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_16-16-16/adapters_256_slots_192_rate_1.6-0.1-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 33, 17280, 17280, 33, 17280, 1080, 17280, 33, 1080, 33, 17280, 1080, 1080, 1080, 1080, 17280, 33, 33, 33, 1080, 17280, 33, 17280, 17280, 1080, 1080, 1080, 33, 17280, 33, 1080, 1080, 33, 1080, 33, 33, 1080, 1080, 17280, 1080, 33, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 33, 17280, 17280, 1080, 33, 33, 17280, 1080, 33, 1080, 1080, 17280, 1080, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 1080, 33, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 33, 17280, 17280, 33, 17280, 33, 1080, 17280, 17280, 17280, 1080, 33, 17280, 1080, 33, 33, 33, 33, 33, 17280, 1080, 33, 17280, 33, 17280, 33, 33, 1080, 1080, 17280, 1080, 17280, 33, 1080, 33, 17280, 17280, 33, 17280, 1080, 33, 17280, 33, 33, 17280, 17280, 1080, 17280, 17280, 33, 17280, 1080, 1080, 33, 1080, 17280, 17280, 33, 17280, 1080, 33, 1080, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 1080, 17280, 17280, 1080, 33, 17280, 33, 1080, 1080, 33, 1080, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 1080, 17280, 1080, 33, 1080, 17280, 1080, 17280, 33, 17280, 33, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 33, 17280, 33, 17280, 1080, 1080, 33, 1080, 17280, 1080, 1080, 17280, 33, 17280, 17280, 1080, 33, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 33, 17280, 1080, 17280, 17280, 33, 17280, 1080, 1080, 17280, 33, 1080, 33, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 33, 33, 33, 33]
Prompts retrieved: 1580685 . Total input tokens: 352385458 . Total output tokens: 315982175
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.027580032125115,
    "estimated_duration": 3600.0188592714135,
    "input_throughput": 4686.7576697680715,
    "output_throughput": 4116.921488294518,
    "total_throughput": 8803.679158062589,
    "itl": 204.98161387587035,
    "ttft": 2106595.2909394866,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 265,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7923633281490776,
    "arrivals": 526966,
    "finished_requests": 68134,
    "scheduler_time": 67.78840477138992
}
#Debug simulation 
Total elapsed time: 5.0276782577857375. Arrivals time: 0.29063932690769434 Scheduler time: 4.621246366761625 Scheduler overhead time: 0.02743113785982132 Adapter cache time: 0.04751669894903898 Engine time: 0.028177170548588037 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_16-16-32/adapters_256_slots_192_rate_1.6-0.1-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_16-16-32/adapters_256_slots_192_rate_1.6-0.1-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 33, 17280, 17280, 33, 17280, 1080, 17280, 33, 1080, 33, 17280, 1080, 1080, 1080, 1080, 17280, 33, 33, 33, 1080, 17280, 33, 17280, 17280, 1080, 1080, 1080, 33, 17280, 33, 1080, 1080, 33, 1080, 33, 33, 1080, 1080, 17280, 1080, 33, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 33, 17280, 17280, 1080, 33, 33, 17280, 1080, 33, 1080, 1080, 17280, 1080, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 1080, 33, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 33, 17280, 17280, 33, 17280, 33, 1080, 17280, 17280, 17280, 1080, 33, 17280, 1080, 33, 33, 33, 33, 33, 17280, 1080, 33, 17280, 33, 17280, 33, 33, 1080, 1080, 17280, 1080, 17280, 33, 1080, 33, 17280, 17280, 33, 17280, 1080, 33, 17280, 33, 33, 17280, 17280, 1080, 17280, 17280, 33, 17280, 1080, 1080, 33, 1080, 17280, 17280, 33, 17280, 1080, 33, 1080, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 1080, 17280, 17280, 1080, 33, 17280, 33, 1080, 1080, 33, 1080, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 1080, 17280, 1080, 33, 1080, 17280, 1080, 17280, 33, 17280, 33, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 33, 17280, 33, 17280, 1080, 1080, 33, 1080, 17280, 1080, 1080, 17280, 33, 17280, 17280, 1080, 33, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 33, 17280, 1080, 17280, 17280, 33, 17280, 1080, 1080, 17280, 33, 1080, 33, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 33, 33, 33, 33]
Prompts retrieved: 1580685 . Total input tokens: 352385458 . Total output tokens: 315982175
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.608037549071014,
    "estimated_duration": 3600.0492579804345,
    "input_throughput": 4052.0703897766725,
    "output_throughput": 3580.3648995710637,
    "total_throughput": 7632.435289347736,
    "itl": 94.23724312051861,
    "ttft": 2194492.345017443,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 250,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8358859197050368,
    "arrivals": 526966,
    "finished_requests": 58851,
    "scheduler_time": 68.09587880942607
}
#Debug simulation 
Total elapsed time: 4.608138781040907. Arrivals time: 0.26850955514237285 Scheduler time: 4.119601166807115 Scheduler overhead time: 0.053238760214298964 Adapter cache time: 0.08732046885415912 Engine time: 0.05478013586252928 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-8-8/adapters_256_slots_192_rate_1.6-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-8-8/adapters_256_slots_192_rate_1.6-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 270, 17280, 17280, 270, 17280, 540, 17280, 270, 540, 270, 17280, 540, 540, 540, 540, 17280, 270, 270, 270, 540, 17280, 270, 17280, 17280, 540, 540, 540, 270, 17280, 270, 540, 540, 270, 540, 270, 270, 540, 540, 17280, 540, 270, 540, 17280, 540, 540, 17280, 540, 17280, 270, 17280, 17280, 540, 270, 270, 17280, 540, 270, 540, 540, 17280, 540, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 17280, 17280, 270, 17280, 270, 540, 17280, 17280, 17280, 540, 270, 17280, 540, 270, 270, 270, 270, 270, 17280, 540, 270, 17280, 270, 17280, 270, 270, 540, 540, 17280, 540, 17280, 270, 540, 270, 17280, 17280, 270, 17280, 540, 270, 17280, 270, 270, 17280, 17280, 540, 17280, 17280, 270, 17280, 540, 540, 270, 540, 17280, 17280, 270, 17280, 540, 270, 540, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 540, 17280, 17280, 540, 270, 17280, 270, 540, 540, 270, 540, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 540, 17280, 540, 270, 540, 17280, 540, 17280, 270, 17280, 270, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 270, 17280, 270, 17280, 540, 540, 270, 540, 17280, 540, 540, 17280, 270, 17280, 17280, 540, 270, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 270, 17280, 540, 17280, 17280, 270, 17280, 540, 540, 17280, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 17280, 540, 270, 270, 270, 270]
Prompts retrieved: 1554930 . Total input tokens: 346648835 . Total output tokens: 310860275
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.164043732918799,
    "estimated_duration": 3600.09361192022,
    "input_throughput": 4780.783183807224,
    "output_throughput": 4221.621890518996,
    "total_throughput": 9002.40507432622,
    "itl": 203.53034348432752,
    "ttft": 2090316.5269607084,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1132,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.4644721261319615,
    "arrivals": 518548,
    "finished_requests": 69503,
    "scheduler_time": 69.31349059605938
}
#Debug simulation 
Total elapsed time: 5.164158141706139. Arrivals time: 0.3029494462534785 Scheduler time: 4.7389117064885795 Scheduler overhead time: 0.027803486678749323 Adapter cache time: 0.05080420384183526 Engine time: 0.02853046916425228 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-8-16/adapters_256_slots_192_rate_1.6-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-8-16/adapters_256_slots_192_rate_1.6-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 270, 17280, 17280, 270, 17280, 540, 17280, 270, 540, 270, 17280, 540, 540, 540, 540, 17280, 270, 270, 270, 540, 17280, 270, 17280, 17280, 540, 540, 540, 270, 17280, 270, 540, 540, 270, 540, 270, 270, 540, 540, 17280, 540, 270, 540, 17280, 540, 540, 17280, 540, 17280, 270, 17280, 17280, 540, 270, 270, 17280, 540, 270, 540, 540, 17280, 540, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 17280, 17280, 270, 17280, 270, 540, 17280, 17280, 17280, 540, 270, 17280, 540, 270, 270, 270, 270, 270, 17280, 540, 270, 17280, 270, 17280, 270, 270, 540, 540, 17280, 540, 17280, 270, 540, 270, 17280, 17280, 270, 17280, 540, 270, 17280, 270, 270, 17280, 17280, 540, 17280, 17280, 270, 17280, 540, 540, 270, 540, 17280, 17280, 270, 17280, 540, 270, 540, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 540, 17280, 17280, 540, 270, 17280, 270, 540, 540, 270, 540, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 540, 17280, 540, 270, 540, 17280, 540, 17280, 270, 17280, 270, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 270, 17280, 270, 17280, 540, 540, 270, 540, 17280, 540, 540, 17280, 270, 17280, 17280, 540, 270, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 270, 17280, 540, 17280, 17280, 270, 17280, 540, 540, 17280, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 17280, 540, 270, 270, 270, 270]
Prompts retrieved: 1554930 . Total input tokens: 346648835 . Total output tokens: 310860275
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.17605188023299,
    "estimated_duration": 3600.1305868594263,
    "input_throughput": 4778.290282799595,
    "output_throughput": 4219.422221917624,
    "total_throughput": 8997.71250471722,
    "itl": 200.69750537379576,
    "ttft": 2091092.2511717845,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1131,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.692279325549031,
    "arrivals": 518548,
    "finished_requests": 69458,
    "scheduler_time": 69.3704019940515
}
#Debug simulation 
Total elapsed time: 5.176173896063119. Arrivals time: 0.29721470456570387 Scheduler time: 4.756345423404127 Scheduler overhead time: 0.028354444541037083 Adapter cache time: 0.05237779952585697 Engine time: 0.02884000726044178 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-8-32/adapters_256_slots_192_rate_1.6-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-8-32/adapters_256_slots_192_rate_1.6-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 270, 17280, 17280, 270, 17280, 540, 17280, 270, 540, 270, 17280, 540, 540, 540, 540, 17280, 270, 270, 270, 540, 17280, 270, 17280, 17280, 540, 540, 540, 270, 17280, 270, 540, 540, 270, 540, 270, 270, 540, 540, 17280, 540, 270, 540, 17280, 540, 540, 17280, 540, 17280, 270, 17280, 17280, 540, 270, 270, 17280, 540, 270, 540, 540, 17280, 540, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 17280, 17280, 270, 17280, 270, 540, 17280, 17280, 17280, 540, 270, 17280, 540, 270, 270, 270, 270, 270, 17280, 540, 270, 17280, 270, 17280, 270, 270, 540, 540, 17280, 540, 17280, 270, 540, 270, 17280, 17280, 270, 17280, 540, 270, 17280, 270, 270, 17280, 17280, 540, 17280, 17280, 270, 17280, 540, 540, 270, 540, 17280, 17280, 270, 17280, 540, 270, 540, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 540, 17280, 17280, 540, 270, 17280, 270, 540, 540, 270, 540, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 540, 17280, 540, 270, 540, 17280, 540, 17280, 270, 17280, 270, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 270, 17280, 270, 17280, 540, 540, 270, 540, 17280, 540, 540, 17280, 270, 17280, 17280, 540, 270, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 270, 17280, 540, 17280, 17280, 270, 17280, 540, 540, 17280, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 17280, 540, 270, 270, 270, 270]
Prompts retrieved: 1554930 . Total input tokens: 346648835 . Total output tokens: 310860275
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.702880484052002,
    "estimated_duration": 3600.028474373915,
    "input_throughput": 4107.036404086041,
    "output_throughput": 3647.1714302991563,
    "total_throughput": 7754.207834385197,
    "itl": 92.37960924047914,
    "ttft": 2185753.180371154,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 989,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.2383566952310128,
    "arrivals": 518548,
    "finished_requests": 59679,
    "scheduler_time": 69.4012951481174
}
#Debug simulation 
Total elapsed time: 4.702977180015296. Arrivals time: 0.2691424577496946 Scheduler time: 4.218291088473052 Scheduler overhead time: 0.05416970746591687 Adapter cache time: 0.08024212811142206 Engine time: 0.05575745413079858 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-16-16/adapters_256_slots_192_rate_1.6-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-16-16/adapters_256_slots_192_rate_1.6-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 270, 17280, 17280, 270, 17280, 540, 17280, 270, 540, 270, 17280, 540, 540, 540, 540, 17280, 270, 270, 270, 540, 17280, 270, 17280, 17280, 540, 540, 540, 270, 17280, 270, 540, 540, 270, 540, 270, 270, 540, 540, 17280, 540, 270, 540, 17280, 540, 540, 17280, 540, 17280, 270, 17280, 17280, 540, 270, 270, 17280, 540, 270, 540, 540, 17280, 540, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 17280, 17280, 270, 17280, 270, 540, 17280, 17280, 17280, 540, 270, 17280, 540, 270, 270, 270, 270, 270, 17280, 540, 270, 17280, 270, 17280, 270, 270, 540, 540, 17280, 540, 17280, 270, 540, 270, 17280, 17280, 270, 17280, 540, 270, 17280, 270, 270, 17280, 17280, 540, 17280, 17280, 270, 17280, 540, 540, 270, 540, 17280, 17280, 270, 17280, 540, 270, 540, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 540, 17280, 17280, 540, 270, 17280, 270, 540, 540, 270, 540, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 540, 17280, 540, 270, 540, 17280, 540, 17280, 270, 17280, 270, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 270, 17280, 270, 17280, 540, 540, 270, 540, 17280, 540, 540, 17280, 270, 17280, 17280, 540, 270, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 270, 17280, 540, 17280, 17280, 270, 17280, 540, 540, 17280, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 17280, 540, 270, 270, 270, 270]
Prompts retrieved: 1554930 . Total input tokens: 346648835 . Total output tokens: 310860275
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 5.146311592310667,
    "estimated_duration": 3600.065375204975,
    "input_throughput": 4778.3898921614855,
    "output_throughput": 4219.518096705426,
    "total_throughput": 8997.907988866911,
    "itl": 200.7004670757957,
    "ttft": 2091068.641457769,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1131,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.5472279875026658,
    "arrivals": 518548,
    "finished_requests": 69459,
    "scheduler_time": 69.37155390608157
}
#Debug simulation 
Total elapsed time: 5.146408378146589. Arrivals time: 0.29668602626770735 Scheduler time: 4.7279930636286736 Scheduler overhead time: 0.02813879307359457 Adapter cache time: 0.0515389172360301 Engine time: 0.02902696654200554 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-16-32/adapters_256_slots_192_rate_1.6-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-16-32/adapters_256_slots_192_rate_1.6-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 270, 17280, 17280, 270, 17280, 540, 17280, 270, 540, 270, 17280, 540, 540, 540, 540, 17280, 270, 270, 270, 540, 17280, 270, 17280, 17280, 540, 540, 540, 270, 17280, 270, 540, 540, 270, 540, 270, 270, 540, 540, 17280, 540, 270, 540, 17280, 540, 540, 17280, 540, 17280, 270, 17280, 17280, 540, 270, 270, 17280, 540, 270, 540, 540, 17280, 540, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 17280, 17280, 270, 17280, 270, 540, 17280, 17280, 17280, 540, 270, 17280, 540, 270, 270, 270, 270, 270, 17280, 540, 270, 17280, 270, 17280, 270, 270, 540, 540, 17280, 540, 17280, 270, 540, 270, 17280, 17280, 270, 17280, 540, 270, 17280, 270, 270, 17280, 17280, 540, 17280, 17280, 270, 17280, 540, 540, 270, 540, 17280, 17280, 270, 17280, 540, 270, 540, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 540, 17280, 17280, 540, 270, 17280, 270, 540, 540, 270, 540, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 540, 17280, 540, 270, 540, 17280, 540, 17280, 270, 17280, 270, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 270, 17280, 270, 17280, 540, 540, 270, 540, 17280, 540, 540, 17280, 270, 17280, 17280, 540, 270, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 270, 17280, 540, 17280, 17280, 270, 17280, 540, 540, 17280, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 17280, 540, 270, 270, 270, 270]
Prompts retrieved: 1554930 . Total input tokens: 346648835 . Total output tokens: 310860275
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 4.677939772140235,
    "estimated_duration": 3600.0853649662504,
    "input_throughput": 4101.816902371823,
    "output_throughput": 3642.0572488627413,
    "total_throughput": 7743.874151234565,
    "itl": 92.17256528549214,
    "ttft": 2186182.70269274,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 988,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.275091386754067,
    "arrivals": 518548,
    "finished_requests": 59595,
    "scheduler_time": 69.37936033025666
}
#Debug simulation 
Total elapsed time: 4.678034520242363. Arrivals time: 0.26789151690900326 Scheduler time: 4.194467931520194 Scheduler overhead time: 0.05433297622948885 Adapter cache time: 0.07997246971353889 Engine time: 0.05595775507390499 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_16-16-16/adapters_256_slots_192_rate_1.6-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_16-16-16/adapters_256_slots_192_rate_1.6-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 270, 17280, 17280, 270, 17280, 540, 17280, 270, 540, 270, 17280, 540, 540, 540, 540, 17280, 270, 270, 270, 540, 17280, 270, 17280, 17280, 540, 540, 540, 270, 17280, 270, 540, 540, 270, 540, 270, 270, 540, 540, 17280, 540, 270, 540, 17280, 540, 540, 17280, 540, 17280, 270, 17280, 17280, 540, 270, 270, 17280, 540, 270, 540, 540, 17280, 540, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 17280, 17280, 270, 17280, 270, 540, 17280, 17280, 17280, 540, 270, 17280, 540, 270, 270, 270, 270, 270, 17280, 540, 270, 17280, 270, 17280, 270, 270, 540, 540, 17280, 540, 17280, 270, 540, 270, 17280, 17280, 270, 17280, 540, 270, 17280, 270, 270, 17280, 17280, 540, 17280, 17280, 270, 17280, 540, 540, 270, 540, 17280, 17280, 270, 17280, 540, 270, 540, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 540, 17280, 17280, 540, 270, 17280, 270, 540, 540, 270, 540, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 540, 17280, 540, 270, 540, 17280, 540, 17280, 270, 17280, 270, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 270, 17280, 270, 17280, 540, 540, 270, 540, 17280, 540, 540, 17280, 270, 17280, 17280, 540, 270, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 270, 17280, 540, 17280, 17280, 270, 17280, 540, 540, 17280, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 17280, 540, 270, 270, 270, 270]
Prompts retrieved: 1554930 . Total input tokens: 346648835 . Total output tokens: 310860275
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.198101350106299,
    "estimated_duration": 3600.1202196243535,
    "input_throughput": 4778.519868926775,
    "output_throughput": 4219.609366707505,
    "total_throughput": 8998.12923563428,
    "itl": 200.69188620219273,
    "ttft": 2091073.683144998,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1131,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.3817468835342774,
    "arrivals": 518548,
    "finished_requests": 69463,
    "scheduler_time": 69.37576639453634
}
#Debug simulation 
Total elapsed time: 5.198200754355639. Arrivals time: 0.2980293659493327 Scheduler time: 4.777789854444563 Scheduler overhead time: 0.028349398635327816 Adapter cache time: 0.052084177266806364 Engine time: 0.028917774558067322 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_16-16-32/adapters_256_slots_192_rate_1.6-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_16-16-32/adapters_256_slots_192_rate_1.6-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 270, 17280, 17280, 270, 17280, 540, 17280, 270, 540, 270, 17280, 540, 540, 540, 540, 17280, 270, 270, 270, 540, 17280, 270, 17280, 17280, 540, 540, 540, 270, 17280, 270, 540, 540, 270, 540, 270, 270, 540, 540, 17280, 540, 270, 540, 17280, 540, 540, 17280, 540, 17280, 270, 17280, 17280, 540, 270, 270, 17280, 540, 270, 540, 540, 17280, 540, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 17280, 17280, 270, 17280, 270, 540, 17280, 17280, 17280, 540, 270, 17280, 540, 270, 270, 270, 270, 270, 17280, 540, 270, 17280, 270, 17280, 270, 270, 540, 540, 17280, 540, 17280, 270, 540, 270, 17280, 17280, 270, 17280, 540, 270, 17280, 270, 270, 17280, 17280, 540, 17280, 17280, 270, 17280, 540, 540, 270, 540, 17280, 17280, 270, 17280, 540, 270, 540, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 540, 17280, 17280, 540, 270, 17280, 270, 540, 540, 270, 540, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 540, 17280, 540, 270, 540, 17280, 540, 17280, 270, 17280, 270, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 270, 17280, 270, 17280, 540, 540, 270, 540, 17280, 540, 540, 17280, 270, 17280, 17280, 540, 270, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 270, 17280, 540, 17280, 17280, 270, 17280, 540, 540, 17280, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 17280, 540, 270, 270, 270, 270]
Prompts retrieved: 1554930 . Total input tokens: 346648835 . Total output tokens: 310860275
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.711967649869621,
    "estimated_duration": 3600.011232586764,
    "input_throughput": 4107.122740663185,
    "output_throughput": 3647.068620551468,
    "total_throughput": 7754.191361214653,
    "itl": 92.38490070193568,
    "ttft": 2185764.135838989,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 988,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.3199854885042126,
    "arrivals": 518548,
    "finished_requests": 59678,
    "scheduler_time": 69.39862696719473
}
#Debug simulation 
Total elapsed time: 4.712090074084699. Arrivals time: 0.2698292606510222 Scheduler time: 4.22614646749571 Scheduler overhead time: 0.054583640303462744 Adapter cache time: 0.08005436416715384 Engine time: 0.056042478419840336 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-8/adapters_256_slots_192_rate_1.6-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-8/adapters_256_slots_192_rate_1.6-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 135, 17280, 17280, 135, 17280, 540, 17280, 135, 540, 135, 17280, 540, 540, 540, 540, 17280, 135, 135, 135, 540, 17280, 135, 17280, 17280, 540, 540, 540, 135, 17280, 135, 540, 540, 135, 540, 135, 135, 540, 540, 17280, 540, 135, 540, 17280, 540, 540, 17280, 540, 17280, 135, 17280, 17280, 540, 135, 135, 17280, 540, 135, 540, 540, 17280, 540, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 17280, 17280, 135, 17280, 135, 540, 17280, 17280, 17280, 540, 135, 17280, 540, 135, 135, 135, 135, 135, 17280, 540, 135, 17280, 135, 17280, 135, 135, 540, 540, 17280, 540, 17280, 135, 540, 135, 17280, 17280, 135, 17280, 540, 135, 17280, 135, 135, 17280, 17280, 540, 17280, 17280, 135, 17280, 540, 540, 135, 540, 17280, 17280, 135, 17280, 540, 135, 540, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 540, 17280, 17280, 540, 135, 17280, 135, 540, 540, 135, 540, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 540, 17280, 540, 135, 540, 17280, 540, 17280, 135, 17280, 135, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 135, 17280, 135, 17280, 540, 540, 135, 540, 17280, 540, 540, 17280, 135, 17280, 17280, 540, 135, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 135, 17280, 540, 17280, 17280, 135, 17280, 540, 540, 17280, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 17280, 540, 135, 135, 135, 135]
Prompts retrieved: 1543455 . Total input tokens: 344115126 . Total output tokens: 308543642
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.248848537914455,
    "estimated_duration": 3600.0969985519187,
    "input_throughput": 4905.424494702074,
    "output_throughput": 4340.433606729292,
    "total_throughput": 9245.858101431366,
    "itl": 198.2353961634995,
    "ttft": 2073781.2261440181,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 741,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.267821418254213,
    "arrivals": 514751,
    "finished_requests": 71545,
    "scheduler_time": 71.27895908809919
}
#Debug simulation 
Total elapsed time: 5.248953070025891. Arrivals time: 0.2532153273932636 Scheduler time: 4.880258836317807 Scheduler overhead time: 0.028515718411654234 Adapter cache time: 0.04415903985500336 Engine time: 0.02954179933294654 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-16/adapters_256_slots_192_rate_1.6-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-16/adapters_256_slots_192_rate_1.6-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 135, 17280, 17280, 135, 17280, 540, 17280, 135, 540, 135, 17280, 540, 540, 540, 540, 17280, 135, 135, 135, 540, 17280, 135, 17280, 17280, 540, 540, 540, 135, 17280, 135, 540, 540, 135, 540, 135, 135, 540, 540, 17280, 540, 135, 540, 17280, 540, 540, 17280, 540, 17280, 135, 17280, 17280, 540, 135, 135, 17280, 540, 135, 540, 540, 17280, 540, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 17280, 17280, 135, 17280, 135, 540, 17280, 17280, 17280, 540, 135, 17280, 540, 135, 135, 135, 135, 135, 17280, 540, 135, 17280, 135, 17280, 135, 135, 540, 540, 17280, 540, 17280, 135, 540, 135, 17280, 17280, 135, 17280, 540, 135, 17280, 135, 135, 17280, 17280, 540, 17280, 17280, 135, 17280, 540, 540, 135, 540, 17280, 17280, 135, 17280, 540, 135, 540, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 540, 17280, 17280, 540, 135, 17280, 135, 540, 540, 135, 540, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 540, 17280, 540, 135, 540, 17280, 540, 17280, 135, 17280, 135, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 135, 17280, 135, 17280, 540, 540, 135, 540, 17280, 540, 540, 17280, 135, 17280, 17280, 540, 135, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 135, 17280, 540, 17280, 17280, 135, 17280, 540, 540, 17280, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 17280, 540, 135, 135, 135, 135]
Prompts retrieved: 1543455 . Total input tokens: 344115126 . Total output tokens: 308543642
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.242207389790565,
    "estimated_duration": 3600.094968093232,
    "input_throughput": 4901.88818806265,
    "output_throughput": 4336.846427212268,
    "total_throughput": 9238.73461527492,
    "itl": 196.15224250575443,
    "ttft": 2074810.8361044475,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 741,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.4150217839214063,
    "arrivals": 514751,
    "finished_requests": 71484,
    "scheduler_time": 71.30452651000773
}
#Debug simulation 
Total elapsed time: 5.242306603584439. Arrivals time: 0.25792828295379877 Scheduler time: 4.868401580024511 Scheduler overhead time: 0.028758829459547997 Adapter cache time: 0.04442768916487694 Engine time: 0.029444084968417883 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-32/adapters_256_slots_192_rate_1.6-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-32/adapters_256_slots_192_rate_1.6-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 135, 17280, 17280, 135, 17280, 540, 17280, 135, 540, 135, 17280, 540, 540, 540, 540, 17280, 135, 135, 135, 540, 17280, 135, 17280, 17280, 540, 540, 540, 135, 17280, 135, 540, 540, 135, 540, 135, 135, 540, 540, 17280, 540, 135, 540, 17280, 540, 540, 17280, 540, 17280, 135, 17280, 17280, 540, 135, 135, 17280, 540, 135, 540, 540, 17280, 540, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 17280, 17280, 135, 17280, 135, 540, 17280, 17280, 17280, 540, 135, 17280, 540, 135, 135, 135, 135, 135, 17280, 540, 135, 17280, 135, 17280, 135, 135, 540, 540, 17280, 540, 17280, 135, 540, 135, 17280, 17280, 135, 17280, 540, 135, 17280, 135, 135, 17280, 17280, 540, 17280, 17280, 135, 17280, 540, 540, 135, 540, 17280, 17280, 135, 17280, 540, 135, 540, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 540, 17280, 17280, 540, 135, 17280, 135, 540, 540, 135, 540, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 540, 17280, 540, 135, 540, 17280, 540, 17280, 135, 17280, 135, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 135, 17280, 135, 17280, 540, 540, 135, 540, 17280, 540, 540, 17280, 135, 17280, 17280, 540, 135, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 135, 17280, 540, 17280, 17280, 135, 17280, 540, 540, 17280, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 17280, 540, 135, 135, 135, 135]
Prompts retrieved: 1543455 . Total input tokens: 344115126 . Total output tokens: 308543642
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.691106885671616,
    "estimated_duration": 3600.06332417245,
    "input_throughput": 4157.390204640483,
    "output_throughput": 3693.4761426888335,
    "total_throughput": 7850.866347329316,
    "itl": 91.40110770542023,
    "ttft": 2179949.542195747,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 619,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0235586301237465,
    "arrivals": 514751,
    "finished_requests": 60645,
    "scheduler_time": 70.26348433887256
}
#Debug simulation 
Total elapsed time: 4.6912021967582405. Arrivals time: 0.21806130092591047 Scheduler time: 4.261236170772463 Scheduler overhead time: 0.054964006412774324 Adapter cache time: 0.07450471958145499 Engine time: 0.0567367454059422 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-16-16/adapters_256_slots_192_rate_1.6-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-16-16/adapters_256_slots_192_rate_1.6-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 135, 17280, 17280, 135, 17280, 540, 17280, 135, 540, 135, 17280, 540, 540, 540, 540, 17280, 135, 135, 135, 540, 17280, 135, 17280, 17280, 540, 540, 540, 135, 17280, 135, 540, 540, 135, 540, 135, 135, 540, 540, 17280, 540, 135, 540, 17280, 540, 540, 17280, 540, 17280, 135, 17280, 17280, 540, 135, 135, 17280, 540, 135, 540, 540, 17280, 540, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 17280, 17280, 135, 17280, 135, 540, 17280, 17280, 17280, 540, 135, 17280, 540, 135, 135, 135, 135, 135, 17280, 540, 135, 17280, 135, 17280, 135, 135, 540, 540, 17280, 540, 17280, 135, 540, 135, 17280, 17280, 135, 17280, 540, 135, 17280, 135, 135, 17280, 17280, 540, 17280, 17280, 135, 17280, 540, 540, 135, 540, 17280, 17280, 135, 17280, 540, 135, 540, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 540, 17280, 17280, 540, 135, 17280, 135, 540, 540, 135, 540, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 540, 17280, 540, 135, 540, 17280, 540, 17280, 135, 17280, 135, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 135, 17280, 135, 17280, 540, 540, 135, 540, 17280, 540, 540, 17280, 135, 17280, 17280, 540, 135, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 135, 17280, 540, 17280, 17280, 135, 17280, 540, 540, 17280, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 17280, 540, 135, 135, 135, 135]
Prompts retrieved: 1543455 . Total input tokens: 344115126 . Total output tokens: 308543642
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 5.247168208006769,
    "estimated_duration": 3600.0955253575685,
    "input_throughput": 4901.904651057067,
    "output_throughput": 4336.953808593521,
    "total_throughput": 9238.858459650588,
    "itl": 196.1446365136899,
    "ttft": 2074799.9883153285,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 741,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.318184693451021,
    "arrivals": 514751,
    "finished_requests": 71486,
    "scheduler_time": 71.30654287587653
}
#Debug simulation 
Total elapsed time: 5.247267488855869. Arrivals time: 0.24817729461938143 Scheduler time: 4.88295307289809 Scheduler overhead time: 0.02881546737626195 Adapter cache time: 0.04455035598948598 Engine time: 0.029470847453922033 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-16-32/adapters_256_slots_192_rate_1.6-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-16-32/adapters_256_slots_192_rate_1.6-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 135, 17280, 17280, 135, 17280, 540, 17280, 135, 540, 135, 17280, 540, 540, 540, 540, 17280, 135, 135, 135, 540, 17280, 135, 17280, 17280, 540, 540, 540, 135, 17280, 135, 540, 540, 135, 540, 135, 135, 540, 540, 17280, 540, 135, 540, 17280, 540, 540, 17280, 540, 17280, 135, 17280, 17280, 540, 135, 135, 17280, 540, 135, 540, 540, 17280, 540, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 17280, 17280, 135, 17280, 135, 540, 17280, 17280, 17280, 540, 135, 17280, 540, 135, 135, 135, 135, 135, 17280, 540, 135, 17280, 135, 17280, 135, 135, 540, 540, 17280, 540, 17280, 135, 540, 135, 17280, 17280, 135, 17280, 540, 135, 17280, 135, 135, 17280, 17280, 540, 17280, 17280, 135, 17280, 540, 540, 135, 540, 17280, 17280, 135, 17280, 540, 135, 540, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 540, 17280, 17280, 540, 135, 17280, 135, 540, 540, 135, 540, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 540, 17280, 540, 135, 540, 17280, 540, 17280, 135, 17280, 135, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 135, 17280, 135, 17280, 540, 540, 135, 540, 17280, 540, 540, 17280, 135, 17280, 17280, 540, 135, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 135, 17280, 540, 17280, 17280, 135, 17280, 540, 540, 17280, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 17280, 540, 135, 135, 135, 135]
Prompts retrieved: 1543455 . Total input tokens: 344115126 . Total output tokens: 308543642
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 4.680584236048162,
    "estimated_duration": 3600.087384624635,
    "input_throughput": 4161.7373133741785,
    "output_throughput": 3698.5780003193777,
    "total_throughput": 7860.315313693555,
    "itl": 91.6685718625287,
    "ttft": 2179489.091994244,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 619,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0495496500469783,
    "arrivals": 514751,
    "finished_requests": 60710,
    "scheduler_time": 70.2816225653483
}
#Debug simulation 
Total elapsed time: 4.680685434024781. Arrivals time: 0.22086302051320672 Scheduler time: 4.250673005357385 Scheduler overhead time: 0.054641075897961855 Adapter cache time: 0.07284041587263346 Engine time: 0.05614080326631665 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_16-16-16/adapters_256_slots_192_rate_1.6-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_16-16-16/adapters_256_slots_192_rate_1.6-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 135, 17280, 17280, 135, 17280, 540, 17280, 135, 540, 135, 17280, 540, 540, 540, 540, 17280, 135, 135, 135, 540, 17280, 135, 17280, 17280, 540, 540, 540, 135, 17280, 135, 540, 540, 135, 540, 135, 135, 540, 540, 17280, 540, 135, 540, 17280, 540, 540, 17280, 540, 17280, 135, 17280, 17280, 540, 135, 135, 17280, 540, 135, 540, 540, 17280, 540, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 17280, 17280, 135, 17280, 135, 540, 17280, 17280, 17280, 540, 135, 17280, 540, 135, 135, 135, 135, 135, 17280, 540, 135, 17280, 135, 17280, 135, 135, 540, 540, 17280, 540, 17280, 135, 540, 135, 17280, 17280, 135, 17280, 540, 135, 17280, 135, 135, 17280, 17280, 540, 17280, 17280, 135, 17280, 540, 540, 135, 540, 17280, 17280, 135, 17280, 540, 135, 540, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 540, 17280, 17280, 540, 135, 17280, 135, 540, 540, 135, 540, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 540, 17280, 540, 135, 540, 17280, 540, 17280, 135, 17280, 135, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 135, 17280, 135, 17280, 540, 540, 135, 540, 17280, 540, 540, 17280, 135, 17280, 17280, 540, 135, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 135, 17280, 540, 17280, 17280, 135, 17280, 540, 540, 17280, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 17280, 540, 135, 135, 135, 135]
Prompts retrieved: 1543455 . Total input tokens: 344115126 . Total output tokens: 308543642
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.23136992007494,
    "estimated_duration": 3600.177156696719,
    "input_throughput": 4901.936274767232,
    "output_throughput": 4337.081293612395,
    "total_throughput": 9239.017568379626,
    "itl": 196.12855893544634,
    "ttft": 2074801.5248424027,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 741,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2156272685224705,
    "arrivals": 514751,
    "finished_requests": 71488,
    "scheduler_time": 71.30962921708553
}
#Debug simulation 
Total elapsed time: 5.231492691207677. Arrivals time: 0.24993353337049484 Scheduler time: 4.865054908208549 Scheduler overhead time: 0.029006964527070522 Adapter cache time: 0.044501558877527714 Engine time: 0.029586246237158775 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_16-16-32/adapters_256_slots_192_rate_1.6-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_16-16-32/adapters_256_slots_192_rate_1.6-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 135, 17280, 17280, 135, 17280, 540, 17280, 135, 540, 135, 17280, 540, 540, 540, 540, 17280, 135, 135, 135, 540, 17280, 135, 17280, 17280, 540, 540, 540, 135, 17280, 135, 540, 540, 135, 540, 135, 135, 540, 540, 17280, 540, 135, 540, 17280, 540, 540, 17280, 540, 17280, 135, 17280, 17280, 540, 135, 135, 17280, 540, 135, 540, 540, 17280, 540, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 17280, 17280, 135, 17280, 135, 540, 17280, 17280, 17280, 540, 135, 17280, 540, 135, 135, 135, 135, 135, 17280, 540, 135, 17280, 135, 17280, 135, 135, 540, 540, 17280, 540, 17280, 135, 540, 135, 17280, 17280, 135, 17280, 540, 135, 17280, 135, 135, 17280, 17280, 540, 17280, 17280, 135, 17280, 540, 540, 135, 540, 17280, 17280, 135, 17280, 540, 135, 540, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 540, 17280, 17280, 540, 135, 17280, 135, 540, 540, 135, 540, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 540, 17280, 540, 135, 540, 17280, 540, 17280, 135, 17280, 135, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 135, 17280, 135, 17280, 540, 540, 135, 540, 17280, 540, 540, 17280, 135, 17280, 17280, 540, 135, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 135, 17280, 540, 17280, 17280, 135, 17280, 540, 540, 17280, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 17280, 540, 135, 135, 135, 135]
Prompts retrieved: 1543455 . Total input tokens: 344115126 . Total output tokens: 308543642
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.693102583754808,
    "estimated_duration": 3600.066643862705,
    "input_throughput": 4160.806863266295,
    "output_throughput": 3697.29016619494,
    "total_throughput": 7858.097029461235,
    "itl": 91.58681525809169,
    "ttft": 2179396.5608072155,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 620,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.079127217829225,
    "arrivals": 514751,
    "finished_requests": 60694,
    "scheduler_time": 70.27786968090963
}
#Debug simulation 
Total elapsed time: 4.693201025947928. Arrivals time: 0.22044927347451448 Scheduler time: 4.264168553985655 Scheduler overhead time: 0.054672934114933014 Adapter cache time: 0.07186805177479982 Engine time: 0.056299406103789806 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-8/adapters_256_slots_192_rate_1.6-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-8/adapters_256_slots_192_rate_1.6-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 66, 17280, 17280, 66, 17280, 540, 17280, 66, 540, 66, 17280, 540, 540, 540, 540, 17280, 66, 66, 66, 540, 17280, 66, 17280, 17280, 540, 540, 540, 66, 17280, 66, 540, 540, 66, 540, 66, 66, 540, 540, 17280, 540, 66, 540, 17280, 540, 540, 17280, 540, 17280, 66, 17280, 17280, 540, 66, 66, 17280, 540, 66, 540, 540, 17280, 540, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 17280, 17280, 66, 17280, 66, 540, 17280, 17280, 17280, 540, 66, 17280, 540, 66, 66, 66, 66, 66, 17280, 540, 66, 17280, 66, 17280, 66, 66, 540, 540, 17280, 540, 17280, 66, 540, 66, 17280, 17280, 66, 17280, 540, 66, 17280, 66, 66, 17280, 17280, 540, 17280, 17280, 66, 17280, 540, 540, 66, 540, 17280, 17280, 66, 17280, 540, 66, 540, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 540, 17280, 17280, 540, 66, 17280, 66, 540, 540, 66, 540, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 540, 17280, 540, 66, 540, 17280, 540, 17280, 66, 17280, 66, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 66, 17280, 66, 17280, 540, 540, 66, 540, 17280, 540, 540, 17280, 66, 17280, 17280, 540, 66, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 66, 17280, 540, 17280, 17280, 66, 17280, 540, 540, 17280, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 17280, 540, 66, 66, 66, 66]
Prompts retrieved: 1537590 . Total input tokens: 342761459 . Total output tokens: 307388398
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.31564293988049,
    "estimated_duration": 3600.070748536277,
    "input_throughput": 5017.066958293416,
    "output_throughput": 4394.647245872195,
    "total_throughput": 9411.714204165612,
    "itl": 194.64738282592216,
    "ttft": 2065406.4257123782,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 484,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4812760680634682,
    "arrivals": 512803,
    "finished_requests": 72691,
    "scheduler_time": 72.16871165989288
}
#Debug simulation 
Total elapsed time: 5.315757005941123. Arrivals time: 0.2600568667985499 Scheduler time: 4.942948611918837 Scheduler overhead time: 0.02895831409841776 Adapter cache time: 0.04072440089657903 Engine time: 0.029728869907557964 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-16/adapters_256_slots_192_rate_1.6-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-16/adapters_256_slots_192_rate_1.6-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 66, 17280, 17280, 66, 17280, 540, 17280, 66, 540, 66, 17280, 540, 540, 540, 540, 17280, 66, 66, 66, 540, 17280, 66, 17280, 17280, 540, 540, 540, 66, 17280, 66, 540, 540, 66, 540, 66, 66, 540, 540, 17280, 540, 66, 540, 17280, 540, 540, 17280, 540, 17280, 66, 17280, 17280, 540, 66, 66, 17280, 540, 66, 540, 540, 17280, 540, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 17280, 17280, 66, 17280, 66, 540, 17280, 17280, 17280, 540, 66, 17280, 540, 66, 66, 66, 66, 66, 17280, 540, 66, 17280, 66, 17280, 66, 66, 540, 540, 17280, 540, 17280, 66, 540, 66, 17280, 17280, 66, 17280, 540, 66, 17280, 66, 66, 17280, 17280, 540, 17280, 17280, 66, 17280, 540, 540, 66, 540, 17280, 17280, 66, 17280, 540, 66, 540, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 540, 17280, 17280, 540, 66, 17280, 66, 540, 540, 66, 540, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 540, 17280, 540, 66, 540, 17280, 540, 17280, 66, 17280, 66, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 66, 17280, 66, 17280, 540, 540, 66, 540, 17280, 540, 540, 17280, 66, 17280, 17280, 540, 66, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 66, 17280, 540, 17280, 17280, 66, 17280, 540, 540, 17280, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 17280, 540, 66, 66, 66, 66]
Prompts retrieved: 1537590 . Total input tokens: 342761459 . Total output tokens: 307388398
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.236165934242308,
    "estimated_duration": 3600.0084690519325,
    "input_throughput": 5011.816542962617,
    "output_throughput": 4390.811892773904,
    "total_throughput": 9402.62843573652,
    "itl": 192.88902991765104,
    "ttft": 2066170.034231122,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 483,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5729018177464653,
    "arrivals": 512803,
    "finished_requests": 72622,
    "scheduler_time": 72.18466749071283
}
#Debug simulation 
Total elapsed time: 5.236287379171699. Arrivals time: 0.25113325472921133 Scheduler time: 4.87217176053673 Scheduler overhead time: 0.029071274679154158 Adapter cache time: 0.040684920735657215 Engine time: 0.029813974630087614 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-32/adapters_256_slots_192_rate_1.6-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-32/adapters_256_slots_192_rate_1.6-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 66, 17280, 17280, 66, 17280, 540, 17280, 66, 540, 66, 17280, 540, 540, 540, 540, 17280, 66, 66, 66, 540, 17280, 66, 17280, 17280, 540, 540, 540, 66, 17280, 66, 540, 540, 66, 540, 66, 66, 540, 540, 17280, 540, 66, 540, 17280, 540, 540, 17280, 540, 17280, 66, 17280, 17280, 540, 66, 66, 17280, 540, 66, 540, 540, 17280, 540, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 17280, 17280, 66, 17280, 66, 540, 17280, 17280, 17280, 540, 66, 17280, 540, 66, 66, 66, 66, 66, 17280, 540, 66, 17280, 66, 17280, 66, 66, 540, 540, 17280, 540, 17280, 66, 540, 66, 17280, 17280, 66, 17280, 540, 66, 17280, 66, 66, 17280, 17280, 540, 17280, 17280, 66, 17280, 540, 540, 66, 540, 17280, 17280, 66, 17280, 540, 66, 540, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 540, 17280, 17280, 540, 66, 17280, 66, 540, 540, 66, 540, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 540, 17280, 540, 66, 540, 17280, 540, 17280, 66, 17280, 66, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 66, 17280, 66, 17280, 540, 540, 66, 540, 17280, 540, 540, 17280, 66, 17280, 17280, 540, 66, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 66, 17280, 540, 17280, 17280, 66, 17280, 540, 540, 17280, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 17280, 540, 66, 66, 66, 66]
Prompts retrieved: 1537590 . Total input tokens: 342761459 . Total output tokens: 307388398
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.767278654035181,
    "estimated_duration": 3600.0886732020995,
    "input_throughput": 4212.134304600982,
    "output_throughput": 3713.8093568423174,
    "total_throughput": 7925.9436614433,
    "itl": 91.254967942836,
    "ttft": 2170955.160660649,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 424,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3835323003679594,
    "arrivals": 512803,
    "finished_requests": 61140,
    "scheduler_time": 70.54577985987906
}
#Debug simulation 
Total elapsed time: 4.767382227815688. Arrivals time: 0.23199399141594768 Scheduler time: 4.3305363967083395 Scheduler overhead time: 0.054852113127708435 Adapter cache time: 0.06801241775974631 Engine time: 0.05632628872990608 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-16-16/adapters_256_slots_192_rate_1.6-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-16-16/adapters_256_slots_192_rate_1.6-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 66, 17280, 17280, 66, 17280, 540, 17280, 66, 540, 66, 17280, 540, 540, 540, 540, 17280, 66, 66, 66, 540, 17280, 66, 17280, 17280, 540, 540, 540, 66, 17280, 66, 540, 540, 66, 540, 66, 66, 540, 540, 17280, 540, 66, 540, 17280, 540, 540, 17280, 540, 17280, 66, 17280, 17280, 540, 66, 66, 17280, 540, 66, 540, 540, 17280, 540, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 17280, 17280, 66, 17280, 66, 540, 17280, 17280, 17280, 540, 66, 17280, 540, 66, 66, 66, 66, 66, 17280, 540, 66, 17280, 66, 17280, 66, 66, 540, 540, 17280, 540, 17280, 66, 540, 66, 17280, 17280, 66, 17280, 540, 66, 17280, 66, 66, 17280, 17280, 540, 17280, 17280, 66, 17280, 540, 540, 66, 540, 17280, 17280, 66, 17280, 540, 66, 540, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 540, 17280, 17280, 540, 66, 17280, 66, 540, 540, 66, 540, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 540, 17280, 540, 66, 540, 17280, 540, 17280, 66, 17280, 66, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 66, 17280, 66, 17280, 540, 540, 66, 540, 17280, 540, 540, 17280, 66, 17280, 17280, 540, 66, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 66, 17280, 540, 17280, 17280, 66, 17280, 540, 540, 17280, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 17280, 540, 66, 66, 66, 66]
Prompts retrieved: 1537590 . Total input tokens: 342761459 . Total output tokens: 307388398
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 5.2738498779945076,
    "estimated_duration": 3600.168852368198,
    "input_throughput": 5011.851871372906,
    "output_throughput": 4390.712949366784,
    "total_throughput": 9402.56482073969,
    "itl": 192.8796029417567,
    "ttft": 2066205.3626613906,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 483,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5128383059357249,
    "arrivals": 512803,
    "finished_requests": 72626,
    "scheduler_time": 72.1889413696462
}
#Debug simulation 
Total elapsed time: 5.273952089250088. Arrivals time: 0.2551338477060199 Scheduler time: 4.904836516361684 Scheduler overhead time: 0.029271111823618412 Adapter cache time: 0.041211722418665886 Engine time: 0.03000863967463374 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-16-32/adapters_256_slots_192_rate_1.6-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-16-32/adapters_256_slots_192_rate_1.6-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 66, 17280, 17280, 66, 17280, 540, 17280, 66, 540, 66, 17280, 540, 540, 540, 540, 17280, 66, 66, 66, 540, 17280, 66, 17280, 17280, 540, 540, 540, 66, 17280, 66, 540, 540, 66, 540, 66, 66, 540, 540, 17280, 540, 66, 540, 17280, 540, 540, 17280, 540, 17280, 66, 17280, 17280, 540, 66, 66, 17280, 540, 66, 540, 540, 17280, 540, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 17280, 17280, 66, 17280, 66, 540, 17280, 17280, 17280, 540, 66, 17280, 540, 66, 66, 66, 66, 66, 17280, 540, 66, 17280, 66, 17280, 66, 66, 540, 540, 17280, 540, 17280, 66, 540, 66, 17280, 17280, 66, 17280, 540, 66, 17280, 66, 66, 17280, 17280, 540, 17280, 17280, 66, 17280, 540, 540, 66, 540, 17280, 17280, 66, 17280, 540, 66, 540, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 540, 17280, 17280, 540, 66, 17280, 66, 540, 540, 66, 540, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 540, 17280, 540, 66, 540, 17280, 540, 17280, 66, 17280, 66, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 66, 17280, 66, 17280, 540, 540, 66, 540, 17280, 540, 540, 17280, 66, 17280, 17280, 540, 66, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 66, 17280, 540, 17280, 17280, 66, 17280, 540, 540, 17280, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 17280, 540, 66, 66, 66, 66]
Prompts retrieved: 1537590 . Total input tokens: 342761459 . Total output tokens: 307388398
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 4.695278028026223,
    "estimated_duration": 3600.0129341788206,
    "input_throughput": 4208.288769233481,
    "output_throughput": 3710.1666700113433,
    "total_throughput": 7918.4554392448235,
    "itl": 91.08136468299708,
    "ttft": 2170944.9139553728,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 424,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4000060463883028,
    "arrivals": 512803,
    "finished_requests": 61086,
    "scheduler_time": 70.52941085103636
}
#Debug simulation 
Total elapsed time: 4.695379283744842. Arrivals time: 0.22385855996981263 Scheduler time: 4.265033716801554 Scheduler overhead time: 0.05489329295232892 Adapter cache time: 0.06957102054730058 Engine time: 0.05645115161314607 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_16-16-16/adapters_256_slots_192_rate_1.6-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_16-16-16/adapters_256_slots_192_rate_1.6-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 66, 17280, 17280, 66, 17280, 540, 17280, 66, 540, 66, 17280, 540, 540, 540, 540, 17280, 66, 66, 66, 540, 17280, 66, 17280, 17280, 540, 540, 540, 66, 17280, 66, 540, 540, 66, 540, 66, 66, 540, 540, 17280, 540, 66, 540, 17280, 540, 540, 17280, 540, 17280, 66, 17280, 17280, 540, 66, 66, 17280, 540, 66, 540, 540, 17280, 540, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 17280, 17280, 66, 17280, 66, 540, 17280, 17280, 17280, 540, 66, 17280, 540, 66, 66, 66, 66, 66, 17280, 540, 66, 17280, 66, 17280, 66, 66, 540, 540, 17280, 540, 17280, 66, 540, 66, 17280, 17280, 66, 17280, 540, 66, 17280, 66, 66, 17280, 17280, 540, 17280, 17280, 66, 17280, 540, 540, 66, 540, 17280, 17280, 66, 17280, 540, 66, 540, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 540, 17280, 17280, 540, 66, 17280, 66, 540, 540, 66, 540, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 540, 17280, 540, 66, 540, 17280, 540, 17280, 66, 17280, 66, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 66, 17280, 66, 17280, 540, 540, 66, 540, 17280, 540, 540, 17280, 66, 17280, 17280, 540, 66, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 66, 17280, 540, 17280, 17280, 66, 17280, 540, 540, 17280, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 17280, 540, 66, 66, 66, 66]
Prompts retrieved: 1537590 . Total input tokens: 342761459 . Total output tokens: 307388398
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.259442508220673,
    "estimated_duration": 3600.122504927758,
    "input_throughput": 5011.916393206756,
    "output_throughput": 4390.769474750748,
    "total_throughput": 9402.685867957503,
    "itl": 192.86724375441884,
    "ttft": 2066188.709785857,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 483,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4441942924377364,
    "arrivals": 512803,
    "finished_requests": 72626,
    "scheduler_time": 72.1892668194335
}
#Debug simulation 
Total elapsed time: 5.2595454840920866. Arrivals time: 0.2536775819025934 Scheduler time: 4.8920067409053445 Scheduler overhead time: 0.029309211298823357 Adapter cache time: 0.04108800692483783 Engine time: 0.030057989060878754 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_16-16-32/adapters_256_slots_192_rate_1.6-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_16-16-32/adapters_256_slots_192_rate_1.6-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 66, 17280, 17280, 66, 17280, 540, 17280, 66, 540, 66, 17280, 540, 540, 540, 540, 17280, 66, 66, 66, 540, 17280, 66, 17280, 17280, 540, 540, 540, 66, 17280, 66, 540, 540, 66, 540, 66, 66, 540, 540, 17280, 540, 66, 540, 17280, 540, 540, 17280, 540, 17280, 66, 17280, 17280, 540, 66, 66, 17280, 540, 66, 540, 540, 17280, 540, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 17280, 17280, 66, 17280, 66, 540, 17280, 17280, 17280, 540, 66, 17280, 540, 66, 66, 66, 66, 66, 17280, 540, 66, 17280, 66, 17280, 66, 66, 540, 540, 17280, 540, 17280, 66, 540, 66, 17280, 17280, 66, 17280, 540, 66, 17280, 66, 66, 17280, 17280, 540, 17280, 17280, 66, 17280, 540, 540, 66, 540, 17280, 17280, 66, 17280, 540, 66, 540, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 540, 17280, 17280, 540, 66, 17280, 66, 540, 540, 66, 540, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 540, 17280, 540, 66, 540, 17280, 540, 17280, 66, 17280, 66, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 66, 17280, 66, 17280, 540, 540, 66, 540, 17280, 540, 540, 17280, 66, 17280, 17280, 540, 66, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 66, 17280, 540, 17280, 17280, 66, 17280, 540, 540, 17280, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 17280, 540, 66, 66, 66, 66]
Prompts retrieved: 1537590 . Total input tokens: 342761459 . Total output tokens: 307388398
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.713769249152392,
    "estimated_duration": 3600.0303521344954,
    "input_throughput": 4212.202541850535,
    "output_throughput": 3713.869521147999,
    "total_throughput": 7926.072062998534,
    "itl": 91.25623373817346,
    "ttft": 2170835.0084689762,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 423,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.415196826569737,
    "arrivals": 512803,
    "finished_requests": 61140,
    "scheduler_time": 70.5423848462299
}
#Debug simulation 
Total elapsed time: 4.713862334843725. Arrivals time: 0.22159768408164382 Scheduler time: 4.285887150559574 Scheduler overhead time: 0.05482814786955714 Adapter cache time: 0.06950255716219544 Engine time: 0.05641801981255412 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-8/adapters_256_slots_192_rate_1.6-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-8/adapters_256_slots_192_rate_1.6-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 33, 17280, 17280, 33, 17280, 540, 17280, 33, 540, 33, 17280, 540, 540, 540, 540, 17280, 33, 33, 33, 540, 17280, 33, 17280, 17280, 540, 540, 540, 33, 17280, 33, 540, 540, 33, 540, 33, 33, 540, 540, 17280, 540, 33, 540, 17280, 540, 540, 17280, 540, 17280, 33, 17280, 17280, 540, 33, 33, 17280, 540, 33, 540, 540, 17280, 540, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 17280, 17280, 33, 17280, 33, 540, 17280, 17280, 17280, 540, 33, 17280, 540, 33, 33, 33, 33, 33, 17280, 540, 33, 17280, 33, 17280, 33, 33, 540, 540, 17280, 540, 17280, 33, 540, 33, 17280, 17280, 33, 17280, 540, 33, 17280, 33, 33, 17280, 17280, 540, 17280, 17280, 33, 17280, 540, 540, 33, 540, 17280, 17280, 33, 17280, 540, 33, 540, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 540, 17280, 17280, 540, 33, 17280, 33, 540, 540, 33, 540, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 540, 17280, 540, 33, 540, 17280, 540, 17280, 33, 17280, 33, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 33, 17280, 33, 17280, 540, 540, 33, 540, 17280, 540, 540, 17280, 33, 17280, 17280, 540, 33, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 33, 17280, 540, 17280, 17280, 33, 17280, 540, 540, 17280, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 17280, 540, 33, 33, 33, 33]
Prompts retrieved: 1534785 . Total input tokens: 342133886 . Total output tokens: 306836984
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.371824078261852,
    "estimated_duration": 3600.2257432902106,
    "input_throughput": 4977.0792938179375,
    "output_throughput": 4412.736626198658,
    "total_throughput": 9389.815920016596,
    "itl": 194.7009330758667,
    "ttft": 2062799.70100253,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 321,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9824165658024127,
    "arrivals": 511802,
    "finished_requests": 72625,
    "scheduler_time": 72.47292571029683
}
#Debug simulation 
Total elapsed time: 5.371926410123706. Arrivals time: 0.28221903229132295 Scheduler time: 4.979880302678794 Scheduler overhead time: 0.02895294316112995 Adapter cache time: 0.03773175133392215 Engine time: 0.029738495592027903 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-16/adapters_256_slots_192_rate_1.6-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-16/adapters_256_slots_192_rate_1.6-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 33, 17280, 17280, 33, 17280, 540, 17280, 33, 540, 33, 17280, 540, 540, 540, 540, 17280, 33, 33, 33, 540, 17280, 33, 17280, 17280, 540, 540, 540, 33, 17280, 33, 540, 540, 33, 540, 33, 33, 540, 540, 17280, 540, 33, 540, 17280, 540, 540, 17280, 540, 17280, 33, 17280, 17280, 540, 33, 33, 17280, 540, 33, 540, 540, 17280, 540, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 17280, 17280, 33, 17280, 33, 540, 17280, 17280, 17280, 540, 33, 17280, 540, 33, 33, 33, 33, 33, 17280, 540, 33, 17280, 33, 17280, 33, 33, 540, 540, 17280, 540, 17280, 33, 540, 33, 17280, 17280, 33, 17280, 540, 33, 17280, 33, 33, 17280, 17280, 540, 17280, 17280, 33, 17280, 540, 540, 33, 540, 17280, 17280, 33, 17280, 540, 33, 540, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 540, 17280, 17280, 540, 33, 17280, 33, 540, 540, 33, 540, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 540, 17280, 540, 33, 540, 17280, 540, 17280, 33, 17280, 33, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 33, 17280, 33, 17280, 540, 540, 33, 540, 17280, 540, 540, 17280, 33, 17280, 17280, 540, 33, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 33, 17280, 540, 17280, 17280, 33, 17280, 540, 540, 17280, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 17280, 540, 33, 33, 33, 33]
Prompts retrieved: 1534785 . Total input tokens: 342133886 . Total output tokens: 306836984
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.3246188228949904,
    "estimated_duration": 3600.1796956702065,
    "input_throughput": 4970.493562174469,
    "output_throughput": 4408.026082444118,
    "total_throughput": 9378.519644618587,
    "itl": 191.79614117837536,
    "ttft": 2063889.488004379,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 322,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0518699743785023,
    "arrivals": 511802,
    "finished_requests": 72521,
    "scheduler_time": 72.49615164857022
}
#Debug simulation 
Total elapsed time: 5.324718643911183. Arrivals time: 0.2541189300827682 Scheduler time: 4.959478082600981 Scheduler overhead time: 0.029446433763951063 Adapter cache time: 0.038098562974482775 Engine time: 0.029990439768880606 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-32/adapters_256_slots_192_rate_1.6-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-32/adapters_256_slots_192_rate_1.6-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 33, 17280, 17280, 33, 17280, 540, 17280, 33, 540, 33, 17280, 540, 540, 540, 540, 17280, 33, 33, 33, 540, 17280, 33, 17280, 17280, 540, 540, 540, 33, 17280, 33, 540, 540, 33, 540, 33, 33, 540, 540, 17280, 540, 33, 540, 17280, 540, 540, 17280, 540, 17280, 33, 17280, 17280, 540, 33, 33, 17280, 540, 33, 540, 540, 17280, 540, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 17280, 17280, 33, 17280, 33, 540, 17280, 17280, 17280, 540, 33, 17280, 540, 33, 33, 33, 33, 33, 17280, 540, 33, 17280, 33, 17280, 33, 33, 540, 540, 17280, 540, 17280, 33, 540, 33, 17280, 17280, 33, 17280, 540, 33, 17280, 33, 33, 17280, 17280, 540, 17280, 17280, 33, 17280, 540, 540, 33, 540, 17280, 17280, 33, 17280, 540, 33, 540, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 540, 17280, 17280, 540, 33, 17280, 33, 540, 540, 33, 540, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 540, 17280, 540, 33, 540, 17280, 540, 17280, 33, 17280, 33, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 33, 17280, 33, 17280, 540, 540, 33, 540, 17280, 540, 540, 17280, 33, 17280, 17280, 540, 33, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 33, 17280, 540, 17280, 17280, 33, 17280, 540, 540, 17280, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 17280, 540, 33, 33, 33, 33]
Prompts retrieved: 1534785 . Total input tokens: 342133886 . Total output tokens: 306836984
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.710393995977938,
    "estimated_duration": 3600.070205671496,
    "input_throughput": 4178.932115351307,
    "output_throughput": 3728.310347630139,
    "total_throughput": 7907.242462981446,
    "itl": 90.53809556036015,
    "ttft": 2173613.7861042093,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 299,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9777988821826926,
    "arrivals": 511802,
    "finished_requests": 61090,
    "scheduler_time": 70.85813970208034
}
#Debug simulation 
Total elapsed time: 4.710491971578449. Arrivals time: 0.22298964112997055 Scheduler time: 4.284563469234854 Scheduler overhead time: 0.055202236864715815 Adapter cache time: 0.06520584737882018 Engine time: 0.05677366256713867 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-16-16/adapters_256_slots_192_rate_1.6-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-16-16/adapters_256_slots_192_rate_1.6-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 33, 17280, 17280, 33, 17280, 540, 17280, 33, 540, 33, 17280, 540, 540, 540, 540, 17280, 33, 33, 33, 540, 17280, 33, 17280, 17280, 540, 540, 540, 33, 17280, 33, 540, 540, 33, 540, 33, 33, 540, 540, 17280, 540, 33, 540, 17280, 540, 540, 17280, 540, 17280, 33, 17280, 17280, 540, 33, 33, 17280, 540, 33, 540, 540, 17280, 540, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 17280, 17280, 33, 17280, 33, 540, 17280, 17280, 17280, 540, 33, 17280, 540, 33, 33, 33, 33, 33, 17280, 540, 33, 17280, 33, 17280, 33, 33, 540, 540, 17280, 540, 17280, 33, 540, 33, 17280, 17280, 33, 17280, 540, 33, 17280, 33, 33, 17280, 17280, 540, 17280, 17280, 33, 17280, 540, 540, 33, 540, 17280, 17280, 33, 17280, 540, 33, 540, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 540, 17280, 17280, 540, 33, 17280, 33, 540, 540, 33, 540, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 540, 17280, 540, 33, 540, 17280, 540, 17280, 33, 17280, 33, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 33, 17280, 33, 17280, 540, 540, 33, 540, 17280, 540, 540, 17280, 33, 17280, 17280, 540, 33, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 33, 17280, 540, 17280, 17280, 33, 17280, 540, 540, 17280, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 17280, 540, 33, 33, 33, 33]
Prompts retrieved: 1534785 . Total input tokens: 342133886 . Total output tokens: 306836984
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 5.295550423674285,
    "estimated_duration": 3600.139758600261,
    "input_throughput": 4970.548700853067,
    "output_throughput": 4408.074981558537,
    "total_throughput": 9378.623682411604,
    "itl": 191.78610240758695,
    "ttft": 2063870.2042423643,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 322,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0077416799869423,
    "arrivals": 511802,
    "finished_requests": 72521,
    "scheduler_time": 72.49617900513526
}
#Debug simulation 
Total elapsed time: 5.295647657942027. Arrivals time: 0.2554002683609724 Scheduler time: 4.929245350882411 Scheduler overhead time: 0.029192167799919844 Adapter cache time: 0.03827409818768501 Engine time: 0.029996325261890888 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-16-32/adapters_256_slots_192_rate_1.6-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-16-32/adapters_256_slots_192_rate_1.6-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 33, 17280, 17280, 33, 17280, 540, 17280, 33, 540, 33, 17280, 540, 540, 540, 540, 17280, 33, 33, 33, 540, 17280, 33, 17280, 17280, 540, 540, 540, 33, 17280, 33, 540, 540, 33, 540, 33, 33, 540, 540, 17280, 540, 33, 540, 17280, 540, 540, 17280, 540, 17280, 33, 17280, 17280, 540, 33, 33, 17280, 540, 33, 540, 540, 17280, 540, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 17280, 17280, 33, 17280, 33, 540, 17280, 17280, 17280, 540, 33, 17280, 540, 33, 33, 33, 33, 33, 17280, 540, 33, 17280, 33, 17280, 33, 33, 540, 540, 17280, 540, 17280, 33, 540, 33, 17280, 17280, 33, 17280, 540, 33, 17280, 33, 33, 17280, 17280, 540, 17280, 17280, 33, 17280, 540, 540, 33, 540, 17280, 17280, 33, 17280, 540, 33, 540, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 540, 17280, 17280, 540, 33, 17280, 33, 540, 540, 33, 540, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 540, 17280, 540, 33, 540, 17280, 540, 17280, 33, 17280, 33, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 33, 17280, 33, 17280, 540, 540, 33, 540, 17280, 540, 540, 17280, 33, 17280, 17280, 540, 33, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 33, 17280, 540, 17280, 17280, 33, 17280, 540, 540, 17280, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 17280, 540, 33, 33, 33, 33]
Prompts retrieved: 1534785 . Total input tokens: 342133886 . Total output tokens: 306836984
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 4.714437260758132,
    "estimated_duration": 3600.009114413629,
    "input_throughput": 4178.015255511337,
    "output_throughput": 3727.6583401611165,
    "total_throughput": 7905.673595672453,
    "itl": 90.5414765249284,
    "ttft": 2173639.2213905123,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 299,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.990500014610594,
    "arrivals": 511802,
    "finished_requests": 61079,
    "scheduler_time": 70.85659383459517
}
#Debug simulation 
Total elapsed time: 4.714537601917982. Arrivals time: 0.2215117267332971 Scheduler time: 4.289978688117117 Scheduler overhead time: 0.05505419755354524 Adapter cache time: 0.065843656193465 Engine time: 0.05646885046735406 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_16-16-16/adapters_256_slots_192_rate_1.6-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_16-16-16/adapters_256_slots_192_rate_1.6-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 33, 17280, 17280, 33, 17280, 540, 17280, 33, 540, 33, 17280, 540, 540, 540, 540, 17280, 33, 33, 33, 540, 17280, 33, 17280, 17280, 540, 540, 540, 33, 17280, 33, 540, 540, 33, 540, 33, 33, 540, 540, 17280, 540, 33, 540, 17280, 540, 540, 17280, 540, 17280, 33, 17280, 17280, 540, 33, 33, 17280, 540, 33, 540, 540, 17280, 540, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 17280, 17280, 33, 17280, 33, 540, 17280, 17280, 17280, 540, 33, 17280, 540, 33, 33, 33, 33, 33, 17280, 540, 33, 17280, 33, 17280, 33, 33, 540, 540, 17280, 540, 17280, 33, 540, 33, 17280, 17280, 33, 17280, 540, 33, 17280, 33, 33, 17280, 17280, 540, 17280, 17280, 33, 17280, 540, 540, 33, 540, 17280, 17280, 33, 17280, 540, 33, 540, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 540, 17280, 17280, 540, 33, 17280, 33, 540, 540, 33, 540, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 540, 17280, 540, 33, 540, 17280, 540, 17280, 33, 17280, 33, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 33, 17280, 33, 17280, 540, 540, 33, 540, 17280, 540, 540, 17280, 33, 17280, 17280, 540, 33, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 33, 17280, 540, 17280, 17280, 33, 17280, 540, 540, 17280, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 17280, 540, 33, 33, 33, 33]
Prompts retrieved: 1534785 . Total input tokens: 342133886 . Total output tokens: 306836984
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.2901910985819995,
    "estimated_duration": 3600.059548845776,
    "input_throughput": 4970.5047256057405,
    "output_throughput": 4408.030974123151,
    "total_throughput": 9378.535699728893,
    "itl": 191.7852787041003,
    "ttft": 2063815.0010042733,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 322,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9627961949585019,
    "arrivals": 511802,
    "finished_requests": 72520,
    "scheduler_time": 72.49549817468206
}
#Debug simulation 
Total elapsed time: 5.290288558695465. Arrivals time: 0.2547997091896832 Scheduler time: 4.924455682747066 Scheduler overhead time: 0.02917306637391448 Adapter cache time: 0.038258026354014874 Engine time: 0.03006982896476984 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_16-16-32/adapters_256_slots_192_rate_1.6-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_16-16-32/adapters_256_slots_192_rate_1.6-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 17280, 33, 17280, 17280, 33, 17280, 540, 17280, 33, 540, 33, 17280, 540, 540, 540, 540, 17280, 33, 33, 33, 540, 17280, 33, 17280, 17280, 540, 540, 540, 33, 17280, 33, 540, 540, 33, 540, 33, 33, 540, 540, 17280, 540, 33, 540, 17280, 540, 540, 17280, 540, 17280, 33, 17280, 17280, 540, 33, 33, 17280, 540, 33, 540, 540, 17280, 540, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 17280, 17280, 33, 17280, 33, 540, 17280, 17280, 17280, 540, 33, 17280, 540, 33, 33, 33, 33, 33, 17280, 540, 33, 17280, 33, 17280, 33, 33, 540, 540, 17280, 540, 17280, 33, 540, 33, 17280, 17280, 33, 17280, 540, 33, 17280, 33, 33, 17280, 17280, 540, 17280, 17280, 33, 17280, 540, 540, 33, 540, 17280, 17280, 33, 17280, 540, 33, 540, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 540, 17280, 17280, 540, 33, 17280, 33, 540, 540, 33, 540, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 540, 17280, 540, 33, 540, 17280, 540, 17280, 33, 17280, 33, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 540, 33, 17280, 33, 17280, 540, 540, 33, 540, 17280, 540, 540, 17280, 33, 17280, 17280, 540, 33, 17280, 17280, 540, 540, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 17280, 33, 17280, 540, 17280, 17280, 33, 17280, 540, 540, 17280, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 17280, 540, 33, 33, 33, 33]
Prompts retrieved: 1534785 . Total input tokens: 342133886 . Total output tokens: 306836984
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.7244630991481245,
    "estimated_duration": 3600.066867858055,
    "input_throughput": 4177.800733170442,
    "output_throughput": 3727.4443760495983,
    "total_throughput": 7905.245109220041,
    "itl": 90.54667392940651,
    "ttft": 2173559.88661494,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 299,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0030753932520802,
    "arrivals": 511802,
    "finished_requests": 61077,
    "scheduler_time": 70.85632960623556
}
#Debug simulation 
Total elapsed time: 4.724559886846691. Arrivals time: 0.22025845386087894 Scheduler time: 4.299869099166244 Scheduler overhead time: 0.05523573327809572 Adapter cache time: 0.0666708960197866 Engine time: 0.05679691303521395 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-8/adapters_256_slots_192_rate_1.6-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-8/adapters_256_slots_192_rate_1.6-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 17280, 135, 17280, 17280, 135, 17280, 270, 17280, 135, 270, 135, 17280, 270, 270, 270, 270, 17280, 135, 135, 135, 270, 17280, 135, 17280, 17280, 270, 270, 270, 135, 17280, 135, 270, 270, 135, 270, 135, 135, 270, 270, 17280, 270, 135, 270, 17280, 270, 270, 17280, 270, 17280, 135, 17280, 17280, 270, 135, 135, 17280, 270, 135, 270, 270, 17280, 270, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 17280, 17280, 135, 17280, 135, 270, 17280, 17280, 17280, 270, 135, 17280, 270, 135, 135, 135, 135, 135, 17280, 270, 135, 17280, 135, 17280, 135, 135, 270, 270, 17280, 270, 17280, 135, 270, 135, 17280, 17280, 135, 17280, 270, 135, 17280, 135, 135, 17280, 17280, 270, 17280, 17280, 135, 17280, 270, 270, 135, 270, 17280, 17280, 135, 17280, 270, 135, 270, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 270, 17280, 17280, 270, 135, 17280, 135, 270, 270, 135, 270, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 270, 17280, 270, 135, 270, 17280, 270, 17280, 135, 17280, 135, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 270, 135, 17280, 135, 17280, 270, 270, 135, 270, 17280, 270, 270, 17280, 135, 17280, 17280, 270, 135, 17280, 17280, 270, 270, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 17280, 135, 17280, 270, 17280, 17280, 135, 17280, 270, 270, 17280, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 17280, 270, 135, 135, 135, 135]
Prompts retrieved: 1520505 . Total input tokens: 338953303 . Total output tokens: 303979113
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.470422531012446,
    "estimated_duration": 3600.110945929234,
    "input_throughput": 5175.500222032949,
    "output_throughput": 4555.972925930602,
    "total_throughput": 9731.473147963552,
    "itl": 188.24898312078543,
    "ttft": 2037780.463733735,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 692,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.117857518801503,
    "arrivals": 507065,
    "finished_requests": 75438,
    "scheduler_time": 74.81026588737862
}
#Debug simulation 
Total elapsed time: 5.470522531308234. Arrivals time: 0.2585048242472112 Scheduler time: 5.102713943459094 Scheduler overhead time: 0.029993001837283373 Adapter cache time: 0.03503200178965926 Engine time: 0.030383266508579254 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-16/adapters_256_slots_192_rate_1.6-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-16/adapters_256_slots_192_rate_1.6-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 17280, 135, 17280, 17280, 135, 17280, 270, 17280, 135, 270, 135, 17280, 270, 270, 270, 270, 17280, 135, 135, 135, 270, 17280, 135, 17280, 17280, 270, 270, 270, 135, 17280, 135, 270, 270, 135, 270, 135, 135, 270, 270, 17280, 270, 135, 270, 17280, 270, 270, 17280, 270, 17280, 135, 17280, 17280, 270, 135, 135, 17280, 270, 135, 270, 270, 17280, 270, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 17280, 17280, 135, 17280, 135, 270, 17280, 17280, 17280, 270, 135, 17280, 270, 135, 135, 135, 135, 135, 17280, 270, 135, 17280, 135, 17280, 135, 135, 270, 270, 17280, 270, 17280, 135, 270, 135, 17280, 17280, 135, 17280, 270, 135, 17280, 135, 135, 17280, 17280, 270, 17280, 17280, 135, 17280, 270, 270, 135, 270, 17280, 17280, 135, 17280, 270, 135, 270, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 270, 17280, 17280, 270, 135, 17280, 135, 270, 270, 135, 270, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 270, 17280, 270, 135, 270, 17280, 270, 17280, 135, 17280, 135, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 270, 135, 17280, 135, 17280, 270, 270, 135, 270, 17280, 270, 270, 17280, 135, 17280, 17280, 270, 135, 17280, 17280, 270, 270, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 17280, 135, 17280, 270, 17280, 17280, 135, 17280, 270, 270, 17280, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 17280, 270, 135, 135, 135, 135]
Prompts retrieved: 1520505 . Total input tokens: 338953303 . Total output tokens: 303979113
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.429529523011297,
    "estimated_duration": 3600.147005287387,
    "input_throughput": 5171.658260803084,
    "output_throughput": 4552.672148089581,
    "total_throughput": 9724.330408892665,
    "itl": 187.04526984150974,
    "ttft": 2038659.1684667445,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 692,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2578858411917526,
    "arrivals": 507065,
    "finished_requests": 75389,
    "scheduler_time": 74.80851612221016
}
#Debug simulation 
Total elapsed time: 5.429651554208249. Arrivals time: 0.25677669141441584 Scheduler time: 5.06364350952208 Scheduler overhead time: 0.029990633949637413 Adapter cache time: 0.034610393457114697 Engine time: 0.030776041094213724 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-32/adapters_256_slots_192_rate_1.6-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-32/adapters_256_slots_192_rate_1.6-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 17280, 135, 17280, 17280, 135, 17280, 270, 17280, 135, 270, 135, 17280, 270, 270, 270, 270, 17280, 135, 135, 135, 270, 17280, 135, 17280, 17280, 270, 270, 270, 135, 17280, 135, 270, 270, 135, 270, 135, 135, 270, 270, 17280, 270, 135, 270, 17280, 270, 270, 17280, 270, 17280, 135, 17280, 17280, 270, 135, 135, 17280, 270, 135, 270, 270, 17280, 270, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 17280, 17280, 135, 17280, 135, 270, 17280, 17280, 17280, 270, 135, 17280, 270, 135, 135, 135, 135, 135, 17280, 270, 135, 17280, 135, 17280, 135, 135, 270, 270, 17280, 270, 17280, 135, 270, 135, 17280, 17280, 135, 17280, 270, 135, 17280, 135, 135, 17280, 17280, 270, 17280, 17280, 135, 17280, 270, 270, 135, 270, 17280, 17280, 135, 17280, 270, 135, 270, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 270, 17280, 17280, 270, 135, 17280, 135, 270, 270, 135, 270, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 270, 17280, 270, 135, 270, 17280, 270, 17280, 135, 17280, 135, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 270, 135, 17280, 135, 17280, 270, 270, 135, 270, 17280, 270, 270, 17280, 135, 17280, 17280, 270, 135, 17280, 17280, 270, 270, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 17280, 135, 17280, 270, 17280, 17280, 135, 17280, 270, 270, 17280, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 17280, 270, 135, 135, 135, 135]
Prompts retrieved: 1520505 . Total input tokens: 338953303 . Total output tokens: 303979113
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.821412642020732,
    "estimated_duration": 3600.029868421314,
    "input_throughput": 4292.40466462473,
    "output_throughput": 3795.8343401168586,
    "total_throughput": 8088.239004741588,
    "itl": 89.77708438233026,
    "ttft": 2155725.8460665783,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 602,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9677718397602562,
    "arrivals": 507065,
    "finished_requests": 62556,
    "scheduler_time": 71.9989166737807
}
#Debug simulation 
Total elapsed time: 4.821512465830892. Arrivals time: 0.2227533790282905 Scheduler time: 4.40178079996258 Scheduler overhead time: 0.05588501412421465 Adapter cache time: 0.057696386240422726 Engine time: 0.05735817085951567 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-16-16/adapters_256_slots_192_rate_1.6-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-16-16/adapters_256_slots_192_rate_1.6-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 17280, 135, 17280, 17280, 135, 17280, 270, 17280, 135, 270, 135, 17280, 270, 270, 270, 270, 17280, 135, 135, 135, 270, 17280, 135, 17280, 17280, 270, 270, 270, 135, 17280, 135, 270, 270, 135, 270, 135, 135, 270, 270, 17280, 270, 135, 270, 17280, 270, 270, 17280, 270, 17280, 135, 17280, 17280, 270, 135, 135, 17280, 270, 135, 270, 270, 17280, 270, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 17280, 17280, 135, 17280, 135, 270, 17280, 17280, 17280, 270, 135, 17280, 270, 135, 135, 135, 135, 135, 17280, 270, 135, 17280, 135, 17280, 135, 135, 270, 270, 17280, 270, 17280, 135, 270, 135, 17280, 17280, 135, 17280, 270, 135, 17280, 135, 135, 17280, 17280, 270, 17280, 17280, 135, 17280, 270, 270, 135, 270, 17280, 17280, 135, 17280, 270, 135, 270, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 270, 17280, 17280, 270, 135, 17280, 135, 270, 270, 135, 270, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 270, 17280, 270, 135, 270, 17280, 270, 17280, 135, 17280, 135, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 270, 135, 17280, 135, 17280, 270, 270, 135, 270, 17280, 270, 270, 17280, 135, 17280, 17280, 270, 135, 17280, 17280, 270, 270, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 17280, 135, 17280, 270, 17280, 17280, 135, 17280, 270, 270, 17280, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 17280, 270, 135, 135, 135, 135]
Prompts retrieved: 1520505 . Total input tokens: 338953303 . Total output tokens: 303979113
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 5.489347861148417,
    "estimated_duration": 3600.198000310482,
    "input_throughput": 5171.893878723954,
    "output_throughput": 4552.982641117623,
    "total_throughput": 9724.876519841577,
    "itl": 187.05228038810694,
    "ttft": 2038669.101688995,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 692,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1720808243192593,
    "arrivals": 507065,
    "finished_requests": 75394,
    "scheduler_time": 74.8106870000573
}
#Debug simulation 
Total elapsed time: 5.489451196976006. Arrivals time: 0.26347664510831237 Scheduler time: 5.115824423264712 Scheduler overhead time: 0.03012138558551669 Adapter cache time: 0.03490001522004604 Engine time: 0.031120406463742256 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-16-32/adapters_256_slots_192_rate_1.6-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-16-32/adapters_256_slots_192_rate_1.6-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 17280, 135, 17280, 17280, 135, 17280, 270, 17280, 135, 270, 135, 17280, 270, 270, 270, 270, 17280, 135, 135, 135, 270, 17280, 135, 17280, 17280, 270, 270, 270, 135, 17280, 135, 270, 270, 135, 270, 135, 135, 270, 270, 17280, 270, 135, 270, 17280, 270, 270, 17280, 270, 17280, 135, 17280, 17280, 270, 135, 135, 17280, 270, 135, 270, 270, 17280, 270, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 17280, 17280, 135, 17280, 135, 270, 17280, 17280, 17280, 270, 135, 17280, 270, 135, 135, 135, 135, 135, 17280, 270, 135, 17280, 135, 17280, 135, 135, 270, 270, 17280, 270, 17280, 135, 270, 135, 17280, 17280, 135, 17280, 270, 135, 17280, 135, 135, 17280, 17280, 270, 17280, 17280, 135, 17280, 270, 270, 135, 270, 17280, 17280, 135, 17280, 270, 135, 270, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 270, 17280, 17280, 270, 135, 17280, 135, 270, 270, 135, 270, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 270, 17280, 270, 135, 270, 17280, 270, 17280, 135, 17280, 135, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 270, 135, 17280, 135, 17280, 270, 270, 135, 270, 17280, 270, 270, 17280, 135, 17280, 17280, 270, 135, 17280, 17280, 270, 270, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 17280, 135, 17280, 270, 17280, 17280, 135, 17280, 270, 270, 17280, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 17280, 270, 135, 135, 135, 135]
Prompts retrieved: 1520505 . Total input tokens: 338953303 . Total output tokens: 303979113
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 4.760749412700534,
    "estimated_duration": 3600.0128335507557,
    "input_throughput": 4289.634985764357,
    "output_throughput": 3793.4970322120266,
    "total_throughput": 8083.132017976384,
    "itl": 89.60693293900593,
    "ttft": 2156580.0324731325,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 602,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9911620440334126,
    "arrivals": 507065,
    "finished_requests": 62515,
    "scheduler_time": 71.97880653183847
}
#Debug simulation 
Total elapsed time: 4.760874414816499. Arrivals time: 0.22582861641421914 Scheduler time: 4.338019098620862 Scheduler overhead time: 0.055733487475663424 Adapter cache time: 0.0574515569023788 Engine time: 0.05769483000040054 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_16-16-16/adapters_256_slots_192_rate_1.6-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_16-16-16/adapters_256_slots_192_rate_1.6-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 17280, 135, 17280, 17280, 135, 17280, 270, 17280, 135, 270, 135, 17280, 270, 270, 270, 270, 17280, 135, 135, 135, 270, 17280, 135, 17280, 17280, 270, 270, 270, 135, 17280, 135, 270, 270, 135, 270, 135, 135, 270, 270, 17280, 270, 135, 270, 17280, 270, 270, 17280, 270, 17280, 135, 17280, 17280, 270, 135, 135, 17280, 270, 135, 270, 270, 17280, 270, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 17280, 17280, 135, 17280, 135, 270, 17280, 17280, 17280, 270, 135, 17280, 270, 135, 135, 135, 135, 135, 17280, 270, 135, 17280, 135, 17280, 135, 135, 270, 270, 17280, 270, 17280, 135, 270, 135, 17280, 17280, 135, 17280, 270, 135, 17280, 135, 135, 17280, 17280, 270, 17280, 17280, 135, 17280, 270, 270, 135, 270, 17280, 17280, 135, 17280, 270, 135, 270, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 270, 17280, 17280, 270, 135, 17280, 135, 270, 270, 135, 270, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 270, 17280, 270, 135, 270, 17280, 270, 17280, 135, 17280, 135, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 270, 135, 17280, 135, 17280, 270, 270, 135, 270, 17280, 270, 270, 17280, 135, 17280, 17280, 270, 135, 17280, 17280, 270, 270, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 17280, 135, 17280, 270, 17280, 17280, 135, 17280, 270, 270, 17280, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 17280, 270, 135, 135, 135, 135]
Prompts retrieved: 1520505 . Total input tokens: 338953303 . Total output tokens: 303979113
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.465423769317567,
    "estimated_duration": 3600.1871189094395,
    "input_throughput": 5171.970062945046,
    "output_throughput": 4553.143339106629,
    "total_throughput": 9725.113402051677,
    "itl": 187.03337724335177,
    "ttft": 2038663.7662557238,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 692,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.069114804072269,
    "arrivals": 507065,
    "finished_requests": 75395,
    "scheduler_time": 74.8128899483728
}
#Debug simulation 
Total elapsed time: 5.465525494422764. Arrivals time: 0.2583662415854633 Scheduler time: 5.097155960276723 Scheduler overhead time: 0.030035389587283134 Adapter cache time: 0.03516815043985844 Engine time: 0.030906782019883394 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_16-16-32/adapters_256_slots_192_rate_1.6-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_16-16-32/adapters_256_slots_192_rate_1.6-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 17280, 135, 17280, 17280, 135, 17280, 270, 17280, 135, 270, 135, 17280, 270, 270, 270, 270, 17280, 135, 135, 135, 270, 17280, 135, 17280, 17280, 270, 270, 270, 135, 17280, 135, 270, 270, 135, 270, 135, 135, 270, 270, 17280, 270, 135, 270, 17280, 270, 270, 17280, 270, 17280, 135, 17280, 17280, 270, 135, 135, 17280, 270, 135, 270, 270, 17280, 270, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 17280, 17280, 135, 17280, 135, 270, 17280, 17280, 17280, 270, 135, 17280, 270, 135, 135, 135, 135, 135, 17280, 270, 135, 17280, 135, 17280, 135, 135, 270, 270, 17280, 270, 17280, 135, 270, 135, 17280, 17280, 135, 17280, 270, 135, 17280, 135, 135, 17280, 17280, 270, 17280, 17280, 135, 17280, 270, 270, 135, 270, 17280, 17280, 135, 17280, 270, 135, 270, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 270, 17280, 17280, 270, 135, 17280, 135, 270, 270, 135, 270, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 270, 17280, 270, 135, 270, 17280, 270, 17280, 135, 17280, 135, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 270, 135, 17280, 135, 17280, 270, 270, 135, 270, 17280, 270, 270, 17280, 135, 17280, 17280, 270, 135, 17280, 17280, 270, 270, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 17280, 135, 17280, 270, 17280, 17280, 135, 17280, 270, 270, 17280, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 17280, 270, 135, 135, 135, 135]
Prompts retrieved: 1520505 . Total input tokens: 338953303 . Total output tokens: 303979113
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.749936825595796,
    "estimated_duration": 3600.0162146722496,
    "input_throughput": 4292.441222075676,
    "output_throughput": 3795.936791702512,
    "total_throughput": 8088.378013778188,
    "itl": 89.7799596050809,
    "ttft": 2155674.120530306,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 602,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.018324861899014,
    "arrivals": 507065,
    "finished_requests": 62556,
    "scheduler_time": 71.99676875105638
}
#Debug simulation 
Total elapsed time: 4.75003123562783. Arrivals time: 0.22824622318148613 Scheduler time: 4.324594531673938 Scheduler overhead time: 0.055863450281322 Adapter cache time: 0.05844989698380232 Engine time: 0.056913933251053095 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-8/adapters_256_slots_192_rate_1.6-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-8/adapters_256_slots_192_rate_1.6-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 17280, 66, 17280, 17280, 66, 17280, 270, 17280, 66, 270, 66, 17280, 270, 270, 270, 270, 17280, 66, 66, 66, 270, 17280, 66, 17280, 17280, 270, 270, 270, 66, 17280, 66, 270, 270, 66, 270, 66, 66, 270, 270, 17280, 270, 66, 270, 17280, 270, 270, 17280, 270, 17280, 66, 17280, 17280, 270, 66, 66, 17280, 270, 66, 270, 270, 17280, 270, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 17280, 17280, 66, 17280, 66, 270, 17280, 17280, 17280, 270, 66, 17280, 270, 66, 66, 66, 66, 66, 17280, 270, 66, 17280, 66, 17280, 66, 66, 270, 270, 17280, 270, 17280, 66, 270, 66, 17280, 17280, 66, 17280, 270, 66, 17280, 66, 66, 17280, 17280, 270, 17280, 17280, 66, 17280, 270, 270, 66, 270, 17280, 17280, 66, 17280, 270, 66, 270, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 270, 17280, 17280, 270, 66, 17280, 66, 270, 270, 66, 270, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 270, 17280, 270, 66, 270, 17280, 270, 17280, 66, 17280, 66, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 270, 66, 17280, 66, 17280, 270, 270, 66, 270, 17280, 270, 270, 17280, 66, 17280, 17280, 270, 66, 17280, 17280, 270, 270, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 17280, 66, 17280, 270, 17280, 17280, 66, 17280, 270, 270, 17280, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 17280, 270, 66, 66, 66, 66]
Prompts retrieved: 1514640 . Total input tokens: 337655110 . Total output tokens: 302796901
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.558318397961557,
    "estimated_duration": 3600.021620212556,
    "input_throughput": 5270.675568576081,
    "output_throughput": 4617.884488987719,
    "total_throughput": 9888.5600575638,
    "itl": 185.15586532553883,
    "ttft": 2033244.9115704955,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 493,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.508820457758864,
    "arrivals": 505172,
    "finished_requests": 76384,
    "scheduler_time": 75.80732575537544
}
#Debug simulation 
Total elapsed time: 5.558418134693056. Arrivals time: 0.3070017867721617 Scheduler time: 5.145462951157242 Scheduler overhead time: 0.030154970474541187 Adapter cache time: 0.03051126841455698 Engine time: 0.031305630691349506 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-16/adapters_256_slots_192_rate_1.6-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-16/adapters_256_slots_192_rate_1.6-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 17280, 66, 17280, 17280, 66, 17280, 270, 17280, 66, 270, 66, 17280, 270, 270, 270, 270, 17280, 66, 66, 66, 270, 17280, 66, 17280, 17280, 270, 270, 270, 66, 17280, 66, 270, 270, 66, 270, 66, 66, 270, 270, 17280, 270, 66, 270, 17280, 270, 270, 17280, 270, 17280, 66, 17280, 17280, 270, 66, 66, 17280, 270, 66, 270, 270, 17280, 270, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 17280, 17280, 66, 17280, 66, 270, 17280, 17280, 17280, 270, 66, 17280, 270, 66, 66, 66, 66, 66, 17280, 270, 66, 17280, 66, 17280, 66, 66, 270, 270, 17280, 270, 17280, 66, 270, 66, 17280, 17280, 66, 17280, 270, 66, 17280, 66, 66, 17280, 17280, 270, 17280, 17280, 66, 17280, 270, 270, 66, 270, 17280, 17280, 66, 17280, 270, 66, 270, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 270, 17280, 17280, 270, 66, 17280, 66, 270, 270, 66, 270, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 270, 17280, 270, 66, 270, 17280, 270, 17280, 66, 17280, 66, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 270, 66, 17280, 66, 17280, 270, 270, 66, 270, 17280, 270, 270, 17280, 66, 17280, 17280, 270, 66, 17280, 17280, 270, 270, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 17280, 66, 17280, 270, 17280, 17280, 66, 17280, 270, 270, 17280, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 17280, 270, 66, 66, 66, 66]
Prompts retrieved: 1514640 . Total input tokens: 337655110 . Total output tokens: 302796901
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.573587280232459,
    "estimated_duration": 3600.0526814356967,
    "input_throughput": 5262.77965255893,
    "output_throughput": 4611.122244294444,
    "total_throughput": 9873.901896853373,
    "itl": 183.03166383297983,
    "ttft": 2034513.2565952565,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 494,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6106955148116735,
    "arrivals": 505172,
    "finished_requests": 76268,
    "scheduler_time": 75.79805569030366
}
#Debug simulation 
Total elapsed time: 5.573685925919563. Arrivals time: 0.28604905074462295 Scheduler time: 5.180901977233589 Scheduler overhead time: 0.030559516046196222 Adapter cache time: 0.030788843519985676 Engine time: 0.031242941040545702 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-32/adapters_256_slots_192_rate_1.6-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-32/adapters_256_slots_192_rate_1.6-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 17280, 66, 17280, 17280, 66, 17280, 270, 17280, 66, 270, 66, 17280, 270, 270, 270, 270, 17280, 66, 66, 66, 270, 17280, 66, 17280, 17280, 270, 270, 270, 66, 17280, 66, 270, 270, 66, 270, 66, 66, 270, 270, 17280, 270, 66, 270, 17280, 270, 270, 17280, 270, 17280, 66, 17280, 17280, 270, 66, 66, 17280, 270, 66, 270, 270, 17280, 270, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 17280, 17280, 66, 17280, 66, 270, 17280, 17280, 17280, 270, 66, 17280, 270, 66, 66, 66, 66, 66, 17280, 270, 66, 17280, 66, 17280, 66, 66, 270, 270, 17280, 270, 17280, 66, 270, 66, 17280, 17280, 66, 17280, 270, 66, 17280, 66, 66, 17280, 17280, 270, 17280, 17280, 66, 17280, 270, 270, 66, 270, 17280, 17280, 66, 17280, 270, 66, 270, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 270, 17280, 17280, 270, 66, 17280, 66, 270, 270, 66, 270, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 270, 17280, 270, 66, 270, 17280, 270, 17280, 66, 17280, 66, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 270, 66, 17280, 66, 17280, 270, 270, 66, 270, 17280, 270, 270, 17280, 66, 17280, 17280, 270, 66, 17280, 17280, 270, 270, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 17280, 66, 17280, 270, 17280, 17280, 66, 17280, 270, 270, 17280, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 17280, 270, 66, 66, 66, 66]
Prompts retrieved: 1514640 . Total input tokens: 337655110 . Total output tokens: 302796901
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.842268939130008,
    "estimated_duration": 3600.0446193117027,
    "input_throughput": 4322.053375820341,
    "output_throughput": 3795.086573847006,
    "total_throughput": 8117.1399496673475,
    "itl": 88.10914557659422,
    "ttft": 2154130.4863182507,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 437,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4284940053150141,
    "arrivals": 505172,
    "finished_requests": 62508,
    "scheduler_time": 72.29146677195446
}
#Debug simulation 
Total elapsed time: 4.842385179828852. Arrivals time: 0.2840987532399595 Scheduler time: 4.359450635034591 Scheduler overhead time: 0.05637352494522929 Adapter cache time: 0.0565921007655561 Engine time: 0.05937066953629255 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-16-16/adapters_256_slots_192_rate_1.6-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-16-16/adapters_256_slots_192_rate_1.6-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 17280, 66, 17280, 17280, 66, 17280, 270, 17280, 66, 270, 66, 17280, 270, 270, 270, 270, 17280, 66, 66, 66, 270, 17280, 66, 17280, 17280, 270, 270, 270, 66, 17280, 66, 270, 270, 66, 270, 66, 66, 270, 270, 17280, 270, 66, 270, 17280, 270, 270, 17280, 270, 17280, 66, 17280, 17280, 270, 66, 66, 17280, 270, 66, 270, 270, 17280, 270, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 17280, 17280, 66, 17280, 66, 270, 17280, 17280, 17280, 270, 66, 17280, 270, 66, 66, 66, 66, 66, 17280, 270, 66, 17280, 66, 17280, 66, 66, 270, 270, 17280, 270, 17280, 66, 270, 66, 17280, 17280, 66, 17280, 270, 66, 17280, 66, 66, 17280, 17280, 270, 17280, 17280, 66, 17280, 270, 270, 66, 270, 17280, 17280, 66, 17280, 270, 66, 270, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 270, 17280, 17280, 270, 66, 17280, 66, 270, 270, 66, 270, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 270, 17280, 270, 66, 270, 17280, 270, 17280, 66, 17280, 66, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 270, 66, 17280, 66, 17280, 270, 270, 66, 270, 17280, 270, 270, 17280, 66, 17280, 17280, 270, 66, 17280, 17280, 270, 270, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 17280, 66, 17280, 270, 17280, 17280, 66, 17280, 270, 270, 17280, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 17280, 270, 66, 66, 66, 66]
Prompts retrieved: 1514640 . Total input tokens: 337655110 . Total output tokens: 302796901
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 5.553786349017173,
    "estimated_duration": 3600.0193424717622,
    "input_throughput": 5262.828389969577,
    "output_throughput": 4611.164946853396,
    "total_throughput": 9873.993336822972,
    "itl": 183.01515556462093,
    "ttft": 2034503.2729071113,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 494,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5453202638612076,
    "arrivals": 505172,
    "finished_requests": 76268,
    "scheduler_time": 75.7984045173209
}
#Debug simulation 
Total elapsed time: 5.553913765121251. Arrivals time: 0.30681641958653927 Scheduler time: 5.139729266986251 Scheduler overhead time: 0.030652104876935482 Adapter cache time: 0.03097782703116536 Engine time: 0.03158844402059913 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-16-32/adapters_256_slots_192_rate_1.6-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-16-32/adapters_256_slots_192_rate_1.6-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 17280, 66, 17280, 17280, 66, 17280, 270, 17280, 66, 270, 66, 17280, 270, 270, 270, 270, 17280, 66, 66, 66, 270, 17280, 66, 17280, 17280, 270, 270, 270, 66, 17280, 66, 270, 270, 66, 270, 66, 66, 270, 270, 17280, 270, 66, 270, 17280, 270, 270, 17280, 270, 17280, 66, 17280, 17280, 270, 66, 66, 17280, 270, 66, 270, 270, 17280, 270, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 17280, 17280, 66, 17280, 66, 270, 17280, 17280, 17280, 270, 66, 17280, 270, 66, 66, 66, 66, 66, 17280, 270, 66, 17280, 66, 17280, 66, 66, 270, 270, 17280, 270, 17280, 66, 270, 66, 17280, 17280, 66, 17280, 270, 66, 17280, 66, 66, 17280, 17280, 270, 17280, 17280, 66, 17280, 270, 270, 66, 270, 17280, 17280, 66, 17280, 270, 66, 270, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 270, 17280, 17280, 270, 66, 17280, 66, 270, 270, 66, 270, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 270, 17280, 270, 66, 270, 17280, 270, 17280, 66, 17280, 66, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 270, 66, 17280, 66, 17280, 270, 270, 66, 270, 17280, 270, 270, 17280, 66, 17280, 17280, 270, 66, 17280, 17280, 270, 270, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 17280, 66, 17280, 270, 17280, 17280, 66, 17280, 270, 270, 17280, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 17280, 270, 66, 66, 66, 66]
Prompts retrieved: 1514640 . Total input tokens: 337655110 . Total output tokens: 302796901
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 4.800492906942964,
    "estimated_duration": 3600.044670307013,
    "input_throughput": 4329.3746126408,
    "output_throughput": 3801.100334355855,
    "total_throughput": 8130.474946996655,
    "itl": 88.4388025008667,
    "ttft": 2153014.6097460845,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 437,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4466025505587508,
    "arrivals": 505172,
    "finished_requests": 62608,
    "scheduler_time": 72.32742625065654
}
#Debug simulation 
Total elapsed time: 4.800596023909748. Arrivals time: 0.2291786246933043 Scheduler time: 4.375808058306575 Scheduler overhead time: 0.056161072105169296 Adapter cache time: 0.055097246542572975 Engine time: 0.05811199266463518 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_16-16-16/adapters_256_slots_192_rate_1.6-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_16-16-16/adapters_256_slots_192_rate_1.6-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 17280, 66, 17280, 17280, 66, 17280, 270, 17280, 66, 270, 66, 17280, 270, 270, 270, 270, 17280, 66, 66, 66, 270, 17280, 66, 17280, 17280, 270, 270, 270, 66, 17280, 66, 270, 270, 66, 270, 66, 66, 270, 270, 17280, 270, 66, 270, 17280, 270, 270, 17280, 270, 17280, 66, 17280, 17280, 270, 66, 66, 17280, 270, 66, 270, 270, 17280, 270, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 17280, 17280, 66, 17280, 66, 270, 17280, 17280, 17280, 270, 66, 17280, 270, 66, 66, 66, 66, 66, 17280, 270, 66, 17280, 66, 17280, 66, 66, 270, 270, 17280, 270, 17280, 66, 270, 66, 17280, 17280, 66, 17280, 270, 66, 17280, 66, 66, 17280, 17280, 270, 17280, 17280, 66, 17280, 270, 270, 66, 270, 17280, 17280, 66, 17280, 270, 66, 270, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 270, 17280, 17280, 270, 66, 17280, 66, 270, 270, 66, 270, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 270, 17280, 270, 66, 270, 17280, 270, 17280, 66, 17280, 66, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 270, 66, 17280, 66, 17280, 270, 270, 66, 270, 17280, 270, 270, 17280, 66, 17280, 17280, 270, 66, 17280, 17280, 270, 270, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 17280, 66, 17280, 270, 17280, 17280, 66, 17280, 270, 270, 17280, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 17280, 270, 66, 66, 66, 66]
Prompts retrieved: 1514640 . Total input tokens: 337655110 . Total output tokens: 302796901
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.594256744720042,
    "estimated_duration": 3600.134261766313,
    "input_throughput": 5263.027326848595,
    "output_throughput": 4611.531902105949,
    "total_throughput": 9874.559228954544,
    "itl": 183.02257209222148,
    "ttft": 2034519.2696326622,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 494,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4770848456816592,
    "arrivals": 505172,
    "finished_requests": 76276,
    "scheduler_time": 75.80210746789008
}
#Debug simulation 
Total elapsed time: 5.59436967689544. Arrivals time: 0.31626253528520465 Scheduler time: 5.170651521068066 Scheduler overhead time: 0.03073188289999962 Adapter cache time: 0.03105161152780056 Engine time: 0.03147443989291787 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_16-16-32/adapters_256_slots_192_rate_1.6-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_16-16-32/adapters_256_slots_192_rate_1.6-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 17280, 66, 17280, 17280, 66, 17280, 270, 17280, 66, 270, 66, 17280, 270, 270, 270, 270, 17280, 66, 66, 66, 270, 17280, 66, 17280, 17280, 270, 270, 270, 66, 17280, 66, 270, 270, 66, 270, 66, 66, 270, 270, 17280, 270, 66, 270, 17280, 270, 270, 17280, 270, 17280, 66, 17280, 17280, 270, 66, 66, 17280, 270, 66, 270, 270, 17280, 270, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 17280, 17280, 66, 17280, 66, 270, 17280, 17280, 17280, 270, 66, 17280, 270, 66, 66, 66, 66, 66, 17280, 270, 66, 17280, 66, 17280, 66, 66, 270, 270, 17280, 270, 17280, 66, 270, 66, 17280, 17280, 66, 17280, 270, 66, 17280, 66, 66, 17280, 17280, 270, 17280, 17280, 66, 17280, 270, 270, 66, 270, 17280, 17280, 66, 17280, 270, 66, 270, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 270, 17280, 17280, 270, 66, 17280, 66, 270, 270, 66, 270, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 270, 17280, 270, 66, 270, 17280, 270, 17280, 66, 17280, 66, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 270, 66, 17280, 66, 17280, 270, 270, 66, 270, 17280, 270, 270, 17280, 66, 17280, 17280, 270, 66, 17280, 17280, 270, 270, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 17280, 66, 17280, 270, 17280, 17280, 66, 17280, 270, 270, 17280, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 17280, 270, 66, 66, 66, 66]
Prompts retrieved: 1514640 . Total input tokens: 337655110 . Total output tokens: 302796901
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.8338854047469795,
    "estimated_duration": 3600.100373299721,
    "input_throughput": 4326.332153268358,
    "output_throughput": 3798.317708421727,
    "total_throughput": 8124.649861690084,
    "itl": 88.27280123110971,
    "ttft": 2153966.167768427,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 437,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4652141109481458,
    "arrivals": 505172,
    "finished_requests": 62563,
    "scheduler_time": 72.30803714173094
}
#Debug simulation 
Total elapsed time: 4.834015633910894. Arrivals time: 0.27578595699742436 Scheduler time: 4.3619482116773725 Scheduler overhead time: 0.0563579211011529 Adapter cache time: 0.05548309255391359 Engine time: 0.058121417183429 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-8/adapters_256_slots_192_rate_1.6-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-8/adapters_256_slots_192_rate_1.6-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 17280, 33, 17280, 17280, 33, 17280, 270, 17280, 33, 270, 33, 17280, 270, 270, 270, 270, 17280, 33, 33, 33, 270, 17280, 33, 17280, 17280, 270, 270, 270, 33, 17280, 33, 270, 270, 33, 270, 33, 33, 270, 270, 17280, 270, 33, 270, 17280, 270, 270, 17280, 270, 17280, 33, 17280, 17280, 270, 33, 33, 17280, 270, 33, 270, 270, 17280, 270, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 17280, 17280, 33, 17280, 33, 270, 17280, 17280, 17280, 270, 33, 17280, 270, 33, 33, 33, 33, 33, 17280, 270, 33, 17280, 33, 17280, 33, 33, 270, 270, 17280, 270, 17280, 33, 270, 33, 17280, 17280, 33, 17280, 270, 33, 17280, 33, 33, 17280, 17280, 270, 17280, 17280, 33, 17280, 270, 270, 33, 270, 17280, 17280, 33, 17280, 270, 33, 270, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 270, 17280, 17280, 270, 33, 17280, 33, 270, 270, 33, 270, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 270, 17280, 270, 33, 270, 17280, 270, 17280, 33, 17280, 33, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 270, 33, 17280, 33, 17280, 270, 270, 33, 270, 17280, 270, 270, 17280, 33, 17280, 17280, 270, 33, 17280, 17280, 270, 270, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 17280, 33, 17280, 270, 17280, 17280, 33, 17280, 270, 270, 17280, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 17280, 270, 33, 33, 33, 33]
Prompts retrieved: 1511835 . Total input tokens: 337040131 . Total output tokens: 302236107
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.5809105462394655,
    "estimated_duration": 3600.0055174830854,
    "input_throughput": 5280.905239637407,
    "output_throughput": 4648.914819358644,
    "total_throughput": 9929.82005899605,
    "itl": 184.3445491908137,
    "ttft": 2023855.8714205807,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 333,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0191424187296063,
    "arrivals": 504244,
    "finished_requests": 76994,
    "scheduler_time": 76.29464365533467
}
#Debug simulation 
Total elapsed time: 5.581016831099987. Arrivals time: 0.26271858997642994 Scheduler time: 5.214003523811698 Scheduler overhead time: 0.030419412069022655 Adapter cache time: 0.02845200104638934 Engine time: 0.03138623060658574 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-16/adapters_256_slots_192_rate_1.6-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-16/adapters_256_slots_192_rate_1.6-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 17280, 33, 17280, 17280, 33, 17280, 270, 17280, 33, 270, 33, 17280, 270, 270, 270, 270, 17280, 33, 33, 33, 270, 17280, 33, 17280, 17280, 270, 270, 270, 33, 17280, 33, 270, 270, 33, 270, 33, 33, 270, 270, 17280, 270, 33, 270, 17280, 270, 270, 17280, 270, 17280, 33, 17280, 17280, 270, 33, 33, 17280, 270, 33, 270, 270, 17280, 270, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 17280, 17280, 33, 17280, 33, 270, 17280, 17280, 17280, 270, 33, 17280, 270, 33, 33, 33, 33, 33, 17280, 270, 33, 17280, 33, 17280, 33, 33, 270, 270, 17280, 270, 17280, 33, 270, 33, 17280, 17280, 33, 17280, 270, 33, 17280, 33, 33, 17280, 17280, 270, 17280, 17280, 33, 17280, 270, 270, 33, 270, 17280, 17280, 33, 17280, 270, 33, 270, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 270, 17280, 17280, 270, 33, 17280, 33, 270, 270, 33, 270, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 270, 17280, 270, 33, 270, 17280, 270, 17280, 33, 17280, 33, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 270, 33, 17280, 33, 17280, 270, 270, 33, 270, 17280, 270, 270, 17280, 33, 17280, 17280, 270, 33, 17280, 17280, 270, 270, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 17280, 33, 17280, 270, 17280, 17280, 33, 17280, 270, 270, 17280, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 17280, 270, 33, 33, 33, 33]
Prompts retrieved: 1511835 . Total input tokens: 337040131 . Total output tokens: 302236107
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.5447431821376085,
    "estimated_duration": 3600.0346242210007,
    "input_throughput": 5272.374568927146,
    "output_throughput": 4642.120352833053,
    "total_throughput": 9914.494921760199,
    "itl": 182.1946563883211,
    "ttft": 2025143.1833861389,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 333,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.088437885488389,
    "arrivals": 504244,
    "finished_requests": 76877,
    "scheduler_time": 76.27868216337605
}
#Debug simulation 
Total elapsed time: 5.5448475969024. Arrivals time: 0.2609568778425455 Scheduler time: 5.178380887024105 Scheduler overhead time: 0.030854687560349703 Adapter cache time: 0.028762411791831255 Engine time: 0.03165069967508316 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-32/adapters_256_slots_192_rate_1.6-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-32/adapters_256_slots_192_rate_1.6-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 17280, 33, 17280, 17280, 33, 17280, 270, 17280, 33, 270, 33, 17280, 270, 270, 270, 270, 17280, 33, 33, 33, 270, 17280, 33, 17280, 17280, 270, 270, 270, 33, 17280, 33, 270, 270, 33, 270, 33, 33, 270, 270, 17280, 270, 33, 270, 17280, 270, 270, 17280, 270, 17280, 33, 17280, 17280, 270, 33, 33, 17280, 270, 33, 270, 270, 17280, 270, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 17280, 17280, 33, 17280, 33, 270, 17280, 17280, 17280, 270, 33, 17280, 270, 33, 33, 33, 33, 33, 17280, 270, 33, 17280, 33, 17280, 33, 33, 270, 270, 17280, 270, 17280, 33, 270, 33, 17280, 17280, 33, 17280, 270, 33, 17280, 33, 33, 17280, 17280, 270, 17280, 17280, 33, 17280, 270, 270, 33, 270, 17280, 17280, 33, 17280, 270, 33, 270, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 270, 17280, 17280, 270, 33, 17280, 33, 270, 270, 33, 270, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 270, 17280, 270, 33, 270, 17280, 270, 17280, 33, 17280, 33, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 270, 33, 17280, 33, 17280, 270, 270, 33, 270, 17280, 270, 270, 17280, 33, 17280, 17280, 270, 33, 17280, 17280, 270, 270, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 17280, 33, 17280, 270, 17280, 17280, 33, 17280, 270, 270, 17280, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 17280, 270, 33, 33, 33, 33]
Prompts retrieved: 1511835 . Total input tokens: 337040131 . Total output tokens: 302236107
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.7953911679796875,
    "estimated_duration": 3600.044701097189,
    "input_throughput": 4330.162343608954,
    "output_throughput": 3820.4795056595303,
    "total_throughput": 8150.641849268484,
    "itl": 88.31488690908303,
    "ttft": 2150294.1280144565,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 314,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0281731298379655,
    "arrivals": 504244,
    "finished_requests": 63097,
    "scheduler_time": 72.61412722790276
}
#Debug simulation 
Total elapsed time: 4.795488610863686. Arrivals time: 0.22691925102844834 Scheduler time: 4.375144651159644 Scheduler overhead time: 0.056379738729447126 Adapter cache time: 0.05293836211785674 Engine time: 0.057803019881248474 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-16-16/adapters_256_slots_192_rate_1.6-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-16-16/adapters_256_slots_192_rate_1.6-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 17280, 33, 17280, 17280, 33, 17280, 270, 17280, 33, 270, 33, 17280, 270, 270, 270, 270, 17280, 33, 33, 33, 270, 17280, 33, 17280, 17280, 270, 270, 270, 33, 17280, 33, 270, 270, 33, 270, 33, 33, 270, 270, 17280, 270, 33, 270, 17280, 270, 270, 17280, 270, 17280, 33, 17280, 17280, 270, 33, 33, 17280, 270, 33, 270, 270, 17280, 270, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 17280, 17280, 33, 17280, 33, 270, 17280, 17280, 17280, 270, 33, 17280, 270, 33, 33, 33, 33, 33, 17280, 270, 33, 17280, 33, 17280, 33, 33, 270, 270, 17280, 270, 17280, 33, 270, 33, 17280, 17280, 33, 17280, 270, 33, 17280, 33, 33, 17280, 17280, 270, 17280, 17280, 33, 17280, 270, 270, 33, 270, 17280, 17280, 33, 17280, 270, 33, 270, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 270, 17280, 17280, 270, 33, 17280, 33, 270, 270, 33, 270, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 270, 17280, 270, 33, 270, 17280, 270, 17280, 33, 17280, 33, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 270, 33, 17280, 33, 17280, 270, 270, 33, 270, 17280, 270, 270, 17280, 33, 17280, 17280, 270, 33, 17280, 17280, 270, 270, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 17280, 33, 17280, 270, 17280, 17280, 33, 17280, 270, 270, 17280, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 17280, 270, 33, 33, 33, 33]
Prompts retrieved: 1511835 . Total input tokens: 337040131 . Total output tokens: 302236107
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 5.564907401800156,
    "estimated_duration": 3600.1783597170406,
    "input_throughput": 5272.667380149452,
    "output_throughput": 4642.063067484666,
    "total_throughput": 9914.730447634118,
    "itl": 182.19200272008732,
    "ttft": 2025162.7958868751,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 333,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0430838051415077,
    "arrivals": 504244,
    "finished_requests": 76882,
    "scheduler_time": 76.28294331780997
}
#Debug simulation 
Total elapsed time: 5.565010050777346. Arrivals time: 0.2640406973659992 Scheduler time: 5.1956645688042045 Scheduler overhead time: 0.03083307296037674 Adapter cache time: 0.028800057712942362 Engine time: 0.031435681506991386 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-16-32/adapters_256_slots_192_rate_1.6-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-16-32/adapters_256_slots_192_rate_1.6-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 17280, 33, 17280, 17280, 33, 17280, 270, 17280, 33, 270, 33, 17280, 270, 270, 270, 270, 17280, 33, 33, 33, 270, 17280, 33, 17280, 17280, 270, 270, 270, 33, 17280, 33, 270, 270, 33, 270, 33, 33, 270, 270, 17280, 270, 33, 270, 17280, 270, 270, 17280, 270, 17280, 33, 17280, 17280, 270, 33, 33, 17280, 270, 33, 270, 270, 17280, 270, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 17280, 17280, 33, 17280, 33, 270, 17280, 17280, 17280, 270, 33, 17280, 270, 33, 33, 33, 33, 33, 17280, 270, 33, 17280, 33, 17280, 33, 33, 270, 270, 17280, 270, 17280, 33, 270, 33, 17280, 17280, 33, 17280, 270, 33, 17280, 33, 33, 17280, 17280, 270, 17280, 17280, 33, 17280, 270, 270, 33, 270, 17280, 17280, 33, 17280, 270, 33, 270, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 270, 17280, 17280, 270, 33, 17280, 33, 270, 270, 33, 270, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 270, 17280, 270, 33, 270, 17280, 270, 17280, 33, 17280, 33, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 270, 33, 17280, 33, 17280, 270, 270, 33, 270, 17280, 270, 270, 17280, 33, 17280, 17280, 270, 33, 17280, 17280, 270, 270, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 17280, 33, 17280, 270, 17280, 17280, 33, 17280, 270, 270, 17280, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 17280, 270, 33, 33, 33, 33]
Prompts retrieved: 1511835 . Total input tokens: 337040131 . Total output tokens: 302236107
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 4.82601284654811,
    "estimated_duration": 3600.0104729084724,
    "input_throughput": 4324.812696286797,
    "output_throughput": 3816.8194518886735,
    "total_throughput": 8141.632148175471,
    "itl": 88.17088281919794,
    "ttft": 2150316.3193754125,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 314,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0413772774115255,
    "arrivals": 504244,
    "finished_requests": 63024,
    "scheduler_time": 72.59150465314342
}
#Debug simulation 
Total elapsed time: 4.826134440954775. Arrivals time: 0.2256880863569677 Scheduler time: 4.405776152387261 Scheduler overhead time: 0.05655491119250655 Adapter cache time: 0.05366408731788397 Engine time: 0.05807147966697812 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_16-16-16/adapters_256_slots_192_rate_1.6-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_16-16-16/adapters_256_slots_192_rate_1.6-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 17280, 33, 17280, 17280, 33, 17280, 270, 17280, 33, 270, 33, 17280, 270, 270, 270, 270, 17280, 33, 33, 33, 270, 17280, 33, 17280, 17280, 270, 270, 270, 33, 17280, 33, 270, 270, 33, 270, 33, 33, 270, 270, 17280, 270, 33, 270, 17280, 270, 270, 17280, 270, 17280, 33, 17280, 17280, 270, 33, 33, 17280, 270, 33, 270, 270, 17280, 270, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 17280, 17280, 33, 17280, 33, 270, 17280, 17280, 17280, 270, 33, 17280, 270, 33, 33, 33, 33, 33, 17280, 270, 33, 17280, 33, 17280, 33, 33, 270, 270, 17280, 270, 17280, 33, 270, 33, 17280, 17280, 33, 17280, 270, 33, 17280, 33, 33, 17280, 17280, 270, 17280, 17280, 33, 17280, 270, 270, 33, 270, 17280, 17280, 33, 17280, 270, 33, 270, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 270, 17280, 17280, 270, 33, 17280, 33, 270, 270, 33, 270, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 270, 17280, 270, 33, 270, 17280, 270, 17280, 33, 17280, 33, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 270, 33, 17280, 33, 17280, 270, 270, 33, 270, 17280, 270, 270, 17280, 33, 17280, 17280, 270, 33, 17280, 17280, 270, 270, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 17280, 33, 17280, 270, 17280, 17280, 33, 17280, 270, 270, 17280, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 17280, 270, 33, 33, 33, 33]
Prompts retrieved: 1511835 . Total input tokens: 337040131 . Total output tokens: 302236107
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.57438027812168,
    "estimated_duration": 3600.163987562735,
    "input_throughput": 5272.688429076515,
    "output_throughput": 4642.081598986823,
    "total_throughput": 9914.770028063338,
    "itl": 182.18610277416633,
    "ttft": 2025162.190993938,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 333,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9956867482024259,
    "arrivals": 504244,
    "finished_requests": 76882,
    "scheduler_time": 76.28289691680138
}
#Debug simulation 
Total elapsed time: 5.5744811138138175. Arrivals time: 0.2707144203595817 Scheduler time: 5.198537605814636 Scheduler overhead time: 0.03077403688803315 Adapter cache time: 0.02872299449518323 Engine time: 0.03150484152138233 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_16-16-32/adapters_256_slots_192_rate_1.6-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_16-16-32/adapters_256_slots_192_rate_1.6-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 17280, 33, 17280, 17280, 33, 17280, 270, 17280, 33, 270, 33, 17280, 270, 270, 270, 270, 17280, 33, 33, 33, 270, 17280, 33, 17280, 17280, 270, 270, 270, 33, 17280, 33, 270, 270, 33, 270, 33, 33, 270, 270, 17280, 270, 33, 270, 17280, 270, 270, 17280, 270, 17280, 33, 17280, 17280, 270, 33, 33, 17280, 270, 33, 270, 270, 17280, 270, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 17280, 17280, 33, 17280, 33, 270, 17280, 17280, 17280, 270, 33, 17280, 270, 33, 33, 33, 33, 33, 17280, 270, 33, 17280, 33, 17280, 33, 33, 270, 270, 17280, 270, 17280, 33, 270, 33, 17280, 17280, 33, 17280, 270, 33, 17280, 33, 33, 17280, 17280, 270, 17280, 17280, 33, 17280, 270, 270, 33, 270, 17280, 17280, 33, 17280, 270, 33, 270, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 270, 17280, 17280, 270, 33, 17280, 33, 270, 270, 33, 270, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 270, 17280, 270, 33, 270, 17280, 270, 17280, 33, 17280, 33, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 270, 33, 17280, 33, 17280, 270, 270, 33, 270, 17280, 270, 270, 17280, 33, 17280, 17280, 270, 33, 17280, 17280, 270, 270, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 17280, 33, 17280, 270, 17280, 17280, 33, 17280, 270, 270, 17280, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 17280, 270, 33, 33, 33, 33]
Prompts retrieved: 1511835 . Total input tokens: 337040131 . Total output tokens: 302236107
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.797723127994686,
    "estimated_duration": 3600.0731570309695,
    "input_throughput": 4327.406505496739,
    "output_throughput": 3818.574623449448,
    "total_throughput": 8145.981128946187,
    "itl": 88.2562640255874,
    "ttft": 2150179.9071177463,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 314,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.05521019391716,
    "arrivals": 504244,
    "finished_requests": 63064,
    "scheduler_time": 72.60428809892714
}
#Debug simulation 
Total elapsed time: 4.797822151333094. Arrivals time: 0.2286430220119655 Scheduler time: 4.37558730924502 Scheduler overhead time: 0.05651581520214677 Adapter cache time: 0.05266056768596172 Engine time: 0.0579629666171968 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-8/adapters_256_slots_192_rate_1.6-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-8/adapters_256_slots_192_rate_1.6-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 17280, 66, 17280, 17280, 66, 17280, 135, 17280, 66, 135, 66, 17280, 135, 135, 135, 135, 17280, 66, 66, 66, 135, 17280, 66, 17280, 17280, 135, 135, 135, 66, 17280, 66, 135, 135, 66, 135, 66, 66, 135, 135, 17280, 135, 66, 135, 17280, 135, 135, 17280, 135, 17280, 66, 17280, 17280, 135, 66, 66, 17280, 135, 66, 135, 135, 17280, 135, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 17280, 17280, 66, 17280, 66, 135, 17280, 17280, 17280, 135, 66, 17280, 135, 66, 66, 66, 66, 66, 17280, 135, 66, 17280, 66, 17280, 66, 66, 135, 135, 17280, 135, 17280, 66, 135, 66, 17280, 17280, 66, 17280, 135, 66, 17280, 66, 66, 17280, 17280, 135, 17280, 17280, 66, 17280, 135, 135, 66, 135, 17280, 17280, 66, 17280, 135, 66, 135, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 135, 17280, 17280, 135, 66, 17280, 66, 135, 135, 66, 135, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 135, 17280, 135, 66, 135, 17280, 135, 17280, 66, 17280, 66, 135, 17280, 135, 17280, 135, 17280, 135, 17280, 135, 66, 17280, 66, 17280, 135, 135, 66, 135, 17280, 135, 135, 17280, 66, 17280, 17280, 135, 66, 17280, 17280, 135, 135, 17280, 17280, 135, 135, 135, 135, 17280, 17280, 135, 135, 17280, 66, 17280, 135, 17280, 17280, 66, 17280, 135, 135, 17280, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 17280, 135, 66, 66, 66, 66]
Prompts retrieved: 1503165 . Total input tokens: 335100538 . Total output tokens: 300507985
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.715673726983368,
    "estimated_duration": 3600.0274311950748,
    "input_throughput": 5343.14123090294,
    "output_throughput": 4737.910842623175,
    "total_throughput": 10081.052073526114,
    "itl": 182.0337257555547,
    "ttft": 2016747.080901709,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 458,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4017033867212139,
    "arrivals": 501368,
    "finished_requests": 77946,
    "scheduler_time": 77.72373642224653
}
#Debug simulation 
Total elapsed time: 5.715776066761464. Arrivals time: 0.2693152246065438 Scheduler time: 5.345799164380878 Scheduler overhead time: 0.030705824960023165 Adapter cache time: 0.024060083087533712 Engine time: 0.03165059816092253 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-16/adapters_256_slots_192_rate_1.6-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-16/adapters_256_slots_192_rate_1.6-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 17280, 66, 17280, 17280, 66, 17280, 135, 17280, 66, 135, 66, 17280, 135, 135, 135, 135, 17280, 66, 66, 66, 135, 17280, 66, 17280, 17280, 135, 135, 135, 66, 17280, 66, 135, 135, 66, 135, 66, 66, 135, 135, 17280, 135, 66, 135, 17280, 135, 135, 17280, 135, 17280, 66, 17280, 17280, 135, 66, 66, 17280, 135, 66, 135, 135, 17280, 135, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 17280, 17280, 66, 17280, 66, 135, 17280, 17280, 17280, 135, 66, 17280, 135, 66, 66, 66, 66, 66, 17280, 135, 66, 17280, 66, 17280, 66, 66, 135, 135, 17280, 135, 17280, 66, 135, 66, 17280, 17280, 66, 17280, 135, 66, 17280, 66, 66, 17280, 17280, 135, 17280, 17280, 66, 17280, 135, 135, 66, 135, 17280, 17280, 66, 17280, 135, 66, 135, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 135, 17280, 17280, 135, 66, 17280, 66, 135, 135, 66, 135, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 135, 17280, 135, 66, 135, 17280, 135, 17280, 66, 17280, 66, 135, 17280, 135, 17280, 135, 17280, 135, 17280, 135, 66, 17280, 66, 17280, 135, 135, 66, 135, 17280, 135, 135, 17280, 66, 17280, 17280, 135, 66, 17280, 17280, 135, 135, 17280, 17280, 135, 135, 135, 135, 17280, 17280, 135, 135, 17280, 66, 17280, 135, 17280, 17280, 66, 17280, 135, 135, 17280, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 17280, 135, 66, 66, 66, 66]
Prompts retrieved: 1503165 . Total input tokens: 335100538 . Total output tokens: 300507985
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.723254652228206,
    "estimated_duration": 3600.0851703335757,
    "input_throughput": 5332.852444216227,
    "output_throughput": 4730.702245697691,
    "total_throughput": 10063.554689913917,
    "itl": 179.92380398965807,
    "ttft": 2017906.377357694,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 458,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.493247416552628,
    "arrivals": 501368,
    "finished_requests": 77803,
    "scheduler_time": 77.69157058265617
}
#Debug simulation 
Total elapsed time: 5.723355190828443. Arrivals time: 0.30628754012286663 Scheduler time: 5.315021560993046 Scheduler overhead time: 0.031156370416283607 Adapter cache time: 0.024454385042190552 Engine time: 0.03201440814882517 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-32/adapters_256_slots_192_rate_1.6-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-32/adapters_256_slots_192_rate_1.6-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 17280, 66, 17280, 17280, 66, 17280, 135, 17280, 66, 135, 66, 17280, 135, 135, 135, 135, 17280, 66, 66, 66, 135, 17280, 66, 17280, 17280, 135, 135, 135, 66, 17280, 66, 135, 135, 66, 135, 66, 66, 135, 135, 17280, 135, 66, 135, 17280, 135, 135, 17280, 135, 17280, 66, 17280, 17280, 135, 66, 66, 17280, 135, 66, 135, 135, 17280, 135, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 17280, 17280, 66, 17280, 66, 135, 17280, 17280, 17280, 135, 66, 17280, 135, 66, 66, 66, 66, 66, 17280, 135, 66, 17280, 66, 17280, 66, 66, 135, 135, 17280, 135, 17280, 66, 135, 66, 17280, 17280, 66, 17280, 135, 66, 17280, 66, 66, 17280, 17280, 135, 17280, 17280, 66, 17280, 135, 135, 66, 135, 17280, 17280, 66, 17280, 135, 66, 135, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 135, 17280, 17280, 135, 66, 17280, 66, 135, 135, 66, 135, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 135, 17280, 135, 66, 135, 17280, 135, 17280, 66, 17280, 66, 135, 17280, 135, 17280, 135, 17280, 135, 17280, 135, 66, 17280, 66, 17280, 135, 135, 66, 135, 17280, 135, 135, 17280, 66, 17280, 17280, 135, 66, 17280, 17280, 135, 135, 17280, 17280, 135, 135, 135, 135, 17280, 17280, 135, 135, 17280, 66, 17280, 135, 17280, 17280, 66, 17280, 135, 135, 17280, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 17280, 135, 66, 66, 66, 66]
Prompts retrieved: 1503165 . Total input tokens: 335100538 . Total output tokens: 300507985
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.868733712937683,
    "estimated_duration": 3600.0670119629835,
    "input_throughput": 4297.35972930247,
    "output_throughput": 3824.2354806870912,
    "total_throughput": 8121.595209989561,
    "itl": 88.05090353546653,
    "ttft": 2149324.421984598,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 403,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3172576720826403,
    "arrivals": 501368,
    "finished_requests": 62725,
    "scheduler_time": 72.7466324569992
}
#Debug simulation 
Total elapsed time: 4.868845998775214. Arrivals time: 0.27578974049538374 Scheduler time: 4.405800826381892 Scheduler overhead time: 0.05676810955628753 Adapter cache time: 0.045709813479334116 Engine time: 0.058237099554389715 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-16-16/adapters_256_slots_192_rate_1.6-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-16-16/adapters_256_slots_192_rate_1.6-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 17280, 66, 17280, 17280, 66, 17280, 135, 17280, 66, 135, 66, 17280, 135, 135, 135, 135, 17280, 66, 66, 66, 135, 17280, 66, 17280, 17280, 135, 135, 135, 66, 17280, 66, 135, 135, 66, 135, 66, 66, 135, 135, 17280, 135, 66, 135, 17280, 135, 135, 17280, 135, 17280, 66, 17280, 17280, 135, 66, 66, 17280, 135, 66, 135, 135, 17280, 135, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 17280, 17280, 66, 17280, 66, 135, 17280, 17280, 17280, 135, 66, 17280, 135, 66, 66, 66, 66, 66, 17280, 135, 66, 17280, 66, 17280, 66, 66, 135, 135, 17280, 135, 17280, 66, 135, 66, 17280, 17280, 66, 17280, 135, 66, 17280, 66, 66, 17280, 17280, 135, 17280, 17280, 66, 17280, 135, 135, 66, 135, 17280, 17280, 66, 17280, 135, 66, 135, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 135, 17280, 17280, 135, 66, 17280, 66, 135, 135, 66, 135, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 135, 17280, 135, 66, 135, 17280, 135, 17280, 66, 17280, 66, 135, 17280, 135, 17280, 135, 17280, 135, 17280, 135, 66, 17280, 66, 17280, 135, 135, 66, 135, 17280, 135, 135, 17280, 66, 17280, 17280, 135, 66, 17280, 17280, 135, 135, 17280, 17280, 135, 135, 135, 135, 17280, 17280, 135, 135, 17280, 66, 17280, 135, 17280, 17280, 66, 17280, 135, 135, 17280, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 17280, 135, 66, 66, 66, 66]
Prompts retrieved: 1503165 . Total input tokens: 335100538 . Total output tokens: 300507985
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 5.687629961874336,
    "estimated_duration": 3600.04443195432,
    "input_throughput": 5332.91279118402,
    "output_throughput": 4730.755778687595,
    "total_throughput": 10063.668569871616,
    "itl": 179.9147660031011,
    "ttft": 2017891.1240904133,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 458,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4311409281496854,
    "arrivals": 501368,
    "finished_requests": 77803,
    "scheduler_time": 77.69183844822149
}
#Debug simulation 
Total elapsed time: 5.687755620107055. Arrivals time: 0.308697662781924 Scheduler time: 5.277567538432777 Scheduler overhead time: 0.031247397884726524 Adapter cache time: 0.02375390799716115 Engine time: 0.032100383657962084 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-16-32/adapters_256_slots_192_rate_1.6-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-16-32/adapters_256_slots_192_rate_1.6-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 17280, 66, 17280, 17280, 66, 17280, 135, 17280, 66, 135, 66, 17280, 135, 135, 135, 135, 17280, 66, 66, 66, 135, 17280, 66, 17280, 17280, 135, 135, 135, 66, 17280, 66, 135, 135, 66, 135, 66, 66, 135, 135, 17280, 135, 66, 135, 17280, 135, 135, 17280, 135, 17280, 66, 17280, 17280, 135, 66, 66, 17280, 135, 66, 135, 135, 17280, 135, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 17280, 17280, 66, 17280, 66, 135, 17280, 17280, 17280, 135, 66, 17280, 135, 66, 66, 66, 66, 66, 17280, 135, 66, 17280, 66, 17280, 66, 66, 135, 135, 17280, 135, 17280, 66, 135, 66, 17280, 17280, 66, 17280, 135, 66, 17280, 66, 66, 17280, 17280, 135, 17280, 17280, 66, 17280, 135, 135, 66, 135, 17280, 17280, 66, 17280, 135, 66, 135, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 135, 17280, 17280, 135, 66, 17280, 66, 135, 135, 66, 135, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 135, 17280, 135, 66, 135, 17280, 135, 17280, 66, 17280, 66, 135, 17280, 135, 17280, 135, 17280, 135, 17280, 135, 66, 17280, 66, 17280, 135, 135, 66, 135, 17280, 135, 135, 17280, 66, 17280, 17280, 135, 66, 17280, 17280, 135, 135, 17280, 17280, 135, 135, 135, 135, 17280, 17280, 135, 135, 17280, 66, 17280, 135, 17280, 17280, 66, 17280, 135, 135, 17280, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 17280, 135, 66, 66, 66, 66]
Prompts retrieved: 1503165 . Total input tokens: 335100538 . Total output tokens: 300507985
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 4.886446715798229,
    "estimated_duration": 3600.0464932361974,
    "input_throughput": 4318.217008921292,
    "output_throughput": 3845.1336742477424,
    "total_throughput": 8163.350683169035,
    "itl": 87.95003215913736,
    "ttft": 2146016.153271227,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 403,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3339829256758138,
    "arrivals": 501368,
    "finished_requests": 63053,
    "scheduler_time": 73.09648815213323
}
#Debug simulation 
Total elapsed time: 4.886545863002539. Arrivals time: 0.2744518341496587 Scheduler time: 4.42551098857075 Scheduler overhead time: 0.056716767605394125 Adapter cache time: 0.04534963006153703 Engine time: 0.05806217668578029 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_16-16-16/adapters_256_slots_192_rate_1.6-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_16-16-16/adapters_256_slots_192_rate_1.6-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 17280, 66, 17280, 17280, 66, 17280, 135, 17280, 66, 135, 66, 17280, 135, 135, 135, 135, 17280, 66, 66, 66, 135, 17280, 66, 17280, 17280, 135, 135, 135, 66, 17280, 66, 135, 135, 66, 135, 66, 66, 135, 135, 17280, 135, 66, 135, 17280, 135, 135, 17280, 135, 17280, 66, 17280, 17280, 135, 66, 66, 17280, 135, 66, 135, 135, 17280, 135, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 17280, 17280, 66, 17280, 66, 135, 17280, 17280, 17280, 135, 66, 17280, 135, 66, 66, 66, 66, 66, 17280, 135, 66, 17280, 66, 17280, 66, 66, 135, 135, 17280, 135, 17280, 66, 135, 66, 17280, 17280, 66, 17280, 135, 66, 17280, 66, 66, 17280, 17280, 135, 17280, 17280, 66, 17280, 135, 135, 66, 135, 17280, 17280, 66, 17280, 135, 66, 135, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 135, 17280, 17280, 135, 66, 17280, 66, 135, 135, 66, 135, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 135, 17280, 135, 66, 135, 17280, 135, 17280, 66, 17280, 66, 135, 17280, 135, 17280, 135, 17280, 135, 17280, 135, 66, 17280, 66, 17280, 135, 135, 66, 135, 17280, 135, 135, 17280, 66, 17280, 17280, 135, 66, 17280, 17280, 135, 135, 17280, 17280, 135, 135, 135, 135, 17280, 17280, 135, 135, 17280, 66, 17280, 135, 17280, 17280, 66, 17280, 135, 135, 17280, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 17280, 135, 66, 66, 66, 66]
Prompts retrieved: 1503165 . Total input tokens: 335100538 . Total output tokens: 300507985
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.698170440737158,
    "estimated_duration": 3600.1389064721816,
    "input_throughput": 5333.131998180126,
    "output_throughput": 4730.902457508165,
    "total_throughput": 10064.03445568829,
    "itl": 179.921952181367,
    "ttft": 2017882.162260964,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 458,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3694430350651847,
    "arrivals": 501368,
    "finished_requests": 77807,
    "scheduler_time": 77.69486717504574
}
#Debug simulation 
Total elapsed time: 5.698285625781864. Arrivals time: 0.32012001564726233 Scheduler time: 5.275983079802245 Scheduler overhead time: 0.03113286942243576 Adapter cache time: 0.024480757769197226 Engine time: 0.032224925234913826 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_16-16-32/adapters_256_slots_192_rate_1.6-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_16-16-32/adapters_256_slots_192_rate_1.6-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 17280, 66, 17280, 17280, 66, 17280, 135, 17280, 66, 135, 66, 17280, 135, 135, 135, 135, 17280, 66, 66, 66, 135, 17280, 66, 17280, 17280, 135, 135, 135, 66, 17280, 66, 135, 135, 66, 135, 66, 66, 135, 135, 17280, 135, 66, 135, 17280, 135, 135, 17280, 135, 17280, 66, 17280, 17280, 135, 66, 66, 17280, 135, 66, 135, 135, 17280, 135, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 17280, 17280, 66, 17280, 66, 135, 17280, 17280, 17280, 135, 66, 17280, 135, 66, 66, 66, 66, 66, 17280, 135, 66, 17280, 66, 17280, 66, 66, 135, 135, 17280, 135, 17280, 66, 135, 66, 17280, 17280, 66, 17280, 135, 66, 17280, 66, 66, 17280, 17280, 135, 17280, 17280, 66, 17280, 135, 135, 66, 135, 17280, 17280, 66, 17280, 135, 66, 135, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 135, 17280, 17280, 135, 66, 17280, 66, 135, 135, 66, 135, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 135, 17280, 135, 66, 135, 17280, 135, 17280, 66, 17280, 66, 135, 17280, 135, 17280, 135, 17280, 135, 17280, 135, 66, 17280, 66, 17280, 135, 135, 66, 135, 17280, 135, 135, 17280, 66, 17280, 17280, 135, 66, 17280, 17280, 135, 135, 17280, 17280, 135, 135, 135, 135, 17280, 17280, 135, 135, 17280, 66, 17280, 135, 17280, 17280, 66, 17280, 135, 135, 17280, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 17280, 135, 66, 66, 66, 66]
Prompts retrieved: 1503165 . Total input tokens: 335100538 . Total output tokens: 300507985
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.899452260695398,
    "estimated_duration": 3600.025573675327,
    "input_throughput": 4323.377065377393,
    "output_throughput": 3849.73070784355,
    "total_throughput": 8173.107773220943,
    "itl": 88.10893129648355,
    "ttft": 2145766.6588104945,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 403,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3510854406282322,
    "arrivals": 501368,
    "finished_requests": 63118,
    "scheduler_time": 73.12264820909313
}
#Debug simulation 
Total elapsed time: 4.899575458839536. Arrivals time: 0.27775384299457073 Scheduler time: 4.434028822928667 Scheduler overhead time: 0.057093823328614235 Adapter cache time: 0.04594207741320133 Engine time: 0.05812461534515023 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-8/adapters_256_slots_192_rate_1.6-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-8/adapters_256_slots_192_rate_1.6-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 17280, 33, 17280, 17280, 33, 17280, 135, 17280, 33, 135, 33, 17280, 135, 135, 135, 135, 17280, 33, 33, 33, 135, 17280, 33, 17280, 17280, 135, 135, 135, 33, 17280, 33, 135, 135, 33, 135, 33, 33, 135, 135, 17280, 135, 33, 135, 17280, 135, 135, 17280, 135, 17280, 33, 17280, 17280, 135, 33, 33, 17280, 135, 33, 135, 135, 17280, 135, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 17280, 17280, 33, 17280, 33, 135, 17280, 17280, 17280, 135, 33, 17280, 135, 33, 33, 33, 33, 33, 17280, 135, 33, 17280, 33, 17280, 33, 33, 135, 135, 17280, 135, 17280, 33, 135, 33, 17280, 17280, 33, 17280, 135, 33, 17280, 33, 33, 17280, 17280, 135, 17280, 17280, 33, 17280, 135, 135, 33, 135, 17280, 17280, 33, 17280, 135, 33, 135, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 135, 17280, 17280, 135, 33, 17280, 33, 135, 135, 33, 135, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 135, 17280, 135, 33, 135, 17280, 135, 17280, 33, 17280, 33, 135, 17280, 135, 17280, 135, 17280, 135, 17280, 135, 33, 17280, 33, 17280, 135, 135, 33, 135, 17280, 135, 135, 17280, 33, 17280, 17280, 135, 33, 17280, 17280, 135, 135, 17280, 17280, 135, 135, 135, 135, 17280, 17280, 135, 135, 17280, 33, 17280, 135, 17280, 17280, 33, 17280, 135, 135, 17280, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 17280, 135, 33, 33, 33, 33]
Prompts retrieved: 1500360 . Total input tokens: 334451225 . Total output tokens: 299936524
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.6910801460035145,
    "estimated_duration": 3600.0148502331913,
    "input_throughput": 5442.064217799257,
    "output_throughput": 4802.686577495661,
    "total_throughput": 10244.750795294918,
    "itl": 179.02944258400154,
    "ttft": 2010589.1677987245,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 323,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9885375412902782,
    "arrivals": 500381,
    "finished_requests": 78916,
    "scheduler_time": 78.82380702592427
}
#Debug simulation 
Total elapsed time: 5.691179695073515. Arrivals time: 0.2656621537171304 Scheduler time: 5.327676550485194 Scheduler overhead time: 0.031191911548376083 Adapter cache time: 0.020377029664814472 Engine time: 0.03191744443029165 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-16/adapters_256_slots_192_rate_1.6-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-16/adapters_256_slots_192_rate_1.6-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 17280, 33, 17280, 17280, 33, 17280, 135, 17280, 33, 135, 33, 17280, 135, 135, 135, 135, 17280, 33, 33, 33, 135, 17280, 33, 17280, 17280, 135, 135, 135, 33, 17280, 33, 135, 135, 33, 135, 33, 33, 135, 135, 17280, 135, 33, 135, 17280, 135, 135, 17280, 135, 17280, 33, 17280, 17280, 135, 33, 33, 17280, 135, 33, 135, 135, 17280, 135, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 17280, 17280, 33, 17280, 33, 135, 17280, 17280, 17280, 135, 33, 17280, 135, 33, 33, 33, 33, 33, 17280, 135, 33, 17280, 33, 17280, 33, 33, 135, 135, 17280, 135, 17280, 33, 135, 33, 17280, 17280, 33, 17280, 135, 33, 17280, 33, 33, 17280, 17280, 135, 17280, 17280, 33, 17280, 135, 135, 33, 135, 17280, 17280, 33, 17280, 135, 33, 135, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 135, 17280, 17280, 135, 33, 17280, 33, 135, 135, 33, 135, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 135, 17280, 135, 33, 135, 17280, 135, 17280, 33, 17280, 33, 135, 17280, 135, 17280, 135, 17280, 135, 17280, 135, 33, 17280, 33, 17280, 135, 135, 33, 135, 17280, 135, 135, 17280, 33, 17280, 17280, 135, 33, 17280, 17280, 135, 135, 17280, 17280, 135, 135, 135, 135, 17280, 17280, 135, 135, 17280, 33, 17280, 135, 17280, 17280, 33, 17280, 135, 135, 17280, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 17280, 135, 33, 33, 33, 33]
Prompts retrieved: 1500360 . Total input tokens: 334451225 . Total output tokens: 299936524
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.721070118248463,
    "estimated_duration": 3600.0204094522,
    "input_throughput": 5432.842255184912,
    "output_throughput": 4794.741428320557,
    "total_throughput": 10227.583683505469,
    "itl": 177.12836226787292,
    "ttft": 2011447.2189082177,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 322,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0514613790600622,
    "arrivals": 500381,
    "finished_requests": 78780,
    "scheduler_time": 78.78679719424942
}
#Debug simulation 
Total elapsed time: 5.721170557197183. Arrivals time: 0.2670553056523204 Scheduler time: 5.355098157189786 Scheduler overhead time: 0.031573329120874405 Adapter cache time: 0.0204395093023777 Engine time: 0.032452660612761974 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-32/adapters_256_slots_192_rate_1.6-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-32/adapters_256_slots_192_rate_1.6-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 17280, 33, 17280, 17280, 33, 17280, 135, 17280, 33, 135, 33, 17280, 135, 135, 135, 135, 17280, 33, 33, 33, 135, 17280, 33, 17280, 17280, 135, 135, 135, 33, 17280, 33, 135, 135, 33, 135, 33, 33, 135, 135, 17280, 135, 33, 135, 17280, 135, 135, 17280, 135, 17280, 33, 17280, 17280, 135, 33, 33, 17280, 135, 33, 135, 135, 17280, 135, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 17280, 17280, 33, 17280, 33, 135, 17280, 17280, 17280, 135, 33, 17280, 135, 33, 33, 33, 33, 33, 17280, 135, 33, 17280, 33, 17280, 33, 33, 135, 135, 17280, 135, 17280, 33, 135, 33, 17280, 17280, 33, 17280, 135, 33, 17280, 33, 33, 17280, 17280, 135, 17280, 17280, 33, 17280, 135, 135, 33, 135, 17280, 17280, 33, 17280, 135, 33, 135, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 135, 17280, 17280, 135, 33, 17280, 33, 135, 135, 33, 135, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 135, 17280, 135, 33, 135, 17280, 135, 17280, 33, 17280, 33, 135, 17280, 135, 17280, 135, 17280, 135, 17280, 135, 33, 17280, 33, 17280, 135, 135, 33, 135, 17280, 135, 135, 17280, 33, 17280, 17280, 135, 33, 17280, 17280, 135, 135, 17280, 17280, 135, 135, 135, 135, 17280, 17280, 135, 135, 17280, 33, 17280, 135, 17280, 17280, 33, 17280, 135, 135, 17280, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 17280, 135, 33, 33, 33, 33]
Prompts retrieved: 1500360 . Total input tokens: 334451225 . Total output tokens: 299936524
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.849594046827406,
    "estimated_duration": 3600.0092931969966,
    "input_throughput": 4379.691194074153,
    "output_throughput": 3871.473061566159,
    "total_throughput": 8251.164255640311,
    "itl": 87.33281478289884,
    "ttft": 2145495.172092304,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 289,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9456774562224795,
    "arrivals": 500381,
    "finished_requests": 63373,
    "scheduler_time": 73.56146247022383
}
#Debug simulation 
Total elapsed time: 4.8497137748636305. Arrivals time: 0.22574122622609138 Scheduler time: 4.439979575108737 Scheduler overhead time: 0.0569584327749908 Adapter cache time: 0.04204137856140733 Engine time: 0.05839494429528713 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-16-16/adapters_256_slots_192_rate_1.6-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-16-16/adapters_256_slots_192_rate_1.6-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 17280, 33, 17280, 17280, 33, 17280, 135, 17280, 33, 135, 33, 17280, 135, 135, 135, 135, 17280, 33, 33, 33, 135, 17280, 33, 17280, 17280, 135, 135, 135, 33, 17280, 33, 135, 135, 33, 135, 33, 33, 135, 135, 17280, 135, 33, 135, 17280, 135, 135, 17280, 135, 17280, 33, 17280, 17280, 135, 33, 33, 17280, 135, 33, 135, 135, 17280, 135, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 17280, 17280, 33, 17280, 33, 135, 17280, 17280, 17280, 135, 33, 17280, 135, 33, 33, 33, 33, 33, 17280, 135, 33, 17280, 33, 17280, 33, 33, 135, 135, 17280, 135, 17280, 33, 135, 33, 17280, 17280, 33, 17280, 135, 33, 17280, 33, 33, 17280, 17280, 135, 17280, 17280, 33, 17280, 135, 135, 33, 135, 17280, 17280, 33, 17280, 135, 33, 135, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 135, 17280, 17280, 135, 33, 17280, 33, 135, 135, 33, 135, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 135, 17280, 135, 33, 135, 17280, 135, 17280, 33, 17280, 33, 135, 17280, 135, 17280, 135, 17280, 135, 17280, 135, 33, 17280, 33, 17280, 135, 135, 33, 135, 17280, 135, 135, 17280, 33, 17280, 17280, 135, 33, 17280, 17280, 135, 135, 17280, 17280, 135, 135, 135, 135, 17280, 17280, 135, 135, 17280, 33, 17280, 135, 17280, 17280, 33, 17280, 135, 135, 17280, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 17280, 135, 33, 33, 33, 33]
Prompts retrieved: 1500360 . Total input tokens: 334451225 . Total output tokens: 299936524
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 5.701878328341991,
    "estimated_duration": 3600.177314753007,
    "input_throughput": 5432.876297466999,
    "output_throughput": 4794.835779132809,
    "total_throughput": 10227.712076599808,
    "itl": 177.12803879694397,
    "ttft": 2011491.0436872728,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 322,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.009376061260704,
    "arrivals": 500381,
    "finished_requests": 78784,
    "scheduler_time": 78.7911096474679
}
#Debug simulation 
Total elapsed time: 5.7019815081730485. Arrivals time: 0.2655981173738837 Scheduler time: 5.337711913511157 Scheduler overhead time: 0.031380931846797466 Adapter cache time: 0.02036789432168007 Engine time: 0.03237362951040268 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-16-32/adapters_256_slots_192_rate_1.6-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-16-32/adapters_256_slots_192_rate_1.6-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 17280, 33, 17280, 17280, 33, 17280, 135, 17280, 33, 135, 33, 17280, 135, 135, 135, 135, 17280, 33, 33, 33, 135, 17280, 33, 17280, 17280, 135, 135, 135, 33, 17280, 33, 135, 135, 33, 135, 33, 33, 135, 135, 17280, 135, 33, 135, 17280, 135, 135, 17280, 135, 17280, 33, 17280, 17280, 135, 33, 33, 17280, 135, 33, 135, 135, 17280, 135, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 17280, 17280, 33, 17280, 33, 135, 17280, 17280, 17280, 135, 33, 17280, 135, 33, 33, 33, 33, 33, 17280, 135, 33, 17280, 33, 17280, 33, 33, 135, 135, 17280, 135, 17280, 33, 135, 33, 17280, 17280, 33, 17280, 135, 33, 17280, 33, 33, 17280, 17280, 135, 17280, 17280, 33, 17280, 135, 135, 33, 135, 17280, 17280, 33, 17280, 135, 33, 135, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 135, 17280, 17280, 135, 33, 17280, 33, 135, 135, 33, 135, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 135, 17280, 135, 33, 135, 17280, 135, 17280, 33, 17280, 33, 135, 17280, 135, 17280, 135, 17280, 135, 17280, 135, 33, 17280, 33, 17280, 135, 135, 33, 135, 17280, 135, 135, 17280, 33, 17280, 17280, 135, 33, 17280, 17280, 135, 135, 17280, 17280, 135, 135, 135, 135, 17280, 17280, 135, 135, 17280, 33, 17280, 135, 17280, 17280, 33, 17280, 135, 135, 17280, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 17280, 135, 33, 33, 33, 33]
Prompts retrieved: 1500360 . Total input tokens: 334451225 . Total output tokens: 299936524
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 4.91538904607296,
    "estimated_duration": 3600.0403168210196,
    "input_throughput": 4379.695117948836,
    "output_throughput": 3871.583586127082,
    "total_throughput": 8251.278704075918,
    "itl": 87.33201839293726,
    "ttft": 2145535.487083556,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 289,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9577498197183062,
    "arrivals": 500381,
    "finished_requests": 63374,
    "scheduler_time": 73.56270508787959
}
#Debug simulation 
Total elapsed time: 4.915498027112335. Arrivals time: 0.26185379922389984 Scheduler time: 4.468489868566394 Scheduler overhead time: 0.05725518288090825 Adapter cache time: 0.04225650057196617 Engine time: 0.05876801582053304 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_16-16-16/adapters_256_slots_192_rate_1.6-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_16-16-16/adapters_256_slots_192_rate_1.6-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 17280, 33, 17280, 17280, 33, 17280, 135, 17280, 33, 135, 33, 17280, 135, 135, 135, 135, 17280, 33, 33, 33, 135, 17280, 33, 17280, 17280, 135, 135, 135, 33, 17280, 33, 135, 135, 33, 135, 33, 33, 135, 135, 17280, 135, 33, 135, 17280, 135, 135, 17280, 135, 17280, 33, 17280, 17280, 135, 33, 33, 17280, 135, 33, 135, 135, 17280, 135, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 17280, 17280, 33, 17280, 33, 135, 17280, 17280, 17280, 135, 33, 17280, 135, 33, 33, 33, 33, 33, 17280, 135, 33, 17280, 33, 17280, 33, 33, 135, 135, 17280, 135, 17280, 33, 135, 33, 17280, 17280, 33, 17280, 135, 33, 17280, 33, 33, 17280, 17280, 135, 17280, 17280, 33, 17280, 135, 135, 33, 135, 17280, 17280, 33, 17280, 135, 33, 135, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 135, 17280, 17280, 135, 33, 17280, 33, 135, 135, 33, 135, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 135, 17280, 135, 33, 135, 17280, 135, 17280, 33, 17280, 33, 135, 17280, 135, 17280, 135, 17280, 135, 17280, 135, 33, 17280, 33, 17280, 135, 135, 33, 135, 17280, 135, 135, 17280, 33, 17280, 17280, 135, 33, 17280, 17280, 135, 135, 17280, 17280, 135, 135, 135, 135, 17280, 17280, 135, 135, 17280, 33, 17280, 135, 17280, 17280, 33, 17280, 135, 135, 17280, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 17280, 135, 33, 33, 33, 33]
Prompts retrieved: 1500360 . Total input tokens: 334451225 . Total output tokens: 299936524
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.676305790897459,
    "estimated_duration": 3600.1201783412016,
    "input_throughput": 5432.962520993449,
    "output_throughput": 4794.911876512354,
    "total_throughput": 10227.874397505802,
    "itl": 177.12704749674936,
    "ttft": 2011460.3951494878,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 322,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9627961949585019,
    "arrivals": 500381,
    "finished_requests": 78784,
    "scheduler_time": 78.79089980982859
}
#Debug simulation 
Total elapsed time: 5.676404127851129. Arrivals time: 0.26833278965204954 Scheduler time: 5.309564157389104 Scheduler overhead time: 0.031461157370358706 Adapter cache time: 0.020246353931725025 Engine time: 0.032220425084233284 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_16-16-32/adapters_256_slots_192_rate_1.6-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_16-16-32/adapters_256_slots_192_rate_1.6-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 17280, 33, 17280, 17280, 33, 17280, 135, 17280, 33, 135, 33, 17280, 135, 135, 135, 135, 17280, 33, 33, 33, 135, 17280, 33, 17280, 17280, 135, 135, 135, 33, 17280, 33, 135, 135, 33, 135, 33, 33, 135, 135, 17280, 135, 33, 135, 17280, 135, 135, 17280, 135, 17280, 33, 17280, 17280, 135, 33, 33, 17280, 135, 33, 135, 135, 17280, 135, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 17280, 17280, 33, 17280, 33, 135, 17280, 17280, 17280, 135, 33, 17280, 135, 33, 33, 33, 33, 33, 17280, 135, 33, 17280, 33, 17280, 33, 33, 135, 135, 17280, 135, 17280, 33, 135, 33, 17280, 17280, 33, 17280, 135, 33, 17280, 33, 33, 17280, 17280, 135, 17280, 17280, 33, 17280, 135, 135, 33, 135, 17280, 17280, 33, 17280, 135, 33, 135, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 135, 17280, 17280, 135, 33, 17280, 33, 135, 135, 33, 135, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 135, 17280, 135, 33, 135, 17280, 135, 17280, 33, 17280, 33, 135, 17280, 135, 17280, 135, 17280, 135, 17280, 135, 33, 17280, 33, 17280, 135, 135, 33, 135, 17280, 135, 135, 17280, 33, 17280, 17280, 135, 33, 17280, 17280, 135, 135, 17280, 17280, 135, 135, 135, 135, 17280, 17280, 135, 135, 17280, 33, 17280, 135, 17280, 17280, 33, 17280, 135, 135, 17280, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 17280, 135, 33, 33, 33, 33]
Prompts retrieved: 1500360 . Total input tokens: 334451225 . Total output tokens: 299936524
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.857482781168073,
    "estimated_duration": 3600.0005493566014,
    "input_throughput": 4379.686553886188,
    "output_throughput": 3871.502186990199,
    "total_throughput": 8251.188740876389,
    "itl": 87.33219512173349,
    "ttft": 2145485.719270937,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 289,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9703251983597926,
    "arrivals": 500381,
    "finished_requests": 63375,
    "scheduler_time": 73.55995333258207
}
#Debug simulation 
Total elapsed time: 4.857580308336765. Arrivals time: 0.22882165107876062 Scheduler time: 4.445194116793573 Scheduler overhead time: 0.056970889680087566 Adapter cache time: 0.04168654140084982 Engine time: 0.058358384761959314 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-8/adapters_256_slots_192_rate_1.6-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-8/adapters_256_slots_192_rate_1.6-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 17280, 33, 17280, 17280, 33, 17280, 66, 17280, 33, 66, 33, 17280, 66, 66, 66, 66, 17280, 33, 33, 33, 66, 17280, 33, 17280, 17280, 66, 66, 66, 33, 17280, 33, 66, 66, 33, 66, 33, 33, 66, 66, 17280, 66, 33, 66, 17280, 66, 66, 17280, 66, 17280, 33, 17280, 17280, 66, 33, 33, 17280, 66, 33, 66, 66, 17280, 66, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 17280, 17280, 33, 17280, 33, 66, 17280, 17280, 17280, 66, 33, 17280, 66, 33, 33, 33, 33, 33, 17280, 66, 33, 17280, 33, 17280, 33, 33, 66, 66, 17280, 66, 17280, 33, 66, 33, 17280, 17280, 33, 17280, 66, 33, 17280, 33, 33, 17280, 17280, 66, 17280, 17280, 33, 17280, 66, 66, 33, 66, 17280, 17280, 33, 17280, 66, 33, 66, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 66, 17280, 17280, 66, 33, 17280, 33, 66, 66, 33, 66, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 66, 17280, 66, 33, 66, 17280, 66, 17280, 33, 17280, 33, 66, 17280, 66, 17280, 66, 17280, 66, 17280, 66, 33, 17280, 33, 17280, 66, 66, 33, 66, 17280, 66, 66, 17280, 33, 17280, 17280, 66, 33, 17280, 17280, 66, 66, 17280, 17280, 66, 66, 66, 66, 17280, 17280, 66, 66, 17280, 33, 17280, 66, 17280, 17280, 33, 17280, 66, 66, 17280, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 17280, 66, 33, 33, 33, 33]
Prompts retrieved: 1494495 . Total input tokens: 333126301 . Total output tokens: 298768414
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.794876809697598,
    "estimated_duration": 3600.096743083108,
    "input_throughput": 5533.70101463968,
    "output_throughput": 4887.630598762996,
    "total_throughput": 10421.331613402675,
    "itl": 175.98485713778715,
    "ttft": 1997115.462489266,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 286,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8752994947647664,
    "arrivals": 498436,
    "finished_requests": 80640,
    "scheduler_time": 80.13991926046917
}
#Debug simulation 
Total elapsed time: 5.794977329671383. Arrivals time: 0.26871929690241814 Scheduler time: 5.431926271878183 Scheduler overhead time: 0.031602414790540934 Adapter cache time: 0.015724264550954103 Engine time: 0.03232128079980612 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-16/adapters_256_slots_192_rate_1.6-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-16/adapters_256_slots_192_rate_1.6-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 17280, 33, 17280, 17280, 33, 17280, 66, 17280, 33, 66, 33, 17280, 66, 66, 66, 66, 17280, 33, 33, 33, 66, 17280, 33, 17280, 17280, 66, 66, 66, 33, 17280, 33, 66, 66, 33, 66, 33, 33, 66, 66, 17280, 66, 33, 66, 17280, 66, 66, 17280, 66, 17280, 33, 17280, 17280, 66, 33, 33, 17280, 66, 33, 66, 66, 17280, 66, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 17280, 17280, 33, 17280, 33, 66, 17280, 17280, 17280, 66, 33, 17280, 66, 33, 33, 33, 33, 33, 17280, 66, 33, 17280, 33, 17280, 33, 33, 66, 66, 17280, 66, 17280, 33, 66, 33, 17280, 17280, 33, 17280, 66, 33, 17280, 33, 33, 17280, 17280, 66, 17280, 17280, 33, 17280, 66, 66, 33, 66, 17280, 17280, 33, 17280, 66, 33, 66, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 66, 17280, 17280, 66, 33, 17280, 33, 66, 66, 33, 66, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 66, 17280, 66, 33, 66, 17280, 66, 17280, 33, 17280, 33, 66, 17280, 66, 17280, 66, 17280, 66, 17280, 66, 33, 17280, 33, 17280, 66, 66, 33, 66, 17280, 66, 66, 17280, 33, 17280, 17280, 66, 33, 17280, 17280, 66, 66, 17280, 17280, 66, 66, 66, 66, 17280, 17280, 66, 66, 17280, 33, 17280, 66, 17280, 17280, 33, 17280, 66, 66, 17280, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 17280, 66, 33, 33, 33, 33]
Prompts retrieved: 1494495 . Total input tokens: 333126301 . Total output tokens: 298768414
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.7491148468106985,
    "estimated_duration": 3600.1669709638504,
    "input_throughput": 5519.413171739674,
    "output_throughput": 4876.202448826997,
    "total_throughput": 10395.61562056667,
    "itl": 174.0233241884249,
    "ttft": 1998501.7204193526,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 286,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.933604685482574,
    "arrivals": 498436,
    "finished_requests": 80440,
    "scheduler_time": 80.08001212104458
}
#Debug simulation 
Total elapsed time: 5.749217679724097. Arrivals time: 0.26997908391058445 Scheduler time: 5.383837109431624 Scheduler overhead time: 0.03216554410755634 Adapter cache time: 0.01579555729404092 Engine time: 0.03265316318720579 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-32/adapters_256_slots_192_rate_1.6-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-32/adapters_256_slots_192_rate_1.6-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 17280, 33, 17280, 17280, 33, 17280, 66, 17280, 33, 66, 33, 17280, 66, 66, 66, 66, 17280, 33, 33, 33, 66, 17280, 33, 17280, 17280, 66, 66, 66, 33, 17280, 33, 66, 66, 33, 66, 33, 33, 66, 66, 17280, 66, 33, 66, 17280, 66, 66, 17280, 66, 17280, 33, 17280, 17280, 66, 33, 33, 17280, 66, 33, 66, 66, 17280, 66, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 17280, 17280, 33, 17280, 33, 66, 17280, 17280, 17280, 66, 33, 17280, 66, 33, 33, 33, 33, 33, 17280, 66, 33, 17280, 33, 17280, 33, 33, 66, 66, 17280, 66, 17280, 33, 66, 33, 17280, 17280, 33, 17280, 66, 33, 17280, 33, 33, 17280, 17280, 66, 17280, 17280, 33, 17280, 66, 66, 33, 66, 17280, 17280, 33, 17280, 66, 33, 66, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 66, 17280, 17280, 66, 33, 17280, 33, 66, 66, 33, 66, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 66, 17280, 66, 33, 66, 17280, 66, 17280, 33, 17280, 33, 66, 17280, 66, 17280, 66, 17280, 66, 17280, 66, 33, 17280, 33, 17280, 66, 66, 33, 66, 17280, 66, 66, 17280, 33, 17280, 17280, 66, 33, 17280, 17280, 66, 66, 17280, 17280, 66, 66, 66, 66, 17280, 17280, 66, 66, 17280, 33, 17280, 66, 17280, 17280, 33, 17280, 66, 66, 17280, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 17280, 66, 33, 33, 33, 33]
Prompts retrieved: 1494495 . Total input tokens: 333126301 . Total output tokens: 298768414
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.874133464880288,
    "estimated_duration": 3600.0778601022316,
    "input_throughput": 4392.842770225784,
    "output_throughput": 3901.848944900627,
    "total_throughput": 8294.691715126412,
    "itl": 86.73735689071935,
    "ttft": 2138861.1415024134,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 255,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8337666280008893,
    "arrivals": 498436,
    "finished_requests": 64083,
    "scheduler_time": 74.0806606709443
}
#Debug simulation 
Total elapsed time: 4.874234377872199. Arrivals time: 0.22795094083994627 Scheduler time: 4.4679663218557835 Scheduler overhead time: 0.057217177003622055 Adapter cache time: 0.03596021141856909 Engine time: 0.058567436411976814 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-16-16/adapters_256_slots_192_rate_1.6-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-16-16/adapters_256_slots_192_rate_1.6-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 17280, 33, 17280, 17280, 33, 17280, 66, 17280, 33, 66, 33, 17280, 66, 66, 66, 66, 17280, 33, 33, 33, 66, 17280, 33, 17280, 17280, 66, 66, 66, 33, 17280, 33, 66, 66, 33, 66, 33, 33, 66, 66, 17280, 66, 33, 66, 17280, 66, 66, 17280, 66, 17280, 33, 17280, 17280, 66, 33, 33, 17280, 66, 33, 66, 66, 17280, 66, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 17280, 17280, 33, 17280, 33, 66, 17280, 17280, 17280, 66, 33, 17280, 66, 33, 33, 33, 33, 33, 17280, 66, 33, 17280, 33, 17280, 33, 33, 66, 66, 17280, 66, 17280, 33, 66, 33, 17280, 17280, 33, 17280, 66, 33, 17280, 33, 33, 17280, 17280, 66, 17280, 17280, 33, 17280, 66, 66, 33, 66, 17280, 17280, 33, 17280, 66, 33, 66, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 66, 17280, 17280, 66, 33, 17280, 33, 66, 66, 33, 66, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 66, 17280, 66, 33, 66, 17280, 66, 17280, 33, 17280, 33, 66, 17280, 66, 17280, 66, 17280, 66, 17280, 66, 33, 17280, 33, 17280, 66, 66, 33, 66, 17280, 66, 66, 17280, 33, 17280, 17280, 66, 33, 17280, 17280, 66, 66, 17280, 17280, 66, 66, 66, 66, 17280, 17280, 66, 66, 17280, 33, 17280, 66, 17280, 17280, 33, 17280, 66, 66, 17280, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 17280, 66, 33, 33, 33, 33]
Prompts retrieved: 1494495 . Total input tokens: 333126301 . Total output tokens: 298768414
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 5.772525867912918,
    "estimated_duration": 3600.115984820615,
    "input_throughput": 5519.491339663079,
    "output_throughput": 4876.271507367764,
    "total_throughput": 10395.762847030843,
    "itl": 174.025025827729,
    "ttft": 1998473.577135432,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 286,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8947881302307392,
    "arrivals": 498436,
    "finished_requests": 80440,
    "scheduler_time": 80.07965710151436
}
#Debug simulation 
Total elapsed time: 5.772621502168477. Arrivals time: 0.2675745910964906 Scheduler time: 5.409867951646447 Scheduler overhead time: 0.03187913401052356 Adapter cache time: 0.015843294095247984 Engine time: 0.03266279213130474 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-16-32/adapters_256_slots_192_rate_1.6-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-16-32/adapters_256_slots_192_rate_1.6-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 17280, 33, 17280, 17280, 33, 17280, 66, 17280, 33, 66, 33, 17280, 66, 66, 66, 66, 17280, 33, 33, 33, 66, 17280, 33, 17280, 17280, 66, 66, 66, 33, 17280, 33, 66, 66, 33, 66, 33, 33, 66, 66, 17280, 66, 33, 66, 17280, 66, 66, 17280, 66, 17280, 33, 17280, 17280, 66, 33, 33, 17280, 66, 33, 66, 66, 17280, 66, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 17280, 17280, 33, 17280, 33, 66, 17280, 17280, 17280, 66, 33, 17280, 66, 33, 33, 33, 33, 33, 17280, 66, 33, 17280, 33, 17280, 33, 33, 66, 66, 17280, 66, 17280, 33, 66, 33, 17280, 17280, 33, 17280, 66, 33, 17280, 33, 33, 17280, 17280, 66, 17280, 17280, 33, 17280, 66, 66, 33, 66, 17280, 17280, 33, 17280, 66, 33, 66, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 66, 17280, 17280, 66, 33, 17280, 33, 66, 66, 33, 66, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 66, 17280, 66, 33, 66, 17280, 66, 17280, 33, 17280, 33, 66, 17280, 66, 17280, 66, 17280, 66, 17280, 66, 33, 17280, 33, 17280, 66, 66, 33, 66, 17280, 66, 66, 17280, 33, 17280, 17280, 66, 33, 17280, 17280, 66, 66, 17280, 17280, 66, 66, 66, 66, 17280, 17280, 66, 66, 17280, 33, 17280, 66, 17280, 17280, 33, 17280, 66, 66, 17280, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 17280, 66, 33, 33, 33, 33]
Prompts retrieved: 1494495 . Total input tokens: 333126301 . Total output tokens: 298768414
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 4.8526195590384305,
    "estimated_duration": 3600.0371378452724,
    "input_throughput": 4390.812481857063,
    "output_throughput": 3900.743648551648,
    "total_throughput": 8291.556130408711,
    "itl": 86.70816348807045,
    "ttft": 2138779.697235987,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 254,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8410749335028269,
    "arrivals": 498436,
    "finished_requests": 64055,
    "scheduler_time": 74.06689633889337
}
#Debug simulation 
Total elapsed time: 4.852715749293566. Arrivals time: 0.22885676380246878 Scheduler time: 4.446616874542087 Scheduler overhead time: 0.05712966341525316 Adapter cache time: 0.03502969676628709 Engine time: 0.05853292066603899 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_16-16-16/adapters_256_slots_192_rate_1.6-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_16-16-16/adapters_256_slots_192_rate_1.6-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 17280, 33, 17280, 17280, 33, 17280, 66, 17280, 33, 66, 33, 17280, 66, 66, 66, 66, 17280, 33, 33, 33, 66, 17280, 33, 17280, 17280, 66, 66, 66, 33, 17280, 33, 66, 66, 33, 66, 33, 33, 66, 66, 17280, 66, 33, 66, 17280, 66, 66, 17280, 66, 17280, 33, 17280, 17280, 66, 33, 33, 17280, 66, 33, 66, 66, 17280, 66, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 17280, 17280, 33, 17280, 33, 66, 17280, 17280, 17280, 66, 33, 17280, 66, 33, 33, 33, 33, 33, 17280, 66, 33, 17280, 33, 17280, 33, 33, 66, 66, 17280, 66, 17280, 33, 66, 33, 17280, 17280, 33, 17280, 66, 33, 17280, 33, 33, 17280, 17280, 66, 17280, 17280, 33, 17280, 66, 66, 33, 66, 17280, 17280, 33, 17280, 66, 33, 66, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 66, 17280, 17280, 66, 33, 17280, 33, 66, 66, 33, 66, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 66, 17280, 66, 33, 66, 17280, 66, 17280, 33, 17280, 33, 66, 17280, 66, 17280, 66, 17280, 66, 17280, 66, 33, 17280, 33, 17280, 66, 66, 33, 66, 17280, 66, 66, 17280, 33, 17280, 17280, 66, 33, 17280, 17280, 66, 66, 17280, 17280, 66, 66, 66, 66, 17280, 17280, 66, 66, 17280, 33, 17280, 66, 17280, 17280, 33, 17280, 66, 66, 17280, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 17280, 66, 33, 33, 33, 33]
Prompts retrieved: 1494495 . Total input tokens: 333126301 . Total output tokens: 298768414
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.707182627171278,
    "estimated_duration": 3600.105134377291,
    "input_throughput": 5519.507974990583,
    "output_throughput": 4876.286204079567,
    "total_throughput": 10395.79417907015,
    "itl": 174.01637937009298,
    "ttft": 1998471.292609749,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 286,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8551543843420234,
    "arrivals": 498436,
    "finished_requests": 80440,
    "scheduler_time": 80.08007616937336
}
#Debug simulation 
Total elapsed time: 5.707280089147389. Arrivals time: 0.25084603065624833 Scheduler time: 5.362729439511895 Scheduler overhead time: 0.03188525838777423 Adapter cache time: 0.015100873075425625 Engine time: 0.03201696090400219 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_16-16-32/adapters_256_slots_192_rate_1.6-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_16-16-32/adapters_256_slots_192_rate_1.6-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 17280, 33, 17280, 17280, 33, 17280, 66, 17280, 33, 66, 33, 17280, 66, 66, 66, 66, 17280, 33, 33, 33, 66, 17280, 33, 17280, 17280, 66, 66, 66, 33, 17280, 33, 66, 66, 33, 66, 33, 33, 66, 66, 17280, 66, 33, 66, 17280, 66, 66, 17280, 66, 17280, 33, 17280, 17280, 66, 33, 33, 17280, 66, 33, 66, 66, 17280, 66, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 17280, 17280, 33, 17280, 33, 66, 17280, 17280, 17280, 66, 33, 17280, 66, 33, 33, 33, 33, 33, 17280, 66, 33, 17280, 33, 17280, 33, 33, 66, 66, 17280, 66, 17280, 33, 66, 33, 17280, 17280, 33, 17280, 66, 33, 17280, 33, 33, 17280, 17280, 66, 17280, 17280, 33, 17280, 66, 66, 33, 66, 17280, 17280, 33, 17280, 66, 33, 66, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 66, 17280, 17280, 66, 33, 17280, 33, 66, 66, 33, 66, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 66, 17280, 66, 33, 66, 17280, 66, 17280, 33, 17280, 33, 66, 17280, 66, 17280, 66, 17280, 66, 17280, 66, 33, 17280, 33, 17280, 66, 66, 33, 66, 17280, 66, 66, 17280, 33, 17280, 17280, 66, 33, 17280, 17280, 66, 66, 17280, 17280, 66, 66, 66, 66, 17280, 17280, 66, 66, 17280, 33, 17280, 66, 17280, 17280, 33, 17280, 66, 66, 17280, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 17280, 66, 33, 33, 33, 33]
Prompts retrieved: 1494495 . Total input tokens: 333126301 . Total output tokens: 298768414
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.867472962941974,
    "estimated_duration": 3600.0478557858496,
    "input_throughput": 4390.799409678817,
    "output_throughput": 3900.732035389738,
    "total_throughput": 8291.531445068555,
    "itl": 86.70840128332964,
    "ttft": 2138785.1349362014,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 254,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8517640053480902,
    "arrivals": 498436,
    "finished_requests": 64055,
    "scheduler_time": 74.06692520763069
}
#Debug simulation 
Total elapsed time: 4.867567869834602. Arrivals time: 0.21513435197994113 Scheduler time: 4.474802260752767 Scheduler overhead time: 0.05717318598181009 Adapter cache time: 0.034354112576693296 Engine time: 0.0592360645532608 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-8-8/adapters_256_slots_192_rate_0.8-0.4-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-8-8/adapters_256_slots_192_rate_0.8-0.4-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 1080, 8640, 8640, 1080, 8640, 4320, 8640, 1080, 4320, 1080, 8640, 4320, 4320, 4320, 4320, 8640, 1080, 1080, 1080, 4320, 8640, 1080, 8640, 8640, 4320, 4320, 4320, 1080, 8640, 1080, 4320, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 8640, 4320, 1080, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 1080, 8640, 8640, 4320, 1080, 1080, 8640, 4320, 1080, 4320, 4320, 8640, 4320, 1080, 1080, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 4320, 1080, 4320, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 8640, 8640, 1080, 8640, 1080, 4320, 8640, 8640, 8640, 4320, 1080, 8640, 4320, 1080, 1080, 1080, 1080, 1080, 8640, 4320, 1080, 8640, 1080, 8640, 1080, 1080, 4320, 4320, 8640, 4320, 8640, 1080, 4320, 1080, 8640, 8640, 1080, 8640, 4320, 1080, 8640, 1080, 1080, 8640, 8640, 4320, 8640, 8640, 1080, 8640, 4320, 4320, 1080, 4320, 8640, 8640, 1080, 8640, 4320, 1080, 4320, 8640, 1080, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 1080, 1080, 8640, 1080, 4320, 8640, 8640, 4320, 1080, 8640, 1080, 4320, 4320, 1080, 4320, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 8640, 4320, 8640, 4320, 1080, 4320, 8640, 4320, 8640, 1080, 8640, 1080, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 1080, 8640, 1080, 8640, 4320, 4320, 1080, 4320, 8640, 4320, 4320, 8640, 1080, 8640, 8640, 4320, 1080, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 1080, 8640, 4320, 8640, 8640, 1080, 8640, 4320, 4320, 8640, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 1080, 1080, 1080, 1080]
Prompts retrieved: 1202040 . Total input tokens: 267960373 . Total output tokens: 240348610
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.492326558101922,
    "estimated_duration": 3600.0715867111903,
    "input_throughput": 3714.939738800508,
    "output_throughput": 3238.8889273871605,
    "total_throughput": 6953.828666187668,
    "itl": 262.1826505705834,
    "ttft": 2196484.055447517,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1371,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.195928696931915,
    "arrivals": 401058,
    "finished_requests": 53622,
    "scheduler_time": 53.3443776947769
}
#Debug simulation 
Total elapsed time: 4.492426041979343. Arrivals time: 0.19400412077084184 Scheduler time: 4.207535638008267 Scheduler overhead time: 0.02263065706938505 Adapter cache time: 0.03593774512410164 Engine time: 0.022078492678701878 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-8-16/adapters_256_slots_192_rate_0.8-0.4-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-8-16/adapters_256_slots_192_rate_0.8-0.4-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 1080, 8640, 8640, 1080, 8640, 4320, 8640, 1080, 4320, 1080, 8640, 4320, 4320, 4320, 4320, 8640, 1080, 1080, 1080, 4320, 8640, 1080, 8640, 8640, 4320, 4320, 4320, 1080, 8640, 1080, 4320, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 8640, 4320, 1080, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 1080, 8640, 8640, 4320, 1080, 1080, 8640, 4320, 1080, 4320, 4320, 8640, 4320, 1080, 1080, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 4320, 1080, 4320, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 8640, 8640, 1080, 8640, 1080, 4320, 8640, 8640, 8640, 4320, 1080, 8640, 4320, 1080, 1080, 1080, 1080, 1080, 8640, 4320, 1080, 8640, 1080, 8640, 1080, 1080, 4320, 4320, 8640, 4320, 8640, 1080, 4320, 1080, 8640, 8640, 1080, 8640, 4320, 1080, 8640, 1080, 1080, 8640, 8640, 4320, 8640, 8640, 1080, 8640, 4320, 4320, 1080, 4320, 8640, 8640, 1080, 8640, 4320, 1080, 4320, 8640, 1080, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 1080, 1080, 8640, 1080, 4320, 8640, 8640, 4320, 1080, 8640, 1080, 4320, 4320, 1080, 4320, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 8640, 4320, 8640, 4320, 1080, 4320, 8640, 4320, 8640, 1080, 8640, 1080, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 1080, 8640, 1080, 8640, 4320, 4320, 1080, 4320, 8640, 4320, 4320, 8640, 1080, 8640, 8640, 4320, 1080, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 1080, 8640, 4320, 8640, 8640, 1080, 8640, 4320, 4320, 8640, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 1080, 1080, 1080, 1080]
Prompts retrieved: 1202040 . Total input tokens: 267960373 . Total output tokens: 240348610
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.5076179201714694,
    "estimated_duration": 3600.1892941517103,
    "input_throughput": 3705.290725037601,
    "output_throughput": 3231.1784324498904,
    "total_throughput": 6936.469157487491,
    "itl": 259.13719907497824,
    "ttft": 2198491.2394843297,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1393,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.5390047771716056,
    "arrivals": 401058,
    "finished_requests": 53488,
    "scheduler_time": 53.28039152634329
}
#Debug simulation 
Total elapsed time: 4.507746362127364. Arrivals time: 0.19455710984766483 Scheduler time: 4.220568480435759 Scheduler overhead time: 0.022807275876402855 Adapter cache time: 0.03693607496097684 Engine time: 0.02246062085032463 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-8-32/adapters_256_slots_192_rate_0.8-0.4-0.1_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-8-32/adapters_256_slots_192_rate_0.8-0.4-0.1_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 1080, 8640, 8640, 1080, 8640, 4320, 8640, 1080, 4320, 1080, 8640, 4320, 4320, 4320, 4320, 8640, 1080, 1080, 1080, 4320, 8640, 1080, 8640, 8640, 4320, 4320, 4320, 1080, 8640, 1080, 4320, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 8640, 4320, 1080, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 1080, 8640, 8640, 4320, 1080, 1080, 8640, 4320, 1080, 4320, 4320, 8640, 4320, 1080, 1080, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 4320, 1080, 4320, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 8640, 8640, 1080, 8640, 1080, 4320, 8640, 8640, 8640, 4320, 1080, 8640, 4320, 1080, 1080, 1080, 1080, 1080, 8640, 4320, 1080, 8640, 1080, 8640, 1080, 1080, 4320, 4320, 8640, 4320, 8640, 1080, 4320, 1080, 8640, 8640, 1080, 8640, 4320, 1080, 8640, 1080, 1080, 8640, 8640, 4320, 8640, 8640, 1080, 8640, 4320, 4320, 1080, 4320, 8640, 8640, 1080, 8640, 4320, 1080, 4320, 8640, 1080, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 1080, 1080, 8640, 1080, 4320, 8640, 8640, 4320, 1080, 8640, 1080, 4320, 4320, 1080, 4320, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 8640, 4320, 8640, 4320, 1080, 4320, 8640, 4320, 8640, 1080, 8640, 1080, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 1080, 8640, 1080, 8640, 4320, 4320, 1080, 4320, 8640, 4320, 4320, 8640, 1080, 8640, 8640, 4320, 1080, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 1080, 8640, 4320, 8640, 8640, 1080, 8640, 4320, 4320, 8640, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 1080, 1080, 1080, 1080]
Prompts retrieved: 1202040 . Total input tokens: 267960373 . Total output tokens: 240348610
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 3.6901972531341016,
    "estimated_duration": 3600.13841921111,
    "input_throughput": 3141.059226961043,
    "output_throughput": 2746.492731289671,
    "total_throughput": 5887.551958250714,
    "itl": 122.10779962991775,
    "ttft": 2310476.9705580776,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4727,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.442972750997706,
    "arrivals": 401058,
    "finished_requests": 45248,
    "scheduler_time": 52.23295090664837
}
#Debug simulation 
Total elapsed time: 3.690295248758048. Arrivals time: 0.1767235454171896 Scheduler time: 3.2190946768969297 Scheduler overhead time: 0.041658883448690176 Adapter cache time: 0.19090192997828126 Engine time: 0.042338660918176174 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-16-16/adapters_256_slots_192_rate_0.8-0.4-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-16-16/adapters_256_slots_192_rate_0.8-0.4-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 1080, 8640, 8640, 1080, 8640, 4320, 8640, 1080, 4320, 1080, 8640, 4320, 4320, 4320, 4320, 8640, 1080, 1080, 1080, 4320, 8640, 1080, 8640, 8640, 4320, 4320, 4320, 1080, 8640, 1080, 4320, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 8640, 4320, 1080, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 1080, 8640, 8640, 4320, 1080, 1080, 8640, 4320, 1080, 4320, 4320, 8640, 4320, 1080, 1080, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 4320, 1080, 4320, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 8640, 8640, 1080, 8640, 1080, 4320, 8640, 8640, 8640, 4320, 1080, 8640, 4320, 1080, 1080, 1080, 1080, 1080, 8640, 4320, 1080, 8640, 1080, 8640, 1080, 1080, 4320, 4320, 8640, 4320, 8640, 1080, 4320, 1080, 8640, 8640, 1080, 8640, 4320, 1080, 8640, 1080, 1080, 8640, 8640, 4320, 8640, 8640, 1080, 8640, 4320, 4320, 1080, 4320, 8640, 8640, 1080, 8640, 4320, 1080, 4320, 8640, 1080, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 1080, 1080, 8640, 1080, 4320, 8640, 8640, 4320, 1080, 8640, 1080, 4320, 4320, 1080, 4320, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 8640, 4320, 8640, 4320, 1080, 4320, 8640, 4320, 8640, 1080, 8640, 1080, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 1080, 8640, 1080, 8640, 4320, 4320, 1080, 4320, 8640, 4320, 4320, 8640, 1080, 8640, 8640, 4320, 1080, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 1080, 8640, 4320, 8640, 8640, 1080, 8640, 4320, 4320, 8640, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 1080, 1080, 1080, 1080]
Prompts retrieved: 1202040 . Total input tokens: 267960373 . Total output tokens: 240348610
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 4.467577125877142,
    "estimated_duration": 3600.169268667129,
    "input_throughput": 3704.3994336792634,
    "output_throughput": 3230.2070075459114,
    "total_throughput": 6934.606441225174,
    "itl": 258.8622730356443,
    "ttft": 2198562.0992399724,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1407,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.3994491599126935,
    "arrivals": 401058,
    "finished_requests": 53472,
    "scheduler_time": 53.276697540027264
}
#Debug simulation 
Total elapsed time: 4.467693951912224. Arrivals time: 0.19448534166440368 Scheduler time: 4.1806624084711075 Scheduler overhead time: 0.022776128258556128 Adapter cache time: 0.03694269200786948 Engine time: 0.022399896755814552 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-16-32/adapters_256_slots_192_rate_0.8-0.4-0.1_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-16-32/adapters_256_slots_192_rate_0.8-0.4-0.1_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 1080, 8640, 8640, 1080, 8640, 4320, 8640, 1080, 4320, 1080, 8640, 4320, 4320, 4320, 4320, 8640, 1080, 1080, 1080, 4320, 8640, 1080, 8640, 8640, 4320, 4320, 4320, 1080, 8640, 1080, 4320, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 8640, 4320, 1080, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 1080, 8640, 8640, 4320, 1080, 1080, 8640, 4320, 1080, 4320, 4320, 8640, 4320, 1080, 1080, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 4320, 1080, 4320, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 8640, 8640, 1080, 8640, 1080, 4320, 8640, 8640, 8640, 4320, 1080, 8640, 4320, 1080, 1080, 1080, 1080, 1080, 8640, 4320, 1080, 8640, 1080, 8640, 1080, 1080, 4320, 4320, 8640, 4320, 8640, 1080, 4320, 1080, 8640, 8640, 1080, 8640, 4320, 1080, 8640, 1080, 1080, 8640, 8640, 4320, 8640, 8640, 1080, 8640, 4320, 4320, 1080, 4320, 8640, 8640, 1080, 8640, 4320, 1080, 4320, 8640, 1080, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 1080, 1080, 8640, 1080, 4320, 8640, 8640, 4320, 1080, 8640, 1080, 4320, 4320, 1080, 4320, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 8640, 4320, 8640, 4320, 1080, 4320, 8640, 4320, 8640, 1080, 8640, 1080, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 1080, 8640, 1080, 8640, 4320, 4320, 1080, 4320, 8640, 4320, 4320, 8640, 1080, 8640, 8640, 4320, 1080, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 1080, 8640, 4320, 8640, 8640, 1080, 8640, 4320, 4320, 8640, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 1080, 1080, 1080, 1080]
Prompts retrieved: 1202040 . Total input tokens: 267960373 . Total output tokens: 240348610
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 3.702576662879437,
    "estimated_duration": 3600.0353646974972,
    "input_throughput": 3142.553295709258,
    "output_throughput": 2748.050226676396,
    "total_throughput": 5890.603522385654,
    "itl": 121.68774156756339,
    "ttft": 2310002.757438204,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4724,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.622055598850071,
    "arrivals": 401058,
    "finished_requests": 45272,
    "scheduler_time": 52.294839794234676
}
#Debug simulation 
Total elapsed time: 3.702674829866737. Arrivals time: 0.1753438706509769 Scheduler time: 3.2320204032585025 Scheduler overhead time: 0.041868590749800205 Adapter cache time: 0.19131644302979112 Engine time: 0.04256012104451656 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_16-16-16/adapters_256_slots_192_rate_0.8-0.4-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_16-16-16/adapters_256_slots_192_rate_0.8-0.4-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 1080, 8640, 8640, 1080, 8640, 4320, 8640, 1080, 4320, 1080, 8640, 4320, 4320, 4320, 4320, 8640, 1080, 1080, 1080, 4320, 8640, 1080, 8640, 8640, 4320, 4320, 4320, 1080, 8640, 1080, 4320, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 8640, 4320, 1080, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 1080, 8640, 8640, 4320, 1080, 1080, 8640, 4320, 1080, 4320, 4320, 8640, 4320, 1080, 1080, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 4320, 1080, 4320, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 8640, 8640, 1080, 8640, 1080, 4320, 8640, 8640, 8640, 4320, 1080, 8640, 4320, 1080, 1080, 1080, 1080, 1080, 8640, 4320, 1080, 8640, 1080, 8640, 1080, 1080, 4320, 4320, 8640, 4320, 8640, 1080, 4320, 1080, 8640, 8640, 1080, 8640, 4320, 1080, 8640, 1080, 1080, 8640, 8640, 4320, 8640, 8640, 1080, 8640, 4320, 4320, 1080, 4320, 8640, 8640, 1080, 8640, 4320, 1080, 4320, 8640, 1080, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 1080, 1080, 8640, 1080, 4320, 8640, 8640, 4320, 1080, 8640, 1080, 4320, 4320, 1080, 4320, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 8640, 4320, 8640, 4320, 1080, 4320, 8640, 4320, 8640, 1080, 8640, 1080, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 1080, 8640, 1080, 8640, 4320, 4320, 1080, 4320, 8640, 4320, 4320, 8640, 1080, 8640, 8640, 4320, 1080, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 1080, 8640, 4320, 8640, 8640, 1080, 8640, 4320, 4320, 8640, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 1080, 1080, 1080, 1080]
Prompts retrieved: 1202040 . Total input tokens: 267960373 . Total output tokens: 240348610
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.473441063426435,
    "estimated_duration": 3600.26560388657,
    "input_throughput": 3706.4326547448863,
    "output_throughput": 3231.924330093563,
    "total_throughput": 6938.3569848384495,
    "itl": 259.33638102389625,
    "ttft": 2198253.8950434425,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1412,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.221951016401759,
    "arrivals": 401058,
    "finished_requests": 53499,
    "scheduler_time": 53.29037081209266
}
#Debug simulation 
Total elapsed time: 4.473570416215807. Arrivals time: 0.1954859448596835 Scheduler time: 4.184794965200126 Scheduler overhead time: 0.022917686961591244 Adapter cache time: 0.037533808033913374 Engine time: 0.022467397153377533 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_16-16-32/adapters_256_slots_192_rate_0.8-0.4-0.1_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_16-16-32/adapters_256_slots_192_rate_0.8-0.4-0.1_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 1080, 8640, 8640, 1080, 8640, 4320, 8640, 1080, 4320, 1080, 8640, 4320, 4320, 4320, 4320, 8640, 1080, 1080, 1080, 4320, 8640, 1080, 8640, 8640, 4320, 4320, 4320, 1080, 8640, 1080, 4320, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 8640, 4320, 1080, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 1080, 8640, 8640, 4320, 1080, 1080, 8640, 4320, 1080, 4320, 4320, 8640, 4320, 1080, 1080, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 4320, 1080, 4320, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 8640, 8640, 1080, 8640, 1080, 4320, 8640, 8640, 8640, 4320, 1080, 8640, 4320, 1080, 1080, 1080, 1080, 1080, 8640, 4320, 1080, 8640, 1080, 8640, 1080, 1080, 4320, 4320, 8640, 4320, 8640, 1080, 4320, 1080, 8640, 8640, 1080, 8640, 4320, 1080, 8640, 1080, 1080, 8640, 8640, 4320, 8640, 8640, 1080, 8640, 4320, 4320, 1080, 4320, 8640, 8640, 1080, 8640, 4320, 1080, 4320, 8640, 1080, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 1080, 1080, 8640, 1080, 4320, 8640, 8640, 4320, 1080, 8640, 1080, 4320, 4320, 1080, 4320, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 8640, 4320, 8640, 4320, 1080, 4320, 8640, 4320, 8640, 1080, 8640, 1080, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 1080, 8640, 1080, 8640, 4320, 4320, 1080, 4320, 8640, 4320, 4320, 8640, 1080, 8640, 8640, 4320, 1080, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 1080, 8640, 4320, 8640, 8640, 1080, 8640, 4320, 4320, 8640, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 1080, 1080, 1080, 1080]
Prompts retrieved: 1202040 . Total input tokens: 267960373 . Total output tokens: 240348610
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 3.72406057594344,
    "estimated_duration": 3600.0305782426904,
    "input_throughput": 3138.268343685822,
    "output_throughput": 2744.101136169303,
    "total_throughput": 5882.369479855125,
    "itl": 121.81340656232949,
    "ttft": 2310223.422741506,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4709,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.776494255400088,
    "arrivals": 401058,
    "finished_requests": 45206,
    "scheduler_time": 52.235725827024005
}
#Debug simulation 
Total elapsed time: 3.72415710426867. Arrivals time: 0.1739495717920363 Scheduler time: 3.2554697608575225 Scheduler overhead time: 0.04184929467737675 Adapter cache time: 0.19032220542430878 Engine time: 0.042772865388542414 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-8-8/adapters_256_slots_192_rate_0.8-0.4-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-8-8/adapters_256_slots_192_rate_0.8-0.4-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 540, 8640, 8640, 540, 8640, 4320, 8640, 540, 4320, 540, 8640, 4320, 4320, 4320, 4320, 8640, 540, 540, 540, 4320, 8640, 540, 8640, 8640, 4320, 4320, 4320, 540, 8640, 540, 4320, 4320, 540, 4320, 540, 540, 4320, 4320, 8640, 4320, 540, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 540, 8640, 8640, 4320, 540, 540, 8640, 4320, 540, 4320, 4320, 8640, 4320, 540, 540, 8640, 8640, 8640, 8640, 8640, 8640, 540, 4320, 540, 4320, 540, 540, 540, 4320, 4320, 4320, 540, 540, 8640, 8640, 540, 8640, 540, 4320, 8640, 8640, 8640, 4320, 540, 8640, 4320, 540, 540, 540, 540, 540, 8640, 4320, 540, 8640, 540, 8640, 540, 540, 4320, 4320, 8640, 4320, 8640, 540, 4320, 540, 8640, 8640, 540, 8640, 4320, 540, 8640, 540, 540, 8640, 8640, 4320, 8640, 8640, 540, 8640, 4320, 4320, 540, 4320, 8640, 8640, 540, 8640, 4320, 540, 4320, 8640, 540, 540, 540, 540, 540, 540, 8640, 540, 540, 540, 8640, 540, 4320, 8640, 8640, 4320, 540, 8640, 540, 4320, 4320, 540, 4320, 540, 8640, 540, 540, 8640, 540, 8640, 8640, 4320, 8640, 4320, 540, 4320, 8640, 4320, 8640, 540, 8640, 540, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 540, 8640, 540, 8640, 4320, 4320, 540, 4320, 8640, 4320, 4320, 8640, 540, 8640, 8640, 4320, 540, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 540, 8640, 4320, 8640, 8640, 540, 8640, 4320, 4320, 8640, 540, 4320, 540, 540, 540, 540, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 540, 540, 540, 540]
Prompts retrieved: 1156140 . Total input tokens: 257714928 . Total output tokens: 231188240
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.301545014139265,
    "estimated_duration": 3600.2685454015095,
    "input_throughput": 3682.542241726422,
    "output_throughput": 3238.928666833529,
    "total_throughput": 6921.470908559952,
    "itl": 263.27840587352574,
    "ttft": 2192005.4322719383,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1608,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.921264292244003,
    "arrivals": 385672,
    "finished_requests": 53593,
    "scheduler_time": 53.34325576147394
}
#Debug simulation 
Total elapsed time: 4.301610777154565. Arrivals time: 0.19476652750745416 Scheduler time: 4.011402691714466 Scheduler overhead time: 0.022255814634263515 Adapter cache time: 0.04085293272510171 Engine time: 0.02217943873256445 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-8-16/adapters_256_slots_192_rate_0.8-0.4-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-8-16/adapters_256_slots_192_rate_0.8-0.4-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 540, 8640, 8640, 540, 8640, 4320, 8640, 540, 4320, 540, 8640, 4320, 4320, 4320, 4320, 8640, 540, 540, 540, 4320, 8640, 540, 8640, 8640, 4320, 4320, 4320, 540, 8640, 540, 4320, 4320, 540, 4320, 540, 540, 4320, 4320, 8640, 4320, 540, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 540, 8640, 8640, 4320, 540, 540, 8640, 4320, 540, 4320, 4320, 8640, 4320, 540, 540, 8640, 8640, 8640, 8640, 8640, 8640, 540, 4320, 540, 4320, 540, 540, 540, 4320, 4320, 4320, 540, 540, 8640, 8640, 540, 8640, 540, 4320, 8640, 8640, 8640, 4320, 540, 8640, 4320, 540, 540, 540, 540, 540, 8640, 4320, 540, 8640, 540, 8640, 540, 540, 4320, 4320, 8640, 4320, 8640, 540, 4320, 540, 8640, 8640, 540, 8640, 4320, 540, 8640, 540, 540, 8640, 8640, 4320, 8640, 8640, 540, 8640, 4320, 4320, 540, 4320, 8640, 8640, 540, 8640, 4320, 540, 4320, 8640, 540, 540, 540, 540, 540, 540, 8640, 540, 540, 540, 8640, 540, 4320, 8640, 8640, 4320, 540, 8640, 540, 4320, 4320, 540, 4320, 540, 8640, 540, 540, 8640, 540, 8640, 8640, 4320, 8640, 4320, 540, 4320, 8640, 4320, 8640, 540, 8640, 540, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 540, 8640, 540, 8640, 4320, 4320, 540, 4320, 8640, 4320, 4320, 8640, 540, 8640, 8640, 4320, 540, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 540, 8640, 4320, 8640, 8640, 540, 8640, 4320, 4320, 8640, 540, 4320, 540, 540, 540, 540, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 540, 540, 540, 540]
Prompts retrieved: 1156140 . Total input tokens: 257714928 . Total output tokens: 231188240
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.049888286739588,
    "estimated_duration": 3600.02244129705,
    "input_throughput": 3674.740981679458,
    "output_throughput": 3232.4298500226505,
    "total_throughput": 6907.170831702108,
    "itl": 260.7297440704025,
    "ttft": 2194049.846598703,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1639,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.3423839725785625,
    "arrivals": 385672,
    "finished_requests": 53469,
    "scheduler_time": 53.2842481692153
}
#Debug simulation 
Total elapsed time: 4.049988249782473. Arrivals time: 0.19307396141812205 Scheduler time: 3.758862575981766 Scheduler overhead time: 0.022423131857067347 Adapter cache time: 0.04306928068399429 Engine time: 0.022312724497169256 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-8-32/adapters_256_slots_192_rate_0.8-0.4-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-8-32/adapters_256_slots_192_rate_0.8-0.4-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 540, 8640, 8640, 540, 8640, 4320, 8640, 540, 4320, 540, 8640, 4320, 4320, 4320, 4320, 8640, 540, 540, 540, 4320, 8640, 540, 8640, 8640, 4320, 4320, 4320, 540, 8640, 540, 4320, 4320, 540, 4320, 540, 540, 4320, 4320, 8640, 4320, 540, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 540, 8640, 8640, 4320, 540, 540, 8640, 4320, 540, 4320, 4320, 8640, 4320, 540, 540, 8640, 8640, 8640, 8640, 8640, 8640, 540, 4320, 540, 4320, 540, 540, 540, 4320, 4320, 4320, 540, 540, 8640, 8640, 540, 8640, 540, 4320, 8640, 8640, 8640, 4320, 540, 8640, 4320, 540, 540, 540, 540, 540, 8640, 4320, 540, 8640, 540, 8640, 540, 540, 4320, 4320, 8640, 4320, 8640, 540, 4320, 540, 8640, 8640, 540, 8640, 4320, 540, 8640, 540, 540, 8640, 8640, 4320, 8640, 8640, 540, 8640, 4320, 4320, 540, 4320, 8640, 8640, 540, 8640, 4320, 540, 4320, 8640, 540, 540, 540, 540, 540, 540, 8640, 540, 540, 540, 8640, 540, 4320, 8640, 8640, 4320, 540, 8640, 540, 4320, 4320, 540, 4320, 540, 8640, 540, 540, 8640, 540, 8640, 8640, 4320, 8640, 4320, 540, 4320, 8640, 4320, 8640, 540, 8640, 540, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 540, 8640, 540, 8640, 4320, 4320, 540, 4320, 8640, 4320, 4320, 8640, 540, 8640, 8640, 4320, 540, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 540, 8640, 4320, 8640, 8640, 540, 8640, 4320, 4320, 8640, 540, 4320, 540, 540, 540, 540, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 540, 540, 540, 540]
Prompts retrieved: 1156140 . Total input tokens: 257714928 . Total output tokens: 231188240
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 3.8072993140667677,
    "estimated_duration": 3600.0953718915184,
    "input_throughput": 3206.9089308414827,
    "output_throughput": 2850.791142960103,
    "total_throughput": 6057.700073801586,
    "itl": 118.70822008942746,
    "ttft": 2284025.629030655,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2317,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.563774869292939,
    "arrivals": 385672,
    "finished_requests": 46729,
    "scheduler_time": 54.07092963304136
}
#Debug simulation 
Total elapsed time: 3.807392568793148. Arrivals time: 0.1771037201397121 Scheduler time: 3.3549353615380824 Scheduler overhead time: 0.0428693019784987 Adapter cache time: 0.16886355029419065 Engine time: 0.04359743930399418 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-16-16/adapters_256_slots_192_rate_0.8-0.4-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-16-16/adapters_256_slots_192_rate_0.8-0.4-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 540, 8640, 8640, 540, 8640, 4320, 8640, 540, 4320, 540, 8640, 4320, 4320, 4320, 4320, 8640, 540, 540, 540, 4320, 8640, 540, 8640, 8640, 4320, 4320, 4320, 540, 8640, 540, 4320, 4320, 540, 4320, 540, 540, 4320, 4320, 8640, 4320, 540, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 540, 8640, 8640, 4320, 540, 540, 8640, 4320, 540, 4320, 4320, 8640, 4320, 540, 540, 8640, 8640, 8640, 8640, 8640, 8640, 540, 4320, 540, 4320, 540, 540, 540, 4320, 4320, 4320, 540, 540, 8640, 8640, 540, 8640, 540, 4320, 8640, 8640, 8640, 4320, 540, 8640, 4320, 540, 540, 540, 540, 540, 8640, 4320, 540, 8640, 540, 8640, 540, 540, 4320, 4320, 8640, 4320, 8640, 540, 4320, 540, 8640, 8640, 540, 8640, 4320, 540, 8640, 540, 540, 8640, 8640, 4320, 8640, 8640, 540, 8640, 4320, 4320, 540, 4320, 8640, 8640, 540, 8640, 4320, 540, 4320, 8640, 540, 540, 540, 540, 540, 540, 8640, 540, 540, 540, 8640, 540, 4320, 8640, 8640, 4320, 540, 8640, 540, 4320, 4320, 540, 4320, 540, 8640, 540, 540, 8640, 540, 8640, 8640, 4320, 8640, 4320, 540, 4320, 8640, 4320, 8640, 540, 8640, 540, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 540, 8640, 540, 8640, 4320, 4320, 540, 4320, 8640, 4320, 4320, 8640, 540, 8640, 8640, 4320, 540, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 540, 8640, 4320, 8640, 8640, 540, 8640, 4320, 4320, 8640, 540, 4320, 540, 540, 540, 540, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 540, 540, 540, 540]
Prompts retrieved: 1156140 . Total input tokens: 257714928 . Total output tokens: 231188240
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 4.108041062019765,
    "estimated_duration": 3600.2198085977216,
    "input_throughput": 3675.013944538401,
    "output_throughput": 3232.698451412927,
    "total_throughput": 6907.712395951328,
    "itl": 260.7181903493848,
    "ttft": 2193946.8512098133,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1646,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.154113521601417,
    "arrivals": 385672,
    "finished_requests": 53476,
    "scheduler_time": 53.289592467110694
}
#Debug simulation 
Total elapsed time: 4.108136081136763. Arrivals time: 0.1986153139732778 Scheduler time: 3.81209976086393 Scheduler overhead time: 0.022565501742064953 Adapter cache time: 0.04213473154231906 Engine time: 0.022376450709998608 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-16-32/adapters_256_slots_192_rate_0.8-0.4-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-16-32/adapters_256_slots_192_rate_0.8-0.4-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 540, 8640, 8640, 540, 8640, 4320, 8640, 540, 4320, 540, 8640, 4320, 4320, 4320, 4320, 8640, 540, 540, 540, 4320, 8640, 540, 8640, 8640, 4320, 4320, 4320, 540, 8640, 540, 4320, 4320, 540, 4320, 540, 540, 4320, 4320, 8640, 4320, 540, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 540, 8640, 8640, 4320, 540, 540, 8640, 4320, 540, 4320, 4320, 8640, 4320, 540, 540, 8640, 8640, 8640, 8640, 8640, 8640, 540, 4320, 540, 4320, 540, 540, 540, 4320, 4320, 4320, 540, 540, 8640, 8640, 540, 8640, 540, 4320, 8640, 8640, 8640, 4320, 540, 8640, 4320, 540, 540, 540, 540, 540, 8640, 4320, 540, 8640, 540, 8640, 540, 540, 4320, 4320, 8640, 4320, 8640, 540, 4320, 540, 8640, 8640, 540, 8640, 4320, 540, 8640, 540, 540, 8640, 8640, 4320, 8640, 8640, 540, 8640, 4320, 4320, 540, 4320, 8640, 8640, 540, 8640, 4320, 540, 4320, 8640, 540, 540, 540, 540, 540, 540, 8640, 540, 540, 540, 8640, 540, 4320, 8640, 8640, 4320, 540, 8640, 540, 4320, 4320, 540, 4320, 540, 8640, 540, 540, 8640, 540, 8640, 8640, 4320, 8640, 4320, 540, 4320, 8640, 4320, 8640, 540, 8640, 540, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 540, 8640, 540, 8640, 4320, 4320, 540, 4320, 8640, 4320, 4320, 8640, 540, 8640, 8640, 4320, 540, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 540, 8640, 4320, 8640, 8640, 540, 8640, 4320, 4320, 8640, 540, 4320, 540, 540, 540, 540, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 540, 540, 540, 540]
Prompts retrieved: 1156140 . Total input tokens: 257714928 . Total output tokens: 231188240
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 3.7865754943341017,
    "estimated_duration": 3600.065752002859,
    "input_throughput": 3207.136145659717,
    "output_throughput": 2851.0432050552863,
    "total_throughput": 6058.179350715003,
    "itl": 118.70176912101313,
    "ttft": 2284095.7753009005,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2312,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.640569032840264,
    "arrivals": 385672,
    "finished_requests": 46733,
    "scheduler_time": 54.07363102465263
}
#Debug simulation 
Total elapsed time: 3.7866693041287363. Arrivals time: 0.17966866306960583 Scheduler time: 3.3322990285232663 Scheduler overhead time: 0.042861831840127707 Adapter cache time: 0.16834677569568157 Engine time: 0.04351805103942752 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_16-16-16/adapters_256_slots_192_rate_0.8-0.4-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_16-16-16/adapters_256_slots_192_rate_0.8-0.4-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 540, 8640, 8640, 540, 8640, 4320, 8640, 540, 4320, 540, 8640, 4320, 4320, 4320, 4320, 8640, 540, 540, 540, 4320, 8640, 540, 8640, 8640, 4320, 4320, 4320, 540, 8640, 540, 4320, 4320, 540, 4320, 540, 540, 4320, 4320, 8640, 4320, 540, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 540, 8640, 8640, 4320, 540, 540, 8640, 4320, 540, 4320, 4320, 8640, 4320, 540, 540, 8640, 8640, 8640, 8640, 8640, 8640, 540, 4320, 540, 4320, 540, 540, 540, 4320, 4320, 4320, 540, 540, 8640, 8640, 540, 8640, 540, 4320, 8640, 8640, 8640, 4320, 540, 8640, 4320, 540, 540, 540, 540, 540, 8640, 4320, 540, 8640, 540, 8640, 540, 540, 4320, 4320, 8640, 4320, 8640, 540, 4320, 540, 8640, 8640, 540, 8640, 4320, 540, 8640, 540, 540, 8640, 8640, 4320, 8640, 8640, 540, 8640, 4320, 4320, 540, 4320, 8640, 8640, 540, 8640, 4320, 540, 4320, 8640, 540, 540, 540, 540, 540, 540, 8640, 540, 540, 540, 8640, 540, 4320, 8640, 8640, 4320, 540, 8640, 540, 4320, 4320, 540, 4320, 540, 8640, 540, 540, 8640, 540, 8640, 8640, 4320, 8640, 4320, 540, 4320, 8640, 4320, 8640, 540, 8640, 540, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 540, 8640, 540, 8640, 4320, 4320, 540, 4320, 8640, 4320, 4320, 8640, 540, 8640, 8640, 4320, 540, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 540, 8640, 4320, 8640, 8640, 540, 8640, 4320, 4320, 8640, 540, 4320, 540, 540, 540, 540, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 540, 540, 540, 540]
Prompts retrieved: 1156140 . Total input tokens: 257714928 . Total output tokens: 231188240
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.067869252990931,
    "estimated_duration": 3600.146454181011,
    "input_throughput": 3675.452976262366,
    "output_throughput": 3232.956533332963,
    "total_throughput": 6908.409509595329,
    "itl": 260.67475939028316,
    "ttft": 2193917.2198140766,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1646,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.921622785408843,
    "arrivals": 385672,
    "finished_requests": 53479,
    "scheduler_time": 53.291523374372076
}
#Debug simulation 
Total elapsed time: 4.067961531225592. Arrivals time: 0.19155979109928012 Scheduler time: 3.7794021763838828 Scheduler overhead time: 0.02239214302971959 Adapter cache time: 0.042119582649320364 Engine time: 0.02221244154497981 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_16-16-32/adapters_256_slots_192_rate_0.8-0.4-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_16-16-32/adapters_256_slots_192_rate_0.8-0.4-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 540, 8640, 8640, 540, 8640, 4320, 8640, 540, 4320, 540, 8640, 4320, 4320, 4320, 4320, 8640, 540, 540, 540, 4320, 8640, 540, 8640, 8640, 4320, 4320, 4320, 540, 8640, 540, 4320, 4320, 540, 4320, 540, 540, 4320, 4320, 8640, 4320, 540, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 540, 8640, 8640, 4320, 540, 540, 8640, 4320, 540, 4320, 4320, 8640, 4320, 540, 540, 8640, 8640, 8640, 8640, 8640, 8640, 540, 4320, 540, 4320, 540, 540, 540, 4320, 4320, 4320, 540, 540, 8640, 8640, 540, 8640, 540, 4320, 8640, 8640, 8640, 4320, 540, 8640, 4320, 540, 540, 540, 540, 540, 8640, 4320, 540, 8640, 540, 8640, 540, 540, 4320, 4320, 8640, 4320, 8640, 540, 4320, 540, 8640, 8640, 540, 8640, 4320, 540, 8640, 540, 540, 8640, 8640, 4320, 8640, 8640, 540, 8640, 4320, 4320, 540, 4320, 8640, 8640, 540, 8640, 4320, 540, 4320, 8640, 540, 540, 540, 540, 540, 540, 8640, 540, 540, 540, 8640, 540, 4320, 8640, 8640, 4320, 540, 8640, 540, 4320, 4320, 540, 4320, 540, 8640, 540, 540, 8640, 540, 8640, 8640, 4320, 8640, 4320, 540, 4320, 8640, 4320, 8640, 540, 8640, 540, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 540, 8640, 540, 8640, 4320, 4320, 540, 4320, 8640, 4320, 4320, 8640, 540, 8640, 8640, 4320, 540, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 540, 8640, 4320, 8640, 8640, 540, 8640, 4320, 4320, 8640, 540, 4320, 540, 540, 540, 540, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 540, 540, 540, 540]
Prompts retrieved: 1156140 . Total input tokens: 257714928 . Total output tokens: 231188240
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 3.7763481508009136,
    "estimated_duration": 3600.1141990005326,
    "input_throughput": 3206.934103147402,
    "output_throughput": 2850.7767900388435,
    "total_throughput": 6057.710893186245,
    "itl": 118.70942077450532,
    "ttft": 2284220.9614906944,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2318,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.759564641043233,
    "arrivals": 385672,
    "finished_requests": 46730,
    "scheduler_time": 54.07130192157802
}
#Debug simulation 
Total elapsed time: 3.776452229823917. Arrivals time: 0.17551312083378434 Scheduler time: 3.326525880023837 Scheduler overhead time: 0.04275163868442178 Adapter cache time: 0.1680741347372532 Engine time: 0.043654927518218756 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-8-8/adapters_256_slots_192_rate_0.8-0.4-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-8-8/adapters_256_slots_192_rate_0.8-0.4-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 270, 8640, 8640, 270, 8640, 4320, 8640, 270, 4320, 270, 8640, 4320, 4320, 4320, 4320, 8640, 270, 270, 270, 4320, 8640, 270, 8640, 8640, 4320, 4320, 4320, 270, 8640, 270, 4320, 4320, 270, 4320, 270, 270, 4320, 4320, 8640, 4320, 270, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 270, 8640, 8640, 4320, 270, 270, 8640, 4320, 270, 4320, 4320, 8640, 4320, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 270, 4320, 270, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 270, 8640, 8640, 270, 8640, 270, 4320, 8640, 8640, 8640, 4320, 270, 8640, 4320, 270, 270, 270, 270, 270, 8640, 4320, 270, 8640, 270, 8640, 270, 270, 4320, 4320, 8640, 4320, 8640, 270, 4320, 270, 8640, 8640, 270, 8640, 4320, 270, 8640, 270, 270, 8640, 8640, 4320, 8640, 8640, 270, 8640, 4320, 4320, 270, 4320, 8640, 8640, 270, 8640, 4320, 270, 4320, 8640, 270, 270, 270, 270, 270, 270, 8640, 270, 270, 270, 8640, 270, 4320, 8640, 8640, 4320, 270, 8640, 270, 4320, 4320, 270, 4320, 270, 8640, 270, 270, 8640, 270, 8640, 8640, 4320, 8640, 4320, 270, 4320, 8640, 4320, 8640, 270, 8640, 270, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 270, 8640, 270, 8640, 4320, 4320, 270, 4320, 8640, 4320, 4320, 8640, 270, 8640, 8640, 4320, 270, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 270, 8640, 4320, 8640, 8640, 270, 8640, 4320, 4320, 8640, 270, 4320, 270, 270, 270, 270, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 270, 270, 270, 270]
Prompts retrieved: 1133190 . Total input tokens: 252615163 . Total output tokens: 226586703
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 3.9857717165723443,
    "estimated_duration": 3600.1970247976706,
    "input_throughput": 3763.640408197242,
    "output_throughput": 3309.18861327306,
    "total_throughput": 7072.829021470302,
    "itl": 258.2572244603983,
    "ttft": 2176883.0310854684,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1157,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.540984319730283,
    "arrivals": 378122,
    "finished_requests": 54838,
    "scheduler_time": 54.46556699998412
}
#Debug simulation 
Total elapsed time: 3.985861762892455. Arrivals time: 0.19197758473455906 Scheduler time: 3.7022369196638465 Scheduler overhead time: 0.021726513747125864 Adapter cache time: 0.03764766873791814 Engine time: 0.022204861976206303 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-8-16/adapters_256_slots_192_rate_0.8-0.4-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-8-16/adapters_256_slots_192_rate_0.8-0.4-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 270, 8640, 8640, 270, 8640, 4320, 8640, 270, 4320, 270, 8640, 4320, 4320, 4320, 4320, 8640, 270, 270, 270, 4320, 8640, 270, 8640, 8640, 4320, 4320, 4320, 270, 8640, 270, 4320, 4320, 270, 4320, 270, 270, 4320, 4320, 8640, 4320, 270, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 270, 8640, 8640, 4320, 270, 270, 8640, 4320, 270, 4320, 4320, 8640, 4320, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 270, 4320, 270, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 270, 8640, 8640, 270, 8640, 270, 4320, 8640, 8640, 8640, 4320, 270, 8640, 4320, 270, 270, 270, 270, 270, 8640, 4320, 270, 8640, 270, 8640, 270, 270, 4320, 4320, 8640, 4320, 8640, 270, 4320, 270, 8640, 8640, 270, 8640, 4320, 270, 8640, 270, 270, 8640, 8640, 4320, 8640, 8640, 270, 8640, 4320, 4320, 270, 4320, 8640, 8640, 270, 8640, 4320, 270, 4320, 8640, 270, 270, 270, 270, 270, 270, 8640, 270, 270, 270, 8640, 270, 4320, 8640, 8640, 4320, 270, 8640, 270, 4320, 4320, 270, 4320, 270, 8640, 270, 270, 8640, 270, 8640, 8640, 4320, 8640, 4320, 270, 4320, 8640, 4320, 8640, 270, 8640, 270, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 270, 8640, 270, 8640, 4320, 4320, 270, 4320, 8640, 4320, 4320, 8640, 270, 8640, 8640, 4320, 270, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 270, 8640, 4320, 8640, 8640, 270, 8640, 4320, 4320, 8640, 270, 4320, 270, 270, 270, 270, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 270, 270, 270, 270]
Prompts retrieved: 1133190 . Total input tokens: 252615163 . Total output tokens: 226586703
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.003486318979412,
    "estimated_duration": 3600.209441728519,
    "input_throughput": 3759.484335306243,
    "output_throughput": 3305.8254506120675,
    "total_throughput": 7065.30978591831,
    "itl": 255.28902570704997,
    "ttft": 2178212.935431885,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1138,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.7201557980268336,
    "arrivals": 378122,
    "finished_requests": 54768,
    "scheduler_time": 54.45683904688784
}
#Debug simulation 
Total elapsed time: 4.003584125079215. Arrivals time: 0.19232808239758015 Scheduler time: 3.7187626152299345 Scheduler overhead time: 0.022068306803703308 Adapter cache time: 0.03799044759944081 Engine time: 0.022211385425180197 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-8-32/adapters_256_slots_192_rate_0.8-0.4-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-8-32/adapters_256_slots_192_rate_0.8-0.4-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 270, 8640, 8640, 270, 8640, 4320, 8640, 270, 4320, 270, 8640, 4320, 4320, 4320, 4320, 8640, 270, 270, 270, 4320, 8640, 270, 8640, 8640, 4320, 4320, 4320, 270, 8640, 270, 4320, 4320, 270, 4320, 270, 270, 4320, 4320, 8640, 4320, 270, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 270, 8640, 8640, 4320, 270, 270, 8640, 4320, 270, 4320, 4320, 8640, 4320, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 270, 4320, 270, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 270, 8640, 8640, 270, 8640, 270, 4320, 8640, 8640, 8640, 4320, 270, 8640, 4320, 270, 270, 270, 270, 270, 8640, 4320, 270, 8640, 270, 8640, 270, 270, 4320, 4320, 8640, 4320, 8640, 270, 4320, 270, 8640, 8640, 270, 8640, 4320, 270, 8640, 270, 270, 8640, 8640, 4320, 8640, 8640, 270, 8640, 4320, 4320, 270, 4320, 8640, 8640, 270, 8640, 4320, 270, 4320, 8640, 270, 270, 270, 270, 270, 270, 8640, 270, 270, 270, 8640, 270, 4320, 8640, 8640, 4320, 270, 8640, 270, 4320, 4320, 270, 4320, 270, 8640, 270, 270, 8640, 270, 8640, 8640, 4320, 8640, 4320, 270, 4320, 8640, 4320, 8640, 270, 8640, 270, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 270, 8640, 270, 8640, 4320, 4320, 270, 4320, 8640, 4320, 4320, 8640, 270, 8640, 8640, 4320, 270, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 270, 8640, 4320, 8640, 8640, 270, 8640, 4320, 4320, 8640, 270, 4320, 270, 270, 270, 270, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 270, 270, 270, 270]
Prompts retrieved: 1133190 . Total input tokens: 252615163 . Total output tokens: 226586703
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 3.8256538501009345,
    "estimated_duration": 3600.0341945884666,
    "input_throughput": 3271.4572594070355,
    "output_throughput": 2903.71241909689,
    "total_throughput": 6175.169678503926,
    "itl": 116.11345073552987,
    "ttft": 2271528.6911247578,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1049,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.4314224984868935,
    "arrivals": 378122,
    "finished_requests": 47794,
    "scheduler_time": 55.14401661091692
}
#Debug simulation 
Total elapsed time: 3.825744118075818. Arrivals time: 0.18022171966731548 Scheduler time: 3.3898909352719784 Scheduler overhead time: 0.04365781834349036 Adapter cache time: 0.14636581437662244 Engine time: 0.04518719296902418 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-16-16/adapters_256_slots_192_rate_0.8-0.4-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-16-16/adapters_256_slots_192_rate_0.8-0.4-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 270, 8640, 8640, 270, 8640, 4320, 8640, 270, 4320, 270, 8640, 4320, 4320, 4320, 4320, 8640, 270, 270, 270, 4320, 8640, 270, 8640, 8640, 4320, 4320, 4320, 270, 8640, 270, 4320, 4320, 270, 4320, 270, 270, 4320, 4320, 8640, 4320, 270, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 270, 8640, 8640, 4320, 270, 270, 8640, 4320, 270, 4320, 4320, 8640, 4320, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 270, 4320, 270, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 270, 8640, 8640, 270, 8640, 270, 4320, 8640, 8640, 8640, 4320, 270, 8640, 4320, 270, 270, 270, 270, 270, 8640, 4320, 270, 8640, 270, 8640, 270, 270, 4320, 4320, 8640, 4320, 8640, 270, 4320, 270, 8640, 8640, 270, 8640, 4320, 270, 8640, 270, 270, 8640, 8640, 4320, 8640, 8640, 270, 8640, 4320, 4320, 270, 4320, 8640, 8640, 270, 8640, 4320, 270, 4320, 8640, 270, 270, 270, 270, 270, 270, 8640, 270, 270, 270, 8640, 270, 4320, 8640, 8640, 4320, 270, 8640, 270, 4320, 4320, 270, 4320, 270, 8640, 270, 270, 8640, 270, 8640, 8640, 4320, 8640, 4320, 270, 4320, 8640, 4320, 8640, 270, 8640, 270, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 270, 8640, 270, 8640, 4320, 4320, 270, 4320, 8640, 4320, 4320, 8640, 270, 8640, 8640, 4320, 270, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 270, 8640, 4320, 8640, 8640, 270, 8640, 4320, 4320, 8640, 270, 4320, 270, 270, 270, 270, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 270, 270, 270, 270]
Prompts retrieved: 1133190 . Total input tokens: 252615163 . Total output tokens: 226586703
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 4.004506577737629,
    "estimated_duration": 3600.0800899408514,
    "input_throughput": 3760.5791154003,
    "output_throughput": 3307.0139281805828,
    "total_throughput": 7067.593043580882,
    "itl": 255.5837231483594,
    "ttft": 2177998.75426271,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1146,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.582681049602066,
    "arrivals": 378122,
    "finished_requests": 54787,
    "scheduler_time": 54.46946238852034
}
#Debug simulation 
Total elapsed time: 4.004620668012649. Arrivals time: 0.19666967820376158 Scheduler time: 3.7155898474156857 Scheduler overhead time: 0.021983910351991653 Adapter cache time: 0.038013636600226164 Engine time: 0.02221230184659362 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-16-32/adapters_256_slots_192_rate_0.8-0.4-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-16-32/adapters_256_slots_192_rate_0.8-0.4-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 270, 8640, 8640, 270, 8640, 4320, 8640, 270, 4320, 270, 8640, 4320, 4320, 4320, 4320, 8640, 270, 270, 270, 4320, 8640, 270, 8640, 8640, 4320, 4320, 4320, 270, 8640, 270, 4320, 4320, 270, 4320, 270, 270, 4320, 4320, 8640, 4320, 270, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 270, 8640, 8640, 4320, 270, 270, 8640, 4320, 270, 4320, 4320, 8640, 4320, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 270, 4320, 270, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 270, 8640, 8640, 270, 8640, 270, 4320, 8640, 8640, 8640, 4320, 270, 8640, 4320, 270, 270, 270, 270, 270, 8640, 4320, 270, 8640, 270, 8640, 270, 270, 4320, 4320, 8640, 4320, 8640, 270, 4320, 270, 8640, 8640, 270, 8640, 4320, 270, 8640, 270, 270, 8640, 8640, 4320, 8640, 8640, 270, 8640, 4320, 4320, 270, 4320, 8640, 8640, 270, 8640, 4320, 270, 4320, 8640, 270, 270, 270, 270, 270, 270, 8640, 270, 270, 270, 8640, 270, 4320, 8640, 8640, 4320, 270, 8640, 270, 4320, 4320, 270, 4320, 270, 8640, 270, 270, 8640, 270, 8640, 8640, 4320, 8640, 4320, 270, 4320, 8640, 4320, 8640, 270, 8640, 270, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 270, 8640, 270, 8640, 4320, 4320, 270, 4320, 8640, 4320, 4320, 8640, 270, 8640, 8640, 4320, 270, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 270, 8640, 4320, 8640, 8640, 270, 8640, 4320, 4320, 8640, 270, 4320, 270, 270, 270, 270, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 270, 270, 270, 270]
Prompts retrieved: 1133190 . Total input tokens: 252615163 . Total output tokens: 226586703
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 3.577092469204217,
    "estimated_duration": 3600.0572443505143,
    "input_throughput": 3024.6446822721186,
    "output_throughput": 2681.583192919936,
    "total_throughput": 5706.227875192055,
    "itl": 105.80629429866424,
    "ttft": 2321276.736672385,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 984,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.2522511453181497,
    "arrivals": 378122,
    "finished_requests": 44153,
    "scheduler_time": 53.127360863154856
}
#Debug simulation 
Total elapsed time: 3.5771817578934133. Arrivals time: 0.16963669145479798 Scheduler time: 3.1592355100438 Scheduler overhead time: 0.046900197863578796 Adapter cache time: 0.13126336876302958 Engine time: 0.04826738638803363 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_16-16-16/adapters_256_slots_192_rate_0.8-0.4-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_16-16-16/adapters_256_slots_192_rate_0.8-0.4-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 270, 8640, 8640, 270, 8640, 4320, 8640, 270, 4320, 270, 8640, 4320, 4320, 4320, 4320, 8640, 270, 270, 270, 4320, 8640, 270, 8640, 8640, 4320, 4320, 4320, 270, 8640, 270, 4320, 4320, 270, 4320, 270, 270, 4320, 4320, 8640, 4320, 270, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 270, 8640, 8640, 4320, 270, 270, 8640, 4320, 270, 4320, 4320, 8640, 4320, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 270, 4320, 270, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 270, 8640, 8640, 270, 8640, 270, 4320, 8640, 8640, 8640, 4320, 270, 8640, 4320, 270, 270, 270, 270, 270, 8640, 4320, 270, 8640, 270, 8640, 270, 270, 4320, 4320, 8640, 4320, 8640, 270, 4320, 270, 8640, 8640, 270, 8640, 4320, 270, 8640, 270, 270, 8640, 8640, 4320, 8640, 8640, 270, 8640, 4320, 4320, 270, 4320, 8640, 8640, 270, 8640, 4320, 270, 4320, 8640, 270, 270, 270, 270, 270, 270, 8640, 270, 270, 270, 8640, 270, 4320, 8640, 8640, 4320, 270, 8640, 270, 4320, 4320, 270, 4320, 270, 8640, 270, 270, 8640, 270, 8640, 8640, 4320, 8640, 4320, 270, 4320, 8640, 4320, 8640, 270, 8640, 270, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 270, 8640, 270, 8640, 4320, 4320, 270, 4320, 8640, 4320, 4320, 8640, 270, 8640, 8640, 4320, 270, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 270, 8640, 4320, 8640, 8640, 270, 8640, 4320, 4320, 8640, 270, 4320, 270, 270, 270, 270, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 270, 270, 270, 270]
Prompts retrieved: 1133190 . Total input tokens: 252615163 . Total output tokens: 226586703
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.039514516014606,
    "estimated_duration": 3600.067263900643,
    "input_throughput": 3760.915007274062,
    "output_throughput": 3307.200706883402,
    "total_throughput": 7068.115714157464,
    "itl": 255.64959415975986,
    "ttft": 2177889.1629209514,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1143,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.4176274870731023,
    "arrivals": 378122,
    "finished_requests": 54791,
    "scheduler_time": 54.47177620145857
}
#Debug simulation 
Total elapsed time: 4.039601814933121. Arrivals time: 0.19351519271731377 Scheduler time: 3.752904067747295 Scheduler overhead time: 0.022172647062689066 Adapter cache time: 0.03841311624273658 Engine time: 0.022411928977817297 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_16-16-32/adapters_256_slots_192_rate_0.8-0.4-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_16-16-32/adapters_256_slots_192_rate_0.8-0.4-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 270, 8640, 8640, 270, 8640, 4320, 8640, 270, 4320, 270, 8640, 4320, 4320, 4320, 4320, 8640, 270, 270, 270, 4320, 8640, 270, 8640, 8640, 4320, 4320, 4320, 270, 8640, 270, 4320, 4320, 270, 4320, 270, 270, 4320, 4320, 8640, 4320, 270, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 270, 8640, 8640, 4320, 270, 270, 8640, 4320, 270, 4320, 4320, 8640, 4320, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 270, 4320, 270, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 270, 8640, 8640, 270, 8640, 270, 4320, 8640, 8640, 8640, 4320, 270, 8640, 4320, 270, 270, 270, 270, 270, 8640, 4320, 270, 8640, 270, 8640, 270, 270, 4320, 4320, 8640, 4320, 8640, 270, 4320, 270, 8640, 8640, 270, 8640, 4320, 270, 8640, 270, 270, 8640, 8640, 4320, 8640, 8640, 270, 8640, 4320, 4320, 270, 4320, 8640, 8640, 270, 8640, 4320, 270, 4320, 8640, 270, 270, 270, 270, 270, 270, 8640, 270, 270, 270, 8640, 270, 4320, 8640, 8640, 4320, 270, 8640, 270, 4320, 4320, 270, 4320, 270, 8640, 270, 270, 8640, 270, 8640, 8640, 4320, 8640, 4320, 270, 4320, 8640, 4320, 8640, 270, 8640, 270, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 270, 8640, 270, 8640, 4320, 4320, 270, 4320, 8640, 4320, 4320, 8640, 270, 8640, 8640, 4320, 270, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 270, 8640, 4320, 8640, 8640, 270, 8640, 4320, 4320, 8640, 270, 4320, 270, 270, 270, 270, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 270, 270, 270, 270]
Prompts retrieved: 1133190 . Total input tokens: 252615163 . Total output tokens: 226586703
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 3.5809869719669223,
    "estimated_duration": 3600.062255753692,
    "input_throughput": 3024.5813062253274,
    "output_throughput": 2681.578904523393,
    "total_throughput": 5706.16021074872,
    "itl": 105.80835443166228,
    "ttft": 2321279.2535419227,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 984,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.292995372116604,
    "arrivals": 378122,
    "finished_requests": 44152,
    "scheduler_time": 53.126755543745105
}
#Debug simulation 
Total elapsed time: 3.5810729297809303. Arrivals time: 0.17032226035371423 Scheduler time: 3.161083442158997 Scheduler overhead time: 0.04638947965577245 Adapter cache time: 0.13356071431189775 Engine time: 0.04789167083799839 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-8/adapters_256_slots_192_rate_0.8-0.4-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-8/adapters_256_slots_192_rate_0.8-0.4-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 135, 8640, 8640, 135, 8640, 4320, 8640, 135, 4320, 135, 8640, 4320, 4320, 4320, 4320, 8640, 135, 135, 135, 4320, 8640, 135, 8640, 8640, 4320, 4320, 4320, 135, 8640, 135, 4320, 4320, 135, 4320, 135, 135, 4320, 4320, 8640, 4320, 135, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 135, 8640, 8640, 4320, 135, 135, 8640, 4320, 135, 4320, 4320, 8640, 4320, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 135, 4320, 135, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 135, 8640, 8640, 135, 8640, 135, 4320, 8640, 8640, 8640, 4320, 135, 8640, 4320, 135, 135, 135, 135, 135, 8640, 4320, 135, 8640, 135, 8640, 135, 135, 4320, 4320, 8640, 4320, 8640, 135, 4320, 135, 8640, 8640, 135, 8640, 4320, 135, 8640, 135, 135, 8640, 8640, 4320, 8640, 8640, 135, 8640, 4320, 4320, 135, 4320, 8640, 8640, 135, 8640, 4320, 135, 4320, 8640, 135, 135, 135, 135, 135, 135, 8640, 135, 135, 135, 8640, 135, 4320, 8640, 8640, 4320, 135, 8640, 135, 4320, 4320, 135, 4320, 135, 8640, 135, 135, 8640, 135, 8640, 8640, 4320, 8640, 4320, 135, 4320, 8640, 4320, 8640, 135, 8640, 135, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 135, 8640, 135, 8640, 4320, 4320, 135, 4320, 8640, 4320, 4320, 8640, 135, 8640, 8640, 4320, 135, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 135, 8640, 4320, 8640, 8640, 135, 8640, 4320, 4320, 8640, 135, 4320, 135, 135, 135, 135, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 135, 135, 135, 135]
Prompts retrieved: 1121715 . Total input tokens: 250060486 . Total output tokens: 224302544
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.150085696950555,
    "estimated_duration": 3600.159432760336,
    "input_throughput": 3869.3678044472726,
    "output_throughput": 3398.269779019101,
    "total_throughput": 7267.637583466374,
    "itl": 250.62875623569892,
    "ttft": 2158715.399496727,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 603,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8454741095914786,
    "arrivals": 374287,
    "finished_requests": 56169,
    "scheduler_time": 55.95266846171031
}
#Debug simulation 
Total elapsed time: 4.150174560956657. Arrivals time: 0.21304823784157634 Scheduler time: 3.852056080941111 Scheduler overhead time: 0.022412055637687445 Adapter cache time: 0.029724597465246916 Engine time: 0.022607180289924145 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-16/adapters_256_slots_192_rate_0.8-0.4-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-16/adapters_256_slots_192_rate_0.8-0.4-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 135, 8640, 8640, 135, 8640, 4320, 8640, 135, 4320, 135, 8640, 4320, 4320, 4320, 4320, 8640, 135, 135, 135, 4320, 8640, 135, 8640, 8640, 4320, 4320, 4320, 135, 8640, 135, 4320, 4320, 135, 4320, 135, 135, 4320, 4320, 8640, 4320, 135, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 135, 8640, 8640, 4320, 135, 135, 8640, 4320, 135, 4320, 4320, 8640, 4320, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 135, 4320, 135, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 135, 8640, 8640, 135, 8640, 135, 4320, 8640, 8640, 8640, 4320, 135, 8640, 4320, 135, 135, 135, 135, 135, 8640, 4320, 135, 8640, 135, 8640, 135, 135, 4320, 4320, 8640, 4320, 8640, 135, 4320, 135, 8640, 8640, 135, 8640, 4320, 135, 8640, 135, 135, 8640, 8640, 4320, 8640, 8640, 135, 8640, 4320, 4320, 135, 4320, 8640, 8640, 135, 8640, 4320, 135, 4320, 8640, 135, 135, 135, 135, 135, 135, 8640, 135, 135, 135, 8640, 135, 4320, 8640, 8640, 4320, 135, 8640, 135, 4320, 4320, 135, 4320, 135, 8640, 135, 135, 8640, 135, 8640, 8640, 4320, 8640, 4320, 135, 4320, 8640, 4320, 8640, 135, 8640, 135, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 135, 8640, 135, 8640, 4320, 4320, 135, 4320, 8640, 4320, 4320, 8640, 135, 8640, 8640, 4320, 135, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 135, 8640, 4320, 8640, 8640, 135, 8640, 4320, 4320, 8640, 135, 4320, 135, 135, 135, 135, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 135, 135, 135, 135]
Prompts retrieved: 1121715 . Total input tokens: 250060486 . Total output tokens: 224302544
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.135647037997842,
    "estimated_duration": 3600.262401895052,
    "input_throughput": 3862.6428986620786,
    "output_throughput": 3393.165729689529,
    "total_throughput": 7255.808628351608,
    "itl": 247.7921813096997,
    "ttft": 2159868.67359894,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 604,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9698371008154991,
    "arrivals": 374287,
    "finished_requests": 56066,
    "scheduler_time": 55.9346081643098
}
#Debug simulation 
Total elapsed time: 4.135739152785391. Arrivals time: 0.2307160529308021 Scheduler time: 3.81907627498731 Scheduler overhead time: 0.02262812666594982 Adapter cache time: 0.0299303000792861 Engine time: 0.02298779785633087 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-32/adapters_256_slots_192_rate_0.8-0.4-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-32/adapters_256_slots_192_rate_0.8-0.4-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 135, 8640, 8640, 135, 8640, 4320, 8640, 135, 4320, 135, 8640, 4320, 4320, 4320, 4320, 8640, 135, 135, 135, 4320, 8640, 135, 8640, 8640, 4320, 4320, 4320, 135, 8640, 135, 4320, 4320, 135, 4320, 135, 135, 4320, 4320, 8640, 4320, 135, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 135, 8640, 8640, 4320, 135, 135, 8640, 4320, 135, 4320, 4320, 8640, 4320, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 135, 4320, 135, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 135, 8640, 8640, 135, 8640, 135, 4320, 8640, 8640, 8640, 4320, 135, 8640, 4320, 135, 135, 135, 135, 135, 8640, 4320, 135, 8640, 135, 8640, 135, 135, 4320, 4320, 8640, 4320, 8640, 135, 4320, 135, 8640, 8640, 135, 8640, 4320, 135, 8640, 135, 135, 8640, 8640, 4320, 8640, 8640, 135, 8640, 4320, 4320, 135, 4320, 8640, 8640, 135, 8640, 4320, 135, 4320, 8640, 135, 135, 135, 135, 135, 135, 8640, 135, 135, 135, 8640, 135, 4320, 8640, 8640, 4320, 135, 8640, 135, 4320, 4320, 135, 4320, 135, 8640, 135, 135, 8640, 135, 8640, 8640, 4320, 8640, 4320, 135, 4320, 8640, 4320, 8640, 135, 8640, 135, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 135, 8640, 135, 8640, 4320, 4320, 135, 4320, 8640, 4320, 4320, 8640, 135, 8640, 8640, 4320, 135, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 135, 8640, 4320, 8640, 8640, 135, 8640, 4320, 4320, 8640, 135, 4320, 135, 135, 135, 135, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 135, 135, 135, 135]
Prompts retrieved: 1121715 . Total input tokens: 250060486 . Total output tokens: 224302544
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 3.9147407840937376,
    "estimated_duration": 3600.1194114755826,
    "input_throughput": 3325.115539735255,
    "output_throughput": 2944.441777739598,
    "total_throughput": 6269.557317474853,
    "itl": 113.72675799585403,
    "ttft": 2260070.821672184,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 557,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.819684324245911,
    "arrivals": 374287,
    "finished_requests": 48325,
    "scheduler_time": 55.92103623765945
}
#Debug simulation 
Total elapsed time: 3.914826087653637. Arrivals time: 0.21610013535246253 Scheduler time: 3.444621881004423 Scheduler overhead time: 0.04431940242648125 Adapter cache time: 0.14384964853525162 Engine time: 0.04526197258383036 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-16-16/adapters_256_slots_192_rate_0.8-0.4-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-16-16/adapters_256_slots_192_rate_0.8-0.4-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 135, 8640, 8640, 135, 8640, 4320, 8640, 135, 4320, 135, 8640, 4320, 4320, 4320, 4320, 8640, 135, 135, 135, 4320, 8640, 135, 8640, 8640, 4320, 4320, 4320, 135, 8640, 135, 4320, 4320, 135, 4320, 135, 135, 4320, 4320, 8640, 4320, 135, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 135, 8640, 8640, 4320, 135, 135, 8640, 4320, 135, 4320, 4320, 8640, 4320, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 135, 4320, 135, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 135, 8640, 8640, 135, 8640, 135, 4320, 8640, 8640, 8640, 4320, 135, 8640, 4320, 135, 135, 135, 135, 135, 8640, 4320, 135, 8640, 135, 8640, 135, 135, 4320, 4320, 8640, 4320, 8640, 135, 4320, 135, 8640, 8640, 135, 8640, 4320, 135, 8640, 135, 135, 8640, 8640, 4320, 8640, 8640, 135, 8640, 4320, 4320, 135, 4320, 8640, 8640, 135, 8640, 4320, 135, 4320, 8640, 135, 135, 135, 135, 135, 135, 8640, 135, 135, 135, 8640, 135, 4320, 8640, 8640, 4320, 135, 8640, 135, 4320, 4320, 135, 4320, 135, 8640, 135, 135, 8640, 135, 8640, 8640, 4320, 8640, 4320, 135, 4320, 8640, 4320, 8640, 135, 8640, 135, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 135, 8640, 135, 8640, 4320, 4320, 135, 4320, 8640, 4320, 4320, 8640, 135, 8640, 8640, 4320, 135, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 135, 8640, 4320, 8640, 8640, 135, 8640, 4320, 4320, 8640, 135, 4320, 135, 135, 135, 135, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 135, 135, 135, 135]
Prompts retrieved: 1121715 . Total input tokens: 250060486 . Total output tokens: 224302544
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 4.149553072173148,
    "estimated_duration": 3600.1695106953243,
    "input_throughput": 3862.6475666458846,
    "output_throughput": 3393.145229331344,
    "total_throughput": 7255.792795977229,
    "itl": 247.7935196468409,
    "ttft": 2159786.6056726906,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 604,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8917953949933766,
    "arrivals": 374287,
    "finished_requests": 56065,
    "scheduler_time": 55.934044612613135
}
#Debug simulation 
Total elapsed time: 4.149641909170896. Arrivals time: 0.22795228334143758 Scheduler time: 3.835453181527555 Scheduler overhead time: 0.022572859190404415 Adapter cache time: 0.030350371729582548 Engine time: 0.02290151547640562 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-16-32/adapters_256_slots_192_rate_0.8-0.4-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-16-32/adapters_256_slots_192_rate_0.8-0.4-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 135, 8640, 8640, 135, 8640, 4320, 8640, 135, 4320, 135, 8640, 4320, 4320, 4320, 4320, 8640, 135, 135, 135, 4320, 8640, 135, 8640, 8640, 4320, 4320, 4320, 135, 8640, 135, 4320, 4320, 135, 4320, 135, 135, 4320, 4320, 8640, 4320, 135, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 135, 8640, 8640, 4320, 135, 135, 8640, 4320, 135, 4320, 4320, 8640, 4320, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 135, 4320, 135, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 135, 8640, 8640, 135, 8640, 135, 4320, 8640, 8640, 8640, 4320, 135, 8640, 4320, 135, 135, 135, 135, 135, 8640, 4320, 135, 8640, 135, 8640, 135, 135, 4320, 4320, 8640, 4320, 8640, 135, 4320, 135, 8640, 8640, 135, 8640, 4320, 135, 8640, 135, 135, 8640, 8640, 4320, 8640, 8640, 135, 8640, 4320, 4320, 135, 4320, 8640, 8640, 135, 8640, 4320, 135, 4320, 8640, 135, 135, 135, 135, 135, 135, 8640, 135, 135, 135, 8640, 135, 4320, 8640, 8640, 4320, 135, 8640, 135, 4320, 4320, 135, 4320, 135, 8640, 135, 135, 8640, 135, 8640, 8640, 4320, 8640, 4320, 135, 4320, 8640, 4320, 8640, 135, 8640, 135, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 135, 8640, 135, 8640, 4320, 4320, 135, 4320, 8640, 4320, 4320, 8640, 135, 8640, 8640, 4320, 135, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 135, 8640, 4320, 8640, 8640, 135, 8640, 4320, 4320, 8640, 135, 4320, 135, 135, 135, 135, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 135, 135, 135, 135]
Prompts retrieved: 1121715 . Total input tokens: 250060486 . Total output tokens: 224302544
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 3.9228544076904655,
    "estimated_duration": 3600.0238741021076,
    "input_throughput": 3320.7518666752394,
    "output_throughput": 2940.0827244902307,
    "total_throughput": 6260.83459116547,
    "itl": 113.60279589649113,
    "ttft": 2261137.1612229147,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 556,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.837933209165935,
    "arrivals": 374287,
    "finished_requests": 48252,
    "scheduler_time": 55.87280310040412
}
#Debug simulation 
Total elapsed time: 3.922945844940841. Arrivals time: 0.2109379442408681 Scheduler time: 3.458876586984843 Scheduler overhead time: 0.044386029709130526 Adapter cache time: 0.14255990320816636 Engine time: 0.04539253283292055 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_16-16-16/adapters_256_slots_192_rate_0.8-0.4-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_16-16-16/adapters_256_slots_192_rate_0.8-0.4-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 135, 8640, 8640, 135, 8640, 4320, 8640, 135, 4320, 135, 8640, 4320, 4320, 4320, 4320, 8640, 135, 135, 135, 4320, 8640, 135, 8640, 8640, 4320, 4320, 4320, 135, 8640, 135, 4320, 4320, 135, 4320, 135, 135, 4320, 4320, 8640, 4320, 135, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 135, 8640, 8640, 4320, 135, 135, 8640, 4320, 135, 4320, 4320, 8640, 4320, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 135, 4320, 135, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 135, 8640, 8640, 135, 8640, 135, 4320, 8640, 8640, 8640, 4320, 135, 8640, 4320, 135, 135, 135, 135, 135, 8640, 4320, 135, 8640, 135, 8640, 135, 135, 4320, 4320, 8640, 4320, 8640, 135, 4320, 135, 8640, 8640, 135, 8640, 4320, 135, 8640, 135, 135, 8640, 8640, 4320, 8640, 8640, 135, 8640, 4320, 4320, 135, 4320, 8640, 8640, 135, 8640, 4320, 135, 4320, 8640, 135, 135, 135, 135, 135, 135, 8640, 135, 135, 135, 8640, 135, 4320, 8640, 8640, 4320, 135, 8640, 135, 4320, 4320, 135, 4320, 135, 8640, 135, 135, 8640, 135, 8640, 8640, 4320, 8640, 4320, 135, 4320, 8640, 4320, 8640, 135, 8640, 135, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 135, 8640, 135, 8640, 4320, 4320, 135, 4320, 8640, 4320, 4320, 8640, 135, 8640, 8640, 4320, 135, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 135, 8640, 4320, 8640, 8640, 135, 8640, 4320, 4320, 8640, 135, 4320, 135, 135, 135, 135, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 135, 135, 135, 135]
Prompts retrieved: 1121715 . Total input tokens: 250060486 . Total output tokens: 224302544
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.162959835957736,
    "estimated_duration": 3600.1153334737983,
    "input_throughput": 3862.800691604902,
    "output_throughput": 3393.304344006209,
    "total_throughput": 7256.105035611111,
    "itl": 247.7801019902157,
    "ttft": 2159806.962364151,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 604,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8059903781208868,
    "arrivals": 374287,
    "finished_requests": 56066,
    "scheduler_time": 55.9343583288035
}
#Debug simulation 
Total elapsed time: 4.163061894942075. Arrivals time: 0.22909405827522278 Scheduler time: 3.847438346594572 Scheduler overhead time: 0.022540622856467962 Adapter cache time: 0.030507758259773254 Engine time: 0.02305776998400688 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_16-16-32/adapters_256_slots_192_rate_0.8-0.4-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_16-16-32/adapters_256_slots_192_rate_0.8-0.4-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 135, 8640, 8640, 135, 8640, 4320, 8640, 135, 4320, 135, 8640, 4320, 4320, 4320, 4320, 8640, 135, 135, 135, 4320, 8640, 135, 8640, 8640, 4320, 4320, 4320, 135, 8640, 135, 4320, 4320, 135, 4320, 135, 135, 4320, 4320, 8640, 4320, 135, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 135, 8640, 8640, 4320, 135, 135, 8640, 4320, 135, 4320, 4320, 8640, 4320, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 135, 4320, 135, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 135, 8640, 8640, 135, 8640, 135, 4320, 8640, 8640, 8640, 4320, 135, 8640, 4320, 135, 135, 135, 135, 135, 8640, 4320, 135, 8640, 135, 8640, 135, 135, 4320, 4320, 8640, 4320, 8640, 135, 4320, 135, 8640, 8640, 135, 8640, 4320, 135, 8640, 135, 135, 8640, 8640, 4320, 8640, 8640, 135, 8640, 4320, 4320, 135, 4320, 8640, 8640, 135, 8640, 4320, 135, 4320, 8640, 135, 135, 135, 135, 135, 135, 8640, 135, 135, 135, 8640, 135, 4320, 8640, 8640, 4320, 135, 8640, 135, 4320, 4320, 135, 4320, 135, 8640, 135, 135, 8640, 135, 8640, 8640, 4320, 8640, 4320, 135, 4320, 8640, 4320, 8640, 135, 8640, 135, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 135, 8640, 135, 8640, 4320, 4320, 135, 4320, 8640, 4320, 4320, 8640, 135, 8640, 8640, 4320, 135, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 135, 8640, 4320, 8640, 8640, 135, 8640, 4320, 4320, 8640, 135, 4320, 135, 135, 135, 135, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 135, 135, 135, 135]
Prompts retrieved: 1121715 . Total input tokens: 250060486 . Total output tokens: 224302544
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 3.933840489014983,
    "estimated_duration": 3600.0505669330087,
    "input_throughput": 3321.316125341664,
    "output_throughput": 2940.5059187872757,
    "total_throughput": 6261.8220441289395,
    "itl": 113.65466648010964,
    "ttft": 2260997.0713241515,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 557,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.86608747143298,
    "arrivals": 374287,
    "finished_requests": 48260,
    "scheduler_time": 55.875703158269175
}
#Debug simulation 
Total elapsed time: 3.933925817720592. Arrivals time: 0.21595426509156823 Scheduler time: 3.4619602863676846 Scheduler overhead time: 0.04445767914876342 Adapter cache time: 0.14538791123777628 Engine time: 0.045341705437749624 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-8/adapters_256_slots_192_rate_0.8-0.4-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-8/adapters_256_slots_192_rate_0.8-0.4-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 66, 8640, 8640, 66, 8640, 4320, 8640, 66, 4320, 66, 8640, 4320, 4320, 4320, 4320, 8640, 66, 66, 66, 4320, 8640, 66, 8640, 8640, 4320, 4320, 4320, 66, 8640, 66, 4320, 4320, 66, 4320, 66, 66, 4320, 4320, 8640, 4320, 66, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 66, 8640, 8640, 4320, 66, 66, 8640, 4320, 66, 4320, 4320, 8640, 4320, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 66, 4320, 66, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 66, 8640, 8640, 66, 8640, 66, 4320, 8640, 8640, 8640, 4320, 66, 8640, 4320, 66, 66, 66, 66, 66, 8640, 4320, 66, 8640, 66, 8640, 66, 66, 4320, 4320, 8640, 4320, 8640, 66, 4320, 66, 8640, 8640, 66, 8640, 4320, 66, 8640, 66, 66, 8640, 8640, 4320, 8640, 8640, 66, 8640, 4320, 4320, 66, 4320, 8640, 8640, 66, 8640, 4320, 66, 4320, 8640, 66, 66, 66, 66, 66, 66, 8640, 66, 66, 66, 8640, 66, 4320, 8640, 8640, 4320, 66, 8640, 66, 4320, 4320, 66, 4320, 66, 8640, 66, 66, 8640, 66, 8640, 8640, 4320, 8640, 4320, 66, 4320, 8640, 4320, 8640, 66, 8640, 66, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 66, 8640, 66, 8640, 4320, 4320, 66, 4320, 8640, 4320, 4320, 8640, 66, 8640, 8640, 4320, 66, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 66, 8640, 4320, 8640, 8640, 66, 8640, 4320, 4320, 8640, 66, 4320, 66, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 66, 66, 66, 66]
Prompts retrieved: 1115850 . Total input tokens: 248770296 . Total output tokens: 223140963
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.183977665379643,
    "estimated_duration": 3600.1653451735483,
    "input_throughput": 3920.001346304746,
    "output_throughput": 3464.2847770089793,
    "total_throughput": 7384.2861233137255,
    "itl": 247.1975400471132,
    "ttft": 2149408.9001796627,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 375,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1476829039747865,
    "arrivals": 372356,
    "finished_requests": 57013,
    "scheduler_time": 56.97179384895216
}
#Debug simulation 
Total elapsed time: 4.18407616019249. Arrivals time: 0.19933424470946193 Scheduler time: 3.9053158429451287 Scheduler overhead time: 0.022655384615063667 Adapter cache time: 0.02331722155213356 Engine time: 0.022958592046052217 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-16/adapters_256_slots_192_rate_0.8-0.4-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-16/adapters_256_slots_192_rate_0.8-0.4-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 66, 8640, 8640, 66, 8640, 4320, 8640, 66, 4320, 66, 8640, 4320, 4320, 4320, 4320, 8640, 66, 66, 66, 4320, 8640, 66, 8640, 8640, 4320, 4320, 4320, 66, 8640, 66, 4320, 4320, 66, 4320, 66, 66, 4320, 4320, 8640, 4320, 66, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 66, 8640, 8640, 4320, 66, 66, 8640, 4320, 66, 4320, 4320, 8640, 4320, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 66, 4320, 66, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 66, 8640, 8640, 66, 8640, 66, 4320, 8640, 8640, 8640, 4320, 66, 8640, 4320, 66, 66, 66, 66, 66, 8640, 4320, 66, 8640, 66, 8640, 66, 66, 4320, 4320, 8640, 4320, 8640, 66, 4320, 66, 8640, 8640, 66, 8640, 4320, 66, 8640, 66, 66, 8640, 8640, 4320, 8640, 8640, 66, 8640, 4320, 4320, 66, 4320, 8640, 8640, 66, 8640, 4320, 66, 4320, 8640, 66, 66, 66, 66, 66, 66, 8640, 66, 66, 66, 8640, 66, 4320, 8640, 8640, 4320, 66, 8640, 66, 4320, 4320, 66, 4320, 66, 8640, 66, 66, 8640, 66, 8640, 8640, 4320, 8640, 4320, 66, 4320, 8640, 4320, 8640, 66, 8640, 66, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 66, 8640, 66, 8640, 4320, 4320, 66, 4320, 8640, 4320, 4320, 8640, 66, 8640, 8640, 4320, 66, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 66, 8640, 4320, 8640, 8640, 66, 8640, 4320, 4320, 8640, 66, 4320, 66, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 66, 66, 66, 66]
Prompts retrieved: 1115850 . Total input tokens: 248770296 . Total output tokens: 223140963
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.188332866877317,
    "estimated_duration": 3600.121669684296,
    "input_throughput": 3913.727449449112,
    "output_throughput": 3457.9856299944718,
    "total_throughput": 7371.713079443584,
    "itl": 243.7669885959223,
    "ttft": 2151487.674614928,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 375,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2242348808352903,
    "arrivals": 372356,
    "finished_requests": 56908,
    "scheduler_time": 56.93556531180377
}
#Debug simulation 
Total elapsed time: 4.188424691092223. Arrivals time: 0.19976561376824975 Scheduler time: 3.9069279530085623 Scheduler overhead time: 0.023002993781119585 Adapter cache time: 0.024635428562760353 Engine time: 0.02349459705874324 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-32/adapters_256_slots_192_rate_0.8-0.4-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-32/adapters_256_slots_192_rate_0.8-0.4-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 66, 8640, 8640, 66, 8640, 4320, 8640, 66, 4320, 66, 8640, 4320, 4320, 4320, 4320, 8640, 66, 66, 66, 4320, 8640, 66, 8640, 8640, 4320, 4320, 4320, 66, 8640, 66, 4320, 4320, 66, 4320, 66, 66, 4320, 4320, 8640, 4320, 66, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 66, 8640, 8640, 4320, 66, 66, 8640, 4320, 66, 4320, 4320, 8640, 4320, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 66, 4320, 66, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 66, 8640, 8640, 66, 8640, 66, 4320, 8640, 8640, 8640, 4320, 66, 8640, 4320, 66, 66, 66, 66, 66, 8640, 4320, 66, 8640, 66, 8640, 66, 66, 4320, 4320, 8640, 4320, 8640, 66, 4320, 66, 8640, 8640, 66, 8640, 4320, 66, 8640, 66, 66, 8640, 8640, 4320, 8640, 8640, 66, 8640, 4320, 4320, 66, 4320, 8640, 8640, 66, 8640, 4320, 66, 4320, 8640, 66, 66, 66, 66, 66, 66, 8640, 66, 66, 66, 8640, 66, 4320, 8640, 8640, 4320, 66, 8640, 66, 4320, 4320, 66, 4320, 66, 8640, 66, 66, 8640, 66, 8640, 8640, 4320, 8640, 4320, 66, 4320, 8640, 4320, 8640, 66, 8640, 66, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 66, 8640, 66, 8640, 4320, 4320, 66, 4320, 8640, 4320, 4320, 8640, 66, 8640, 8640, 4320, 66, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 66, 8640, 4320, 8640, 8640, 66, 8640, 4320, 4320, 8640, 66, 4320, 66, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 66, 66, 66, 66]
Prompts retrieved: 1115850 . Total input tokens: 248770296 . Total output tokens: 223140963
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 3.9090673900209367,
    "estimated_duration": 3600.1193229174282,
    "input_throughput": 3338.161300237447,
    "output_throughput": 2974.726124166754,
    "total_throughput": 6312.887424404201,
    "itl": 113.60352156459989,
    "ttft": 2257711.754811586,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 342,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1181131225265624,
    "arrivals": 372356,
    "finished_requests": 48577,
    "scheduler_time": 56.39417522269774
}
#Debug simulation 
Total elapsed time: 3.909174044150859. Arrivals time: 0.19680022215470672 Scheduler time: 3.4647892704233527 Scheduler overhead time: 0.04441047366708517 Adapter cache time: 0.13679245067760348 Engine time: 0.04558964353054762 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-16-16/adapters_256_slots_192_rate_0.8-0.4-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-16-16/adapters_256_slots_192_rate_0.8-0.4-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 66, 8640, 8640, 66, 8640, 4320, 8640, 66, 4320, 66, 8640, 4320, 4320, 4320, 4320, 8640, 66, 66, 66, 4320, 8640, 66, 8640, 8640, 4320, 4320, 4320, 66, 8640, 66, 4320, 4320, 66, 4320, 66, 66, 4320, 4320, 8640, 4320, 66, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 66, 8640, 8640, 4320, 66, 66, 8640, 4320, 66, 4320, 4320, 8640, 4320, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 66, 4320, 66, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 66, 8640, 8640, 66, 8640, 66, 4320, 8640, 8640, 8640, 4320, 66, 8640, 4320, 66, 66, 66, 66, 66, 8640, 4320, 66, 8640, 66, 8640, 66, 66, 4320, 4320, 8640, 4320, 8640, 66, 4320, 66, 8640, 8640, 66, 8640, 4320, 66, 8640, 66, 66, 8640, 8640, 4320, 8640, 8640, 66, 8640, 4320, 4320, 66, 4320, 8640, 8640, 66, 8640, 4320, 66, 4320, 8640, 66, 66, 66, 66, 66, 66, 8640, 66, 66, 66, 8640, 66, 4320, 8640, 8640, 4320, 66, 8640, 66, 4320, 4320, 66, 4320, 66, 8640, 66, 66, 8640, 66, 8640, 8640, 4320, 8640, 4320, 66, 4320, 8640, 4320, 8640, 66, 8640, 66, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 66, 8640, 66, 8640, 4320, 4320, 66, 4320, 8640, 4320, 4320, 8640, 66, 8640, 8640, 4320, 66, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 66, 8640, 4320, 8640, 8640, 66, 8640, 4320, 4320, 8640, 66, 4320, 66, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 66, 66, 66, 66]
Prompts retrieved: 1115850 . Total input tokens: 248770296 . Total output tokens: 223140963
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 4.390195306856185,
    "estimated_duration": 3600.00802729159,
    "input_throughput": 3913.850439550356,
    "output_throughput": 3458.0653447503164,
    "total_throughput": 7371.915784300672,
    "itl": 243.78237965644473,
    "ttft": 2151417.862616689,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 375,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1743862519855623,
    "arrivals": 372356,
    "finished_requests": 56906,
    "scheduler_time": 56.93436670038174
}
#Debug simulation 
Total elapsed time: 4.3902627769857645. Arrivals time: 0.20320277614519 Scheduler time: 4.1065182643942535 Scheduler overhead time: 0.022807522676885128 Adapter cache time: 0.024087376426905394 Engine time: 0.023117182310670614 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-16-32/adapters_256_slots_192_rate_0.8-0.4-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-16-32/adapters_256_slots_192_rate_0.8-0.4-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 66, 8640, 8640, 66, 8640, 4320, 8640, 66, 4320, 66, 8640, 4320, 4320, 4320, 4320, 8640, 66, 66, 66, 4320, 8640, 66, 8640, 8640, 4320, 4320, 4320, 66, 8640, 66, 4320, 4320, 66, 4320, 66, 66, 4320, 4320, 8640, 4320, 66, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 66, 8640, 8640, 4320, 66, 66, 8640, 4320, 66, 4320, 4320, 8640, 4320, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 66, 4320, 66, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 66, 8640, 8640, 66, 8640, 66, 4320, 8640, 8640, 8640, 4320, 66, 8640, 4320, 66, 66, 66, 66, 66, 8640, 4320, 66, 8640, 66, 8640, 66, 66, 4320, 4320, 8640, 4320, 8640, 66, 4320, 66, 8640, 8640, 66, 8640, 4320, 66, 8640, 66, 66, 8640, 8640, 4320, 8640, 8640, 66, 8640, 4320, 4320, 66, 4320, 8640, 8640, 66, 8640, 4320, 66, 4320, 8640, 66, 66, 66, 66, 66, 66, 8640, 66, 66, 66, 8640, 66, 4320, 8640, 8640, 4320, 66, 8640, 66, 4320, 4320, 66, 4320, 66, 8640, 66, 66, 8640, 66, 8640, 8640, 4320, 8640, 4320, 66, 4320, 8640, 4320, 8640, 66, 8640, 66, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 66, 8640, 66, 8640, 4320, 4320, 66, 4320, 8640, 4320, 4320, 8640, 66, 8640, 8640, 4320, 66, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 66, 8640, 4320, 8640, 8640, 66, 8640, 4320, 4320, 8640, 66, 4320, 66, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 66, 66, 66, 66]
Prompts retrieved: 1115850 . Total input tokens: 248770296 . Total output tokens: 223140963
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 3.947453922126442,
    "estimated_duration": 3600.060343085468,
    "input_throughput": 3338.077102813357,
    "output_throughput": 2974.6359725797975,
    "total_throughput": 6312.713075393154,
    "itl": 113.60222040054414,
    "ttft": 2257730.3516924307,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 342,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1323233003914401,
    "arrivals": 372356,
    "finished_requests": 48575,
    "scheduler_time": 56.394875956211365
}
#Debug simulation 
Total elapsed time: 3.9475412741303444. Arrivals time: 0.1975967134349048 Scheduler time: 3.501548934727907 Scheduler overhead time: 0.044460603035986423 Adapter cache time: 0.13775046542286873 Engine time: 0.0453827022574842 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_16-16-16/adapters_256_slots_192_rate_0.8-0.4-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_16-16-16/adapters_256_slots_192_rate_0.8-0.4-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 66, 8640, 8640, 66, 8640, 4320, 8640, 66, 4320, 66, 8640, 4320, 4320, 4320, 4320, 8640, 66, 66, 66, 4320, 8640, 66, 8640, 8640, 4320, 4320, 4320, 66, 8640, 66, 4320, 4320, 66, 4320, 66, 66, 4320, 4320, 8640, 4320, 66, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 66, 8640, 8640, 4320, 66, 66, 8640, 4320, 66, 4320, 4320, 8640, 4320, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 66, 4320, 66, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 66, 8640, 8640, 66, 8640, 66, 4320, 8640, 8640, 8640, 4320, 66, 8640, 4320, 66, 66, 66, 66, 66, 8640, 4320, 66, 8640, 66, 8640, 66, 66, 4320, 4320, 8640, 4320, 8640, 66, 4320, 66, 8640, 8640, 66, 8640, 4320, 66, 8640, 66, 66, 8640, 8640, 4320, 8640, 8640, 66, 8640, 4320, 4320, 66, 4320, 8640, 8640, 66, 8640, 4320, 66, 4320, 8640, 66, 66, 66, 66, 66, 66, 8640, 66, 66, 66, 8640, 66, 4320, 8640, 8640, 4320, 66, 8640, 66, 4320, 4320, 66, 4320, 66, 8640, 66, 66, 8640, 66, 8640, 8640, 4320, 8640, 4320, 66, 4320, 8640, 4320, 8640, 66, 8640, 66, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 66, 8640, 66, 8640, 4320, 4320, 66, 4320, 8640, 4320, 4320, 8640, 66, 8640, 8640, 4320, 66, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 66, 8640, 4320, 8640, 8640, 66, 8640, 4320, 4320, 8640, 66, 4320, 66, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 66, 66, 66, 66]
Prompts retrieved: 1115850 . Total input tokens: 248770296 . Total output tokens: 223140963
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.162918369751424,
    "estimated_duration": 3600.0386496567553,
    "input_throughput": 3913.8177034136556,
    "output_throughput": 3458.0653741556252,
    "total_throughput": 7371.883077569281,
    "itl": 243.7580121139324,
    "ttft": 2151451.2388361027,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 375,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.121268860588313,
    "arrivals": 372356,
    "finished_requests": 56908,
    "scheduler_time": 56.93538426089514
}
#Debug simulation 
Total elapsed time: 4.163005968090147. Arrivals time: 0.1987582161091268 Scheduler time: 3.883266204968095 Scheduler overhead time: 0.022931356448680162 Adapter cache time: 0.024229377042502165 Engine time: 0.023214766290038824 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_16-16-32/adapters_256_slots_192_rate_0.8-0.4-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_16-16-32/adapters_256_slots_192_rate_0.8-0.4-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 66, 8640, 8640, 66, 8640, 4320, 8640, 66, 4320, 66, 8640, 4320, 4320, 4320, 4320, 8640, 66, 66, 66, 4320, 8640, 66, 8640, 8640, 4320, 4320, 4320, 66, 8640, 66, 4320, 4320, 66, 4320, 66, 66, 4320, 4320, 8640, 4320, 66, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 66, 8640, 8640, 4320, 66, 66, 8640, 4320, 66, 4320, 4320, 8640, 4320, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 66, 4320, 66, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 66, 8640, 8640, 66, 8640, 66, 4320, 8640, 8640, 8640, 4320, 66, 8640, 4320, 66, 66, 66, 66, 66, 8640, 4320, 66, 8640, 66, 8640, 66, 66, 4320, 4320, 8640, 4320, 8640, 66, 4320, 66, 8640, 8640, 66, 8640, 4320, 66, 8640, 66, 66, 8640, 8640, 4320, 8640, 8640, 66, 8640, 4320, 4320, 66, 4320, 8640, 8640, 66, 8640, 4320, 66, 4320, 8640, 66, 66, 66, 66, 66, 66, 8640, 66, 66, 66, 8640, 66, 4320, 8640, 8640, 4320, 66, 8640, 66, 4320, 4320, 66, 4320, 66, 8640, 66, 66, 8640, 66, 8640, 8640, 4320, 8640, 4320, 66, 4320, 8640, 4320, 8640, 66, 8640, 66, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 66, 8640, 66, 8640, 4320, 4320, 66, 4320, 8640, 4320, 4320, 8640, 66, 8640, 8640, 4320, 66, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 66, 8640, 4320, 8640, 8640, 66, 8640, 4320, 4320, 8640, 66, 4320, 66, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 66, 66, 66, 66]
Prompts retrieved: 1115850 . Total input tokens: 248770296 . Total output tokens: 223140963
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 3.890997970942408,
    "estimated_duration": 3600.081187549526,
    "input_throughput": 3338.171383901512,
    "output_throughput": 2974.81707830309,
    "total_throughput": 6312.988462204602,
    "itl": 113.60339259437974,
    "ttft": 2257734.1558577283,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 342,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.146910739615563,
    "arrivals": 372356,
    "finished_requests": 48576,
    "scheduler_time": 56.39379523320615
}
#Debug simulation 
Total elapsed time: 3.891084719914943. Arrivals time: 0.1823847251944244 Scheduler time: 3.4615510129369795 Scheduler overhead time: 0.0443605026230216 Adapter cache time: 0.13691521948203444 Engine time: 0.04512361902743578 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-8/adapters_256_slots_192_rate_0.8-0.4-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-8/adapters_256_slots_192_rate_0.8-0.4-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 33, 8640, 8640, 33, 8640, 4320, 8640, 33, 4320, 33, 8640, 4320, 4320, 4320, 4320, 8640, 33, 33, 33, 4320, 8640, 33, 8640, 8640, 4320, 4320, 4320, 33, 8640, 33, 4320, 4320, 33, 4320, 33, 33, 4320, 4320, 8640, 4320, 33, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 33, 8640, 8640, 4320, 33, 33, 8640, 4320, 33, 4320, 4320, 8640, 4320, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 4320, 33, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 33, 8640, 8640, 33, 8640, 33, 4320, 8640, 8640, 8640, 4320, 33, 8640, 4320, 33, 33, 33, 33, 33, 8640, 4320, 33, 8640, 33, 8640, 33, 33, 4320, 4320, 8640, 4320, 8640, 33, 4320, 33, 8640, 8640, 33, 8640, 4320, 33, 8640, 33, 33, 8640, 8640, 4320, 8640, 8640, 33, 8640, 4320, 4320, 33, 4320, 8640, 8640, 33, 8640, 4320, 33, 4320, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 4320, 8640, 8640, 4320, 33, 8640, 33, 4320, 4320, 33, 4320, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 4320, 8640, 4320, 33, 4320, 8640, 4320, 8640, 33, 8640, 33, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 33, 8640, 33, 8640, 4320, 4320, 33, 4320, 8640, 4320, 4320, 8640, 33, 8640, 8640, 4320, 33, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 33, 8640, 4320, 8640, 8640, 33, 8640, 4320, 4320, 8640, 33, 4320, 33, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 33, 33, 33, 33]
Prompts retrieved: 1113045 . Total input tokens: 248170653 . Total output tokens: 222577894
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.21310165990144,
    "estimated_duration": 3600.007952874366,
    "input_throughput": 3970.789283558804,
    "output_throughput": 3483.515915565437,
    "total_throughput": 7454.305199124241,
    "itl": 244.5003198891367,
    "ttft": 2134171.3726729937,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 280,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8569365683011699,
    "arrivals": 371350,
    "finished_requests": 57823,
    "scheduler_time": 57.2901159044522
}
#Debug simulation 
Total elapsed time: 4.21319342777133. Arrivals time: 0.20157641312107444 Scheduler time: 3.935426291078329 Scheduler overhead time: 0.022754031233489513 Adapter cache time: 0.019810471683740616 Engine time: 0.023092404007911682 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-16/adapters_256_slots_192_rate_0.8-0.4-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-16/adapters_256_slots_192_rate_0.8-0.4-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 33, 8640, 8640, 33, 8640, 4320, 8640, 33, 4320, 33, 8640, 4320, 4320, 4320, 4320, 8640, 33, 33, 33, 4320, 8640, 33, 8640, 8640, 4320, 4320, 4320, 33, 8640, 33, 4320, 4320, 33, 4320, 33, 33, 4320, 4320, 8640, 4320, 33, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 33, 8640, 8640, 4320, 33, 33, 8640, 4320, 33, 4320, 4320, 8640, 4320, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 4320, 33, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 33, 8640, 8640, 33, 8640, 33, 4320, 8640, 8640, 8640, 4320, 33, 8640, 4320, 33, 33, 33, 33, 33, 8640, 4320, 33, 8640, 33, 8640, 33, 33, 4320, 4320, 8640, 4320, 8640, 33, 4320, 33, 8640, 8640, 33, 8640, 4320, 33, 8640, 33, 33, 8640, 8640, 4320, 8640, 8640, 33, 8640, 4320, 4320, 33, 4320, 8640, 8640, 33, 8640, 4320, 33, 4320, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 4320, 8640, 8640, 4320, 33, 8640, 33, 4320, 4320, 33, 4320, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 4320, 8640, 4320, 33, 4320, 8640, 4320, 8640, 33, 8640, 33, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 33, 8640, 33, 8640, 4320, 4320, 33, 4320, 8640, 4320, 4320, 8640, 33, 8640, 8640, 4320, 33, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 33, 8640, 4320, 8640, 8640, 33, 8640, 4320, 4320, 8640, 33, 4320, 33, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 33, 33, 33, 33]
Prompts retrieved: 1113045 . Total input tokens: 248170653 . Total output tokens: 222577894
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.171244250610471,
    "estimated_duration": 3600.1791055054737,
    "input_throughput": 3963.9766749872056,
    "output_throughput": 3477.835861236144,
    "total_throughput": 7441.8125362233495,
    "itl": 241.49406711936984,
    "ttft": 2135263.7696103225,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 280,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9140300024393992,
    "arrivals": 371350,
    "finished_requests": 57730,
    "scheduler_time": 57.26351477948554
}
#Debug simulation 
Total elapsed time: 4.171333748847246. Arrivals time: 0.20047373604029417 Scheduler time: 3.893148190807551 Scheduler overhead time: 0.023029897827655077 Adapter cache time: 0.020554335322231054 Engine time: 0.023487338330596685 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-32/adapters_256_slots_192_rate_0.8-0.4-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-32/adapters_256_slots_192_rate_0.8-0.4-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 33, 8640, 8640, 33, 8640, 4320, 8640, 33, 4320, 33, 8640, 4320, 4320, 4320, 4320, 8640, 33, 33, 33, 4320, 8640, 33, 8640, 8640, 4320, 4320, 4320, 33, 8640, 33, 4320, 4320, 33, 4320, 33, 33, 4320, 4320, 8640, 4320, 33, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 33, 8640, 8640, 4320, 33, 33, 8640, 4320, 33, 4320, 4320, 8640, 4320, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 4320, 33, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 33, 8640, 8640, 33, 8640, 33, 4320, 8640, 8640, 8640, 4320, 33, 8640, 4320, 33, 33, 33, 33, 33, 8640, 4320, 33, 8640, 33, 8640, 33, 33, 4320, 4320, 8640, 4320, 8640, 33, 4320, 33, 8640, 8640, 33, 8640, 4320, 33, 8640, 33, 33, 8640, 8640, 4320, 8640, 8640, 33, 8640, 4320, 4320, 33, 4320, 8640, 8640, 33, 8640, 4320, 33, 4320, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 4320, 8640, 8640, 4320, 33, 8640, 33, 4320, 4320, 33, 4320, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 4320, 8640, 4320, 33, 4320, 8640, 4320, 8640, 33, 8640, 33, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 33, 8640, 33, 8640, 4320, 4320, 33, 4320, 8640, 4320, 4320, 8640, 33, 8640, 8640, 4320, 33, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 33, 8640, 4320, 8640, 8640, 33, 8640, 4320, 4320, 8640, 33, 4320, 33, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 33, 33, 33, 33]
Prompts retrieved: 1113045 . Total input tokens: 248170653 . Total output tokens: 222577894
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.1293074120767415,
    "estimated_duration": 3600.019713142586,
    "input_throughput": 3359.37104895542,
    "output_throughput": 2966.1070913077733,
    "total_throughput": 6325.478140263193,
    "itl": 112.63082873249046,
    "ttft": 2248518.2912741154,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 266,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8699433152936442,
    "arrivals": 371350,
    "finished_requests": 48919,
    "scheduler_time": 56.389129448668555
}
#Debug simulation 
Total elapsed time: 4.129370820708573. Arrivals time: 0.184941285289824 Scheduler time: 3.6942721814848483 Scheduler overhead time: 0.04461490502581 Adapter cache time: 0.13893639435991645 Engine time: 0.04576092306524515 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-16-16/adapters_256_slots_192_rate_0.8-0.4-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-16-16/adapters_256_slots_192_rate_0.8-0.4-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 33, 8640, 8640, 33, 8640, 4320, 8640, 33, 4320, 33, 8640, 4320, 4320, 4320, 4320, 8640, 33, 33, 33, 4320, 8640, 33, 8640, 8640, 4320, 4320, 4320, 33, 8640, 33, 4320, 4320, 33, 4320, 33, 33, 4320, 4320, 8640, 4320, 33, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 33, 8640, 8640, 4320, 33, 33, 8640, 4320, 33, 4320, 4320, 8640, 4320, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 4320, 33, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 33, 8640, 8640, 33, 8640, 33, 4320, 8640, 8640, 8640, 4320, 33, 8640, 4320, 33, 33, 33, 33, 33, 8640, 4320, 33, 8640, 33, 8640, 33, 33, 4320, 4320, 8640, 4320, 8640, 33, 4320, 33, 8640, 8640, 33, 8640, 4320, 33, 8640, 33, 33, 8640, 8640, 4320, 8640, 8640, 33, 8640, 4320, 4320, 33, 4320, 8640, 8640, 33, 8640, 4320, 33, 4320, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 4320, 8640, 8640, 4320, 33, 8640, 33, 4320, 4320, 33, 4320, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 4320, 8640, 4320, 33, 4320, 8640, 4320, 8640, 33, 8640, 33, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 33, 8640, 33, 8640, 4320, 4320, 33, 4320, 8640, 4320, 4320, 8640, 33, 8640, 8640, 4320, 33, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 33, 8640, 4320, 8640, 8640, 33, 8640, 4320, 4320, 8640, 33, 4320, 33, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 33, 33, 33, 33]
Prompts retrieved: 1113045 . Total input tokens: 248170653 . Total output tokens: 222577894
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 4.187846091110259,
    "estimated_duration": 3600.1675744415784,
    "input_throughput": 3963.9893713040783,
    "output_throughput": 3477.8470004808332,
    "total_throughput": 7441.8363717849115,
    "itl": 241.48294318948524,
    "ttft": 2135258.1386241624,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 280,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8764392331428855,
    "arrivals": 371350,
    "finished_requests": 57730,
    "scheduler_time": 57.263527610994466
}
#Debug simulation 
Total elapsed time: 4.187946371268481. Arrivals time: 0.20162477111443877 Scheduler time: 3.9084028862416744 Scheduler overhead time: 0.022966776974499226 Adapter cache time: 0.02090991521254182 Engine time: 0.02337686438113451 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-16-32/adapters_256_slots_192_rate_0.8-0.4-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-16-32/adapters_256_slots_192_rate_0.8-0.4-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 33, 8640, 8640, 33, 8640, 4320, 8640, 33, 4320, 33, 8640, 4320, 4320, 4320, 4320, 8640, 33, 33, 33, 4320, 8640, 33, 8640, 8640, 4320, 4320, 4320, 33, 8640, 33, 4320, 4320, 33, 4320, 33, 33, 4320, 4320, 8640, 4320, 33, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 33, 8640, 8640, 4320, 33, 33, 8640, 4320, 33, 4320, 4320, 8640, 4320, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 4320, 33, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 33, 8640, 8640, 33, 8640, 33, 4320, 8640, 8640, 8640, 4320, 33, 8640, 4320, 33, 33, 33, 33, 33, 8640, 4320, 33, 8640, 33, 8640, 33, 33, 4320, 4320, 8640, 4320, 8640, 33, 4320, 33, 8640, 8640, 33, 8640, 4320, 33, 8640, 33, 33, 8640, 8640, 4320, 8640, 8640, 33, 8640, 4320, 4320, 33, 4320, 8640, 8640, 33, 8640, 4320, 33, 4320, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 4320, 8640, 8640, 4320, 33, 8640, 33, 4320, 4320, 33, 4320, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 4320, 8640, 4320, 33, 4320, 8640, 4320, 8640, 33, 8640, 33, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 33, 8640, 33, 8640, 4320, 4320, 33, 4320, 8640, 4320, 4320, 8640, 33, 8640, 8640, 4320, 33, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 33, 8640, 4320, 8640, 8640, 33, 8640, 4320, 4320, 8640, 33, 4320, 33, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 33, 33, 33, 33]
Prompts retrieved: 1113045 . Total input tokens: 248170653 . Total output tokens: 222577894
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 3.893915819004178,
    "estimated_duration": 3600.00496443715,
    "input_throughput": 3358.242591171034,
    "output_throughput": 2964.846467001682,
    "total_throughput": 6323.089058172715,
    "itl": 112.4726994517795,
    "ttft": 2248983.414281572,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 266,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8806323871389072,
    "arrivals": 371350,
    "finished_requests": 48903,
    "scheduler_time": 56.38382300482198
}
#Debug simulation 
Total elapsed time: 3.8940028669312596. Arrivals time: 0.1830020509660244 Scheduler time: 3.4644104498438537 Scheduler overhead time: 0.044834667816758156 Adapter cache time: 0.13497588876634836 Engine time: 0.045807423535734415 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_16-16-16/adapters_256_slots_192_rate_0.8-0.4-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_16-16-16/adapters_256_slots_192_rate_0.8-0.4-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 33, 8640, 8640, 33, 8640, 4320, 8640, 33, 4320, 33, 8640, 4320, 4320, 4320, 4320, 8640, 33, 33, 33, 4320, 8640, 33, 8640, 8640, 4320, 4320, 4320, 33, 8640, 33, 4320, 4320, 33, 4320, 33, 33, 4320, 4320, 8640, 4320, 33, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 33, 8640, 8640, 4320, 33, 33, 8640, 4320, 33, 4320, 4320, 8640, 4320, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 4320, 33, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 33, 8640, 8640, 33, 8640, 33, 4320, 8640, 8640, 8640, 4320, 33, 8640, 4320, 33, 33, 33, 33, 33, 8640, 4320, 33, 8640, 33, 8640, 33, 33, 4320, 4320, 8640, 4320, 8640, 33, 4320, 33, 8640, 8640, 33, 8640, 4320, 33, 8640, 33, 33, 8640, 8640, 4320, 8640, 8640, 33, 8640, 4320, 4320, 33, 4320, 8640, 8640, 33, 8640, 4320, 33, 4320, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 4320, 8640, 8640, 4320, 33, 8640, 33, 4320, 4320, 33, 4320, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 4320, 8640, 4320, 33, 4320, 8640, 4320, 8640, 33, 8640, 33, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 33, 8640, 33, 8640, 4320, 4320, 33, 4320, 8640, 4320, 4320, 8640, 33, 8640, 8640, 4320, 33, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 33, 8640, 4320, 8640, 8640, 33, 8640, 4320, 4320, 8640, 33, 4320, 33, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 33, 33, 33, 33]
Prompts retrieved: 1113045 . Total input tokens: 248170653 . Total output tokens: 222577894
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.17397699598223,
    "estimated_duration": 3600.1251315559653,
    "input_throughput": 3964.0361038873384,
    "output_throughput": 3477.8880017952397,
    "total_throughput": 7441.924105682578,
    "itl": 241.48828702040842,
    "ttft": 2135234.3261290467,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 280,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8372140825726103,
    "arrivals": 371350,
    "finished_requests": 57730,
    "scheduler_time": 57.26333262477495
}
#Debug simulation 
Total elapsed time: 4.174070632550865. Arrivals time: 0.2010816466063261 Scheduler time: 3.895119400229305 Scheduler overhead time: 0.022995244711637497 Adapter cache time: 0.020568573381751776 Engine time: 0.023483201395720243 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_16-16-32/adapters_256_slots_192_rate_0.8-0.4-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_16-16-32/adapters_256_slots_192_rate_0.8-0.4-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 8640, 33, 8640, 8640, 33, 8640, 4320, 8640, 33, 4320, 33, 8640, 4320, 4320, 4320, 4320, 8640, 33, 33, 33, 4320, 8640, 33, 8640, 8640, 4320, 4320, 4320, 33, 8640, 33, 4320, 4320, 33, 4320, 33, 33, 4320, 4320, 8640, 4320, 33, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 33, 8640, 8640, 4320, 33, 33, 8640, 4320, 33, 4320, 4320, 8640, 4320, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 4320, 33, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 33, 8640, 8640, 33, 8640, 33, 4320, 8640, 8640, 8640, 4320, 33, 8640, 4320, 33, 33, 33, 33, 33, 8640, 4320, 33, 8640, 33, 8640, 33, 33, 4320, 4320, 8640, 4320, 8640, 33, 4320, 33, 8640, 8640, 33, 8640, 4320, 33, 8640, 33, 33, 8640, 8640, 4320, 8640, 8640, 33, 8640, 4320, 4320, 33, 4320, 8640, 8640, 33, 8640, 4320, 33, 4320, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 4320, 8640, 8640, 4320, 33, 8640, 33, 4320, 4320, 33, 4320, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 4320, 8640, 4320, 33, 4320, 8640, 4320, 8640, 33, 8640, 33, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 4320, 33, 8640, 33, 8640, 4320, 4320, 33, 4320, 8640, 4320, 4320, 8640, 33, 8640, 8640, 4320, 33, 8640, 8640, 4320, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 4320, 4320, 8640, 33, 8640, 4320, 8640, 8640, 33, 8640, 4320, 4320, 8640, 33, 4320, 33, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 33, 33, 33, 33]
Prompts retrieved: 1113045 . Total input tokens: 248170653 . Total output tokens: 222577894
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 3.8871530471369624,
    "estimated_duration": 3600.020095176861,
    "input_throughput": 3361.6162354797802,
    "output_throughput": 2968.158709534939,
    "total_throughput": 6329.774945014719,
    "itl": 112.86972173967673,
    "ttft": 2248234.34148374,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 266,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8924532430619044,
    "arrivals": 371350,
    "finished_requests": 48954,
    "scheduler_time": 56.387309672032856
}
#Debug simulation 
Total elapsed time: 3.8872393500059843. Arrivals time: 0.18321438040584326 Scheduler time: 3.4566507767885923 Scheduler overhead time: 0.044605959206819534 Adapter cache time: 0.13625735230743885 Engine time: 0.04559518350288272 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-8-8/adapters_256_slots_192_rate_0.8-0.1-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-8-8/adapters_256_slots_192_rate_0.8-0.1-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 540, 8640, 8640, 540, 8640, 1080, 8640, 540, 1080, 540, 8640, 1080, 1080, 1080, 1080, 8640, 540, 540, 540, 1080, 8640, 540, 8640, 8640, 1080, 1080, 1080, 540, 8640, 540, 1080, 1080, 540, 1080, 540, 540, 1080, 1080, 8640, 1080, 540, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 540, 8640, 8640, 1080, 540, 540, 8640, 1080, 540, 1080, 1080, 8640, 1080, 540, 540, 8640, 8640, 8640, 8640, 8640, 8640, 540, 1080, 540, 1080, 540, 540, 540, 1080, 1080, 1080, 540, 540, 8640, 8640, 540, 8640, 540, 1080, 8640, 8640, 8640, 1080, 540, 8640, 1080, 540, 540, 540, 540, 540, 8640, 1080, 540, 8640, 540, 8640, 540, 540, 1080, 1080, 8640, 1080, 8640, 540, 1080, 540, 8640, 8640, 540, 8640, 1080, 540, 8640, 540, 540, 8640, 8640, 1080, 8640, 8640, 540, 8640, 1080, 1080, 540, 1080, 8640, 8640, 540, 8640, 1080, 540, 1080, 8640, 540, 540, 540, 540, 540, 540, 8640, 540, 540, 540, 8640, 540, 1080, 8640, 8640, 1080, 540, 8640, 540, 1080, 1080, 540, 1080, 540, 8640, 540, 540, 8640, 540, 8640, 8640, 1080, 8640, 1080, 540, 1080, 8640, 1080, 8640, 540, 8640, 540, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 540, 8640, 540, 8640, 1080, 1080, 540, 1080, 8640, 1080, 1080, 8640, 540, 8640, 8640, 1080, 540, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 540, 8640, 1080, 8640, 8640, 540, 8640, 1080, 1080, 8640, 540, 1080, 540, 540, 540, 540, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 540, 540, 540, 540]
Prompts retrieved: 880740 . Total input tokens: 196366859 . Total output tokens: 176168866
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.114880292676389,
    "estimated_duration": 3600.203328789082,
    "input_throughput": 3760.5245491936384,
    "output_throughput": 3323.2236924863214,
    "total_throughput": 7083.74824167996,
    "itl": 257.5495563682931,
    "ttft": 2117997.5700199977,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3106,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.50587493265499,
    "arrivals": 293562,
    "finished_requests": 54832,
    "scheduler_time": 54.54075068030606
}
#Debug simulation 
Total elapsed time: 4.114970574621111. Arrivals time: 0.19175078300759196 Scheduler time: 3.7904378841631114 Scheduler overhead time: 0.022164981346577406 Adapter cache time: 0.07806686777621508 Engine time: 0.022340521682053804 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-8-16/adapters_256_slots_192_rate_0.8-0.1-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-8-16/adapters_256_slots_192_rate_0.8-0.1-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 540, 8640, 8640, 540, 8640, 1080, 8640, 540, 1080, 540, 8640, 1080, 1080, 1080, 1080, 8640, 540, 540, 540, 1080, 8640, 540, 8640, 8640, 1080, 1080, 1080, 540, 8640, 540, 1080, 1080, 540, 1080, 540, 540, 1080, 1080, 8640, 1080, 540, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 540, 8640, 8640, 1080, 540, 540, 8640, 1080, 540, 1080, 1080, 8640, 1080, 540, 540, 8640, 8640, 8640, 8640, 8640, 8640, 540, 1080, 540, 1080, 540, 540, 540, 1080, 1080, 1080, 540, 540, 8640, 8640, 540, 8640, 540, 1080, 8640, 8640, 8640, 1080, 540, 8640, 1080, 540, 540, 540, 540, 540, 8640, 1080, 540, 8640, 540, 8640, 540, 540, 1080, 1080, 8640, 1080, 8640, 540, 1080, 540, 8640, 8640, 540, 8640, 1080, 540, 8640, 540, 540, 8640, 8640, 1080, 8640, 8640, 540, 8640, 1080, 1080, 540, 1080, 8640, 8640, 540, 8640, 1080, 540, 1080, 8640, 540, 540, 540, 540, 540, 540, 8640, 540, 540, 540, 8640, 540, 1080, 8640, 8640, 1080, 540, 8640, 540, 1080, 1080, 540, 1080, 540, 8640, 540, 540, 8640, 540, 8640, 8640, 1080, 8640, 1080, 540, 1080, 8640, 1080, 8640, 540, 8640, 540, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 540, 8640, 540, 8640, 1080, 1080, 540, 1080, 8640, 1080, 1080, 8640, 540, 8640, 8640, 1080, 540, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 540, 8640, 1080, 8640, 8640, 540, 8640, 1080, 1080, 8640, 540, 1080, 540, 540, 540, 540, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 540, 540, 540, 540]
Prompts retrieved: 880740 . Total input tokens: 196366859 . Total output tokens: 176168866
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.079104057047516,
    "estimated_duration": 3600.2515257906343,
    "input_throughput": 3760.65336074726,
    "output_throughput": 3323.8938763790998,
    "total_throughput": 7084.5472371263595,
    "itl": 253.5137789766671,
    "ttft": 2118037.3264773465,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3108,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.133965481906225,
    "arrivals": 293562,
    "finished_requests": 54834,
    "scheduler_time": 54.62961908384277
}
#Debug simulation 
Total elapsed time: 4.079189674928784. Arrivals time: 0.1918821814469993 Scheduler time: 3.7527217934839427 Scheduler overhead time: 0.022588699124753475 Adapter cache time: 0.07891747448593378 Engine time: 0.02271590242162347 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-8-32/adapters_256_slots_192_rate_0.8-0.1-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-8-32/adapters_256_slots_192_rate_0.8-0.1-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 540, 8640, 8640, 540, 8640, 1080, 8640, 540, 1080, 540, 8640, 1080, 1080, 1080, 1080, 8640, 540, 540, 540, 1080, 8640, 540, 8640, 8640, 1080, 1080, 1080, 540, 8640, 540, 1080, 1080, 540, 1080, 540, 540, 1080, 1080, 8640, 1080, 540, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 540, 8640, 8640, 1080, 540, 540, 8640, 1080, 540, 1080, 1080, 8640, 1080, 540, 540, 8640, 8640, 8640, 8640, 8640, 8640, 540, 1080, 540, 1080, 540, 540, 540, 1080, 1080, 1080, 540, 540, 8640, 8640, 540, 8640, 540, 1080, 8640, 8640, 8640, 1080, 540, 8640, 1080, 540, 540, 540, 540, 540, 8640, 1080, 540, 8640, 540, 8640, 540, 540, 1080, 1080, 8640, 1080, 8640, 540, 1080, 540, 8640, 8640, 540, 8640, 1080, 540, 8640, 540, 540, 8640, 8640, 1080, 8640, 8640, 540, 8640, 1080, 1080, 540, 1080, 8640, 8640, 540, 8640, 1080, 540, 1080, 8640, 540, 540, 540, 540, 540, 540, 8640, 540, 540, 540, 8640, 540, 1080, 8640, 8640, 1080, 540, 8640, 540, 1080, 1080, 540, 1080, 540, 8640, 540, 540, 8640, 540, 8640, 8640, 1080, 8640, 1080, 540, 1080, 8640, 1080, 8640, 540, 8640, 540, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 540, 8640, 540, 8640, 1080, 1080, 540, 1080, 8640, 1080, 1080, 8640, 540, 8640, 8640, 1080, 540, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 540, 8640, 1080, 8640, 8640, 540, 8640, 1080, 1080, 8640, 540, 1080, 540, 540, 540, 540, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 540, 540, 540, 540]
Prompts retrieved: 880740 . Total input tokens: 196366859 . Total output tokens: 176168866
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.130300961900502,
    "estimated_duration": 3600.00201407229,
    "input_throughput": 3534.5316336660494,
    "output_throughput": 3145.5162957507755,
    "total_throughput": 6680.047929416825,
    "itl": 106.9992545519068,
    "ttft": 2173253.1811088184,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2882,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.419611006639617,
    "arrivals": 293562,
    "finished_requests": 51520,
    "scheduler_time": 59.406594023988696
}
#Debug simulation 
Total elapsed time: 4.130389811005443. Arrivals time: 0.18651532707735896 Scheduler time: 3.675744719337672 Scheduler overhead time: 0.04767565568909049 Adapter cache time: 0.1500032185576856 Engine time: 0.048201065976172686 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-16-16/adapters_256_slots_192_rate_0.8-0.1-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-16-16/adapters_256_slots_192_rate_0.8-0.1-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 540, 8640, 8640, 540, 8640, 1080, 8640, 540, 1080, 540, 8640, 1080, 1080, 1080, 1080, 8640, 540, 540, 540, 1080, 8640, 540, 8640, 8640, 1080, 1080, 1080, 540, 8640, 540, 1080, 1080, 540, 1080, 540, 540, 1080, 1080, 8640, 1080, 540, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 540, 8640, 8640, 1080, 540, 540, 8640, 1080, 540, 1080, 1080, 8640, 1080, 540, 540, 8640, 8640, 8640, 8640, 8640, 8640, 540, 1080, 540, 1080, 540, 540, 540, 1080, 1080, 1080, 540, 540, 8640, 8640, 540, 8640, 540, 1080, 8640, 8640, 8640, 1080, 540, 8640, 1080, 540, 540, 540, 540, 540, 8640, 1080, 540, 8640, 540, 8640, 540, 540, 1080, 1080, 8640, 1080, 8640, 540, 1080, 540, 8640, 8640, 540, 8640, 1080, 540, 8640, 540, 540, 8640, 8640, 1080, 8640, 8640, 540, 8640, 1080, 1080, 540, 1080, 8640, 8640, 540, 8640, 1080, 540, 1080, 8640, 540, 540, 540, 540, 540, 540, 8640, 540, 540, 540, 8640, 540, 1080, 8640, 8640, 1080, 540, 8640, 540, 1080, 1080, 540, 1080, 540, 8640, 540, 540, 8640, 540, 8640, 8640, 1080, 8640, 1080, 540, 1080, 8640, 1080, 8640, 540, 8640, 540, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 540, 8640, 540, 8640, 1080, 1080, 540, 1080, 8640, 1080, 1080, 8640, 540, 8640, 8640, 1080, 540, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 540, 8640, 1080, 8640, 8640, 540, 8640, 1080, 1080, 8640, 540, 1080, 540, 540, 540, 540, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 540, 540, 540, 540]
Prompts retrieved: 880740 . Total input tokens: 196366859 . Total output tokens: 176168866
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 4.096379491966218,
    "estimated_duration": 3600.2089557903673,
    "input_throughput": 3760.867818025727,
    "output_throughput": 3324.0617827897076,
    "total_throughput": 7084.929600815434,
    "itl": 253.91224931700006,
    "ttft": 2118060.63082325,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3105,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.738872755095434,
    "arrivals": 293562,
    "finished_requests": 54838,
    "scheduler_time": 54.623150003568135
}
#Debug simulation 
Total elapsed time: 4.096470075193793. Arrivals time: 0.19750522077083588 Scheduler time: 3.765158650930971 Scheduler overhead time: 0.022578860633075237 Adapter cache time: 0.07829301059246063 Engine time: 0.022576901596039534 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-16-32/adapters_256_slots_192_rate_0.8-0.1-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-16-32/adapters_256_slots_192_rate_0.8-0.1-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 540, 8640, 8640, 540, 8640, 1080, 8640, 540, 1080, 540, 8640, 1080, 1080, 1080, 1080, 8640, 540, 540, 540, 1080, 8640, 540, 8640, 8640, 1080, 1080, 1080, 540, 8640, 540, 1080, 1080, 540, 1080, 540, 540, 1080, 1080, 8640, 1080, 540, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 540, 8640, 8640, 1080, 540, 540, 8640, 1080, 540, 1080, 1080, 8640, 1080, 540, 540, 8640, 8640, 8640, 8640, 8640, 8640, 540, 1080, 540, 1080, 540, 540, 540, 1080, 1080, 1080, 540, 540, 8640, 8640, 540, 8640, 540, 1080, 8640, 8640, 8640, 1080, 540, 8640, 1080, 540, 540, 540, 540, 540, 8640, 1080, 540, 8640, 540, 8640, 540, 540, 1080, 1080, 8640, 1080, 8640, 540, 1080, 540, 8640, 8640, 540, 8640, 1080, 540, 8640, 540, 540, 8640, 8640, 1080, 8640, 8640, 540, 8640, 1080, 1080, 540, 1080, 8640, 8640, 540, 8640, 1080, 540, 1080, 8640, 540, 540, 540, 540, 540, 540, 8640, 540, 540, 540, 8640, 540, 1080, 8640, 8640, 1080, 540, 8640, 540, 1080, 1080, 540, 1080, 540, 8640, 540, 540, 8640, 540, 8640, 8640, 1080, 8640, 1080, 540, 1080, 8640, 1080, 8640, 540, 8640, 540, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 540, 8640, 540, 8640, 1080, 1080, 540, 1080, 8640, 1080, 1080, 8640, 540, 8640, 8640, 1080, 540, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 540, 8640, 1080, 8640, 8640, 540, 8640, 1080, 1080, 8640, 540, 1080, 540, 540, 540, 540, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 540, 540, 540, 540]
Prompts retrieved: 880740 . Total input tokens: 196366859 . Total output tokens: 176168866
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 4.101933471858501,
    "estimated_duration": 3600.0349930552325,
    "input_throughput": 3534.5978648949135,
    "output_throughput": 3145.5535909637374,
    "total_throughput": 6680.151455858651,
    "itl": 107.00302496445528,
    "ttft": 2173423.878405932,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2877,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.514085015821811,
    "arrivals": 293562,
    "finished_requests": 51520,
    "scheduler_time": 59.40372842056736
}
#Debug simulation 
Total elapsed time: 4.102021699771285. Arrivals time: 0.18692393507808447 Scheduler time: 3.646338808350265 Scheduler overhead time: 0.047129026148468256 Adapter cache time: 0.15134633658453822 Engine time: 0.04827292822301388 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_16-16-16/adapters_256_slots_192_rate_0.8-0.1-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_16-16-16/adapters_256_slots_192_rate_0.8-0.1-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 540, 8640, 8640, 540, 8640, 1080, 8640, 540, 1080, 540, 8640, 1080, 1080, 1080, 1080, 8640, 540, 540, 540, 1080, 8640, 540, 8640, 8640, 1080, 1080, 1080, 540, 8640, 540, 1080, 1080, 540, 1080, 540, 540, 1080, 1080, 8640, 1080, 540, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 540, 8640, 8640, 1080, 540, 540, 8640, 1080, 540, 1080, 1080, 8640, 1080, 540, 540, 8640, 8640, 8640, 8640, 8640, 8640, 540, 1080, 540, 1080, 540, 540, 540, 1080, 1080, 1080, 540, 540, 8640, 8640, 540, 8640, 540, 1080, 8640, 8640, 8640, 1080, 540, 8640, 1080, 540, 540, 540, 540, 540, 8640, 1080, 540, 8640, 540, 8640, 540, 540, 1080, 1080, 8640, 1080, 8640, 540, 1080, 540, 8640, 8640, 540, 8640, 1080, 540, 8640, 540, 540, 8640, 8640, 1080, 8640, 8640, 540, 8640, 1080, 1080, 540, 1080, 8640, 8640, 540, 8640, 1080, 540, 1080, 8640, 540, 540, 540, 540, 540, 540, 8640, 540, 540, 540, 8640, 540, 1080, 8640, 8640, 1080, 540, 8640, 540, 1080, 1080, 540, 1080, 540, 8640, 540, 540, 8640, 540, 8640, 8640, 1080, 8640, 1080, 540, 1080, 8640, 1080, 8640, 540, 8640, 540, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 540, 8640, 540, 8640, 1080, 1080, 540, 1080, 8640, 1080, 1080, 8640, 540, 8640, 8640, 1080, 540, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 540, 8640, 1080, 8640, 8640, 540, 8640, 1080, 1080, 8640, 540, 1080, 540, 540, 540, 540, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 540, 540, 540, 540]
Prompts retrieved: 880740 . Total input tokens: 196366859 . Total output tokens: 176168866
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.104638292919844,
    "estimated_duration": 3600.224162634358,
    "input_throughput": 3761.1977444459067,
    "output_throughput": 3324.6093741123577,
    "total_throughput": 7085.807118558264,
    "itl": 253.8591772776954,
    "ttft": 2118002.095719799,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3105,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.284106165671343,
    "arrivals": 293562,
    "finished_requests": 54845,
    "scheduler_time": 54.63181905777928
}
#Debug simulation 
Total elapsed time: 4.104735190980136. Arrivals time: 0.1929843001998961 Scheduler time: 3.7770368685014546 Scheduler overhead time: 0.022539190482348204 Adapter cache time: 0.07889334158971906 Engine time: 0.02290080627426505 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_16-16-32/adapters_256_slots_192_rate_0.8-0.1-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_16-16-32/adapters_256_slots_192_rate_0.8-0.1-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 540, 8640, 8640, 540, 8640, 1080, 8640, 540, 1080, 540, 8640, 1080, 1080, 1080, 1080, 8640, 540, 540, 540, 1080, 8640, 540, 8640, 8640, 1080, 1080, 1080, 540, 8640, 540, 1080, 1080, 540, 1080, 540, 540, 1080, 1080, 8640, 1080, 540, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 540, 8640, 8640, 1080, 540, 540, 8640, 1080, 540, 1080, 1080, 8640, 1080, 540, 540, 8640, 8640, 8640, 8640, 8640, 8640, 540, 1080, 540, 1080, 540, 540, 540, 1080, 1080, 1080, 540, 540, 8640, 8640, 540, 8640, 540, 1080, 8640, 8640, 8640, 1080, 540, 8640, 1080, 540, 540, 540, 540, 540, 8640, 1080, 540, 8640, 540, 8640, 540, 540, 1080, 1080, 8640, 1080, 8640, 540, 1080, 540, 8640, 8640, 540, 8640, 1080, 540, 8640, 540, 540, 8640, 8640, 1080, 8640, 8640, 540, 8640, 1080, 1080, 540, 1080, 8640, 8640, 540, 8640, 1080, 540, 1080, 8640, 540, 540, 540, 540, 540, 540, 8640, 540, 540, 540, 8640, 540, 1080, 8640, 8640, 1080, 540, 8640, 540, 1080, 1080, 540, 1080, 540, 8640, 540, 540, 8640, 540, 8640, 8640, 1080, 8640, 1080, 540, 1080, 8640, 1080, 8640, 540, 8640, 540, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 540, 8640, 540, 8640, 1080, 1080, 540, 1080, 8640, 1080, 1080, 8640, 540, 8640, 8640, 1080, 540, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 540, 8640, 1080, 8640, 8640, 540, 8640, 1080, 1080, 8640, 540, 1080, 540, 540, 540, 540, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 540, 540, 540, 540]
Prompts retrieved: 880740 . Total input tokens: 196366859 . Total output tokens: 176168866
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.099733664654195,
    "estimated_duration": 3600.092779434208,
    "input_throughput": 3534.541407568895,
    "output_throughput": 3145.5064338035486,
    "total_throughput": 6680.047841372443,
    "itl": 107.00491928178718,
    "ttft": 2173485.374983888,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2882,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.659457779004674,
    "arrivals": 293562,
    "finished_requests": 51521,
    "scheduler_time": 59.40331366815871
}
#Debug simulation 
Total elapsed time: 4.09982403088361. Arrivals time: 0.19135778164491057 Scheduler time: 3.6403614757582545 Scheduler overhead time: 0.047198886051774025 Adapter cache time: 0.15077693248167634 Engine time: 0.047989687882363796 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-8-8/adapters_256_slots_192_rate_0.8-0.1-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-8-8/adapters_256_slots_192_rate_0.8-0.1-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 270, 8640, 8640, 270, 8640, 1080, 8640, 270, 1080, 270, 8640, 1080, 1080, 1080, 1080, 8640, 270, 270, 270, 1080, 8640, 270, 8640, 8640, 1080, 1080, 1080, 270, 8640, 270, 1080, 1080, 270, 1080, 270, 270, 1080, 1080, 8640, 1080, 270, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 270, 8640, 8640, 1080, 270, 270, 8640, 1080, 270, 1080, 1080, 8640, 1080, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 270, 1080, 270, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 270, 8640, 8640, 270, 8640, 270, 1080, 8640, 8640, 8640, 1080, 270, 8640, 1080, 270, 270, 270, 270, 270, 8640, 1080, 270, 8640, 270, 8640, 270, 270, 1080, 1080, 8640, 1080, 8640, 270, 1080, 270, 8640, 8640, 270, 8640, 1080, 270, 8640, 270, 270, 8640, 8640, 1080, 8640, 8640, 270, 8640, 1080, 1080, 270, 1080, 8640, 8640, 270, 8640, 1080, 270, 1080, 8640, 270, 270, 270, 270, 270, 270, 8640, 270, 270, 270, 8640, 270, 1080, 8640, 8640, 1080, 270, 8640, 270, 1080, 1080, 270, 1080, 270, 8640, 270, 270, 8640, 270, 8640, 8640, 1080, 8640, 1080, 270, 1080, 8640, 1080, 8640, 270, 8640, 270, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 270, 8640, 270, 8640, 1080, 1080, 270, 1080, 8640, 1080, 1080, 8640, 270, 8640, 8640, 1080, 270, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 270, 8640, 1080, 8640, 8640, 270, 8640, 1080, 1080, 8640, 270, 1080, 270, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 270, 270, 270, 270]
Prompts retrieved: 857790 . Total input tokens: 191327038 . Total output tokens: 171596853
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.526934420224279,
    "estimated_duration": 3600.261312215688,
    "input_throughput": 3995.121673862072,
    "output_throughput": 3528.4941559372414,
    "total_throughput": 7523.615829799313,
    "itl": 242.59181897585947,
    "ttft": 2073991.0738586623,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1980,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.059765732987027,
    "arrivals": 285871,
    "finished_requests": 58135,
    "scheduler_time": 57.81824621849748
}
#Debug simulation 
Total elapsed time: 4.52699919603765. Arrivals time: 0.2299111532047391 Scheduler time: 4.170972533524036 Scheduler overhead time: 0.0234191850759089 Adapter cache time: 0.06833974877372384 Engine time: 0.02362801320850849 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-8-16/adapters_256_slots_192_rate_0.8-0.1-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-8-16/adapters_256_slots_192_rate_0.8-0.1-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 270, 8640, 8640, 270, 8640, 1080, 8640, 270, 1080, 270, 8640, 1080, 1080, 1080, 1080, 8640, 270, 270, 270, 1080, 8640, 270, 8640, 8640, 1080, 1080, 1080, 270, 8640, 270, 1080, 1080, 270, 1080, 270, 270, 1080, 1080, 8640, 1080, 270, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 270, 8640, 8640, 1080, 270, 270, 8640, 1080, 270, 1080, 1080, 8640, 1080, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 270, 1080, 270, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 270, 8640, 8640, 270, 8640, 270, 1080, 8640, 8640, 8640, 1080, 270, 8640, 1080, 270, 270, 270, 270, 270, 8640, 1080, 270, 8640, 270, 8640, 270, 270, 1080, 1080, 8640, 1080, 8640, 270, 1080, 270, 8640, 8640, 270, 8640, 1080, 270, 8640, 270, 270, 8640, 8640, 1080, 8640, 8640, 270, 8640, 1080, 1080, 270, 1080, 8640, 8640, 270, 8640, 1080, 270, 1080, 8640, 270, 270, 270, 270, 270, 270, 8640, 270, 270, 270, 8640, 270, 1080, 8640, 8640, 1080, 270, 8640, 270, 1080, 1080, 270, 1080, 270, 8640, 270, 270, 8640, 270, 8640, 8640, 1080, 8640, 1080, 270, 1080, 8640, 1080, 8640, 270, 8640, 270, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 270, 8640, 270, 8640, 1080, 1080, 270, 1080, 8640, 1080, 1080, 8640, 270, 8640, 8640, 1080, 270, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 270, 8640, 1080, 8640, 8640, 270, 8640, 1080, 1080, 8640, 270, 1080, 270, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 270, 270, 270, 270]
Prompts retrieved: 857790 . Total input tokens: 191327038 . Total output tokens: 171596853
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.322917660232633,
    "estimated_duration": 3600.1126244791503,
    "input_throughput": 3993.5614520059758,
    "output_throughput": 3526.4432878226266,
    "total_throughput": 7520.004739828602,
    "itl": 238.6899418886354,
    "ttft": 2074907.248525864,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1980,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.446978949375696,
    "arrivals": 285871,
    "finished_requests": 58108,
    "scheduler_time": 57.897331055526664
}
#Debug simulation 
Total elapsed time: 4.3230266510508955. Arrivals time: 0.2114590872079134 Scheduler time: 3.982802525162697 Scheduler overhead time: 0.02373713394626975 Adapter cache time: 0.07010034332051873 Engine time: 0.02400511084124446 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-8-32/adapters_256_slots_192_rate_0.8-0.1-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-8-32/adapters_256_slots_192_rate_0.8-0.1-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 270, 8640, 8640, 270, 8640, 1080, 8640, 270, 1080, 270, 8640, 1080, 1080, 1080, 1080, 8640, 270, 270, 270, 1080, 8640, 270, 8640, 8640, 1080, 1080, 1080, 270, 8640, 270, 1080, 1080, 270, 1080, 270, 270, 1080, 1080, 8640, 1080, 270, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 270, 8640, 8640, 1080, 270, 270, 8640, 1080, 270, 1080, 1080, 8640, 1080, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 270, 1080, 270, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 270, 8640, 8640, 270, 8640, 270, 1080, 8640, 8640, 8640, 1080, 270, 8640, 1080, 270, 270, 270, 270, 270, 8640, 1080, 270, 8640, 270, 8640, 270, 270, 1080, 1080, 8640, 1080, 8640, 270, 1080, 270, 8640, 8640, 270, 8640, 1080, 270, 8640, 270, 270, 8640, 8640, 1080, 8640, 8640, 270, 8640, 1080, 1080, 270, 1080, 8640, 8640, 270, 8640, 1080, 270, 1080, 8640, 270, 270, 270, 270, 270, 270, 8640, 270, 270, 270, 8640, 270, 1080, 8640, 8640, 1080, 270, 8640, 270, 1080, 1080, 270, 1080, 270, 8640, 270, 270, 8640, 270, 8640, 8640, 1080, 8640, 1080, 270, 1080, 8640, 1080, 8640, 270, 8640, 270, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 270, 8640, 270, 8640, 1080, 1080, 270, 1080, 8640, 1080, 1080, 8640, 270, 8640, 8640, 1080, 270, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 270, 8640, 1080, 8640, 8640, 270, 8640, 1080, 1080, 8640, 270, 1080, 270, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 270, 270, 270, 270]
Prompts retrieved: 857790 . Total input tokens: 191327038 . Total output tokens: 171596853
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.444349617231637,
    "estimated_duration": 3600.1067649362712,
    "input_throughput": 3647.566824377903,
    "output_throughput": 3250.6705395463905,
    "total_throughput": 6898.237363924293,
    "itl": 103.73908273288036,
    "ttft": 2144823.7081296253,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1789,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.841121026519639,
    "arrivals": 285871,
    "finished_requests": 53130,
    "scheduler_time": 61.26612067196787
}
#Debug simulation 
Total elapsed time: 4.444411925971508. Arrivals time: 0.40312947845086455 Scheduler time: 3.7892669583670795 Scheduler overhead time: 0.04861967545002699 Adapter cache time: 0.1315993033349514 Engine time: 0.04915147228166461 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-16-16/adapters_256_slots_192_rate_0.8-0.1-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-16-16/adapters_256_slots_192_rate_0.8-0.1-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 270, 8640, 8640, 270, 8640, 1080, 8640, 270, 1080, 270, 8640, 1080, 1080, 1080, 1080, 8640, 270, 270, 270, 1080, 8640, 270, 8640, 8640, 1080, 1080, 1080, 270, 8640, 270, 1080, 1080, 270, 1080, 270, 270, 1080, 1080, 8640, 1080, 270, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 270, 8640, 8640, 1080, 270, 270, 8640, 1080, 270, 1080, 1080, 8640, 1080, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 270, 1080, 270, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 270, 8640, 8640, 270, 8640, 270, 1080, 8640, 8640, 8640, 1080, 270, 8640, 1080, 270, 270, 270, 270, 270, 8640, 1080, 270, 8640, 270, 8640, 270, 270, 1080, 1080, 8640, 1080, 8640, 270, 1080, 270, 8640, 8640, 270, 8640, 1080, 270, 8640, 270, 270, 8640, 8640, 1080, 8640, 8640, 270, 8640, 1080, 1080, 270, 1080, 8640, 8640, 270, 8640, 1080, 270, 1080, 8640, 270, 270, 270, 270, 270, 270, 8640, 270, 270, 270, 8640, 270, 1080, 8640, 8640, 1080, 270, 8640, 270, 1080, 1080, 270, 1080, 270, 8640, 270, 270, 8640, 270, 8640, 8640, 1080, 8640, 1080, 270, 1080, 8640, 1080, 8640, 270, 8640, 270, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 270, 8640, 270, 8640, 1080, 1080, 270, 1080, 8640, 1080, 1080, 8640, 270, 8640, 8640, 1080, 270, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 270, 8640, 1080, 8640, 8640, 270, 8640, 1080, 1080, 8640, 270, 1080, 270, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 270, 270, 270, 270]
Prompts retrieved: 857790 . Total input tokens: 191327038 . Total output tokens: 171596853
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 4.322616638150066,
    "estimated_duration": 3600.1141069083615,
    "input_throughput": 3993.615916898483,
    "output_throughput": 3526.6762727427017,
    "total_throughput": 7520.292189641184,
    "itl": 238.6822147038675,
    "ttft": 2074859.1753066743,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1979,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.202509065882574,
    "arrivals": 285871,
    "finished_requests": 58110,
    "scheduler_time": 57.901345350157335
}
#Debug simulation 
Total elapsed time: 4.3227046160027385. Arrivals time: 0.2225689860060811 Scheduler time: 3.9711041916161776 Scheduler overhead time: 0.023723075166344643 Adapter cache time: 0.07026692852377892 Engine time: 0.02413104008883238 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-16-32/adapters_256_slots_192_rate_0.8-0.1-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-16-32/adapters_256_slots_192_rate_0.8-0.1-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 270, 8640, 8640, 270, 8640, 1080, 8640, 270, 1080, 270, 8640, 1080, 1080, 1080, 1080, 8640, 270, 270, 270, 1080, 8640, 270, 8640, 8640, 1080, 1080, 1080, 270, 8640, 270, 1080, 1080, 270, 1080, 270, 270, 1080, 1080, 8640, 1080, 270, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 270, 8640, 8640, 1080, 270, 270, 8640, 1080, 270, 1080, 1080, 8640, 1080, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 270, 1080, 270, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 270, 8640, 8640, 270, 8640, 270, 1080, 8640, 8640, 8640, 1080, 270, 8640, 1080, 270, 270, 270, 270, 270, 8640, 1080, 270, 8640, 270, 8640, 270, 270, 1080, 1080, 8640, 1080, 8640, 270, 1080, 270, 8640, 8640, 270, 8640, 1080, 270, 8640, 270, 270, 8640, 8640, 1080, 8640, 8640, 270, 8640, 1080, 1080, 270, 1080, 8640, 8640, 270, 8640, 1080, 270, 1080, 8640, 270, 270, 270, 270, 270, 270, 8640, 270, 270, 270, 8640, 270, 1080, 8640, 8640, 1080, 270, 8640, 270, 1080, 1080, 270, 1080, 270, 8640, 270, 270, 8640, 270, 8640, 8640, 1080, 8640, 1080, 270, 1080, 8640, 1080, 8640, 270, 8640, 270, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 270, 8640, 270, 8640, 1080, 1080, 270, 1080, 8640, 1080, 1080, 8640, 270, 8640, 8640, 1080, 270, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 270, 8640, 1080, 8640, 8640, 270, 8640, 1080, 1080, 8640, 270, 1080, 270, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 270, 270, 270, 270]
Prompts retrieved: 857790 . Total input tokens: 191327038 . Total output tokens: 171596853
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 4.4328049630858,
    "estimated_duration": 3600.040439402178,
    "input_throughput": 3647.780412761342,
    "output_throughput": 3250.96237028479,
    "total_throughput": 6898.742783046132,
    "itl": 103.73766767174241,
    "ttft": 2144751.0628139847,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1793,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.922088135275909,
    "arrivals": 285871,
    "finished_requests": 53134,
    "scheduler_time": 61.266738396974
}
#Debug simulation 
Total elapsed time: 4.4328697277233005. Arrivals time: 0.3996880636550486 Scheduler time: 3.7811830639839172 Scheduler overhead time: 0.0485115610063076 Adapter cache time: 0.13198174303397536 Engine time: 0.04889254039153457 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_16-16-16/adapters_256_slots_192_rate_0.8-0.1-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_16-16-16/adapters_256_slots_192_rate_0.8-0.1-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 270, 8640, 8640, 270, 8640, 1080, 8640, 270, 1080, 270, 8640, 1080, 1080, 1080, 1080, 8640, 270, 270, 270, 1080, 8640, 270, 8640, 8640, 1080, 1080, 1080, 270, 8640, 270, 1080, 1080, 270, 1080, 270, 270, 1080, 1080, 8640, 1080, 270, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 270, 8640, 8640, 1080, 270, 270, 8640, 1080, 270, 1080, 1080, 8640, 1080, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 270, 1080, 270, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 270, 8640, 8640, 270, 8640, 270, 1080, 8640, 8640, 8640, 1080, 270, 8640, 1080, 270, 270, 270, 270, 270, 8640, 1080, 270, 8640, 270, 8640, 270, 270, 1080, 1080, 8640, 1080, 8640, 270, 1080, 270, 8640, 8640, 270, 8640, 1080, 270, 8640, 270, 270, 8640, 8640, 1080, 8640, 8640, 270, 8640, 1080, 1080, 270, 1080, 8640, 8640, 270, 8640, 1080, 270, 1080, 8640, 270, 270, 270, 270, 270, 270, 8640, 270, 270, 270, 8640, 270, 1080, 8640, 8640, 1080, 270, 8640, 270, 1080, 1080, 270, 1080, 270, 8640, 270, 270, 8640, 270, 8640, 8640, 1080, 8640, 1080, 270, 1080, 8640, 1080, 8640, 270, 8640, 270, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 270, 8640, 270, 8640, 1080, 1080, 270, 1080, 8640, 1080, 1080, 8640, 270, 8640, 8640, 1080, 270, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 270, 8640, 1080, 8640, 8640, 270, 8640, 1080, 1080, 8640, 270, 1080, 270, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 270, 270, 270, 270]
Prompts retrieved: 857790 . Total input tokens: 191327038 . Total output tokens: 171596853
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.317582887131721,
    "estimated_duration": 3600.1075084572394,
    "input_throughput": 3993.986559074111,
    "output_throughput": 3527.0466146277363,
    "total_throughput": 7521.033173701847,
    "itl": 238.6730955204279,
    "ttft": 2074780.778699513,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1979,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.917309533611232,
    "arrivals": 285871,
    "finished_requests": 58114,
    "scheduler_time": 57.90534790679996
}
#Debug simulation 
Total elapsed time: 4.31767251342535. Arrivals time: 0.2051144316792488 Scheduler time: 3.984170349314809 Scheduler overhead time: 0.023683817125856876 Adapter cache time: 0.06992488726973534 Engine time: 0.02388852648437023 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_16-16-32/adapters_256_slots_192_rate_0.8-0.1-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_16-16-32/adapters_256_slots_192_rate_0.8-0.1-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 270, 8640, 8640, 270, 8640, 1080, 8640, 270, 1080, 270, 8640, 1080, 1080, 1080, 1080, 8640, 270, 270, 270, 1080, 8640, 270, 8640, 8640, 1080, 1080, 1080, 270, 8640, 270, 1080, 1080, 270, 1080, 270, 270, 1080, 1080, 8640, 1080, 270, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 270, 8640, 8640, 1080, 270, 270, 8640, 1080, 270, 1080, 1080, 8640, 1080, 270, 270, 8640, 8640, 8640, 8640, 8640, 8640, 270, 1080, 270, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 270, 8640, 8640, 270, 8640, 270, 1080, 8640, 8640, 8640, 1080, 270, 8640, 1080, 270, 270, 270, 270, 270, 8640, 1080, 270, 8640, 270, 8640, 270, 270, 1080, 1080, 8640, 1080, 8640, 270, 1080, 270, 8640, 8640, 270, 8640, 1080, 270, 8640, 270, 270, 8640, 8640, 1080, 8640, 8640, 270, 8640, 1080, 1080, 270, 1080, 8640, 8640, 270, 8640, 1080, 270, 1080, 8640, 270, 270, 270, 270, 270, 270, 8640, 270, 270, 270, 8640, 270, 1080, 8640, 8640, 1080, 270, 8640, 270, 1080, 1080, 270, 1080, 270, 8640, 270, 270, 8640, 270, 8640, 8640, 1080, 8640, 1080, 270, 1080, 8640, 1080, 8640, 270, 8640, 270, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 270, 8640, 270, 8640, 1080, 1080, 270, 1080, 8640, 1080, 1080, 8640, 270, 8640, 8640, 1080, 270, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 270, 8640, 1080, 8640, 8640, 270, 8640, 1080, 1080, 8640, 270, 1080, 270, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 270, 270, 270, 270]
Prompts retrieved: 857790 . Total input tokens: 191327038 . Total output tokens: 171596853
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.422866269946098,
    "estimated_duration": 3600.107559822505,
    "input_throughput": 3645.8527368685395,
    "output_throughput": 3248.9479288159578,
    "total_throughput": 6894.800665684497,
    "itl": 103.53480331384588,
    "ttft": 2145337.9671110776,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1781,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.962681569643185,
    "arrivals": 285871,
    "finished_requests": 53099,
    "scheduler_time": 61.26203600564825
}
#Debug simulation 
Total elapsed time: 4.4229278662241995. Arrivals time: 0.18833451392129064 Scheduler time: 3.983309166505933 Scheduler overhead time: 0.04842595476657152 Adapter cache time: 0.13079942716285586 Engine time: 0.049429604317992926 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-8/adapters_256_slots_192_rate_0.8-0.1-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-8/adapters_256_slots_192_rate_0.8-0.1-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 135, 8640, 8640, 135, 8640, 1080, 8640, 135, 1080, 135, 8640, 1080, 1080, 1080, 1080, 8640, 135, 135, 135, 1080, 8640, 135, 8640, 8640, 1080, 1080, 1080, 135, 8640, 135, 1080, 1080, 135, 1080, 135, 135, 1080, 1080, 8640, 1080, 135, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 135, 8640, 8640, 1080, 135, 135, 8640, 1080, 135, 1080, 1080, 8640, 1080, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 135, 1080, 135, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 135, 8640, 8640, 135, 8640, 135, 1080, 8640, 8640, 8640, 1080, 135, 8640, 1080, 135, 135, 135, 135, 135, 8640, 1080, 135, 8640, 135, 8640, 135, 135, 1080, 1080, 8640, 1080, 8640, 135, 1080, 135, 8640, 8640, 135, 8640, 1080, 135, 8640, 135, 135, 8640, 8640, 1080, 8640, 8640, 135, 8640, 1080, 1080, 135, 1080, 8640, 8640, 135, 8640, 1080, 135, 1080, 8640, 135, 135, 135, 135, 135, 135, 8640, 135, 135, 135, 8640, 135, 1080, 8640, 8640, 1080, 135, 8640, 135, 1080, 1080, 135, 1080, 135, 8640, 135, 135, 8640, 135, 8640, 8640, 1080, 8640, 1080, 135, 1080, 8640, 1080, 8640, 135, 8640, 135, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 135, 8640, 135, 8640, 1080, 1080, 135, 1080, 8640, 1080, 1080, 8640, 135, 8640, 8640, 1080, 135, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 135, 8640, 1080, 8640, 8640, 135, 8640, 1080, 1080, 8640, 135, 1080, 135, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 135, 135, 135, 135]
Prompts retrieved: 846315 . Total input tokens: 188744173 . Total output tokens: 169308446
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.3693663533777,
    "estimated_duration": 3600.126206902541,
    "input_throughput": 4121.870219868576,
    "output_throughput": 3648.070718970641,
    "total_throughput": 7769.940938839217,
    "itl": 234.93537107675937,
    "ttft": 2044712.3009173225,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1062,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.2502379840566613,
    "arrivals": 281942,
    "finished_requests": 60215,
    "scheduler_time": 59.7586281025855
}
#Debug simulation 
Total elapsed time: 4.369452471379191. Arrivals time: 0.19893747521564364 Scheduler time: 4.0533616044558585 Scheduler overhead time: 0.02393847471103072 Adapter cache time: 0.05773856909945607 Engine time: 0.024485181085765362 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-16/adapters_256_slots_192_rate_0.8-0.1-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-16/adapters_256_slots_192_rate_0.8-0.1-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 135, 8640, 8640, 135, 8640, 1080, 8640, 135, 1080, 135, 8640, 1080, 1080, 1080, 1080, 8640, 135, 135, 135, 1080, 8640, 135, 8640, 8640, 1080, 1080, 1080, 135, 8640, 135, 1080, 1080, 135, 1080, 135, 135, 1080, 1080, 8640, 1080, 135, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 135, 8640, 8640, 1080, 135, 135, 8640, 1080, 135, 1080, 1080, 8640, 1080, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 135, 1080, 135, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 135, 8640, 8640, 135, 8640, 135, 1080, 8640, 8640, 8640, 1080, 135, 8640, 1080, 135, 135, 135, 135, 135, 8640, 1080, 135, 8640, 135, 8640, 135, 135, 1080, 1080, 8640, 1080, 8640, 135, 1080, 135, 8640, 8640, 135, 8640, 1080, 135, 8640, 135, 135, 8640, 8640, 1080, 8640, 8640, 135, 8640, 1080, 1080, 135, 1080, 8640, 8640, 135, 8640, 1080, 135, 1080, 8640, 135, 135, 135, 135, 135, 135, 8640, 135, 135, 135, 8640, 135, 1080, 8640, 8640, 1080, 135, 8640, 135, 1080, 1080, 135, 1080, 135, 8640, 135, 135, 8640, 135, 8640, 8640, 1080, 8640, 1080, 135, 1080, 8640, 1080, 8640, 135, 8640, 135, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 135, 8640, 135, 8640, 1080, 1080, 135, 1080, 8640, 1080, 1080, 8640, 135, 8640, 8640, 1080, 135, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 135, 8640, 1080, 8640, 8640, 135, 8640, 1080, 1080, 8640, 135, 1080, 135, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 135, 135, 135, 135]
Prompts retrieved: 846315 . Total input tokens: 188744173 . Total output tokens: 169308446
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.413026648107916,
    "estimated_duration": 3600.183982344417,
    "input_throughput": 4120.494972687435,
    "output_throughput": 3647.9638441832217,
    "total_throughput": 7768.458816870657,
    "itl": 232.10448494396675,
    "ttft": 2044885.3644343943,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1062,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.460224350139036,
    "arrivals": 281942,
    "finished_requests": 60191,
    "scheduler_time": 59.81522825413032
}
#Debug simulation 
Total elapsed time: 4.413123534992337. Arrivals time: 0.19920884864404798 Scheduler time: 4.095573629252613 Scheduler overhead time: 0.024417809676378965 Adapter cache time: 0.058041660115122795 Engine time: 0.024690533988177776 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-32/adapters_256_slots_192_rate_0.8-0.1-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-32/adapters_256_slots_192_rate_0.8-0.1-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 135, 8640, 8640, 135, 8640, 1080, 8640, 135, 1080, 135, 8640, 1080, 1080, 1080, 1080, 8640, 135, 135, 135, 1080, 8640, 135, 8640, 8640, 1080, 1080, 1080, 135, 8640, 135, 1080, 1080, 135, 1080, 135, 135, 1080, 1080, 8640, 1080, 135, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 135, 8640, 8640, 1080, 135, 135, 8640, 1080, 135, 1080, 1080, 8640, 1080, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 135, 1080, 135, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 135, 8640, 8640, 135, 8640, 135, 1080, 8640, 8640, 8640, 1080, 135, 8640, 1080, 135, 135, 135, 135, 135, 8640, 1080, 135, 8640, 135, 8640, 135, 135, 1080, 1080, 8640, 1080, 8640, 135, 1080, 135, 8640, 8640, 135, 8640, 1080, 135, 8640, 135, 135, 8640, 8640, 1080, 8640, 8640, 135, 8640, 1080, 1080, 135, 1080, 8640, 8640, 135, 8640, 1080, 135, 1080, 8640, 135, 135, 135, 135, 135, 135, 8640, 135, 135, 135, 8640, 135, 1080, 8640, 8640, 1080, 135, 8640, 135, 1080, 1080, 135, 1080, 135, 8640, 135, 135, 8640, 135, 8640, 8640, 1080, 8640, 1080, 135, 1080, 8640, 1080, 8640, 135, 8640, 135, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 135, 8640, 135, 8640, 1080, 1080, 135, 1080, 8640, 1080, 1080, 8640, 135, 8640, 8640, 1080, 135, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 135, 8640, 1080, 8640, 8640, 135, 8640, 1080, 1080, 8640, 135, 1080, 135, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 135, 135, 135, 135]
Prompts retrieved: 846315 . Total input tokens: 188744173 . Total output tokens: 169308446
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.292681148275733,
    "estimated_duration": 3600.1027061564705,
    "input_throughput": 3714.712076722279,
    "output_throughput": 3306.309283800377,
    "total_throughput": 7021.021360522656,
    "itl": 102.04919355515469,
    "ttft": 2130174.4492801027,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 951,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.107189594227792,
    "arrivals": 281942,
    "finished_requests": 54181,
    "scheduler_time": 62.27854242754775
}
#Debug simulation 
Total elapsed time: 4.2927702302113175. Arrivals time: 0.18761781929060817 Scheduler time: 3.858666904270649 Scheduler overhead time: 0.04930455004796386 Adapter cache time: 0.1236552158370614 Engine time: 0.050443227868527174 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-16-16/adapters_256_slots_192_rate_0.8-0.1-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-16-16/adapters_256_slots_192_rate_0.8-0.1-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 135, 8640, 8640, 135, 8640, 1080, 8640, 135, 1080, 135, 8640, 1080, 1080, 1080, 1080, 8640, 135, 135, 135, 1080, 8640, 135, 8640, 8640, 1080, 1080, 1080, 135, 8640, 135, 1080, 1080, 135, 1080, 135, 135, 1080, 1080, 8640, 1080, 135, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 135, 8640, 8640, 1080, 135, 135, 8640, 1080, 135, 1080, 1080, 8640, 1080, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 135, 1080, 135, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 135, 8640, 8640, 135, 8640, 135, 1080, 8640, 8640, 8640, 1080, 135, 8640, 1080, 135, 135, 135, 135, 135, 8640, 1080, 135, 8640, 135, 8640, 135, 135, 1080, 1080, 8640, 1080, 8640, 135, 1080, 135, 8640, 8640, 135, 8640, 1080, 135, 8640, 135, 135, 8640, 8640, 1080, 8640, 8640, 135, 8640, 1080, 1080, 135, 1080, 8640, 8640, 135, 8640, 1080, 135, 1080, 8640, 135, 135, 135, 135, 135, 135, 8640, 135, 135, 135, 8640, 135, 1080, 8640, 8640, 1080, 135, 8640, 135, 1080, 1080, 135, 1080, 135, 8640, 135, 135, 8640, 135, 8640, 8640, 1080, 8640, 1080, 135, 1080, 8640, 1080, 8640, 135, 8640, 135, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 135, 8640, 135, 8640, 1080, 1080, 135, 1080, 8640, 1080, 1080, 8640, 135, 8640, 8640, 1080, 135, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 135, 8640, 1080, 8640, 8640, 135, 8640, 1080, 1080, 8640, 135, 1080, 135, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 135, 135, 135, 135]
Prompts retrieved: 846315 . Total input tokens: 188744173 . Total output tokens: 169308446
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 4.4264620509929955,
    "estimated_duration": 3600.0401029677864,
    "input_throughput": 4120.659652588526,
    "output_throughput": 3648.1096388824085,
    "total_throughput": 7768.769291470934,
    "itl": 232.10261446945427,
    "ttft": 2044827.7559979009,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1062,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.321301941869279,
    "arrivals": 281942,
    "finished_requests": 60191,
    "scheduler_time": 59.815000670448484
}
#Debug simulation 
Total elapsed time: 4.426557946950197. Arrivals time: 0.20559242367744446 Scheduler time: 4.1018753494136035 Scheduler overhead time: 0.02436300367116928 Adapter cache time: 0.05857674591243267 Engine time: 0.024919897317886353 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-16-32/adapters_256_slots_192_rate_0.8-0.1-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-16-32/adapters_256_slots_192_rate_0.8-0.1-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 135, 8640, 8640, 135, 8640, 1080, 8640, 135, 1080, 135, 8640, 1080, 1080, 1080, 1080, 8640, 135, 135, 135, 1080, 8640, 135, 8640, 8640, 1080, 1080, 1080, 135, 8640, 135, 1080, 1080, 135, 1080, 135, 135, 1080, 1080, 8640, 1080, 135, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 135, 8640, 8640, 1080, 135, 135, 8640, 1080, 135, 1080, 1080, 8640, 1080, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 135, 1080, 135, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 135, 8640, 8640, 135, 8640, 135, 1080, 8640, 8640, 8640, 1080, 135, 8640, 1080, 135, 135, 135, 135, 135, 8640, 1080, 135, 8640, 135, 8640, 135, 135, 1080, 1080, 8640, 1080, 8640, 135, 1080, 135, 8640, 8640, 135, 8640, 1080, 135, 8640, 135, 135, 8640, 8640, 1080, 8640, 8640, 135, 8640, 1080, 1080, 135, 1080, 8640, 8640, 135, 8640, 1080, 135, 1080, 8640, 135, 135, 135, 135, 135, 135, 8640, 135, 135, 135, 8640, 135, 1080, 8640, 8640, 1080, 135, 8640, 135, 1080, 1080, 135, 1080, 135, 8640, 135, 135, 8640, 135, 8640, 8640, 1080, 8640, 1080, 135, 1080, 8640, 1080, 8640, 135, 8640, 135, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 135, 8640, 135, 8640, 1080, 1080, 135, 1080, 8640, 1080, 1080, 8640, 135, 8640, 8640, 1080, 135, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 135, 8640, 1080, 8640, 8640, 135, 8640, 1080, 1080, 8640, 135, 1080, 135, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 135, 135, 135, 135]
Prompts retrieved: 846315 . Total input tokens: 188744173 . Total output tokens: 169308446
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 4.2733974028378725,
    "estimated_duration": 3600.0048823399316,
    "input_throughput": 3715.535516525717,
    "output_throughput": 3307.1157926490296,
    "total_throughput": 7022.6513091747465,
    "itl": 102.15630735445828,
    "ttft": 2129902.7214414794,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 953,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.1529348007030795,
    "arrivals": 281942,
    "finished_requests": 54194,
    "scheduler_time": 62.27570542012853
}
#Debug simulation 
Total elapsed time: 4.273497933987528. Arrivals time: 0.20553944120183587 Scheduler time: 3.8228063341230154 Scheduler overhead time: 0.04926013993099332 Adapter cache time: 0.1227958663366735 Engine time: 0.05013757711276412 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_16-16-16/adapters_256_slots_192_rate_0.8-0.1-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_16-16-16/adapters_256_slots_192_rate_0.8-0.1-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 135, 8640, 8640, 135, 8640, 1080, 8640, 135, 1080, 135, 8640, 1080, 1080, 1080, 1080, 8640, 135, 135, 135, 1080, 8640, 135, 8640, 8640, 1080, 1080, 1080, 135, 8640, 135, 1080, 1080, 135, 1080, 135, 135, 1080, 1080, 8640, 1080, 135, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 135, 8640, 8640, 1080, 135, 135, 8640, 1080, 135, 1080, 1080, 8640, 1080, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 135, 1080, 135, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 135, 8640, 8640, 135, 8640, 135, 1080, 8640, 8640, 8640, 1080, 135, 8640, 1080, 135, 135, 135, 135, 135, 8640, 1080, 135, 8640, 135, 8640, 135, 135, 1080, 1080, 8640, 1080, 8640, 135, 1080, 135, 8640, 8640, 135, 8640, 1080, 135, 8640, 135, 135, 8640, 8640, 1080, 8640, 8640, 135, 8640, 1080, 1080, 135, 1080, 8640, 8640, 135, 8640, 1080, 135, 1080, 8640, 135, 135, 135, 135, 135, 135, 8640, 135, 135, 135, 8640, 135, 1080, 8640, 8640, 1080, 135, 8640, 135, 1080, 1080, 135, 1080, 135, 8640, 135, 135, 8640, 135, 8640, 8640, 1080, 8640, 1080, 135, 1080, 8640, 1080, 8640, 135, 8640, 135, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 135, 8640, 135, 8640, 1080, 1080, 135, 1080, 8640, 1080, 1080, 8640, 135, 8640, 8640, 1080, 135, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 135, 8640, 1080, 8640, 8640, 135, 8640, 1080, 1080, 8640, 135, 1080, 135, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 135, 135, 135, 135]
Prompts retrieved: 846315 . Total input tokens: 188744173 . Total output tokens: 169308446
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.39158920198679,
    "estimated_duration": 3600.2020272576747,
    "input_throughput": 4120.540427365922,
    "output_throughput": 3648.065275382388,
    "total_throughput": 7768.60570274831,
    "itl": 232.11953277454532,
    "ttft": 2044847.8864266207,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1062,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.1754334131860347,
    "arrivals": 281942,
    "finished_requests": 60195,
    "scheduler_time": 59.818890103766925
}
#Debug simulation 
Total elapsed time: 4.391684402246028. Arrivals time: 0.20154439564794302 Scheduler time: 4.07085181819275 Scheduler overhead time: 0.024374340660870075 Adapter cache time: 0.05903502460569143 Engine time: 0.024699002038687468 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_16-16-32/adapters_256_slots_192_rate_0.8-0.1-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_16-16-32/adapters_256_slots_192_rate_0.8-0.1-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 135, 8640, 8640, 135, 8640, 1080, 8640, 135, 1080, 135, 8640, 1080, 1080, 1080, 1080, 8640, 135, 135, 135, 1080, 8640, 135, 8640, 8640, 1080, 1080, 1080, 135, 8640, 135, 1080, 1080, 135, 1080, 135, 135, 1080, 1080, 8640, 1080, 135, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 135, 8640, 8640, 1080, 135, 135, 8640, 1080, 135, 1080, 1080, 8640, 1080, 135, 135, 8640, 8640, 8640, 8640, 8640, 8640, 135, 1080, 135, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 135, 8640, 8640, 135, 8640, 135, 1080, 8640, 8640, 8640, 1080, 135, 8640, 1080, 135, 135, 135, 135, 135, 8640, 1080, 135, 8640, 135, 8640, 135, 135, 1080, 1080, 8640, 1080, 8640, 135, 1080, 135, 8640, 8640, 135, 8640, 1080, 135, 8640, 135, 135, 8640, 8640, 1080, 8640, 8640, 135, 8640, 1080, 1080, 135, 1080, 8640, 8640, 135, 8640, 1080, 135, 1080, 8640, 135, 135, 135, 135, 135, 135, 8640, 135, 135, 135, 8640, 135, 1080, 8640, 8640, 1080, 135, 8640, 135, 1080, 1080, 135, 1080, 135, 8640, 135, 135, 8640, 135, 8640, 8640, 1080, 8640, 1080, 135, 1080, 8640, 1080, 8640, 135, 8640, 135, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 135, 8640, 135, 8640, 1080, 1080, 135, 1080, 8640, 1080, 1080, 8640, 135, 8640, 8640, 1080, 135, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 135, 8640, 1080, 8640, 8640, 135, 8640, 1080, 1080, 8640, 135, 1080, 135, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 135, 135, 135, 135]
Prompts retrieved: 846315 . Total input tokens: 188744173 . Total output tokens: 169308446
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.289310338906944,
    "estimated_duration": 3600.061711944185,
    "input_throughput": 3715.4054764179486,
    "output_throughput": 3307.210529335668,
    "total_throughput": 7022.616005753617,
    "itl": 102.15838617296815,
    "ttft": 2129968.3551224507,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 951,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.186540233455633,
    "arrivals": 281942,
    "finished_requests": 54194,
    "scheduler_time": 62.275842902991315
}
#Debug simulation 
Total elapsed time: 4.289430222008377. Arrivals time: 0.18476991122588515 Scheduler time: 3.8564151423051953 Scheduler overhead time: 0.04927403526380658 Adapter cache time: 0.12523153610527515 Engine time: 0.05061559425666928 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-8/adapters_256_slots_192_rate_0.8-0.1-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-8/adapters_256_slots_192_rate_0.8-0.1-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 8640, 66, 8640, 8640, 66, 8640, 1080, 8640, 66, 1080, 66, 8640, 1080, 1080, 1080, 1080, 8640, 66, 66, 66, 1080, 8640, 66, 8640, 8640, 1080, 1080, 1080, 66, 8640, 66, 1080, 1080, 66, 1080, 66, 66, 1080, 1080, 8640, 1080, 66, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 66, 8640, 8640, 1080, 66, 66, 8640, 1080, 66, 1080, 1080, 8640, 1080, 66, 66, 8640, 8640, 8640, 8640, 8640, 8640, 66, 1080, 66, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 66, 8640, 8640, 66, 8640, 66, 1080, 8640, 8640, 8640, 1080, 66, 8640, 1080, 66, 66, 66, 66, 66, 8640, 1080, 66, 8640, 66, 8640, 66, 66, 1080, 1080, 8640, 1080, 8640, 66, 1080, 66, 8640, 8640, 66, 8640, 1080, 66, 8640, 66, 66, 8640, 8640, 1080, 8640, 8640, 66, 8640, 1080, 1080, 66, 1080, 8640, 8640, 66, 8640, 1080, 66, 1080, 8640, 66, 66, 66, 66, 66, 66, 8640, 66, 66, 66, 8640, 66, 1080, 8640, 8640, 1080, 66, 8640, 66, 1080, 1080, 66, 1080, 66, 8640, 66, 66, 8640, 66, 8640, 8640, 1080, 8640, 1080, 66, 1080, 8640, 1080, 8640, 66, 8640, 66, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 1080, 66, 8640, 66, 8640, 1080, 1080, 66, 1080, 8640, 1080, 1080, 8640, 66, 8640, 8640, 1080, 66, 8640, 8640, 1080, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 8640, 66, 8640, 1080, 8640, 8640, 66, 8640, 1080, 1080, 8640, 66, 1080, 66, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 66, 66, 66, 66]
Prompts retrieved: 840450 . Total input tokens: 187460075 . Total output tokens: 168134870
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.481456848792732,
    "estimated_duration": 3600.162188057441,
    "input_throughput": 4250.072969144764,
    "output_throughput": 3726.4907243634284,
    "total_throughput": 7976.563693508193,
    "itl": 228.96906921330518,
    "ttft": 2028291.11671275,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 539,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6496028939797756,
    "arrivals": 279961,
    "finished_requests": 61591,
    "scheduler_time": 61.05487934418744
}
#Debug simulation 
Total elapsed time: 4.481544867157936. Arrivals time: 0.2024644035845995 Scheduler time: 4.165394727606326 Scheduler overhead time: 0.0246833642013371 Adapter cache time: 0.05269050970673561 Engine time: 0.024920166935771704 
