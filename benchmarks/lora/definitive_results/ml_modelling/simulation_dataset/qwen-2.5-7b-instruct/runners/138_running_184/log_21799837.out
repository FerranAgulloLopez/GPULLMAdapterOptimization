INFO 06-01 00:47:15 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 06-01 00:47:16 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-16-16/adapters_256_slots_64_rate_3.2-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-16-16/adapters_256_slots_64_rate_3.2-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 135, 34560, 34560, 135, 34560, 540, 34560, 135, 540, 135, 34560, 540, 540, 540, 540, 34560, 135, 135, 135, 540, 34560, 135, 34560, 34560, 540, 540, 540, 135, 34560, 135, 540, 540, 135, 540, 135, 135, 540, 540, 34560, 540, 135, 540, 34560, 540, 540, 34560, 540, 34560, 135, 34560, 34560, 540, 135, 135, 34560, 540, 135, 540, 540, 34560, 540, 135, 135, 34560, 34560, 34560, 34560, 34560, 34560, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 34560, 34560, 135, 34560, 135, 540, 34560, 34560, 34560, 540, 135, 34560, 540, 135, 135, 135, 135, 135, 34560, 540, 135, 34560, 135, 34560, 135, 135, 540, 540, 34560, 540, 34560, 135, 540, 135, 34560, 34560, 135, 34560, 540, 135, 34560, 135, 135, 34560, 34560, 540, 34560, 34560, 135, 34560, 540, 540, 135, 540, 34560, 34560, 135, 34560, 540, 135, 540, 34560, 135, 135, 135, 135, 135, 135, 34560, 135, 135, 135, 34560, 135, 540, 34560, 34560, 540, 135, 34560, 135, 540, 540, 135, 540, 135, 34560, 135, 135, 34560, 135, 34560, 34560, 540, 34560, 540, 135, 540, 34560, 540, 34560, 135, 34560, 135, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 135, 34560, 135, 34560, 540, 540, 135, 540, 34560, 540, 540, 34560, 135, 34560, 34560, 540, 135, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 135, 34560, 540, 34560, 34560, 135, 34560, 540, 540, 34560, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 34560, 540, 135, 135, 135, 135]
Prompts retrieved: 3029535 . Total input tokens: 675430113 . Total output tokens: 605954314
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 143.57972505129874,
    "estimated_duration": 3600.135795437692,
    "input_throughput": 6269.752110074442,
    "output_throughput": 5528.286189988095,
    "total_throughput": 11798.038300062537,
    "itl": 154.73092594045093,
    "ttft": 2052483.8621190765,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 686,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.149645974047003,
    "arrivals": 1008682,
    "finished_requests": 91204,
    "scheduler_time": 161.7141866585639
}
#Debug simulation 
Total elapsed time: 143.5799515871331. Arrivals time: 0.9320028694346547 Scheduler time: 142.37634626636282 Scheduler overhead time: 0.10509584518149495 Adapter cache time: 0.02892590593546629 Engine time: 0.10738120879977942 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-16-32/adapters_256_slots_64_rate_3.2-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-16-32/adapters_256_slots_64_rate_3.2-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 135, 34560, 34560, 135, 34560, 540, 34560, 135, 540, 135, 34560, 540, 540, 540, 540, 34560, 135, 135, 135, 540, 34560, 135, 34560, 34560, 540, 540, 540, 135, 34560, 135, 540, 540, 135, 540, 135, 135, 540, 540, 34560, 540, 135, 540, 34560, 540, 540, 34560, 540, 34560, 135, 34560, 34560, 540, 135, 135, 34560, 540, 135, 540, 540, 34560, 540, 135, 135, 34560, 34560, 34560, 34560, 34560, 34560, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 34560, 34560, 135, 34560, 135, 540, 34560, 34560, 34560, 540, 135, 34560, 540, 135, 135, 135, 135, 135, 34560, 540, 135, 34560, 135, 34560, 135, 135, 540, 540, 34560, 540, 34560, 135, 540, 135, 34560, 34560, 135, 34560, 540, 135, 34560, 135, 135, 34560, 34560, 540, 34560, 34560, 135, 34560, 540, 540, 135, 540, 34560, 34560, 135, 34560, 540, 135, 540, 34560, 135, 135, 135, 135, 135, 135, 34560, 135, 135, 135, 34560, 135, 540, 34560, 34560, 540, 135, 34560, 135, 540, 540, 135, 540, 135, 34560, 135, 135, 34560, 135, 34560, 34560, 540, 34560, 540, 135, 540, 34560, 540, 34560, 135, 34560, 135, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 135, 34560, 135, 34560, 540, 540, 135, 540, 34560, 540, 540, 34560, 135, 34560, 34560, 540, 135, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 135, 34560, 540, 34560, 34560, 135, 34560, 540, 540, 34560, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 34560, 540, 135, 135, 135, 135]
Prompts retrieved: 3029535 . Total input tokens: 675430113 . Total output tokens: 605954314
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 141.34178460016847,
    "estimated_duration": 3600.0808440323376,
    "input_throughput": 6269.538373676938,
    "output_throughput": 5528.312241373996,
    "total_throughput": 11797.850615050935,
    "itl": 154.73554947544537,
    "ttft": 2052401.129179106,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 684,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.260862562805418,
    "arrivals": 1008682,
    "finished_requests": 91203,
    "scheduler_time": 161.70698655172933
}
#Debug simulation 
Total elapsed time: 141.3420904208906. Arrivals time: 0.7699165805242956 Scheduler time: 140.30644036829472 Scheduler overhead time: 0.1048793587833643 Adapter cache time: 0.028396185021847486 Engine time: 0.10242117755115032 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_16-16-16/adapters_256_slots_64_rate_3.2-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_16-16-16/adapters_256_slots_64_rate_3.2-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 135, 34560, 34560, 135, 34560, 540, 34560, 135, 540, 135, 34560, 540, 540, 540, 540, 34560, 135, 135, 135, 540, 34560, 135, 34560, 34560, 540, 540, 540, 135, 34560, 135, 540, 540, 135, 540, 135, 135, 540, 540, 34560, 540, 135, 540, 34560, 540, 540, 34560, 540, 34560, 135, 34560, 34560, 540, 135, 135, 34560, 540, 135, 540, 540, 34560, 540, 135, 135, 34560, 34560, 34560, 34560, 34560, 34560, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 34560, 34560, 135, 34560, 135, 540, 34560, 34560, 34560, 540, 135, 34560, 540, 135, 135, 135, 135, 135, 34560, 540, 135, 34560, 135, 34560, 135, 135, 540, 540, 34560, 540, 34560, 135, 540, 135, 34560, 34560, 135, 34560, 540, 135, 34560, 135, 135, 34560, 34560, 540, 34560, 34560, 135, 34560, 540, 540, 135, 540, 34560, 34560, 135, 34560, 540, 135, 540, 34560, 135, 135, 135, 135, 135, 135, 34560, 135, 135, 135, 34560, 135, 540, 34560, 34560, 540, 135, 34560, 135, 540, 540, 135, 540, 135, 34560, 135, 135, 34560, 135, 34560, 34560, 540, 34560, 540, 135, 540, 34560, 540, 34560, 135, 34560, 135, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 135, 34560, 135, 34560, 540, 540, 135, 540, 34560, 540, 540, 34560, 135, 34560, 34560, 540, 135, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 135, 34560, 540, 34560, 34560, 135, 34560, 540, 540, 34560, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 34560, 540, 135, 135, 135, 135]
Prompts retrieved: 3029535 . Total input tokens: 675430113 . Total output tokens: 605954314
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 145.3384435446933,
    "estimated_duration": 3600.037077441428,
    "input_throughput": 6269.9240353496725,
    "output_throughput": 5528.437783242195,
    "total_throughput": 11798.361818591868,
    "itl": 154.72697402403426,
    "ttft": 2052469.2053191657,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 686,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0511745023028567,
    "arrivals": 1008682,
    "finished_requests": 91204,
    "scheduler_time": 161.7139401340084
}
#Debug simulation 
Total elapsed time: 145.33861888200045. Arrivals time: 0.8822881057858467 Scheduler time: 144.1821781564504 Scheduler overhead time: 0.1071237656287849 Adapter cache time: 0.02785735158249736 Engine time: 0.10734779620543122 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_16-16-32/adapters_256_slots_64_rate_3.2-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_16-16-32/adapters_256_slots_64_rate_3.2-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 135, 34560, 34560, 135, 34560, 540, 34560, 135, 540, 135, 34560, 540, 540, 540, 540, 34560, 135, 135, 135, 540, 34560, 135, 34560, 34560, 540, 540, 540, 135, 34560, 135, 540, 540, 135, 540, 135, 135, 540, 540, 34560, 540, 135, 540, 34560, 540, 540, 34560, 540, 34560, 135, 34560, 34560, 540, 135, 135, 34560, 540, 135, 540, 540, 34560, 540, 135, 135, 34560, 34560, 34560, 34560, 34560, 34560, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 34560, 34560, 135, 34560, 135, 540, 34560, 34560, 34560, 540, 135, 34560, 540, 135, 135, 135, 135, 135, 34560, 540, 135, 34560, 135, 34560, 135, 135, 540, 540, 34560, 540, 34560, 135, 540, 135, 34560, 34560, 135, 34560, 540, 135, 34560, 135, 135, 34560, 34560, 540, 34560, 34560, 135, 34560, 540, 540, 135, 540, 34560, 34560, 135, 34560, 540, 135, 540, 34560, 135, 135, 135, 135, 135, 135, 34560, 135, 135, 135, 34560, 135, 540, 34560, 34560, 540, 135, 34560, 135, 540, 540, 135, 540, 135, 34560, 135, 135, 34560, 135, 34560, 34560, 540, 34560, 540, 135, 540, 34560, 540, 34560, 135, 34560, 135, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 135, 34560, 135, 34560, 540, 540, 135, 540, 34560, 540, 540, 34560, 135, 34560, 34560, 540, 135, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 135, 34560, 540, 34560, 34560, 135, 34560, 540, 540, 34560, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 34560, 540, 135, 135, 135, 135]
Prompts retrieved: 3029535 . Total input tokens: 675430113 . Total output tokens: 605954314
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 145.25702601391822,
    "estimated_duration": 3600.1111031112355,
    "input_throughput": 6269.485677954259,
    "output_throughput": 5528.265775686829,
    "total_throughput": 11797.751453641089,
    "itl": 154.73676684479952,
    "ttft": 2052405.6212008358,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 684,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2910434715449868,
    "arrivals": 1008682,
    "finished_requests": 91203,
    "scheduler_time": 161.70706472195874
}
#Debug simulation 
Total elapsed time: 145.25731606502086. Arrivals time: 0.8193174251355231 Scheduler time: 144.1661416841671 Scheduler overhead time: 0.10683816159144044 Adapter cache time: 0.028481241781264544 Engine time: 0.10641914932057261 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-8/adapters_256_slots_64_rate_3.2-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-8/adapters_256_slots_64_rate_3.2-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 66, 34560, 34560, 66, 34560, 540, 34560, 66, 540, 66, 34560, 540, 540, 540, 540, 34560, 66, 66, 66, 540, 34560, 66, 34560, 34560, 540, 540, 540, 66, 34560, 66, 540, 540, 66, 540, 66, 66, 540, 540, 34560, 540, 66, 540, 34560, 540, 540, 34560, 540, 34560, 66, 34560, 34560, 540, 66, 66, 34560, 540, 66, 540, 540, 34560, 540, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 34560, 34560, 66, 34560, 66, 540, 34560, 34560, 34560, 540, 66, 34560, 540, 66, 66, 66, 66, 66, 34560, 540, 66, 34560, 66, 34560, 66, 66, 540, 540, 34560, 540, 34560, 66, 540, 66, 34560, 34560, 66, 34560, 540, 66, 34560, 66, 66, 34560, 34560, 540, 34560, 34560, 66, 34560, 540, 540, 66, 540, 34560, 34560, 66, 34560, 540, 66, 540, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 540, 34560, 34560, 540, 66, 34560, 66, 540, 540, 66, 540, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 540, 34560, 540, 66, 540, 34560, 540, 34560, 66, 34560, 66, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 66, 34560, 66, 34560, 540, 540, 66, 540, 34560, 540, 540, 34560, 66, 34560, 34560, 540, 66, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 66, 34560, 540, 34560, 34560, 66, 34560, 540, 540, 34560, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 34560, 540, 66, 66, 66, 66]
Prompts retrieved: 3023670 . Total input tokens: 674122022 . Total output tokens: 604779064
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 141.11292555788532,
    "estimated_duration": 3600.1610779565162,
    "input_throughput": 6284.096325168164,
    "output_throughput": 5530.566429905859,
    "total_throughput": 11814.662755074023,
    "itl": 154.7042929570523,
    "ttft": 2052668.5391165765,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 769,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.353515075084333,
    "arrivals": 1006798,
    "finished_requests": 91113,
    "scheduler_time": 161.8311193209028
}
#Debug simulation 
Total elapsed time: 141.11310422001407. Arrivals time: 0.7993054809048772 Scheduler time: 140.0439212261699 Scheduler overhead time: 0.10549590364098549 Adapter cache time: 0.02901325188577175 Engine time: 0.10576183907687664 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-16/adapters_256_slots_64_rate_3.2-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-16/adapters_256_slots_64_rate_3.2-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 66, 34560, 34560, 66, 34560, 540, 34560, 66, 540, 66, 34560, 540, 540, 540, 540, 34560, 66, 66, 66, 540, 34560, 66, 34560, 34560, 540, 540, 540, 66, 34560, 66, 540, 540, 66, 540, 66, 66, 540, 540, 34560, 540, 66, 540, 34560, 540, 540, 34560, 540, 34560, 66, 34560, 34560, 540, 66, 66, 34560, 540, 66, 540, 540, 34560, 540, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 34560, 34560, 66, 34560, 66, 540, 34560, 34560, 34560, 540, 66, 34560, 540, 66, 66, 66, 66, 66, 34560, 540, 66, 34560, 66, 34560, 66, 66, 540, 540, 34560, 540, 34560, 66, 540, 66, 34560, 34560, 66, 34560, 540, 66, 34560, 66, 66, 34560, 34560, 540, 34560, 34560, 66, 34560, 540, 540, 66, 540, 34560, 34560, 66, 34560, 540, 66, 540, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 540, 34560, 34560, 540, 66, 34560, 66, 540, 540, 66, 540, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 540, 34560, 540, 66, 540, 34560, 540, 34560, 66, 34560, 66, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 66, 34560, 66, 34560, 540, 540, 66, 540, 34560, 540, 540, 34560, 66, 34560, 34560, 540, 66, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 66, 34560, 540, 34560, 34560, 66, 34560, 540, 540, 34560, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 34560, 540, 66, 66, 66, 66]
Prompts retrieved: 3023670 . Total input tokens: 674122022 . Total output tokens: 604779064
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 139.32516182400286,
    "estimated_duration": 3600.1074978985407,
    "input_throughput": 6283.632367423695,
    "output_throughput": 5530.31819511549,
    "total_throughput": 11813.950562539185,
    "itl": 154.7115873450134,
    "ttft": 2052678.152577557,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 771,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.5120780085003984,
    "arrivals": 1006798,
    "finished_requests": 91107,
    "scheduler_time": 161.82033363578188
}
#Debug simulation 
Total elapsed time: 139.32535292813554. Arrivals time: 0.8129736511036754 Scheduler time: 138.23731966223568 Scheduler overhead time: 0.1086629987694323 Adapter cache time: 0.029918936546891928 Engine time: 0.10579359252005816 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-32/adapters_256_slots_64_rate_3.2-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-32/adapters_256_slots_64_rate_3.2-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 66, 34560, 34560, 66, 34560, 540, 34560, 66, 540, 66, 34560, 540, 540, 540, 540, 34560, 66, 66, 66, 540, 34560, 66, 34560, 34560, 540, 540, 540, 66, 34560, 66, 540, 540, 66, 540, 66, 66, 540, 540, 34560, 540, 66, 540, 34560, 540, 540, 34560, 540, 34560, 66, 34560, 34560, 540, 66, 66, 34560, 540, 66, 540, 540, 34560, 540, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 34560, 34560, 66, 34560, 66, 540, 34560, 34560, 34560, 540, 66, 34560, 540, 66, 66, 66, 66, 66, 34560, 540, 66, 34560, 66, 34560, 66, 66, 540, 540, 34560, 540, 34560, 66, 540, 66, 34560, 34560, 66, 34560, 540, 66, 34560, 66, 66, 34560, 34560, 540, 34560, 34560, 66, 34560, 540, 540, 66, 540, 34560, 34560, 66, 34560, 540, 66, 540, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 540, 34560, 34560, 540, 66, 34560, 66, 540, 540, 66, 540, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 540, 34560, 540, 66, 540, 34560, 540, 34560, 66, 34560, 66, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 66, 34560, 66, 34560, 540, 540, 66, 540, 34560, 540, 540, 34560, 66, 34560, 34560, 540, 66, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 66, 34560, 540, 34560, 34560, 66, 34560, 540, 540, 34560, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 34560, 540, 66, 66, 66, 66]
Prompts retrieved: 3023670 . Total input tokens: 674122022 . Total output tokens: 604779064
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 139.23286966094747,
    "estimated_duration": 3600.112634571388,
    "input_throughput": 6283.6234018809355,
    "output_throughput": 5530.310304408117,
    "total_throughput": 11813.933706289052,
    "itl": 154.71179789707355,
    "ttft": 2052678.9856281749,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 771,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.5172002646326925,
    "arrivals": 1006798,
    "finished_requests": 91107,
    "scheduler_time": 161.82034805242256
}
#Debug simulation 
Total elapsed time: 139.23304046783596. Arrivals time: 0.8019189452752471 Scheduler time: 138.159956112504 Scheduler overhead time: 0.10653999727219343 Adapter cache time: 0.02787654474377632 Engine time: 0.10555550595745444 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-16-16/adapters_256_slots_64_rate_3.2-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-16-16/adapters_256_slots_64_rate_3.2-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 66, 34560, 34560, 66, 34560, 540, 34560, 66, 540, 66, 34560, 540, 540, 540, 540, 34560, 66, 66, 66, 540, 34560, 66, 34560, 34560, 540, 540, 540, 66, 34560, 66, 540, 540, 66, 540, 66, 66, 540, 540, 34560, 540, 66, 540, 34560, 540, 540, 34560, 540, 34560, 66, 34560, 34560, 540, 66, 66, 34560, 540, 66, 540, 540, 34560, 540, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 34560, 34560, 66, 34560, 66, 540, 34560, 34560, 34560, 540, 66, 34560, 540, 66, 66, 66, 66, 66, 34560, 540, 66, 34560, 66, 34560, 66, 66, 540, 540, 34560, 540, 34560, 66, 540, 66, 34560, 34560, 66, 34560, 540, 66, 34560, 66, 66, 34560, 34560, 540, 34560, 34560, 66, 34560, 540, 540, 66, 540, 34560, 34560, 66, 34560, 540, 66, 540, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 540, 34560, 34560, 540, 66, 34560, 66, 540, 540, 66, 540, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 540, 34560, 540, 66, 540, 34560, 540, 34560, 66, 34560, 66, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 66, 34560, 66, 34560, 540, 540, 66, 540, 34560, 540, 540, 34560, 66, 34560, 34560, 540, 66, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 66, 34560, 540, 34560, 34560, 66, 34560, 540, 540, 34560, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 34560, 540, 66, 66, 66, 66]
Prompts retrieved: 3023670 . Total input tokens: 674122022 . Total output tokens: 604779064
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 141.6363665042445,
    "estimated_duration": 3600.050909394158,
    "input_throughput": 6283.7311386263,
    "output_throughput": 5530.405125118231,
    "total_throughput": 11814.13626374453,
    "itl": 154.70636884039814,
    "ttft": 2052667.411609631,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 769,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.4121209846692917,
    "arrivals": 1006798,
    "finished_requests": 91107,
    "scheduler_time": 161.82357029006334
}
#Debug simulation 
Total elapsed time: 141.63656891416758. Arrivals time: 0.9228815417736769 Scheduler time: 140.44519484974444 Scheduler overhead time: 0.10592381516471505 Adapter cache time: 0.027721683029085398 Engine time: 0.10465453285723925 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-16-32/adapters_256_slots_64_rate_3.2-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-16-32/adapters_256_slots_64_rate_3.2-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 66, 34560, 34560, 66, 34560, 540, 34560, 66, 540, 66, 34560, 540, 540, 540, 540, 34560, 66, 66, 66, 540, 34560, 66, 34560, 34560, 540, 540, 540, 66, 34560, 66, 540, 540, 66, 540, 66, 66, 540, 540, 34560, 540, 66, 540, 34560, 540, 540, 34560, 540, 34560, 66, 34560, 34560, 540, 66, 66, 34560, 540, 66, 540, 540, 34560, 540, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 34560, 34560, 66, 34560, 66, 540, 34560, 34560, 34560, 540, 66, 34560, 540, 66, 66, 66, 66, 66, 34560, 540, 66, 34560, 66, 34560, 66, 66, 540, 540, 34560, 540, 34560, 66, 540, 66, 34560, 34560, 66, 34560, 540, 66, 34560, 66, 66, 34560, 34560, 540, 34560, 34560, 66, 34560, 540, 540, 66, 540, 34560, 34560, 66, 34560, 540, 66, 540, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 540, 34560, 34560, 540, 66, 34560, 66, 540, 540, 66, 540, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 540, 34560, 540, 66, 540, 34560, 540, 34560, 66, 34560, 66, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 66, 34560, 66, 34560, 540, 540, 66, 540, 34560, 540, 540, 34560, 66, 34560, 34560, 540, 66, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 66, 34560, 540, 34560, 34560, 66, 34560, 540, 540, 34560, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 34560, 540, 66, 66, 66, 66]
Prompts retrieved: 3023670 . Total input tokens: 674122022 . Total output tokens: 604779064
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 140.87656575301662,
    "estimated_duration": 3600.1416473253717,
    "input_throughput": 6283.572763534518,
    "output_throughput": 5530.265736847162,
    "total_throughput": 11813.83850038168,
    "itl": 154.7129293037603,
    "ttft": 2052683.770087447,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 771,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.5461236355081223,
    "arrivals": 1006798,
    "finished_requests": 91107,
    "scheduler_time": 161.82043743559473
}
#Debug simulation 
Total elapsed time: 140.87676766794175. Arrivals time: 0.7884450140409172 Scheduler time: 139.82285685418174 Scheduler overhead time: 0.10420628869906068 Adapter cache time: 0.027427427005022764 Engine time: 0.10396686755120754 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_16-16-16/adapters_256_slots_64_rate_3.2-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_16-16-16/adapters_256_slots_64_rate_3.2-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 66, 34560, 34560, 66, 34560, 540, 34560, 66, 540, 66, 34560, 540, 540, 540, 540, 34560, 66, 66, 66, 540, 34560, 66, 34560, 34560, 540, 540, 540, 66, 34560, 66, 540, 540, 66, 540, 66, 66, 540, 540, 34560, 540, 66, 540, 34560, 540, 540, 34560, 540, 34560, 66, 34560, 34560, 540, 66, 66, 34560, 540, 66, 540, 540, 34560, 540, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 34560, 34560, 66, 34560, 66, 540, 34560, 34560, 34560, 540, 66, 34560, 540, 66, 66, 66, 66, 66, 34560, 540, 66, 34560, 66, 34560, 66, 66, 540, 540, 34560, 540, 34560, 66, 540, 66, 34560, 34560, 66, 34560, 540, 66, 34560, 66, 66, 34560, 34560, 540, 34560, 34560, 66, 34560, 540, 540, 66, 540, 34560, 34560, 66, 34560, 540, 66, 540, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 540, 34560, 34560, 540, 66, 34560, 66, 540, 540, 66, 540, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 540, 34560, 540, 66, 540, 34560, 540, 34560, 66, 34560, 66, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 66, 34560, 66, 34560, 540, 540, 66, 540, 34560, 540, 540, 34560, 66, 34560, 34560, 540, 66, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 66, 34560, 540, 34560, 34560, 66, 34560, 540, 540, 34560, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 34560, 540, 66, 66, 66, 66]
Prompts retrieved: 3023670 . Total input tokens: 674122022 . Total output tokens: 604779064
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 140.77785715460777,
    "estimated_duration": 3600.106749611432,
    "input_throughput": 6284.191156954397,
    "output_throughput": 5530.649890353678,
    "total_throughput": 11814.841047308075,
    "itl": 154.70217798171603,
    "ttft": 2052660.0473626312,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 769,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2993486767797284,
    "arrivals": 1006798,
    "finished_requests": 91113,
    "scheduler_time": 161.83095737397255
}
#Debug simulation 
Total elapsed time: 140.77810748387128. Arrivals time: 0.8206153744831681 Scheduler time: 139.686963934917 Scheduler overhead time: 0.10696186497807503 Adapter cache time: 0.029264296870678663 Engine time: 0.10439318651333451 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_16-16-32/adapters_256_slots_64_rate_3.2-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_16-16-32/adapters_256_slots_64_rate_3.2-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 66, 34560, 34560, 66, 34560, 540, 34560, 66, 540, 66, 34560, 540, 540, 540, 540, 34560, 66, 66, 66, 540, 34560, 66, 34560, 34560, 540, 540, 540, 66, 34560, 66, 540, 540, 66, 540, 66, 66, 540, 540, 34560, 540, 66, 540, 34560, 540, 540, 34560, 540, 34560, 66, 34560, 34560, 540, 66, 66, 34560, 540, 66, 540, 540, 34560, 540, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 34560, 34560, 66, 34560, 66, 540, 34560, 34560, 34560, 540, 66, 34560, 540, 66, 66, 66, 66, 66, 34560, 540, 66, 34560, 66, 34560, 66, 66, 540, 540, 34560, 540, 34560, 66, 540, 66, 34560, 34560, 66, 34560, 540, 66, 34560, 66, 66, 34560, 34560, 540, 34560, 34560, 66, 34560, 540, 540, 66, 540, 34560, 34560, 66, 34560, 540, 66, 540, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 540, 34560, 34560, 540, 66, 34560, 66, 540, 540, 66, 540, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 540, 34560, 540, 66, 540, 34560, 540, 34560, 66, 34560, 66, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 66, 34560, 66, 34560, 540, 540, 66, 540, 34560, 540, 540, 34560, 66, 34560, 34560, 540, 66, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 66, 34560, 540, 34560, 34560, 66, 34560, 540, 540, 34560, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 34560, 540, 66, 66, 66, 66]
Prompts retrieved: 3023670 . Total input tokens: 674122022 . Total output tokens: 604779064
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 138.82661031698808,
    "estimated_duration": 3600.0063073563756,
    "input_throughput": 6283.365657937099,
    "output_throughput": 5529.997811203624,
    "total_throughput": 11813.363469140724,
    "itl": 154.71251398956312,
    "ttft": 2052653.7611067793,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 771,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.5808316805586378,
    "arrivals": 1006798,
    "finished_requests": 91100,
    "scheduler_time": 161.8130848282775
}
#Debug simulation 
Total elapsed time: 138.82676884066314. Arrivals time: 0.7794802505522966 Scheduler time: 137.77859094087034 Scheduler overhead time: 0.10598723497241735 Adapter cache time: 0.028268953319638968 Engine time: 0.10464632790535688 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-8/adapters_256_slots_64_rate_3.2-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-8/adapters_256_slots_64_rate_3.2-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 33, 34560, 34560, 33, 34560, 540, 34560, 33, 540, 33, 34560, 540, 540, 540, 540, 34560, 33, 33, 33, 540, 34560, 33, 34560, 34560, 540, 540, 540, 33, 34560, 33, 540, 540, 33, 540, 33, 33, 540, 540, 34560, 540, 33, 540, 34560, 540, 540, 34560, 540, 34560, 33, 34560, 34560, 540, 33, 33, 34560, 540, 33, 540, 540, 34560, 540, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 34560, 34560, 33, 34560, 33, 540, 34560, 34560, 34560, 540, 33, 34560, 540, 33, 33, 33, 33, 33, 34560, 540, 33, 34560, 33, 34560, 33, 33, 540, 540, 34560, 540, 34560, 33, 540, 33, 34560, 34560, 33, 34560, 540, 33, 34560, 33, 33, 34560, 34560, 540, 34560, 34560, 33, 34560, 540, 540, 33, 540, 34560, 34560, 33, 34560, 540, 33, 540, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 540, 34560, 34560, 540, 33, 34560, 33, 540, 540, 33, 540, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 540, 34560, 540, 33, 540, 34560, 540, 34560, 33, 34560, 33, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 33, 34560, 33, 34560, 540, 540, 33, 540, 34560, 540, 540, 34560, 33, 34560, 34560, 540, 33, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 33, 34560, 540, 34560, 34560, 33, 34560, 540, 540, 34560, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 34560, 540, 33, 33, 33, 33]
Prompts retrieved: 3020865 . Total input tokens: 673492761 . Total output tokens: 604222272
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 142.94537287438288,
    "estimated_duration": 3600.0573961906152,
    "input_throughput": 6256.452473183687,
    "output_throughput": 5529.732115122631,
    "total_throughput": 11786.184588306318,
    "itl": 154.9901660550544,
    "ttft": 2053468.8617523448,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 723,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2127326388634216,
    "arrivals": 1005871,
    "finished_requests": 91160,
    "scheduler_time": 161.7791129103111
}
#Debug simulation 
Total elapsed time: 142.9455510112457. Arrivals time: 1.3394726640544832 Scheduler time: 141.33994224248454 Scheduler overhead time: 0.10517243947833776 Adapter cache time: 0.02789479400962591 Engine time: 0.10264382231980562 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-16/adapters_256_slots_64_rate_3.2-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-16/adapters_256_slots_64_rate_3.2-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 33, 34560, 34560, 33, 34560, 540, 34560, 33, 540, 33, 34560, 540, 540, 540, 540, 34560, 33, 33, 33, 540, 34560, 33, 34560, 34560, 540, 540, 540, 33, 34560, 33, 540, 540, 33, 540, 33, 33, 540, 540, 34560, 540, 33, 540, 34560, 540, 540, 34560, 540, 34560, 33, 34560, 34560, 540, 33, 33, 34560, 540, 33, 540, 540, 34560, 540, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 34560, 34560, 33, 34560, 33, 540, 34560, 34560, 34560, 540, 33, 34560, 540, 33, 33, 33, 33, 33, 34560, 540, 33, 34560, 33, 34560, 33, 33, 540, 540, 34560, 540, 34560, 33, 540, 33, 34560, 34560, 33, 34560, 540, 33, 34560, 33, 33, 34560, 34560, 540, 34560, 34560, 33, 34560, 540, 540, 33, 540, 34560, 34560, 33, 34560, 540, 33, 540, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 540, 34560, 34560, 540, 33, 34560, 33, 540, 540, 33, 540, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 540, 34560, 540, 33, 540, 34560, 540, 34560, 33, 34560, 33, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 33, 34560, 33, 34560, 540, 540, 33, 540, 34560, 540, 540, 34560, 33, 34560, 34560, 540, 33, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 33, 34560, 540, 34560, 34560, 33, 34560, 540, 540, 34560, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 34560, 540, 33, 33, 33, 33]
Prompts retrieved: 3020865 . Total input tokens: 673492761 . Total output tokens: 604222272
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 140.87814914202318,
    "estimated_duration": 3600.0431581778894,
    "input_throughput": 6256.178054098509,
    "output_throughput": 5529.5856536551955,
    "total_throughput": 11785.763707753706,
    "itl": 154.99469560252223,
    "ttft": 2053416.1589426827,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 723,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.353846162881241,
    "arrivals": 1005871,
    "finished_requests": 91156,
    "scheduler_time": 161.77416067924386
}
#Debug simulation 
Total elapsed time: 140.8783096098341. Arrivals time: 0.6275432063266635 Scheduler time: 140.00699382647872 Scheduler overhead time: 0.0939857205376029 Adapter cache time: 0.024996038526296616 Engine time: 0.0971190882846713 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-32/adapters_256_slots_64_rate_3.2-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-32/adapters_256_slots_64_rate_3.2-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 33, 34560, 34560, 33, 34560, 540, 34560, 33, 540, 33, 34560, 540, 540, 540, 540, 34560, 33, 33, 33, 540, 34560, 33, 34560, 34560, 540, 540, 540, 33, 34560, 33, 540, 540, 33, 540, 33, 33, 540, 540, 34560, 540, 33, 540, 34560, 540, 540, 34560, 540, 34560, 33, 34560, 34560, 540, 33, 33, 34560, 540, 33, 540, 540, 34560, 540, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 34560, 34560, 33, 34560, 33, 540, 34560, 34560, 34560, 540, 33, 34560, 540, 33, 33, 33, 33, 33, 34560, 540, 33, 34560, 33, 34560, 33, 33, 540, 540, 34560, 540, 34560, 33, 540, 33, 34560, 34560, 33, 34560, 540, 33, 34560, 33, 33, 34560, 34560, 540, 34560, 34560, 33, 34560, 540, 540, 33, 540, 34560, 34560, 33, 34560, 540, 33, 540, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 540, 34560, 34560, 540, 33, 34560, 33, 540, 540, 33, 540, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 540, 34560, 540, 33, 540, 34560, 540, 34560, 33, 34560, 33, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 33, 34560, 33, 34560, 540, 540, 33, 540, 34560, 540, 540, 34560, 33, 34560, 34560, 540, 33, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 33, 34560, 540, 34560, 34560, 33, 34560, 540, 540, 34560, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 34560, 540, 33, 33, 33, 33]
Prompts retrieved: 3020865 . Total input tokens: 673492761 . Total output tokens: 604222272
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 140.05050597107038,
    "estimated_duration": 3600.048297041991,
    "input_throughput": 6256.169123760313,
    "output_throughput": 5529.577760486308,
    "total_throughput": 11785.74688424662,
    "itl": 154.9948972696568,
    "ttft": 2053416.9514928176,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 723,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.35897045008838,
    "arrivals": 1005871,
    "finished_requests": 91156,
    "scheduler_time": 161.77417525606944
}
#Debug simulation 
Total elapsed time: 140.05070059280843. Arrivals time: 0.7249356424435973 Scheduler time: 139.07738220784813 Scheduler overhead time: 0.09637207258492708 Adapter cache time: 0.02586280880495906 Engine time: 0.09778680093586445 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-16-16/adapters_256_slots_64_rate_3.2-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-16-16/adapters_256_slots_64_rate_3.2-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 33, 34560, 34560, 33, 34560, 540, 34560, 33, 540, 33, 34560, 540, 540, 540, 540, 34560, 33, 33, 33, 540, 34560, 33, 34560, 34560, 540, 540, 540, 33, 34560, 33, 540, 540, 33, 540, 33, 33, 540, 540, 34560, 540, 33, 540, 34560, 540, 540, 34560, 540, 34560, 33, 34560, 34560, 540, 33, 33, 34560, 540, 33, 540, 540, 34560, 540, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 34560, 34560, 33, 34560, 33, 540, 34560, 34560, 34560, 540, 33, 34560, 540, 33, 33, 33, 33, 33, 34560, 540, 33, 34560, 33, 34560, 33, 33, 540, 540, 34560, 540, 34560, 33, 540, 33, 34560, 34560, 33, 34560, 540, 33, 34560, 33, 33, 34560, 34560, 540, 34560, 34560, 33, 34560, 540, 540, 33, 540, 34560, 34560, 33, 34560, 540, 33, 540, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 540, 34560, 34560, 540, 33, 34560, 33, 540, 540, 33, 540, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 540, 34560, 540, 33, 540, 34560, 540, 34560, 33, 34560, 33, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 33, 34560, 33, 34560, 540, 540, 33, 540, 34560, 540, 540, 34560, 33, 34560, 34560, 540, 33, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 33, 34560, 540, 34560, 34560, 33, 34560, 540, 540, 34560, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 34560, 540, 33, 33, 33, 33]
Prompts retrieved: 3020865 . Total input tokens: 673492761 . Total output tokens: 604222272
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 140.98958967719227,
    "estimated_duration": 3600.1549494372257,
    "input_throughput": 6255.673801906924,
    "output_throughput": 5528.7814773393175,
    "total_throughput": 11784.455279246242,
    "itl": 155.02064150312793,
    "ttft": 2053330.0593034865,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 703,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2033369962894214,
    "arrivals": 1005871,
    "finished_requests": 91146,
    "scheduler_time": 161.7491773754032
}
#Debug simulation 
Total elapsed time: 140.9897630950436. Arrivals time: 0.6333530680276453 Scheduler time: 140.10240933811292 Scheduler overhead time: 0.0991428755223751 Adapter cache time: 0.026429510209709406 Engine time: 0.09946665773168206 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-16-32/adapters_256_slots_64_rate_3.2-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-16-32/adapters_256_slots_64_rate_3.2-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 33, 34560, 34560, 33, 34560, 540, 34560, 33, 540, 33, 34560, 540, 540, 540, 540, 34560, 33, 33, 33, 540, 34560, 33, 34560, 34560, 540, 540, 540, 33, 34560, 33, 540, 540, 33, 540, 33, 33, 540, 540, 34560, 540, 33, 540, 34560, 540, 540, 34560, 540, 34560, 33, 34560, 34560, 540, 33, 33, 34560, 540, 33, 540, 540, 34560, 540, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 34560, 34560, 33, 34560, 33, 540, 34560, 34560, 34560, 540, 33, 34560, 540, 33, 33, 33, 33, 33, 34560, 540, 33, 34560, 33, 34560, 33, 33, 540, 540, 34560, 540, 34560, 33, 540, 33, 34560, 34560, 33, 34560, 540, 33, 34560, 33, 33, 34560, 34560, 540, 34560, 34560, 33, 34560, 540, 540, 33, 540, 34560, 34560, 33, 34560, 540, 33, 540, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 540, 34560, 34560, 540, 33, 34560, 33, 540, 540, 33, 540, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 540, 34560, 540, 33, 540, 34560, 540, 34560, 33, 34560, 33, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 33, 34560, 33, 34560, 540, 540, 33, 540, 34560, 540, 540, 34560, 33, 34560, 34560, 540, 33, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 33, 34560, 540, 34560, 34560, 33, 34560, 540, 540, 34560, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 34560, 540, 33, 33, 33, 33]
Prompts retrieved: 3020865 . Total input tokens: 673492761 . Total output tokens: 604222272
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 140.235159908887,
    "estimated_duration": 3600.0755506846313,
    "input_throughput": 6256.121762699358,
    "output_throughput": 5529.535899938074,
    "total_throughput": 11785.657662637434,
    "itl": 154.99593808679683,
    "ttft": 2053421.371391135,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 723,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3861332679539946,
    "arrivals": 1005871,
    "finished_requests": 91156,
    "scheduler_time": 161.77426608090568
}
#Debug simulation 
Total elapsed time: 140.2353248107247. Arrivals time: 0.6617877511307597 Scheduler time: 139.32315110741183 Scheduler overhead time: 0.09785924572497606 Adapter cache time: 0.026287482120096684 Engine time: 0.09796554921194911 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_16-16-16/adapters_256_slots_64_rate_3.2-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_16-16-16/adapters_256_slots_64_rate_3.2-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 33, 34560, 34560, 33, 34560, 540, 34560, 33, 540, 33, 34560, 540, 540, 540, 540, 34560, 33, 33, 33, 540, 34560, 33, 34560, 34560, 540, 540, 540, 33, 34560, 33, 540, 540, 33, 540, 33, 33, 540, 540, 34560, 540, 33, 540, 34560, 540, 540, 34560, 540, 34560, 33, 34560, 34560, 540, 33, 33, 34560, 540, 33, 540, 540, 34560, 540, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 34560, 34560, 33, 34560, 33, 540, 34560, 34560, 34560, 540, 33, 34560, 540, 33, 33, 33, 33, 33, 34560, 540, 33, 34560, 33, 34560, 33, 33, 540, 540, 34560, 540, 34560, 33, 540, 33, 34560, 34560, 33, 34560, 540, 33, 34560, 33, 33, 34560, 34560, 540, 34560, 34560, 33, 34560, 540, 540, 33, 540, 34560, 34560, 33, 34560, 540, 33, 540, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 540, 34560, 34560, 540, 33, 34560, 33, 540, 540, 33, 540, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 540, 34560, 540, 33, 540, 34560, 540, 34560, 33, 34560, 33, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 33, 34560, 33, 34560, 540, 540, 33, 540, 34560, 540, 540, 34560, 33, 34560, 34560, 540, 33, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 33, 34560, 540, 34560, 34560, 33, 34560, 540, 540, 34560, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 34560, 540, 33, 33, 33, 33]
Prompts retrieved: 3020865 . Total input tokens: 673492761 . Total output tokens: 604222272
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 140.9482141751796,
    "estimated_duration": 3600.0063124533553,
    "input_throughput": 6256.541251631996,
    "output_throughput": 5529.8105814801775,
    "total_throughput": 11786.351833112174,
    "itl": 154.9881770665635,
    "ttft": 2053461.0175742668,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 723,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1618063632142333,
    "arrivals": 1005871,
    "finished_requests": 91160,
    "scheduler_time": 161.778955448558
}
#Debug simulation 
Total elapsed time: 140.9483732902445. Arrivals time: 0.6424803449772298 Scheduler time: 140.0530448751524 Scheduler overhead time: 0.09801275189965963 Adapter cache time: 0.025890287943184376 Engine time: 0.10051084961742163 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_16-16-32/adapters_256_slots_64_rate_3.2-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_16-16-32/adapters_256_slots_64_rate_3.2-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [540, 540, 34560, 33, 34560, 34560, 33, 34560, 540, 34560, 33, 540, 33, 34560, 540, 540, 540, 540, 34560, 33, 33, 33, 540, 34560, 33, 34560, 34560, 540, 540, 540, 33, 34560, 33, 540, 540, 33, 540, 33, 33, 540, 540, 34560, 540, 33, 540, 34560, 540, 540, 34560, 540, 34560, 33, 34560, 34560, 540, 33, 33, 34560, 540, 33, 540, 540, 34560, 540, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 34560, 34560, 33, 34560, 33, 540, 34560, 34560, 34560, 540, 33, 34560, 540, 33, 33, 33, 33, 33, 34560, 540, 33, 34560, 33, 34560, 33, 33, 540, 540, 34560, 540, 34560, 33, 540, 33, 34560, 34560, 33, 34560, 540, 33, 34560, 33, 33, 34560, 34560, 540, 34560, 34560, 33, 34560, 540, 540, 33, 540, 34560, 34560, 33, 34560, 540, 33, 540, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 540, 34560, 34560, 540, 33, 34560, 33, 540, 540, 33, 540, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 540, 34560, 540, 33, 540, 34560, 540, 34560, 33, 34560, 33, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 540, 33, 34560, 33, 34560, 540, 540, 33, 540, 34560, 540, 540, 34560, 33, 34560, 34560, 540, 33, 34560, 34560, 540, 540, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 34560, 33, 34560, 540, 34560, 34560, 33, 34560, 540, 540, 34560, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 34560, 540, 33, 33, 33, 33]
Prompts retrieved: 3020865 . Total input tokens: 673492761 . Total output tokens: 604222272
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 140.50184772582725,
    "estimated_duration": 3600.1075864952113,
    "input_throughput": 6256.066092159815,
    "output_throughput": 5529.486694973936,
    "total_throughput": 11785.55278713375,
    "itl": 154.99720888472203,
    "ttft": 2053426.0485079985,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 723,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.4180747297033767,
    "arrivals": 1005871,
    "finished_requests": 91156,
    "scheduler_time": 161.77436042980963
}
#Debug simulation 
Total elapsed time: 140.5019987761043. Arrivals time: 0.651028239633888 Scheduler time: 139.60123056266457 Scheduler overhead time: 0.09757946757599711 Adapter cache time: 0.02492989506572485 Engine time: 0.09923502523452044 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-8/adapters_256_slots_64_rate_3.2-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-8/adapters_256_slots_64_rate_3.2-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 34560, 135, 34560, 34560, 135, 34560, 270, 34560, 135, 270, 135, 34560, 270, 270, 270, 270, 34560, 135, 135, 135, 270, 34560, 135, 34560, 34560, 270, 270, 270, 135, 34560, 135, 270, 270, 135, 270, 135, 135, 270, 270, 34560, 270, 135, 270, 34560, 270, 270, 34560, 270, 34560, 135, 34560, 34560, 270, 135, 135, 34560, 270, 135, 270, 270, 34560, 270, 135, 135, 34560, 34560, 34560, 34560, 34560, 34560, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 34560, 34560, 135, 34560, 135, 270, 34560, 34560, 34560, 270, 135, 34560, 270, 135, 135, 135, 135, 135, 34560, 270, 135, 34560, 135, 34560, 135, 135, 270, 270, 34560, 270, 34560, 135, 270, 135, 34560, 34560, 135, 34560, 270, 135, 34560, 135, 135, 34560, 34560, 270, 34560, 34560, 135, 34560, 270, 270, 135, 270, 34560, 34560, 135, 34560, 270, 135, 270, 34560, 135, 135, 135, 135, 135, 135, 34560, 135, 135, 135, 34560, 135, 270, 34560, 34560, 270, 135, 34560, 135, 270, 270, 135, 270, 135, 34560, 135, 135, 34560, 135, 34560, 34560, 270, 34560, 270, 135, 270, 34560, 270, 34560, 135, 34560, 135, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 270, 135, 34560, 135, 34560, 270, 270, 135, 270, 34560, 270, 270, 34560, 135, 34560, 34560, 270, 135, 34560, 34560, 270, 270, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 34560, 135, 34560, 270, 34560, 34560, 135, 34560, 270, 270, 34560, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 34560, 270, 135, 135, 135, 135]
Prompts retrieved: 3006585 . Total input tokens: 670334443 . Total output tokens: 601394933
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 146.7229791949503,
    "estimated_duration": 3600.0895813302645,
    "input_throughput": 6289.639046046492,
    "output_throughput": 5562.530194762643,
    "total_throughput": 11852.169240809135,
    "itl": 154.15201751426622,
    "ttft": 2055167.021172299,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 738,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2586399550224145,
    "arrivals": 1001073,
    "finished_requests": 91426,
    "scheduler_time": 162.7366511893778
}
#Debug simulation 
Total elapsed time: 146.72313994262367. Arrivals time: 0.7355077350512147 Scheduler time: 145.72859247261658 Scheduler overhead time: 0.1023860084824264 Adapter cache time: 0.025915803853422403 Engine time: 0.10106133343651891 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-16/adapters_256_slots_64_rate_3.2-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-16/adapters_256_slots_64_rate_3.2-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 34560, 135, 34560, 34560, 135, 34560, 270, 34560, 135, 270, 135, 34560, 270, 270, 270, 270, 34560, 135, 135, 135, 270, 34560, 135, 34560, 34560, 270, 270, 270, 135, 34560, 135, 270, 270, 135, 270, 135, 135, 270, 270, 34560, 270, 135, 270, 34560, 270, 270, 34560, 270, 34560, 135, 34560, 34560, 270, 135, 135, 34560, 270, 135, 270, 270, 34560, 270, 135, 135, 34560, 34560, 34560, 34560, 34560, 34560, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 34560, 34560, 135, 34560, 135, 270, 34560, 34560, 34560, 270, 135, 34560, 270, 135, 135, 135, 135, 135, 34560, 270, 135, 34560, 135, 34560, 135, 135, 270, 270, 34560, 270, 34560, 135, 270, 135, 34560, 34560, 135, 34560, 270, 135, 34560, 135, 135, 34560, 34560, 270, 34560, 34560, 135, 34560, 270, 270, 135, 270, 34560, 34560, 135, 34560, 270, 135, 270, 34560, 135, 135, 135, 135, 135, 135, 34560, 135, 135, 135, 34560, 135, 270, 34560, 34560, 270, 135, 34560, 135, 270, 270, 135, 270, 135, 34560, 135, 135, 34560, 135, 34560, 34560, 270, 34560, 270, 135, 270, 34560, 270, 34560, 135, 34560, 135, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 270, 135, 34560, 135, 34560, 270, 270, 135, 270, 34560, 270, 270, 34560, 135, 34560, 34560, 270, 135, 34560, 34560, 270, 270, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 34560, 135, 34560, 270, 34560, 34560, 135, 34560, 270, 270, 34560, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 34560, 270, 135, 135, 135, 135]
Prompts retrieved: 3006585 . Total input tokens: 670334443 . Total output tokens: 601394933
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 144.75826294813305,
    "estimated_duration": 3600.0729071316287,
    "input_throughput": 6289.652066530246,
    "output_throughput": 5562.516514687854,
    "total_throughput": 11852.1685812181,
    "itl": 154.15783662830876,
    "ttft": 2055153.0120323733,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 738,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.4089118002657837,
    "arrivals": 1001073,
    "finished_requests": 91425,
    "scheduler_time": 162.72931107648307
}
#Debug simulation 
Total elapsed time: 144.7584163271822. Arrivals time: 0.755411634221673 Scheduler time: 143.7424691184424 Scheduler overhead time: 0.10189113253727555 Adapter cache time: 0.027691824827343225 Engine time: 0.10168920876458287 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-32/adapters_256_slots_64_rate_3.2-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-32/adapters_256_slots_64_rate_3.2-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 34560, 135, 34560, 34560, 135, 34560, 270, 34560, 135, 270, 135, 34560, 270, 270, 270, 270, 34560, 135, 135, 135, 270, 34560, 135, 34560, 34560, 270, 270, 270, 135, 34560, 135, 270, 270, 135, 270, 135, 135, 270, 270, 34560, 270, 135, 270, 34560, 270, 270, 34560, 270, 34560, 135, 34560, 34560, 270, 135, 135, 34560, 270, 135, 270, 270, 34560, 270, 135, 135, 34560, 34560, 34560, 34560, 34560, 34560, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 34560, 34560, 135, 34560, 135, 270, 34560, 34560, 34560, 270, 135, 34560, 270, 135, 135, 135, 135, 135, 34560, 270, 135, 34560, 135, 34560, 135, 135, 270, 270, 34560, 270, 34560, 135, 270, 135, 34560, 34560, 135, 34560, 270, 135, 34560, 135, 135, 34560, 34560, 270, 34560, 34560, 135, 34560, 270, 270, 135, 270, 34560, 34560, 135, 34560, 270, 135, 270, 34560, 135, 135, 135, 135, 135, 135, 34560, 135, 135, 135, 34560, 135, 270, 34560, 34560, 270, 135, 34560, 135, 270, 270, 135, 270, 135, 34560, 135, 135, 34560, 135, 34560, 34560, 270, 34560, 270, 135, 270, 34560, 270, 34560, 135, 34560, 135, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 270, 135, 34560, 135, 34560, 270, 270, 135, 270, 34560, 270, 270, 34560, 135, 34560, 34560, 270, 135, 34560, 34560, 270, 270, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 34560, 135, 34560, 270, 34560, 34560, 135, 34560, 270, 270, 34560, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 34560, 270, 135, 135, 135, 135]
Prompts retrieved: 3006585 . Total input tokens: 670334443 . Total output tokens: 601394933
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 145.52111281640828,
    "estimated_duration": 3600.077063847895,
    "input_throughput": 6289.644804380412,
    "output_throughput": 5562.5100921023195,
    "total_throughput": 11852.15489648273,
    "itl": 154.15799396461898,
    "ttft": 2055153.6952196443,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 738,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.4130544201843405,
    "arrivals": 1001073,
    "finished_requests": 91425,
    "scheduler_time": 162.72932517275393
}
#Debug simulation 
Total elapsed time: 145.5212870752439. Arrivals time: 0.8549924371764064 Scheduler time: 144.40478269848973 Scheduler overhead time: 0.10362762166187167 Adapter cache time: 0.02609576703980565 Engine time: 0.10292819235473871 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-16-16/adapters_256_slots_64_rate_3.2-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-16-16/adapters_256_slots_64_rate_3.2-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 34560, 135, 34560, 34560, 135, 34560, 270, 34560, 135, 270, 135, 34560, 270, 270, 270, 270, 34560, 135, 135, 135, 270, 34560, 135, 34560, 34560, 270, 270, 270, 135, 34560, 135, 270, 270, 135, 270, 135, 135, 270, 270, 34560, 270, 135, 270, 34560, 270, 270, 34560, 270, 34560, 135, 34560, 34560, 270, 135, 135, 34560, 270, 135, 270, 270, 34560, 270, 135, 135, 34560, 34560, 34560, 34560, 34560, 34560, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 34560, 34560, 135, 34560, 135, 270, 34560, 34560, 34560, 270, 135, 34560, 270, 135, 135, 135, 135, 135, 34560, 270, 135, 34560, 135, 34560, 135, 135, 270, 270, 34560, 270, 34560, 135, 270, 135, 34560, 34560, 135, 34560, 270, 135, 34560, 135, 135, 34560, 34560, 270, 34560, 34560, 135, 34560, 270, 270, 135, 270, 34560, 34560, 135, 34560, 270, 135, 270, 34560, 135, 135, 135, 135, 135, 135, 34560, 135, 135, 135, 34560, 135, 270, 34560, 34560, 270, 135, 34560, 135, 270, 270, 135, 270, 135, 34560, 135, 135, 34560, 135, 34560, 34560, 270, 34560, 270, 135, 270, 34560, 270, 34560, 135, 34560, 135, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 270, 135, 34560, 135, 34560, 270, 270, 135, 270, 34560, 270, 270, 34560, 135, 34560, 34560, 270, 135, 34560, 34560, 270, 270, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 34560, 135, 34560, 270, 34560, 34560, 135, 34560, 270, 270, 34560, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 34560, 270, 135, 135, 135, 135]
Prompts retrieved: 3006585 . Total input tokens: 670334443 . Total output tokens: 601394933
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 144.06919971108437,
    "estimated_duration": 3600.1455849123963,
    "input_throughput": 6289.5412049151855,
    "output_throughput": 5562.443664479555,
    "total_throughput": 11851.98486939474,
    "itl": 154.1543332614182,
    "ttft": 2055174.1727729214,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 738,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3145262817060415,
    "arrivals": 1001073,
    "finished_requests": 91426,
    "scheduler_time": 162.73676844472195
}
#Debug simulation 
Total elapsed time: 144.0693588810973. Arrivals time: 1.3987187375314534 Scheduler time: 142.41801502835006 Scheduler overhead time: 0.09851713245734572 Adapter cache time: 0.02634442364796996 Engine time: 0.098645422141999 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-16-32/adapters_256_slots_64_rate_3.2-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-16-32/adapters_256_slots_64_rate_3.2-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 34560, 135, 34560, 34560, 135, 34560, 270, 34560, 135, 270, 135, 34560, 270, 270, 270, 270, 34560, 135, 135, 135, 270, 34560, 135, 34560, 34560, 270, 270, 270, 135, 34560, 135, 270, 270, 135, 270, 135, 135, 270, 270, 34560, 270, 135, 270, 34560, 270, 270, 34560, 270, 34560, 135, 34560, 34560, 270, 135, 135, 34560, 270, 135, 270, 270, 34560, 270, 135, 135, 34560, 34560, 34560, 34560, 34560, 34560, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 34560, 34560, 135, 34560, 135, 270, 34560, 34560, 34560, 270, 135, 34560, 270, 135, 135, 135, 135, 135, 34560, 270, 135, 34560, 135, 34560, 135, 135, 270, 270, 34560, 270, 34560, 135, 270, 135, 34560, 34560, 135, 34560, 270, 135, 34560, 135, 135, 34560, 34560, 270, 34560, 34560, 135, 34560, 270, 270, 135, 270, 34560, 34560, 135, 34560, 270, 135, 270, 34560, 135, 135, 135, 135, 135, 135, 34560, 135, 135, 135, 34560, 135, 270, 34560, 34560, 270, 135, 34560, 135, 270, 270, 135, 270, 135, 34560, 135, 135, 34560, 135, 34560, 34560, 270, 34560, 270, 135, 270, 34560, 270, 34560, 135, 34560, 135, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 270, 135, 34560, 135, 34560, 270, 270, 135, 270, 34560, 270, 270, 34560, 135, 34560, 34560, 270, 135, 34560, 34560, 270, 270, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 34560, 135, 34560, 270, 34560, 34560, 135, 34560, 270, 270, 34560, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 34560, 270, 135, 135, 135, 135]
Prompts retrieved: 3006585 . Total input tokens: 670334443 . Total output tokens: 601394933
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 152.7501378939487,
    "estimated_duration": 3600.1062122871253,
    "input_throughput": 6289.5938799580335,
    "output_throughput": 5562.465054962349,
    "total_throughput": 11852.058934920382,
    "itl": 154.15909981679417,
    "ttft": 2055158.490765844,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 738,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.4421035448461788,
    "arrivals": 1001073,
    "finished_requests": 91425,
    "scheduler_time": 162.72942448738968
}
#Debug simulation 
Total elapsed time: 152.75028664804995. Arrivals time: 0.780355267226696 Scheduler time: 151.71446020994335 Scheduler overhead time: 0.09949788963422179 Adapter cache time: 0.026316244155168533 Engine time: 0.10053289355710149 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_16-16-16/adapters_256_slots_64_rate_3.2-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_16-16-16/adapters_256_slots_64_rate_3.2-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 34560, 135, 34560, 34560, 135, 34560, 270, 34560, 135, 270, 135, 34560, 270, 270, 270, 270, 34560, 135, 135, 135, 270, 34560, 135, 34560, 34560, 270, 270, 270, 135, 34560, 135, 270, 270, 135, 270, 135, 135, 270, 270, 34560, 270, 135, 270, 34560, 270, 270, 34560, 270, 34560, 135, 34560, 34560, 270, 135, 135, 34560, 270, 135, 270, 270, 34560, 270, 135, 135, 34560, 34560, 34560, 34560, 34560, 34560, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 34560, 34560, 135, 34560, 135, 270, 34560, 34560, 34560, 270, 135, 34560, 270, 135, 135, 135, 135, 135, 34560, 270, 135, 34560, 135, 34560, 135, 135, 270, 270, 34560, 270, 34560, 135, 270, 135, 34560, 34560, 135, 34560, 270, 135, 34560, 135, 135, 34560, 34560, 270, 34560, 34560, 135, 34560, 270, 270, 135, 270, 34560, 34560, 135, 34560, 270, 135, 270, 34560, 135, 135, 135, 135, 135, 135, 34560, 135, 135, 135, 34560, 135, 270, 34560, 34560, 270, 135, 34560, 135, 270, 270, 135, 270, 135, 34560, 135, 135, 34560, 135, 34560, 34560, 270, 34560, 270, 135, 270, 34560, 270, 34560, 135, 34560, 135, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 270, 135, 34560, 135, 34560, 270, 270, 135, 270, 34560, 270, 270, 34560, 135, 34560, 34560, 270, 135, 34560, 34560, 270, 270, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 34560, 135, 34560, 270, 34560, 34560, 135, 34560, 270, 270, 34560, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 34560, 270, 135, 135, 135, 135]
Prompts retrieved: 3006585 . Total input tokens: 670334443 . Total output tokens: 601394933
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 146.1192374760285,
    "estimated_duration": 3600.0374453562617,
    "input_throughput": 6289.7301330039945,
    "output_throughput": 5562.610751682961,
    "total_throughput": 11852.340884686955,
    "itl": 154.14998305597396,
    "ttft": 2055159.06227204,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 738,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2066571176377643,
    "arrivals": 1001073,
    "finished_requests": 91426,
    "scheduler_time": 162.7364980526169
}
#Debug simulation 
Total elapsed time: 146.11938088713214. Arrivals time: 0.6890349253080785 Scheduler time: 145.1748920828104 Scheduler overhead time: 0.09942997759208083 Adapter cache time: 0.02573783416301012 Engine time: 0.10137219959869981 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_16-16-32/adapters_256_slots_64_rate_3.2-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_16-16-32/adapters_256_slots_64_rate_3.2-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 34560, 135, 34560, 34560, 135, 34560, 270, 34560, 135, 270, 135, 34560, 270, 270, 270, 270, 34560, 135, 135, 135, 270, 34560, 135, 34560, 34560, 270, 270, 270, 135, 34560, 135, 270, 270, 135, 270, 135, 135, 270, 270, 34560, 270, 135, 270, 34560, 270, 270, 34560, 270, 34560, 135, 34560, 34560, 270, 135, 135, 34560, 270, 135, 270, 270, 34560, 270, 135, 135, 34560, 34560, 34560, 34560, 34560, 34560, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 34560, 34560, 135, 34560, 135, 270, 34560, 34560, 34560, 270, 135, 34560, 270, 135, 135, 135, 135, 135, 34560, 270, 135, 34560, 135, 34560, 135, 135, 270, 270, 34560, 270, 34560, 135, 270, 135, 34560, 34560, 135, 34560, 270, 135, 34560, 135, 135, 34560, 34560, 270, 34560, 34560, 135, 34560, 270, 270, 135, 270, 34560, 34560, 135, 34560, 270, 135, 270, 34560, 135, 135, 135, 135, 135, 135, 34560, 135, 135, 135, 34560, 135, 270, 34560, 34560, 270, 135, 34560, 135, 270, 270, 135, 270, 135, 34560, 135, 135, 34560, 135, 34560, 34560, 270, 34560, 270, 135, 270, 34560, 270, 34560, 135, 34560, 135, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 270, 135, 34560, 135, 34560, 270, 270, 135, 270, 34560, 270, 270, 34560, 135, 34560, 34560, 270, 135, 34560, 34560, 270, 270, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 34560, 135, 34560, 270, 34560, 34560, 135, 34560, 270, 270, 34560, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 34560, 270, 135, 135, 135, 135]
Prompts retrieved: 3006585 . Total input tokens: 670334443 . Total output tokens: 601394933
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 144.7532646227628,
    "estimated_duration": 3600.139500830019,
    "input_throughput": 6289.535723485038,
    "output_throughput": 5562.413621856344,
    "total_throughput": 11851.949345341383,
    "itl": 154.160438908217,
    "ttft": 2055163.1460440126,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 738,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.4753025444597117,
    "arrivals": 1001073,
    "finished_requests": 91425,
    "scheduler_time": 162.72951403074674
}
#Debug simulation 
Total elapsed time: 144.75342696299776. Arrivals time: 0.8906785193830729 Scheduler time: 143.59893863881007 Scheduler overhead time: 0.1040243012830615 Adapter cache time: 0.027378985658288002 Engine time: 0.10288512334227562 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-8/adapters_256_slots_64_rate_3.2-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-8/adapters_256_slots_64_rate_3.2-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 34560, 66, 34560, 34560, 66, 34560, 270, 34560, 66, 270, 66, 34560, 270, 270, 270, 270, 34560, 66, 66, 66, 270, 34560, 66, 34560, 34560, 270, 270, 270, 66, 34560, 66, 270, 270, 66, 270, 66, 66, 270, 270, 34560, 270, 66, 270, 34560, 270, 270, 34560, 270, 34560, 66, 34560, 34560, 270, 66, 66, 34560, 270, 66, 270, 270, 34560, 270, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 34560, 34560, 66, 34560, 66, 270, 34560, 34560, 34560, 270, 66, 34560, 270, 66, 66, 66, 66, 66, 34560, 270, 66, 34560, 66, 34560, 66, 66, 270, 270, 34560, 270, 34560, 66, 270, 66, 34560, 34560, 66, 34560, 270, 66, 34560, 66, 66, 34560, 34560, 270, 34560, 34560, 66, 34560, 270, 270, 66, 270, 34560, 34560, 66, 34560, 270, 66, 270, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 270, 34560, 34560, 270, 66, 34560, 66, 270, 270, 66, 270, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 270, 34560, 270, 66, 270, 34560, 270, 34560, 66, 34560, 66, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 270, 66, 34560, 66, 34560, 270, 270, 66, 270, 34560, 270, 270, 34560, 66, 34560, 34560, 270, 66, 34560, 34560, 270, 270, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 34560, 66, 34560, 270, 34560, 34560, 66, 34560, 270, 270, 34560, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 34560, 270, 66, 66, 66, 66]
Prompts retrieved: 3000720 . Total input tokens: 669021209 . Total output tokens: 600212181
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 147.56649703206494,
    "estimated_duration": 3600.1080070253306,
    "input_throughput": 6338.083734008221,
    "output_throughput": 5628.028648157566,
    "total_throughput": 11966.112382165786,
    "itl": 153.01420423889041,
    "ttft": 2059062.0795467398,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 629,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.925046790933733,
    "arrivals": 999127,
    "finished_requests": 92500,
    "scheduler_time": 164.1846969544942
}
#Debug simulation 
Total elapsed time: 147.56666643405333. Arrivals time: 1.0681779724545777 Scheduler time: 146.24127770308405 Scheduler overhead time: 0.10166988568380475 Adapter cache time: 0.026693374384194613 Engine time: 0.1000063382089138 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-16/adapters_256_slots_64_rate_3.2-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-16/adapters_256_slots_64_rate_3.2-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 34560, 66, 34560, 34560, 66, 34560, 270, 34560, 66, 270, 66, 34560, 270, 270, 270, 270, 34560, 66, 66, 66, 270, 34560, 66, 34560, 34560, 270, 270, 270, 66, 34560, 66, 270, 270, 66, 270, 66, 66, 270, 270, 34560, 270, 66, 270, 34560, 270, 270, 34560, 270, 34560, 66, 34560, 34560, 270, 66, 66, 34560, 270, 66, 270, 270, 34560, 270, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 34560, 34560, 66, 34560, 66, 270, 34560, 34560, 34560, 270, 66, 34560, 270, 66, 66, 66, 66, 66, 34560, 270, 66, 34560, 66, 34560, 66, 66, 270, 270, 34560, 270, 34560, 66, 270, 66, 34560, 34560, 66, 34560, 270, 66, 34560, 66, 66, 34560, 34560, 270, 34560, 34560, 66, 34560, 270, 270, 66, 270, 34560, 34560, 66, 34560, 270, 66, 270, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 270, 34560, 34560, 270, 66, 34560, 66, 270, 270, 66, 270, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 270, 34560, 270, 66, 270, 34560, 270, 34560, 66, 34560, 66, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 270, 66, 34560, 66, 34560, 270, 270, 66, 270, 34560, 270, 270, 34560, 66, 34560, 34560, 270, 66, 34560, 34560, 270, 270, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 34560, 66, 34560, 270, 34560, 34560, 66, 34560, 270, 270, 34560, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 34560, 270, 66, 66, 66, 66]
Prompts retrieved: 3000720 . Total input tokens: 669021209 . Total output tokens: 600212181
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 146.5609949720092,
    "estimated_duration": 3600.108473714044,
    "input_throughput": 6337.827086765814,
    "output_throughput": 5627.832091153071,
    "total_throughput": 11965.659177918886,
    "itl": 153.02036080534253,
    "ttft": 2059032.5905945287,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 630,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0553417195333226,
    "arrivals": 999127,
    "finished_requests": 92497,
    "scheduler_time": 164.1775579182911
}
#Debug simulation 
Total elapsed time: 146.56115452712402. Arrivals time: 0.7178182727657259 Scheduler time: 145.58175168279558 Scheduler overhead time: 0.10171266319230199 Adapter cache time: 0.027288279961794615 Engine time: 0.10237804846838117 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-32/adapters_256_slots_64_rate_3.2-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-32/adapters_256_slots_64_rate_3.2-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 34560, 66, 34560, 34560, 66, 34560, 270, 34560, 66, 270, 66, 34560, 270, 270, 270, 270, 34560, 66, 66, 66, 270, 34560, 66, 34560, 34560, 270, 270, 270, 66, 34560, 66, 270, 270, 66, 270, 66, 66, 270, 270, 34560, 270, 66, 270, 34560, 270, 270, 34560, 270, 34560, 66, 34560, 34560, 270, 66, 66, 34560, 270, 66, 270, 270, 34560, 270, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 34560, 34560, 66, 34560, 66, 270, 34560, 34560, 34560, 270, 66, 34560, 270, 66, 66, 66, 66, 66, 34560, 270, 66, 34560, 66, 34560, 66, 66, 270, 270, 34560, 270, 34560, 66, 270, 66, 34560, 34560, 66, 34560, 270, 66, 34560, 66, 66, 34560, 34560, 270, 34560, 34560, 66, 34560, 270, 270, 66, 270, 34560, 34560, 66, 34560, 270, 66, 270, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 270, 34560, 34560, 270, 66, 34560, 66, 270, 270, 66, 270, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 270, 34560, 270, 66, 270, 34560, 270, 34560, 66, 34560, 66, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 270, 66, 34560, 66, 34560, 270, 270, 66, 270, 34560, 270, 270, 34560, 66, 34560, 34560, 270, 66, 34560, 34560, 270, 270, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 34560, 66, 34560, 270, 34560, 34560, 66, 34560, 270, 270, 34560, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 34560, 270, 66, 66, 66, 66]
Prompts retrieved: 3000720 . Total input tokens: 669021209 . Total output tokens: 600212181
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 146.8683989327401,
    "estimated_duration": 3600.1122021077263,
    "input_throughput": 6337.820523105254,
    "output_throughput": 5627.8262627865,
    "total_throughput": 11965.646785891755,
    "itl": 153.02050837756812,
    "ttft": 2059033.0716265053,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 630,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0590608224272833,
    "arrivals": 999127,
    "finished_requests": 92497,
    "scheduler_time": 164.17756720901508
}
#Debug simulation 
Total elapsed time: 146.86858296999708. Arrivals time: 0.7004448808729649 Scheduler time: 145.90724032232538 Scheduler overhead time: 0.1007817811332643 Adapter cache time: 0.027768456377089024 Engine time: 0.1033706022426486 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-16-16/adapters_256_slots_64_rate_3.2-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-16-16/adapters_256_slots_64_rate_3.2-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 34560, 66, 34560, 34560, 66, 34560, 270, 34560, 66, 270, 66, 34560, 270, 270, 270, 270, 34560, 66, 66, 66, 270, 34560, 66, 34560, 34560, 270, 270, 270, 66, 34560, 66, 270, 270, 66, 270, 66, 66, 270, 270, 34560, 270, 66, 270, 34560, 270, 270, 34560, 270, 34560, 66, 34560, 34560, 270, 66, 66, 34560, 270, 66, 270, 270, 34560, 270, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 34560, 34560, 66, 34560, 66, 270, 34560, 34560, 34560, 270, 66, 34560, 270, 66, 66, 66, 66, 66, 34560, 270, 66, 34560, 66, 34560, 66, 66, 270, 270, 34560, 270, 34560, 66, 270, 66, 34560, 34560, 66, 34560, 270, 66, 34560, 66, 66, 34560, 34560, 270, 34560, 34560, 66, 34560, 270, 270, 66, 270, 34560, 34560, 66, 34560, 270, 66, 270, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 270, 34560, 34560, 270, 66, 34560, 66, 270, 270, 66, 270, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 270, 34560, 270, 66, 270, 34560, 270, 34560, 66, 34560, 66, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 270, 66, 34560, 66, 34560, 270, 270, 66, 270, 34560, 270, 270, 34560, 66, 34560, 34560, 270, 66, 34560, 34560, 270, 270, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 34560, 66, 34560, 270, 34560, 34560, 66, 34560, 270, 270, 34560, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 34560, 270, 66, 66, 66, 66]
Prompts retrieved: 3000720 . Total input tokens: 669021209 . Total output tokens: 600212181
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 145.63650846201926,
    "estimated_duration": 3600.000466817523,
    "input_throughput": 6338.017233695137,
    "output_throughput": 5628.000936875151,
    "total_throughput": 11966.018170570289,
    "itl": 153.01631512980398,
    "ttft": 2059012.3477331859,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 629,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.973492772779417,
    "arrivals": 999127,
    "finished_requests": 92497,
    "scheduler_time": 164.17716502492596
}
#Debug simulation 
Total elapsed time: 145.63666759524494. Arrivals time: 0.7052941783331335 Scheduler time: 144.6725044338964 Scheduler overhead time: 0.10207024030387402 Adapter cache time: 0.025937682949006557 Engine time: 0.10201902454718947 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-16-32/adapters_256_slots_64_rate_3.2-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-16-32/adapters_256_slots_64_rate_3.2-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 34560, 66, 34560, 34560, 66, 34560, 270, 34560, 66, 270, 66, 34560, 270, 270, 270, 270, 34560, 66, 66, 66, 270, 34560, 66, 34560, 34560, 270, 270, 270, 66, 34560, 66, 270, 270, 66, 270, 66, 66, 270, 270, 34560, 270, 66, 270, 34560, 270, 270, 34560, 270, 34560, 66, 34560, 34560, 270, 66, 66, 34560, 270, 66, 270, 270, 34560, 270, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 34560, 34560, 66, 34560, 66, 270, 34560, 34560, 34560, 270, 66, 34560, 270, 66, 66, 66, 66, 66, 34560, 270, 66, 34560, 66, 34560, 66, 66, 270, 270, 34560, 270, 34560, 66, 270, 66, 34560, 34560, 66, 34560, 270, 66, 34560, 66, 66, 34560, 34560, 270, 34560, 34560, 66, 34560, 270, 270, 66, 270, 34560, 34560, 66, 34560, 270, 66, 270, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 270, 34560, 34560, 270, 66, 34560, 66, 270, 270, 66, 270, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 270, 34560, 270, 66, 270, 34560, 270, 34560, 66, 34560, 66, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 270, 66, 34560, 66, 34560, 270, 270, 66, 270, 34560, 270, 270, 34560, 66, 34560, 34560, 270, 66, 34560, 34560, 270, 270, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 34560, 66, 34560, 270, 34560, 34560, 66, 34560, 270, 270, 34560, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 34560, 270, 66, 66, 66, 66]
Prompts retrieved: 3000720 . Total input tokens: 669021209 . Total output tokens: 600212181
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 146.84657789301127,
    "estimated_duration": 3600.1365972123,
    "input_throughput": 6337.777577014112,
    "output_throughput": 5627.78812773065,
    "total_throughput": 11965.565704744762,
    "itl": 153.0214044357581,
    "ttft": 2059038.0413677199,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 630,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0833313032053455,
    "arrivals": 999127,
    "finished_requests": 92497,
    "scheduler_time": 164.17769183286444
}
#Debug simulation 
Total elapsed time: 146.8467657151632. Arrivals time: 0.719959442038089 Scheduler time: 145.86417033988982 Scheduler overhead time: 0.10239084716886282 Adapter cache time: 0.02691009035333991 Engine time: 0.10320734791457653 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_16-16-16/adapters_256_slots_64_rate_3.2-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_16-16-16/adapters_256_slots_64_rate_3.2-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 34560, 66, 34560, 34560, 66, 34560, 270, 34560, 66, 270, 66, 34560, 270, 270, 270, 270, 34560, 66, 66, 66, 270, 34560, 66, 34560, 34560, 270, 270, 270, 66, 34560, 66, 270, 270, 66, 270, 66, 66, 270, 270, 34560, 270, 66, 270, 34560, 270, 270, 34560, 270, 34560, 66, 34560, 34560, 270, 66, 66, 34560, 270, 66, 270, 270, 34560, 270, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 34560, 34560, 66, 34560, 66, 270, 34560, 34560, 34560, 270, 66, 34560, 270, 66, 66, 66, 66, 66, 34560, 270, 66, 34560, 66, 34560, 66, 66, 270, 270, 34560, 270, 34560, 66, 270, 66, 34560, 34560, 66, 34560, 270, 66, 34560, 66, 66, 34560, 34560, 270, 34560, 34560, 66, 34560, 270, 270, 66, 270, 34560, 34560, 66, 34560, 270, 66, 270, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 270, 34560, 34560, 270, 66, 34560, 66, 270, 270, 66, 270, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 270, 34560, 270, 66, 270, 34560, 270, 34560, 66, 34560, 66, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 270, 66, 34560, 66, 34560, 270, 270, 66, 270, 34560, 270, 270, 34560, 66, 34560, 34560, 270, 66, 34560, 34560, 270, 270, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 34560, 66, 34560, 270, 34560, 34560, 66, 34560, 270, 270, 34560, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 34560, 270, 66, 66, 66, 66]
Prompts retrieved: 3000720 . Total input tokens: 669021209 . Total output tokens: 600212181
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 145.81001669494435,
    "estimated_duration": 3600.063523744405,
    "input_throughput": 6338.162048948335,
    "output_throughput": 5628.098189480313,
    "total_throughput": 11966.260238428647,
    "itl": 153.0125081850965,
    "ttft": 2059054.338360188,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 629,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8807416354934385,
    "arrivals": 999127,
    "finished_requests": 92500,
    "scheduler_time": 164.18451882888945
}
#Debug simulation 
Total elapsed time: 145.81018311390653. Arrivals time: 0.6941954167559743 Scheduler time: 144.8538225358352 Scheduler overhead time: 0.10094994306564331 Adapter cache time: 0.02679559774696827 Engine time: 0.10434541432186961 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_16-16-32/adapters_256_slots_64_rate_3.2-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_16-16-32/adapters_256_slots_64_rate_3.2-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 34560, 66, 34560, 34560, 66, 34560, 270, 34560, 66, 270, 66, 34560, 270, 270, 270, 270, 34560, 66, 66, 66, 270, 34560, 66, 34560, 34560, 270, 270, 270, 66, 34560, 66, 270, 270, 66, 270, 66, 66, 270, 270, 34560, 270, 66, 270, 34560, 270, 270, 34560, 270, 34560, 66, 34560, 34560, 270, 66, 66, 34560, 270, 66, 270, 270, 34560, 270, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 34560, 34560, 66, 34560, 66, 270, 34560, 34560, 34560, 270, 66, 34560, 270, 66, 66, 66, 66, 66, 34560, 270, 66, 34560, 66, 34560, 66, 66, 270, 270, 34560, 270, 34560, 66, 270, 66, 34560, 34560, 66, 34560, 270, 66, 34560, 66, 66, 34560, 34560, 270, 34560, 34560, 66, 34560, 270, 270, 66, 270, 34560, 34560, 66, 34560, 270, 66, 270, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 270, 34560, 34560, 270, 66, 34560, 66, 270, 270, 66, 270, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 270, 34560, 270, 66, 270, 34560, 270, 34560, 66, 34560, 66, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 270, 66, 34560, 66, 34560, 270, 270, 66, 270, 34560, 270, 270, 34560, 66, 34560, 34560, 270, 66, 34560, 34560, 270, 270, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 34560, 66, 34560, 270, 34560, 34560, 66, 34560, 270, 270, 34560, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 34560, 270, 66, 66, 66, 66]
Prompts retrieved: 3000720 . Total input tokens: 669021209 . Total output tokens: 600212181
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 147.88955276599154,
    "estimated_duration": 3600.0092699510583,
    "input_throughput": 6337.628402915244,
    "output_throughput": 5627.718564256761,
    "total_throughput": 11965.346967172005,
    "itl": 153.02245682646713,
    "ttft": 2059024.9125686951,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 630,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1118774127215127,
    "arrivals": 999127,
    "finished_requests": 92494,
    "scheduler_time": 164.17014328425262
}
#Debug simulation 
Total elapsed time: 147.88977231783792. Arrivals time: 0.7236613016575575 Scheduler time: 146.90080496296287 Scheduler overhead time: 0.10461478913202882 Adapter cache time: 0.027044976595789194 Engine time: 0.10354767553508282 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-8/adapters_256_slots_64_rate_3.2-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-8/adapters_256_slots_64_rate_3.2-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [270, 270, 34560, 33, 34560, 34560, 33, 34560, 270, 34560, 33, 270, 33, 34560, 270, 270, 270, 270, 34560, 33, 33, 33, 270, 34560, 33, 34560, 34560, 270, 270, 270, 33, 34560, 33, 270, 270, 33, 270, 33, 33, 270, 270, 34560, 270, 33, 270, 34560, 270, 270, 34560, 270, 34560, 33, 34560, 34560, 270, 33, 33, 34560, 270, 33, 270, 270, 34560, 270, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 34560, 34560, 33, 34560, 33, 270, 34560, 34560, 34560, 270, 33, 34560, 270, 33, 33, 33, 33, 33, 34560, 270, 33, 34560, 33, 34560, 33, 33, 270, 270, 34560, 270, 34560, 33, 270, 33, 34560, 34560, 33, 34560, 270, 33, 34560, 33, 33, 34560, 34560, 270, 34560, 34560, 33, 34560, 270, 270, 33, 270, 34560, 34560, 33, 34560, 270, 33, 270, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 270, 34560, 34560, 270, 33, 34560, 33, 270, 270, 33, 270, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 270, 34560, 270, 33, 270, 34560, 270, 34560, 33, 34560, 33, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 270, 33, 34560, 33, 34560, 270, 270, 33, 270, 34560, 270, 270, 34560, 33, 34560, 34560, 270, 33, 34560, 34560, 270, 270, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 34560, 33, 34560, 270, 34560, 34560, 33, 34560, 270, 270, 34560, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 34560, 270, 33, 33, 33, 33]
Prompts retrieved: 2997915 . Total input tokens: 668391315 . Total output tokens: 599640789
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 145.50274642230943,
    "estimated_duration": 3600.0198072289922,
    "input_throughput": 6392.8348265713,
    "output_throughput": 5627.312371815345,
    "total_throughput": 12020.147198386645,
    "itl": 151.76442089187682,
    "ttft": 2060150.6885655571,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 542,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6587843572115741,
    "arrivals": 998127,
    "finished_requests": 93290,
    "scheduler_time": 164.764050676478
}
#Debug simulation 
Total elapsed time: 145.50291403010488. Arrivals time: 0.7195509797893465 Scheduler time: 144.51515393843874 Scheduler overhead time: 0.1058444264344871 Adapter cache time: 0.027795298490673304 Engine time: 0.10346332285553217 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-16/adapters_256_slots_64_rate_3.2-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-16/adapters_256_slots_64_rate_3.2-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [270, 270, 34560, 33, 34560, 34560, 33, 34560, 270, 34560, 33, 270, 33, 34560, 270, 270, 270, 270, 34560, 33, 33, 33, 270, 34560, 33, 34560, 34560, 270, 270, 270, 33, 34560, 33, 270, 270, 33, 270, 33, 33, 270, 270, 34560, 270, 33, 270, 34560, 270, 270, 34560, 270, 34560, 33, 34560, 34560, 270, 33, 33, 34560, 270, 33, 270, 270, 34560, 270, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 34560, 34560, 33, 34560, 33, 270, 34560, 34560, 34560, 270, 33, 34560, 270, 33, 33, 33, 33, 33, 34560, 270, 33, 34560, 33, 34560, 33, 33, 270, 270, 34560, 270, 34560, 33, 270, 33, 34560, 34560, 33, 34560, 270, 33, 34560, 33, 33, 34560, 34560, 270, 34560, 34560, 33, 34560, 270, 270, 33, 270, 34560, 34560, 33, 34560, 270, 33, 270, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 270, 34560, 34560, 270, 33, 34560, 33, 270, 270, 33, 270, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 270, 34560, 270, 33, 270, 34560, 270, 34560, 33, 34560, 33, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 270, 33, 34560, 33, 34560, 270, 270, 33, 270, 34560, 270, 270, 34560, 33, 34560, 34560, 270, 33, 34560, 34560, 270, 270, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 34560, 33, 34560, 270, 34560, 34560, 33, 34560, 270, 270, 34560, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 34560, 270, 33, 33, 33, 33]
Prompts retrieved: 2997915 . Total input tokens: 668391315 . Total output tokens: 599640789
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 145.97374288644642,
    "estimated_duration": 3600.1287417826284,
    "input_throughput": 6392.641388875526,
    "output_throughput": 5627.142097693122,
    "total_throughput": 12019.783486568647,
    "itl": 151.76843182433285,
    "ttft": 2060170.6903897347,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 542,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7672929791570693,
    "arrivals": 998127,
    "finished_requests": 93290,
    "scheduler_time": 164.76447660811743
}
#Debug simulation 
Total elapsed time: 145.97389381099492. Arrivals time: 0.7198899248614907 Scheduler time: 144.9918691245839 Scheduler overhead time: 0.10165255283936858 Adapter cache time: 0.02622803393751383 Engine time: 0.10357588576152921 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-32/adapters_256_slots_64_rate_3.2-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-32/adapters_256_slots_64_rate_3.2-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [270, 270, 34560, 33, 34560, 34560, 33, 34560, 270, 34560, 33, 270, 33, 34560, 270, 270, 270, 270, 34560, 33, 33, 33, 270, 34560, 33, 34560, 34560, 270, 270, 270, 33, 34560, 33, 270, 270, 33, 270, 33, 33, 270, 270, 34560, 270, 33, 270, 34560, 270, 270, 34560, 270, 34560, 33, 34560, 34560, 270, 33, 33, 34560, 270, 33, 270, 270, 34560, 270, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 34560, 34560, 33, 34560, 33, 270, 34560, 34560, 34560, 270, 33, 34560, 270, 33, 33, 33, 33, 33, 34560, 270, 33, 34560, 33, 34560, 33, 33, 270, 270, 34560, 270, 34560, 33, 270, 33, 34560, 34560, 33, 34560, 270, 33, 34560, 33, 33, 34560, 34560, 270, 34560, 34560, 33, 34560, 270, 270, 33, 270, 34560, 34560, 33, 34560, 270, 33, 270, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 270, 34560, 34560, 270, 33, 34560, 33, 270, 270, 33, 270, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 270, 34560, 270, 33, 270, 34560, 270, 34560, 33, 34560, 33, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 270, 33, 34560, 33, 34560, 270, 270, 33, 270, 34560, 270, 270, 34560, 33, 34560, 34560, 270, 33, 34560, 34560, 270, 270, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 34560, 33, 34560, 270, 34560, 34560, 33, 34560, 270, 270, 34560, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 34560, 270, 33, 33, 33, 33]
Prompts retrieved: 2997915 . Total input tokens: 668391315 . Total output tokens: 599640789
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 146.60095569165424,
    "estimated_duration": 3600.132123888585,
    "input_throughput": 6392.635383376345,
    "output_throughput": 5627.136811334135,
    "total_throughput": 12019.77219471048,
    "itl": 151.76856656125264,
    "ttft": 2060171.3672163896,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 542,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.770659066569071,
    "arrivals": 998127,
    "finished_requests": 93290,
    "scheduler_time": 164.76449262660708
}
#Debug simulation 
Total elapsed time: 146.60111901070923. Arrivals time: 0.7083469284698367 Scheduler time: 145.6304009188898 Scheduler overhead time: 0.10323922242969275 Adapter cache time: 0.026104845106601715 Engine time: 0.10249581886455417 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-16-16/adapters_256_slots_64_rate_3.2-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-16-16/adapters_256_slots_64_rate_3.2-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [270, 270, 34560, 33, 34560, 34560, 33, 34560, 270, 34560, 33, 270, 33, 34560, 270, 270, 270, 270, 34560, 33, 33, 33, 270, 34560, 33, 34560, 34560, 270, 270, 270, 33, 34560, 33, 270, 270, 33, 270, 33, 33, 270, 270, 34560, 270, 33, 270, 34560, 270, 270, 34560, 270, 34560, 33, 34560, 34560, 270, 33, 33, 34560, 270, 33, 270, 270, 34560, 270, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 34560, 34560, 33, 34560, 33, 270, 34560, 34560, 34560, 270, 33, 34560, 270, 33, 33, 33, 33, 33, 34560, 270, 33, 34560, 33, 34560, 33, 33, 270, 270, 34560, 270, 34560, 33, 270, 33, 34560, 34560, 33, 34560, 270, 33, 34560, 33, 33, 34560, 34560, 270, 34560, 34560, 33, 34560, 270, 270, 33, 270, 34560, 34560, 33, 34560, 270, 33, 270, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 270, 34560, 34560, 270, 33, 34560, 33, 270, 270, 33, 270, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 270, 34560, 270, 33, 270, 34560, 270, 34560, 33, 34560, 33, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 270, 33, 34560, 33, 34560, 270, 270, 33, 270, 34560, 270, 270, 34560, 33, 34560, 34560, 270, 33, 34560, 34560, 270, 270, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 34560, 33, 34560, 270, 34560, 34560, 33, 34560, 270, 270, 34560, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 34560, 270, 33, 33, 33, 33]
Prompts retrieved: 2997915 . Total input tokens: 668391315 . Total output tokens: 599640789
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 146.54486522823572,
    "estimated_duration": 3600.0642983783705,
    "input_throughput": 6392.755821157606,
    "output_throughput": 5627.242827058756,
    "total_throughput": 12019.998648216362,
    "itl": 151.7660959255406,
    "ttft": 2060157.477176096,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 542,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7031435141619244,
    "arrivals": 998127,
    "finished_requests": 93290,
    "scheduler_time": 164.7641826688326
}
#Debug simulation 
Total elapsed time: 146.5450263209641. Arrivals time: 0.7401375654153526 Scheduler time: 145.54095899267122 Scheduler overhead time: 0.10506126005202532 Adapter cache time: 0.02660044329240918 Engine time: 0.10142367985099554 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-16-32/adapters_256_slots_64_rate_3.2-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-16-32/adapters_256_slots_64_rate_3.2-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [270, 270, 34560, 33, 34560, 34560, 33, 34560, 270, 34560, 33, 270, 33, 34560, 270, 270, 270, 270, 34560, 33, 33, 33, 270, 34560, 33, 34560, 34560, 270, 270, 270, 33, 34560, 33, 270, 270, 33, 270, 33, 33, 270, 270, 34560, 270, 33, 270, 34560, 270, 270, 34560, 270, 34560, 33, 34560, 34560, 270, 33, 33, 34560, 270, 33, 270, 270, 34560, 270, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 34560, 34560, 33, 34560, 33, 270, 34560, 34560, 34560, 270, 33, 34560, 270, 33, 33, 33, 33, 33, 34560, 270, 33, 34560, 33, 34560, 33, 33, 270, 270, 34560, 270, 34560, 33, 270, 33, 34560, 34560, 33, 34560, 270, 33, 34560, 33, 33, 34560, 34560, 270, 34560, 34560, 33, 34560, 270, 270, 33, 270, 34560, 34560, 33, 34560, 270, 33, 270, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 270, 34560, 34560, 270, 33, 34560, 33, 270, 270, 33, 270, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 270, 34560, 270, 33, 270, 34560, 270, 34560, 33, 34560, 33, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 270, 33, 34560, 33, 34560, 270, 270, 33, 270, 34560, 270, 270, 34560, 33, 34560, 34560, 270, 33, 34560, 34560, 270, 270, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 34560, 33, 34560, 270, 34560, 34560, 33, 34560, 270, 270, 34560, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 34560, 270, 33, 33, 33, 33]
Prompts retrieved: 2997915 . Total input tokens: 668391315 . Total output tokens: 599640789
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 146.4952367809601,
    "estimated_duration": 3600.151951970818,
    "input_throughput": 6392.6001755013,
    "output_throughput": 5627.105819494646,
    "total_throughput": 12019.705994995946,
    "itl": 151.76928522766005,
    "ttft": 2060175.4294917046,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 542,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7904024110361991,
    "arrivals": 998127,
    "finished_requests": 93290,
    "scheduler_time": 164.76457736441725
}
#Debug simulation 
Total elapsed time: 146.49544733483344. Arrivals time: 0.7271495135501027 Scheduler time: 145.50483063748106 Scheduler overhead time: 0.10509509034454823 Adapter cache time: 0.02704703900963068 Engine time: 0.10113431932404637 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_16-16-16/adapters_256_slots_64_rate_3.2-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_16-16-16/adapters_256_slots_64_rate_3.2-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [270, 270, 34560, 33, 34560, 34560, 33, 34560, 270, 34560, 33, 270, 33, 34560, 270, 270, 270, 270, 34560, 33, 33, 33, 270, 34560, 33, 34560, 34560, 270, 270, 270, 33, 34560, 33, 270, 270, 33, 270, 33, 33, 270, 270, 34560, 270, 33, 270, 34560, 270, 270, 34560, 270, 34560, 33, 34560, 34560, 270, 33, 33, 34560, 270, 33, 270, 270, 34560, 270, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 34560, 34560, 33, 34560, 33, 270, 34560, 34560, 34560, 270, 33, 34560, 270, 33, 33, 33, 33, 33, 34560, 270, 33, 34560, 33, 34560, 33, 33, 270, 270, 34560, 270, 34560, 33, 270, 33, 34560, 34560, 33, 34560, 270, 33, 34560, 33, 33, 34560, 34560, 270, 34560, 34560, 33, 34560, 270, 270, 33, 270, 34560, 34560, 33, 34560, 270, 33, 270, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 270, 34560, 34560, 270, 33, 34560, 33, 270, 270, 33, 270, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 270, 34560, 270, 33, 270, 34560, 270, 34560, 33, 34560, 33, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 270, 33, 34560, 33, 34560, 270, 270, 33, 270, 34560, 270, 270, 34560, 33, 34560, 34560, 270, 33, 34560, 34560, 270, 270, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 34560, 33, 34560, 270, 34560, 34560, 33, 34560, 270, 270, 34560, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 34560, 270, 33, 33, 33, 33]
Prompts retrieved: 2997915 . Total input tokens: 668391315 . Total output tokens: 599640789
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 147.0079870908521,
    "estimated_duration": 3600.1378752691385,
    "input_throughput": 6393.077931294333,
    "output_throughput": 5627.326980771665,
    "total_throughput": 12020.404912065998,
    "itl": 151.76151966261008,
    "ttft": 2060158.6086463858,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 542,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6206072598369585,
    "arrivals": 998127,
    "finished_requests": 93294,
    "scheduler_time": 164.77167675904073
}
#Debug simulation 
Total elapsed time: 147.0081443618983. Arrivals time: 1.1320021343417466 Scheduler time: 145.61003077868372 Scheduler overhead time: 0.10500774858519435 Adapter cache time: 0.027203666511923075 Engine time: 0.10277755605056882 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_16-16-32/adapters_256_slots_64_rate_3.2-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_16-16-32/adapters_256_slots_64_rate_3.2-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [270, 270, 34560, 33, 34560, 34560, 33, 34560, 270, 34560, 33, 270, 33, 34560, 270, 270, 270, 270, 34560, 33, 33, 33, 270, 34560, 33, 34560, 34560, 270, 270, 270, 33, 34560, 33, 270, 270, 33, 270, 33, 33, 270, 270, 34560, 270, 33, 270, 34560, 270, 270, 34560, 270, 34560, 33, 34560, 34560, 270, 33, 33, 34560, 270, 33, 270, 270, 34560, 270, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 34560, 34560, 33, 34560, 33, 270, 34560, 34560, 34560, 270, 33, 34560, 270, 33, 33, 33, 33, 33, 34560, 270, 33, 34560, 33, 34560, 33, 33, 270, 270, 34560, 270, 34560, 33, 270, 33, 34560, 34560, 33, 34560, 270, 33, 34560, 33, 33, 34560, 34560, 270, 34560, 34560, 33, 34560, 270, 270, 33, 270, 34560, 34560, 33, 34560, 270, 33, 270, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 270, 34560, 34560, 270, 33, 34560, 33, 270, 270, 33, 270, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 270, 34560, 270, 33, 270, 34560, 270, 34560, 33, 34560, 33, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 270, 33, 34560, 33, 34560, 270, 270, 33, 270, 34560, 270, 270, 34560, 33, 34560, 34560, 270, 33, 34560, 34560, 270, 270, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 34560, 33, 34560, 270, 34560, 34560, 33, 34560, 270, 270, 34560, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 34560, 270, 33, 33, 33, 33]
Prompts retrieved: 2997915 . Total input tokens: 668391315 . Total output tokens: 599640789
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 146.99057740019634,
    "estimated_duration": 3600.0215734180874,
    "input_throughput": 6392.612802636483,
    "output_throughput": 5627.1712785226,
    "total_throughput": 12019.784081159083,
    "itl": 151.77093032784515,
    "ttft": 2060113.04678745,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 542,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8158046758919923,
    "arrivals": 998127,
    "finished_requests": 93286,
    "scheduler_time": 164.75691091581825
}
#Debug simulation 
Total elapsed time: 146.9907429763116. Arrivals time: 0.7325235237367451 Scheduler time: 145.99410102516413 Scheduler overhead time: 0.10503730969503522 Adapter cache time: 0.027281688060611486 Engine time: 0.10146938124671578 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-8/adapters_256_slots_64_rate_3.2-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-8/adapters_256_slots_64_rate_3.2-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 34560, 66, 34560, 34560, 66, 34560, 135, 34560, 66, 135, 66, 34560, 135, 135, 135, 135, 34560, 66, 66, 66, 135, 34560, 66, 34560, 34560, 135, 135, 135, 66, 34560, 66, 135, 135, 66, 135, 66, 66, 135, 135, 34560, 135, 66, 135, 34560, 135, 135, 34560, 135, 34560, 66, 34560, 34560, 135, 66, 66, 34560, 135, 66, 135, 135, 34560, 135, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 34560, 34560, 66, 34560, 66, 135, 34560, 34560, 34560, 135, 66, 34560, 135, 66, 66, 66, 66, 66, 34560, 135, 66, 34560, 66, 34560, 66, 66, 135, 135, 34560, 135, 34560, 66, 135, 66, 34560, 34560, 66, 34560, 135, 66, 34560, 66, 66, 34560, 34560, 135, 34560, 34560, 66, 34560, 135, 135, 66, 135, 34560, 34560, 66, 34560, 135, 66, 135, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 135, 34560, 34560, 135, 66, 34560, 66, 135, 135, 66, 135, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 135, 34560, 135, 66, 135, 34560, 135, 34560, 66, 34560, 66, 135, 34560, 135, 34560, 135, 34560, 135, 34560, 135, 66, 34560, 66, 34560, 135, 135, 66, 135, 34560, 135, 135, 34560, 66, 34560, 34560, 135, 66, 34560, 34560, 135, 135, 34560, 34560, 135, 135, 135, 135, 34560, 34560, 135, 135, 34560, 66, 34560, 135, 34560, 34560, 66, 34560, 135, 135, 34560, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 34560, 135, 66, 66, 66, 66]
Prompts retrieved: 2989245 . Total input tokens: 666447743 . Total output tokens: 597918174
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 150.63636472495273,
    "estimated_duration": 3600.12482736257,
    "input_throughput": 6427.200474865559,
    "output_throughput": 5669.175092173693,
    "total_throughput": 12096.375567039253,
    "itl": 151.0403850241589,
    "ttft": 2068950.09836084,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 423,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2945863156835637,
    "arrivals": 995247,
    "finished_requests": 93358,
    "scheduler_time": 166.0213340626346
}
#Debug simulation 
Total elapsed time: 150.63651415286586. Arrivals time: 0.7279024608433247 Scheduler time: 149.64126726984978 Scheduler overhead time: 0.10688196402043104 Adapter cache time: 0.025740901473909616 Engine time: 0.105097611900419 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-16/adapters_256_slots_64_rate_3.2-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-16/adapters_256_slots_64_rate_3.2-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 34560, 66, 34560, 34560, 66, 34560, 135, 34560, 66, 135, 66, 34560, 135, 135, 135, 135, 34560, 66, 66, 66, 135, 34560, 66, 34560, 34560, 135, 135, 135, 66, 34560, 66, 135, 135, 66, 135, 66, 66, 135, 135, 34560, 135, 66, 135, 34560, 135, 135, 34560, 135, 34560, 66, 34560, 34560, 135, 66, 66, 34560, 135, 66, 135, 135, 34560, 135, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 34560, 34560, 66, 34560, 66, 135, 34560, 34560, 34560, 135, 66, 34560, 135, 66, 66, 66, 66, 66, 34560, 135, 66, 34560, 66, 34560, 66, 66, 135, 135, 34560, 135, 34560, 66, 135, 66, 34560, 34560, 66, 34560, 135, 66, 34560, 66, 66, 34560, 34560, 135, 34560, 34560, 66, 34560, 135, 135, 66, 135, 34560, 34560, 66, 34560, 135, 66, 135, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 135, 34560, 34560, 135, 66, 34560, 66, 135, 135, 66, 135, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 135, 34560, 135, 66, 135, 34560, 135, 34560, 66, 34560, 66, 135, 34560, 135, 34560, 135, 34560, 135, 34560, 135, 66, 34560, 66, 34560, 135, 135, 66, 135, 34560, 135, 135, 34560, 66, 34560, 34560, 135, 66, 34560, 34560, 135, 135, 34560, 34560, 135, 135, 135, 135, 34560, 34560, 135, 135, 34560, 66, 34560, 135, 34560, 34560, 66, 34560, 135, 135, 34560, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 34560, 135, 66, 66, 66, 66]
Prompts retrieved: 2989245 . Total input tokens: 666447743 . Total output tokens: 597918174
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 150.24089166522026,
    "estimated_duration": 3600.0575909219997,
    "input_throughput": 6427.119682292137,
    "output_throughput": 5668.937366852857,
    "total_throughput": 12096.057049144994,
    "itl": 151.04325141687903,
    "ttft": 2068953.18177012,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 423,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3828753217728875,
    "arrivals": 995247,
    "finished_requests": 93354,
    "scheduler_time": 166.01389831601094
}
#Debug simulation 
Total elapsed time: 150.24103547725827. Arrivals time: 0.724685781635344 Scheduler time: 149.25098650110886 Scheduler overhead time: 0.10666723875328898 Adapter cache time: 0.02542649209499359 Engine time: 0.1032487154006958 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-32/adapters_256_slots_64_rate_3.2-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-32/adapters_256_slots_64_rate_3.2-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 34560, 66, 34560, 34560, 66, 34560, 135, 34560, 66, 135, 66, 34560, 135, 135, 135, 135, 34560, 66, 66, 66, 135, 34560, 66, 34560, 34560, 135, 135, 135, 66, 34560, 66, 135, 135, 66, 135, 66, 66, 135, 135, 34560, 135, 66, 135, 34560, 135, 135, 34560, 135, 34560, 66, 34560, 34560, 135, 66, 66, 34560, 135, 66, 135, 135, 34560, 135, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 34560, 34560, 66, 34560, 66, 135, 34560, 34560, 34560, 135, 66, 34560, 135, 66, 66, 66, 66, 66, 34560, 135, 66, 34560, 66, 34560, 66, 66, 135, 135, 34560, 135, 34560, 66, 135, 66, 34560, 34560, 66, 34560, 135, 66, 34560, 66, 66, 34560, 34560, 135, 34560, 34560, 66, 34560, 135, 135, 66, 135, 34560, 34560, 66, 34560, 135, 66, 135, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 135, 34560, 34560, 135, 66, 34560, 66, 135, 135, 66, 135, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 135, 34560, 135, 66, 135, 34560, 135, 34560, 66, 34560, 66, 135, 34560, 135, 34560, 135, 34560, 135, 34560, 135, 66, 34560, 66, 34560, 135, 135, 66, 135, 34560, 135, 135, 34560, 66, 34560, 34560, 135, 66, 34560, 34560, 135, 135, 34560, 34560, 135, 135, 135, 135, 34560, 34560, 135, 135, 34560, 66, 34560, 135, 34560, 34560, 66, 34560, 135, 135, 34560, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 34560, 135, 66, 66, 66, 66]
Prompts retrieved: 2989245 . Total input tokens: 666447743 . Total output tokens: 597918174
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 149.25145015260205,
    "estimated_duration": 3600.0595974093894,
    "input_throughput": 6427.116100147385,
    "output_throughput": 5668.934207279791,
    "total_throughput": 12096.050307427176,
    "itl": 151.04332636092417,
    "ttft": 2068953.589516188,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 423,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3848729989491484,
    "arrivals": 995247,
    "finished_requests": 93354,
    "scheduler_time": 166.01390712618024
}
#Debug simulation 
Total elapsed time: 149.25159057881683. Arrivals time: 0.7418002639897168 Scheduler time: 148.2466919431463 Scheduler overhead time: 0.10423266002908349 Adapter cache time: 0.02493189973756671 Engine time: 0.10338940052315593 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-16-16/adapters_256_slots_64_rate_3.2-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-16-16/adapters_256_slots_64_rate_3.2-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 34560, 66, 34560, 34560, 66, 34560, 135, 34560, 66, 135, 66, 34560, 135, 135, 135, 135, 34560, 66, 66, 66, 135, 34560, 66, 34560, 34560, 135, 135, 135, 66, 34560, 66, 135, 135, 66, 135, 66, 66, 135, 135, 34560, 135, 66, 135, 34560, 135, 135, 34560, 135, 34560, 66, 34560, 34560, 135, 66, 66, 34560, 135, 66, 135, 135, 34560, 135, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 34560, 34560, 66, 34560, 66, 135, 34560, 34560, 34560, 135, 66, 34560, 135, 66, 66, 66, 66, 66, 34560, 135, 66, 34560, 66, 34560, 66, 66, 135, 135, 34560, 135, 34560, 66, 135, 66, 34560, 34560, 66, 34560, 135, 66, 34560, 66, 66, 34560, 34560, 135, 34560, 34560, 66, 34560, 135, 135, 66, 135, 34560, 34560, 66, 34560, 135, 66, 135, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 135, 34560, 34560, 135, 66, 34560, 66, 135, 135, 66, 135, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 135, 34560, 135, 66, 135, 34560, 135, 34560, 66, 34560, 66, 135, 34560, 135, 34560, 135, 34560, 135, 34560, 135, 66, 34560, 66, 34560, 135, 135, 66, 135, 34560, 135, 135, 34560, 66, 34560, 34560, 135, 66, 34560, 34560, 135, 135, 34560, 34560, 135, 135, 135, 135, 34560, 34560, 135, 135, 34560, 66, 34560, 135, 34560, 34560, 66, 34560, 135, 135, 34560, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 34560, 135, 66, 66, 66, 66]
Prompts retrieved: 2989245 . Total input tokens: 666447743 . Total output tokens: 597918174
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 149.04523491626605,
    "estimated_duration": 3600.0012442973893,
    "input_throughput": 6427.220278507385,
    "output_throughput": 5669.0260961237855,
    "total_throughput": 12096.246374631171,
    "itl": 151.04133378889162,
    "ttft": 2068939.6628359545,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 423,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.326897763146553,
    "arrivals": 995247,
    "finished_requests": 93354,
    "scheduler_time": 166.01352925000973
}
#Debug simulation 
Total elapsed time: 149.0454164110124. Arrivals time: 0.8574276152066886 Scheduler time: 147.9239878472872 Scheduler overhead time: 0.10568883595988154 Adapter cache time: 0.02518341224640608 Engine time: 0.10226481035351753 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-16-32/adapters_256_slots_64_rate_3.2-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-16-32/adapters_256_slots_64_rate_3.2-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 34560, 66, 34560, 34560, 66, 34560, 135, 34560, 66, 135, 66, 34560, 135, 135, 135, 135, 34560, 66, 66, 66, 135, 34560, 66, 34560, 34560, 135, 135, 135, 66, 34560, 66, 135, 135, 66, 135, 66, 66, 135, 135, 34560, 135, 66, 135, 34560, 135, 135, 34560, 135, 34560, 66, 34560, 34560, 135, 66, 66, 34560, 135, 66, 135, 135, 34560, 135, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 34560, 34560, 66, 34560, 66, 135, 34560, 34560, 34560, 135, 66, 34560, 135, 66, 66, 66, 66, 66, 34560, 135, 66, 34560, 66, 34560, 66, 66, 135, 135, 34560, 135, 34560, 66, 135, 66, 34560, 34560, 66, 34560, 135, 66, 34560, 66, 66, 34560, 34560, 135, 34560, 34560, 66, 34560, 135, 135, 66, 135, 34560, 34560, 66, 34560, 135, 66, 135, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 135, 34560, 34560, 135, 66, 34560, 66, 135, 135, 66, 135, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 135, 34560, 135, 66, 135, 34560, 135, 34560, 66, 34560, 66, 135, 34560, 135, 34560, 135, 34560, 135, 34560, 135, 66, 34560, 66, 34560, 135, 135, 66, 135, 34560, 135, 135, 34560, 66, 34560, 34560, 135, 66, 34560, 34560, 135, 135, 34560, 34560, 135, 135, 135, 135, 34560, 34560, 135, 135, 34560, 66, 34560, 135, 34560, 34560, 66, 34560, 135, 135, 34560, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 34560, 135, 66, 66, 66, 66]
Prompts retrieved: 2989245 . Total input tokens: 666447743 . Total output tokens: 597918174
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 152.4412466068752,
    "estimated_duration": 3600.0769410112166,
    "input_throughput": 6427.085137102882,
    "output_throughput": 5668.90689682524,
    "total_throughput": 12095.992033928123,
    "itl": 151.04391662907835,
    "ttft": 2068957.7515909742,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 423,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4021012676879814,
    "arrivals": 995247,
    "finished_requests": 93354,
    "scheduler_time": 166.0140224593056
}
#Debug simulation 
Total elapsed time: 152.44140120688826. Arrivals time: 0.7987403385341167 Scheduler time: 151.38389980094507 Scheduler overhead time: 0.10575345018878579 Adapter cache time: 0.02439574897289276 Engine time: 0.09883083682507277 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_16-16-16/adapters_256_slots_64_rate_3.2-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_16-16-16/adapters_256_slots_64_rate_3.2-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 34560, 66, 34560, 34560, 66, 34560, 135, 34560, 66, 135, 66, 34560, 135, 135, 135, 135, 34560, 66, 66, 66, 135, 34560, 66, 34560, 34560, 135, 135, 135, 66, 34560, 66, 135, 135, 66, 135, 66, 66, 135, 135, 34560, 135, 66, 135, 34560, 135, 135, 34560, 135, 34560, 66, 34560, 34560, 135, 66, 66, 34560, 135, 66, 135, 135, 34560, 135, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 34560, 34560, 66, 34560, 66, 135, 34560, 34560, 34560, 135, 66, 34560, 135, 66, 66, 66, 66, 66, 34560, 135, 66, 34560, 66, 34560, 66, 66, 135, 135, 34560, 135, 34560, 66, 135, 66, 34560, 34560, 66, 34560, 135, 66, 34560, 66, 66, 34560, 34560, 135, 34560, 34560, 66, 34560, 135, 135, 66, 135, 34560, 34560, 66, 34560, 135, 66, 135, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 135, 34560, 34560, 135, 66, 34560, 66, 135, 135, 66, 135, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 135, 34560, 135, 66, 135, 34560, 135, 34560, 66, 34560, 66, 135, 34560, 135, 34560, 135, 34560, 135, 34560, 135, 66, 34560, 66, 34560, 135, 135, 66, 135, 34560, 135, 135, 34560, 66, 34560, 34560, 135, 66, 34560, 34560, 135, 135, 34560, 34560, 135, 135, 135, 135, 34560, 34560, 135, 135, 34560, 66, 34560, 135, 34560, 34560, 66, 34560, 135, 135, 34560, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 34560, 135, 66, 66, 66, 66]
Prompts retrieved: 2989245 . Total input tokens: 666447743 . Total output tokens: 597918174
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 150.49361311504617,
    "estimated_duration": 3600.0948769423576,
    "input_throughput": 6427.253944943875,
    "output_throughput": 5669.222255979668,
    "total_throughput": 12096.476200923544,
    "itl": 151.03932083720323,
    "ttft": 2068944.0563727939,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 423,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2647912747436123,
    "arrivals": 995247,
    "finished_requests": 93358,
    "scheduler_time": 166.02117868328511
}
#Debug simulation 
Total elapsed time: 150.49378600902855. Arrivals time: 1.0376713247969747 Scheduler time: 149.1887721652165 Scheduler overhead time: 0.10716034099459648 Adapter cache time: 0.026445133611559868 Engine time: 0.10252950945869088 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_16-16-32/adapters_256_slots_64_rate_3.2-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_16-16-32/adapters_256_slots_64_rate_3.2-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 34560, 66, 34560, 34560, 66, 34560, 135, 34560, 66, 135, 66, 34560, 135, 135, 135, 135, 34560, 66, 66, 66, 135, 34560, 66, 34560, 34560, 135, 135, 135, 66, 34560, 66, 135, 135, 66, 135, 66, 66, 135, 135, 34560, 135, 66, 135, 34560, 135, 135, 34560, 135, 34560, 66, 34560, 34560, 135, 66, 66, 34560, 135, 66, 135, 135, 34560, 135, 66, 66, 34560, 34560, 34560, 34560, 34560, 34560, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 34560, 34560, 66, 34560, 66, 135, 34560, 34560, 34560, 135, 66, 34560, 135, 66, 66, 66, 66, 66, 34560, 135, 66, 34560, 66, 34560, 66, 66, 135, 135, 34560, 135, 34560, 66, 135, 66, 34560, 34560, 66, 34560, 135, 66, 34560, 66, 66, 34560, 34560, 135, 34560, 34560, 66, 34560, 135, 135, 66, 135, 34560, 34560, 66, 34560, 135, 66, 135, 34560, 66, 66, 66, 66, 66, 66, 34560, 66, 66, 66, 34560, 66, 135, 34560, 34560, 135, 66, 34560, 66, 135, 135, 66, 135, 66, 34560, 66, 66, 34560, 66, 34560, 34560, 135, 34560, 135, 66, 135, 34560, 135, 34560, 66, 34560, 66, 135, 34560, 135, 34560, 135, 34560, 135, 34560, 135, 66, 34560, 66, 34560, 135, 135, 66, 135, 34560, 135, 135, 34560, 66, 34560, 34560, 135, 66, 34560, 34560, 135, 135, 34560, 34560, 135, 135, 135, 135, 34560, 34560, 135, 135, 34560, 66, 34560, 135, 34560, 34560, 66, 34560, 135, 135, 34560, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 34560, 135, 66, 66, 66, 66]
Prompts retrieved: 2989245 . Total input tokens: 666447743 . Total output tokens: 597918174
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 151.1589078051038,
    "estimated_duration": 3600.096126068061,
    "input_throughput": 6427.0508869080595,
    "output_throughput": 5668.87668699271,
    "total_throughput": 12095.92757390077,
    "itl": 151.04461751408033,
    "ttft": 2068960.9484406556,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 423,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.421215843223036,
    "arrivals": 995247,
    "finished_requests": 93354,
    "scheduler_time": 166.01409294066002
}
#Debug simulation 
Total elapsed time: 151.15906926477328. Arrivals time: 0.802367425058037 Scheduler time: 150.0935784704052 Scheduler overhead time: 0.10405777674168348 Adapter cache time: 0.025511072017252445 Engine time: 0.10336341429501772 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-8/adapters_256_slots_64_rate_3.2-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-8/adapters_256_slots_64_rate_3.2-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [135, 135, 34560, 33, 34560, 34560, 33, 34560, 135, 34560, 33, 135, 33, 34560, 135, 135, 135, 135, 34560, 33, 33, 33, 135, 34560, 33, 34560, 34560, 135, 135, 135, 33, 34560, 33, 135, 135, 33, 135, 33, 33, 135, 135, 34560, 135, 33, 135, 34560, 135, 135, 34560, 135, 34560, 33, 34560, 34560, 135, 33, 33, 34560, 135, 33, 135, 135, 34560, 135, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 34560, 34560, 33, 34560, 33, 135, 34560, 34560, 34560, 135, 33, 34560, 135, 33, 33, 33, 33, 33, 34560, 135, 33, 34560, 33, 34560, 33, 33, 135, 135, 34560, 135, 34560, 33, 135, 33, 34560, 34560, 33, 34560, 135, 33, 34560, 33, 33, 34560, 34560, 135, 34560, 34560, 33, 34560, 135, 135, 33, 135, 34560, 34560, 33, 34560, 135, 33, 135, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 135, 34560, 34560, 135, 33, 34560, 33, 135, 135, 33, 135, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 135, 34560, 135, 33, 135, 34560, 135, 34560, 33, 34560, 33, 135, 34560, 135, 34560, 135, 34560, 135, 34560, 135, 33, 34560, 33, 34560, 135, 135, 33, 135, 34560, 135, 135, 34560, 33, 34560, 34560, 135, 33, 34560, 34560, 135, 135, 34560, 34560, 135, 135, 135, 135, 34560, 34560, 135, 135, 34560, 33, 34560, 135, 34560, 34560, 33, 34560, 135, 135, 34560, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 34560, 135, 33, 33, 33, 33]
Prompts retrieved: 2986440 . Total input tokens: 665820289 . Total output tokens: 597372628
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 149.6119769755751,
    "estimated_duration": 3600.124869649123,
    "input_throughput": 6514.878747049105,
    "output_throughput": 5713.639038860556,
    "total_throughput": 12228.51778590966,
    "itl": 149.49622313296783,
    "ttft": 2066634.6803171996,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 377,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1538038794626522,
    "arrivals": 994382,
    "finished_requests": 94385,
    "scheduler_time": 167.31424282028163
}
#Debug simulation 
Total elapsed time: 149.61220236495137. Arrivals time: 0.8966208249330521 Scheduler time: 148.44839195301756 Scheduler overhead time: 0.10682281432673335 Adapter cache time: 0.025693051051348448 Engine time: 0.10443352907896042 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-16/adapters_256_slots_64_rate_3.2-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-16/adapters_256_slots_64_rate_3.2-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [135, 135, 34560, 33, 34560, 34560, 33, 34560, 135, 34560, 33, 135, 33, 34560, 135, 135, 135, 135, 34560, 33, 33, 33, 135, 34560, 33, 34560, 34560, 135, 135, 135, 33, 34560, 33, 135, 135, 33, 135, 33, 33, 135, 135, 34560, 135, 33, 135, 34560, 135, 135, 34560, 135, 34560, 33, 34560, 34560, 135, 33, 33, 34560, 135, 33, 135, 135, 34560, 135, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 34560, 34560, 33, 34560, 33, 135, 34560, 34560, 34560, 135, 33, 34560, 135, 33, 33, 33, 33, 33, 34560, 135, 33, 34560, 33, 34560, 33, 33, 135, 135, 34560, 135, 34560, 33, 135, 33, 34560, 34560, 33, 34560, 135, 33, 34560, 33, 33, 34560, 34560, 135, 34560, 34560, 33, 34560, 135, 135, 33, 135, 34560, 34560, 33, 34560, 135, 33, 135, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 135, 34560, 34560, 135, 33, 34560, 33, 135, 135, 33, 135, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 135, 34560, 135, 33, 135, 34560, 135, 34560, 33, 34560, 33, 135, 34560, 135, 34560, 135, 34560, 135, 34560, 135, 33, 34560, 33, 34560, 135, 135, 33, 135, 34560, 135, 135, 34560, 33, 34560, 34560, 135, 33, 34560, 34560, 135, 135, 34560, 34560, 135, 135, 135, 135, 34560, 34560, 135, 135, 34560, 33, 34560, 135, 34560, 34560, 33, 34560, 135, 135, 34560, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 34560, 135, 33, 33, 33, 33]
Prompts retrieved: 2986440 . Total input tokens: 665820289 . Total output tokens: 597372628
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 148.14261653413996,
    "estimated_duration": 3600.1130380839727,
    "input_throughput": 6504.781864422607,
    "output_throughput": 5705.0825301116365,
    "total_throughput": 12209.864394534243,
    "itl": 149.7149931711001,
    "ttft": 2065475.684459973,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 380,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.242862490175763,
    "arrivals": 994382,
    "finished_requests": 94244,
    "scheduler_time": 167.06280051647795
}
#Debug simulation 
Total elapsed time: 148.1427698712796. Arrivals time: 0.8190710106864572 Scheduler time: 147.05258309468627 Scheduler overhead time: 0.10880030924454331 Adapter cache time: 0.024751681834459305 Engine time: 0.10665005026385188 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-32/adapters_256_slots_64_rate_3.2-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-32/adapters_256_slots_64_rate_3.2-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [135, 135, 34560, 33, 34560, 34560, 33, 34560, 135, 34560, 33, 135, 33, 34560, 135, 135, 135, 135, 34560, 33, 33, 33, 135, 34560, 33, 34560, 34560, 135, 135, 135, 33, 34560, 33, 135, 135, 33, 135, 33, 33, 135, 135, 34560, 135, 33, 135, 34560, 135, 135, 34560, 135, 34560, 33, 34560, 34560, 135, 33, 33, 34560, 135, 33, 135, 135, 34560, 135, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 34560, 34560, 33, 34560, 33, 135, 34560, 34560, 34560, 135, 33, 34560, 135, 33, 33, 33, 33, 33, 34560, 135, 33, 34560, 33, 34560, 33, 33, 135, 135, 34560, 135, 34560, 33, 135, 33, 34560, 34560, 33, 34560, 135, 33, 34560, 33, 33, 34560, 34560, 135, 34560, 34560, 33, 34560, 135, 135, 33, 135, 34560, 34560, 33, 34560, 135, 33, 135, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 135, 34560, 34560, 135, 33, 34560, 33, 135, 135, 33, 135, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 135, 34560, 135, 33, 135, 34560, 135, 34560, 33, 34560, 33, 135, 34560, 135, 34560, 135, 34560, 135, 34560, 135, 33, 34560, 33, 34560, 135, 135, 33, 135, 34560, 135, 135, 34560, 33, 34560, 34560, 135, 33, 34560, 34560, 135, 135, 34560, 34560, 135, 135, 135, 135, 34560, 34560, 135, 135, 34560, 33, 34560, 135, 34560, 34560, 33, 34560, 135, 135, 34560, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 34560, 135, 33, 33, 33, 33]
Prompts retrieved: 2986440 . Total input tokens: 665820289 . Total output tokens: 597372628
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 148.86335347406566,
    "estimated_duration": 3600.1147373959525,
    "input_throughput": 6504.77879406109,
    "output_throughput": 5705.079837221049,
    "total_throughput": 12209.858631282139,
    "itl": 149.71505966069338,
    "ttft": 2065475.9361567958,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 380,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2445587586052786,
    "arrivals": 994382,
    "finished_requests": 94244,
    "scheduler_time": 167.06280355999095
}
#Debug simulation 
Total elapsed time: 148.86354334512725. Arrivals time: 0.8893290865235031 Scheduler time: 147.7120014410466 Scheduler overhead time: 0.10553263826295733 Adapter cache time: 0.023642343934625387 Engine time: 0.10241775633767247 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-16-16/adapters_256_slots_64_rate_3.2-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-16-16/adapters_256_slots_64_rate_3.2-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [135, 135, 34560, 33, 34560, 34560, 33, 34560, 135, 34560, 33, 135, 33, 34560, 135, 135, 135, 135, 34560, 33, 33, 33, 135, 34560, 33, 34560, 34560, 135, 135, 135, 33, 34560, 33, 135, 135, 33, 135, 33, 33, 135, 135, 34560, 135, 33, 135, 34560, 135, 135, 34560, 135, 34560, 33, 34560, 34560, 135, 33, 33, 34560, 135, 33, 135, 135, 34560, 135, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 34560, 34560, 33, 34560, 33, 135, 34560, 34560, 34560, 135, 33, 34560, 135, 33, 33, 33, 33, 33, 34560, 135, 33, 34560, 33, 34560, 33, 33, 135, 135, 34560, 135, 34560, 33, 135, 33, 34560, 34560, 33, 34560, 135, 33, 34560, 33, 33, 34560, 34560, 135, 34560, 34560, 33, 34560, 135, 135, 33, 135, 34560, 34560, 33, 34560, 135, 33, 135, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 135, 34560, 34560, 135, 33, 34560, 33, 135, 135, 33, 135, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 135, 34560, 135, 33, 135, 34560, 135, 34560, 33, 34560, 33, 135, 34560, 135, 34560, 135, 34560, 135, 34560, 135, 33, 34560, 33, 34560, 135, 135, 33, 135, 34560, 135, 135, 34560, 33, 34560, 34560, 135, 33, 34560, 34560, 135, 135, 34560, 34560, 135, 135, 135, 135, 34560, 34560, 135, 135, 34560, 33, 34560, 135, 34560, 34560, 33, 34560, 135, 135, 34560, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 34560, 135, 33, 33, 33, 33]
Prompts retrieved: 2986440 . Total input tokens: 665820289 . Total output tokens: 597372628
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 149.93294498929754,
    "estimated_duration": 3600.0174797478144,
    "input_throughput": 6514.587257404896,
    "output_throughput": 5713.702534977945,
    "total_throughput": 12228.28979238284,
    "itl": 149.49942427120683,
    "ttft": 2066620.580635536,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 378,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1853993794624702,
    "arrivals": 994382,
    "finished_requests": 94379,
    "scheduler_time": 167.3073107749112
}
#Debug simulation 
Total elapsed time: 149.93311589211226. Arrivals time: 0.9426139951683581 Scheduler time: 148.72839959478006 Scheduler overhead time: 0.10428522527217865 Adapter cache time: 0.024683918803930283 Engine time: 0.10253236489370465 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-16-32/adapters_256_slots_64_rate_3.2-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-16-32/adapters_256_slots_64_rate_3.2-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [135, 135, 34560, 33, 34560, 34560, 33, 34560, 135, 34560, 33, 135, 33, 34560, 135, 135, 135, 135, 34560, 33, 33, 33, 135, 34560, 33, 34560, 34560, 135, 135, 135, 33, 34560, 33, 135, 135, 33, 135, 33, 33, 135, 135, 34560, 135, 33, 135, 34560, 135, 135, 34560, 135, 34560, 33, 34560, 34560, 135, 33, 33, 34560, 135, 33, 135, 135, 34560, 135, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 34560, 34560, 33, 34560, 33, 135, 34560, 34560, 34560, 135, 33, 34560, 135, 33, 33, 33, 33, 33, 34560, 135, 33, 34560, 33, 34560, 33, 33, 135, 135, 34560, 135, 34560, 33, 135, 33, 34560, 34560, 33, 34560, 135, 33, 34560, 33, 33, 34560, 34560, 135, 34560, 34560, 33, 34560, 135, 135, 33, 135, 34560, 34560, 33, 34560, 135, 33, 135, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 135, 34560, 34560, 135, 33, 34560, 33, 135, 135, 33, 135, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 135, 34560, 135, 33, 135, 34560, 135, 34560, 33, 34560, 33, 135, 34560, 135, 34560, 135, 34560, 135, 34560, 135, 33, 34560, 33, 34560, 135, 135, 33, 135, 34560, 135, 135, 34560, 33, 34560, 34560, 135, 33, 34560, 34560, 135, 135, 34560, 34560, 135, 135, 135, 135, 34560, 34560, 135, 135, 34560, 33, 34560, 135, 34560, 34560, 33, 34560, 135, 135, 34560, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 34560, 135, 33, 33, 33, 33]
Prompts retrieved: 2986440 . Total input tokens: 665820289 . Total output tokens: 597372628
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 146.88083408912644,
    "estimated_duration": 3600.130570350499,
    "input_throughput": 6504.750186802278,
    "output_throughput": 5705.054746945021,
    "total_throughput": 12209.804933747298,
    "itl": 149.7155753960009,
    "ttft": 2065480.0894054715,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 380,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2602779819071341,
    "arrivals": 994382,
    "finished_requests": 94244,
    "scheduler_time": 167.06291729126738
}
#Debug simulation 
Total elapsed time: 146.88102559000254. Arrivals time: 0.8863331316970289 Scheduler time: 145.72605531010777 Scheduler overhead time: 0.10640942445024848 Adapter cache time: 0.02640860714018345 Engine time: 0.10460872948169708 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_16-16-16/adapters_256_slots_64_rate_3.2-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_16-16-16/adapters_256_slots_64_rate_3.2-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [135, 135, 34560, 33, 34560, 34560, 33, 34560, 135, 34560, 33, 135, 33, 34560, 135, 135, 135, 135, 34560, 33, 33, 33, 135, 34560, 33, 34560, 34560, 135, 135, 135, 33, 34560, 33, 135, 135, 33, 135, 33, 33, 135, 135, 34560, 135, 33, 135, 34560, 135, 135, 34560, 135, 34560, 33, 34560, 34560, 135, 33, 33, 34560, 135, 33, 135, 135, 34560, 135, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 34560, 34560, 33, 34560, 33, 135, 34560, 34560, 34560, 135, 33, 34560, 135, 33, 33, 33, 33, 33, 34560, 135, 33, 34560, 33, 34560, 33, 33, 135, 135, 34560, 135, 34560, 33, 135, 33, 34560, 34560, 33, 34560, 135, 33, 34560, 33, 33, 34560, 34560, 135, 34560, 34560, 33, 34560, 135, 135, 33, 135, 34560, 34560, 33, 34560, 135, 33, 135, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 135, 34560, 34560, 135, 33, 34560, 33, 135, 135, 33, 135, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 135, 34560, 135, 33, 135, 34560, 135, 34560, 33, 34560, 33, 135, 34560, 135, 34560, 135, 34560, 135, 34560, 135, 33, 34560, 33, 34560, 135, 135, 33, 135, 34560, 135, 135, 34560, 33, 34560, 34560, 135, 33, 34560, 34560, 135, 135, 34560, 34560, 135, 135, 135, 135, 34560, 34560, 135, 135, 34560, 33, 34560, 135, 34560, 34560, 33, 34560, 135, 135, 34560, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 34560, 135, 33, 33, 33, 33]
Prompts retrieved: 2986440 . Total input tokens: 665820289 . Total output tokens: 597372628
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 150.12684932583943,
    "estimated_duration": 3600.0981484589815,
    "input_throughput": 6514.927102762357,
    "output_throughput": 5713.681447491894,
    "total_throughput": 12228.608550254252,
    "itl": 149.49530151667162,
    "ttft": 2066628.3874401907,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 377,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1272489611781171,
    "arrivals": 994382,
    "finished_requests": 94385,
    "scheduler_time": 167.3140765483592
}
#Debug simulation 
Total elapsed time: 150.12709899479523. Arrivals time: 0.8944677943363786 Scheduler time: 148.9659923124127 Scheduler overhead time: 0.10640270682051778 Adapter cache time: 0.025243602227419615 Engine time: 0.10384863102808595 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_16-16-32/adapters_256_slots_64_rate_3.2-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_16-16-32/adapters_256_slots_64_rate_3.2-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [135, 135, 34560, 33, 34560, 34560, 33, 34560, 135, 34560, 33, 135, 33, 34560, 135, 135, 135, 135, 34560, 33, 33, 33, 135, 34560, 33, 34560, 34560, 135, 135, 135, 33, 34560, 33, 135, 135, 33, 135, 33, 33, 135, 135, 34560, 135, 33, 135, 34560, 135, 135, 34560, 135, 34560, 33, 34560, 34560, 135, 33, 33, 34560, 135, 33, 135, 135, 34560, 135, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 34560, 34560, 33, 34560, 33, 135, 34560, 34560, 34560, 135, 33, 34560, 135, 33, 33, 33, 33, 33, 34560, 135, 33, 34560, 33, 34560, 33, 33, 135, 135, 34560, 135, 34560, 33, 135, 33, 34560, 34560, 33, 34560, 135, 33, 34560, 33, 33, 34560, 34560, 135, 34560, 34560, 33, 34560, 135, 135, 33, 135, 34560, 34560, 33, 34560, 135, 33, 135, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 135, 34560, 34560, 135, 33, 34560, 33, 135, 135, 33, 135, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 135, 34560, 135, 33, 135, 34560, 135, 34560, 33, 34560, 33, 135, 34560, 135, 34560, 135, 34560, 135, 34560, 135, 33, 34560, 33, 34560, 135, 135, 33, 135, 34560, 135, 135, 34560, 33, 34560, 34560, 135, 33, 34560, 34560, 135, 135, 34560, 34560, 135, 135, 135, 135, 34560, 34560, 135, 135, 34560, 33, 34560, 135, 34560, 34560, 33, 34560, 135, 135, 34560, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 34560, 135, 33, 33, 33, 33]
Prompts retrieved: 2986440 . Total input tokens: 665820289 . Total output tokens: 597372628
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 147.9035185240209,
    "estimated_duration": 3600.0031590287576,
    "input_throughput": 6504.279847998031,
    "output_throughput": 5704.602216388208,
    "total_throughput": 12208.882064386238,
    "itl": 149.71729599816936,
    "ttft": 2065442.6348132123,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 380,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.277380496859553,
    "arrivals": 994382,
    "finished_requests": 94236,
    "scheduler_time": 167.05537887448966
}
#Debug simulation 
Total elapsed time: 147.90367788588628. Arrivals time: 0.8342025708407164 Scheduler time: 146.80138551723212 Scheduler overhead time: 0.10647385381162167 Adapter cache time: 0.024363210424780846 Engine time: 0.10589785221964121 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-8/adapters_256_slots_64_rate_3.2-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-8/adapters_256_slots_64_rate_3.2-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [66, 66, 34560, 33, 34560, 34560, 33, 34560, 66, 34560, 33, 66, 33, 34560, 66, 66, 66, 66, 34560, 33, 33, 33, 66, 34560, 33, 34560, 34560, 66, 66, 66, 33, 34560, 33, 66, 66, 33, 66, 33, 33, 66, 66, 34560, 66, 33, 66, 34560, 66, 66, 34560, 66, 34560, 33, 34560, 34560, 66, 33, 33, 34560, 66, 33, 66, 66, 34560, 66, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 34560, 34560, 33, 34560, 33, 66, 34560, 34560, 34560, 66, 33, 34560, 66, 33, 33, 33, 33, 33, 34560, 66, 33, 34560, 33, 34560, 33, 33, 66, 66, 34560, 66, 34560, 33, 66, 33, 34560, 34560, 33, 34560, 66, 33, 34560, 33, 33, 34560, 34560, 66, 34560, 34560, 33, 34560, 66, 66, 33, 66, 34560, 34560, 33, 34560, 66, 33, 66, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 66, 34560, 34560, 66, 33, 34560, 33, 66, 66, 33, 66, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 66, 34560, 66, 33, 66, 34560, 66, 34560, 33, 34560, 33, 66, 34560, 66, 34560, 66, 34560, 66, 34560, 66, 33, 34560, 33, 34560, 66, 66, 33, 66, 34560, 66, 66, 34560, 33, 34560, 34560, 66, 33, 34560, 34560, 66, 66, 34560, 34560, 66, 66, 66, 66, 34560, 34560, 66, 66, 34560, 33, 34560, 66, 34560, 34560, 33, 34560, 66, 66, 34560, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 34560, 66, 33, 33, 33, 33]
Prompts retrieved: 2980575 . Total input tokens: 664496257 . Total output tokens: 596195076
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 149.5728186708875,
    "estimated_duration": 3600.0067521237133,
    "input_throughput": 6491.940879336678,
    "output_throughput": 5734.40674460451,
    "total_throughput": 12226.347623941188,
    "itl": 149.45390942210798,
    "ttft": 2075319.6323048542,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 291,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8906019334844302,
    "arrivals": 992438,
    "finished_requests": 94660,
    "scheduler_time": 167.7521530741613
}
#Debug simulation 
Total elapsed time: 149.57299570878968. Arrivals time: 0.7288410770706832 Scheduler time: 148.57741206977516 Scheduler overhead time: 0.10731395287439227 Adapter cache time: 0.024474173318594694 Engine time: 0.10455262055620551 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-16/adapters_256_slots_64_rate_3.2-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-16/adapters_256_slots_64_rate_3.2-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [66, 66, 34560, 33, 34560, 34560, 33, 34560, 66, 34560, 33, 66, 33, 34560, 66, 66, 66, 66, 34560, 33, 33, 33, 66, 34560, 33, 34560, 34560, 66, 66, 66, 33, 34560, 33, 66, 66, 33, 66, 33, 33, 66, 66, 34560, 66, 33, 66, 34560, 66, 66, 34560, 66, 34560, 33, 34560, 34560, 66, 33, 33, 34560, 66, 33, 66, 66, 34560, 66, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 34560, 34560, 33, 34560, 33, 66, 34560, 34560, 34560, 66, 33, 34560, 66, 33, 33, 33, 33, 33, 34560, 66, 33, 34560, 33, 34560, 33, 33, 66, 66, 34560, 66, 34560, 33, 66, 33, 34560, 34560, 33, 34560, 66, 33, 34560, 33, 33, 34560, 34560, 66, 34560, 34560, 33, 34560, 66, 66, 33, 66, 34560, 34560, 33, 34560, 66, 33, 66, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 66, 34560, 34560, 66, 33, 34560, 33, 66, 66, 33, 66, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 66, 34560, 66, 33, 66, 34560, 66, 34560, 33, 34560, 33, 66, 34560, 66, 34560, 66, 34560, 66, 34560, 66, 33, 34560, 33, 34560, 66, 66, 33, 66, 34560, 66, 66, 34560, 33, 34560, 34560, 66, 33, 34560, 34560, 66, 66, 34560, 34560, 66, 66, 66, 66, 34560, 34560, 66, 66, 34560, 33, 34560, 66, 34560, 34560, 33, 34560, 66, 66, 34560, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 34560, 66, 33, 33, 33, 33]
Prompts retrieved: 2980575 . Total input tokens: 664496257 . Total output tokens: 596195076
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 147.1895761527121,
    "estimated_duration": 3600.064730632961,
    "input_throughput": 6491.8363275903985,
    "output_throughput": 5734.314392833265,
    "total_throughput": 12226.150720423664,
    "itl": 149.45581618508626,
    "ttft": 2075335.1594943274,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 291,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9481463416386445,
    "arrivals": 992438,
    "finished_requests": 94660,
    "scheduler_time": 167.75258717523045
}
#Debug simulation 
Total elapsed time: 147.18973824800923. Arrivals time: 0.74435700988397 Scheduler time: 146.1774941389449 Scheduler overhead time: 0.108473792206496 Adapter cache time: 0.023939864709973335 Engine time: 0.10318013653159142 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-32/adapters_256_slots_64_rate_3.2-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-32/adapters_256_slots_64_rate_3.2-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [66, 66, 34560, 33, 34560, 34560, 33, 34560, 66, 34560, 33, 66, 33, 34560, 66, 66, 66, 66, 34560, 33, 33, 33, 66, 34560, 33, 34560, 34560, 66, 66, 66, 33, 34560, 33, 66, 66, 33, 66, 33, 33, 66, 66, 34560, 66, 33, 66, 34560, 66, 66, 34560, 66, 34560, 33, 34560, 34560, 66, 33, 33, 34560, 66, 33, 66, 66, 34560, 66, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 34560, 34560, 33, 34560, 33, 66, 34560, 34560, 34560, 66, 33, 34560, 66, 33, 33, 33, 33, 33, 34560, 66, 33, 34560, 33, 34560, 33, 33, 66, 66, 34560, 66, 34560, 33, 66, 33, 34560, 34560, 33, 34560, 66, 33, 34560, 33, 33, 34560, 34560, 66, 34560, 34560, 33, 34560, 66, 66, 33, 66, 34560, 34560, 33, 34560, 66, 33, 66, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 66, 34560, 34560, 66, 33, 34560, 33, 66, 66, 33, 66, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 66, 34560, 66, 33, 66, 34560, 66, 34560, 33, 34560, 33, 66, 34560, 66, 34560, 66, 34560, 66, 34560, 66, 33, 34560, 33, 34560, 66, 66, 33, 66, 34560, 66, 66, 34560, 33, 34560, 34560, 66, 33, 34560, 34560, 66, 66, 34560, 34560, 66, 66, 66, 66, 34560, 34560, 66, 66, 34560, 33, 34560, 66, 34560, 34560, 33, 34560, 66, 66, 34560, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 34560, 66, 33, 33, 33, 33]
Prompts retrieved: 2980575 . Total input tokens: 664496257 . Total output tokens: 596195076
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 147.5821580621414,
    "estimated_duration": 3600.0666763236973,
    "input_throughput": 6491.83281901488,
    "output_throughput": 5734.311293667778,
    "total_throughput": 12226.14411268266,
    "itl": 149.45588311971966,
    "ttft": 2075335.6499548012,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 291,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.950078256446873,
    "arrivals": 992438,
    "finished_requests": 94660,
    "scheduler_time": 167.7526009511315
}
#Debug simulation 
Total elapsed time: 147.5823146412149. Arrivals time: 0.8073507603257895 Scheduler time: 146.5063379202038 Scheduler overhead time: 0.1095420466735959 Adapter cache time: 0.023779071401804686 Engine time: 0.10396771505475044 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-16-16/adapters_256_slots_64_rate_3.2-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-16-16/adapters_256_slots_64_rate_3.2-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [66, 66, 34560, 33, 34560, 34560, 33, 34560, 66, 34560, 33, 66, 33, 34560, 66, 66, 66, 66, 34560, 33, 33, 33, 66, 34560, 33, 34560, 34560, 66, 66, 66, 33, 34560, 33, 66, 66, 33, 66, 33, 33, 66, 66, 34560, 66, 33, 66, 34560, 66, 66, 34560, 66, 34560, 33, 34560, 34560, 66, 33, 33, 34560, 66, 33, 66, 66, 34560, 66, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 34560, 34560, 33, 34560, 33, 66, 34560, 34560, 34560, 66, 33, 34560, 66, 33, 33, 33, 33, 33, 34560, 66, 33, 34560, 33, 34560, 33, 33, 66, 66, 34560, 66, 34560, 33, 66, 33, 34560, 34560, 33, 34560, 66, 33, 34560, 33, 33, 34560, 34560, 66, 34560, 34560, 33, 34560, 66, 66, 33, 66, 34560, 34560, 33, 34560, 66, 33, 66, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 66, 34560, 34560, 66, 33, 34560, 33, 66, 66, 33, 66, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 66, 34560, 66, 33, 66, 34560, 66, 34560, 33, 34560, 33, 66, 34560, 66, 34560, 66, 34560, 66, 34560, 66, 33, 34560, 33, 34560, 66, 66, 33, 66, 34560, 66, 66, 34560, 33, 34560, 34560, 66, 33, 34560, 34560, 66, 66, 34560, 34560, 66, 66, 66, 66, 34560, 34560, 66, 66, 34560, 33, 34560, 66, 34560, 34560, 33, 34560, 66, 66, 34560, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 34560, 66, 33, 33, 33, 33]
Prompts retrieved: 2980575 . Total input tokens: 664496257 . Total output tokens: 596195076
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 147.92964158998802,
    "estimated_duration": 3600.027239141959,
    "input_throughput": 6491.903935029758,
    "output_throughput": 5734.374111269316,
    "total_throughput": 12226.278046299074,
    "itl": 149.4546295271838,
    "ttft": 2075324.4035664392,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 291,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9109641676605709,
    "arrivals": 992438,
    "finished_requests": 94660,
    "scheduler_time": 167.75227785819558
}
#Debug simulation 
Total elapsed time: 147.92979051591828. Arrivals time: 0.7554779583588243 Scheduler time: 146.91040682140738 Scheduler overhead time: 0.10794276325032115 Adapter cache time: 0.023565340787172318 Engine time: 0.10234607942402363 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-16-32/adapters_256_slots_64_rate_3.2-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-16-32/adapters_256_slots_64_rate_3.2-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [66, 66, 34560, 33, 34560, 34560, 33, 34560, 66, 34560, 33, 66, 33, 34560, 66, 66, 66, 66, 34560, 33, 33, 33, 66, 34560, 33, 34560, 34560, 66, 66, 66, 33, 34560, 33, 66, 66, 33, 66, 33, 33, 66, 66, 34560, 66, 33, 66, 34560, 66, 66, 34560, 66, 34560, 33, 34560, 34560, 66, 33, 33, 34560, 66, 33, 66, 66, 34560, 66, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 34560, 34560, 33, 34560, 33, 66, 34560, 34560, 34560, 66, 33, 34560, 66, 33, 33, 33, 33, 33, 34560, 66, 33, 34560, 33, 34560, 33, 33, 66, 66, 34560, 66, 34560, 33, 66, 33, 34560, 34560, 33, 34560, 66, 33, 34560, 33, 33, 34560, 34560, 66, 34560, 34560, 33, 34560, 66, 66, 33, 66, 34560, 34560, 33, 34560, 66, 33, 66, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 66, 34560, 34560, 66, 33, 34560, 33, 66, 66, 33, 66, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 66, 34560, 66, 33, 66, 34560, 66, 34560, 33, 34560, 33, 66, 34560, 66, 34560, 66, 34560, 66, 34560, 66, 33, 34560, 33, 34560, 66, 66, 33, 66, 34560, 66, 66, 34560, 33, 34560, 34560, 66, 33, 34560, 34560, 66, 66, 34560, 34560, 66, 66, 66, 66, 34560, 34560, 66, 66, 34560, 33, 34560, 66, 34560, 34560, 33, 34560, 66, 66, 34560, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 34560, 66, 33, 33, 33, 33]
Prompts retrieved: 2980575 . Total input tokens: 664496257 . Total output tokens: 596195076
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 146.67404820676893,
    "estimated_duration": 3600.0782163495446,
    "input_throughput": 6491.812009489636,
    "output_throughput": 5734.292912372549,
    "total_throughput": 12226.104921862185,
    "itl": 149.45624843363032,
    "ttft": 2075338.9611853994,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 291,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9615218510106257,
    "arrivals": 992438,
    "finished_requests": 94660,
    "scheduler_time": 167.75269738243912
}
#Debug simulation 
Total elapsed time: 146.67421943182126. Arrivals time: 0.7693071188405156 Scheduler time: 145.63725978136063 Scheduler overhead time: 0.1079976805485785 Adapter cache time: 0.02482595667243004 Engine time: 0.10392830753698945 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_16-16-16/adapters_256_slots_64_rate_3.2-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_16-16-16/adapters_256_slots_64_rate_3.2-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [66, 66, 34560, 33, 34560, 34560, 33, 34560, 66, 34560, 33, 66, 33, 34560, 66, 66, 66, 66, 34560, 33, 33, 33, 66, 34560, 33, 34560, 34560, 66, 66, 66, 33, 34560, 33, 66, 66, 33, 66, 33, 33, 66, 66, 34560, 66, 33, 66, 34560, 66, 66, 34560, 66, 34560, 33, 34560, 34560, 66, 33, 33, 34560, 66, 33, 66, 66, 34560, 66, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 34560, 34560, 33, 34560, 33, 66, 34560, 34560, 34560, 66, 33, 34560, 66, 33, 33, 33, 33, 33, 34560, 66, 33, 34560, 33, 34560, 33, 33, 66, 66, 34560, 66, 34560, 33, 66, 33, 34560, 34560, 33, 34560, 66, 33, 34560, 33, 33, 34560, 34560, 66, 34560, 34560, 33, 34560, 66, 66, 33, 66, 34560, 34560, 33, 34560, 66, 33, 66, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 66, 34560, 34560, 66, 33, 34560, 33, 66, 66, 33, 66, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 66, 34560, 66, 33, 66, 34560, 66, 34560, 33, 34560, 33, 66, 34560, 66, 34560, 66, 34560, 66, 34560, 66, 33, 34560, 33, 34560, 66, 66, 33, 66, 34560, 66, 66, 34560, 33, 34560, 34560, 66, 33, 34560, 34560, 66, 66, 34560, 34560, 66, 66, 66, 66, 34560, 34560, 66, 66, 34560, 33, 34560, 66, 34560, 34560, 33, 34560, 66, 66, 34560, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 34560, 66, 33, 33, 33, 33]
Prompts retrieved: 2980575 . Total input tokens: 664496257 . Total output tokens: 596195076
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 149.102143809665,
    "estimated_duration": 3600.1330171883114,
    "input_throughput": 6492.426221032989,
    "output_throughput": 5734.49172612061,
    "total_throughput": 12226.917947153599,
    "itl": 149.45194973219216,
    "ttft": 2075358.667214728,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 291,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8701046358165343,
    "arrivals": 992438,
    "finished_requests": 94667,
    "scheduler_time": 167.75994086923208
}
#Debug simulation 
Total elapsed time: 149.10231912368909. Arrivals time: 0.7525413706898689 Scheduler time: 148.0828263554722 Scheduler overhead time: 0.10692510707303882 Adapter cache time: 0.02474955329671502 Engine time: 0.10465431027114391 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_16-16-32/adapters_256_slots_64_rate_3.2-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_16-16-32/adapters_256_slots_64_rate_3.2-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [85 85 86]
Adapter prompts. [66, 66, 34560, 33, 34560, 34560, 33, 34560, 66, 34560, 33, 66, 33, 34560, 66, 66, 66, 66, 34560, 33, 33, 33, 66, 34560, 33, 34560, 34560, 66, 66, 66, 33, 34560, 33, 66, 66, 33, 66, 33, 33, 66, 66, 34560, 66, 33, 66, 34560, 66, 66, 34560, 66, 34560, 33, 34560, 34560, 66, 33, 33, 34560, 66, 33, 66, 66, 34560, 66, 33, 33, 34560, 34560, 34560, 34560, 34560, 34560, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 34560, 34560, 33, 34560, 33, 66, 34560, 34560, 34560, 66, 33, 34560, 66, 33, 33, 33, 33, 33, 34560, 66, 33, 34560, 33, 34560, 33, 33, 66, 66, 34560, 66, 34560, 33, 66, 33, 34560, 34560, 33, 34560, 66, 33, 34560, 33, 33, 34560, 34560, 66, 34560, 34560, 33, 34560, 66, 66, 33, 66, 34560, 34560, 33, 34560, 66, 33, 66, 34560, 33, 33, 33, 33, 33, 33, 34560, 33, 33, 33, 34560, 33, 66, 34560, 34560, 66, 33, 34560, 33, 66, 66, 33, 66, 33, 34560, 33, 33, 34560, 33, 34560, 34560, 66, 34560, 66, 33, 66, 34560, 66, 34560, 33, 34560, 33, 66, 34560, 66, 34560, 66, 34560, 66, 34560, 66, 33, 34560, 33, 34560, 66, 66, 33, 66, 34560, 66, 66, 34560, 33, 34560, 34560, 66, 33, 34560, 34560, 66, 66, 34560, 34560, 66, 66, 66, 66, 34560, 34560, 66, 66, 34560, 33, 34560, 66, 34560, 34560, 33, 34560, 66, 66, 34560, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 34560, 66, 33, 33, 33, 33]
Prompts retrieved: 2980575 . Total input tokens: 664496257 . Total output tokens: 596195076
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 148.14901133812964,
    "estimated_duration": 3600.090879189111,
    "input_throughput": 6491.789175406628,
    "output_throughput": 5734.272742761943,
    "total_throughput": 12226.06191816857,
    "itl": 149.4566806908252,
    "ttft": 2075342.117070206,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 291,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9740972296521119,
    "arrivals": 992438,
    "finished_requests": 94660,
    "scheduler_time": 167.75278484339253
}
#Debug simulation 
Total elapsed time: 148.14916386129335. Arrivals time: 0.7395945438183844 Scheduler time: 147.14087962917984 Scheduler overhead time: 0.10917617660015821 Adapter cache time: 0.024665968026965857 Engine time: 0.10436642821878195 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-8-8/adapters_256_slots_64_rate_1.6-0.8-0.4_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-8-8/adapters_256_slots_64_rate_1.6-0.8-0.4_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 4320, 17280, 17280, 4320, 17280, 8640, 17280, 4320, 8640, 4320, 17280, 8640, 8640, 8640, 8640, 17280, 4320, 4320, 4320, 8640, 17280, 4320, 17280, 17280, 8640, 8640, 8640, 4320, 17280, 4320, 8640, 8640, 4320, 8640, 4320, 4320, 8640, 8640, 17280, 8640, 4320, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 4320, 17280, 17280, 8640, 4320, 4320, 17280, 8640, 4320, 8640, 8640, 17280, 8640, 4320, 4320, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 8640, 4320, 8640, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 17280, 17280, 4320, 17280, 4320, 8640, 17280, 17280, 17280, 8640, 4320, 17280, 8640, 4320, 4320, 4320, 4320, 4320, 17280, 8640, 4320, 17280, 4320, 17280, 4320, 4320, 8640, 8640, 17280, 8640, 17280, 4320, 8640, 4320, 17280, 17280, 4320, 17280, 8640, 4320, 17280, 4320, 4320, 17280, 17280, 8640, 17280, 17280, 4320, 17280, 8640, 8640, 4320, 8640, 17280, 17280, 4320, 17280, 8640, 4320, 8640, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 4320, 4320, 17280, 4320, 8640, 17280, 17280, 8640, 4320, 17280, 4320, 8640, 8640, 4320, 8640, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 17280, 8640, 17280, 8640, 4320, 8640, 17280, 8640, 17280, 4320, 17280, 4320, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 4320, 17280, 4320, 17280, 8640, 8640, 4320, 8640, 17280, 8640, 8640, 17280, 4320, 17280, 17280, 8640, 4320, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 4320, 17280, 8640, 17280, 17280, 4320, 17280, 8640, 8640, 17280, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 4320, 4320, 4320, 4320]
Prompts retrieved: 2587680 . Total input tokens: 577057570 . Total output tokens: 517693652
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 118.09320501657203,
    "estimated_duration": 3600.0268881179213,
    "input_throughput": 6241.066719295027,
    "output_throughput": 5504.268611271253,
    "total_throughput": 11745.33533056628,
    "itl": 152.89993256002532,
    "ttft": 2028934.094279367,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 418,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2792838769638994,
    "arrivals": 861811,
    "finished_requests": 90608,
    "scheduler_time": 162.5594062565839
}
#Debug simulation 
Total elapsed time: 118.09353689663112. Arrivals time: 1.3168760761618614 Scheduler time: 116.52964876778424 Scheduler overhead time: 0.09677872899919748 Adapter cache time: 0.023865140043199062 Engine time: 0.09756713593378663 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-8-16/adapters_256_slots_64_rate_1.6-0.8-0.4_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-8-16/adapters_256_slots_64_rate_1.6-0.8-0.4_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 4320, 17280, 17280, 4320, 17280, 8640, 17280, 4320, 8640, 4320, 17280, 8640, 8640, 8640, 8640, 17280, 4320, 4320, 4320, 8640, 17280, 4320, 17280, 17280, 8640, 8640, 8640, 4320, 17280, 4320, 8640, 8640, 4320, 8640, 4320, 4320, 8640, 8640, 17280, 8640, 4320, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 4320, 17280, 17280, 8640, 4320, 4320, 17280, 8640, 4320, 8640, 8640, 17280, 8640, 4320, 4320, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 8640, 4320, 8640, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 17280, 17280, 4320, 17280, 4320, 8640, 17280, 17280, 17280, 8640, 4320, 17280, 8640, 4320, 4320, 4320, 4320, 4320, 17280, 8640, 4320, 17280, 4320, 17280, 4320, 4320, 8640, 8640, 17280, 8640, 17280, 4320, 8640, 4320, 17280, 17280, 4320, 17280, 8640, 4320, 17280, 4320, 4320, 17280, 17280, 8640, 17280, 17280, 4320, 17280, 8640, 8640, 4320, 8640, 17280, 17280, 4320, 17280, 8640, 4320, 8640, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 4320, 4320, 17280, 4320, 8640, 17280, 17280, 8640, 4320, 17280, 4320, 8640, 8640, 4320, 8640, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 17280, 8640, 17280, 8640, 4320, 8640, 17280, 8640, 17280, 4320, 17280, 4320, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 4320, 17280, 4320, 17280, 8640, 8640, 4320, 8640, 17280, 8640, 8640, 17280, 4320, 17280, 17280, 8640, 4320, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 4320, 17280, 8640, 17280, 17280, 4320, 17280, 8640, 8640, 17280, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 4320, 4320, 4320, 4320]
Prompts retrieved: 2587680 . Total input tokens: 577057570 . Total output tokens: 517693652
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 118.30501957377419,
    "estimated_duration": 3600.036672336647,
    "input_throughput": 6240.850037068466,
    "output_throughput": 5503.368382950547,
    "total_throughput": 11744.218420019013,
    "itl": 152.82259493805614,
    "ttft": 2028814.5871524431,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 439,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4343934843572848,
    "arrivals": 861811,
    "finished_requests": 90572,
    "scheduler_time": 162.70697647757513
}
#Debug simulation 
Total elapsed time: 118.30520833889022. Arrivals time: 0.8034578100778162 Scheduler time: 117.26299488730729 Scheduler overhead time: 0.0943005159497261 Adapter cache time: 0.025037257932126522 Engine time: 0.09085127990692854 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-8-32/adapters_256_slots_64_rate_1.6-0.8-0.4_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-8-32/adapters_256_slots_64_rate_1.6-0.8-0.4_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 4320, 17280, 17280, 4320, 17280, 8640, 17280, 4320, 8640, 4320, 17280, 8640, 8640, 8640, 8640, 17280, 4320, 4320, 4320, 8640, 17280, 4320, 17280, 17280, 8640, 8640, 8640, 4320, 17280, 4320, 8640, 8640, 4320, 8640, 4320, 4320, 8640, 8640, 17280, 8640, 4320, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 4320, 17280, 17280, 8640, 4320, 4320, 17280, 8640, 4320, 8640, 8640, 17280, 8640, 4320, 4320, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 8640, 4320, 8640, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 17280, 17280, 4320, 17280, 4320, 8640, 17280, 17280, 17280, 8640, 4320, 17280, 8640, 4320, 4320, 4320, 4320, 4320, 17280, 8640, 4320, 17280, 4320, 17280, 4320, 4320, 8640, 8640, 17280, 8640, 17280, 4320, 8640, 4320, 17280, 17280, 4320, 17280, 8640, 4320, 17280, 4320, 4320, 17280, 17280, 8640, 17280, 17280, 4320, 17280, 8640, 8640, 4320, 8640, 17280, 17280, 4320, 17280, 8640, 4320, 8640, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 4320, 4320, 17280, 4320, 8640, 17280, 17280, 8640, 4320, 17280, 4320, 8640, 8640, 4320, 8640, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 17280, 8640, 17280, 8640, 4320, 8640, 17280, 8640, 17280, 4320, 17280, 4320, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 4320, 17280, 4320, 17280, 8640, 8640, 4320, 8640, 17280, 8640, 8640, 17280, 4320, 17280, 17280, 8640, 4320, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 4320, 17280, 8640, 17280, 17280, 4320, 17280, 8640, 8640, 17280, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 4320, 4320, 4320, 4320]
Prompts retrieved: 2587680 . Total input tokens: 577057570 . Total output tokens: 517693652
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 118.70049357833341,
    "estimated_duration": 3600.0390385167075,
    "input_throughput": 6240.84593517547,
    "output_throughput": 5503.364765778512,
    "total_throughput": 11744.210700953981,
    "itl": 152.8226839035371,
    "ttft": 2028815.7219540526,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 439,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4366045279800976,
    "arrivals": 861811,
    "finished_requests": 90572,
    "scheduler_time": 162.7069923760655
}
#Debug simulation 
Total elapsed time: 118.70071431435645. Arrivals time: 0.812919148709625 Scheduler time: 117.63703554170206 Scheduler overhead time: 0.09853750700131059 Adapter cache time: 0.02488983143121004 Engine time: 0.0973861999809742 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-16-16/adapters_256_slots_64_rate_1.6-0.8-0.4_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-16-16/adapters_256_slots_64_rate_1.6-0.8-0.4_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 4320, 17280, 17280, 4320, 17280, 8640, 17280, 4320, 8640, 4320, 17280, 8640, 8640, 8640, 8640, 17280, 4320, 4320, 4320, 8640, 17280, 4320, 17280, 17280, 8640, 8640, 8640, 4320, 17280, 4320, 8640, 8640, 4320, 8640, 4320, 4320, 8640, 8640, 17280, 8640, 4320, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 4320, 17280, 17280, 8640, 4320, 4320, 17280, 8640, 4320, 8640, 8640, 17280, 8640, 4320, 4320, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 8640, 4320, 8640, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 17280, 17280, 4320, 17280, 4320, 8640, 17280, 17280, 17280, 8640, 4320, 17280, 8640, 4320, 4320, 4320, 4320, 4320, 17280, 8640, 4320, 17280, 4320, 17280, 4320, 4320, 8640, 8640, 17280, 8640, 17280, 4320, 8640, 4320, 17280, 17280, 4320, 17280, 8640, 4320, 17280, 4320, 4320, 17280, 17280, 8640, 17280, 17280, 4320, 17280, 8640, 8640, 4320, 8640, 17280, 17280, 4320, 17280, 8640, 4320, 8640, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 4320, 4320, 17280, 4320, 8640, 17280, 17280, 8640, 4320, 17280, 4320, 8640, 8640, 4320, 8640, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 17280, 8640, 17280, 8640, 4320, 8640, 17280, 8640, 17280, 4320, 17280, 4320, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 4320, 17280, 4320, 17280, 8640, 8640, 4320, 8640, 17280, 8640, 8640, 17280, 4320, 17280, 17280, 8640, 4320, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 4320, 17280, 8640, 17280, 17280, 4320, 17280, 8640, 8640, 17280, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 4320, 4320, 4320, 4320]
Prompts retrieved: 2587680 . Total input tokens: 577057570 . Total output tokens: 517693652
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 116.79862729320303,
    "estimated_duration": 3600.1659295479503,
    "input_throughput": 6231.2925123473,
    "output_throughput": 5499.767618345904,
    "total_throughput": 11731.060130693204,
    "itl": 152.8738260551244,
    "ttft": 2029268.7741526964,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 426,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3342335327574963,
    "arrivals": 861811,
    "finished_requests": 90492,
    "scheduler_time": 162.82670200985027
}
#Debug simulation 
Total elapsed time: 116.79878387320787. Arrivals time: 1.280257860198617 Scheduler time: 115.26983506511897 Scheduler overhead time: 0.09934637509286404 Adapter cache time: 0.024638867005705833 Engine time: 0.0973362154327333 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-16-32/adapters_256_slots_64_rate_1.6-0.8-0.4_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-16-32/adapters_256_slots_64_rate_1.6-0.8-0.4_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 4320, 17280, 17280, 4320, 17280, 8640, 17280, 4320, 8640, 4320, 17280, 8640, 8640, 8640, 8640, 17280, 4320, 4320, 4320, 8640, 17280, 4320, 17280, 17280, 8640, 8640, 8640, 4320, 17280, 4320, 8640, 8640, 4320, 8640, 4320, 4320, 8640, 8640, 17280, 8640, 4320, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 4320, 17280, 17280, 8640, 4320, 4320, 17280, 8640, 4320, 8640, 8640, 17280, 8640, 4320, 4320, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 8640, 4320, 8640, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 17280, 17280, 4320, 17280, 4320, 8640, 17280, 17280, 17280, 8640, 4320, 17280, 8640, 4320, 4320, 4320, 4320, 4320, 17280, 8640, 4320, 17280, 4320, 17280, 4320, 4320, 8640, 8640, 17280, 8640, 17280, 4320, 8640, 4320, 17280, 17280, 4320, 17280, 8640, 4320, 17280, 4320, 4320, 17280, 17280, 8640, 17280, 17280, 4320, 17280, 8640, 8640, 4320, 8640, 17280, 17280, 4320, 17280, 8640, 4320, 8640, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 4320, 4320, 17280, 4320, 8640, 17280, 17280, 8640, 4320, 17280, 4320, 8640, 8640, 4320, 8640, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 17280, 8640, 17280, 8640, 4320, 8640, 17280, 8640, 17280, 4320, 17280, 4320, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 4320, 17280, 4320, 17280, 8640, 8640, 4320, 8640, 17280, 8640, 8640, 17280, 4320, 17280, 17280, 8640, 4320, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 4320, 17280, 8640, 17280, 17280, 4320, 17280, 8640, 8640, 17280, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 4320, 4320, 4320, 4320]
Prompts retrieved: 2587680 . Total input tokens: 577057570 . Total output tokens: 517693652
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 114.05785608803853,
    "estimated_duration": 3600.0230305189934,
    "input_throughput": 6239.465083855799,
    "output_throughput": 5501.323139353597,
    "total_throughput": 11740.788223209396,
    "itl": 152.75049392858142,
    "ttft": 2029980.9144103306,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 439,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4541243181563963,
    "arrivals": 861811,
    "finished_requests": 90562,
    "scheduler_time": 162.86983021575378
}
#Debug simulation 
Total elapsed time: 114.0580293093808. Arrivals time: 0.7924325368367136 Scheduler time: 113.02791367238387 Scheduler overhead time: 0.09525319281965494 Adapter cache time: 0.024182039313018322 Engine time: 0.09084768081083894 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_16-16-16/adapters_256_slots_64_rate_1.6-0.8-0.4_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_16-16-16/adapters_256_slots_64_rate_1.6-0.8-0.4_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 4320, 17280, 17280, 4320, 17280, 8640, 17280, 4320, 8640, 4320, 17280, 8640, 8640, 8640, 8640, 17280, 4320, 4320, 4320, 8640, 17280, 4320, 17280, 17280, 8640, 8640, 8640, 4320, 17280, 4320, 8640, 8640, 4320, 8640, 4320, 4320, 8640, 8640, 17280, 8640, 4320, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 4320, 17280, 17280, 8640, 4320, 4320, 17280, 8640, 4320, 8640, 8640, 17280, 8640, 4320, 4320, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 8640, 4320, 8640, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 17280, 17280, 4320, 17280, 4320, 8640, 17280, 17280, 17280, 8640, 4320, 17280, 8640, 4320, 4320, 4320, 4320, 4320, 17280, 8640, 4320, 17280, 4320, 17280, 4320, 4320, 8640, 8640, 17280, 8640, 17280, 4320, 8640, 4320, 17280, 17280, 4320, 17280, 8640, 4320, 17280, 4320, 4320, 17280, 17280, 8640, 17280, 17280, 4320, 17280, 8640, 8640, 4320, 8640, 17280, 17280, 4320, 17280, 8640, 4320, 8640, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 4320, 4320, 17280, 4320, 8640, 17280, 17280, 8640, 4320, 17280, 4320, 8640, 8640, 4320, 8640, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 17280, 8640, 17280, 8640, 4320, 8640, 17280, 8640, 17280, 4320, 17280, 4320, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 4320, 17280, 4320, 17280, 8640, 8640, 4320, 8640, 17280, 8640, 8640, 17280, 4320, 17280, 17280, 8640, 4320, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 4320, 17280, 8640, 17280, 17280, 4320, 17280, 8640, 8640, 17280, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 4320, 4320, 4320, 4320]
Prompts retrieved: 2587680 . Total input tokens: 577057570 . Total output tokens: 517693652
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 128.9164629690349,
    "estimated_duration": 3600.0043838344773,
    "input_throughput": 6233.1335208262135,
    "output_throughput": 5507.565515484557,
    "total_throughput": 11740.69903631077,
    "itl": 153.20754891971987,
    "ttft": 2028414.2083396076,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 428,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2797415262181226,
    "arrivals": 861811,
    "finished_requests": 90556,
    "scheduler_time": 162.37245531368706
}
#Debug simulation 
Total elapsed time: 128.91661904007196. Arrivals time: 0.9094838555902243 Scheduler time: 127.72490528225899 Scheduler overhead time: 0.11233069933950901 Adapter cache time: 0.027888511773198843 Engine time: 0.11016920628026128 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_16-16-32/adapters_256_slots_64_rate_1.6-0.8-0.4_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_16-16-32/adapters_256_slots_64_rate_1.6-0.8-0.4_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 4320, 17280, 17280, 4320, 17280, 8640, 17280, 4320, 8640, 4320, 17280, 8640, 8640, 8640, 8640, 17280, 4320, 4320, 4320, 8640, 17280, 4320, 17280, 17280, 8640, 8640, 8640, 4320, 17280, 4320, 8640, 8640, 4320, 8640, 4320, 4320, 8640, 8640, 17280, 8640, 4320, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 4320, 17280, 17280, 8640, 4320, 4320, 17280, 8640, 4320, 8640, 8640, 17280, 8640, 4320, 4320, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 8640, 4320, 8640, 4320, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 17280, 17280, 4320, 17280, 4320, 8640, 17280, 17280, 17280, 8640, 4320, 17280, 8640, 4320, 4320, 4320, 4320, 4320, 17280, 8640, 4320, 17280, 4320, 17280, 4320, 4320, 8640, 8640, 17280, 8640, 17280, 4320, 8640, 4320, 17280, 17280, 4320, 17280, 8640, 4320, 17280, 4320, 4320, 17280, 17280, 8640, 17280, 17280, 4320, 17280, 8640, 8640, 4320, 8640, 17280, 17280, 4320, 17280, 8640, 4320, 8640, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 4320, 4320, 17280, 4320, 8640, 17280, 17280, 8640, 4320, 17280, 4320, 8640, 8640, 4320, 8640, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 17280, 8640, 17280, 8640, 4320, 8640, 17280, 8640, 17280, 4320, 17280, 4320, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 4320, 17280, 4320, 17280, 8640, 8640, 4320, 8640, 17280, 8640, 8640, 17280, 4320, 17280, 17280, 8640, 4320, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 4320, 17280, 8640, 17280, 17280, 4320, 17280, 8640, 8640, 17280, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 4320, 4320, 4320, 4320]
Prompts retrieved: 2587680 . Total input tokens: 577057570 . Total output tokens: 517693652
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 114.8926980108954,
    "estimated_duration": 3600.0455584474194,
    "input_throughput": 6239.426039288017,
    "output_throughput": 5501.288713840942,
    "total_throughput": 11740.71475312896,
    "itl": 152.75115173438277,
    "ttft": 2029991.310841228,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 439,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.473616155050695,
    "arrivals": 861811,
    "finished_requests": 90562,
    "scheduler_time": 162.87008154864438
}
#Debug simulation 
Total elapsed time: 114.89289999287575. Arrivals time: 0.7965965638868511 Scheduler time: 113.85613053292036 Scheduler overhead time: 0.09545264858752489 Adapter cache time: 0.0252910815179348 Engine time: 0.09199197823181748 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-8-8/adapters_256_slots_64_rate_1.6-0.8-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-8-8/adapters_256_slots_64_rate_1.6-0.8-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 1080, 17280, 17280, 1080, 17280, 8640, 17280, 1080, 8640, 1080, 17280, 8640, 8640, 8640, 8640, 17280, 1080, 1080, 1080, 8640, 17280, 1080, 17280, 17280, 8640, 8640, 8640, 1080, 17280, 1080, 8640, 8640, 1080, 8640, 1080, 1080, 8640, 8640, 17280, 8640, 1080, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 1080, 17280, 17280, 8640, 1080, 1080, 17280, 8640, 1080, 8640, 8640, 17280, 8640, 1080, 1080, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 8640, 1080, 8640, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 17280, 17280, 1080, 17280, 1080, 8640, 17280, 17280, 17280, 8640, 1080, 17280, 8640, 1080, 1080, 1080, 1080, 1080, 17280, 8640, 1080, 17280, 1080, 17280, 1080, 1080, 8640, 8640, 17280, 8640, 17280, 1080, 8640, 1080, 17280, 17280, 1080, 17280, 8640, 1080, 17280, 1080, 1080, 17280, 17280, 8640, 17280, 17280, 1080, 17280, 8640, 8640, 1080, 8640, 17280, 17280, 1080, 17280, 8640, 1080, 8640, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 1080, 1080, 17280, 1080, 8640, 17280, 17280, 8640, 1080, 17280, 1080, 8640, 8640, 1080, 8640, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 17280, 8640, 17280, 8640, 1080, 8640, 17280, 8640, 17280, 1080, 17280, 1080, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 1080, 17280, 1080, 17280, 8640, 8640, 1080, 8640, 17280, 8640, 8640, 17280, 1080, 17280, 17280, 8640, 1080, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 1080, 17280, 8640, 17280, 17280, 1080, 17280, 8640, 8640, 17280, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 1080, 1080, 1080, 1080]
Prompts retrieved: 2312280 . Total input tokens: 515501074 . Total output tokens: 462498738
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 113.90547641599551,
    "estimated_duration": 3600.0284747926444,
    "input_throughput": 6286.699163206919,
    "output_throughput": 5515.097488539611,
    "total_throughput": 11801.79665174653,
    "itl": 153.49204928645835,
    "ttft": 2010317.506455632,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 512,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5669697248935883,
    "arrivals": 769968,
    "finished_requests": 91173,
    "scheduler_time": 162.0749104835148
}
#Debug simulation 
Total elapsed time: 113.90565815707669. Arrivals time: 0.8334528263658285 Scheduler time: 112.82664916757494 Scheduler overhead time: 0.09456234471872449 Adapter cache time: 0.0271337004378438 Engine time: 0.09421436674892902 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-8-16/adapters_256_slots_64_rate_1.6-0.8-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-8-16/adapters_256_slots_64_rate_1.6-0.8-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 1080, 17280, 17280, 1080, 17280, 8640, 17280, 1080, 8640, 1080, 17280, 8640, 8640, 8640, 8640, 17280, 1080, 1080, 1080, 8640, 17280, 1080, 17280, 17280, 8640, 8640, 8640, 1080, 17280, 1080, 8640, 8640, 1080, 8640, 1080, 1080, 8640, 8640, 17280, 8640, 1080, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 1080, 17280, 17280, 8640, 1080, 1080, 17280, 8640, 1080, 8640, 8640, 17280, 8640, 1080, 1080, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 8640, 1080, 8640, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 17280, 17280, 1080, 17280, 1080, 8640, 17280, 17280, 17280, 8640, 1080, 17280, 8640, 1080, 1080, 1080, 1080, 1080, 17280, 8640, 1080, 17280, 1080, 17280, 1080, 1080, 8640, 8640, 17280, 8640, 17280, 1080, 8640, 1080, 17280, 17280, 1080, 17280, 8640, 1080, 17280, 1080, 1080, 17280, 17280, 8640, 17280, 17280, 1080, 17280, 8640, 8640, 1080, 8640, 17280, 17280, 1080, 17280, 8640, 1080, 8640, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 1080, 1080, 17280, 1080, 8640, 17280, 17280, 8640, 1080, 17280, 1080, 8640, 8640, 1080, 8640, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 17280, 8640, 17280, 8640, 1080, 8640, 17280, 8640, 17280, 1080, 17280, 1080, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 1080, 17280, 1080, 17280, 8640, 8640, 1080, 8640, 17280, 8640, 8640, 17280, 1080, 17280, 17280, 8640, 1080, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 1080, 17280, 8640, 17280, 17280, 1080, 17280, 8640, 8640, 17280, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 1080, 1080, 1080, 1080]
Prompts retrieved: 2312280 . Total input tokens: 515501074 . Total output tokens: 462498738
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 112.45947496592999,
    "estimated_duration": 3600.1709811274804,
    "input_throughput": 6293.103888333839,
    "output_throughput": 5515.173613721466,
    "total_throughput": 11808.277502055305,
    "itl": 153.54211650480116,
    "ttft": 2012201.1893606689,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 502,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6387018703552947,
    "arrivals": 769968,
    "finished_requests": 91218,
    "scheduler_time": 161.97048691503178
}
#Debug simulation 
Total elapsed time: 112.45964971091598. Arrivals time: 0.811218065675348 Scheduler time: 111.40398613596335 Scheduler overhead time: 0.09468388417735696 Adapter cache time: 0.026471705175936222 Engine time: 0.09433407103642821 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-8-32/adapters_256_slots_64_rate_1.6-0.8-0.1_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-8-32/adapters_256_slots_64_rate_1.6-0.8-0.1_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 1080, 17280, 17280, 1080, 17280, 8640, 17280, 1080, 8640, 1080, 17280, 8640, 8640, 8640, 8640, 17280, 1080, 1080, 1080, 8640, 17280, 1080, 17280, 17280, 8640, 8640, 8640, 1080, 17280, 1080, 8640, 8640, 1080, 8640, 1080, 1080, 8640, 8640, 17280, 8640, 1080, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 1080, 17280, 17280, 8640, 1080, 1080, 17280, 8640, 1080, 8640, 8640, 17280, 8640, 1080, 1080, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 8640, 1080, 8640, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 17280, 17280, 1080, 17280, 1080, 8640, 17280, 17280, 17280, 8640, 1080, 17280, 8640, 1080, 1080, 1080, 1080, 1080, 17280, 8640, 1080, 17280, 1080, 17280, 1080, 1080, 8640, 8640, 17280, 8640, 17280, 1080, 8640, 1080, 17280, 17280, 1080, 17280, 8640, 1080, 17280, 1080, 1080, 17280, 17280, 8640, 17280, 17280, 1080, 17280, 8640, 8640, 1080, 8640, 17280, 17280, 1080, 17280, 8640, 1080, 8640, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 1080, 1080, 17280, 1080, 8640, 17280, 17280, 8640, 1080, 17280, 1080, 8640, 8640, 1080, 8640, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 17280, 8640, 17280, 8640, 1080, 8640, 17280, 8640, 17280, 1080, 17280, 1080, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 1080, 17280, 1080, 17280, 8640, 8640, 1080, 8640, 17280, 8640, 8640, 17280, 1080, 17280, 17280, 8640, 1080, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 1080, 17280, 8640, 17280, 17280, 1080, 17280, 8640, 8640, 17280, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 1080, 1080, 1080, 1080]
Prompts retrieved: 2312280 . Total input tokens: 515501074 . Total output tokens: 462498738
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 113.74543572077528,
    "estimated_duration": 3600.000448156591,
    "input_throughput": 6292.811438843077,
    "output_throughput": 5514.9132023486945,
    "total_throughput": 11807.724641191771,
    "itl": 153.54197020650116,
    "ttft": 2012170.877193031,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 502,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6414988677390019,
    "arrivals": 769968,
    "finished_requests": 91212,
    "scheduler_time": 161.96269876386665
}
#Debug simulation 
Total elapsed time: 113.7456713099964. Arrivals time: 0.779169388115406 Scheduler time: 112.71964300842956 Scheduler overhead time: 0.09569462109357119 Adapter cache time: 0.026836581528186798 Engine time: 0.09561170684173703 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-16-16/adapters_256_slots_64_rate_1.6-0.8-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-16-16/adapters_256_slots_64_rate_1.6-0.8-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 1080, 17280, 17280, 1080, 17280, 8640, 17280, 1080, 8640, 1080, 17280, 8640, 8640, 8640, 8640, 17280, 1080, 1080, 1080, 8640, 17280, 1080, 17280, 17280, 8640, 8640, 8640, 1080, 17280, 1080, 8640, 8640, 1080, 8640, 1080, 1080, 8640, 8640, 17280, 8640, 1080, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 1080, 17280, 17280, 8640, 1080, 1080, 17280, 8640, 1080, 8640, 8640, 17280, 8640, 1080, 1080, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 8640, 1080, 8640, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 17280, 17280, 1080, 17280, 1080, 8640, 17280, 17280, 17280, 8640, 1080, 17280, 8640, 1080, 1080, 1080, 1080, 1080, 17280, 8640, 1080, 17280, 1080, 17280, 1080, 1080, 8640, 8640, 17280, 8640, 17280, 1080, 8640, 1080, 17280, 17280, 1080, 17280, 8640, 1080, 17280, 1080, 1080, 17280, 17280, 8640, 17280, 17280, 1080, 17280, 8640, 8640, 1080, 8640, 17280, 17280, 1080, 17280, 8640, 1080, 8640, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 1080, 1080, 17280, 1080, 8640, 17280, 17280, 8640, 1080, 17280, 1080, 8640, 8640, 1080, 8640, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 17280, 8640, 17280, 8640, 1080, 8640, 17280, 8640, 17280, 1080, 17280, 1080, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 1080, 17280, 1080, 17280, 8640, 8640, 1080, 8640, 17280, 8640, 8640, 17280, 1080, 17280, 17280, 8640, 1080, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 1080, 17280, 8640, 17280, 17280, 1080, 17280, 8640, 8640, 17280, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 1080, 1080, 1080, 1080]
Prompts retrieved: 2312280 . Total input tokens: 515501074 . Total output tokens: 462498738
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 117.06643439689651,
    "estimated_duration": 3600.0055993786173,
    "input_throughput": 6285.963000698107,
    "output_throughput": 5507.703655633867,
    "total_throughput": 11793.666656331974,
    "itl": 153.29322335976423,
    "ttft": 2009484.6804911783,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 515,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6126058685569955,
    "arrivals": 769968,
    "finished_requests": 91048,
    "scheduler_time": 162.15558265954095
}
#Debug simulation 
Total elapsed time: 117.06660070922226. Arrivals time: 0.7839242503978312 Scheduler time: 116.0313291256316 Scheduler overhead time: 0.09924717713147402 Adapter cache time: 0.02638655761256814 Engine time: 0.09623752208426595 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-16-32/adapters_256_slots_64_rate_1.6-0.8-0.1_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-16-32/adapters_256_slots_64_rate_1.6-0.8-0.1_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 1080, 17280, 17280, 1080, 17280, 8640, 17280, 1080, 8640, 1080, 17280, 8640, 8640, 8640, 8640, 17280, 1080, 1080, 1080, 8640, 17280, 1080, 17280, 17280, 8640, 8640, 8640, 1080, 17280, 1080, 8640, 8640, 1080, 8640, 1080, 1080, 8640, 8640, 17280, 8640, 1080, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 1080, 17280, 17280, 8640, 1080, 1080, 17280, 8640, 1080, 8640, 8640, 17280, 8640, 1080, 1080, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 8640, 1080, 8640, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 17280, 17280, 1080, 17280, 1080, 8640, 17280, 17280, 17280, 8640, 1080, 17280, 8640, 1080, 1080, 1080, 1080, 1080, 17280, 8640, 1080, 17280, 1080, 17280, 1080, 1080, 8640, 8640, 17280, 8640, 17280, 1080, 8640, 1080, 17280, 17280, 1080, 17280, 8640, 1080, 17280, 1080, 1080, 17280, 17280, 8640, 17280, 17280, 1080, 17280, 8640, 8640, 1080, 8640, 17280, 17280, 1080, 17280, 8640, 1080, 8640, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 1080, 1080, 17280, 1080, 8640, 17280, 17280, 8640, 1080, 17280, 1080, 8640, 8640, 1080, 8640, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 17280, 8640, 17280, 8640, 1080, 8640, 17280, 8640, 17280, 1080, 17280, 1080, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 1080, 17280, 1080, 17280, 8640, 8640, 1080, 8640, 17280, 8640, 8640, 17280, 1080, 17280, 17280, 8640, 1080, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 1080, 17280, 8640, 17280, 17280, 1080, 17280, 8640, 8640, 17280, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 1080, 1080, 1080, 1080]
Prompts retrieved: 2312280 . Total input tokens: 515501074 . Total output tokens: 462498738
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 111.49328249692917,
    "estimated_duration": 3600.0143961382328,
    "input_throughput": 6283.89320450133,
    "output_throughput": 5510.551297039386,
    "total_throughput": 11794.444501540716,
    "itl": 153.39602807863898,
    "ttft": 2011219.2055757218,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 522,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7280058520473582,
    "arrivals": 769968,
    "finished_requests": 91123,
    "scheduler_time": 162.12983728274122
}
#Debug simulation 
Total elapsed time: 111.49355892697349. Arrivals time: 0.8012634855695069 Scheduler time: 110.45104141393676 Scheduler overhead time: 0.09327107109129429 Adapter cache time: 0.027506503742188215 Engine time: 0.09317572182044387 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_16-16-16/adapters_256_slots_64_rate_1.6-0.8-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_16-16-16/adapters_256_slots_64_rate_1.6-0.8-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 1080, 17280, 17280, 1080, 17280, 8640, 17280, 1080, 8640, 1080, 17280, 8640, 8640, 8640, 8640, 17280, 1080, 1080, 1080, 8640, 17280, 1080, 17280, 17280, 8640, 8640, 8640, 1080, 17280, 1080, 8640, 8640, 1080, 8640, 1080, 1080, 8640, 8640, 17280, 8640, 1080, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 1080, 17280, 17280, 8640, 1080, 1080, 17280, 8640, 1080, 8640, 8640, 17280, 8640, 1080, 1080, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 8640, 1080, 8640, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 17280, 17280, 1080, 17280, 1080, 8640, 17280, 17280, 17280, 8640, 1080, 17280, 8640, 1080, 1080, 1080, 1080, 1080, 17280, 8640, 1080, 17280, 1080, 17280, 1080, 1080, 8640, 8640, 17280, 8640, 17280, 1080, 8640, 1080, 17280, 17280, 1080, 17280, 8640, 1080, 17280, 1080, 1080, 17280, 17280, 8640, 17280, 17280, 1080, 17280, 8640, 8640, 1080, 8640, 17280, 17280, 1080, 17280, 8640, 1080, 8640, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 1080, 1080, 17280, 1080, 8640, 17280, 17280, 8640, 1080, 17280, 1080, 8640, 8640, 1080, 8640, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 17280, 8640, 17280, 8640, 1080, 8640, 17280, 8640, 17280, 1080, 17280, 1080, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 1080, 17280, 1080, 17280, 8640, 8640, 1080, 8640, 17280, 8640, 8640, 17280, 1080, 17280, 17280, 8640, 1080, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 1080, 17280, 8640, 17280, 17280, 1080, 17280, 8640, 8640, 17280, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 1080, 1080, 1080, 1080]
Prompts retrieved: 2312280 . Total input tokens: 515501074 . Total output tokens: 462498738
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 112.91678414074704,
    "estimated_duration": 3600.0820881530244,
    "input_throughput": 6290.229624074461,
    "output_throughput": 5513.983435356662,
    "total_throughput": 11804.213059431124,
    "itl": 153.44357336549356,
    "ttft": 2010736.6209273608,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 522,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5608062539389171,
    "arrivals": 769968,
    "finished_requests": 91140,
    "scheduler_time": 162.09393930653525
}
#Debug simulation 
Total elapsed time: 112.91696040984243. Arrivals time: 0.81247076112777 Scheduler time: 111.85899807699025 Scheduler overhead time: 0.09629298700019717 Adapter cache time: 0.025781275238841772 Engine time: 0.09468088485300541 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_16-16-32/adapters_256_slots_64_rate_1.6-0.8-0.1_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_16-16-32/adapters_256_slots_64_rate_1.6-0.8-0.1_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 1080, 17280, 17280, 1080, 17280, 8640, 17280, 1080, 8640, 1080, 17280, 8640, 8640, 8640, 8640, 17280, 1080, 1080, 1080, 8640, 17280, 1080, 17280, 17280, 8640, 8640, 8640, 1080, 17280, 1080, 8640, 8640, 1080, 8640, 1080, 1080, 8640, 8640, 17280, 8640, 1080, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 1080, 17280, 17280, 8640, 1080, 1080, 17280, 8640, 1080, 8640, 8640, 17280, 8640, 1080, 1080, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 8640, 1080, 8640, 1080, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 17280, 17280, 1080, 17280, 1080, 8640, 17280, 17280, 17280, 8640, 1080, 17280, 8640, 1080, 1080, 1080, 1080, 1080, 17280, 8640, 1080, 17280, 1080, 17280, 1080, 1080, 8640, 8640, 17280, 8640, 17280, 1080, 8640, 1080, 17280, 17280, 1080, 17280, 8640, 1080, 17280, 1080, 1080, 17280, 17280, 8640, 17280, 17280, 1080, 17280, 8640, 8640, 1080, 8640, 17280, 17280, 1080, 17280, 8640, 1080, 8640, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 1080, 1080, 17280, 1080, 8640, 17280, 17280, 8640, 1080, 17280, 1080, 8640, 8640, 1080, 8640, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 17280, 8640, 17280, 8640, 1080, 8640, 17280, 8640, 17280, 1080, 17280, 1080, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 1080, 17280, 1080, 17280, 8640, 8640, 1080, 8640, 17280, 8640, 8640, 17280, 1080, 17280, 17280, 8640, 1080, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 1080, 17280, 8640, 17280, 17280, 1080, 17280, 8640, 8640, 17280, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 1080, 1080, 1080, 1080]
Prompts retrieved: 2312280 . Total input tokens: 515501074 . Total output tokens: 462498738
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 113.06046337168664,
    "estimated_duration": 3600.0364556592235,
    "input_throughput": 6283.854699426241,
    "output_throughput": 5510.517530680766,
    "total_throughput": 11794.372230107007,
    "itl": 153.396656232115,
    "ttft": 2011227.4336390367,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 522,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7507672873884412,
    "arrivals": 769968,
    "finished_requests": 91123,
    "scheduler_time": 162.1299707960159
}
#Debug simulation 
Total elapsed time: 113.06063524400815. Arrivals time: 0.7735617621801794 Scheduler time: 112.041418928653 Scheduler overhead time: 0.09645878383889794 Adapter cache time: 0.026782259345054626 Engine time: 0.09402106376364827 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-8-8/adapters_256_slots_64_rate_1.6-0.8-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-8-8/adapters_256_slots_64_rate_1.6-0.8-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 540, 17280, 17280, 540, 17280, 8640, 17280, 540, 8640, 540, 17280, 8640, 8640, 8640, 8640, 17280, 540, 540, 540, 8640, 17280, 540, 17280, 17280, 8640, 8640, 8640, 540, 17280, 540, 8640, 8640, 540, 8640, 540, 540, 8640, 8640, 17280, 8640, 540, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 540, 17280, 17280, 8640, 540, 540, 17280, 8640, 540, 8640, 8640, 17280, 8640, 540, 540, 17280, 17280, 17280, 17280, 17280, 17280, 540, 8640, 540, 8640, 540, 540, 540, 8640, 8640, 8640, 540, 540, 17280, 17280, 540, 17280, 540, 8640, 17280, 17280, 17280, 8640, 540, 17280, 8640, 540, 540, 540, 540, 540, 17280, 8640, 540, 17280, 540, 17280, 540, 540, 8640, 8640, 17280, 8640, 17280, 540, 8640, 540, 17280, 17280, 540, 17280, 8640, 540, 17280, 540, 540, 17280, 17280, 8640, 17280, 17280, 540, 17280, 8640, 8640, 540, 8640, 17280, 17280, 540, 17280, 8640, 540, 8640, 17280, 540, 540, 540, 540, 540, 540, 17280, 540, 540, 540, 17280, 540, 8640, 17280, 17280, 8640, 540, 17280, 540, 8640, 8640, 540, 8640, 540, 17280, 540, 540, 17280, 540, 17280, 17280, 8640, 17280, 8640, 540, 8640, 17280, 8640, 17280, 540, 17280, 540, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 540, 17280, 540, 17280, 8640, 8640, 540, 8640, 17280, 8640, 8640, 17280, 540, 17280, 17280, 8640, 540, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 540, 17280, 8640, 17280, 17280, 540, 17280, 8640, 8640, 17280, 540, 8640, 540, 540, 540, 540, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 540, 540, 540, 540]
Prompts retrieved: 2266380 . Total input tokens: 505284175 . Total output tokens: 453316467
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 107.79912582132965,
    "estimated_duration": 3600.0285493731544,
    "input_throughput": 6277.95771340072,
    "output_throughput": 5515.585425970419,
    "total_throughput": 11793.543139371139,
    "itl": 153.73969952773191,
    "ttft": 2011880.4266411683,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 496,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5180019209906626,
    "arrivals": 754714,
    "finished_requests": 91124,
    "scheduler_time": 161.93782320830715
}
#Debug simulation 
Total elapsed time: 107.79929904825985. Arrivals time: 0.7553640701808035 Scheduler time: 106.8066017664969 Scheduler overhead time: 0.0924989739432931 Adapter cache time: 0.026177999563515186 Engine time: 0.0908611505292356 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-8-16/adapters_256_slots_64_rate_1.6-0.8-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-8-16/adapters_256_slots_64_rate_1.6-0.8-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 540, 17280, 17280, 540, 17280, 8640, 17280, 540, 8640, 540, 17280, 8640, 8640, 8640, 8640, 17280, 540, 540, 540, 8640, 17280, 540, 17280, 17280, 8640, 8640, 8640, 540, 17280, 540, 8640, 8640, 540, 8640, 540, 540, 8640, 8640, 17280, 8640, 540, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 540, 17280, 17280, 8640, 540, 540, 17280, 8640, 540, 8640, 8640, 17280, 8640, 540, 540, 17280, 17280, 17280, 17280, 17280, 17280, 540, 8640, 540, 8640, 540, 540, 540, 8640, 8640, 8640, 540, 540, 17280, 17280, 540, 17280, 540, 8640, 17280, 17280, 17280, 8640, 540, 17280, 8640, 540, 540, 540, 540, 540, 17280, 8640, 540, 17280, 540, 17280, 540, 540, 8640, 8640, 17280, 8640, 17280, 540, 8640, 540, 17280, 17280, 540, 17280, 8640, 540, 17280, 540, 540, 17280, 17280, 8640, 17280, 17280, 540, 17280, 8640, 8640, 540, 8640, 17280, 17280, 540, 17280, 8640, 540, 8640, 17280, 540, 540, 540, 540, 540, 540, 17280, 540, 540, 540, 17280, 540, 8640, 17280, 17280, 8640, 540, 17280, 540, 8640, 8640, 540, 8640, 540, 17280, 540, 540, 17280, 540, 17280, 17280, 8640, 17280, 8640, 540, 8640, 17280, 8640, 17280, 540, 17280, 540, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 540, 17280, 540, 17280, 8640, 8640, 540, 8640, 17280, 8640, 8640, 17280, 540, 17280, 17280, 8640, 540, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 540, 17280, 8640, 17280, 17280, 540, 17280, 8640, 8640, 17280, 540, 8640, 540, 540, 540, 540, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 540, 540, 540, 540]
Prompts retrieved: 2266380 . Total input tokens: 505284175 . Total output tokens: 453316467
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 111.75101258605719,
    "estimated_duration": 3600.0830571837637,
    "input_throughput": 6261.762476567583,
    "output_throughput": 5504.020514321306,
    "total_throughput": 11765.782990888889,
    "itl": 153.11080334131194,
    "ttft": 2008662.4739658777,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 511,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6672467042831762,
    "arrivals": 754714,
    "finished_requests": 90822,
    "scheduler_time": 162.49015574306995
}
#Debug simulation 
Total elapsed time: 111.75119310803711. Arrivals time: 0.9356591030955315 Scheduler time: 110.5729654203169 Scheduler overhead time: 0.09530862746760249 Adapter cache time: 0.026307630818337202 Engine time: 0.09219926409423351 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-8-32/adapters_256_slots_64_rate_1.6-0.8-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-8-32/adapters_256_slots_64_rate_1.6-0.8-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 540, 17280, 17280, 540, 17280, 8640, 17280, 540, 8640, 540, 17280, 8640, 8640, 8640, 8640, 17280, 540, 540, 540, 8640, 17280, 540, 17280, 17280, 8640, 8640, 8640, 540, 17280, 540, 8640, 8640, 540, 8640, 540, 540, 8640, 8640, 17280, 8640, 540, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 540, 17280, 17280, 8640, 540, 540, 17280, 8640, 540, 8640, 8640, 17280, 8640, 540, 540, 17280, 17280, 17280, 17280, 17280, 17280, 540, 8640, 540, 8640, 540, 540, 540, 8640, 8640, 8640, 540, 540, 17280, 17280, 540, 17280, 540, 8640, 17280, 17280, 17280, 8640, 540, 17280, 8640, 540, 540, 540, 540, 540, 17280, 8640, 540, 17280, 540, 17280, 540, 540, 8640, 8640, 17280, 8640, 17280, 540, 8640, 540, 17280, 17280, 540, 17280, 8640, 540, 17280, 540, 540, 17280, 17280, 8640, 17280, 17280, 540, 17280, 8640, 8640, 540, 8640, 17280, 17280, 540, 17280, 8640, 540, 8640, 17280, 540, 540, 540, 540, 540, 540, 17280, 540, 540, 540, 17280, 540, 8640, 17280, 17280, 8640, 540, 17280, 540, 8640, 8640, 540, 8640, 540, 17280, 540, 540, 17280, 540, 17280, 17280, 8640, 17280, 8640, 540, 8640, 17280, 8640, 17280, 540, 17280, 540, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 540, 17280, 540, 17280, 8640, 8640, 540, 8640, 17280, 8640, 8640, 17280, 540, 17280, 17280, 8640, 540, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 540, 17280, 8640, 17280, 17280, 540, 17280, 8640, 8640, 17280, 540, 8640, 540, 540, 540, 540, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 540, 540, 540, 540]
Prompts retrieved: 2266380 . Total input tokens: 505284175 . Total output tokens: 453316467
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 108.55579427210614,
    "estimated_duration": 3600.086350027876,
    "input_throughput": 6261.75674920282,
    "output_throughput": 5504.015480030519,
    "total_throughput": 11765.77222923334,
    "itl": 153.11092487402274,
    "ttft": 2008663.7406944262,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 511,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6702395273558897,
    "arrivals": 754714,
    "finished_requests": 90822,
    "scheduler_time": 162.49017728821732
}
#Debug simulation 
Total elapsed time: 108.55600941926241. Arrivals time: 0.8990469733253121 Scheduler time: 107.42096719518304 Scheduler overhead time: 0.09095725929364562 Adapter cache time: 0.026696222834289074 Engine time: 0.09155296022072434 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-16-16/adapters_256_slots_64_rate_1.6-0.8-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-16-16/adapters_256_slots_64_rate_1.6-0.8-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 540, 17280, 17280, 540, 17280, 8640, 17280, 540, 8640, 540, 17280, 8640, 8640, 8640, 8640, 17280, 540, 540, 540, 8640, 17280, 540, 17280, 17280, 8640, 8640, 8640, 540, 17280, 540, 8640, 8640, 540, 8640, 540, 540, 8640, 8640, 17280, 8640, 540, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 540, 17280, 17280, 8640, 540, 540, 17280, 8640, 540, 8640, 8640, 17280, 8640, 540, 540, 17280, 17280, 17280, 17280, 17280, 17280, 540, 8640, 540, 8640, 540, 540, 540, 8640, 8640, 8640, 540, 540, 17280, 17280, 540, 17280, 540, 8640, 17280, 17280, 17280, 8640, 540, 17280, 8640, 540, 540, 540, 540, 540, 17280, 8640, 540, 17280, 540, 17280, 540, 540, 8640, 8640, 17280, 8640, 17280, 540, 8640, 540, 17280, 17280, 540, 17280, 8640, 540, 17280, 540, 540, 17280, 17280, 8640, 17280, 17280, 540, 17280, 8640, 8640, 540, 8640, 17280, 17280, 540, 17280, 8640, 540, 8640, 17280, 540, 540, 540, 540, 540, 540, 17280, 540, 540, 540, 17280, 540, 8640, 17280, 17280, 8640, 540, 17280, 540, 8640, 8640, 540, 8640, 540, 17280, 540, 540, 17280, 540, 17280, 17280, 8640, 17280, 8640, 540, 8640, 17280, 8640, 17280, 540, 17280, 540, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 540, 17280, 540, 17280, 8640, 8640, 540, 8640, 17280, 8640, 8640, 17280, 540, 17280, 17280, 8640, 540, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 540, 17280, 8640, 17280, 17280, 540, 17280, 8640, 8640, 17280, 540, 8640, 540, 540, 540, 540, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 540, 540, 540, 540]
Prompts retrieved: 2266380 . Total input tokens: 505284175 . Total output tokens: 453316467
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 112.95907151279971,
    "estimated_duration": 3600.127777152068,
    "input_throughput": 6242.985358086261,
    "output_throughput": 5494.577477371701,
    "total_throughput": 11737.562835457962,
    "itl": 152.69948768181695,
    "ttft": 2005675.6131654277,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 523,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6336661036871296,
    "arrivals": 754714,
    "finished_requests": 90614,
    "scheduler_time": 162.95566111952118
}
#Debug simulation 
Total elapsed time: 112.95922368811443. Arrivals time: 0.7752323187887669 Scheduler time: 111.93548156972975 Scheduler overhead time: 0.09702965756878257 Adapter cache time: 0.0271663093008101 Engine time: 0.09521105838939548 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-16-32/adapters_256_slots_64_rate_1.6-0.8-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-16-32/adapters_256_slots_64_rate_1.6-0.8-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 540, 17280, 17280, 540, 17280, 8640, 17280, 540, 8640, 540, 17280, 8640, 8640, 8640, 8640, 17280, 540, 540, 540, 8640, 17280, 540, 17280, 17280, 8640, 8640, 8640, 540, 17280, 540, 8640, 8640, 540, 8640, 540, 540, 8640, 8640, 17280, 8640, 540, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 540, 17280, 17280, 8640, 540, 540, 17280, 8640, 540, 8640, 8640, 17280, 8640, 540, 540, 17280, 17280, 17280, 17280, 17280, 17280, 540, 8640, 540, 8640, 540, 540, 540, 8640, 8640, 8640, 540, 540, 17280, 17280, 540, 17280, 540, 8640, 17280, 17280, 17280, 8640, 540, 17280, 8640, 540, 540, 540, 540, 540, 17280, 8640, 540, 17280, 540, 17280, 540, 540, 8640, 8640, 17280, 8640, 17280, 540, 8640, 540, 17280, 17280, 540, 17280, 8640, 540, 17280, 540, 540, 17280, 17280, 8640, 17280, 17280, 540, 17280, 8640, 8640, 540, 8640, 17280, 17280, 540, 17280, 8640, 540, 8640, 17280, 540, 540, 540, 540, 540, 540, 17280, 540, 540, 540, 17280, 540, 8640, 17280, 17280, 8640, 540, 17280, 540, 8640, 8640, 540, 8640, 540, 17280, 540, 540, 17280, 540, 17280, 17280, 8640, 17280, 8640, 540, 8640, 17280, 8640, 17280, 540, 17280, 540, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 540, 17280, 540, 17280, 8640, 8640, 540, 8640, 17280, 8640, 8640, 17280, 540, 17280, 17280, 8640, 540, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 540, 17280, 8640, 17280, 17280, 540, 17280, 8640, 8640, 17280, 540, 8640, 540, 540, 540, 540, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 540, 540, 540, 540]
Prompts retrieved: 2266380 . Total input tokens: 505284175 . Total output tokens: 453316467
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 111.85664299270138,
    "estimated_duration": 3600.109290860167,
    "input_throughput": 6261.716847660999,
    "output_throughput": 5503.9804070130485,
    "total_throughput": 11765.697254674047,
    "itl": 153.1115316074997,
    "ttft": 2008672.4735501395,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 511,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6922464399784838,
    "arrivals": 754714,
    "finished_requests": 90822,
    "scheduler_time": 162.49034111662303
}
#Debug simulation 
Total elapsed time: 111.85681052971631. Arrivals time: 0.9346037656068802 Scheduler time: 110.67774857906625 Scheduler overhead time: 0.09624469047412276 Adapter cache time: 0.02678908361122012 Engine time: 0.09322405001148582 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_16-16-16/adapters_256_slots_64_rate_1.6-0.8-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_16-16-16/adapters_256_slots_64_rate_1.6-0.8-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 540, 17280, 17280, 540, 17280, 8640, 17280, 540, 8640, 540, 17280, 8640, 8640, 8640, 8640, 17280, 540, 540, 540, 8640, 17280, 540, 17280, 17280, 8640, 8640, 8640, 540, 17280, 540, 8640, 8640, 540, 8640, 540, 540, 8640, 8640, 17280, 8640, 540, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 540, 17280, 17280, 8640, 540, 540, 17280, 8640, 540, 8640, 8640, 17280, 8640, 540, 540, 17280, 17280, 17280, 17280, 17280, 17280, 540, 8640, 540, 8640, 540, 540, 540, 8640, 8640, 8640, 540, 540, 17280, 17280, 540, 17280, 540, 8640, 17280, 17280, 17280, 8640, 540, 17280, 8640, 540, 540, 540, 540, 540, 17280, 8640, 540, 17280, 540, 17280, 540, 540, 8640, 8640, 17280, 8640, 17280, 540, 8640, 540, 17280, 17280, 540, 17280, 8640, 540, 17280, 540, 540, 17280, 17280, 8640, 17280, 17280, 540, 17280, 8640, 8640, 540, 8640, 17280, 17280, 540, 17280, 8640, 540, 8640, 17280, 540, 540, 540, 540, 540, 540, 17280, 540, 540, 540, 17280, 540, 8640, 17280, 17280, 8640, 540, 17280, 540, 8640, 8640, 540, 8640, 540, 17280, 540, 540, 17280, 540, 17280, 17280, 8640, 17280, 8640, 540, 8640, 17280, 8640, 17280, 540, 17280, 540, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 540, 17280, 540, 17280, 8640, 8640, 540, 8640, 17280, 8640, 8640, 17280, 540, 17280, 17280, 8640, 540, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 540, 17280, 8640, 17280, 17280, 540, 17280, 8640, 8640, 17280, 540, 8640, 540, 540, 540, 540, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 540, 540, 540, 540]
Prompts retrieved: 2266380 . Total input tokens: 505284175 . Total output tokens: 453316467
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 116.50921045430005,
    "estimated_duration": 3600.0117788209864,
    "input_throughput": 6239.450140731594,
    "output_throughput": 5487.492878834366,
    "total_throughput": 11726.94301956596,
    "itl": 152.5939243370733,
    "ttft": 2004105.4449401975,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 507,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.515955499515386,
    "arrivals": 754714,
    "finished_requests": 90539,
    "scheduler_time": 163.3003636222289
}
#Debug simulation 
Total elapsed time: 116.50936844106764. Arrivals time: 0.9451881032437086 Scheduler time: 115.31803863542154 Scheduler overhead time: 0.09700312465429306 Adapter cache time: 0.026763497851788998 Engine time: 0.0937250372953713 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_16-16-32/adapters_256_slots_64_rate_1.6-0.8-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_16-16-32/adapters_256_slots_64_rate_1.6-0.8-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 540, 17280, 17280, 540, 17280, 8640, 17280, 540, 8640, 540, 17280, 8640, 8640, 8640, 8640, 17280, 540, 540, 540, 8640, 17280, 540, 17280, 17280, 8640, 8640, 8640, 540, 17280, 540, 8640, 8640, 540, 8640, 540, 540, 8640, 8640, 17280, 8640, 540, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 540, 17280, 17280, 8640, 540, 540, 17280, 8640, 540, 8640, 8640, 17280, 8640, 540, 540, 17280, 17280, 17280, 17280, 17280, 17280, 540, 8640, 540, 8640, 540, 540, 540, 8640, 8640, 8640, 540, 540, 17280, 17280, 540, 17280, 540, 8640, 17280, 17280, 17280, 8640, 540, 17280, 8640, 540, 540, 540, 540, 540, 17280, 8640, 540, 17280, 540, 17280, 540, 540, 8640, 8640, 17280, 8640, 17280, 540, 8640, 540, 17280, 17280, 540, 17280, 8640, 540, 17280, 540, 540, 17280, 17280, 8640, 17280, 17280, 540, 17280, 8640, 8640, 540, 8640, 17280, 17280, 540, 17280, 8640, 540, 8640, 17280, 540, 540, 540, 540, 540, 540, 17280, 540, 540, 540, 17280, 540, 8640, 17280, 17280, 8640, 540, 17280, 540, 8640, 8640, 540, 8640, 540, 17280, 540, 540, 17280, 540, 17280, 17280, 8640, 17280, 8640, 540, 8640, 17280, 8640, 17280, 540, 17280, 540, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 540, 17280, 540, 17280, 8640, 8640, 540, 8640, 17280, 8640, 8640, 17280, 540, 17280, 17280, 8640, 540, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 540, 17280, 8640, 17280, 17280, 540, 17280, 8640, 8640, 17280, 540, 8640, 540, 540, 540, 540, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 540, 540, 540, 540]
Prompts retrieved: 2266380 . Total input tokens: 505284175 . Total output tokens: 453316467
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 111.10868627810851,
    "estimated_duration": 3600.1300099739,
    "input_throughput": 6261.680810844781,
    "output_throughput": 5503.94873104698,
    "total_throughput": 11765.629541891762,
    "itl": 153.11216720613092,
    "ttft": 2008680.4063730796,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 511,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7131215685233454,
    "arrivals": 754714,
    "finished_requests": 90822,
    "scheduler_time": 162.49046357769745
}
#Debug simulation 
Total elapsed time: 111.10885491315275. Arrivals time: 0.8015796048566699 Scheduler time: 110.06240766076371 Scheduler overhead time: 0.09600644139572978 Adapter cache time: 0.026207888964563608 Engine time: 0.09452784107998013 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-8-8/adapters_256_slots_64_rate_1.6-0.8-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-8-8/adapters_256_slots_64_rate_1.6-0.8-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 270, 17280, 17280, 270, 17280, 8640, 17280, 270, 8640, 270, 17280, 8640, 8640, 8640, 8640, 17280, 270, 270, 270, 8640, 17280, 270, 17280, 17280, 8640, 8640, 8640, 270, 17280, 270, 8640, 8640, 270, 8640, 270, 270, 8640, 8640, 17280, 8640, 270, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 270, 17280, 17280, 8640, 270, 270, 17280, 8640, 270, 8640, 8640, 17280, 8640, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 8640, 270, 8640, 270, 270, 270, 8640, 8640, 8640, 270, 270, 17280, 17280, 270, 17280, 270, 8640, 17280, 17280, 17280, 8640, 270, 17280, 8640, 270, 270, 270, 270, 270, 17280, 8640, 270, 17280, 270, 17280, 270, 270, 8640, 8640, 17280, 8640, 17280, 270, 8640, 270, 17280, 17280, 270, 17280, 8640, 270, 17280, 270, 270, 17280, 17280, 8640, 17280, 17280, 270, 17280, 8640, 8640, 270, 8640, 17280, 17280, 270, 17280, 8640, 270, 8640, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 8640, 17280, 17280, 8640, 270, 17280, 270, 8640, 8640, 270, 8640, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 8640, 17280, 8640, 270, 8640, 17280, 8640, 17280, 270, 17280, 270, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 270, 17280, 270, 17280, 8640, 8640, 270, 8640, 17280, 8640, 8640, 17280, 270, 17280, 17280, 8640, 270, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 270, 17280, 8640, 17280, 17280, 270, 17280, 8640, 8640, 17280, 270, 8640, 270, 270, 270, 270, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 270, 270, 270, 270]
Prompts retrieved: 2243430 . Total input tokens: 500187779 . Total output tokens: 448743425
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 116.91496532503515,
    "estimated_duration": 3600.050484452091,
    "input_throughput": 6217.90363681715,
    "output_throughput": 5499.297325274347,
    "total_throughput": 11717.200962091496,
    "itl": 153.44980386292266,
    "ttft": 2004667.9249142513,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 586,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.79344581794462,
    "arrivals": 746983,
    "finished_requests": 90447,
    "scheduler_time": 162.58902558067575
}
#Debug simulation 
Total elapsed time: 116.91514013707638. Arrivals time: 0.8277221964672208 Scheduler time: 115.84193506417796 Scheduler overhead time: 0.09546722611412406 Adapter cache time: 0.02777073299512267 Engine time: 0.0938449832610786 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-8-16/adapters_256_slots_64_rate_1.6-0.8-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-8-16/adapters_256_slots_64_rate_1.6-0.8-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 270, 17280, 17280, 270, 17280, 8640, 17280, 270, 8640, 270, 17280, 8640, 8640, 8640, 8640, 17280, 270, 270, 270, 8640, 17280, 270, 17280, 17280, 8640, 8640, 8640, 270, 17280, 270, 8640, 8640, 270, 8640, 270, 270, 8640, 8640, 17280, 8640, 270, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 270, 17280, 17280, 8640, 270, 270, 17280, 8640, 270, 8640, 8640, 17280, 8640, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 8640, 270, 8640, 270, 270, 270, 8640, 8640, 8640, 270, 270, 17280, 17280, 270, 17280, 270, 8640, 17280, 17280, 17280, 8640, 270, 17280, 8640, 270, 270, 270, 270, 270, 17280, 8640, 270, 17280, 270, 17280, 270, 270, 8640, 8640, 17280, 8640, 17280, 270, 8640, 270, 17280, 17280, 270, 17280, 8640, 270, 17280, 270, 270, 17280, 17280, 8640, 17280, 17280, 270, 17280, 8640, 8640, 270, 8640, 17280, 17280, 270, 17280, 8640, 270, 8640, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 8640, 17280, 17280, 8640, 270, 17280, 270, 8640, 8640, 270, 8640, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 8640, 17280, 8640, 270, 8640, 17280, 8640, 17280, 270, 17280, 270, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 270, 17280, 270, 17280, 8640, 8640, 270, 8640, 17280, 8640, 8640, 17280, 270, 17280, 17280, 8640, 270, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 270, 17280, 8640, 17280, 17280, 270, 17280, 8640, 8640, 17280, 270, 8640, 270, 270, 270, 270, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 270, 270, 270, 270]
Prompts retrieved: 2243430 . Total input tokens: 500187779 . Total output tokens: 448743425
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 117.8830995648168,
    "estimated_duration": 3600.1215464998722,
    "input_throughput": 6214.269632576916,
    "output_throughput": 5493.220643960472,
    "total_throughput": 11707.490276537388,
    "itl": 153.58557297769525,
    "ttft": 2003446.9480622823,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 562,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8356744867423618,
    "arrivals": 746983,
    "finished_requests": 90366,
    "scheduler_time": 162.8345415829736
}
#Debug simulation 
Total elapsed time: 117.88327542785555. Arrivals time: 0.9231663751415908 Scheduler time: 116.71110651409253 Scheduler overhead time: 0.09744232567027211 Adapter cache time: 0.027964791748672724 Engine time: 0.09476185822859406 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-8-32/adapters_256_slots_64_rate_1.6-0.8-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-8-32/adapters_256_slots_64_rate_1.6-0.8-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 270, 17280, 17280, 270, 17280, 8640, 17280, 270, 8640, 270, 17280, 8640, 8640, 8640, 8640, 17280, 270, 270, 270, 8640, 17280, 270, 17280, 17280, 8640, 8640, 8640, 270, 17280, 270, 8640, 8640, 270, 8640, 270, 270, 8640, 8640, 17280, 8640, 270, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 270, 17280, 17280, 8640, 270, 270, 17280, 8640, 270, 8640, 8640, 17280, 8640, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 8640, 270, 8640, 270, 270, 270, 8640, 8640, 8640, 270, 270, 17280, 17280, 270, 17280, 270, 8640, 17280, 17280, 17280, 8640, 270, 17280, 8640, 270, 270, 270, 270, 270, 17280, 8640, 270, 17280, 270, 17280, 270, 270, 8640, 8640, 17280, 8640, 17280, 270, 8640, 270, 17280, 17280, 270, 17280, 8640, 270, 17280, 270, 270, 17280, 17280, 8640, 17280, 17280, 270, 17280, 8640, 8640, 270, 8640, 17280, 17280, 270, 17280, 8640, 270, 8640, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 8640, 17280, 17280, 8640, 270, 17280, 270, 8640, 8640, 270, 8640, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 8640, 17280, 8640, 270, 8640, 17280, 8640, 17280, 270, 17280, 270, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 270, 17280, 270, 17280, 8640, 8640, 270, 8640, 17280, 8640, 8640, 17280, 270, 17280, 17280, 8640, 270, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 270, 17280, 8640, 17280, 17280, 270, 17280, 8640, 8640, 17280, 270, 8640, 270, 270, 270, 270, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 270, 270, 270, 270]
Prompts retrieved: 2243430 . Total input tokens: 500187779 . Total output tokens: 448743425
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 117.56144001800567,
    "estimated_duration": 3600.1244971096253,
    "input_throughput": 6214.264539451776,
    "output_throughput": 5493.216141796611,
    "total_throughput": 11707.480681248386,
    "itl": 153.58566549322146,
    "ttft": 2003448.1671321,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 562,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8386116409301871,
    "arrivals": 746983,
    "finished_requests": 90366,
    "scheduler_time": 162.83455503850487
}
#Debug simulation 
Total elapsed time: 117.56163831008598. Arrivals time: 0.9216086454689503 Scheduler time: 116.39238058310002 Scheduler overhead time: 0.09782551927492023 Adapter cache time: 0.027233141008764505 Engine time: 0.09416671609506011 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-16-16/adapters_256_slots_64_rate_1.6-0.8-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-16-16/adapters_256_slots_64_rate_1.6-0.8-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 270, 17280, 17280, 270, 17280, 8640, 17280, 270, 8640, 270, 17280, 8640, 8640, 8640, 8640, 17280, 270, 270, 270, 8640, 17280, 270, 17280, 17280, 8640, 8640, 8640, 270, 17280, 270, 8640, 8640, 270, 8640, 270, 270, 8640, 8640, 17280, 8640, 270, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 270, 17280, 17280, 8640, 270, 270, 17280, 8640, 270, 8640, 8640, 17280, 8640, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 8640, 270, 8640, 270, 270, 270, 8640, 8640, 8640, 270, 270, 17280, 17280, 270, 17280, 270, 8640, 17280, 17280, 17280, 8640, 270, 17280, 8640, 270, 270, 270, 270, 270, 17280, 8640, 270, 17280, 270, 17280, 270, 270, 8640, 8640, 17280, 8640, 17280, 270, 8640, 270, 17280, 17280, 270, 17280, 8640, 270, 17280, 270, 270, 17280, 17280, 8640, 17280, 17280, 270, 17280, 8640, 8640, 270, 8640, 17280, 17280, 270, 17280, 8640, 270, 8640, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 8640, 17280, 17280, 8640, 270, 17280, 270, 8640, 8640, 270, 8640, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 8640, 17280, 8640, 270, 8640, 17280, 8640, 17280, 270, 17280, 270, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 270, 17280, 270, 17280, 8640, 8640, 270, 8640, 17280, 8640, 8640, 17280, 270, 17280, 17280, 8640, 270, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 270, 17280, 8640, 17280, 17280, 270, 17280, 8640, 8640, 17280, 270, 8640, 270, 270, 270, 270, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 270, 270, 270, 270]
Prompts retrieved: 2243430 . Total input tokens: 500187779 . Total output tokens: 448743425
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 117.3991209701635,
    "estimated_duration": 3600.08834750787,
    "input_throughput": 6217.838241524173,
    "output_throughput": 5499.2394877489105,
    "total_throughput": 11717.077729273084,
    "itl": 153.4510315179214,
    "ttft": 2004680.5218672378,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 586,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8318455599085322,
    "arrivals": 746983,
    "finished_requests": 90447,
    "scheduler_time": 162.58918508408925
}
#Debug simulation 
Total elapsed time: 117.39928264915943. Arrivals time: 0.8669773736037314 Scheduler time: 116.28518190141767 Scheduler overhead time: 0.09671594481915236 Adapter cache time: 0.027537225279957056 Engine time: 0.09445808408781886 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-16-32/adapters_256_slots_64_rate_1.6-0.8-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-16-32/adapters_256_slots_64_rate_1.6-0.8-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 270, 17280, 17280, 270, 17280, 8640, 17280, 270, 8640, 270, 17280, 8640, 8640, 8640, 8640, 17280, 270, 270, 270, 8640, 17280, 270, 17280, 17280, 8640, 8640, 8640, 270, 17280, 270, 8640, 8640, 270, 8640, 270, 270, 8640, 8640, 17280, 8640, 270, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 270, 17280, 17280, 8640, 270, 270, 17280, 8640, 270, 8640, 8640, 17280, 8640, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 8640, 270, 8640, 270, 270, 270, 8640, 8640, 8640, 270, 270, 17280, 17280, 270, 17280, 270, 8640, 17280, 17280, 17280, 8640, 270, 17280, 8640, 270, 270, 270, 270, 270, 17280, 8640, 270, 17280, 270, 17280, 270, 270, 8640, 8640, 17280, 8640, 17280, 270, 8640, 270, 17280, 17280, 270, 17280, 8640, 270, 17280, 270, 270, 17280, 17280, 8640, 17280, 17280, 270, 17280, 8640, 8640, 270, 8640, 17280, 17280, 270, 17280, 8640, 270, 8640, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 8640, 17280, 17280, 8640, 270, 17280, 270, 8640, 8640, 270, 8640, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 8640, 17280, 8640, 270, 8640, 17280, 8640, 17280, 270, 17280, 270, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 270, 17280, 270, 17280, 8640, 8640, 270, 8640, 17280, 8640, 8640, 17280, 270, 17280, 17280, 8640, 270, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 270, 17280, 8640, 17280, 17280, 270, 17280, 8640, 8640, 17280, 270, 8640, 270, 270, 270, 270, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 270, 270, 270, 270]
Prompts retrieved: 2243430 . Total input tokens: 500187779 . Total output tokens: 448743425
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 116.78155030868948,
    "estimated_duration": 3600.057320736077,
    "input_throughput": 6221.972042217413,
    "output_throughput": 5497.9638479625855,
    "total_throughput": 11719.935890179999,
    "itl": 153.6549818092941,
    "ttft": 2004635.4321117643,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 559,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8538773189485105,
    "arrivals": 746983,
    "finished_requests": 90444,
    "scheduler_time": 162.49058005006705
}
#Debug simulation 
Total elapsed time: 116.78176155267283. Arrivals time: 0.9817815939895809 Scheduler time: 115.54701654007658 Scheduler overhead time: 0.09882437903434038 Adapter cache time: 0.02893600706011057 Engine time: 0.09636112675070763 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_16-16-16/adapters_256_slots_64_rate_1.6-0.8-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_16-16-16/adapters_256_slots_64_rate_1.6-0.8-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 270, 17280, 17280, 270, 17280, 8640, 17280, 270, 8640, 270, 17280, 8640, 8640, 8640, 8640, 17280, 270, 270, 270, 8640, 17280, 270, 17280, 17280, 8640, 8640, 8640, 270, 17280, 270, 8640, 8640, 270, 8640, 270, 270, 8640, 8640, 17280, 8640, 270, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 270, 17280, 17280, 8640, 270, 270, 17280, 8640, 270, 8640, 8640, 17280, 8640, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 8640, 270, 8640, 270, 270, 270, 8640, 8640, 8640, 270, 270, 17280, 17280, 270, 17280, 270, 8640, 17280, 17280, 17280, 8640, 270, 17280, 8640, 270, 270, 270, 270, 270, 17280, 8640, 270, 17280, 270, 17280, 270, 270, 8640, 8640, 17280, 8640, 17280, 270, 8640, 270, 17280, 17280, 270, 17280, 8640, 270, 17280, 270, 270, 17280, 17280, 8640, 17280, 17280, 270, 17280, 8640, 8640, 270, 8640, 17280, 17280, 270, 17280, 8640, 270, 8640, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 8640, 17280, 17280, 8640, 270, 17280, 270, 8640, 8640, 270, 8640, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 8640, 17280, 8640, 270, 8640, 17280, 8640, 17280, 270, 17280, 270, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 270, 17280, 270, 17280, 8640, 8640, 270, 8640, 17280, 8640, 8640, 17280, 270, 17280, 17280, 8640, 270, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 270, 17280, 8640, 17280, 17280, 270, 17280, 8640, 8640, 17280, 270, 8640, 270, 270, 270, 270, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 270, 270, 270, 270]
Prompts retrieved: 2243430 . Total input tokens: 500187779 . Total output tokens: 448743425
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 116.83752086292952,
    "estimated_duration": 3600.0058137687047,
    "input_throughput": 6217.980791693852,
    "output_throughput": 5499.365563322387,
    "total_throughput": 11717.346355016238,
    "itl": 153.44827450881562,
    "ttft": 2004650.9268225068,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 586,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7521694728126496,
    "arrivals": 746983,
    "finished_requests": 90447,
    "scheduler_time": 162.588693114414
}
#Debug simulation 
Total elapsed time: 116.83769977884367. Arrivals time: 0.914581966586411 Scheduler time: 115.68042522668839 Scheduler overhead time: 0.0940063651651144 Adapter cache time: 0.02748802024871111 Engine time: 0.0919968350790441 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_16-16-32/adapters_256_slots_64_rate_1.6-0.8-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_16-16-32/adapters_256_slots_64_rate_1.6-0.8-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 270, 17280, 17280, 270, 17280, 8640, 17280, 270, 8640, 270, 17280, 8640, 8640, 8640, 8640, 17280, 270, 270, 270, 8640, 17280, 270, 17280, 17280, 8640, 8640, 8640, 270, 17280, 270, 8640, 8640, 270, 8640, 270, 270, 8640, 8640, 17280, 8640, 270, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 270, 17280, 17280, 8640, 270, 270, 17280, 8640, 270, 8640, 8640, 17280, 8640, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 8640, 270, 8640, 270, 270, 270, 8640, 8640, 8640, 270, 270, 17280, 17280, 270, 17280, 270, 8640, 17280, 17280, 17280, 8640, 270, 17280, 8640, 270, 270, 270, 270, 270, 17280, 8640, 270, 17280, 270, 17280, 270, 270, 8640, 8640, 17280, 8640, 17280, 270, 8640, 270, 17280, 17280, 270, 17280, 8640, 270, 17280, 270, 270, 17280, 17280, 8640, 17280, 17280, 270, 17280, 8640, 8640, 270, 8640, 17280, 17280, 270, 17280, 8640, 270, 8640, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 8640, 17280, 17280, 8640, 270, 17280, 270, 8640, 8640, 270, 8640, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 8640, 17280, 8640, 270, 8640, 17280, 8640, 17280, 270, 17280, 270, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 270, 17280, 270, 17280, 8640, 8640, 270, 8640, 17280, 8640, 8640, 17280, 270, 17280, 17280, 8640, 270, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 270, 17280, 8640, 17280, 17280, 270, 17280, 8640, 8640, 17280, 270, 8640, 270, 270, 270, 270, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 270, 270, 270, 270]
Prompts retrieved: 2243430 . Total input tokens: 500187779 . Total output tokens: 448743425
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 117.61509232316166,
    "estimated_duration": 3600.080660570122,
    "input_throughput": 6221.931704289298,
    "output_throughput": 5497.928203882385,
    "total_throughput": 11719.859908171684,
    "itl": 153.65565473779404,
    "ttft": 2004643.3543696322,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 559,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8772675232216671,
    "arrivals": 746983,
    "finished_requests": 90444,
    "scheduler_time": 162.49094739366225
}
#Debug simulation 
Total elapsed time: 117.61524866102263. Arrivals time: 0.9400306981988251 Scheduler time: 116.43050920777023 Scheduler overhead time: 0.09527148539200425 Adapter cache time: 0.02737989416345954 Engine time: 0.09373132651671767 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-8/adapters_256_slots_64_rate_1.6-0.8-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-8/adapters_256_slots_64_rate_1.6-0.8-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 135, 17280, 17280, 135, 17280, 8640, 17280, 135, 8640, 135, 17280, 8640, 8640, 8640, 8640, 17280, 135, 135, 135, 8640, 17280, 135, 17280, 17280, 8640, 8640, 8640, 135, 17280, 135, 8640, 8640, 135, 8640, 135, 135, 8640, 8640, 17280, 8640, 135, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 135, 17280, 17280, 8640, 135, 135, 17280, 8640, 135, 8640, 8640, 17280, 8640, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 8640, 135, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 135, 17280, 17280, 135, 17280, 135, 8640, 17280, 17280, 17280, 8640, 135, 17280, 8640, 135, 135, 135, 135, 135, 17280, 8640, 135, 17280, 135, 17280, 135, 135, 8640, 8640, 17280, 8640, 17280, 135, 8640, 135, 17280, 17280, 135, 17280, 8640, 135, 17280, 135, 135, 17280, 17280, 8640, 17280, 17280, 135, 17280, 8640, 8640, 135, 8640, 17280, 17280, 135, 17280, 8640, 135, 8640, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 8640, 17280, 17280, 8640, 135, 17280, 135, 8640, 8640, 135, 8640, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 8640, 17280, 8640, 135, 8640, 17280, 8640, 17280, 135, 17280, 135, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 135, 17280, 135, 17280, 8640, 8640, 135, 8640, 17280, 8640, 8640, 17280, 135, 17280, 17280, 8640, 135, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 135, 17280, 8640, 17280, 17280, 135, 17280, 8640, 8640, 17280, 135, 8640, 135, 135, 135, 135, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 135, 135, 135, 135]
Prompts retrieved: 2231955 . Total input tokens: 497616808 . Total output tokens: 446425470
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 113.0789711792022,
    "estimated_duration": 3600.124714971974,
    "input_throughput": 6271.105249801257,
    "output_throughput": 5520.1537650494165,
    "total_throughput": 11791.259014850673,
    "itl": 153.2797370180434,
    "ttft": 2003358.060710017,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 515,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.576151188125387,
    "arrivals": 743226,
    "finished_requests": 91347,
    "scheduler_time": 162.1921000518295
}
#Debug simulation 
Total elapsed time: 113.07915568724275. Arrivals time: 0.7485726806335151 Scheduler time: 112.08212889591232 Scheduler overhead time: 0.09701360575854778 Adapter cache time: 0.024306342005729675 Engine time: 0.09784767404198647 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-16/adapters_256_slots_64_rate_1.6-0.8-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-16/adapters_256_slots_64_rate_1.6-0.8-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 135, 17280, 17280, 135, 17280, 8640, 17280, 135, 8640, 135, 17280, 8640, 8640, 8640, 8640, 17280, 135, 135, 135, 8640, 17280, 135, 17280, 17280, 8640, 8640, 8640, 135, 17280, 135, 8640, 8640, 135, 8640, 135, 135, 8640, 8640, 17280, 8640, 135, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 135, 17280, 17280, 8640, 135, 135, 17280, 8640, 135, 8640, 8640, 17280, 8640, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 8640, 135, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 135, 17280, 17280, 135, 17280, 135, 8640, 17280, 17280, 17280, 8640, 135, 17280, 8640, 135, 135, 135, 135, 135, 17280, 8640, 135, 17280, 135, 17280, 135, 135, 8640, 8640, 17280, 8640, 17280, 135, 8640, 135, 17280, 17280, 135, 17280, 8640, 135, 17280, 135, 135, 17280, 17280, 8640, 17280, 17280, 135, 17280, 8640, 8640, 135, 8640, 17280, 17280, 135, 17280, 8640, 135, 8640, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 8640, 17280, 17280, 8640, 135, 17280, 135, 8640, 8640, 135, 8640, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 8640, 17280, 8640, 135, 8640, 17280, 8640, 17280, 135, 17280, 135, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 135, 17280, 135, 17280, 8640, 8640, 135, 8640, 17280, 8640, 8640, 17280, 135, 17280, 17280, 8640, 135, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 135, 17280, 8640, 17280, 17280, 135, 17280, 8640, 8640, 17280, 135, 8640, 135, 135, 135, 135, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 135, 135, 135, 135]
Prompts retrieved: 2231955 . Total input tokens: 497616808 . Total output tokens: 446425470
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 124.81297731213272,
    "estimated_duration": 3600.1403781724575,
    "input_throughput": 6268.190300805822,
    "output_throughput": 5518.342318108442,
    "total_throughput": 11786.532618914263,
    "itl": 153.29830132570112,
    "ttft": 2003165.2132123548,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 516,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6846485276683292,
    "arrivals": 743226,
    "finished_requests": 91305,
    "scheduler_time": 162.17829110241595
}
#Debug simulation 
Total elapsed time: 124.81314288824797. Arrivals time: 0.8297138684429228 Scheduler time: 123.70880369003862 Scheduler overhead time: 0.10840202309191227 Adapter cache time: 0.0276606110855937 Engine time: 0.10821752389892936 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-32/adapters_256_slots_64_rate_1.6-0.8-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-32/adapters_256_slots_64_rate_1.6-0.8-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 135, 17280, 17280, 135, 17280, 8640, 17280, 135, 8640, 135, 17280, 8640, 8640, 8640, 8640, 17280, 135, 135, 135, 8640, 17280, 135, 17280, 17280, 8640, 8640, 8640, 135, 17280, 135, 8640, 8640, 135, 8640, 135, 135, 8640, 8640, 17280, 8640, 135, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 135, 17280, 17280, 8640, 135, 135, 17280, 8640, 135, 8640, 8640, 17280, 8640, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 8640, 135, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 135, 17280, 17280, 135, 17280, 135, 8640, 17280, 17280, 17280, 8640, 135, 17280, 8640, 135, 135, 135, 135, 135, 17280, 8640, 135, 17280, 135, 17280, 135, 135, 8640, 8640, 17280, 8640, 17280, 135, 8640, 135, 17280, 17280, 135, 17280, 8640, 135, 17280, 135, 135, 17280, 17280, 8640, 17280, 17280, 135, 17280, 8640, 8640, 135, 8640, 17280, 17280, 135, 17280, 8640, 135, 8640, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 8640, 17280, 17280, 8640, 135, 17280, 135, 8640, 8640, 135, 8640, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 8640, 17280, 8640, 135, 8640, 17280, 8640, 17280, 135, 17280, 135, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 135, 17280, 135, 17280, 8640, 8640, 135, 8640, 17280, 8640, 8640, 17280, 135, 17280, 17280, 8640, 135, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 135, 17280, 8640, 17280, 17280, 135, 17280, 8640, 8640, 17280, 135, 8640, 135, 135, 135, 135, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 135, 135, 135, 135]
Prompts retrieved: 2231955 . Total input tokens: 497616808 . Total output tokens: 446425470
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 112.87202027533203,
    "estimated_duration": 3600.144084845021,
    "input_throughput": 6268.183847139395,
    "output_throughput": 5518.336636478044,
    "total_throughput": 11786.520483617438,
    "itl": 153.29844068930944,
    "ttft": 2003166.8241683755,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 516,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6874806065671248,
    "arrivals": 743226,
    "finished_requests": 91305,
    "scheduler_time": 162.17833026845955
}
#Debug simulation 
Total elapsed time: 112.8722804011777. Arrivals time: 0.7461075936444104 Scheduler time: 111.88018919108436 Scheduler overhead time: 0.09633845882490277 Adapter cache time: 0.023889473173767328 Engine time: 0.09616947546601295 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-16-16/adapters_256_slots_64_rate_1.6-0.8-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-16-16/adapters_256_slots_64_rate_1.6-0.8-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 135, 17280, 17280, 135, 17280, 8640, 17280, 135, 8640, 135, 17280, 8640, 8640, 8640, 8640, 17280, 135, 135, 135, 8640, 17280, 135, 17280, 17280, 8640, 8640, 8640, 135, 17280, 135, 8640, 8640, 135, 8640, 135, 135, 8640, 8640, 17280, 8640, 135, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 135, 17280, 17280, 8640, 135, 135, 17280, 8640, 135, 8640, 8640, 17280, 8640, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 8640, 135, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 135, 17280, 17280, 135, 17280, 135, 8640, 17280, 17280, 17280, 8640, 135, 17280, 8640, 135, 135, 135, 135, 135, 17280, 8640, 135, 17280, 135, 17280, 135, 135, 8640, 8640, 17280, 8640, 17280, 135, 8640, 135, 17280, 17280, 135, 17280, 8640, 135, 17280, 135, 135, 17280, 17280, 8640, 17280, 17280, 135, 17280, 8640, 8640, 135, 8640, 17280, 17280, 135, 17280, 8640, 135, 8640, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 8640, 17280, 17280, 8640, 135, 17280, 135, 8640, 8640, 135, 8640, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 8640, 17280, 8640, 135, 8640, 17280, 8640, 17280, 135, 17280, 135, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 135, 17280, 135, 17280, 8640, 8640, 135, 8640, 17280, 8640, 8640, 17280, 135, 17280, 17280, 8640, 135, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 135, 17280, 8640, 17280, 17280, 135, 17280, 8640, 8640, 17280, 135, 8640, 135, 135, 135, 135, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 135, 135, 135, 135]
Prompts retrieved: 2231955 . Total input tokens: 497616808 . Total output tokens: 446425470
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 112.20255725923926,
    "estimated_duration": 3600.159486022623,
    "input_throughput": 6271.044682229428,
    "output_throughput": 5520.100450315194,
    "total_throughput": 11791.145132544623,
    "itl": 153.280723349063,
    "ttft": 2003370.581367722,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 515,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6105628919647939,
    "arrivals": 743226,
    "finished_requests": 91347,
    "scheduler_time": 162.19258977501306
}
#Debug simulation 
Total elapsed time: 112.20273428224027. Arrivals time: 0.8617264614440501 Scheduler time: 111.09785042051226 Scheduler overhead time: 0.09741734573617578 Adapter cache time: 0.023955087643116713 Engine time: 0.09339265432208776 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-16-32/adapters_256_slots_64_rate_1.6-0.8-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-16-32/adapters_256_slots_64_rate_1.6-0.8-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 135, 17280, 17280, 135, 17280, 8640, 17280, 135, 8640, 135, 17280, 8640, 8640, 8640, 8640, 17280, 135, 135, 135, 8640, 17280, 135, 17280, 17280, 8640, 8640, 8640, 135, 17280, 135, 8640, 8640, 135, 8640, 135, 135, 8640, 8640, 17280, 8640, 135, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 135, 17280, 17280, 8640, 135, 135, 17280, 8640, 135, 8640, 8640, 17280, 8640, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 8640, 135, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 135, 17280, 17280, 135, 17280, 135, 8640, 17280, 17280, 17280, 8640, 135, 17280, 8640, 135, 135, 135, 135, 135, 17280, 8640, 135, 17280, 135, 17280, 135, 135, 8640, 8640, 17280, 8640, 17280, 135, 8640, 135, 17280, 17280, 135, 17280, 8640, 135, 17280, 135, 135, 17280, 17280, 8640, 17280, 17280, 135, 17280, 8640, 8640, 135, 8640, 17280, 17280, 135, 17280, 8640, 135, 8640, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 8640, 17280, 17280, 8640, 135, 17280, 135, 8640, 8640, 135, 8640, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 8640, 17280, 8640, 135, 8640, 17280, 8640, 17280, 135, 17280, 135, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 135, 17280, 135, 17280, 8640, 8640, 135, 8640, 17280, 8640, 8640, 17280, 135, 17280, 17280, 8640, 135, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 135, 17280, 8640, 17280, 17280, 135, 17280, 8640, 8640, 17280, 135, 8640, 135, 135, 135, 135, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 135, 135, 135, 135]
Prompts retrieved: 2231955 . Total input tokens: 497616808 . Total output tokens: 446425470
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 110.02797615202144,
    "estimated_duration": 3600.1671122571206,
    "input_throughput": 6268.143754541451,
    "output_throughput": 5518.301340057665,
    "total_throughput": 11786.445094599116,
    "itl": 153.29929575420948,
    "ttft": 2003175.9354212654,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 516,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7092360116168894,
    "arrivals": 743226,
    "finished_requests": 91305,
    "scheduler_time": 162.1784883720675
}
#Debug simulation 
Total elapsed time: 110.02813174109906. Arrivals time: 0.7628550427034497 Scheduler time: 109.02922510635108 Scheduler overhead time: 0.09414798300713301 Adapter cache time: 0.024090726394206285 Engine time: 0.09030329901725054 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_16-16-16/adapters_256_slots_64_rate_1.6-0.8-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_16-16-16/adapters_256_slots_64_rate_1.6-0.8-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 135, 17280, 17280, 135, 17280, 8640, 17280, 135, 8640, 135, 17280, 8640, 8640, 8640, 8640, 17280, 135, 135, 135, 8640, 17280, 135, 17280, 17280, 8640, 8640, 8640, 135, 17280, 135, 8640, 8640, 135, 8640, 135, 135, 8640, 8640, 17280, 8640, 135, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 135, 17280, 17280, 8640, 135, 135, 17280, 8640, 135, 8640, 8640, 17280, 8640, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 8640, 135, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 135, 17280, 17280, 135, 17280, 135, 8640, 17280, 17280, 17280, 8640, 135, 17280, 8640, 135, 135, 135, 135, 135, 17280, 8640, 135, 17280, 135, 17280, 135, 135, 8640, 8640, 17280, 8640, 17280, 135, 8640, 135, 17280, 17280, 135, 17280, 8640, 135, 17280, 135, 135, 17280, 17280, 8640, 17280, 17280, 135, 17280, 8640, 8640, 135, 8640, 17280, 17280, 135, 17280, 8640, 135, 8640, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 8640, 17280, 17280, 8640, 135, 17280, 135, 8640, 8640, 135, 8640, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 8640, 17280, 8640, 135, 8640, 17280, 8640, 17280, 135, 17280, 135, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 135, 17280, 135, 17280, 8640, 8640, 135, 8640, 17280, 8640, 8640, 17280, 135, 17280, 17280, 8640, 135, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 135, 17280, 8640, 17280, 17280, 135, 17280, 8640, 8640, 17280, 135, 8640, 135, 135, 135, 135, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 135, 135, 135, 135]
Prompts retrieved: 2231955 . Total input tokens: 497616808 . Total output tokens: 446425470
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 110.0699004153721,
    "estimated_duration": 3600.0359690974215,
    "input_throughput": 6268.372092309316,
    "output_throughput": 5518.502362347474,
    "total_throughput": 11786.87445465679,
    "itl": 153.292357024452,
    "ttft": 2003137.520047696,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 516,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5428659521695047,
    "arrivals": 743226,
    "finished_requests": 91305,
    "scheduler_time": 162.179843887491
}
#Debug simulation 
Total elapsed time: 110.07006657822058. Arrivals time: 0.8124277596361935 Scheduler time: 109.01933395350352 Scheduler overhead time: 0.09483919478952885 Adapter cache time: 0.024031296838074923 Engine time: 0.09199160104617476 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_16-16-32/adapters_256_slots_64_rate_1.6-0.8-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_16-16-32/adapters_256_slots_64_rate_1.6-0.8-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 135, 17280, 17280, 135, 17280, 8640, 17280, 135, 8640, 135, 17280, 8640, 8640, 8640, 8640, 17280, 135, 135, 135, 8640, 17280, 135, 17280, 17280, 8640, 8640, 8640, 135, 17280, 135, 8640, 8640, 135, 8640, 135, 135, 8640, 8640, 17280, 8640, 135, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 135, 17280, 17280, 8640, 135, 135, 17280, 8640, 135, 8640, 8640, 17280, 8640, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 8640, 135, 8640, 135, 135, 135, 8640, 8640, 8640, 135, 135, 17280, 17280, 135, 17280, 135, 8640, 17280, 17280, 17280, 8640, 135, 17280, 8640, 135, 135, 135, 135, 135, 17280, 8640, 135, 17280, 135, 17280, 135, 135, 8640, 8640, 17280, 8640, 17280, 135, 8640, 135, 17280, 17280, 135, 17280, 8640, 135, 17280, 135, 135, 17280, 17280, 8640, 17280, 17280, 135, 17280, 8640, 8640, 135, 8640, 17280, 17280, 135, 17280, 8640, 135, 8640, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 8640, 17280, 17280, 8640, 135, 17280, 135, 8640, 8640, 135, 8640, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 8640, 17280, 8640, 135, 8640, 17280, 8640, 17280, 135, 17280, 135, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 135, 17280, 135, 17280, 8640, 8640, 135, 8640, 17280, 8640, 8640, 17280, 135, 17280, 17280, 8640, 135, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 135, 17280, 8640, 17280, 17280, 135, 17280, 8640, 8640, 17280, 135, 8640, 135, 135, 135, 135, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 135, 135, 135, 135]
Prompts retrieved: 2231955 . Total input tokens: 497616808 . Total output tokens: 446425470
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 112.95985843800008,
    "estimated_duration": 3600.011196776563,
    "input_throughput": 6267.8424501023765,
    "output_throughput": 5518.290059149777,
    "total_throughput": 11786.132509252153,
    "itl": 153.30030606971764,
    "ttft": 2003132.7233583468,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 516,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.731117170453069,
    "arrivals": 743226,
    "finished_requests": 91298,
    "scheduler_time": 162.17068916368345
}
#Debug simulation 
Total elapsed time: 112.96004132321104. Arrivals time: 0.7597480467520654 Scheduler time: 111.95119504397735 Scheduler overhead time: 0.09877329459413886 Adapter cache time: 0.024436749517917633 Engine time: 0.09733748156577349 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-8/adapters_256_slots_64_rate_1.6-0.8-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-8/adapters_256_slots_64_rate_1.6-0.8-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 66, 17280, 17280, 66, 17280, 8640, 17280, 66, 8640, 66, 17280, 8640, 8640, 8640, 8640, 17280, 66, 66, 66, 8640, 17280, 66, 17280, 17280, 8640, 8640, 8640, 66, 17280, 66, 8640, 8640, 66, 8640, 66, 66, 8640, 8640, 17280, 8640, 66, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 66, 17280, 17280, 8640, 66, 66, 17280, 8640, 66, 8640, 8640, 17280, 8640, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 8640, 66, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 66, 17280, 17280, 66, 17280, 66, 8640, 17280, 17280, 17280, 8640, 66, 17280, 8640, 66, 66, 66, 66, 66, 17280, 8640, 66, 17280, 66, 17280, 66, 66, 8640, 8640, 17280, 8640, 17280, 66, 8640, 66, 17280, 17280, 66, 17280, 8640, 66, 17280, 66, 66, 17280, 17280, 8640, 17280, 17280, 66, 17280, 8640, 8640, 66, 8640, 17280, 17280, 66, 17280, 8640, 66, 8640, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 8640, 17280, 17280, 8640, 66, 17280, 66, 8640, 8640, 66, 8640, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 8640, 17280, 8640, 66, 8640, 17280, 8640, 17280, 66, 17280, 66, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 66, 17280, 66, 17280, 8640, 8640, 66, 8640, 17280, 8640, 8640, 17280, 66, 17280, 17280, 8640, 66, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 66, 17280, 8640, 17280, 17280, 66, 17280, 8640, 8640, 17280, 66, 8640, 66, 66, 66, 66, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 66, 66, 66, 66]
Prompts retrieved: 2226090 . Total input tokens: 496312659 . Total output tokens: 445233650
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 114.37235759431496,
    "estimated_duration": 3600.111959588533,
    "input_throughput": 6245.721592105682,
    "output_throughput": 5525.493713332615,
    "total_throughput": 11771.215305438298,
    "itl": 153.95331632289674,
    "ttft": 2003923.4704250863,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 413,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2639814382442351,
    "arrivals": 741292,
    "finished_requests": 90798,
    "scheduler_time": 161.9499764460689
}
#Debug simulation 
Total elapsed time: 114.37255864124745. Arrivals time: 0.7832475998438895 Scheduler time: 113.35108734713867 Scheduler overhead time: 0.09482772555202246 Adapter cache time: 0.022408429998904467 Engine time: 0.09286754531785846 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-16/adapters_256_slots_64_rate_1.6-0.8-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-16/adapters_256_slots_64_rate_1.6-0.8-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 66, 17280, 17280, 66, 17280, 8640, 17280, 66, 8640, 66, 17280, 8640, 8640, 8640, 8640, 17280, 66, 66, 66, 8640, 17280, 66, 17280, 17280, 8640, 8640, 8640, 66, 17280, 66, 8640, 8640, 66, 8640, 66, 66, 8640, 8640, 17280, 8640, 66, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 66, 17280, 17280, 8640, 66, 66, 17280, 8640, 66, 8640, 8640, 17280, 8640, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 8640, 66, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 66, 17280, 17280, 66, 17280, 66, 8640, 17280, 17280, 17280, 8640, 66, 17280, 8640, 66, 66, 66, 66, 66, 17280, 8640, 66, 17280, 66, 17280, 66, 66, 8640, 8640, 17280, 8640, 17280, 66, 8640, 66, 17280, 17280, 66, 17280, 8640, 66, 17280, 66, 66, 17280, 17280, 8640, 17280, 17280, 66, 17280, 8640, 8640, 66, 8640, 17280, 17280, 66, 17280, 8640, 66, 8640, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 8640, 17280, 17280, 8640, 66, 17280, 66, 8640, 8640, 66, 8640, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 8640, 17280, 8640, 66, 8640, 17280, 8640, 17280, 66, 17280, 66, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 66, 17280, 66, 17280, 8640, 8640, 66, 8640, 17280, 8640, 8640, 17280, 66, 17280, 17280, 8640, 66, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 66, 17280, 8640, 17280, 17280, 66, 17280, 8640, 8640, 17280, 66, 8640, 66, 66, 66, 66, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 66, 66, 66, 66]
Prompts retrieved: 2226090 . Total input tokens: 496312659 . Total output tokens: 445233650
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 114.7067599161528,
    "estimated_duration": 3600.066695205232,
    "input_throughput": 6270.312444506846,
    "output_throughput": 5545.70475780084,
    "total_throughput": 11816.017202307685,
    "itl": 153.5963354161565,
    "ttft": 2005575.426605673,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 420,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3665504551562524,
    "arrivals": 741292,
    "finished_requests": 91154,
    "scheduler_time": 162.2363551610452
}
#Debug simulation 
Total elapsed time: 114.70694763818756. Arrivals time: 0.8177359662950039 Scheduler time: 113.64688310353085 Scheduler overhead time: 0.09777784394100308 Adapter cache time: 0.022953373845666647 Engine time: 0.09375948319211602 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-32/adapters_256_slots_64_rate_1.6-0.8-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-32/adapters_256_slots_64_rate_1.6-0.8-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 66, 17280, 17280, 66, 17280, 8640, 17280, 66, 8640, 66, 17280, 8640, 8640, 8640, 8640, 17280, 66, 66, 66, 8640, 17280, 66, 17280, 17280, 8640, 8640, 8640, 66, 17280, 66, 8640, 8640, 66, 8640, 66, 66, 8640, 8640, 17280, 8640, 66, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 66, 17280, 17280, 8640, 66, 66, 17280, 8640, 66, 8640, 8640, 17280, 8640, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 8640, 66, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 66, 17280, 17280, 66, 17280, 66, 8640, 17280, 17280, 17280, 8640, 66, 17280, 8640, 66, 66, 66, 66, 66, 17280, 8640, 66, 17280, 66, 17280, 66, 66, 8640, 8640, 17280, 8640, 17280, 66, 8640, 66, 17280, 17280, 66, 17280, 8640, 66, 17280, 66, 66, 17280, 17280, 8640, 17280, 17280, 66, 17280, 8640, 8640, 66, 8640, 17280, 17280, 66, 17280, 8640, 66, 8640, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 8640, 17280, 17280, 8640, 66, 17280, 66, 8640, 8640, 66, 8640, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 8640, 17280, 8640, 66, 8640, 17280, 8640, 17280, 66, 17280, 66, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 66, 17280, 66, 17280, 8640, 8640, 66, 8640, 17280, 8640, 8640, 17280, 66, 17280, 17280, 8640, 66, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 66, 17280, 8640, 17280, 17280, 66, 17280, 8640, 8640, 17280, 66, 8640, 66, 66, 66, 66, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 66, 66, 66, 66]
Prompts retrieved: 2226090 . Total input tokens: 496312659 . Total output tokens: 445233650
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 114.25740631995723,
    "estimated_duration": 3600.070553174408,
    "input_throughput": 6270.305725007387,
    "output_throughput": 5545.6988148178625,
    "total_throughput": 11816.00453982525,
    "itl": 153.5964604433405,
    "ttft": 2005576.9814774317,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 420,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3696719875000496,
    "arrivals": 741292,
    "finished_requests": 91154,
    "scheduler_time": 162.23639540819744
}
#Debug simulation 
Total elapsed time: 114.25760226510465. Arrivals time: 0.8543404187075794 Scheduler time: 113.16240736702457 Scheduler overhead time: 0.09619306586682796 Adapter cache time: 0.023660496342927217 Engine time: 0.0934842643328011 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-16-16/adapters_256_slots_64_rate_1.6-0.8-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-16-16/adapters_256_slots_64_rate_1.6-0.8-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 66, 17280, 17280, 66, 17280, 8640, 17280, 66, 8640, 66, 17280, 8640, 8640, 8640, 8640, 17280, 66, 66, 66, 8640, 17280, 66, 17280, 17280, 8640, 8640, 8640, 66, 17280, 66, 8640, 8640, 66, 8640, 66, 66, 8640, 8640, 17280, 8640, 66, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 66, 17280, 17280, 8640, 66, 66, 17280, 8640, 66, 8640, 8640, 17280, 8640, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 8640, 66, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 66, 17280, 17280, 66, 17280, 66, 8640, 17280, 17280, 17280, 8640, 66, 17280, 8640, 66, 66, 66, 66, 66, 17280, 8640, 66, 17280, 66, 17280, 66, 66, 8640, 8640, 17280, 8640, 17280, 66, 8640, 66, 17280, 17280, 66, 17280, 8640, 66, 17280, 66, 66, 17280, 17280, 8640, 17280, 17280, 66, 17280, 8640, 8640, 66, 8640, 17280, 17280, 66, 17280, 8640, 66, 8640, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 8640, 17280, 17280, 8640, 66, 17280, 66, 8640, 8640, 66, 8640, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 8640, 17280, 8640, 66, 8640, 17280, 8640, 17280, 66, 17280, 66, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 66, 17280, 66, 17280, 8640, 8640, 66, 8640, 17280, 8640, 8640, 17280, 66, 17280, 17280, 8640, 66, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 66, 17280, 8640, 17280, 17280, 66, 17280, 8640, 8640, 17280, 66, 8640, 66, 66, 66, 66, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 66, 66, 66, 66]
Prompts retrieved: 2226090 . Total input tokens: 496312659 . Total output tokens: 445233650
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 113.86310509964824,
    "estimated_duration": 3600.0214196303655,
    "input_throughput": 6277.665704089183,
    "output_throughput": 5553.836121911989,
    "total_throughput": 11831.501826001171,
    "itl": 153.32330755407784,
    "ttft": 2006323.3042192888,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 417,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3020113409636518,
    "arrivals": 741292,
    "finished_requests": 91285,
    "scheduler_time": 162.57451071848206
}
#Debug simulation 
Total elapsed time: 113.8633748809807. Arrivals time: 0.7836083988659084 Scheduler time: 112.83366545056924 Scheduler overhead time: 0.09772507147863507 Adapter cache time: 0.023674029391258955 Engine time: 0.09637233195826411 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-16-32/adapters_256_slots_64_rate_1.6-0.8-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-16-32/adapters_256_slots_64_rate_1.6-0.8-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 66, 17280, 17280, 66, 17280, 8640, 17280, 66, 8640, 66, 17280, 8640, 8640, 8640, 8640, 17280, 66, 66, 66, 8640, 17280, 66, 17280, 17280, 8640, 8640, 8640, 66, 17280, 66, 8640, 8640, 66, 8640, 66, 66, 8640, 8640, 17280, 8640, 66, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 66, 17280, 17280, 8640, 66, 66, 17280, 8640, 66, 8640, 8640, 17280, 8640, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 8640, 66, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 66, 17280, 17280, 66, 17280, 66, 8640, 17280, 17280, 17280, 8640, 66, 17280, 8640, 66, 66, 66, 66, 66, 17280, 8640, 66, 17280, 66, 17280, 66, 66, 8640, 8640, 17280, 8640, 17280, 66, 8640, 66, 17280, 17280, 66, 17280, 8640, 66, 17280, 66, 66, 17280, 17280, 8640, 17280, 17280, 66, 17280, 8640, 8640, 66, 8640, 17280, 17280, 66, 17280, 8640, 66, 8640, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 8640, 17280, 17280, 8640, 66, 17280, 66, 8640, 8640, 66, 8640, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 8640, 17280, 8640, 66, 8640, 17280, 8640, 17280, 66, 17280, 66, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 66, 17280, 66, 17280, 8640, 8640, 66, 8640, 17280, 8640, 8640, 17280, 66, 17280, 17280, 8640, 66, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 66, 17280, 8640, 17280, 17280, 66, 17280, 8640, 8640, 17280, 66, 8640, 66, 66, 66, 66, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 66, 66, 66, 66]
Prompts retrieved: 2226090 . Total input tokens: 496312659 . Total output tokens: 445233650
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 114.34658155404031,
    "estimated_duration": 3600.0880462128625,
    "input_throughput": 6270.389976641496,
    "output_throughput": 5545.691311911745,
    "total_throughput": 11816.081288553241,
    "itl": 153.59721768008558,
    "ttft": 2005579.197244677,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 420,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3863972410932237,
    "arrivals": 741292,
    "finished_requests": 91155,
    "scheduler_time": 162.2367627506777
}
#Debug simulation 
Total elapsed time: 114.34680424816906. Arrivals time: 0.8050453457981348 Scheduler time: 113.29899689462036 Scheduler overhead time: 0.09644375601783395 Adapter cache time: 0.02347826398909092 Engine time: 0.09320087265223265 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_16-16-16/adapters_256_slots_64_rate_1.6-0.8-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_16-16-16/adapters_256_slots_64_rate_1.6-0.8-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 66, 17280, 17280, 66, 17280, 8640, 17280, 66, 8640, 66, 17280, 8640, 8640, 8640, 8640, 17280, 66, 66, 66, 8640, 17280, 66, 17280, 17280, 8640, 8640, 8640, 66, 17280, 66, 8640, 8640, 66, 8640, 66, 66, 8640, 8640, 17280, 8640, 66, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 66, 17280, 17280, 8640, 66, 66, 17280, 8640, 66, 8640, 8640, 17280, 8640, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 8640, 66, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 66, 17280, 17280, 66, 17280, 66, 8640, 17280, 17280, 17280, 8640, 66, 17280, 8640, 66, 66, 66, 66, 66, 17280, 8640, 66, 17280, 66, 17280, 66, 66, 8640, 8640, 17280, 8640, 17280, 66, 8640, 66, 17280, 17280, 66, 17280, 8640, 66, 17280, 66, 66, 17280, 17280, 8640, 17280, 17280, 66, 17280, 8640, 8640, 66, 8640, 17280, 17280, 66, 17280, 8640, 66, 8640, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 8640, 17280, 17280, 8640, 66, 17280, 66, 8640, 8640, 66, 8640, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 8640, 17280, 8640, 66, 8640, 17280, 8640, 17280, 66, 17280, 66, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 66, 17280, 66, 17280, 8640, 8640, 66, 8640, 17280, 8640, 8640, 17280, 66, 17280, 17280, 8640, 66, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 66, 17280, 8640, 17280, 17280, 66, 17280, 8640, 8640, 17280, 66, 8640, 66, 66, 66, 66, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 66, 66, 66, 66]
Prompts retrieved: 2226090 . Total input tokens: 496312659 . Total output tokens: 445233650
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 115.8688310389407,
    "estimated_duration": 3600.035123493169,
    "input_throughput": 6240.231894793797,
    "output_throughput": 5523.3983330434385,
    "total_throughput": 11763.630227837235,
    "itl": 154.12421555232376,
    "ttft": 2003357.822349156,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 409,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2229305706149833,
    "arrivals": 741292,
    "finished_requests": 90702,
    "scheduler_time": 161.82836070890963
}
#Debug simulation 
Total elapsed time: 115.86899976991117. Arrivals time: 0.796423776075244 Scheduler time: 114.82987219654024 Scheduler overhead time: 0.09710019873455167 Adapter cache time: 0.022455282974988222 Engine time: 0.09439118020236492 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_16-16-32/adapters_256_slots_64_rate_1.6-0.8-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_16-16-32/adapters_256_slots_64_rate_1.6-0.8-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 66, 17280, 17280, 66, 17280, 8640, 17280, 66, 8640, 66, 17280, 8640, 8640, 8640, 8640, 17280, 66, 66, 66, 8640, 17280, 66, 17280, 17280, 8640, 8640, 8640, 66, 17280, 66, 8640, 8640, 66, 8640, 66, 66, 8640, 8640, 17280, 8640, 66, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 66, 17280, 17280, 8640, 66, 66, 17280, 8640, 66, 8640, 8640, 17280, 8640, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 8640, 66, 8640, 66, 66, 66, 8640, 8640, 8640, 66, 66, 17280, 17280, 66, 17280, 66, 8640, 17280, 17280, 17280, 8640, 66, 17280, 8640, 66, 66, 66, 66, 66, 17280, 8640, 66, 17280, 66, 17280, 66, 66, 8640, 8640, 17280, 8640, 17280, 66, 8640, 66, 17280, 17280, 66, 17280, 8640, 66, 17280, 66, 66, 17280, 17280, 8640, 17280, 17280, 66, 17280, 8640, 8640, 66, 8640, 17280, 17280, 66, 17280, 8640, 66, 8640, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 8640, 17280, 17280, 8640, 66, 17280, 66, 8640, 8640, 66, 8640, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 8640, 17280, 8640, 66, 8640, 17280, 8640, 17280, 66, 17280, 66, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 66, 17280, 66, 17280, 8640, 8640, 66, 8640, 17280, 8640, 8640, 17280, 66, 17280, 17280, 8640, 66, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 66, 17280, 8640, 17280, 17280, 66, 17280, 8640, 8640, 17280, 66, 8640, 66, 66, 66, 66, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 66, 66, 66, 66]
Prompts retrieved: 2226090 . Total input tokens: 496312659 . Total output tokens: 445233650
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 115.64354284107685,
    "estimated_duration": 3600.068012650619,
    "input_throughput": 6261.194210996019,
    "output_throughput": 5541.695859604351,
    "total_throughput": 11802.89007060037,
    "itl": 153.8035634267159,
    "ttft": 2004259.0034015444,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 416,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3892621818184876,
    "arrivals": 741292,
    "finished_requests": 91022,
    "scheduler_time": 162.10331095602191
}
#Debug simulation 
Total elapsed time: 115.64372293883935. Arrivals time: 0.8668426261283457 Scheduler time: 114.53075886145234 Scheduler overhead time: 0.09814576525241137 Adapter cache time: 0.024185421876609325 Engine time: 0.0953409573994577 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-8/adapters_256_slots_64_rate_1.6-0.8-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-8/adapters_256_slots_64_rate_1.6-0.8-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 33, 17280, 17280, 33, 17280, 8640, 17280, 33, 8640, 33, 17280, 8640, 8640, 8640, 8640, 17280, 33, 33, 33, 8640, 17280, 33, 17280, 17280, 8640, 8640, 8640, 33, 17280, 33, 8640, 8640, 33, 8640, 33, 33, 8640, 8640, 17280, 8640, 33, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 33, 17280, 17280, 8640, 33, 33, 17280, 8640, 33, 8640, 8640, 17280, 8640, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 8640, 33, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 33, 17280, 17280, 33, 17280, 33, 8640, 17280, 17280, 17280, 8640, 33, 17280, 8640, 33, 33, 33, 33, 33, 17280, 8640, 33, 17280, 33, 17280, 33, 33, 8640, 8640, 17280, 8640, 17280, 33, 8640, 33, 17280, 17280, 33, 17280, 8640, 33, 17280, 33, 33, 17280, 17280, 8640, 17280, 17280, 33, 17280, 8640, 8640, 33, 8640, 17280, 17280, 33, 17280, 8640, 33, 8640, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 8640, 17280, 17280, 8640, 33, 17280, 33, 8640, 8640, 33, 8640, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 8640, 17280, 8640, 33, 8640, 17280, 8640, 17280, 33, 17280, 33, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 33, 17280, 33, 17280, 8640, 8640, 33, 8640, 17280, 8640, 8640, 17280, 33, 17280, 17280, 8640, 33, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 33, 17280, 8640, 17280, 17280, 33, 17280, 8640, 8640, 17280, 33, 8640, 33, 33, 33, 33, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 33, 33, 33, 33]
Prompts retrieved: 2223285 . Total input tokens: 495676136 . Total output tokens: 444666343
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 113.2460576123558,
    "estimated_duration": 3600.0046527837508,
    "input_throughput": 6360.608445962327,
    "output_throughput": 5584.138893947025,
    "total_throughput": 11944.747339909352,
    "itl": 151.45909791184062,
    "ttft": 2000474.4614580446,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 349,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.068110222632532,
    "arrivals": 740358,
    "finished_requests": 92410,
    "scheduler_time": 164.31791905190693
}
#Debug simulation 
Total elapsed time: 113.24623314803466. Arrivals time: 0.8050342123024166 Scheduler time: 112.1987881148234 Scheduler overhead time: 0.09582543093711138 Adapter cache time: 0.02297645201906562 Engine time: 0.09577776119112968 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-16/adapters_256_slots_64_rate_1.6-0.8-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-16/adapters_256_slots_64_rate_1.6-0.8-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 33, 17280, 17280, 33, 17280, 8640, 17280, 33, 8640, 33, 17280, 8640, 8640, 8640, 8640, 17280, 33, 33, 33, 8640, 17280, 33, 17280, 17280, 8640, 8640, 8640, 33, 17280, 33, 8640, 8640, 33, 8640, 33, 33, 8640, 8640, 17280, 8640, 33, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 33, 17280, 17280, 8640, 33, 33, 17280, 8640, 33, 8640, 8640, 17280, 8640, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 8640, 33, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 33, 17280, 17280, 33, 17280, 33, 8640, 17280, 17280, 17280, 8640, 33, 17280, 8640, 33, 33, 33, 33, 33, 17280, 8640, 33, 17280, 33, 17280, 33, 33, 8640, 8640, 17280, 8640, 17280, 33, 8640, 33, 17280, 17280, 33, 17280, 8640, 33, 17280, 33, 33, 17280, 17280, 8640, 17280, 17280, 33, 17280, 8640, 8640, 33, 8640, 17280, 17280, 33, 17280, 8640, 33, 8640, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 8640, 17280, 17280, 8640, 33, 17280, 33, 8640, 8640, 33, 8640, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 8640, 17280, 8640, 33, 8640, 17280, 8640, 17280, 33, 17280, 33, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 33, 17280, 33, 17280, 8640, 8640, 33, 8640, 17280, 8640, 8640, 17280, 33, 17280, 17280, 8640, 33, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 33, 17280, 8640, 17280, 17280, 33, 17280, 8640, 8640, 17280, 33, 8640, 33, 33, 33, 33, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 33, 33, 33, 33]
Prompts retrieved: 2223285 . Total input tokens: 495676136 . Total output tokens: 444666343
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 112.18908174801618,
    "estimated_duration": 3600.1203111415452,
    "input_throughput": 6349.421137193009,
    "output_throughput": 5569.6066428519,
    "total_throughput": 11919.02778004491,
    "itl": 151.63631170388746,
    "ttft": 2000537.0114245997,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 337,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1024410632602002,
    "arrivals": 740358,
    "finished_requests": 92293,
    "scheduler_time": 163.96385843466246
}
#Debug simulation 
Total elapsed time: 112.18928611790761. Arrivals time: 1.16046590404585 Scheduler time: 110.78619702532887 Scheduler overhead time: 0.09582109050825238 Adapter cache time: 0.023207122460007668 Engine time: 0.09452302334830165 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-32/adapters_256_slots_64_rate_1.6-0.8-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-32/adapters_256_slots_64_rate_1.6-0.8-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 33, 17280, 17280, 33, 17280, 8640, 17280, 33, 8640, 33, 17280, 8640, 8640, 8640, 8640, 17280, 33, 33, 33, 8640, 17280, 33, 17280, 17280, 8640, 8640, 8640, 33, 17280, 33, 8640, 8640, 33, 8640, 33, 33, 8640, 8640, 17280, 8640, 33, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 33, 17280, 17280, 8640, 33, 33, 17280, 8640, 33, 8640, 8640, 17280, 8640, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 8640, 33, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 33, 17280, 17280, 33, 17280, 33, 8640, 17280, 17280, 17280, 8640, 33, 17280, 8640, 33, 33, 33, 33, 33, 17280, 8640, 33, 17280, 33, 17280, 33, 33, 8640, 8640, 17280, 8640, 17280, 33, 8640, 33, 17280, 17280, 33, 17280, 8640, 33, 17280, 33, 33, 17280, 17280, 8640, 17280, 17280, 33, 17280, 8640, 8640, 33, 8640, 17280, 17280, 33, 17280, 8640, 33, 8640, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 8640, 17280, 17280, 8640, 33, 17280, 33, 8640, 8640, 33, 8640, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 8640, 17280, 8640, 33, 8640, 17280, 8640, 17280, 33, 17280, 33, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 33, 17280, 33, 17280, 8640, 8640, 33, 8640, 17280, 8640, 8640, 17280, 33, 17280, 17280, 8640, 33, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 33, 17280, 8640, 17280, 17280, 33, 17280, 8640, 8640, 17280, 33, 8640, 33, 33, 33, 33, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 33, 33, 33, 33]
Prompts retrieved: 2223285 . Total input tokens: 495676136 . Total output tokens: 444666343
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 114.48206970840693,
    "estimated_duration": 3600.1217884018192,
    "input_throughput": 6349.4185317957035,
    "output_throughput": 5569.604357440706,
    "total_throughput": 11919.022889236408,
    "itl": 151.63636594992758,
    "ttft": 2000537.8295870859,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 337,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1039072707668007,
    "arrivals": 740358,
    "finished_requests": 92293,
    "scheduler_time": 163.9638694874203
}
#Debug simulation 
Total elapsed time: 114.48225400503725. Arrivals time: 0.808998323045671 Scheduler time: 113.43146276194602 Scheduler overhead time: 0.09588864911347628 Adapter cache time: 0.02292965305969119 Engine time: 0.09416690142825246 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-16-16/adapters_256_slots_64_rate_1.6-0.8-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-16-16/adapters_256_slots_64_rate_1.6-0.8-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 33, 17280, 17280, 33, 17280, 8640, 17280, 33, 8640, 33, 17280, 8640, 8640, 8640, 8640, 17280, 33, 33, 33, 8640, 17280, 33, 17280, 17280, 8640, 8640, 8640, 33, 17280, 33, 8640, 8640, 33, 8640, 33, 33, 8640, 8640, 17280, 8640, 33, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 33, 17280, 17280, 8640, 33, 33, 17280, 8640, 33, 8640, 8640, 17280, 8640, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 8640, 33, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 33, 17280, 17280, 33, 17280, 33, 8640, 17280, 17280, 17280, 8640, 33, 17280, 8640, 33, 33, 33, 33, 33, 17280, 8640, 33, 17280, 33, 17280, 33, 33, 8640, 8640, 17280, 8640, 17280, 33, 8640, 33, 17280, 17280, 33, 17280, 8640, 33, 17280, 33, 33, 17280, 17280, 8640, 17280, 17280, 33, 17280, 8640, 8640, 33, 8640, 17280, 17280, 33, 17280, 8640, 33, 8640, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 8640, 17280, 17280, 8640, 33, 17280, 33, 8640, 8640, 33, 8640, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 8640, 17280, 8640, 33, 8640, 17280, 8640, 17280, 33, 17280, 33, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 33, 17280, 33, 17280, 8640, 8640, 33, 8640, 17280, 8640, 8640, 17280, 33, 17280, 17280, 8640, 33, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 33, 17280, 8640, 17280, 17280, 33, 17280, 8640, 8640, 17280, 33, 8640, 33, 33, 33, 33, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 33, 33, 33, 33]
Prompts retrieved: 2223285 . Total input tokens: 495676136 . Total output tokens: 444666343
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 109.1853316151537,
    "estimated_duration": 3600.0320064732036,
    "input_throughput": 6360.560116917516,
    "output_throughput": 5584.09646465726,
    "total_throughput": 11944.656581574776,
    "itl": 151.4597169414815,
    "ttft": 2000486.2856006739,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 349,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0946019677259053,
    "arrivals": 740358,
    "finished_requests": 92410,
    "scheduler_time": 164.31822404450713
}
#Debug simulation 
Total elapsed time: 109.18551359279081. Arrivals time: 0.8168488219380379 Scheduler time: 108.12958280788735 Scheduler overhead time: 0.0950813265517354 Adapter cache time: 0.02344452915713191 Engine time: 0.09254888026043773 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-16-32/adapters_256_slots_64_rate_1.6-0.8-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-16-32/adapters_256_slots_64_rate_1.6-0.8-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 33, 17280, 17280, 33, 17280, 8640, 17280, 33, 8640, 33, 17280, 8640, 8640, 8640, 8640, 17280, 33, 33, 33, 8640, 17280, 33, 17280, 17280, 8640, 8640, 8640, 33, 17280, 33, 8640, 8640, 33, 8640, 33, 33, 8640, 8640, 17280, 8640, 33, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 33, 17280, 17280, 8640, 33, 33, 17280, 8640, 33, 8640, 8640, 17280, 8640, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 8640, 33, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 33, 17280, 17280, 33, 17280, 33, 8640, 17280, 17280, 17280, 8640, 33, 17280, 8640, 33, 33, 33, 33, 33, 17280, 8640, 33, 17280, 33, 17280, 33, 33, 8640, 8640, 17280, 8640, 17280, 33, 8640, 33, 17280, 17280, 33, 17280, 8640, 33, 17280, 33, 33, 17280, 17280, 8640, 17280, 17280, 33, 17280, 8640, 8640, 33, 8640, 17280, 17280, 33, 17280, 8640, 33, 8640, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 8640, 17280, 17280, 8640, 33, 17280, 33, 8640, 8640, 33, 8640, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 8640, 17280, 8640, 33, 8640, 17280, 8640, 17280, 33, 17280, 33, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 33, 17280, 33, 17280, 8640, 8640, 33, 8640, 17280, 8640, 8640, 17280, 33, 17280, 17280, 8640, 33, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 33, 17280, 8640, 17280, 17280, 33, 17280, 8640, 8640, 17280, 33, 8640, 33, 33, 33, 33, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 33, 33, 33, 33]
Prompts retrieved: 2223285 . Total input tokens: 495676136 . Total output tokens: 444666343
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 113.57312435889617,
    "estimated_duration": 3600.0153871304483,
    "input_throughput": 6351.619240779496,
    "output_throughput": 5569.9250818989385,
    "total_throughput": 11921.544322678434,
    "itl": 151.62584967218422,
    "ttft": 2000502.8696082379,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 336,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1157884386368144,
    "arrivals": 740358,
    "finished_requests": 92279,
    "scheduler_time": 163.97244027572486
}
#Debug simulation 
Total elapsed time: 113.57341764075682. Arrivals time: 0.7890357123687863 Scheduler time: 112.52906914893538 Scheduler overhead time: 0.10228504473343492 Adapter cache time: 0.02281735185533762 Engine time: 0.09956181142479181 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_16-16-16/adapters_256_slots_64_rate_1.6-0.8-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_16-16-16/adapters_256_slots_64_rate_1.6-0.8-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 33, 17280, 17280, 33, 17280, 8640, 17280, 33, 8640, 33, 17280, 8640, 8640, 8640, 8640, 17280, 33, 33, 33, 8640, 17280, 33, 17280, 17280, 8640, 8640, 8640, 33, 17280, 33, 8640, 8640, 33, 8640, 33, 33, 8640, 8640, 17280, 8640, 33, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 33, 17280, 17280, 8640, 33, 33, 17280, 8640, 33, 8640, 8640, 17280, 8640, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 8640, 33, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 33, 17280, 17280, 33, 17280, 33, 8640, 17280, 17280, 17280, 8640, 33, 17280, 8640, 33, 33, 33, 33, 33, 17280, 8640, 33, 17280, 33, 17280, 33, 33, 8640, 8640, 17280, 8640, 17280, 33, 8640, 33, 17280, 17280, 33, 17280, 8640, 33, 17280, 33, 33, 17280, 17280, 8640, 17280, 17280, 33, 17280, 8640, 8640, 33, 8640, 17280, 17280, 33, 17280, 8640, 33, 8640, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 8640, 17280, 17280, 8640, 33, 17280, 33, 8640, 8640, 33, 8640, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 8640, 17280, 8640, 33, 8640, 17280, 8640, 17280, 33, 17280, 33, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 33, 17280, 33, 17280, 8640, 8640, 33, 8640, 17280, 8640, 8640, 17280, 33, 17280, 17280, 8640, 33, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 33, 17280, 8640, 17280, 17280, 33, 17280, 8640, 8640, 17280, 33, 8640, 33, 33, 33, 33, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 33, 33, 33, 33]
Prompts retrieved: 2223285 . Total input tokens: 495676136 . Total output tokens: 444666343
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 110.61387366522104,
    "estimated_duration": 3600.1583602830992,
    "input_throughput": 6360.95629921102,
    "output_throughput": 5584.233521999601,
    "total_throughput": 11945.189821210623,
    "itl": 151.45945536182427,
    "ttft": 2000486.8407341177,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 349,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0435275529208592,
    "arrivals": 740358,
    "finished_requests": 92414,
    "scheduler_time": 164.32551430584772
}
#Debug simulation 
Total elapsed time: 110.61404192587361. Arrivals time: 0.7825566995888948 Scheduler time: 109.5910979481414 Scheduler overhead time: 0.09486810164526105 Adapter cache time: 0.022461815271526575 Engine time: 0.09465817548334599 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_16-16-32/adapters_256_slots_64_rate_1.6-0.8-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_16-16-32/adapters_256_slots_64_rate_1.6-0.8-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [85 85 86]
Adapter prompts. [8640, 8640, 17280, 33, 17280, 17280, 33, 17280, 8640, 17280, 33, 8640, 33, 17280, 8640, 8640, 8640, 8640, 17280, 33, 33, 33, 8640, 17280, 33, 17280, 17280, 8640, 8640, 8640, 33, 17280, 33, 8640, 8640, 33, 8640, 33, 33, 8640, 8640, 17280, 8640, 33, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 33, 17280, 17280, 8640, 33, 33, 17280, 8640, 33, 8640, 8640, 17280, 8640, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 8640, 33, 8640, 33, 33, 33, 8640, 8640, 8640, 33, 33, 17280, 17280, 33, 17280, 33, 8640, 17280, 17280, 17280, 8640, 33, 17280, 8640, 33, 33, 33, 33, 33, 17280, 8640, 33, 17280, 33, 17280, 33, 33, 8640, 8640, 17280, 8640, 17280, 33, 8640, 33, 17280, 17280, 33, 17280, 8640, 33, 17280, 33, 33, 17280, 17280, 8640, 17280, 17280, 33, 17280, 8640, 8640, 33, 8640, 17280, 17280, 33, 17280, 8640, 33, 8640, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 8640, 17280, 17280, 8640, 33, 17280, 33, 8640, 8640, 33, 8640, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 8640, 17280, 8640, 33, 8640, 17280, 8640, 17280, 33, 17280, 33, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 33, 17280, 33, 17280, 8640, 8640, 33, 8640, 17280, 8640, 8640, 17280, 33, 17280, 17280, 8640, 33, 17280, 17280, 8640, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 17280, 33, 17280, 8640, 17280, 17280, 33, 17280, 8640, 8640, 17280, 33, 8640, 33, 33, 33, 33, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 33, 33, 33, 33]
Prompts retrieved: 2223285 . Total input tokens: 495676136 . Total output tokens: 444666343
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 113.70126331690699,
    "estimated_duration": 3600.0325657496523,
    "input_throughput": 6351.588932151372,
    "output_throughput": 5569.898503355486,
    "total_throughput": 11921.487435506859,
    "itl": 151.62666113547365,
    "ttft": 2000510.1386596283,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 336,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1305016316473522,
    "arrivals": 740358,
    "finished_requests": 92279,
    "scheduler_time": 163.97302823633854
}
#Debug simulation 
Total elapsed time: 113.70142084592953. Arrivals time: 0.9520930009894073 Scheduler time: 112.50065510207787 Scheduler overhead time: 0.1000970946624875 Adapter cache time: 0.022519401274621487 Engine time: 0.09657656121999025 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-8-8/adapters_256_slots_64_rate_1.6-0.4-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-8-8/adapters_256_slots_64_rate_1.6-0.4-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 1080, 17280, 17280, 1080, 17280, 4320, 17280, 1080, 4320, 1080, 17280, 4320, 4320, 4320, 4320, 17280, 1080, 1080, 1080, 4320, 17280, 1080, 17280, 17280, 4320, 4320, 4320, 1080, 17280, 1080, 4320, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 17280, 4320, 1080, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 1080, 17280, 17280, 4320, 1080, 1080, 17280, 4320, 1080, 4320, 4320, 17280, 4320, 1080, 1080, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 4320, 1080, 4320, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 17280, 17280, 1080, 17280, 1080, 4320, 17280, 17280, 17280, 4320, 1080, 17280, 4320, 1080, 1080, 1080, 1080, 1080, 17280, 4320, 1080, 17280, 1080, 17280, 1080, 1080, 4320, 4320, 17280, 4320, 17280, 1080, 4320, 1080, 17280, 17280, 1080, 17280, 4320, 1080, 17280, 1080, 1080, 17280, 17280, 4320, 17280, 17280, 1080, 17280, 4320, 4320, 1080, 4320, 17280, 17280, 1080, 17280, 4320, 1080, 4320, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 1080, 1080, 17280, 1080, 4320, 17280, 17280, 4320, 1080, 17280, 1080, 4320, 4320, 1080, 4320, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 17280, 4320, 17280, 4320, 1080, 4320, 17280, 4320, 17280, 1080, 17280, 1080, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 1080, 17280, 1080, 17280, 4320, 4320, 1080, 4320, 17280, 4320, 4320, 17280, 1080, 17280, 17280, 4320, 1080, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 1080, 17280, 4320, 17280, 17280, 1080, 17280, 4320, 4320, 17280, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 1080, 1080, 1080, 1080]
Prompts retrieved: 1945080 . Total input tokens: 433756482 . Total output tokens: 389122472
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 104.29549889173359,
    "estimated_duration": 3600.1002295685594,
    "input_throughput": 6248.632972836957,
    "output_throughput": 5526.653351644163,
    "total_throughput": 11775.286324481121,
    "itl": 154.24059378237325,
    "ttft": 1972596.893931478,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 371,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.135440952999055,
    "arrivals": 648144,
    "finished_requests": 91257,
    "scheduler_time": 161.1837779353636
}
#Debug simulation 
Total elapsed time: 104.29568138672039. Arrivals time: 0.7791908569633961 Scheduler time: 103.28307581041008 Scheduler overhead time: 0.0930798021145165 Adapter cache time: 0.0225141579285264 Engine time: 0.09053204115480185 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-8-16/adapters_256_slots_64_rate_1.6-0.4-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-8-16/adapters_256_slots_64_rate_1.6-0.4-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 1080, 17280, 17280, 1080, 17280, 4320, 17280, 1080, 4320, 1080, 17280, 4320, 4320, 4320, 4320, 17280, 1080, 1080, 1080, 4320, 17280, 1080, 17280, 17280, 4320, 4320, 4320, 1080, 17280, 1080, 4320, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 17280, 4320, 1080, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 1080, 17280, 17280, 4320, 1080, 1080, 17280, 4320, 1080, 4320, 4320, 17280, 4320, 1080, 1080, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 4320, 1080, 4320, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 17280, 17280, 1080, 17280, 1080, 4320, 17280, 17280, 17280, 4320, 1080, 17280, 4320, 1080, 1080, 1080, 1080, 1080, 17280, 4320, 1080, 17280, 1080, 17280, 1080, 1080, 4320, 4320, 17280, 4320, 17280, 1080, 4320, 1080, 17280, 17280, 1080, 17280, 4320, 1080, 17280, 1080, 1080, 17280, 17280, 4320, 17280, 17280, 1080, 17280, 4320, 4320, 1080, 4320, 17280, 17280, 1080, 17280, 4320, 1080, 4320, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 1080, 1080, 17280, 1080, 4320, 17280, 17280, 4320, 1080, 17280, 1080, 4320, 4320, 1080, 4320, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 17280, 4320, 17280, 4320, 1080, 4320, 17280, 4320, 17280, 1080, 17280, 1080, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 1080, 17280, 1080, 17280, 4320, 4320, 1080, 4320, 17280, 4320, 4320, 17280, 1080, 17280, 17280, 4320, 1080, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 1080, 17280, 4320, 17280, 17280, 1080, 17280, 4320, 4320, 17280, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 1080, 1080, 1080, 1080]
Prompts retrieved: 1945080 . Total input tokens: 433756482 . Total output tokens: 389122472
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 103.88012605626136,
    "estimated_duration": 3600.01588290113,
    "input_throughput": 6252.518803295009,
    "output_throughput": 5529.120883755463,
    "total_throughput": 11781.639687050472,
    "itl": 154.49731423522775,
    "ttft": 1973000.7482763007,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 377,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2273548141960113,
    "arrivals": 648144,
    "finished_requests": 91314,
    "scheduler_time": 160.97275222821878
}
#Debug simulation 
Total elapsed time: 103.88033616030589. Arrivals time: 0.7716787671670318 Scheduler time: 102.86697730328888 Scheduler overhead time: 0.0965623720549047 Adapter cache time: 0.024025551043450832 Engine time: 0.09327197866514325 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-8-32/adapters_256_slots_64_rate_1.6-0.4-0.1_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-8-32/adapters_256_slots_64_rate_1.6-0.4-0.1_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 1080, 17280, 17280, 1080, 17280, 4320, 17280, 1080, 4320, 1080, 17280, 4320, 4320, 4320, 4320, 17280, 1080, 1080, 1080, 4320, 17280, 1080, 17280, 17280, 4320, 4320, 4320, 1080, 17280, 1080, 4320, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 17280, 4320, 1080, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 1080, 17280, 17280, 4320, 1080, 1080, 17280, 4320, 1080, 4320, 4320, 17280, 4320, 1080, 1080, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 4320, 1080, 4320, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 17280, 17280, 1080, 17280, 1080, 4320, 17280, 17280, 17280, 4320, 1080, 17280, 4320, 1080, 1080, 1080, 1080, 1080, 17280, 4320, 1080, 17280, 1080, 17280, 1080, 1080, 4320, 4320, 17280, 4320, 17280, 1080, 4320, 1080, 17280, 17280, 1080, 17280, 4320, 1080, 17280, 1080, 1080, 17280, 17280, 4320, 17280, 17280, 1080, 17280, 4320, 4320, 1080, 4320, 17280, 17280, 1080, 17280, 4320, 1080, 4320, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 1080, 1080, 17280, 1080, 4320, 17280, 17280, 4320, 1080, 17280, 1080, 4320, 4320, 1080, 4320, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 17280, 4320, 17280, 4320, 1080, 4320, 17280, 4320, 17280, 1080, 17280, 1080, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 1080, 17280, 1080, 17280, 4320, 4320, 1080, 4320, 17280, 4320, 4320, 17280, 1080, 17280, 17280, 4320, 1080, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 1080, 17280, 4320, 17280, 17280, 1080, 17280, 4320, 4320, 17280, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 1080, 1080, 1080, 1080]
Prompts retrieved: 1945080 . Total input tokens: 433756482 . Total output tokens: 389122472
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 107.62055011000484,
    "estimated_duration": 3600.1626824584046,
    "input_throughput": 6250.864470555771,
    "output_throughput": 5528.880707803953,
    "total_throughput": 11779.745178359724,
    "itl": 154.41455868371264,
    "ttft": 1972062.5980941167,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 379,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2371310223266552,
    "arrivals": 648144,
    "finished_requests": 91335,
    "scheduler_time": 161.03215579545423
}
#Debug simulation 
Total elapsed time: 107.62079265201464. Arrivals time: 0.8100692885927856 Scheduler time: 106.5650489688851 Scheduler overhead time: 0.09841577569022775 Adapter cache time: 0.02391052572056651 Engine time: 0.09530250541865826 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-16-16/adapters_256_slots_64_rate_1.6-0.4-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-16-16/adapters_256_slots_64_rate_1.6-0.4-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 1080, 17280, 17280, 1080, 17280, 4320, 17280, 1080, 4320, 1080, 17280, 4320, 4320, 4320, 4320, 17280, 1080, 1080, 1080, 4320, 17280, 1080, 17280, 17280, 4320, 4320, 4320, 1080, 17280, 1080, 4320, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 17280, 4320, 1080, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 1080, 17280, 17280, 4320, 1080, 1080, 17280, 4320, 1080, 4320, 4320, 17280, 4320, 1080, 1080, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 4320, 1080, 4320, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 17280, 17280, 1080, 17280, 1080, 4320, 17280, 17280, 17280, 4320, 1080, 17280, 4320, 1080, 1080, 1080, 1080, 1080, 17280, 4320, 1080, 17280, 1080, 17280, 1080, 1080, 4320, 4320, 17280, 4320, 17280, 1080, 4320, 1080, 17280, 17280, 1080, 17280, 4320, 1080, 17280, 1080, 1080, 17280, 17280, 4320, 17280, 17280, 1080, 17280, 4320, 4320, 1080, 4320, 17280, 17280, 1080, 17280, 4320, 1080, 4320, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 1080, 1080, 17280, 1080, 4320, 17280, 17280, 4320, 1080, 17280, 1080, 4320, 4320, 1080, 4320, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 17280, 4320, 17280, 4320, 1080, 4320, 17280, 4320, 17280, 1080, 17280, 1080, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 1080, 17280, 1080, 17280, 4320, 4320, 1080, 4320, 17280, 4320, 4320, 17280, 1080, 17280, 17280, 4320, 1080, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 1080, 17280, 4320, 17280, 17280, 1080, 17280, 4320, 4320, 17280, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 1080, 1080, 1080, 1080]
Prompts retrieved: 1945080 . Total input tokens: 433756482 . Total output tokens: 389122472
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 105.27957071177661,
    "estimated_duration": 3600.0349045747153,
    "input_throughput": 6252.602432103124,
    "output_throughput": 5529.230834597004,
    "total_throughput": 11781.833266700127,
    "itl": 154.49484548318486,
    "ttft": 1973080.8673172898,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 377,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1766889947094026,
    "arrivals": 648144,
    "finished_requests": 91315,
    "scheduler_time": 160.97645384286338
}
#Debug simulation 
Total elapsed time: 105.27976074395701. Arrivals time: 0.7770209345035255 Scheduler time: 104.2564112865366 Scheduler overhead time: 0.09814375312998891 Adapter cache time: 0.024111172184348106 Engine time: 0.09494122257456183 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-16-32/adapters_256_slots_64_rate_1.6-0.4-0.1_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-16-32/adapters_256_slots_64_rate_1.6-0.4-0.1_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 1080, 17280, 17280, 1080, 17280, 4320, 17280, 1080, 4320, 1080, 17280, 4320, 4320, 4320, 4320, 17280, 1080, 1080, 1080, 4320, 17280, 1080, 17280, 17280, 4320, 4320, 4320, 1080, 17280, 1080, 4320, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 17280, 4320, 1080, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 1080, 17280, 17280, 4320, 1080, 1080, 17280, 4320, 1080, 4320, 4320, 17280, 4320, 1080, 1080, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 4320, 1080, 4320, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 17280, 17280, 1080, 17280, 1080, 4320, 17280, 17280, 17280, 4320, 1080, 17280, 4320, 1080, 1080, 1080, 1080, 1080, 17280, 4320, 1080, 17280, 1080, 17280, 1080, 1080, 4320, 4320, 17280, 4320, 17280, 1080, 4320, 1080, 17280, 17280, 1080, 17280, 4320, 1080, 17280, 1080, 1080, 17280, 17280, 4320, 17280, 17280, 1080, 17280, 4320, 4320, 1080, 4320, 17280, 17280, 1080, 17280, 4320, 1080, 4320, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 1080, 1080, 17280, 1080, 4320, 17280, 17280, 4320, 1080, 17280, 1080, 4320, 4320, 1080, 4320, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 17280, 4320, 17280, 4320, 1080, 4320, 17280, 4320, 17280, 1080, 17280, 1080, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 1080, 17280, 1080, 17280, 4320, 4320, 1080, 4320, 17280, 4320, 4320, 17280, 1080, 17280, 17280, 4320, 1080, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 1080, 17280, 4320, 17280, 17280, 1080, 17280, 4320, 4320, 17280, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 1080, 1080, 1080, 1080]
Prompts retrieved: 1945080 . Total input tokens: 433756482 . Total output tokens: 389122472
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 95.67137606441975,
    "estimated_duration": 3600.090122233624,
    "input_throughput": 6245.434485415062,
    "output_throughput": 5527.3480175140685,
    "total_throughput": 11772.78250292913,
    "itl": 154.27103939221834,
    "ttft": 1971889.8060610336,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 359,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1870926360786007,
    "arrivals": 648144,
    "finished_requests": 91255,
    "scheduler_time": 161.17216192718158
}
#Debug simulation 
Total elapsed time: 95.67166978307068. Arrivals time: 0.7023850637488067 Scheduler time: 94.751711408142 Scheduler overhead time: 0.08687705686315894 Adapter cache time: 0.020556806586682796 Engine time: 0.08364388020709157 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_16-16-16/adapters_256_slots_64_rate_1.6-0.4-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_16-16-16/adapters_256_slots_64_rate_1.6-0.4-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 1080, 17280, 17280, 1080, 17280, 4320, 17280, 1080, 4320, 1080, 17280, 4320, 4320, 4320, 4320, 17280, 1080, 1080, 1080, 4320, 17280, 1080, 17280, 17280, 4320, 4320, 4320, 1080, 17280, 1080, 4320, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 17280, 4320, 1080, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 1080, 17280, 17280, 4320, 1080, 1080, 17280, 4320, 1080, 4320, 4320, 17280, 4320, 1080, 1080, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 4320, 1080, 4320, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 17280, 17280, 1080, 17280, 1080, 4320, 17280, 17280, 17280, 4320, 1080, 17280, 4320, 1080, 1080, 1080, 1080, 1080, 17280, 4320, 1080, 17280, 1080, 17280, 1080, 1080, 4320, 4320, 17280, 4320, 17280, 1080, 4320, 1080, 17280, 17280, 1080, 17280, 4320, 1080, 17280, 1080, 1080, 17280, 17280, 4320, 17280, 17280, 1080, 17280, 4320, 4320, 1080, 4320, 17280, 17280, 1080, 17280, 4320, 1080, 4320, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 1080, 1080, 17280, 1080, 4320, 17280, 17280, 4320, 1080, 17280, 1080, 4320, 4320, 1080, 4320, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 17280, 4320, 17280, 4320, 1080, 4320, 17280, 4320, 17280, 1080, 17280, 1080, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 1080, 17280, 1080, 17280, 4320, 4320, 1080, 4320, 17280, 4320, 4320, 17280, 1080, 17280, 17280, 4320, 1080, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 1080, 17280, 4320, 17280, 17280, 1080, 17280, 4320, 4320, 17280, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 1080, 1080, 1080, 1080]
Prompts retrieved: 1945080 . Total input tokens: 433756482 . Total output tokens: 389122472
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 105.6503968751058,
    "estimated_duration": 3600.072591480736,
    "input_throughput": 6248.680944166005,
    "output_throughput": 5526.6957802693705,
    "total_throughput": 11775.376724435375,
    "itl": 154.2399684302201,
    "ttft": 1972584.489243038,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 371,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1093086594087047,
    "arrivals": 648144,
    "finished_requests": 91257,
    "scheduler_time": 161.1835252824811
}
#Debug simulation 
Total elapsed time: 105.65057299891487. Arrivals time: 0.8211628496646881 Scheduler time: 104.58591593289748 Scheduler overhead time: 0.09622494271025062 Adapter cache time: 0.02364359889179468 Engine time: 0.09498377470299602 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_16-16-32/adapters_256_slots_64_rate_1.6-0.4-0.1_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_16-16-32/adapters_256_slots_64_rate_1.6-0.4-0.1_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 1080, 17280, 17280, 1080, 17280, 4320, 17280, 1080, 4320, 1080, 17280, 4320, 4320, 4320, 4320, 17280, 1080, 1080, 1080, 4320, 17280, 1080, 17280, 17280, 4320, 4320, 4320, 1080, 17280, 1080, 4320, 4320, 1080, 4320, 1080, 1080, 4320, 4320, 17280, 4320, 1080, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 1080, 17280, 17280, 4320, 1080, 1080, 17280, 4320, 1080, 4320, 4320, 17280, 4320, 1080, 1080, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 4320, 1080, 4320, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 17280, 17280, 1080, 17280, 1080, 4320, 17280, 17280, 17280, 4320, 1080, 17280, 4320, 1080, 1080, 1080, 1080, 1080, 17280, 4320, 1080, 17280, 1080, 17280, 1080, 1080, 4320, 4320, 17280, 4320, 17280, 1080, 4320, 1080, 17280, 17280, 1080, 17280, 4320, 1080, 17280, 1080, 1080, 17280, 17280, 4320, 17280, 17280, 1080, 17280, 4320, 4320, 1080, 4320, 17280, 17280, 1080, 17280, 4320, 1080, 4320, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 1080, 1080, 17280, 1080, 4320, 17280, 17280, 4320, 1080, 17280, 1080, 4320, 4320, 1080, 4320, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 17280, 4320, 17280, 4320, 1080, 4320, 17280, 4320, 17280, 1080, 17280, 1080, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 1080, 17280, 1080, 17280, 4320, 4320, 1080, 4320, 17280, 4320, 4320, 17280, 1080, 17280, 17280, 4320, 1080, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 1080, 17280, 4320, 17280, 17280, 1080, 17280, 4320, 4320, 17280, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 1080, 1080, 1080, 1080]
Prompts retrieved: 1945080 . Total input tokens: 433756482 . Total output tokens: 389122472
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 107.79022233281285,
    "estimated_duration": 3600.1056163636163,
    "input_throughput": 6245.407606322033,
    "output_throughput": 5527.32422892067,
    "total_throughput": 11772.731835242703,
    "itl": 154.271491101464,
    "ttft": 1971897.2181630572,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 359,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2014285677298935,
    "arrivals": 648144,
    "finished_requests": 91255,
    "scheduler_time": 161.17234546000245
}
#Debug simulation 
Total elapsed time: 107.79039721982554. Arrivals time: 0.7951811542734504 Scheduler time: 106.74896723870188 Scheduler overhead time: 0.09781977441161871 Adapter cache time: 0.022963943425565958 Engine time: 0.09694609744474292 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-8-8/adapters_256_slots_64_rate_1.6-0.4-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-8-8/adapters_256_slots_64_rate_1.6-0.4-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 540, 17280, 17280, 540, 17280, 4320, 17280, 540, 4320, 540, 17280, 4320, 4320, 4320, 4320, 17280, 540, 540, 540, 4320, 17280, 540, 17280, 17280, 4320, 4320, 4320, 540, 17280, 540, 4320, 4320, 540, 4320, 540, 540, 4320, 4320, 17280, 4320, 540, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 540, 17280, 17280, 4320, 540, 540, 17280, 4320, 540, 4320, 4320, 17280, 4320, 540, 540, 17280, 17280, 17280, 17280, 17280, 17280, 540, 4320, 540, 4320, 540, 540, 540, 4320, 4320, 4320, 540, 540, 17280, 17280, 540, 17280, 540, 4320, 17280, 17280, 17280, 4320, 540, 17280, 4320, 540, 540, 540, 540, 540, 17280, 4320, 540, 17280, 540, 17280, 540, 540, 4320, 4320, 17280, 4320, 17280, 540, 4320, 540, 17280, 17280, 540, 17280, 4320, 540, 17280, 540, 540, 17280, 17280, 4320, 17280, 17280, 540, 17280, 4320, 4320, 540, 4320, 17280, 17280, 540, 17280, 4320, 540, 4320, 17280, 540, 540, 540, 540, 540, 540, 17280, 540, 540, 540, 17280, 540, 4320, 17280, 17280, 4320, 540, 17280, 540, 4320, 4320, 540, 4320, 540, 17280, 540, 540, 17280, 540, 17280, 17280, 4320, 17280, 4320, 540, 4320, 17280, 4320, 17280, 540, 17280, 540, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 540, 17280, 540, 17280, 4320, 4320, 540, 4320, 17280, 4320, 4320, 17280, 540, 17280, 17280, 4320, 540, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 540, 17280, 4320, 17280, 17280, 540, 17280, 4320, 4320, 17280, 540, 4320, 540, 540, 540, 540, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 540, 540, 540, 540]
Prompts retrieved: 1899180 . Total input tokens: 423567319 . Total output tokens: 379831664
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 99.13796504866332,
    "estimated_duration": 3600.010394929022,
    "input_throughput": 6239.534483467199,
    "output_throughput": 5526.050988081169,
    "total_throughput": 11765.585471548367,
    "itl": 154.42966008724434,
    "ttft": 1977164.767709643,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 453,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3864009480015496,
    "arrivals": 632850,
    "finished_requests": 91048,
    "scheduler_time": 161.1531459242266
}
#Debug simulation 
Total elapsed time: 99.13811952993274. Arrivals time: 0.7345600514672697 Scheduler time: 98.17151948949322 Scheduler overhead time: 0.09177723899483681 Adapter cache time: 0.0237545701675117 Engine time: 0.08958548493683338 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-8-16/adapters_256_slots_64_rate_1.6-0.4-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-8-16/adapters_256_slots_64_rate_1.6-0.4-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 540, 17280, 17280, 540, 17280, 4320, 17280, 540, 4320, 540, 17280, 4320, 4320, 4320, 4320, 17280, 540, 540, 540, 4320, 17280, 540, 17280, 17280, 4320, 4320, 4320, 540, 17280, 540, 4320, 4320, 540, 4320, 540, 540, 4320, 4320, 17280, 4320, 540, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 540, 17280, 17280, 4320, 540, 540, 17280, 4320, 540, 4320, 4320, 17280, 4320, 540, 540, 17280, 17280, 17280, 17280, 17280, 17280, 540, 4320, 540, 4320, 540, 540, 540, 4320, 4320, 4320, 540, 540, 17280, 17280, 540, 17280, 540, 4320, 17280, 17280, 17280, 4320, 540, 17280, 4320, 540, 540, 540, 540, 540, 17280, 4320, 540, 17280, 540, 17280, 540, 540, 4320, 4320, 17280, 4320, 17280, 540, 4320, 540, 17280, 17280, 540, 17280, 4320, 540, 17280, 540, 540, 17280, 17280, 4320, 17280, 17280, 540, 17280, 4320, 4320, 540, 4320, 17280, 17280, 540, 17280, 4320, 540, 4320, 17280, 540, 540, 540, 540, 540, 540, 17280, 540, 540, 540, 17280, 540, 4320, 17280, 17280, 4320, 540, 17280, 540, 4320, 4320, 540, 4320, 540, 17280, 540, 540, 17280, 540, 17280, 17280, 4320, 17280, 4320, 540, 4320, 17280, 4320, 17280, 540, 17280, 540, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 540, 17280, 540, 17280, 4320, 4320, 540, 4320, 17280, 4320, 4320, 17280, 540, 17280, 17280, 4320, 540, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 540, 17280, 4320, 17280, 17280, 540, 17280, 4320, 4320, 17280, 540, 4320, 540, 540, 540, 540, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 540, 540, 540, 540]
Prompts retrieved: 1899180 . Total input tokens: 423567319 . Total output tokens: 379831664
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 97.27868276834488,
    "estimated_duration": 3600.152254009175,
    "input_throughput": 6235.649332608139,
    "output_throughput": 5523.212519097345,
    "total_throughput": 11758.861851705484,
    "itl": 154.42446017798576,
    "ttft": 1977800.5718908722,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 456,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4893102925550252,
    "arrivals": 632850,
    "finished_requests": 91012,
    "scheduler_time": 161.15027210825005
}
#Debug simulation 
Total elapsed time: 97.27886263700202. Arrivals time: 0.8150725085288286 Scheduler time: 96.22644818807021 Scheduler overhead time: 0.09280148334801197 Adapter cache time: 0.02480430295690894 Engine time: 0.09234508080407977 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-8-32/adapters_256_slots_64_rate_1.6-0.4-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-8-32/adapters_256_slots_64_rate_1.6-0.4-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 540, 17280, 17280, 540, 17280, 4320, 17280, 540, 4320, 540, 17280, 4320, 4320, 4320, 4320, 17280, 540, 540, 540, 4320, 17280, 540, 17280, 17280, 4320, 4320, 4320, 540, 17280, 540, 4320, 4320, 540, 4320, 540, 540, 4320, 4320, 17280, 4320, 540, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 540, 17280, 17280, 4320, 540, 540, 17280, 4320, 540, 4320, 4320, 17280, 4320, 540, 540, 17280, 17280, 17280, 17280, 17280, 17280, 540, 4320, 540, 4320, 540, 540, 540, 4320, 4320, 4320, 540, 540, 17280, 17280, 540, 17280, 540, 4320, 17280, 17280, 17280, 4320, 540, 17280, 4320, 540, 540, 540, 540, 540, 17280, 4320, 540, 17280, 540, 17280, 540, 540, 4320, 4320, 17280, 4320, 17280, 540, 4320, 540, 17280, 17280, 540, 17280, 4320, 540, 17280, 540, 540, 17280, 17280, 4320, 17280, 17280, 540, 17280, 4320, 4320, 540, 4320, 17280, 17280, 540, 17280, 4320, 540, 4320, 17280, 540, 540, 540, 540, 540, 540, 17280, 540, 540, 540, 17280, 540, 4320, 17280, 17280, 4320, 540, 17280, 540, 4320, 4320, 540, 4320, 540, 17280, 540, 540, 17280, 540, 17280, 17280, 4320, 17280, 4320, 540, 4320, 17280, 4320, 17280, 540, 17280, 540, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 540, 17280, 540, 17280, 4320, 4320, 540, 4320, 17280, 4320, 4320, 17280, 540, 17280, 17280, 4320, 540, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 540, 17280, 4320, 17280, 17280, 540, 17280, 4320, 4320, 17280, 540, 4320, 540, 540, 540, 540, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 540, 540, 540, 540]
Prompts retrieved: 1899180 . Total input tokens: 423567319 . Total output tokens: 379831664
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 98.61863754410297,
    "estimated_duration": 3600.1546715927634,
    "input_throughput": 6235.645145231522,
    "output_throughput": 5523.208810137825,
    "total_throughput": 11758.853955369348,
    "itl": 154.42453891957678,
    "ttft": 1977801.5154173428,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 456,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4917168233543723,
    "arrivals": 632850,
    "finished_requests": 91012,
    "scheduler_time": 161.1502831610079
}
#Debug simulation 
Total elapsed time: 98.61884716711938. Arrivals time: 0.7172508738003671 Scheduler time: 97.66814387077466 Scheduler overhead time: 0.09203749103471637 Adapter cache time: 0.023390202783048153 Engine time: 0.09001162415370345 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-16-16/adapters_256_slots_64_rate_1.6-0.4-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-16-16/adapters_256_slots_64_rate_1.6-0.4-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 540, 17280, 17280, 540, 17280, 4320, 17280, 540, 4320, 540, 17280, 4320, 4320, 4320, 4320, 17280, 540, 540, 540, 4320, 17280, 540, 17280, 17280, 4320, 4320, 4320, 540, 17280, 540, 4320, 4320, 540, 4320, 540, 540, 4320, 4320, 17280, 4320, 540, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 540, 17280, 17280, 4320, 540, 540, 17280, 4320, 540, 4320, 4320, 17280, 4320, 540, 540, 17280, 17280, 17280, 17280, 17280, 17280, 540, 4320, 540, 4320, 540, 540, 540, 4320, 4320, 4320, 540, 540, 17280, 17280, 540, 17280, 540, 4320, 17280, 17280, 17280, 4320, 540, 17280, 4320, 540, 540, 540, 540, 540, 17280, 4320, 540, 17280, 540, 17280, 540, 540, 4320, 4320, 17280, 4320, 17280, 540, 4320, 540, 17280, 17280, 540, 17280, 4320, 540, 17280, 540, 540, 17280, 17280, 4320, 17280, 17280, 540, 17280, 4320, 4320, 540, 4320, 17280, 17280, 540, 17280, 4320, 540, 4320, 17280, 540, 540, 540, 540, 540, 540, 17280, 540, 540, 540, 17280, 540, 4320, 17280, 17280, 4320, 540, 17280, 540, 4320, 4320, 540, 4320, 540, 17280, 540, 540, 17280, 540, 17280, 17280, 4320, 17280, 4320, 540, 4320, 17280, 4320, 17280, 540, 17280, 540, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 540, 17280, 540, 17280, 4320, 4320, 540, 4320, 17280, 4320, 4320, 17280, 540, 17280, 17280, 4320, 540, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 540, 17280, 4320, 17280, 17280, 540, 17280, 4320, 4320, 17280, 540, 4320, 540, 540, 540, 540, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 540, 540, 540, 540]
Prompts retrieved: 1899180 . Total input tokens: 423567319 . Total output tokens: 379831664
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 96.75254237605259,
    "estimated_duration": 3600.0366922772537,
    "input_throughput": 6239.488905261991,
    "output_throughput": 5526.010621690601,
    "total_throughput": 11765.499526952592,
    "itl": 154.43059147165715,
    "ttft": 1977173.3404703336,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 453,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4141477000829727,
    "arrivals": 632850,
    "finished_requests": 91048,
    "scheduler_time": 161.15322813759082
}
#Debug simulation 
Total elapsed time: 96.75272776512429. Arrivals time: 0.8255237434059381 Scheduler time: 95.69560661166906 Scheduler overhead time: 0.08948170812800527 Adapter cache time: 0.025129556190222502 Engine time: 0.08985264971852303 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-16-32/adapters_256_slots_64_rate_1.6-0.4-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-16-32/adapters_256_slots_64_rate_1.6-0.4-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 540, 17280, 17280, 540, 17280, 4320, 17280, 540, 4320, 540, 17280, 4320, 4320, 4320, 4320, 17280, 540, 540, 540, 4320, 17280, 540, 17280, 17280, 4320, 4320, 4320, 540, 17280, 540, 4320, 4320, 540, 4320, 540, 540, 4320, 4320, 17280, 4320, 540, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 540, 17280, 17280, 4320, 540, 540, 17280, 4320, 540, 4320, 4320, 17280, 4320, 540, 540, 17280, 17280, 17280, 17280, 17280, 17280, 540, 4320, 540, 4320, 540, 540, 540, 4320, 4320, 4320, 540, 540, 17280, 17280, 540, 17280, 540, 4320, 17280, 17280, 17280, 4320, 540, 17280, 4320, 540, 540, 540, 540, 540, 17280, 4320, 540, 17280, 540, 17280, 540, 540, 4320, 4320, 17280, 4320, 17280, 540, 4320, 540, 17280, 17280, 540, 17280, 4320, 540, 17280, 540, 540, 17280, 17280, 4320, 17280, 17280, 540, 17280, 4320, 4320, 540, 4320, 17280, 17280, 540, 17280, 4320, 540, 4320, 17280, 540, 540, 540, 540, 540, 540, 17280, 540, 540, 540, 17280, 540, 4320, 17280, 17280, 4320, 540, 17280, 540, 4320, 4320, 540, 4320, 540, 17280, 540, 540, 17280, 540, 17280, 17280, 4320, 17280, 4320, 540, 4320, 17280, 4320, 17280, 540, 17280, 540, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 540, 17280, 540, 17280, 4320, 4320, 540, 4320, 17280, 4320, 4320, 17280, 540, 17280, 17280, 4320, 540, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 540, 17280, 4320, 17280, 17280, 540, 17280, 4320, 4320, 17280, 540, 4320, 540, 540, 540, 540, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 540, 540, 540, 540]
Prompts retrieved: 1899180 . Total input tokens: 423567319 . Total output tokens: 379831664
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 99.09463807893917,
    "estimated_duration": 3600.17348962405,
    "input_throughput": 6235.612551645193,
    "output_throughput": 5523.17994044127,
    "total_throughput": 11758.792492086463,
    "itl": 154.4250844739075,
    "ttft": 1977808.2966445903,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 456,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5120889367535748,
    "arrivals": 632850,
    "finished_requests": 91012,
    "scheduler_time": 161.15039993412435
}
#Debug simulation 
Total elapsed time: 99.0948261199519. Arrivals time: 0.7387885986827314 Scheduler time: 98.11557540623471 Scheduler overhead time: 0.09520338661968708 Adapter cache time: 0.02521541714668274 Engine time: 0.0920049948617816 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_16-16-16/adapters_256_slots_64_rate_1.6-0.4-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_16-16-16/adapters_256_slots_64_rate_1.6-0.4-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 540, 17280, 17280, 540, 17280, 4320, 17280, 540, 4320, 540, 17280, 4320, 4320, 4320, 4320, 17280, 540, 540, 540, 4320, 17280, 540, 17280, 17280, 4320, 4320, 4320, 540, 17280, 540, 4320, 4320, 540, 4320, 540, 540, 4320, 4320, 17280, 4320, 540, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 540, 17280, 17280, 4320, 540, 540, 17280, 4320, 540, 4320, 4320, 17280, 4320, 540, 540, 17280, 17280, 17280, 17280, 17280, 17280, 540, 4320, 540, 4320, 540, 540, 540, 4320, 4320, 4320, 540, 540, 17280, 17280, 540, 17280, 540, 4320, 17280, 17280, 17280, 4320, 540, 17280, 4320, 540, 540, 540, 540, 540, 17280, 4320, 540, 17280, 540, 17280, 540, 540, 4320, 4320, 17280, 4320, 17280, 540, 4320, 540, 17280, 17280, 540, 17280, 4320, 540, 17280, 540, 540, 17280, 17280, 4320, 17280, 17280, 540, 17280, 4320, 4320, 540, 4320, 17280, 17280, 540, 17280, 4320, 540, 4320, 17280, 540, 540, 540, 540, 540, 540, 17280, 540, 540, 540, 17280, 540, 4320, 17280, 17280, 4320, 540, 17280, 540, 4320, 4320, 540, 4320, 540, 17280, 540, 540, 17280, 540, 17280, 17280, 4320, 17280, 4320, 540, 4320, 17280, 4320, 17280, 540, 17280, 540, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 540, 17280, 540, 17280, 4320, 4320, 540, 4320, 17280, 4320, 4320, 17280, 540, 17280, 17280, 4320, 540, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 540, 17280, 4320, 17280, 17280, 540, 17280, 4320, 4320, 17280, 540, 4320, 540, 540, 540, 540, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 540, 540, 540, 540]
Prompts retrieved: 1899180 . Total input tokens: 423567319 . Total output tokens: 379831664
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 92.8361389003694,
    "estimated_duration": 3600.0857856608486,
    "input_throughput": 6235.655852817178,
    "output_throughput": 5527.934939568911,
    "total_throughput": 11763.59079238609,
    "itl": 154.5022924705644,
    "ttft": 1977390.2903451743,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 489,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4621345942071489,
    "arrivals": 632850,
    "finished_requests": 91024,
    "scheduler_time": 161.12943013137823
}
#Debug simulation 
Total elapsed time: 92.83642996614799. Arrivals time: 0.7766581228934228 Scheduler time: 91.83442029403523 Scheduler overhead time: 0.08829462202265859 Adapter cache time: 0.024448732379823923 Engine time: 0.08563576964661479 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_16-16-32/adapters_256_slots_64_rate_1.6-0.4-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_16-16-32/adapters_256_slots_64_rate_1.6-0.4-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 540, 17280, 17280, 540, 17280, 4320, 17280, 540, 4320, 540, 17280, 4320, 4320, 4320, 4320, 17280, 540, 540, 540, 4320, 17280, 540, 17280, 17280, 4320, 4320, 4320, 540, 17280, 540, 4320, 4320, 540, 4320, 540, 540, 4320, 4320, 17280, 4320, 540, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 540, 17280, 17280, 4320, 540, 540, 17280, 4320, 540, 4320, 4320, 17280, 4320, 540, 540, 17280, 17280, 17280, 17280, 17280, 17280, 540, 4320, 540, 4320, 540, 540, 540, 4320, 4320, 4320, 540, 540, 17280, 17280, 540, 17280, 540, 4320, 17280, 17280, 17280, 4320, 540, 17280, 4320, 540, 540, 540, 540, 540, 17280, 4320, 540, 17280, 540, 17280, 540, 540, 4320, 4320, 17280, 4320, 17280, 540, 4320, 540, 17280, 17280, 540, 17280, 4320, 540, 17280, 540, 540, 17280, 17280, 4320, 17280, 17280, 540, 17280, 4320, 4320, 540, 4320, 17280, 17280, 540, 17280, 4320, 540, 4320, 17280, 540, 540, 540, 540, 540, 540, 17280, 540, 540, 540, 17280, 540, 4320, 17280, 17280, 4320, 540, 17280, 540, 4320, 4320, 540, 4320, 540, 17280, 540, 540, 17280, 540, 17280, 17280, 4320, 17280, 4320, 540, 4320, 17280, 4320, 17280, 540, 17280, 540, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 540, 17280, 540, 17280, 4320, 4320, 540, 4320, 17280, 4320, 4320, 17280, 540, 17280, 17280, 4320, 540, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 540, 17280, 4320, 17280, 17280, 540, 17280, 4320, 4320, 17280, 540, 4320, 540, 540, 540, 540, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 540, 540, 540, 540]
Prompts retrieved: 1899180 . Total input tokens: 423567319 . Total output tokens: 379831664
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 98.87817913061008,
    "estimated_duration": 3600.0158873603746,
    "input_throughput": 6235.394982231344,
    "output_throughput": 5522.907293217088,
    "total_throughput": 11758.302275448432,
    "itl": 154.42561997839385,
    "ttft": 1977799.5933243525,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 456,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5304489895701403,
    "arrivals": 632850,
    "finished_requests": 91007,
    "scheduler_time": 161.1426249555184
}
#Debug simulation 
Total elapsed time: 98.87833534600213. Arrivals time: 0.7112012375146151 Scheduler time: 97.93431080551818 Scheduler overhead time: 0.09215369494631886 Adapter cache time: 0.024338883813470602 Engine time: 0.08922361209988594 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-8-8/adapters_256_slots_64_rate_1.6-0.4-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-8-8/adapters_256_slots_64_rate_1.6-0.4-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 270, 17280, 17280, 270, 17280, 4320, 17280, 270, 4320, 270, 17280, 4320, 4320, 4320, 4320, 17280, 270, 270, 270, 4320, 17280, 270, 17280, 17280, 4320, 4320, 4320, 270, 17280, 270, 4320, 4320, 270, 4320, 270, 270, 4320, 4320, 17280, 4320, 270, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 270, 17280, 17280, 4320, 270, 270, 17280, 4320, 270, 4320, 4320, 17280, 4320, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 4320, 270, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 270, 17280, 17280, 270, 17280, 270, 4320, 17280, 17280, 17280, 4320, 270, 17280, 4320, 270, 270, 270, 270, 270, 17280, 4320, 270, 17280, 270, 17280, 270, 270, 4320, 4320, 17280, 4320, 17280, 270, 4320, 270, 17280, 17280, 270, 17280, 4320, 270, 17280, 270, 270, 17280, 17280, 4320, 17280, 17280, 270, 17280, 4320, 4320, 270, 4320, 17280, 17280, 270, 17280, 4320, 270, 4320, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 4320, 17280, 17280, 4320, 270, 17280, 270, 4320, 4320, 270, 4320, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 4320, 17280, 4320, 270, 4320, 17280, 4320, 17280, 270, 17280, 270, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 270, 17280, 270, 17280, 4320, 4320, 270, 4320, 17280, 4320, 4320, 17280, 270, 17280, 17280, 4320, 270, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 270, 17280, 4320, 17280, 17280, 270, 17280, 4320, 4320, 17280, 270, 4320, 270, 270, 270, 270, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 270, 270, 270, 270]
Prompts retrieved: 1876230 . Total input tokens: 418371695 . Total output tokens: 375262201
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 103.26186236692593,
    "estimated_duration": 3600.015368553169,
    "input_throughput": 6285.756221394807,
    "output_throughput": 5525.311134433904,
    "total_throughput": 11811.06735582871,
    "itl": 153.8893896042949,
    "ttft": 1975868.6043435642,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 357,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.092594124583995,
    "arrivals": 625482,
    "finished_requests": 91275,
    "scheduler_time": 161.14137243810487
}
#Debug simulation 
Total elapsed time: 103.26210028817877. Arrivals time: 0.7609501658007503 Scheduler time: 102.27673303056508 Scheduler overhead time: 0.08793445955961943 Adapter cache time: 0.02194068767130375 Engine time: 0.08736912254244089 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-8-16/adapters_256_slots_64_rate_1.6-0.4-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-8-16/adapters_256_slots_64_rate_1.6-0.4-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 270, 17280, 17280, 270, 17280, 4320, 17280, 270, 4320, 270, 17280, 4320, 4320, 4320, 4320, 17280, 270, 270, 270, 4320, 17280, 270, 17280, 17280, 4320, 4320, 4320, 270, 17280, 270, 4320, 4320, 270, 4320, 270, 270, 4320, 4320, 17280, 4320, 270, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 270, 17280, 17280, 4320, 270, 270, 17280, 4320, 270, 4320, 4320, 17280, 4320, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 4320, 270, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 270, 17280, 17280, 270, 17280, 270, 4320, 17280, 17280, 17280, 4320, 270, 17280, 4320, 270, 270, 270, 270, 270, 17280, 4320, 270, 17280, 270, 17280, 270, 270, 4320, 4320, 17280, 4320, 17280, 270, 4320, 270, 17280, 17280, 270, 17280, 4320, 270, 17280, 270, 270, 17280, 17280, 4320, 17280, 17280, 270, 17280, 4320, 4320, 270, 4320, 17280, 17280, 270, 17280, 4320, 270, 4320, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 4320, 17280, 17280, 4320, 270, 17280, 270, 4320, 4320, 270, 4320, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 4320, 17280, 4320, 270, 4320, 17280, 4320, 17280, 270, 17280, 270, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 270, 17280, 270, 17280, 4320, 4320, 270, 4320, 17280, 4320, 4320, 17280, 270, 17280, 17280, 4320, 270, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 270, 17280, 4320, 17280, 17280, 270, 17280, 4320, 4320, 17280, 270, 4320, 270, 270, 270, 270, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 270, 270, 270, 270]
Prompts retrieved: 1876230 . Total input tokens: 418371695 . Total output tokens: 375262201
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 106.6509046847932,
    "estimated_duration": 3600.082751312834,
    "input_throughput": 6291.765652258953,
    "output_throughput": 5533.040870445558,
    "total_throughput": 11824.806522704512,
    "itl": 154.53914306845326,
    "ttft": 1976674.1325337796,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 391,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2773874246934485,
    "arrivals": 625482,
    "finished_requests": 91412,
    "scheduler_time": 160.72856347852945
}
#Debug simulation 
Total elapsed time: 106.65109749184921. Arrivals time: 0.8048223699443042 Scheduler time: 105.61421036254615 Scheduler overhead time: 0.09105355385690928 Adapter cache time: 0.0240356232970953 Engine time: 0.0896213548257947 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-8-32/adapters_256_slots_64_rate_1.6-0.4-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-8-32/adapters_256_slots_64_rate_1.6-0.4-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 270, 17280, 17280, 270, 17280, 4320, 17280, 270, 4320, 270, 17280, 4320, 4320, 4320, 4320, 17280, 270, 270, 270, 4320, 17280, 270, 17280, 17280, 4320, 4320, 4320, 270, 17280, 270, 4320, 4320, 270, 4320, 270, 270, 4320, 4320, 17280, 4320, 270, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 270, 17280, 17280, 4320, 270, 270, 17280, 4320, 270, 4320, 4320, 17280, 4320, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 4320, 270, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 270, 17280, 17280, 270, 17280, 270, 4320, 17280, 17280, 17280, 4320, 270, 17280, 4320, 270, 270, 270, 270, 270, 17280, 4320, 270, 17280, 270, 17280, 270, 270, 4320, 4320, 17280, 4320, 17280, 270, 4320, 270, 17280, 17280, 270, 17280, 4320, 270, 17280, 270, 270, 17280, 17280, 4320, 17280, 17280, 270, 17280, 4320, 4320, 270, 4320, 17280, 17280, 270, 17280, 4320, 270, 4320, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 4320, 17280, 17280, 4320, 270, 17280, 270, 4320, 4320, 270, 4320, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 4320, 17280, 4320, 270, 4320, 17280, 4320, 17280, 270, 17280, 270, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 270, 17280, 270, 17280, 4320, 4320, 270, 4320, 17280, 4320, 4320, 17280, 270, 17280, 17280, 4320, 270, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 270, 17280, 4320, 17280, 17280, 270, 17280, 4320, 4320, 17280, 270, 4320, 270, 270, 270, 270, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 270, 270, 270, 270]
Prompts retrieved: 1876230 . Total input tokens: 418371695 . Total output tokens: 375262201
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 110.06809642305598,
    "estimated_duration": 3600.084755790373,
    "input_throughput": 6291.762149090615,
    "output_throughput": 5533.037789724714,
    "total_throughput": 11824.79993881533,
    "itl": 154.53920267277178,
    "ttft": 1976674.721159316,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 391,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2793864559196009,
    "arrivals": 625482,
    "finished_requests": 91412,
    "scheduler_time": 160.72856892481593
}
#Debug simulation 
Total elapsed time: 110.06830792874098. Arrivals time: 0.991480749566108 Scheduler time: 108.84295478090644 Scheduler overhead time: 0.09408614411950111 Adapter cache time: 0.023198973387479782 Engine time: 0.08869004715234041 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-16-16/adapters_256_slots_64_rate_1.6-0.4-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-16-16/adapters_256_slots_64_rate_1.6-0.4-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 270, 17280, 17280, 270, 17280, 4320, 17280, 270, 4320, 270, 17280, 4320, 4320, 4320, 4320, 17280, 270, 270, 270, 4320, 17280, 270, 17280, 17280, 4320, 4320, 4320, 270, 17280, 270, 4320, 4320, 270, 4320, 270, 270, 4320, 4320, 17280, 4320, 270, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 270, 17280, 17280, 4320, 270, 270, 17280, 4320, 270, 4320, 4320, 17280, 4320, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 4320, 270, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 270, 17280, 17280, 270, 17280, 270, 4320, 17280, 17280, 17280, 4320, 270, 17280, 4320, 270, 270, 270, 270, 270, 17280, 4320, 270, 17280, 270, 17280, 270, 270, 4320, 4320, 17280, 4320, 17280, 270, 4320, 270, 17280, 17280, 270, 17280, 4320, 270, 17280, 270, 270, 17280, 17280, 4320, 17280, 17280, 270, 17280, 4320, 4320, 270, 4320, 17280, 17280, 270, 17280, 4320, 270, 4320, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 4320, 17280, 17280, 4320, 270, 17280, 270, 4320, 4320, 270, 4320, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 4320, 17280, 4320, 270, 4320, 17280, 4320, 17280, 270, 17280, 270, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 270, 17280, 270, 17280, 4320, 4320, 270, 4320, 17280, 4320, 4320, 17280, 270, 17280, 17280, 4320, 270, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 270, 17280, 4320, 17280, 17280, 270, 17280, 4320, 4320, 17280, 270, 4320, 270, 270, 270, 270, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 270, 270, 270, 270]
Prompts retrieved: 1876230 . Total input tokens: 418371695 . Total output tokens: 375262201
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 104.34095739107579,
    "estimated_duration": 3600.020781638072,
    "input_throughput": 6286.270378056716,
    "output_throughput": 5526.143377135667,
    "total_throughput": 11812.413755192383,
    "itl": 153.87501247434284,
    "ttft": 1976006.5852314366,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 354,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1083264332450937,
    "arrivals": 625482,
    "finished_requests": 91287,
    "scheduler_time": 161.1543952146548
}
#Debug simulation 
Total elapsed time: 104.34116223687306. Arrivals time: 1.095549514517188 Scheduler time: 103.02306688157842 Scheduler overhead time: 0.08796500507742167 Adapter cache time: 0.0222222744487226 Engine time: 0.08568570809438825 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-16-32/adapters_256_slots_64_rate_1.6-0.4-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-16-32/adapters_256_slots_64_rate_1.6-0.4-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 270, 17280, 17280, 270, 17280, 4320, 17280, 270, 4320, 270, 17280, 4320, 4320, 4320, 4320, 17280, 270, 270, 270, 4320, 17280, 270, 17280, 17280, 4320, 4320, 4320, 270, 17280, 270, 4320, 4320, 270, 4320, 270, 270, 4320, 4320, 17280, 4320, 270, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 270, 17280, 17280, 4320, 270, 270, 17280, 4320, 270, 4320, 4320, 17280, 4320, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 4320, 270, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 270, 17280, 17280, 270, 17280, 270, 4320, 17280, 17280, 17280, 4320, 270, 17280, 4320, 270, 270, 270, 270, 270, 17280, 4320, 270, 17280, 270, 17280, 270, 270, 4320, 4320, 17280, 4320, 17280, 270, 4320, 270, 17280, 17280, 270, 17280, 4320, 270, 17280, 270, 270, 17280, 17280, 4320, 17280, 17280, 270, 17280, 4320, 4320, 270, 4320, 17280, 17280, 270, 17280, 4320, 270, 4320, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 4320, 17280, 17280, 4320, 270, 17280, 270, 4320, 4320, 270, 4320, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 4320, 17280, 4320, 270, 4320, 17280, 4320, 17280, 270, 17280, 270, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 270, 17280, 270, 17280, 4320, 4320, 270, 4320, 17280, 4320, 4320, 17280, 270, 17280, 17280, 4320, 270, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 270, 17280, 4320, 17280, 17280, 270, 17280, 4320, 4320, 17280, 270, 4320, 270, 270, 270, 270, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 270, 270, 270, 270]
Prompts retrieved: 1876230 . Total input tokens: 418371695 . Total output tokens: 375262201
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 110.02699632011354,
    "estimated_duration": 3600.1031374668783,
    "input_throughput": 6291.73002413973,
    "output_throughput": 5533.009538725545,
    "total_throughput": 11824.739562865276,
    "itl": 154.5396738957065,
    "ttft": 1976682.269561331,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 391,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2958602019399441,
    "arrivals": 625482,
    "finished_requests": 91412,
    "scheduler_time": 160.72880600013528
}
#Debug simulation 
Total elapsed time: 110.02716128295287. Arrivals time: 1.0431990753859282 Scheduler time: 108.75273910071701 Scheduler overhead time: 0.09209738671779633 Adapter cache time: 0.022843585815280676 Engine time: 0.08911091880872846 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_16-16-16/adapters_256_slots_64_rate_1.6-0.4-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_16-16-16/adapters_256_slots_64_rate_1.6-0.4-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 270, 17280, 17280, 270, 17280, 4320, 17280, 270, 4320, 270, 17280, 4320, 4320, 4320, 4320, 17280, 270, 270, 270, 4320, 17280, 270, 17280, 17280, 4320, 4320, 4320, 270, 17280, 270, 4320, 4320, 270, 4320, 270, 270, 4320, 4320, 17280, 4320, 270, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 270, 17280, 17280, 4320, 270, 270, 17280, 4320, 270, 4320, 4320, 17280, 4320, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 4320, 270, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 270, 17280, 17280, 270, 17280, 270, 4320, 17280, 17280, 17280, 4320, 270, 17280, 4320, 270, 270, 270, 270, 270, 17280, 4320, 270, 17280, 270, 17280, 270, 270, 4320, 4320, 17280, 4320, 17280, 270, 4320, 270, 17280, 17280, 270, 17280, 4320, 270, 17280, 270, 270, 17280, 17280, 4320, 17280, 17280, 270, 17280, 4320, 4320, 270, 4320, 17280, 17280, 270, 17280, 4320, 270, 4320, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 4320, 17280, 17280, 4320, 270, 17280, 270, 4320, 4320, 270, 4320, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 4320, 17280, 4320, 270, 4320, 17280, 4320, 17280, 270, 17280, 270, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 270, 17280, 270, 17280, 4320, 4320, 270, 4320, 17280, 4320, 4320, 17280, 270, 17280, 17280, 4320, 270, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 270, 17280, 4320, 17280, 17280, 270, 17280, 4320, 4320, 17280, 270, 4320, 270, 270, 270, 270, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 270, 270, 270, 270]
Prompts retrieved: 1876230 . Total input tokens: 418371695 . Total output tokens: 375262201
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 106.67601784225553,
    "estimated_duration": 3600.1566026147075,
    "input_throughput": 6285.983221830959,
    "output_throughput": 5525.375197721332,
    "total_throughput": 11811.358419552293,
    "itl": 153.8896524019844,
    "ttft": 1975873.2552764828,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 357,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0674479552800757,
    "arrivals": 625482,
    "finished_requests": 91280,
    "scheduler_time": 161.14875503460652
}
#Debug simulation 
Total elapsed time: 106.67618345096707. Arrivals time: 1.037014551460743 Scheduler time: 105.41197244776413 Scheduler overhead time: 0.09073262568563223 Adapter cache time: 0.021213584579527378 Engine time: 0.08828181633725762 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_16-16-32/adapters_256_slots_64_rate_1.6-0.4-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_16-16-32/adapters_256_slots_64_rate_1.6-0.4-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 270, 17280, 17280, 270, 17280, 4320, 17280, 270, 4320, 270, 17280, 4320, 4320, 4320, 4320, 17280, 270, 270, 270, 4320, 17280, 270, 17280, 17280, 4320, 4320, 4320, 270, 17280, 270, 4320, 4320, 270, 4320, 270, 270, 4320, 4320, 17280, 4320, 270, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 270, 17280, 17280, 4320, 270, 270, 17280, 4320, 270, 4320, 4320, 17280, 4320, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 4320, 270, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 270, 17280, 17280, 270, 17280, 270, 4320, 17280, 17280, 17280, 4320, 270, 17280, 4320, 270, 270, 270, 270, 270, 17280, 4320, 270, 17280, 270, 17280, 270, 270, 4320, 4320, 17280, 4320, 17280, 270, 4320, 270, 17280, 17280, 270, 17280, 4320, 270, 17280, 270, 270, 17280, 17280, 4320, 17280, 17280, 270, 17280, 4320, 4320, 270, 4320, 17280, 17280, 270, 17280, 4320, 270, 4320, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 4320, 17280, 17280, 4320, 270, 17280, 270, 4320, 4320, 270, 4320, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 4320, 17280, 4320, 270, 4320, 17280, 4320, 17280, 270, 17280, 270, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 270, 17280, 270, 17280, 4320, 4320, 270, 4320, 17280, 4320, 4320, 17280, 270, 17280, 17280, 4320, 270, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 270, 17280, 4320, 17280, 17280, 270, 17280, 4320, 4320, 17280, 270, 4320, 270, 270, 270, 270, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 270, 270, 270, 270]
Prompts retrieved: 1876230 . Total input tokens: 418371695 . Total output tokens: 375262201
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 107.48122163303196,
    "estimated_duration": 3600.1182499419033,
    "input_throughput": 6291.703612892584,
    "output_throughput": 5532.98631241389,
    "total_throughput": 11824.689925306475,
    "itl": 154.5400866495569,
    "ttft": 1976687.4075724098,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 391,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3127112093195337,
    "arrivals": 625482,
    "finished_requests": 91412,
    "scheduler_time": 160.72887756092538
}
#Debug simulation 
Total elapsed time: 107.4815345061943. Arrivals time: 1.2074084137566388 Scheduler time: 106.04694482777268 Scheduler overhead time: 0.08904664125293493 Adapter cache time: 0.023645238019526005 Engine time: 0.08771892823278904 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-8/adapters_256_slots_64_rate_1.6-0.4-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-8/adapters_256_slots_64_rate_1.6-0.4-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 135, 17280, 17280, 135, 17280, 4320, 17280, 135, 4320, 135, 17280, 4320, 4320, 4320, 4320, 17280, 135, 135, 135, 4320, 17280, 135, 17280, 17280, 4320, 4320, 4320, 135, 17280, 135, 4320, 4320, 135, 4320, 135, 135, 4320, 4320, 17280, 4320, 135, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 135, 17280, 17280, 4320, 135, 135, 17280, 4320, 135, 4320, 4320, 17280, 4320, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 4320, 135, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 135, 17280, 17280, 135, 17280, 135, 4320, 17280, 17280, 17280, 4320, 135, 17280, 4320, 135, 135, 135, 135, 135, 17280, 4320, 135, 17280, 135, 17280, 135, 135, 4320, 4320, 17280, 4320, 17280, 135, 4320, 135, 17280, 17280, 135, 17280, 4320, 135, 17280, 135, 135, 17280, 17280, 4320, 17280, 17280, 135, 17280, 4320, 4320, 135, 4320, 17280, 17280, 135, 17280, 4320, 135, 4320, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 4320, 17280, 17280, 4320, 135, 17280, 135, 4320, 4320, 135, 4320, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 4320, 17280, 4320, 135, 4320, 17280, 4320, 17280, 135, 17280, 135, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 135, 17280, 135, 17280, 4320, 4320, 135, 4320, 17280, 4320, 4320, 17280, 135, 17280, 17280, 4320, 135, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 135, 17280, 4320, 17280, 17280, 135, 17280, 4320, 4320, 17280, 135, 4320, 135, 135, 135, 135, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 135, 135, 135, 135]
Prompts retrieved: 1864755 . Total input tokens: 415800092 . Total output tokens: 372975680
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 112.87184647331014,
    "estimated_duration": 3600.100715173682,
    "input_throughput": 6283.269494283775,
    "output_throughput": 5529.792518329469,
    "total_throughput": 11813.062012613245,
    "itl": 154.60377940782334,
    "ttft": 1957335.8159234573,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 403,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2333765608049065,
    "arrivals": 621618,
    "finished_requests": 91518,
    "scheduler_time": 160.80893593344987
}
#Debug simulation 
Total elapsed time: 112.87204074393958. Arrivals time: 0.8106160736642778 Scheduler time: 111.82429639110342 Scheduler overhead time: 0.093665502499789 Adapter cache time: 0.023768347688019276 Engine time: 0.09069900121539831 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-16/adapters_256_slots_64_rate_1.6-0.4-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-16/adapters_256_slots_64_rate_1.6-0.4-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 135, 17280, 17280, 135, 17280, 4320, 17280, 135, 4320, 135, 17280, 4320, 4320, 4320, 4320, 17280, 135, 135, 135, 4320, 17280, 135, 17280, 17280, 4320, 4320, 4320, 135, 17280, 135, 4320, 4320, 135, 4320, 135, 135, 4320, 4320, 17280, 4320, 135, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 135, 17280, 17280, 4320, 135, 135, 17280, 4320, 135, 4320, 4320, 17280, 4320, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 4320, 135, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 135, 17280, 17280, 135, 17280, 135, 4320, 17280, 17280, 17280, 4320, 135, 17280, 4320, 135, 135, 135, 135, 135, 17280, 4320, 135, 17280, 135, 17280, 135, 135, 4320, 4320, 17280, 4320, 17280, 135, 4320, 135, 17280, 17280, 135, 17280, 4320, 135, 17280, 135, 135, 17280, 17280, 4320, 17280, 17280, 135, 17280, 4320, 4320, 135, 4320, 17280, 17280, 135, 17280, 4320, 135, 4320, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 4320, 17280, 17280, 4320, 135, 17280, 135, 4320, 4320, 135, 4320, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 4320, 17280, 4320, 135, 4320, 17280, 4320, 17280, 135, 17280, 135, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 135, 17280, 135, 17280, 4320, 4320, 135, 4320, 17280, 4320, 4320, 17280, 135, 17280, 17280, 4320, 135, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 135, 17280, 4320, 17280, 17280, 135, 17280, 4320, 4320, 17280, 135, 4320, 135, 135, 135, 135, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 135, 135, 135, 135]
Prompts retrieved: 1864755 . Total input tokens: 415800092 . Total output tokens: 372975680
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 112.49142279708758,
    "estimated_duration": 3600.074249284214,
    "input_throughput": 6291.132746637963,
    "output_throughput": 5533.899197762681,
    "total_throughput": 11825.031944400644,
    "itl": 154.6675442275358,
    "ttft": 1958335.3072765248,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 415,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3536431802739441,
    "arrivals": 621618,
    "finished_requests": 91608,
    "scheduler_time": 160.74331870164312
}
#Debug simulation 
Total elapsed time: 112.49159714067355. Arrivals time: 0.8106162287294865 Scheduler time: 111.44201195146888 Scheduler overhead time: 0.09328102273866534 Adapter cache time: 0.025618286803364754 Engine time: 0.0920123984105885 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-32/adapters_256_slots_64_rate_1.6-0.4-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-32/adapters_256_slots_64_rate_1.6-0.4-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 135, 17280, 17280, 135, 17280, 4320, 17280, 135, 4320, 135, 17280, 4320, 4320, 4320, 4320, 17280, 135, 135, 135, 4320, 17280, 135, 17280, 17280, 4320, 4320, 4320, 135, 17280, 135, 4320, 4320, 135, 4320, 135, 135, 4320, 4320, 17280, 4320, 135, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 135, 17280, 17280, 4320, 135, 135, 17280, 4320, 135, 4320, 4320, 17280, 4320, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 4320, 135, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 135, 17280, 17280, 135, 17280, 135, 4320, 17280, 17280, 17280, 4320, 135, 17280, 4320, 135, 135, 135, 135, 135, 17280, 4320, 135, 17280, 135, 17280, 135, 135, 4320, 4320, 17280, 4320, 17280, 135, 4320, 135, 17280, 17280, 135, 17280, 4320, 135, 17280, 135, 135, 17280, 17280, 4320, 17280, 17280, 135, 17280, 4320, 4320, 135, 4320, 17280, 17280, 135, 17280, 4320, 135, 4320, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 4320, 17280, 17280, 4320, 135, 17280, 135, 4320, 4320, 135, 4320, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 4320, 17280, 4320, 135, 4320, 17280, 4320, 17280, 135, 17280, 135, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 135, 17280, 135, 17280, 4320, 4320, 135, 4320, 17280, 4320, 4320, 17280, 135, 17280, 17280, 4320, 135, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 135, 17280, 4320, 17280, 17280, 135, 17280, 4320, 4320, 17280, 135, 4320, 135, 135, 135, 135, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 135, 135, 135, 135]
Prompts retrieved: 1864755 . Total input tokens: 415800092 . Total output tokens: 372975680
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 112.4663598430343,
    "estimated_duration": 3600.0767622726066,
    "input_throughput": 6291.128355191721,
    "output_throughput": 5533.895334893813,
    "total_throughput": 11825.023690085534,
    "itl": 154.6676262346152,
    "ttft": 1958336.4264460453,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 415,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3561406307295043,
    "arrivals": 621618,
    "finished_requests": 91608,
    "scheduler_time": 160.74333423957808
}
#Debug simulation 
Total elapsed time: 112.46667774580419. Arrivals time: 0.7453538780100644 Scheduler time: 111.48373250244185 Scheduler overhead time: 0.09435792174190283 Adapter cache time: 0.023866906762123108 Engine time: 0.09130447963252664 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-16-16/adapters_256_slots_64_rate_1.6-0.4-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-16-16/adapters_256_slots_64_rate_1.6-0.4-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 135, 17280, 17280, 135, 17280, 4320, 17280, 135, 4320, 135, 17280, 4320, 4320, 4320, 4320, 17280, 135, 135, 135, 4320, 17280, 135, 17280, 17280, 4320, 4320, 4320, 135, 17280, 135, 4320, 4320, 135, 4320, 135, 135, 4320, 4320, 17280, 4320, 135, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 135, 17280, 17280, 4320, 135, 135, 17280, 4320, 135, 4320, 4320, 17280, 4320, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 4320, 135, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 135, 17280, 17280, 135, 17280, 135, 4320, 17280, 17280, 17280, 4320, 135, 17280, 4320, 135, 135, 135, 135, 135, 17280, 4320, 135, 17280, 135, 17280, 135, 135, 4320, 4320, 17280, 4320, 17280, 135, 4320, 135, 17280, 17280, 135, 17280, 4320, 135, 17280, 135, 135, 17280, 17280, 4320, 17280, 17280, 135, 17280, 4320, 4320, 135, 4320, 17280, 17280, 135, 17280, 4320, 135, 4320, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 4320, 17280, 17280, 4320, 135, 17280, 135, 4320, 4320, 135, 4320, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 4320, 17280, 4320, 135, 4320, 17280, 4320, 17280, 135, 17280, 135, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 135, 17280, 135, 17280, 4320, 4320, 135, 4320, 17280, 4320, 4320, 17280, 135, 17280, 17280, 4320, 135, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 135, 17280, 4320, 17280, 17280, 135, 17280, 4320, 4320, 17280, 135, 4320, 135, 135, 135, 135, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 135, 135, 135, 135]
Prompts retrieved: 1864755 . Total input tokens: 415800092 . Total output tokens: 372975680
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 109.66254060110077,
    "estimated_duration": 3600.0516919345264,
    "input_throughput": 6291.635214779004,
    "output_throughput": 5536.159673665728,
    "total_throughput": 11827.794888444732,
    "itl": 154.63836542302693,
    "ttft": 1958980.0245334134,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 385,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2034695642977025,
    "arrivals": 621618,
    "finished_requests": 91627,
    "scheduler_time": 160.75005810802767
}
#Debug simulation 
Total elapsed time: 109.66271711327136. Arrivals time: 0.7947711870074272 Scheduler time: 108.63295526010916 Scheduler overhead time: 0.09308600751683116 Adapter cache time: 0.02404522756114602 Engine time: 0.09019743604585528 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-16-32/adapters_256_slots_64_rate_1.6-0.4-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-16-32/adapters_256_slots_64_rate_1.6-0.4-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 135, 17280, 17280, 135, 17280, 4320, 17280, 135, 4320, 135, 17280, 4320, 4320, 4320, 4320, 17280, 135, 135, 135, 4320, 17280, 135, 17280, 17280, 4320, 4320, 4320, 135, 17280, 135, 4320, 4320, 135, 4320, 135, 135, 4320, 4320, 17280, 4320, 135, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 135, 17280, 17280, 4320, 135, 135, 17280, 4320, 135, 4320, 4320, 17280, 4320, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 4320, 135, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 135, 17280, 17280, 135, 17280, 135, 4320, 17280, 17280, 17280, 4320, 135, 17280, 4320, 135, 135, 135, 135, 135, 17280, 4320, 135, 17280, 135, 17280, 135, 135, 4320, 4320, 17280, 4320, 17280, 135, 4320, 135, 17280, 17280, 135, 17280, 4320, 135, 17280, 135, 135, 17280, 17280, 4320, 17280, 17280, 135, 17280, 4320, 4320, 135, 4320, 17280, 17280, 135, 17280, 4320, 135, 4320, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 4320, 17280, 17280, 4320, 135, 17280, 135, 4320, 4320, 135, 4320, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 4320, 17280, 4320, 135, 4320, 17280, 4320, 17280, 135, 17280, 135, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 135, 17280, 135, 17280, 4320, 4320, 135, 4320, 17280, 4320, 4320, 17280, 135, 17280, 17280, 4320, 135, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 135, 17280, 4320, 17280, 17280, 135, 17280, 4320, 4320, 17280, 135, 4320, 135, 135, 135, 135, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 135, 135, 135, 135]
Prompts retrieved: 1864755 . Total input tokens: 415800092 . Total output tokens: 372975680
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 116.12760940100998,
    "estimated_duration": 3600.1169266013285,
    "input_throughput": 6285.675565921951,
    "output_throughput": 5532.594747916555,
    "total_throughput": 11818.270313838506,
    "itl": 154.6879564692821,
    "ttft": 1955615.9548068515,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 390,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2908789380453578,
    "arrivals": 621618,
    "finished_requests": 91534,
    "scheduler_time": 160.73057003471106
}
#Debug simulation 
Total elapsed time: 116.12776268878952. Arrivals time: 0.77641666168347 Scheduler time: 115.1127483160235 Scheduler overhead time: 0.09578398428857327 Adapter cache time: 0.02445861417800188 Engine time: 0.09145401977002621 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_16-16-16/adapters_256_slots_64_rate_1.6-0.4-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_16-16-16/adapters_256_slots_64_rate_1.6-0.4-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 135, 17280, 17280, 135, 17280, 4320, 17280, 135, 4320, 135, 17280, 4320, 4320, 4320, 4320, 17280, 135, 135, 135, 4320, 17280, 135, 17280, 17280, 4320, 4320, 4320, 135, 17280, 135, 4320, 4320, 135, 4320, 135, 135, 4320, 4320, 17280, 4320, 135, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 135, 17280, 17280, 4320, 135, 135, 17280, 4320, 135, 4320, 4320, 17280, 4320, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 4320, 135, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 135, 17280, 17280, 135, 17280, 135, 4320, 17280, 17280, 17280, 4320, 135, 17280, 4320, 135, 135, 135, 135, 135, 17280, 4320, 135, 17280, 135, 17280, 135, 135, 4320, 4320, 17280, 4320, 17280, 135, 4320, 135, 17280, 17280, 135, 17280, 4320, 135, 17280, 135, 135, 17280, 17280, 4320, 17280, 17280, 135, 17280, 4320, 4320, 135, 4320, 17280, 17280, 135, 17280, 4320, 135, 4320, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 4320, 17280, 17280, 4320, 135, 17280, 135, 4320, 4320, 135, 4320, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 4320, 17280, 4320, 135, 4320, 17280, 4320, 17280, 135, 17280, 135, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 135, 17280, 135, 17280, 4320, 4320, 135, 4320, 17280, 4320, 4320, 17280, 135, 17280, 17280, 4320, 135, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 135, 17280, 4320, 17280, 17280, 135, 17280, 4320, 4320, 17280, 135, 4320, 135, 135, 135, 135, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 135, 135, 135, 135]
Prompts retrieved: 1864755 . Total input tokens: 415800092 . Total output tokens: 372975680
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 113.81583021394908,
    "estimated_duration": 3600.068047015623,
    "input_throughput": 6283.326510661879,
    "output_throughput": 5529.842697418771,
    "total_throughput": 11813.16920808065,
    "itl": 154.60271592399806,
    "ttft": 1957319.1747996944,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 403,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.204990268845571,
    "arrivals": 621618,
    "finished_requests": 91518,
    "scheduler_time": 160.80861023402423
}
#Debug simulation 
Total elapsed time: 113.81600663717836. Arrivals time: 0.7697372590191662 Scheduler time: 112.80574786104262 Scheduler overhead time: 0.0949503080919385 Adapter cache time: 0.02454192517325282 Engine time: 0.09294640040025115 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_16-16-32/adapters_256_slots_64_rate_1.6-0.4-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_16-16-32/adapters_256_slots_64_rate_1.6-0.4-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 135, 17280, 17280, 135, 17280, 4320, 17280, 135, 4320, 135, 17280, 4320, 4320, 4320, 4320, 17280, 135, 135, 135, 4320, 17280, 135, 17280, 17280, 4320, 4320, 4320, 135, 17280, 135, 4320, 4320, 135, 4320, 135, 135, 4320, 4320, 17280, 4320, 135, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 135, 17280, 17280, 4320, 135, 135, 17280, 4320, 135, 4320, 4320, 17280, 4320, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 4320, 135, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 135, 17280, 17280, 135, 17280, 135, 4320, 17280, 17280, 17280, 4320, 135, 17280, 4320, 135, 135, 135, 135, 135, 17280, 4320, 135, 17280, 135, 17280, 135, 135, 4320, 4320, 17280, 4320, 17280, 135, 4320, 135, 17280, 17280, 135, 17280, 4320, 135, 17280, 135, 135, 17280, 17280, 4320, 17280, 17280, 135, 17280, 4320, 4320, 135, 4320, 17280, 17280, 135, 17280, 4320, 135, 4320, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 4320, 17280, 17280, 4320, 135, 17280, 135, 4320, 4320, 135, 4320, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 4320, 17280, 4320, 135, 4320, 17280, 4320, 17280, 135, 17280, 135, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 135, 17280, 135, 17280, 4320, 4320, 135, 4320, 17280, 4320, 4320, 17280, 135, 17280, 17280, 4320, 135, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 135, 17280, 4320, 17280, 17280, 135, 17280, 4320, 4320, 17280, 135, 4320, 135, 135, 135, 135, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 135, 135, 135, 135]
Prompts retrieved: 1864755 . Total input tokens: 415800092 . Total output tokens: 372975680
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 116.25555115099996,
    "estimated_duration": 3600.138485968905,
    "input_throughput": 6285.637924261631,
    "output_throughput": 5532.561616067797,
    "total_throughput": 11818.19954032943,
    "itl": 154.68860874688158,
    "ttft": 1955627.2580074773,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 390,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.307352684065702,
    "arrivals": 621618,
    "finished_requests": 91534,
    "scheduler_time": 160.730873388065
}
#Debug simulation 
Total elapsed time: 116.25572795467451. Arrivals time: 0.7803599396720529 Scheduler time: 115.23792956303805 Scheduler overhead time: 0.094081811606884 Adapter cache time: 0.023659745696932077 Engine time: 0.09247620590031147 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-8/adapters_256_slots_64_rate_1.6-0.4-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-8/adapters_256_slots_64_rate_1.6-0.4-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 66, 17280, 17280, 66, 17280, 4320, 17280, 66, 4320, 66, 17280, 4320, 4320, 4320, 4320, 17280, 66, 66, 66, 4320, 17280, 66, 17280, 17280, 4320, 4320, 4320, 66, 17280, 66, 4320, 4320, 66, 4320, 66, 66, 4320, 4320, 17280, 4320, 66, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 66, 17280, 17280, 4320, 66, 66, 17280, 4320, 66, 4320, 4320, 17280, 4320, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 4320, 66, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 66, 17280, 17280, 66, 17280, 66, 4320, 17280, 17280, 17280, 4320, 66, 17280, 4320, 66, 66, 66, 66, 66, 17280, 4320, 66, 17280, 66, 17280, 66, 66, 4320, 4320, 17280, 4320, 17280, 66, 4320, 66, 17280, 17280, 66, 17280, 4320, 66, 17280, 66, 66, 17280, 17280, 4320, 17280, 17280, 66, 17280, 4320, 4320, 66, 4320, 17280, 17280, 66, 17280, 4320, 66, 4320, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 4320, 17280, 17280, 4320, 66, 17280, 66, 4320, 4320, 66, 4320, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 4320, 17280, 4320, 66, 4320, 17280, 4320, 17280, 66, 17280, 66, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 66, 17280, 66, 17280, 4320, 4320, 66, 4320, 17280, 4320, 4320, 17280, 66, 17280, 17280, 4320, 66, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 66, 17280, 4320, 17280, 17280, 66, 17280, 4320, 4320, 17280, 66, 4320, 66, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 66, 66, 66, 66]
Prompts retrieved: 1858890 . Total input tokens: 414477948 . Total output tokens: 371780131
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 117.40980707621202,
    "estimated_duration": 3600.056318050785,
    "input_throughput": 6299.709781284612,
    "output_throughput": 5557.213341271339,
    "total_throughput": 11856.923122555952,
    "itl": 153.99388361970628,
    "ttft": 1960554.3894903413,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 493,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.508820457758864,
    "arrivals": 619780,
    "finished_requests": 91463,
    "scheduler_time": 161.54361534044793
}
#Debug simulation 
Total elapsed time: 117.40997004695237. Arrivals time: 0.7626419779844582 Scheduler time: 116.39986947458237 Scheduler overhead time: 0.10006398102268577 Adapter cache time: 0.024940076749771833 Engine time: 0.093584512360394 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-16/adapters_256_slots_64_rate_1.6-0.4-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-16/adapters_256_slots_64_rate_1.6-0.4-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 66, 17280, 17280, 66, 17280, 4320, 17280, 66, 4320, 66, 17280, 4320, 4320, 4320, 4320, 17280, 66, 66, 66, 4320, 17280, 66, 17280, 17280, 4320, 4320, 4320, 66, 17280, 66, 4320, 4320, 66, 4320, 66, 66, 4320, 4320, 17280, 4320, 66, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 66, 17280, 17280, 4320, 66, 66, 17280, 4320, 66, 4320, 4320, 17280, 4320, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 4320, 66, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 66, 17280, 17280, 66, 17280, 66, 4320, 17280, 17280, 17280, 4320, 66, 17280, 4320, 66, 66, 66, 66, 66, 17280, 4320, 66, 17280, 66, 17280, 66, 66, 4320, 4320, 17280, 4320, 17280, 66, 4320, 66, 17280, 17280, 66, 17280, 4320, 66, 17280, 66, 66, 17280, 17280, 4320, 17280, 17280, 66, 17280, 4320, 4320, 66, 4320, 17280, 17280, 66, 17280, 4320, 66, 4320, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 4320, 17280, 17280, 4320, 66, 17280, 66, 4320, 4320, 66, 4320, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 4320, 17280, 4320, 66, 4320, 17280, 4320, 17280, 66, 17280, 66, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 66, 17280, 66, 17280, 4320, 4320, 66, 4320, 17280, 4320, 4320, 17280, 66, 17280, 17280, 4320, 66, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 66, 17280, 4320, 17280, 17280, 66, 17280, 4320, 4320, 17280, 66, 4320, 66, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 66, 66, 66, 66]
Prompts retrieved: 1858890 . Total input tokens: 414477948 . Total output tokens: 371780131
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 99.70563574507833,
    "estimated_duration": 3600.1256253626484,
    "input_throughput": 6275.8951634428195,
    "output_throughput": 5536.526519957811,
    "total_throughput": 11812.42168340063,
    "itl": 153.98374994302043,
    "ttft": 1971959.8480384857,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 525,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7074730271380432,
    "arrivals": 619780,
    "finished_requests": 91245,
    "scheduler_time": 161.32940817860526
}
#Debug simulation 
Total elapsed time: 99.70584437297657. Arrivals time: 0.7592965201474726 Scheduler time: 98.72091807797551 Scheduler overhead time: 0.08806323958560824 Adapter cache time: 0.02399206906557083 Engine time: 0.08581664599478245 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-32/adapters_256_slots_64_rate_1.6-0.4-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-32/adapters_256_slots_64_rate_1.6-0.4-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 66, 17280, 17280, 66, 17280, 4320, 17280, 66, 4320, 66, 17280, 4320, 4320, 4320, 4320, 17280, 66, 66, 66, 4320, 17280, 66, 17280, 17280, 4320, 4320, 4320, 66, 17280, 66, 4320, 4320, 66, 4320, 66, 66, 4320, 4320, 17280, 4320, 66, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 66, 17280, 17280, 4320, 66, 66, 17280, 4320, 66, 4320, 4320, 17280, 4320, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 4320, 66, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 66, 17280, 17280, 66, 17280, 66, 4320, 17280, 17280, 17280, 4320, 66, 17280, 4320, 66, 66, 66, 66, 66, 17280, 4320, 66, 17280, 66, 17280, 66, 66, 4320, 4320, 17280, 4320, 17280, 66, 4320, 66, 17280, 17280, 66, 17280, 4320, 66, 17280, 66, 66, 17280, 17280, 4320, 17280, 17280, 66, 17280, 4320, 4320, 66, 4320, 17280, 17280, 66, 17280, 4320, 66, 4320, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 4320, 17280, 17280, 4320, 66, 17280, 66, 4320, 4320, 66, 4320, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 4320, 17280, 4320, 66, 4320, 17280, 4320, 17280, 66, 17280, 66, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 66, 17280, 66, 17280, 4320, 4320, 66, 4320, 17280, 4320, 4320, 17280, 66, 17280, 17280, 4320, 66, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 66, 17280, 4320, 17280, 17280, 66, 17280, 4320, 4320, 17280, 66, 4320, 66, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 66, 66, 66, 66]
Prompts retrieved: 1858890 . Total input tokens: 414477948 . Total output tokens: 371780131
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 98.89901968371123,
    "estimated_duration": 3600.1305530823556,
    "input_throughput": 6275.886573239819,
    "output_throughput": 5536.518941774064,
    "total_throughput": 11812.405515013883,
    "itl": 153.98377298274812,
    "ttft": 1971961.8916993514,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 525,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7114998012594982,
    "arrivals": 619780,
    "finished_requests": 91245,
    "scheduler_time": 161.32946035925346
}
#Debug simulation 
Total elapsed time: 98.899232392665. Arrivals time: 0.7902286844328046 Scheduler time: 97.87611741060391 Scheduler overhead time: 0.09212685190141201 Adapter cache time: 0.024342136923223734 Engine time: 0.08906182553619146 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-16-16/adapters_256_slots_64_rate_1.6-0.4-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-16-16/adapters_256_slots_64_rate_1.6-0.4-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 66, 17280, 17280, 66, 17280, 4320, 17280, 66, 4320, 66, 17280, 4320, 4320, 4320, 4320, 17280, 66, 66, 66, 4320, 17280, 66, 17280, 17280, 4320, 4320, 4320, 66, 17280, 66, 4320, 4320, 66, 4320, 66, 66, 4320, 4320, 17280, 4320, 66, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 66, 17280, 17280, 4320, 66, 66, 17280, 4320, 66, 4320, 4320, 17280, 4320, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 4320, 66, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 66, 17280, 17280, 66, 17280, 66, 4320, 17280, 17280, 17280, 4320, 66, 17280, 4320, 66, 66, 66, 66, 66, 17280, 4320, 66, 17280, 66, 17280, 66, 66, 4320, 4320, 17280, 4320, 17280, 66, 4320, 66, 17280, 17280, 66, 17280, 4320, 66, 17280, 66, 66, 17280, 17280, 4320, 17280, 17280, 66, 17280, 4320, 4320, 66, 4320, 17280, 17280, 66, 17280, 4320, 66, 4320, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 4320, 17280, 17280, 4320, 66, 17280, 66, 4320, 4320, 66, 4320, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 4320, 17280, 4320, 66, 4320, 17280, 4320, 17280, 66, 17280, 66, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 66, 17280, 66, 17280, 4320, 4320, 66, 4320, 17280, 4320, 4320, 17280, 66, 17280, 17280, 4320, 66, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 66, 17280, 4320, 17280, 17280, 66, 17280, 4320, 4320, 17280, 66, 4320, 66, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 66, 66, 66, 66]
Prompts retrieved: 1858890 . Total input tokens: 414477948 . Total output tokens: 371780131
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 113.48062680196017,
    "estimated_duration": 3600.0734942693584,
    "input_throughput": 6300.875256049094,
    "output_throughput": 5556.364899728168,
    "total_throughput": 11857.240155777263,
    "itl": 153.9136268233585,
    "ttft": 1962741.6036511716,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 519,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6225230931444026,
    "arrivals": 619780,
    "finished_requests": 91509,
    "scheduler_time": 161.55670163332067
}
#Debug simulation 
Total elapsed time: 113.48083467409015. Arrivals time: 0.755107341799885 Scheduler time: 112.48700661072508 Scheduler overhead time: 0.09498470602557063 Adapter cache time: 0.025991002563387156 Engine time: 0.09019190166145563 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-16-32/adapters_256_slots_64_rate_1.6-0.4-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-16-32/adapters_256_slots_64_rate_1.6-0.4-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 66, 17280, 17280, 66, 17280, 4320, 17280, 66, 4320, 66, 17280, 4320, 4320, 4320, 4320, 17280, 66, 66, 66, 4320, 17280, 66, 17280, 17280, 4320, 4320, 4320, 66, 17280, 66, 4320, 4320, 66, 4320, 66, 66, 4320, 4320, 17280, 4320, 66, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 66, 17280, 17280, 4320, 66, 66, 17280, 4320, 66, 4320, 4320, 17280, 4320, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 4320, 66, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 66, 17280, 17280, 66, 17280, 66, 4320, 17280, 17280, 17280, 4320, 66, 17280, 4320, 66, 66, 66, 66, 66, 17280, 4320, 66, 17280, 66, 17280, 66, 66, 4320, 4320, 17280, 4320, 17280, 66, 4320, 66, 17280, 17280, 66, 17280, 4320, 66, 17280, 66, 66, 17280, 17280, 4320, 17280, 17280, 66, 17280, 4320, 4320, 66, 4320, 17280, 17280, 66, 17280, 4320, 66, 4320, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 4320, 17280, 17280, 4320, 66, 17280, 66, 4320, 4320, 66, 4320, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 4320, 17280, 4320, 66, 4320, 17280, 4320, 17280, 66, 17280, 66, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 66, 17280, 66, 17280, 4320, 4320, 66, 4320, 17280, 4320, 4320, 17280, 66, 17280, 17280, 4320, 66, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 66, 17280, 4320, 17280, 17280, 66, 17280, 4320, 4320, 17280, 66, 4320, 66, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 66, 66, 66, 66]
Prompts retrieved: 1858890 . Total input tokens: 414477948 . Total output tokens: 371780131
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 96.90864926110953,
    "estimated_duration": 3600.1527833865625,
    "input_throughput": 6275.847820754554,
    "output_throughput": 5536.484754752643,
    "total_throughput": 11812.332575507198,
    "itl": 153.98444793923042,
    "ttft": 1971970.937687757,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 525,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7322491760179446,
    "arrivals": 619780,
    "finished_requests": 91245,
    "scheduler_time": 161.32965242150155
}
#Debug simulation 
Total elapsed time: 96.90881008002907. Arrivals time: 0.723241011146456 Scheduler time: 95.96819470077753 Scheduler overhead time: 0.08544670417904854 Adapter cache time: 0.023421035148203373 Engine time: 0.08208488579839468 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_16-16-16/adapters_256_slots_64_rate_1.6-0.4-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_16-16-16/adapters_256_slots_64_rate_1.6-0.4-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 66, 17280, 17280, 66, 17280, 4320, 17280, 66, 4320, 66, 17280, 4320, 4320, 4320, 4320, 17280, 66, 66, 66, 4320, 17280, 66, 17280, 17280, 4320, 4320, 4320, 66, 17280, 66, 4320, 4320, 66, 4320, 66, 66, 4320, 4320, 17280, 4320, 66, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 66, 17280, 17280, 4320, 66, 66, 17280, 4320, 66, 4320, 4320, 17280, 4320, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 4320, 66, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 66, 17280, 17280, 66, 17280, 66, 4320, 17280, 17280, 17280, 4320, 66, 17280, 4320, 66, 66, 66, 66, 66, 17280, 4320, 66, 17280, 66, 17280, 66, 66, 4320, 4320, 17280, 4320, 17280, 66, 4320, 66, 17280, 17280, 66, 17280, 4320, 66, 17280, 66, 66, 17280, 17280, 4320, 17280, 17280, 66, 17280, 4320, 4320, 66, 4320, 17280, 17280, 66, 17280, 4320, 66, 4320, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 4320, 17280, 17280, 4320, 66, 17280, 66, 4320, 4320, 66, 4320, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 4320, 17280, 4320, 66, 4320, 17280, 4320, 17280, 66, 17280, 66, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 66, 17280, 66, 17280, 4320, 4320, 66, 4320, 17280, 4320, 4320, 17280, 66, 17280, 17280, 4320, 66, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 66, 17280, 4320, 17280, 17280, 66, 17280, 4320, 4320, 17280, 66, 4320, 66, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 66, 66, 66, 66]
Prompts retrieved: 1858890 . Total input tokens: 414477948 . Total output tokens: 371780131
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 122.54638691991568,
    "estimated_duration": 3600.1381117980873,
    "input_throughput": 6265.115753777228,
    "output_throughput": 5534.449063135686,
    "total_throughput": 11799.564816912914,
    "itl": 153.9926451838737,
    "ttft": 1954939.564383117,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 382,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1421992126526275,
    "arrivals": 619780,
    "finished_requests": 91006,
    "scheduler_time": 161.29238614271685
}
#Debug simulation 
Total elapsed time: 122.54655895521864. Arrivals time: 0.811806081328541 Scheduler time: 121.49203112116084 Scheduler overhead time: 0.09710553800687194 Adapter cache time: 0.023587939329445362 Engine time: 0.09433012176305056 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_16-16-32/adapters_256_slots_64_rate_1.6-0.4-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_16-16-32/adapters_256_slots_64_rate_1.6-0.4-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 66, 17280, 17280, 66, 17280, 4320, 17280, 66, 4320, 66, 17280, 4320, 4320, 4320, 4320, 17280, 66, 66, 66, 4320, 17280, 66, 17280, 17280, 4320, 4320, 4320, 66, 17280, 66, 4320, 4320, 66, 4320, 66, 66, 4320, 4320, 17280, 4320, 66, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 66, 17280, 17280, 4320, 66, 66, 17280, 4320, 66, 4320, 4320, 17280, 4320, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 4320, 66, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 66, 17280, 17280, 66, 17280, 66, 4320, 17280, 17280, 17280, 4320, 66, 17280, 4320, 66, 66, 66, 66, 66, 17280, 4320, 66, 17280, 66, 17280, 66, 66, 4320, 4320, 17280, 4320, 17280, 66, 4320, 66, 17280, 17280, 66, 17280, 4320, 66, 17280, 66, 66, 17280, 17280, 4320, 17280, 17280, 66, 17280, 4320, 4320, 66, 4320, 17280, 17280, 66, 17280, 4320, 66, 4320, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 4320, 17280, 17280, 4320, 66, 17280, 66, 4320, 4320, 66, 4320, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 4320, 17280, 4320, 66, 4320, 17280, 4320, 17280, 66, 17280, 66, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 66, 17280, 66, 17280, 4320, 4320, 66, 4320, 17280, 4320, 4320, 17280, 66, 17280, 17280, 4320, 66, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 66, 17280, 4320, 17280, 17280, 66, 17280, 4320, 4320, 17280, 66, 4320, 66, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 66, 66, 66, 66]
Prompts retrieved: 1858890 . Total input tokens: 414477948 . Total output tokens: 371780131
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 79.45437980815768,
    "estimated_duration": 3600.0453051593636,
    "input_throughput": 6286.3722763617225,
    "output_throughput": 5543.831898836761,
    "total_throughput": 11830.204175198483,
    "itl": 154.28043637146786,
    "ttft": 1974098.1759697078,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 522,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7442852694541198,
    "arrivals": 619780,
    "finished_requests": 91311,
    "scheduler_time": 161.20842420760056
}
#Debug simulation 
Total elapsed time: 79.45463967882097. Arrivals time: 0.6929339738562703 Scheduler time: 78.54937892500311 Scheduler overhead time: 0.08350494643673301 Adapter cache time: 0.02255450701341033 Engine time: 0.0799257094040513 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-8/adapters_256_slots_64_rate_1.6-0.4-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-8/adapters_256_slots_64_rate_1.6-0.4-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 33, 17280, 17280, 33, 17280, 4320, 17280, 33, 4320, 33, 17280, 4320, 4320, 4320, 4320, 17280, 33, 33, 33, 4320, 17280, 33, 17280, 17280, 4320, 4320, 4320, 33, 17280, 33, 4320, 4320, 33, 4320, 33, 33, 4320, 4320, 17280, 4320, 33, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 33, 17280, 17280, 4320, 33, 33, 17280, 4320, 33, 4320, 4320, 17280, 4320, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 4320, 33, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 33, 17280, 17280, 33, 17280, 33, 4320, 17280, 17280, 17280, 4320, 33, 17280, 4320, 33, 33, 33, 33, 33, 17280, 4320, 33, 17280, 33, 17280, 33, 33, 4320, 4320, 17280, 4320, 17280, 33, 4320, 33, 17280, 17280, 33, 17280, 4320, 33, 17280, 33, 33, 17280, 17280, 4320, 17280, 17280, 33, 17280, 4320, 4320, 33, 4320, 17280, 17280, 33, 17280, 4320, 33, 4320, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 4320, 17280, 17280, 4320, 33, 17280, 33, 4320, 4320, 33, 4320, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 4320, 17280, 4320, 33, 4320, 17280, 4320, 17280, 33, 17280, 33, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 33, 17280, 33, 17280, 4320, 4320, 33, 4320, 17280, 4320, 4320, 17280, 33, 17280, 17280, 4320, 33, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 33, 17280, 4320, 17280, 17280, 33, 17280, 4320, 4320, 17280, 33, 4320, 33, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 33, 33, 33, 33]
Prompts retrieved: 1856085 . Total input tokens: 413843494 . Total output tokens: 371231399
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 115.44116884795949,
    "estimated_duration": 3600.007218074558,
    "input_throughput": 6309.569293627336,
    "output_throughput": 5567.3557817808,
    "total_throughput": 11876.925075408135,
    "itl": 153.37908708292895,
    "ttft": 1976770.764158191,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 380,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1629853426944508,
    "arrivals": 618816,
    "finished_requests": 91866,
    "scheduler_time": 162.1579643279908
}
#Debug simulation 
Total elapsed time: 115.44134823419154. Arrivals time: 0.7877853712998331 Scheduler time: 114.4044246589765 Scheduler overhead time: 0.09878556244075298 Adapter cache time: 0.023861297871917486 Engine time: 0.09751593740656972 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-16/adapters_256_slots_64_rate_1.6-0.4-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-16/adapters_256_slots_64_rate_1.6-0.4-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 33, 17280, 17280, 33, 17280, 4320, 17280, 33, 4320, 33, 17280, 4320, 4320, 4320, 4320, 17280, 33, 33, 33, 4320, 17280, 33, 17280, 17280, 4320, 4320, 4320, 33, 17280, 33, 4320, 4320, 33, 4320, 33, 33, 4320, 4320, 17280, 4320, 33, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 33, 17280, 17280, 4320, 33, 33, 17280, 4320, 33, 4320, 4320, 17280, 4320, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 4320, 33, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 33, 17280, 17280, 33, 17280, 33, 4320, 17280, 17280, 17280, 4320, 33, 17280, 4320, 33, 33, 33, 33, 33, 17280, 4320, 33, 17280, 33, 17280, 33, 33, 4320, 4320, 17280, 4320, 17280, 33, 4320, 33, 17280, 17280, 33, 17280, 4320, 33, 17280, 33, 33, 17280, 17280, 4320, 17280, 17280, 33, 17280, 4320, 4320, 33, 4320, 17280, 17280, 33, 17280, 4320, 33, 4320, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 4320, 17280, 17280, 4320, 33, 17280, 33, 4320, 4320, 33, 4320, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 4320, 17280, 4320, 33, 4320, 17280, 4320, 17280, 33, 17280, 33, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 33, 17280, 33, 17280, 4320, 4320, 33, 4320, 17280, 4320, 4320, 17280, 33, 17280, 17280, 4320, 33, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 33, 17280, 4320, 17280, 17280, 33, 17280, 4320, 4320, 17280, 33, 4320, 33, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 33, 33, 33, 33]
Prompts retrieved: 1856085 . Total input tokens: 413843494 . Total output tokens: 371231399
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 108.89659793907776,
    "estimated_duration": 3600.117093902377,
    "input_throughput": 6307.828164384641,
    "output_throughput": 5573.317888460903,
    "total_throughput": 11881.146052845545,
    "itl": 153.37880355138688,
    "ttft": 1975977.2809210306,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 400,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3034806867106865,
    "arrivals": 618816,
    "finished_requests": 91937,
    "scheduler_time": 162.14748882029758
}
#Debug simulation 
Total elapsed time: 108.89677242422476. Arrivals time: 0.7475571427494287 Scheduler time: 107.91193037852645 Scheduler overhead time: 0.09403202310204506 Adapter cache time: 0.022145500406622887 Engine time: 0.0932789002545178 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-32/adapters_256_slots_64_rate_1.6-0.4-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-32/adapters_256_slots_64_rate_1.6-0.4-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 33, 17280, 17280, 33, 17280, 4320, 17280, 33, 4320, 33, 17280, 4320, 4320, 4320, 4320, 17280, 33, 33, 33, 4320, 17280, 33, 17280, 17280, 4320, 4320, 4320, 33, 17280, 33, 4320, 4320, 33, 4320, 33, 33, 4320, 4320, 17280, 4320, 33, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 33, 17280, 17280, 4320, 33, 33, 17280, 4320, 33, 4320, 4320, 17280, 4320, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 4320, 33, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 33, 17280, 17280, 33, 17280, 33, 4320, 17280, 17280, 17280, 4320, 33, 17280, 4320, 33, 33, 33, 33, 33, 17280, 4320, 33, 17280, 33, 17280, 33, 33, 4320, 4320, 17280, 4320, 17280, 33, 4320, 33, 17280, 17280, 33, 17280, 4320, 33, 17280, 33, 33, 17280, 17280, 4320, 17280, 17280, 33, 17280, 4320, 4320, 33, 4320, 17280, 17280, 33, 17280, 4320, 33, 4320, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 4320, 17280, 17280, 4320, 33, 17280, 33, 4320, 4320, 33, 4320, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 4320, 17280, 4320, 33, 4320, 17280, 4320, 17280, 33, 17280, 33, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 33, 17280, 33, 17280, 4320, 4320, 33, 4320, 17280, 4320, 4320, 17280, 33, 17280, 17280, 4320, 33, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 33, 17280, 4320, 17280, 17280, 33, 17280, 4320, 4320, 17280, 33, 4320, 33, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 33, 33, 33, 33]
Prompts retrieved: 1856085 . Total input tokens: 413843494 . Total output tokens: 371231399
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 113.8990703811869,
    "estimated_duration": 3600.0306327294866,
    "input_throughput": 6320.469274104027,
    "output_throughput": 5579.889464654296,
    "total_throughput": 11900.358738758323,
    "itl": 153.07480527727398,
    "ttft": 1977877.960459237,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 397,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.296973074022688,
    "arrivals": 618816,
    "finished_requests": 92063,
    "scheduler_time": 162.50049078950232
}
#Debug simulation 
Total elapsed time: 113.89938325900584. Arrivals time: 0.7814170122146606 Scheduler time: 112.88108923332766 Scheduler overhead time: 0.09328061016276479 Adapter cache time: 0.022577678319066763 Engine time: 0.0925253527238965 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-16-16/adapters_256_slots_64_rate_1.6-0.4-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-16-16/adapters_256_slots_64_rate_1.6-0.4-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 33, 17280, 17280, 33, 17280, 4320, 17280, 33, 4320, 33, 17280, 4320, 4320, 4320, 4320, 17280, 33, 33, 33, 4320, 17280, 33, 17280, 17280, 4320, 4320, 4320, 33, 17280, 33, 4320, 4320, 33, 4320, 33, 33, 4320, 4320, 17280, 4320, 33, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 33, 17280, 17280, 4320, 33, 33, 17280, 4320, 33, 4320, 4320, 17280, 4320, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 4320, 33, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 33, 17280, 17280, 33, 17280, 33, 4320, 17280, 17280, 17280, 4320, 33, 17280, 4320, 33, 33, 33, 33, 33, 17280, 4320, 33, 17280, 33, 17280, 33, 33, 4320, 4320, 17280, 4320, 17280, 33, 4320, 33, 17280, 17280, 33, 17280, 4320, 33, 17280, 33, 33, 17280, 17280, 4320, 17280, 17280, 33, 17280, 4320, 4320, 33, 4320, 17280, 17280, 33, 17280, 4320, 33, 4320, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 4320, 17280, 17280, 4320, 33, 17280, 33, 4320, 4320, 33, 4320, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 4320, 17280, 4320, 33, 4320, 17280, 4320, 17280, 33, 17280, 33, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 33, 17280, 33, 17280, 4320, 4320, 33, 4320, 17280, 4320, 4320, 17280, 33, 17280, 17280, 4320, 33, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 33, 17280, 4320, 17280, 17280, 33, 17280, 4320, 4320, 17280, 33, 4320, 33, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 33, 33, 33, 33]
Prompts retrieved: 1856085 . Total input tokens: 413843494 . Total output tokens: 371231399
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 114.16392970504239,
    "estimated_duration": 3600.0334549354598,
    "input_throughput": 6309.523309806914,
    "output_throughput": 5567.315207174739,
    "total_throughput": 11876.838516981652,
    "itl": 153.3799206992358,
    "ttft": 1976779.1866808066,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 380,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1901536940969533,
    "arrivals": 618816,
    "finished_requests": 91866,
    "scheduler_time": 162.1581336830543
}
#Debug simulation 
Total elapsed time: 114.1641011191532. Arrivals time: 0.8390789213590324 Scheduler time: 113.08258512290195 Scheduler overhead time: 0.09719456266611814 Adapter cache time: 0.023451514076441526 Engine time: 0.0942599643021822 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-16-32/adapters_256_slots_64_rate_1.6-0.4-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-16-32/adapters_256_slots_64_rate_1.6-0.4-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 33, 17280, 17280, 33, 17280, 4320, 17280, 33, 4320, 33, 17280, 4320, 4320, 4320, 4320, 17280, 33, 33, 33, 4320, 17280, 33, 17280, 17280, 4320, 4320, 4320, 33, 17280, 33, 4320, 4320, 33, 4320, 33, 33, 4320, 4320, 17280, 4320, 33, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 33, 17280, 17280, 4320, 33, 33, 17280, 4320, 33, 4320, 4320, 17280, 4320, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 4320, 33, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 33, 17280, 17280, 33, 17280, 33, 4320, 17280, 17280, 17280, 4320, 33, 17280, 4320, 33, 33, 33, 33, 33, 17280, 4320, 33, 17280, 33, 17280, 33, 33, 4320, 4320, 17280, 4320, 17280, 33, 4320, 33, 17280, 17280, 33, 17280, 4320, 33, 17280, 33, 33, 17280, 17280, 4320, 17280, 17280, 33, 17280, 4320, 4320, 33, 4320, 17280, 17280, 33, 17280, 4320, 33, 4320, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 4320, 17280, 17280, 4320, 33, 17280, 33, 4320, 4320, 33, 4320, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 4320, 17280, 4320, 33, 4320, 17280, 4320, 17280, 33, 17280, 33, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 33, 17280, 33, 17280, 4320, 4320, 33, 4320, 17280, 4320, 4320, 17280, 33, 17280, 17280, 4320, 33, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 33, 17280, 4320, 17280, 17280, 33, 17280, 4320, 4320, 17280, 33, 4320, 33, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 33, 33, 33, 33]
Prompts retrieved: 1856085 . Total input tokens: 413843494 . Total output tokens: 371231399
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 114.47706851596013,
    "estimated_duration": 3600.047704083514,
    "input_throughput": 6320.439302565463,
    "output_throughput": 5579.863004930338,
    "total_throughput": 11900.3023074958,
    "itl": 153.07522923389007,
    "ttft": 1977883.683047842,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 397,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3130695586837877,
    "arrivals": 618816,
    "finished_requests": 92063,
    "scheduler_time": 162.500630231291
}
#Debug simulation 
Total elapsed time: 114.47723766881973. Arrivals time: 0.7947663520462811 Scheduler time: 113.43713542586192 Scheduler overhead time: 0.09724197164177895 Adapter cache time: 0.023875758051872253 Engine time: 0.09569250047206879 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_16-16-16/adapters_256_slots_64_rate_1.6-0.4-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_16-16-16/adapters_256_slots_64_rate_1.6-0.4-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 33, 17280, 17280, 33, 17280, 4320, 17280, 33, 4320, 33, 17280, 4320, 4320, 4320, 4320, 17280, 33, 33, 33, 4320, 17280, 33, 17280, 17280, 4320, 4320, 4320, 33, 17280, 33, 4320, 4320, 33, 4320, 33, 33, 4320, 4320, 17280, 4320, 33, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 33, 17280, 17280, 4320, 33, 33, 17280, 4320, 33, 4320, 4320, 17280, 4320, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 4320, 33, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 33, 17280, 17280, 33, 17280, 33, 4320, 17280, 17280, 17280, 4320, 33, 17280, 4320, 33, 33, 33, 33, 33, 17280, 4320, 33, 17280, 33, 17280, 33, 33, 4320, 4320, 17280, 4320, 17280, 33, 4320, 33, 17280, 17280, 33, 17280, 4320, 33, 17280, 33, 33, 17280, 17280, 4320, 17280, 17280, 33, 17280, 4320, 4320, 33, 4320, 17280, 17280, 33, 17280, 4320, 33, 4320, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 4320, 17280, 17280, 4320, 33, 17280, 33, 4320, 4320, 33, 4320, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 4320, 17280, 4320, 33, 4320, 17280, 4320, 17280, 33, 17280, 33, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 33, 17280, 33, 17280, 4320, 4320, 33, 4320, 17280, 4320, 4320, 17280, 33, 17280, 17280, 4320, 33, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 33, 17280, 4320, 17280, 17280, 33, 17280, 4320, 4320, 17280, 33, 4320, 33, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 33, 33, 33, 33]
Prompts retrieved: 1856085 . Total input tokens: 413843494 . Total output tokens: 371231399
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 115.475003561005,
    "estimated_duration": 3600.1564480836896,
    "input_throughput": 6309.765513688015,
    "output_throughput": 5567.796924677989,
    "total_throughput": 11877.562438366003,
    "itl": 153.37904032491582,
    "ttft": 1976779.7104231757,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 381,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1392091623577254,
    "arrivals": 618816,
    "finished_requests": 91874,
    "scheduler_time": 162.1657993809518
}
#Debug simulation 
Total elapsed time: 115.47520862100646. Arrivals time: 0.7687908564694226 Scheduler time: 114.45828782161698 Scheduler overhead time: 0.09974684938788414 Adapter cache time: 0.022624180652201176 Engine time: 0.0962479654699564 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_16-16-32/adapters_256_slots_64_rate_1.6-0.4-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_16-16-32/adapters_256_slots_64_rate_1.6-0.4-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [85 85 86]
Adapter prompts. [4320, 4320, 17280, 33, 17280, 17280, 33, 17280, 4320, 17280, 33, 4320, 33, 17280, 4320, 4320, 4320, 4320, 17280, 33, 33, 33, 4320, 17280, 33, 17280, 17280, 4320, 4320, 4320, 33, 17280, 33, 4320, 4320, 33, 4320, 33, 33, 4320, 4320, 17280, 4320, 33, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 33, 17280, 17280, 4320, 33, 33, 17280, 4320, 33, 4320, 4320, 17280, 4320, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 4320, 33, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 33, 17280, 17280, 33, 17280, 33, 4320, 17280, 17280, 17280, 4320, 33, 17280, 4320, 33, 33, 33, 33, 33, 17280, 4320, 33, 17280, 33, 17280, 33, 33, 4320, 4320, 17280, 4320, 17280, 33, 4320, 33, 17280, 17280, 33, 17280, 4320, 33, 17280, 33, 33, 17280, 17280, 4320, 17280, 17280, 33, 17280, 4320, 4320, 33, 4320, 17280, 17280, 33, 17280, 4320, 33, 4320, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 4320, 17280, 17280, 4320, 33, 17280, 33, 4320, 4320, 33, 4320, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 4320, 17280, 4320, 33, 4320, 17280, 4320, 17280, 33, 17280, 33, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 33, 17280, 33, 17280, 4320, 4320, 33, 4320, 17280, 4320, 4320, 17280, 33, 17280, 17280, 4320, 33, 17280, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 33, 17280, 4320, 17280, 17280, 33, 17280, 4320, 4320, 17280, 33, 4320, 33, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 33, 33, 33, 33]
Prompts retrieved: 1856085 . Total input tokens: 413843494 . Total output tokens: 371231399
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 116.0353923337534,
    "estimated_duration": 3600.068437650157,
    "input_throughput": 6320.402901799265,
    "output_throughput": 5579.830869301953,
    "total_throughput": 11900.233771101219,
    "itl": 153.07610291722378,
    "ttft": 1977889.0873414504,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 397,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3300463198497914,
    "arrivals": 618816,
    "finished_requests": 92063,
    "scheduler_time": 162.5007869730485
}
#Debug simulation 
Total elapsed time: 116.03556196484715. Arrivals time: 0.7442034054547548 Scheduler time: 115.04173168772832 Scheduler overhead time: 0.10110178869217634 Adapter cache time: 0.02366448426619172 Engine time: 0.09608983714133501 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-8-8/adapters_256_slots_64_rate_1.6-0.1-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-8-8/adapters_256_slots_64_rate_1.6-0.1-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 540, 17280, 17280, 540, 17280, 1080, 17280, 540, 1080, 540, 17280, 1080, 1080, 1080, 1080, 17280, 540, 540, 540, 1080, 17280, 540, 17280, 17280, 1080, 1080, 1080, 540, 17280, 540, 1080, 1080, 540, 1080, 540, 540, 1080, 1080, 17280, 1080, 540, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 540, 17280, 17280, 1080, 540, 540, 17280, 1080, 540, 1080, 1080, 17280, 1080, 540, 540, 17280, 17280, 17280, 17280, 17280, 17280, 540, 1080, 540, 1080, 540, 540, 540, 1080, 1080, 1080, 540, 540, 17280, 17280, 540, 17280, 540, 1080, 17280, 17280, 17280, 1080, 540, 17280, 1080, 540, 540, 540, 540, 540, 17280, 1080, 540, 17280, 540, 17280, 540, 540, 1080, 1080, 17280, 1080, 17280, 540, 1080, 540, 17280, 17280, 540, 17280, 1080, 540, 17280, 540, 540, 17280, 17280, 1080, 17280, 17280, 540, 17280, 1080, 1080, 540, 1080, 17280, 17280, 540, 17280, 1080, 540, 1080, 17280, 540, 540, 540, 540, 540, 540, 17280, 540, 540, 540, 17280, 540, 1080, 17280, 17280, 1080, 540, 17280, 540, 1080, 1080, 540, 1080, 540, 17280, 540, 540, 17280, 540, 17280, 17280, 1080, 17280, 1080, 540, 1080, 17280, 1080, 17280, 540, 17280, 540, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 540, 17280, 540, 17280, 1080, 1080, 540, 1080, 17280, 1080, 1080, 17280, 540, 17280, 17280, 1080, 540, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 540, 17280, 1080, 17280, 17280, 540, 17280, 1080, 1080, 17280, 540, 1080, 540, 540, 540, 540, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 540, 540, 540, 540]
Prompts retrieved: 1623780 . Total input tokens: 362007641 . Total output tokens: 324668356
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 138.7047984311357,
    "estimated_duration": 3600.047989364003,
    "input_throughput": 6244.125930102183,
    "output_throughput": 5539.068939890112,
    "total_throughput": 11783.194869992296,
    "itl": 154.47410356773847,
    "ttft": 1932336.588171394,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 486,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.487397043551334,
    "arrivals": 541365,
    "finished_requests": 91073,
    "scheduler_time": 160.9926862760751
}
#Debug simulation 
Total elapsed time: 138.70500050997362. Arrivals time: 0.8357260604389012 Scheduler time: 137.60526298359036 Scheduler overhead time: 0.10474238870665431 Adapter cache time: 0.029367731884121895 Engine time: 0.09977275365963578 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-8-16/adapters_256_slots_64_rate_1.6-0.1-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-8-16/adapters_256_slots_64_rate_1.6-0.1-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 540, 17280, 17280, 540, 17280, 1080, 17280, 540, 1080, 540, 17280, 1080, 1080, 1080, 1080, 17280, 540, 540, 540, 1080, 17280, 540, 17280, 17280, 1080, 1080, 1080, 540, 17280, 540, 1080, 1080, 540, 1080, 540, 540, 1080, 1080, 17280, 1080, 540, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 540, 17280, 17280, 1080, 540, 540, 17280, 1080, 540, 1080, 1080, 17280, 1080, 540, 540, 17280, 17280, 17280, 17280, 17280, 17280, 540, 1080, 540, 1080, 540, 540, 540, 1080, 1080, 1080, 540, 540, 17280, 17280, 540, 17280, 540, 1080, 17280, 17280, 17280, 1080, 540, 17280, 1080, 540, 540, 540, 540, 540, 17280, 1080, 540, 17280, 540, 17280, 540, 540, 1080, 1080, 17280, 1080, 17280, 540, 1080, 540, 17280, 17280, 540, 17280, 1080, 540, 17280, 540, 540, 17280, 17280, 1080, 17280, 17280, 540, 17280, 1080, 1080, 540, 1080, 17280, 17280, 540, 17280, 1080, 540, 1080, 17280, 540, 540, 540, 540, 540, 540, 17280, 540, 540, 540, 17280, 540, 1080, 17280, 17280, 1080, 540, 17280, 540, 1080, 1080, 540, 1080, 540, 17280, 540, 540, 17280, 540, 17280, 17280, 1080, 17280, 1080, 540, 1080, 17280, 1080, 17280, 540, 17280, 540, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 540, 17280, 540, 17280, 1080, 1080, 540, 1080, 17280, 1080, 1080, 17280, 540, 17280, 17280, 1080, 540, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 540, 17280, 1080, 17280, 17280, 540, 17280, 1080, 1080, 17280, 540, 1080, 540, 540, 540, 540, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 540, 540, 540, 540]
Prompts retrieved: 1623780 . Total input tokens: 362007641 . Total output tokens: 324668356
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 138.01388181978837,
    "estimated_duration": 3600.01391826079,
    "input_throughput": 6241.379480792416,
    "output_throughput": 5536.621094406587,
    "total_throughput": 11778.000575199003,
    "itl": 154.47034876943627,
    "ttft": 1932800.2716607768,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 489,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5953366680187218,
    "arrivals": 541365,
    "finished_requests": 91057,
    "scheduler_time": 160.9791256674143
}
#Debug simulation 
Total elapsed time: 138.01409688591957. Arrivals time: 0.8411898999474943 Scheduler time: 136.91059818910435 Scheduler overhead time: 0.10413465136662126 Adapter cache time: 0.029696892481297255 Engine time: 0.09955894853919744 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-8-32/adapters_256_slots_64_rate_1.6-0.1-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-8-32/adapters_256_slots_64_rate_1.6-0.1-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 540, 17280, 17280, 540, 17280, 1080, 17280, 540, 1080, 540, 17280, 1080, 1080, 1080, 1080, 17280, 540, 540, 540, 1080, 17280, 540, 17280, 17280, 1080, 1080, 1080, 540, 17280, 540, 1080, 1080, 540, 1080, 540, 540, 1080, 1080, 17280, 1080, 540, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 540, 17280, 17280, 1080, 540, 540, 17280, 1080, 540, 1080, 1080, 17280, 1080, 540, 540, 17280, 17280, 17280, 17280, 17280, 17280, 540, 1080, 540, 1080, 540, 540, 540, 1080, 1080, 1080, 540, 540, 17280, 17280, 540, 17280, 540, 1080, 17280, 17280, 17280, 1080, 540, 17280, 1080, 540, 540, 540, 540, 540, 17280, 1080, 540, 17280, 540, 17280, 540, 540, 1080, 1080, 17280, 1080, 17280, 540, 1080, 540, 17280, 17280, 540, 17280, 1080, 540, 17280, 540, 540, 17280, 17280, 1080, 17280, 17280, 540, 17280, 1080, 1080, 540, 1080, 17280, 17280, 540, 17280, 1080, 540, 1080, 17280, 540, 540, 540, 540, 540, 540, 17280, 540, 540, 540, 17280, 540, 1080, 17280, 17280, 1080, 540, 17280, 540, 1080, 1080, 540, 1080, 540, 17280, 540, 540, 17280, 540, 17280, 17280, 1080, 17280, 1080, 540, 1080, 17280, 1080, 17280, 540, 17280, 540, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 540, 17280, 540, 17280, 1080, 1080, 540, 1080, 17280, 1080, 1080, 17280, 540, 17280, 17280, 1080, 540, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 540, 17280, 1080, 17280, 17280, 540, 17280, 1080, 1080, 17280, 540, 1080, 540, 540, 540, 540, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 540, 540, 540, 540]
Prompts retrieved: 1623780 . Total input tokens: 362007641 . Total output tokens: 324668356
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 137.98685325402766,
    "estimated_duration": 3600.0168102791868,
    "input_throughput": 6241.374466875751,
    "output_throughput": 5536.616646646783,
    "total_throughput": 11777.991113522534,
    "itl": 154.47046130077237,
    "ttft": 1932800.7694699294,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 489,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.598223400264988,
    "arrivals": 541365,
    "finished_requests": 91057,
    "scheduler_time": 160.9791309535159
}
#Debug simulation 
Total elapsed time: 137.9870764138177. Arrivals time: 0.8516304194927216 Scheduler time: 136.87271498003975 Scheduler overhead time: 0.10412992257624865 Adapter cache time: 0.028099115937948227 Engine time: 0.10070164315402508 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-16-16/adapters_256_slots_64_rate_1.6-0.1-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-16-16/adapters_256_slots_64_rate_1.6-0.1-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 540, 17280, 17280, 540, 17280, 1080, 17280, 540, 1080, 540, 17280, 1080, 1080, 1080, 1080, 17280, 540, 540, 540, 1080, 17280, 540, 17280, 17280, 1080, 1080, 1080, 540, 17280, 540, 1080, 1080, 540, 1080, 540, 540, 1080, 1080, 17280, 1080, 540, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 540, 17280, 17280, 1080, 540, 540, 17280, 1080, 540, 1080, 1080, 17280, 1080, 540, 540, 17280, 17280, 17280, 17280, 17280, 17280, 540, 1080, 540, 1080, 540, 540, 540, 1080, 1080, 1080, 540, 540, 17280, 17280, 540, 17280, 540, 1080, 17280, 17280, 17280, 1080, 540, 17280, 1080, 540, 540, 540, 540, 540, 17280, 1080, 540, 17280, 540, 17280, 540, 540, 1080, 1080, 17280, 1080, 17280, 540, 1080, 540, 17280, 17280, 540, 17280, 1080, 540, 17280, 540, 540, 17280, 17280, 1080, 17280, 17280, 540, 17280, 1080, 1080, 540, 1080, 17280, 17280, 540, 17280, 1080, 540, 1080, 17280, 540, 540, 540, 540, 540, 540, 17280, 540, 540, 540, 17280, 540, 1080, 17280, 17280, 1080, 540, 17280, 540, 1080, 1080, 540, 1080, 540, 17280, 540, 540, 17280, 540, 17280, 17280, 1080, 17280, 1080, 540, 1080, 17280, 1080, 17280, 540, 17280, 540, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 540, 17280, 540, 17280, 1080, 1080, 540, 1080, 17280, 1080, 1080, 17280, 540, 17280, 17280, 1080, 540, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 540, 17280, 1080, 17280, 17280, 540, 17280, 1080, 1080, 17280, 540, 1080, 540, 540, 540, 540, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 540, 540, 540, 540]
Prompts retrieved: 1623780 . Total input tokens: 362007641 . Total output tokens: 324668356
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 138.48458021413535,
    "estimated_duration": 3600.0862810338194,
    "input_throughput": 6244.05951558049,
    "output_throughput": 5539.010024580207,
    "total_throughput": 11783.069540160697,
    "itl": 154.4754289187029,
    "ttft": 1932347.8172560607,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 486,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5218084568204315,
    "arrivals": 541365,
    "finished_requests": 91073,
    "scheduler_time": 160.99302154640895
}
#Debug simulation 
Total elapsed time: 138.48476203810424. Arrivals time: 0.8898205114528537 Scheduler time: 137.33534117788076 Scheduler overhead time: 0.10374777717515826 Adapter cache time: 0.02854228299111128 Engine time: 0.09745629271492362 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-16-32/adapters_256_slots_64_rate_1.6-0.1-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-16-32/adapters_256_slots_64_rate_1.6-0.1-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 540, 17280, 17280, 540, 17280, 1080, 17280, 540, 1080, 540, 17280, 1080, 1080, 1080, 1080, 17280, 540, 540, 540, 1080, 17280, 540, 17280, 17280, 1080, 1080, 1080, 540, 17280, 540, 1080, 1080, 540, 1080, 540, 540, 1080, 1080, 17280, 1080, 540, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 540, 17280, 17280, 1080, 540, 540, 17280, 1080, 540, 1080, 1080, 17280, 1080, 540, 540, 17280, 17280, 17280, 17280, 17280, 17280, 540, 1080, 540, 1080, 540, 540, 540, 1080, 1080, 1080, 540, 540, 17280, 17280, 540, 17280, 540, 1080, 17280, 17280, 17280, 1080, 540, 17280, 1080, 540, 540, 540, 540, 540, 17280, 1080, 540, 17280, 540, 17280, 540, 540, 1080, 1080, 17280, 1080, 17280, 540, 1080, 540, 17280, 17280, 540, 17280, 1080, 540, 17280, 540, 540, 17280, 17280, 1080, 17280, 17280, 540, 17280, 1080, 1080, 540, 1080, 17280, 17280, 540, 17280, 1080, 540, 1080, 17280, 540, 540, 540, 540, 540, 540, 17280, 540, 540, 540, 17280, 540, 1080, 17280, 17280, 1080, 540, 17280, 540, 1080, 1080, 540, 1080, 540, 17280, 540, 540, 17280, 540, 17280, 17280, 1080, 17280, 1080, 540, 1080, 17280, 1080, 17280, 540, 17280, 540, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 540, 17280, 540, 17280, 1080, 1080, 540, 1080, 17280, 1080, 1080, 17280, 540, 17280, 17280, 1080, 540, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 540, 17280, 1080, 17280, 17280, 540, 17280, 1080, 1080, 17280, 540, 1080, 540, 540, 540, 540, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 540, 540, 540, 540]
Prompts retrieved: 1623780 . Total input tokens: 362007641 . Total output tokens: 324668356
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 139.46555239986628,
    "estimated_duration": 3600.119809575436,
    "input_throughput": 6246.038240225078,
    "output_throughput": 5543.039414111436,
    "total_throughput": 11789.077654336514,
    "itl": 154.7710886641441,
    "ttft": 1929922.9642304687,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 472,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5629401892796204,
    "arrivals": 541365,
    "finished_requests": 91081,
    "scheduler_time": 160.8488380045047
}
#Debug simulation 
Total elapsed time: 139.46573346760124. Arrivals time: 0.8520901943556964 Scheduler time: 138.34919016528875 Scheduler overhead time: 0.10404817294329405 Adapter cache time: 0.029625328723341227 Engine time: 0.10063762264326215 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_16-16-16/adapters_256_slots_64_rate_1.6-0.1-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_16-16-16/adapters_256_slots_64_rate_1.6-0.1-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 540, 17280, 17280, 540, 17280, 1080, 17280, 540, 1080, 540, 17280, 1080, 1080, 1080, 1080, 17280, 540, 540, 540, 1080, 17280, 540, 17280, 17280, 1080, 1080, 1080, 540, 17280, 540, 1080, 1080, 540, 1080, 540, 540, 1080, 1080, 17280, 1080, 540, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 540, 17280, 17280, 1080, 540, 540, 17280, 1080, 540, 1080, 1080, 17280, 1080, 540, 540, 17280, 17280, 17280, 17280, 17280, 17280, 540, 1080, 540, 1080, 540, 540, 540, 1080, 1080, 1080, 540, 540, 17280, 17280, 540, 17280, 540, 1080, 17280, 17280, 17280, 1080, 540, 17280, 1080, 540, 540, 540, 540, 540, 17280, 1080, 540, 17280, 540, 17280, 540, 540, 1080, 1080, 17280, 1080, 17280, 540, 1080, 540, 17280, 17280, 540, 17280, 1080, 540, 17280, 540, 540, 17280, 17280, 1080, 17280, 17280, 540, 17280, 1080, 1080, 540, 1080, 17280, 17280, 540, 17280, 1080, 540, 1080, 17280, 540, 540, 540, 540, 540, 540, 17280, 540, 540, 540, 17280, 540, 1080, 17280, 17280, 1080, 540, 17280, 540, 1080, 1080, 540, 1080, 540, 17280, 540, 540, 17280, 540, 17280, 17280, 1080, 17280, 1080, 540, 1080, 17280, 1080, 17280, 540, 17280, 540, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 540, 17280, 540, 17280, 1080, 1080, 540, 1080, 17280, 1080, 1080, 17280, 540, 17280, 17280, 1080, 540, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 540, 17280, 1080, 17280, 17280, 540, 17280, 1080, 1080, 17280, 540, 1080, 540, 540, 540, 540, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 540, 540, 540, 540]
Prompts retrieved: 1623780 . Total input tokens: 362007641 . Total output tokens: 324668356
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 139.61848928360268,
    "estimated_duration": 3600.1442593770275,
    "input_throughput": 6241.084906938708,
    "output_throughput": 5537.097561598673,
    "total_throughput": 11778.182468537381,
    "itl": 154.4672972670057,
    "ttft": 1932564.6971418045,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 481,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4382141918479323,
    "arrivals": 541365,
    "finished_requests": 91058,
    "scheduler_time": 160.9991270462401
}
#Debug simulation 
Total elapsed time: 139.61871767463163. Arrivals time: 0.7691818522289395 Scheduler time: 138.5868534608744 Scheduler overhead time: 0.10387459956109524 Adapter cache time: 0.030735188629478216 Engine time: 0.09863077290356159 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_16-16-32/adapters_256_slots_64_rate_1.6-0.1-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_16-16-32/adapters_256_slots_64_rate_1.6-0.1-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 540, 17280, 17280, 540, 17280, 1080, 17280, 540, 1080, 540, 17280, 1080, 1080, 1080, 1080, 17280, 540, 540, 540, 1080, 17280, 540, 17280, 17280, 1080, 1080, 1080, 540, 17280, 540, 1080, 1080, 540, 1080, 540, 540, 1080, 1080, 17280, 1080, 540, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 540, 17280, 17280, 1080, 540, 540, 17280, 1080, 540, 1080, 1080, 17280, 1080, 540, 540, 17280, 17280, 17280, 17280, 17280, 17280, 540, 1080, 540, 1080, 540, 540, 540, 1080, 1080, 1080, 540, 540, 17280, 17280, 540, 17280, 540, 1080, 17280, 17280, 17280, 1080, 540, 17280, 1080, 540, 540, 540, 540, 540, 17280, 1080, 540, 17280, 540, 17280, 540, 540, 1080, 1080, 17280, 1080, 17280, 540, 1080, 540, 17280, 17280, 540, 17280, 1080, 540, 17280, 540, 540, 17280, 17280, 1080, 17280, 17280, 540, 17280, 1080, 1080, 540, 1080, 17280, 17280, 540, 17280, 1080, 540, 1080, 17280, 540, 540, 540, 540, 540, 540, 17280, 540, 540, 540, 17280, 540, 1080, 17280, 17280, 1080, 540, 17280, 540, 1080, 1080, 540, 1080, 540, 17280, 540, 540, 17280, 540, 17280, 17280, 1080, 17280, 1080, 540, 1080, 17280, 1080, 17280, 540, 17280, 540, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 540, 17280, 540, 17280, 1080, 1080, 540, 1080, 17280, 1080, 1080, 17280, 540, 17280, 17280, 1080, 540, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 540, 17280, 1080, 17280, 17280, 540, 17280, 1080, 1080, 17280, 540, 1080, 540, 540, 540, 540, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 540, 540, 540, 540]
Prompts retrieved: 1623780 . Total input tokens: 362007641 . Total output tokens: 324668356
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 139.56941908411682,
    "estimated_duration": 3600.0786689679126,
    "input_throughput": 6244.678260446196,
    "output_throughput": 5544.73494484015,
    "total_throughput": 11789.413205286346,
    "itl": 154.91817391440145,
    "ttft": 1926742.6094969856,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 465,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5601556656137103,
    "arrivals": 541365,
    "finished_requests": 91073,
    "scheduler_time": 160.79578425148085
}
#Debug simulation 
Total elapsed time: 139.56963356304914. Arrivals time: 0.7806004863232374 Scheduler time: 138.5232267579995 Scheduler overhead time: 0.10540197463706136 Adapter cache time: 0.029654968064278364 Engine time: 0.10076947417110205 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-8-8/adapters_256_slots_64_rate_1.6-0.1-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-8-8/adapters_256_slots_64_rate_1.6-0.1-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 270, 17280, 17280, 270, 17280, 1080, 17280, 270, 1080, 270, 17280, 1080, 1080, 1080, 1080, 17280, 270, 270, 270, 1080, 17280, 270, 17280, 17280, 1080, 1080, 1080, 270, 17280, 270, 1080, 1080, 270, 1080, 270, 270, 1080, 1080, 17280, 1080, 270, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 270, 17280, 17280, 1080, 270, 270, 17280, 1080, 270, 1080, 1080, 17280, 1080, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 1080, 270, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 270, 17280, 17280, 270, 17280, 270, 1080, 17280, 17280, 17280, 1080, 270, 17280, 1080, 270, 270, 270, 270, 270, 17280, 1080, 270, 17280, 270, 17280, 270, 270, 1080, 1080, 17280, 1080, 17280, 270, 1080, 270, 17280, 17280, 270, 17280, 1080, 270, 17280, 270, 270, 17280, 17280, 1080, 17280, 17280, 270, 17280, 1080, 1080, 270, 1080, 17280, 17280, 270, 17280, 1080, 270, 1080, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 1080, 17280, 17280, 1080, 270, 17280, 270, 1080, 1080, 270, 1080, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 1080, 17280, 1080, 270, 1080, 17280, 1080, 17280, 270, 17280, 270, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 270, 17280, 270, 17280, 1080, 1080, 270, 1080, 17280, 1080, 1080, 17280, 270, 17280, 17280, 1080, 270, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 270, 17280, 1080, 17280, 17280, 270, 17280, 1080, 1080, 17280, 270, 1080, 270, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 270, 270, 270, 270]
Prompts retrieved: 1600830 . Total input tokens: 356917788 . Total output tokens: 320016626
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 132.82729759300128,
    "estimated_duration": 3600.156779394563,
    "input_throughput": 6257.633036689198,
    "output_throughput": 5519.62295468193,
    "total_throughput": 11777.255991371128,
    "itl": 154.2540231732823,
    "ttft": 1936851.43232671,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 553,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6924497223948356,
    "arrivals": 533687,
    "finished_requests": 90804,
    "scheduler_time": 160.88999164534877
}
#Debug simulation 
Total elapsed time: 132.82745074061677. Arrivals time: 0.7575023556128144 Scheduler time: 131.81791824568063 Scheduler overhead time: 0.10017493553459644 Adapter cache time: 0.028197466395795345 Engine time: 0.09428981551900506 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-8-16/adapters_256_slots_64_rate_1.6-0.1-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-8-16/adapters_256_slots_64_rate_1.6-0.1-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 270, 17280, 17280, 270, 17280, 1080, 17280, 270, 1080, 270, 17280, 1080, 1080, 1080, 1080, 17280, 270, 270, 270, 1080, 17280, 270, 17280, 17280, 1080, 1080, 1080, 270, 17280, 270, 1080, 1080, 270, 1080, 270, 270, 1080, 1080, 17280, 1080, 270, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 270, 17280, 17280, 1080, 270, 270, 17280, 1080, 270, 1080, 1080, 17280, 1080, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 1080, 270, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 270, 17280, 17280, 270, 17280, 270, 1080, 17280, 17280, 17280, 1080, 270, 17280, 1080, 270, 270, 270, 270, 270, 17280, 1080, 270, 17280, 270, 17280, 270, 270, 1080, 1080, 17280, 1080, 17280, 270, 1080, 270, 17280, 17280, 270, 17280, 1080, 270, 17280, 270, 270, 17280, 17280, 1080, 17280, 17280, 270, 17280, 1080, 1080, 270, 1080, 17280, 17280, 270, 17280, 1080, 270, 1080, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 1080, 17280, 17280, 1080, 270, 17280, 270, 1080, 1080, 270, 1080, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 1080, 17280, 1080, 270, 1080, 17280, 1080, 17280, 270, 17280, 270, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 270, 17280, 270, 17280, 1080, 1080, 270, 1080, 17280, 1080, 1080, 17280, 270, 17280, 17280, 1080, 270, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 270, 17280, 1080, 17280, 17280, 270, 17280, 1080, 1080, 17280, 270, 1080, 270, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 270, 270, 270, 270]
Prompts retrieved: 1600830 . Total input tokens: 356917788 . Total output tokens: 320016626
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 130.03836800856516,
    "estimated_duration": 3600.0141189558,
    "input_throughput": 6257.787124050053,
    "output_throughput": 5520.799736686816,
    "total_throughput": 11778.586860736868,
    "itl": 154.20476038282104,
    "ttft": 1936632.5379624295,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 537,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7515255370456773,
    "arrivals": 533687,
    "finished_requests": 90808,
    "scheduler_time": 160.89529082082126
}
#Debug simulation 
Total elapsed time: 130.0385337038897. Arrivals time: 0.80156405037269 Scheduler time: 128.97927335696295 Scheduler overhead time: 0.10188090428709984 Adapter cache time: 0.0284934607334435 Engine time: 0.09692215221002698 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-8-32/adapters_256_slots_64_rate_1.6-0.1-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-8-32/adapters_256_slots_64_rate_1.6-0.1-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 270, 17280, 17280, 270, 17280, 1080, 17280, 270, 1080, 270, 17280, 1080, 1080, 1080, 1080, 17280, 270, 270, 270, 1080, 17280, 270, 17280, 17280, 1080, 1080, 1080, 270, 17280, 270, 1080, 1080, 270, 1080, 270, 270, 1080, 1080, 17280, 1080, 270, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 270, 17280, 17280, 1080, 270, 270, 17280, 1080, 270, 1080, 1080, 17280, 1080, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 1080, 270, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 270, 17280, 17280, 270, 17280, 270, 1080, 17280, 17280, 17280, 1080, 270, 17280, 1080, 270, 270, 270, 270, 270, 17280, 1080, 270, 17280, 270, 17280, 270, 270, 1080, 1080, 17280, 1080, 17280, 270, 1080, 270, 17280, 17280, 270, 17280, 1080, 270, 17280, 270, 270, 17280, 17280, 1080, 17280, 17280, 270, 17280, 1080, 1080, 270, 1080, 17280, 17280, 270, 17280, 1080, 270, 1080, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 1080, 17280, 17280, 1080, 270, 17280, 270, 1080, 1080, 270, 1080, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 1080, 17280, 1080, 270, 1080, 17280, 1080, 17280, 270, 17280, 270, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 270, 17280, 270, 17280, 1080, 1080, 270, 1080, 17280, 1080, 1080, 17280, 270, 17280, 17280, 1080, 270, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 270, 17280, 1080, 17280, 17280, 270, 17280, 1080, 1080, 17280, 270, 1080, 270, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 270, 270, 270, 270]
Prompts retrieved: 1600830 . Total input tokens: 356917788 . Total output tokens: 320016626
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 129.07580615067855,
    "estimated_duration": 3600.018861079448,
    "input_throughput": 6257.778880982044,
    "output_throughput": 5520.792464415198,
    "total_throughput": 11778.571345397242,
    "itl": 154.2047017879835,
    "ttft": 1936633.9605623453,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 537,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7547669773362684,
    "arrivals": 533687,
    "finished_requests": 90808,
    "scheduler_time": 160.89536823086954
}
#Debug simulation 
Total elapsed time: 129.07603518804535. Arrivals time: 0.7962434808723629 Scheduler time: 128.0243629431352 Scheduler overhead time: 0.10079130250960588 Adapter cache time: 0.028301513753831387 Engine time: 0.09692197060212493 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-16-16/adapters_256_slots_64_rate_1.6-0.1-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-16-16/adapters_256_slots_64_rate_1.6-0.1-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 270, 17280, 17280, 270, 17280, 1080, 17280, 270, 1080, 270, 17280, 1080, 1080, 1080, 1080, 17280, 270, 270, 270, 1080, 17280, 270, 17280, 17280, 1080, 1080, 1080, 270, 17280, 270, 1080, 1080, 270, 1080, 270, 270, 1080, 1080, 17280, 1080, 270, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 270, 17280, 17280, 1080, 270, 270, 17280, 1080, 270, 1080, 1080, 17280, 1080, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 1080, 270, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 270, 17280, 17280, 270, 17280, 270, 1080, 17280, 17280, 17280, 1080, 270, 17280, 1080, 270, 270, 270, 270, 270, 17280, 1080, 270, 17280, 270, 17280, 270, 270, 1080, 1080, 17280, 1080, 17280, 270, 1080, 270, 17280, 17280, 270, 17280, 1080, 270, 17280, 270, 270, 17280, 17280, 1080, 17280, 17280, 270, 17280, 1080, 1080, 270, 1080, 17280, 17280, 270, 17280, 1080, 270, 1080, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 1080, 17280, 17280, 1080, 270, 17280, 270, 1080, 1080, 270, 1080, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 1080, 17280, 1080, 270, 1080, 17280, 1080, 17280, 270, 17280, 270, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 270, 17280, 270, 17280, 1080, 1080, 270, 1080, 17280, 1080, 1080, 17280, 270, 17280, 17280, 1080, 270, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 270, 17280, 1080, 17280, 17280, 270, 17280, 1080, 1080, 17280, 270, 1080, 270, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 270, 270, 270, 270]
Prompts retrieved: 1600830 . Total input tokens: 356917788 . Total output tokens: 320016626
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 130.7843919112347,
    "estimated_duration": 3600.015578177616,
    "input_throughput": 6260.447631565233,
    "output_throughput": 5525.376923526914,
    "total_throughput": 11785.824555092147,
    "itl": 154.3941281314031,
    "ttft": 1936074.9927191706,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 541,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6940245340904143,
    "arrivals": 533687,
    "finished_requests": 90862,
    "scheduler_time": 160.81438216333757
}
#Debug simulation 
Total elapsed time: 130.7845556223765. Arrivals time: 0.8084334759041667 Scheduler time: 129.71732484456152 Scheduler overhead time: 0.10128329927101731 Adapter cache time: 0.030524407979100943 Engine time: 0.09664031630381942 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-16-32/adapters_256_slots_64_rate_1.6-0.1-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-16-32/adapters_256_slots_64_rate_1.6-0.1-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 270, 17280, 17280, 270, 17280, 1080, 17280, 270, 1080, 270, 17280, 1080, 1080, 1080, 1080, 17280, 270, 270, 270, 1080, 17280, 270, 17280, 17280, 1080, 1080, 1080, 270, 17280, 270, 1080, 1080, 270, 1080, 270, 270, 1080, 1080, 17280, 1080, 270, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 270, 17280, 17280, 1080, 270, 270, 17280, 1080, 270, 1080, 1080, 17280, 1080, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 1080, 270, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 270, 17280, 17280, 270, 17280, 270, 1080, 17280, 17280, 17280, 1080, 270, 17280, 1080, 270, 270, 270, 270, 270, 17280, 1080, 270, 17280, 270, 17280, 270, 270, 1080, 1080, 17280, 1080, 17280, 270, 1080, 270, 17280, 17280, 270, 17280, 1080, 270, 17280, 270, 270, 17280, 17280, 1080, 17280, 17280, 270, 17280, 1080, 1080, 270, 1080, 17280, 17280, 270, 17280, 1080, 270, 1080, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 1080, 17280, 17280, 1080, 270, 17280, 270, 1080, 1080, 270, 1080, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 1080, 17280, 1080, 270, 1080, 17280, 1080, 17280, 270, 17280, 270, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 270, 17280, 270, 17280, 1080, 1080, 270, 1080, 17280, 1080, 1080, 17280, 270, 17280, 17280, 1080, 270, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 270, 17280, 1080, 17280, 17280, 270, 17280, 1080, 1080, 17280, 270, 1080, 270, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 270, 270, 270, 270]
Prompts retrieved: 1600830 . Total input tokens: 356917788 . Total output tokens: 320016626
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 130.18584966100752,
    "estimated_duration": 3600.0053085430236,
    "input_throughput": 6257.043273393495,
    "output_throughput": 5516.336587858303,
    "total_throughput": 11773.379861251799,
    "itl": 154.06699641806867,
    "ttft": 1936311.193900155,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 545,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8037742946483235,
    "arrivals": 533687,
    "finished_requests": 90752,
    "scheduler_time": 161.05369826025702
}
#Debug simulation 
Total elapsed time: 130.1859991811216. Arrivals time: 0.7469369764439762 Scheduler time: 129.18118726229295 Scheduler overhead time: 0.10340260015800595 Adapter cache time: 0.028445512056350708 Engine time: 0.09644570015370846 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_16-16-16/adapters_256_slots_64_rate_1.6-0.1-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_16-16-16/adapters_256_slots_64_rate_1.6-0.1-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 270, 17280, 17280, 270, 17280, 1080, 17280, 270, 1080, 270, 17280, 1080, 1080, 1080, 1080, 17280, 270, 270, 270, 1080, 17280, 270, 17280, 17280, 1080, 1080, 1080, 270, 17280, 270, 1080, 1080, 270, 1080, 270, 270, 1080, 1080, 17280, 1080, 270, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 270, 17280, 17280, 1080, 270, 270, 17280, 1080, 270, 1080, 1080, 17280, 1080, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 1080, 270, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 270, 17280, 17280, 270, 17280, 270, 1080, 17280, 17280, 17280, 1080, 270, 17280, 1080, 270, 270, 270, 270, 270, 17280, 1080, 270, 17280, 270, 17280, 270, 270, 1080, 1080, 17280, 1080, 17280, 270, 1080, 270, 17280, 17280, 270, 17280, 1080, 270, 17280, 270, 270, 17280, 17280, 1080, 17280, 17280, 270, 17280, 1080, 1080, 270, 1080, 17280, 17280, 270, 17280, 1080, 270, 1080, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 1080, 17280, 17280, 1080, 270, 17280, 270, 1080, 1080, 270, 1080, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 1080, 17280, 1080, 270, 1080, 17280, 1080, 17280, 270, 17280, 270, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 270, 17280, 270, 17280, 1080, 1080, 270, 1080, 17280, 1080, 1080, 17280, 270, 17280, 17280, 1080, 270, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 270, 17280, 1080, 17280, 17280, 270, 17280, 1080, 1080, 17280, 270, 1080, 270, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 270, 270, 270, 270]
Prompts retrieved: 1600830 . Total input tokens: 356917788 . Total output tokens: 320016626
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 133.31248116213828,
    "estimated_duration": 3600.141342378379,
    "input_throughput": 6260.229212309427,
    "output_throughput": 5525.236402762703,
    "total_throughput": 11785.46561507213,
    "itl": 154.39029205205932,
    "ttft": 1936126.6382017033,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 541,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6176172095420565,
    "arrivals": 533687,
    "finished_requests": 90863,
    "scheduler_time": 160.82313306424217
}
#Debug simulation 
Total elapsed time: 133.31265551317483. Arrivals time: 0.7716171992942691 Scheduler time: 132.28282166738063 Scheduler overhead time: 0.10264648636803031 Adapter cache time: 0.028637967072427273 Engine time: 0.09735806984826922 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_16-16-32/adapters_256_slots_64_rate_1.6-0.1-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_16-16-32/adapters_256_slots_64_rate_1.6-0.1-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 270, 17280, 17280, 270, 17280, 1080, 17280, 270, 1080, 270, 17280, 1080, 1080, 1080, 1080, 17280, 270, 270, 270, 1080, 17280, 270, 17280, 17280, 1080, 1080, 1080, 270, 17280, 270, 1080, 1080, 270, 1080, 270, 270, 1080, 1080, 17280, 1080, 270, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 270, 17280, 17280, 1080, 270, 270, 17280, 1080, 270, 1080, 1080, 17280, 1080, 270, 270, 17280, 17280, 17280, 17280, 17280, 17280, 270, 1080, 270, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 270, 17280, 17280, 270, 17280, 270, 1080, 17280, 17280, 17280, 1080, 270, 17280, 1080, 270, 270, 270, 270, 270, 17280, 1080, 270, 17280, 270, 17280, 270, 270, 1080, 1080, 17280, 1080, 17280, 270, 1080, 270, 17280, 17280, 270, 17280, 1080, 270, 17280, 270, 270, 17280, 17280, 1080, 17280, 17280, 270, 17280, 1080, 1080, 270, 1080, 17280, 17280, 270, 17280, 1080, 270, 1080, 17280, 270, 270, 270, 270, 270, 270, 17280, 270, 270, 270, 17280, 270, 1080, 17280, 17280, 1080, 270, 17280, 270, 1080, 1080, 270, 1080, 270, 17280, 270, 270, 17280, 270, 17280, 17280, 1080, 17280, 1080, 270, 1080, 17280, 1080, 17280, 270, 17280, 270, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 270, 17280, 270, 17280, 1080, 1080, 270, 1080, 17280, 1080, 1080, 17280, 270, 17280, 17280, 1080, 270, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 270, 17280, 1080, 17280, 17280, 270, 17280, 1080, 1080, 17280, 270, 1080, 270, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 270, 270, 270, 270]
Prompts retrieved: 1600830 . Total input tokens: 356917788 . Total output tokens: 320016626
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 129.31070999009535,
    "estimated_duration": 3600.082329521949,
    "input_throughput": 6258.054938146837,
    "output_throughput": 5521.673445351357,
    "total_throughput": 11779.728383498194,
    "itl": 154.2642721138298,
    "ttft": 1936710.865284879,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 537,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8001240803673833,
    "arrivals": 533687,
    "finished_requests": 90825,
    "scheduler_time": 160.86408773937532
}
#Debug simulation 
Total elapsed time: 129.3109880220145. Arrivals time: 0.7487905514426529 Scheduler time: 128.3073516297154 Scheduler overhead time: 0.10031767375767231 Adapter cache time: 0.029508152045309544 Engine time: 0.09540796978399158 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-8/adapters_256_slots_64_rate_1.6-0.1-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-8/adapters_256_slots_64_rate_1.6-0.1-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 135, 17280, 17280, 135, 17280, 1080, 17280, 135, 1080, 135, 17280, 1080, 1080, 1080, 1080, 17280, 135, 135, 135, 1080, 17280, 135, 17280, 17280, 1080, 1080, 1080, 135, 17280, 135, 1080, 1080, 135, 1080, 135, 135, 1080, 1080, 17280, 1080, 135, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 135, 17280, 17280, 1080, 135, 135, 17280, 1080, 135, 1080, 1080, 17280, 1080, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 1080, 135, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 135, 17280, 17280, 135, 17280, 135, 1080, 17280, 17280, 17280, 1080, 135, 17280, 1080, 135, 135, 135, 135, 135, 17280, 1080, 135, 17280, 135, 17280, 135, 135, 1080, 1080, 17280, 1080, 17280, 135, 1080, 135, 17280, 17280, 135, 17280, 1080, 135, 17280, 135, 135, 17280, 17280, 1080, 17280, 17280, 135, 17280, 1080, 1080, 135, 1080, 17280, 17280, 135, 17280, 1080, 135, 1080, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 1080, 17280, 17280, 1080, 135, 17280, 135, 1080, 1080, 135, 1080, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 1080, 17280, 1080, 135, 1080, 17280, 1080, 17280, 135, 17280, 135, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 135, 17280, 135, 17280, 1080, 1080, 135, 1080, 17280, 1080, 1080, 17280, 135, 17280, 17280, 1080, 135, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 135, 17280, 1080, 17280, 17280, 135, 17280, 1080, 1080, 17280, 135, 1080, 135, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 135, 135, 135, 135]
Prompts retrieved: 1589355 . Total input tokens: 354333746 . Total output tokens: 317709364
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 137.4425853989087,
    "estimated_duration": 3600.032731374775,
    "input_throughput": 6289.971977936074,
    "output_throughput": 5526.249755068936,
    "total_throughput": 11816.22173300501,
    "itl": 154.24962455949986,
    "ttft": 1929152.2853992505,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 471,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.441489727392341,
    "arrivals": 529924,
    "finished_requests": 91467,
    "scheduler_time": 160.4665362775553
}
#Debug simulation 
Total elapsed time: 137.44277961691841. Arrivals time: 0.7420327896252275 Scheduler time: 136.44042685907334 Scheduler overhead time: 0.10388148156926036 Adapter cache time: 0.027624267619103193 Engine time: 0.09829845884814858 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-16/adapters_256_slots_64_rate_1.6-0.1-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-16/adapters_256_slots_64_rate_1.6-0.1-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 135, 17280, 17280, 135, 17280, 1080, 17280, 135, 1080, 135, 17280, 1080, 1080, 1080, 1080, 17280, 135, 135, 135, 1080, 17280, 135, 17280, 17280, 1080, 1080, 1080, 135, 17280, 135, 1080, 1080, 135, 1080, 135, 135, 1080, 1080, 17280, 1080, 135, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 135, 17280, 17280, 1080, 135, 135, 17280, 1080, 135, 1080, 1080, 17280, 1080, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 1080, 135, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 135, 17280, 17280, 135, 17280, 135, 1080, 17280, 17280, 17280, 1080, 135, 17280, 1080, 135, 135, 135, 135, 135, 17280, 1080, 135, 17280, 135, 17280, 135, 135, 1080, 1080, 17280, 1080, 17280, 135, 1080, 135, 17280, 17280, 135, 17280, 1080, 135, 17280, 135, 135, 17280, 17280, 1080, 17280, 17280, 135, 17280, 1080, 1080, 135, 1080, 17280, 17280, 135, 17280, 1080, 135, 1080, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 1080, 17280, 17280, 1080, 135, 17280, 135, 1080, 1080, 135, 1080, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 1080, 17280, 1080, 135, 1080, 17280, 1080, 17280, 135, 17280, 135, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 135, 17280, 135, 17280, 1080, 1080, 135, 1080, 17280, 1080, 1080, 17280, 135, 17280, 17280, 1080, 135, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 135, 17280, 1080, 17280, 17280, 135, 17280, 1080, 1080, 17280, 135, 1080, 135, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 135, 135, 135, 135]
Prompts retrieved: 1589355 . Total input tokens: 354333746 . Total output tokens: 317709364
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 135.3108862778172,
    "estimated_duration": 3600.064338456228,
    "input_throughput": 6289.948420674683,
    "output_throughput": 5526.328179048986,
    "total_throughput": 11816.27659972367,
    "itl": 154.25861546069493,
    "ttft": 1929033.0152798179,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 470,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.532396782638976,
    "arrivals": 529924,
    "finished_requests": 91458,
    "scheduler_time": 160.46470758224362
}
#Debug simulation 
Total elapsed time: 135.311046092771. Arrivals time: 0.774261930026114 Scheduler time: 134.27859824709594 Scheduler overhead time: 0.10296293860301375 Adapter cache time: 0.027870650868862867 Engine time: 0.09716454707086086 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-32/adapters_256_slots_64_rate_1.6-0.1-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-32/adapters_256_slots_64_rate_1.6-0.1-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 135, 17280, 17280, 135, 17280, 1080, 17280, 135, 1080, 135, 17280, 1080, 1080, 1080, 1080, 17280, 135, 135, 135, 1080, 17280, 135, 17280, 17280, 1080, 1080, 1080, 135, 17280, 135, 1080, 1080, 135, 1080, 135, 135, 1080, 1080, 17280, 1080, 135, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 135, 17280, 17280, 1080, 135, 135, 17280, 1080, 135, 1080, 1080, 17280, 1080, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 1080, 135, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 135, 17280, 17280, 135, 17280, 135, 1080, 17280, 17280, 17280, 1080, 135, 17280, 1080, 135, 135, 135, 135, 135, 17280, 1080, 135, 17280, 135, 17280, 135, 135, 1080, 1080, 17280, 1080, 17280, 135, 1080, 135, 17280, 17280, 135, 17280, 1080, 135, 17280, 135, 135, 17280, 17280, 1080, 17280, 17280, 135, 17280, 1080, 1080, 135, 1080, 17280, 17280, 135, 17280, 1080, 135, 1080, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 1080, 17280, 17280, 1080, 135, 17280, 135, 1080, 1080, 135, 1080, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 1080, 17280, 1080, 135, 1080, 17280, 1080, 17280, 135, 17280, 135, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 135, 17280, 135, 17280, 1080, 1080, 135, 1080, 17280, 1080, 1080, 17280, 135, 17280, 17280, 1080, 135, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 135, 17280, 1080, 17280, 17280, 135, 17280, 1080, 1080, 17280, 135, 1080, 135, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 135, 135, 135, 135]
Prompts retrieved: 1589355 . Total input tokens: 354333746 . Total output tokens: 317709364
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 136.08267654292285,
    "estimated_duration": 3600.0663053574413,
    "input_throughput": 6289.94498415265,
    "output_throughput": 5526.3251597319295,
    "total_throughput": 11816.27014388458,
    "itl": 154.2586677823174,
    "ttft": 1929032.9076366439,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 470,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.535337829720238,
    "arrivals": 529924,
    "finished_requests": 91458,
    "scheduler_time": 160.46470810186878
}
#Debug simulation 
Total elapsed time: 136.08287953399122. Arrivals time: 0.8072598171420395 Scheduler time: 135.01342007191852 Scheduler overhead time: 0.10402454482391477 Adapter cache time: 0.029176240786910057 Engine time: 0.09964886447414756 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-16-16/adapters_256_slots_64_rate_1.6-0.1-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-16-16/adapters_256_slots_64_rate_1.6-0.1-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 135, 17280, 17280, 135, 17280, 1080, 17280, 135, 1080, 135, 17280, 1080, 1080, 1080, 1080, 17280, 135, 135, 135, 1080, 17280, 135, 17280, 17280, 1080, 1080, 1080, 135, 17280, 135, 1080, 1080, 135, 1080, 135, 135, 1080, 1080, 17280, 1080, 135, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 135, 17280, 17280, 1080, 135, 135, 17280, 1080, 135, 1080, 1080, 17280, 1080, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 1080, 135, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 135, 17280, 17280, 135, 17280, 135, 1080, 17280, 17280, 17280, 1080, 135, 17280, 1080, 135, 135, 135, 135, 135, 17280, 1080, 135, 17280, 135, 17280, 135, 135, 1080, 1080, 17280, 1080, 17280, 135, 1080, 135, 17280, 17280, 135, 17280, 1080, 135, 17280, 135, 135, 17280, 17280, 1080, 17280, 17280, 135, 17280, 1080, 1080, 135, 1080, 17280, 17280, 135, 17280, 1080, 135, 1080, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 1080, 17280, 17280, 1080, 135, 17280, 135, 1080, 1080, 135, 1080, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 1080, 17280, 1080, 135, 1080, 17280, 1080, 17280, 135, 17280, 135, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 135, 17280, 135, 17280, 1080, 1080, 135, 1080, 17280, 1080, 1080, 17280, 135, 17280, 17280, 1080, 135, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 135, 17280, 1080, 17280, 17280, 135, 17280, 1080, 1080, 17280, 135, 1080, 135, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 135, 135, 135, 135]
Prompts retrieved: 1589355 . Total input tokens: 354333746 . Total output tokens: 317709364
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 135.84477320639417,
    "estimated_duration": 3600.140377453368,
    "input_throughput": 6292.006040059867,
    "output_throughput": 5526.731436532081,
    "total_throughput": 11818.737476591949,
    "itl": 154.23629967162606,
    "ttft": 1929353.2112575902,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 465,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4553400427615235,
    "arrivals": 529924,
    "finished_requests": 91477,
    "scheduler_time": 160.47375412981847
}
#Debug simulation 
Total elapsed time: 135.84494008729234. Arrivals time: 0.7166239363141358 Scheduler time: 134.8662735153921 Scheduler overhead time: 0.10492536565288901 Adapter cache time: 0.026849350426346064 Engine time: 0.09946752758696675 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-16-32/adapters_256_slots_64_rate_1.6-0.1-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-16-32/adapters_256_slots_64_rate_1.6-0.1-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 135, 17280, 17280, 135, 17280, 1080, 17280, 135, 1080, 135, 17280, 1080, 1080, 1080, 1080, 17280, 135, 135, 135, 1080, 17280, 135, 17280, 17280, 1080, 1080, 1080, 135, 17280, 135, 1080, 1080, 135, 1080, 135, 135, 1080, 1080, 17280, 1080, 135, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 135, 17280, 17280, 1080, 135, 135, 17280, 1080, 135, 1080, 1080, 17280, 1080, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 1080, 135, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 135, 17280, 17280, 135, 17280, 135, 1080, 17280, 17280, 17280, 1080, 135, 17280, 1080, 135, 135, 135, 135, 135, 17280, 1080, 135, 17280, 135, 17280, 135, 135, 1080, 1080, 17280, 1080, 17280, 135, 1080, 135, 17280, 17280, 135, 17280, 1080, 135, 17280, 135, 135, 17280, 17280, 1080, 17280, 17280, 135, 17280, 1080, 1080, 135, 1080, 17280, 17280, 135, 17280, 1080, 135, 1080, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 1080, 17280, 17280, 1080, 135, 17280, 135, 1080, 1080, 135, 1080, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 1080, 17280, 1080, 135, 1080, 17280, 1080, 17280, 135, 17280, 135, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 135, 17280, 135, 17280, 1080, 1080, 135, 1080, 17280, 1080, 1080, 17280, 135, 17280, 17280, 1080, 135, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 135, 17280, 1080, 17280, 17280, 135, 17280, 1080, 1080, 17280, 135, 1080, 135, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 135, 135, 135, 135]
Prompts retrieved: 1589355 . Total input tokens: 354333746 . Total output tokens: 317709364
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 135.1053618490696,
    "estimated_duration": 3600.0853893874205,
    "input_throughput": 6289.911641193897,
    "output_throughput": 5526.295864717058,
    "total_throughput": 11816.207505910954,
    "itl": 154.25941379784135,
    "ttft": 1929039.7702225444,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 470,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.554200897682463,
    "arrivals": 529924,
    "finished_requests": 91458,
    "scheduler_time": 160.46489776022872
}
#Debug simulation 
Total elapsed time: 135.10551844118163. Arrivals time: 0.8212874792516232 Scheduler time: 134.02914217906073 Scheduler overhead time: 0.10170484473928809 Adapter cache time: 0.02841807622462511 Engine time: 0.09519198490306735 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_16-16-16/adapters_256_slots_64_rate_1.6-0.1-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_16-16-16/adapters_256_slots_64_rate_1.6-0.1-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 135, 17280, 17280, 135, 17280, 1080, 17280, 135, 1080, 135, 17280, 1080, 1080, 1080, 1080, 17280, 135, 135, 135, 1080, 17280, 135, 17280, 17280, 1080, 1080, 1080, 135, 17280, 135, 1080, 1080, 135, 1080, 135, 135, 1080, 1080, 17280, 1080, 135, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 135, 17280, 17280, 1080, 135, 135, 17280, 1080, 135, 1080, 1080, 17280, 1080, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 1080, 135, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 135, 17280, 17280, 135, 17280, 135, 1080, 17280, 17280, 17280, 1080, 135, 17280, 1080, 135, 135, 135, 135, 135, 17280, 1080, 135, 17280, 135, 17280, 135, 135, 1080, 1080, 17280, 1080, 17280, 135, 1080, 135, 17280, 17280, 135, 17280, 1080, 135, 17280, 135, 135, 17280, 17280, 1080, 17280, 17280, 135, 17280, 1080, 1080, 135, 1080, 17280, 17280, 135, 17280, 1080, 135, 1080, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 1080, 17280, 17280, 1080, 135, 17280, 135, 1080, 1080, 135, 1080, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 1080, 17280, 1080, 135, 1080, 17280, 1080, 17280, 135, 17280, 135, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 135, 17280, 135, 17280, 1080, 1080, 135, 1080, 17280, 1080, 1080, 17280, 135, 17280, 17280, 1080, 135, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 135, 17280, 1080, 17280, 17280, 135, 17280, 1080, 1080, 17280, 135, 1080, 135, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 135, 135, 135, 135]
Prompts retrieved: 1589355 . Total input tokens: 354333746 . Total output tokens: 317709364
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 138.10986395878717,
    "estimated_duration": 3600.1390107258644,
    "input_throughput": 6291.287067671695,
    "output_throughput": 5526.303551258887,
    "total_throughput": 11817.590618930582,
    "itl": 154.23797998127242,
    "ttft": 1929276.3437929498,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 462,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.381403236244793,
    "arrivals": 529924,
    "finished_requests": 91468,
    "scheduler_time": 160.47676699628576
}
#Debug simulation 
Total elapsed time: 138.11004057805985. Arrivals time: 0.759472384583205 Scheduler time: 137.08255668357015 Scheduler overhead time: 0.10858665546402335 Adapter cache time: 0.027676316909492016 Engine time: 0.10114461230114102 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_16-16-32/adapters_256_slots_64_rate_1.6-0.1-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_16-16-32/adapters_256_slots_64_rate_1.6-0.1-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 135, 17280, 17280, 135, 17280, 1080, 17280, 135, 1080, 135, 17280, 1080, 1080, 1080, 1080, 17280, 135, 135, 135, 1080, 17280, 135, 17280, 17280, 1080, 1080, 1080, 135, 17280, 135, 1080, 1080, 135, 1080, 135, 135, 1080, 1080, 17280, 1080, 135, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 135, 17280, 17280, 1080, 135, 135, 17280, 1080, 135, 1080, 1080, 17280, 1080, 135, 135, 17280, 17280, 17280, 17280, 17280, 17280, 135, 1080, 135, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 135, 17280, 17280, 135, 17280, 135, 1080, 17280, 17280, 17280, 1080, 135, 17280, 1080, 135, 135, 135, 135, 135, 17280, 1080, 135, 17280, 135, 17280, 135, 135, 1080, 1080, 17280, 1080, 17280, 135, 1080, 135, 17280, 17280, 135, 17280, 1080, 135, 17280, 135, 135, 17280, 17280, 1080, 17280, 17280, 135, 17280, 1080, 1080, 135, 1080, 17280, 17280, 135, 17280, 1080, 135, 1080, 17280, 135, 135, 135, 135, 135, 135, 17280, 135, 135, 135, 17280, 135, 1080, 17280, 17280, 1080, 135, 17280, 135, 1080, 1080, 135, 1080, 135, 17280, 135, 135, 17280, 135, 17280, 17280, 1080, 17280, 1080, 135, 1080, 17280, 1080, 17280, 135, 17280, 135, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 135, 17280, 135, 17280, 1080, 1080, 135, 1080, 17280, 1080, 1080, 17280, 135, 17280, 17280, 1080, 135, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 135, 17280, 1080, 17280, 17280, 135, 17280, 1080, 1080, 17280, 135, 1080, 135, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 135, 135, 135, 135]
Prompts retrieved: 1589355 . Total input tokens: 354333746 . Total output tokens: 317709364
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 135.5501111159101,
    "estimated_duration": 3600.107070530999,
    "input_throughput": 6291.207610294595,
    "output_throughput": 5526.314526269223,
    "total_throughput": 11817.522136563819,
    "itl": 154.24555078357417,
    "ttft": 1929230.5263046797,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 462,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5473210988193746,
    "arrivals": 529924,
    "finished_requests": 91466,
    "scheduler_time": 160.4690572614824
}
#Debug simulation 
Total elapsed time: 135.5502656470053. Arrivals time: 0.7397598847746849 Scheduler time: 134.5501192533411 Scheduler overhead time: 0.10421667573973536 Adapter cache time: 0.027705990243703127 Engine time: 0.09864052897319198 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-8/adapters_256_slots_64_rate_1.6-0.1-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-8/adapters_256_slots_64_rate_1.6-0.1-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 66, 17280, 17280, 66, 17280, 1080, 17280, 66, 1080, 66, 17280, 1080, 1080, 1080, 1080, 17280, 66, 66, 66, 1080, 17280, 66, 17280, 17280, 1080, 1080, 1080, 66, 17280, 66, 1080, 1080, 66, 1080, 66, 66, 1080, 1080, 17280, 1080, 66, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 66, 17280, 17280, 1080, 66, 66, 17280, 1080, 66, 1080, 1080, 17280, 1080, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 1080, 66, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 66, 17280, 17280, 66, 17280, 66, 1080, 17280, 17280, 17280, 1080, 66, 17280, 1080, 66, 66, 66, 66, 66, 17280, 1080, 66, 17280, 66, 17280, 66, 66, 1080, 1080, 17280, 1080, 17280, 66, 1080, 66, 17280, 17280, 66, 17280, 1080, 66, 17280, 66, 66, 17280, 17280, 1080, 17280, 17280, 66, 17280, 1080, 1080, 66, 1080, 17280, 17280, 66, 17280, 1080, 66, 1080, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 1080, 17280, 17280, 1080, 66, 17280, 66, 1080, 1080, 66, 1080, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 1080, 17280, 1080, 66, 1080, 17280, 1080, 17280, 66, 17280, 66, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 66, 17280, 66, 17280, 1080, 1080, 66, 1080, 17280, 1080, 1080, 17280, 66, 17280, 17280, 1080, 66, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 66, 17280, 1080, 17280, 17280, 66, 17280, 1080, 1080, 17280, 66, 1080, 66, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 66, 66, 66, 66]
Prompts retrieved: 1583490 . Total input tokens: 353008931 . Total output tokens: 316540482
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 131.02522941725329,
    "estimated_duration": 3600.0562957718757,
    "input_throughput": 6260.6390423590765,
    "output_throughput": 5529.232146557897,
    "total_throughput": 11789.871188916974,
    "itl": 154.69779693020126,
    "ttft": 1933661.6699889563,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 489,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4965785067831325,
    "arrivals": 527992,
    "finished_requests": 90861,
    "scheduler_time": 160.5382677187763
}
#Debug simulation 
Total elapsed time: 131.02540465816855. Arrivals time: 0.9069320005364716 Scheduler time: 129.86548306467012 Scheduler overhead time: 0.10185037925839424 Adapter cache time: 0.028318542521446943 Engine time: 0.09378208825364709 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-16/adapters_256_slots_64_rate_1.6-0.1-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-16/adapters_256_slots_64_rate_1.6-0.1-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 66, 17280, 17280, 66, 17280, 1080, 17280, 66, 1080, 66, 17280, 1080, 1080, 1080, 1080, 17280, 66, 66, 66, 1080, 17280, 66, 17280, 17280, 1080, 1080, 1080, 66, 17280, 66, 1080, 1080, 66, 1080, 66, 66, 1080, 1080, 17280, 1080, 66, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 66, 17280, 17280, 1080, 66, 66, 17280, 1080, 66, 1080, 1080, 17280, 1080, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 1080, 66, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 66, 17280, 17280, 66, 17280, 66, 1080, 17280, 17280, 17280, 1080, 66, 17280, 1080, 66, 66, 66, 66, 66, 17280, 1080, 66, 17280, 66, 17280, 66, 66, 1080, 1080, 17280, 1080, 17280, 66, 1080, 66, 17280, 17280, 66, 17280, 1080, 66, 17280, 66, 66, 17280, 17280, 1080, 17280, 17280, 66, 17280, 1080, 1080, 66, 1080, 17280, 17280, 66, 17280, 1080, 66, 1080, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 1080, 17280, 17280, 1080, 66, 17280, 66, 1080, 1080, 66, 1080, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 1080, 17280, 1080, 66, 1080, 17280, 1080, 17280, 66, 17280, 66, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 66, 17280, 66, 17280, 1080, 1080, 66, 1080, 17280, 1080, 1080, 17280, 66, 17280, 17280, 1080, 66, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 66, 17280, 1080, 17280, 17280, 66, 17280, 1080, 1080, 17280, 66, 1080, 66, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 66, 66, 66, 66]
Prompts retrieved: 1583490 . Total input tokens: 353008931 . Total output tokens: 316540482
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 133.42958988109604,
    "estimated_duration": 3600.1656388887145,
    "input_throughput": 6260.448896167218,
    "output_throughput": 5529.06421442997,
    "total_throughput": 11789.513110597187,
    "itl": 154.70204139323067,
    "ttft": 1933678.6839681973,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 489,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5961538586556032,
    "arrivals": 527992,
    "finished_requests": 90861,
    "scheduler_time": 160.54053766544843
}
#Debug simulation 
Total elapsed time: 133.42976184282452. Arrivals time: 0.8583353119902313 Scheduler time: 132.31338894646615 Scheduler overhead time: 0.10302283288910985 Adapter cache time: 0.027687881607562304 Engine time: 0.09847450722008944 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-32/adapters_256_slots_64_rate_1.6-0.1-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-32/adapters_256_slots_64_rate_1.6-0.1-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 66, 17280, 17280, 66, 17280, 1080, 17280, 66, 1080, 66, 17280, 1080, 1080, 1080, 1080, 17280, 66, 66, 66, 1080, 17280, 66, 17280, 17280, 1080, 1080, 1080, 66, 17280, 66, 1080, 1080, 66, 1080, 66, 66, 1080, 1080, 17280, 1080, 66, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 66, 17280, 17280, 1080, 66, 66, 17280, 1080, 66, 1080, 1080, 17280, 1080, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 1080, 66, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 66, 17280, 17280, 66, 17280, 66, 1080, 17280, 17280, 17280, 1080, 66, 17280, 1080, 66, 66, 66, 66, 66, 17280, 1080, 66, 17280, 66, 17280, 66, 66, 1080, 1080, 17280, 1080, 17280, 66, 1080, 66, 17280, 17280, 66, 17280, 1080, 66, 17280, 66, 66, 17280, 17280, 1080, 17280, 17280, 66, 17280, 1080, 1080, 66, 1080, 17280, 17280, 66, 17280, 1080, 66, 1080, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 1080, 17280, 17280, 1080, 66, 17280, 66, 1080, 1080, 66, 1080, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 1080, 17280, 1080, 66, 1080, 17280, 1080, 17280, 66, 17280, 66, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 66, 17280, 66, 17280, 1080, 1080, 66, 1080, 17280, 1080, 1080, 17280, 66, 17280, 17280, 1080, 66, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 66, 17280, 1080, 17280, 17280, 66, 17280, 1080, 1080, 17280, 66, 1080, 66, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 66, 66, 66, 66]
Prompts retrieved: 1583490 . Total input tokens: 353008931 . Total output tokens: 316540482
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 130.68734320579097,
    "estimated_duration": 3600.168404390142,
    "input_throughput": 6260.444087147635,
    "output_throughput": 5529.059967230045,
    "total_throughput": 11789.50405437768,
    "itl": 154.702135821441,
    "ttft": 1933679.462995494,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 489,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5988978952542043,
    "arrivals": 527992,
    "finished_requests": 90861,
    "scheduler_time": 160.54055913022452
}
#Debug simulation 
Total elapsed time: 130.6874991087243. Arrivals time: 1.1616998012177646 Scheduler time: 129.27170404745266 Scheduler overhead time: 0.10244769509881735 Adapter cache time: 0.027161232195794582 Engine time: 0.09572445880621672 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-16-16/adapters_256_slots_64_rate_1.6-0.1-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-16-16/adapters_256_slots_64_rate_1.6-0.1-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 66, 17280, 17280, 66, 17280, 1080, 17280, 66, 1080, 66, 17280, 1080, 1080, 1080, 1080, 17280, 66, 66, 66, 1080, 17280, 66, 17280, 17280, 1080, 1080, 1080, 66, 17280, 66, 1080, 1080, 66, 1080, 66, 66, 1080, 1080, 17280, 1080, 66, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 66, 17280, 17280, 1080, 66, 66, 17280, 1080, 66, 1080, 1080, 17280, 1080, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 1080, 66, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 66, 17280, 17280, 66, 17280, 66, 1080, 17280, 17280, 17280, 1080, 66, 17280, 1080, 66, 66, 66, 66, 66, 17280, 1080, 66, 17280, 66, 17280, 66, 66, 1080, 1080, 17280, 1080, 17280, 66, 1080, 66, 17280, 17280, 66, 17280, 1080, 66, 17280, 66, 66, 17280, 17280, 1080, 17280, 17280, 66, 17280, 1080, 1080, 66, 1080, 17280, 17280, 66, 17280, 1080, 66, 1080, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 1080, 17280, 17280, 1080, 66, 17280, 66, 1080, 1080, 66, 1080, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 1080, 17280, 1080, 66, 1080, 17280, 1080, 17280, 66, 17280, 66, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 66, 17280, 66, 17280, 1080, 1080, 66, 1080, 17280, 1080, 1080, 17280, 66, 17280, 17280, 1080, 66, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 66, 17280, 1080, 17280, 17280, 66, 17280, 1080, 1080, 17280, 66, 1080, 66, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 66, 66, 66, 66]
Prompts retrieved: 1583490 . Total input tokens: 353008931 . Total output tokens: 316540482
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 129.97204746911302,
    "estimated_duration": 3600.092525985344,
    "input_throughput": 6260.576037231482,
    "output_throughput": 5529.176502082223,
    "total_throughput": 11789.752539313706,
    "itl": 154.69922478917852,
    "ttft": 1933669.6726134766,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 489,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5311872030235771,
    "arrivals": 527992,
    "finished_requests": 90861,
    "scheduler_time": 160.53853122404618
}
#Debug simulation 
Total elapsed time: 129.97223503282294. Arrivals time: 0.9666477185674012 Scheduler time: 128.75457101128995 Scheduler overhead time: 0.09913935605436563 Adapter cache time: 0.02858590567484498 Engine time: 0.09437131183221936 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-16-32/adapters_256_slots_64_rate_1.6-0.1-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-16-32/adapters_256_slots_64_rate_1.6-0.1-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 66, 17280, 17280, 66, 17280, 1080, 17280, 66, 1080, 66, 17280, 1080, 1080, 1080, 1080, 17280, 66, 66, 66, 1080, 17280, 66, 17280, 17280, 1080, 1080, 1080, 66, 17280, 66, 1080, 1080, 66, 1080, 66, 66, 1080, 1080, 17280, 1080, 66, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 66, 17280, 17280, 1080, 66, 66, 17280, 1080, 66, 1080, 1080, 17280, 1080, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 1080, 66, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 66, 17280, 17280, 66, 17280, 66, 1080, 17280, 17280, 17280, 1080, 66, 17280, 1080, 66, 66, 66, 66, 66, 17280, 1080, 66, 17280, 66, 17280, 66, 66, 1080, 1080, 17280, 1080, 17280, 66, 1080, 66, 17280, 17280, 66, 17280, 1080, 66, 17280, 66, 66, 17280, 17280, 1080, 17280, 17280, 66, 17280, 1080, 1080, 66, 1080, 17280, 17280, 66, 17280, 1080, 66, 1080, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 1080, 17280, 17280, 1080, 66, 17280, 66, 1080, 1080, 66, 1080, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 1080, 17280, 1080, 66, 1080, 17280, 1080, 17280, 66, 17280, 66, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 66, 17280, 66, 17280, 1080, 1080, 66, 1080, 17280, 1080, 1080, 17280, 66, 17280, 17280, 1080, 66, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 66, 17280, 1080, 17280, 17280, 66, 17280, 1080, 1080, 17280, 66, 1080, 66, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 66, 66, 66, 66]
Prompts retrieved: 1583490 . Total input tokens: 353008931 . Total output tokens: 316540482
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 130.81793100293726,
    "estimated_duration": 3600.016039546109,
    "input_throughput": 6260.380718426335,
    "output_throughput": 5528.864255424123,
    "total_throughput": 11789.244973850458,
    "itl": 154.70185967918036,
    "ttft": 1933630.3014654992,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 489,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6188927472941614,
    "arrivals": 527992,
    "finished_requests": 90856,
    "scheduler_time": 160.53289976827335
}
#Debug simulation 
Total elapsed time: 130.81810444500297. Arrivals time: 0.992583008017391 Scheduler time: 129.57968647032976 Scheduler overhead time: 0.09600823326036334 Adapter cache time: 0.026738944463431835 Engine time: 0.09464124543592334 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_16-16-16/adapters_256_slots_64_rate_1.6-0.1-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_16-16-16/adapters_256_slots_64_rate_1.6-0.1-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 66, 17280, 17280, 66, 17280, 1080, 17280, 66, 1080, 66, 17280, 1080, 1080, 1080, 1080, 17280, 66, 66, 66, 1080, 17280, 66, 17280, 17280, 1080, 1080, 1080, 66, 17280, 66, 1080, 1080, 66, 1080, 66, 66, 1080, 1080, 17280, 1080, 66, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 66, 17280, 17280, 1080, 66, 66, 17280, 1080, 66, 1080, 1080, 17280, 1080, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 1080, 66, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 66, 17280, 17280, 66, 17280, 66, 1080, 17280, 17280, 17280, 1080, 66, 17280, 1080, 66, 66, 66, 66, 66, 17280, 1080, 66, 17280, 66, 17280, 66, 66, 1080, 1080, 17280, 1080, 17280, 66, 1080, 66, 17280, 17280, 66, 17280, 1080, 66, 17280, 66, 66, 17280, 17280, 1080, 17280, 17280, 66, 17280, 1080, 1080, 66, 1080, 17280, 17280, 66, 17280, 1080, 66, 1080, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 1080, 17280, 17280, 1080, 66, 17280, 66, 1080, 1080, 66, 1080, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 1080, 17280, 1080, 66, 1080, 17280, 1080, 17280, 66, 17280, 66, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 66, 17280, 66, 17280, 1080, 1080, 66, 1080, 17280, 1080, 1080, 17280, 66, 17280, 17280, 1080, 66, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 66, 17280, 1080, 17280, 17280, 66, 17280, 1080, 1080, 17280, 66, 1080, 66, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 66, 66, 66, 66]
Prompts retrieved: 1583490 . Total input tokens: 353008931 . Total output tokens: 316540482
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 131.3313502119854,
    "estimated_duration": 3600.020152599806,
    "input_throughput": 6260.701897383377,
    "output_throughput": 5529.28765846628,
    "total_throughput": 11789.989555849657,
    "itl": 154.69681422938697,
    "ttft": 1933653.1495620245,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 489,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4621345942071489,
    "arrivals": 527992,
    "finished_requests": 90861,
    "scheduler_time": 160.53800561554274
}
#Debug simulation 
Total elapsed time: 131.331519307103. Arrivals time: 0.6442859750241041 Scheduler time: 130.44900250341743 Scheduler overhead time: 0.09117383416742086 Adapter cache time: 0.02594495052471757 Engine time: 0.09339027525857091 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_16-16-32/adapters_256_slots_64_rate_1.6-0.1-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_16-16-32/adapters_256_slots_64_rate_1.6-0.1-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 66, 17280, 17280, 66, 17280, 1080, 17280, 66, 1080, 66, 17280, 1080, 1080, 1080, 1080, 17280, 66, 66, 66, 1080, 17280, 66, 17280, 17280, 1080, 1080, 1080, 66, 17280, 66, 1080, 1080, 66, 1080, 66, 66, 1080, 1080, 17280, 1080, 66, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 66, 17280, 17280, 1080, 66, 66, 17280, 1080, 66, 1080, 1080, 17280, 1080, 66, 66, 17280, 17280, 17280, 17280, 17280, 17280, 66, 1080, 66, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 66, 17280, 17280, 66, 17280, 66, 1080, 17280, 17280, 17280, 1080, 66, 17280, 1080, 66, 66, 66, 66, 66, 17280, 1080, 66, 17280, 66, 17280, 66, 66, 1080, 1080, 17280, 1080, 17280, 66, 1080, 66, 17280, 17280, 66, 17280, 1080, 66, 17280, 66, 66, 17280, 17280, 1080, 17280, 17280, 66, 17280, 1080, 1080, 66, 1080, 17280, 17280, 66, 17280, 1080, 66, 1080, 17280, 66, 66, 66, 66, 66, 66, 17280, 66, 66, 66, 17280, 66, 1080, 17280, 17280, 1080, 66, 17280, 66, 1080, 1080, 66, 1080, 66, 17280, 66, 66, 17280, 66, 17280, 17280, 1080, 17280, 1080, 66, 1080, 17280, 1080, 17280, 66, 17280, 66, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 66, 17280, 66, 17280, 1080, 1080, 66, 1080, 17280, 1080, 1080, 17280, 66, 17280, 17280, 1080, 66, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 66, 17280, 1080, 17280, 17280, 66, 17280, 1080, 1080, 17280, 66, 1080, 66, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 66, 66, 66, 66]
Prompts retrieved: 1583490 . Total input tokens: 353008931 . Total output tokens: 316540482
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 129.05835023708642,
    "estimated_duration": 3600.1184616659725,
    "input_throughput": 6260.601488532689,
    "output_throughput": 5528.781958688437,
    "total_throughput": 11789.383447221126,
    "itl": 154.70241469645575,
    "ttft": 1933774.8188350154,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 489,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.639682135917245,
    "arrivals": 527992,
    "finished_requests": 90875,
    "scheduler_time": 160.5300661082167
}
#Debug simulation 
Total elapsed time: 129.05850299587473. Arrivals time: 0.9396634753793478 Scheduler time: 127.87978668604046 Scheduler overhead time: 0.0930180330760777 Adapter cache time: 0.024935726542025805 Engine time: 0.09351111063733697 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-8/adapters_256_slots_64_rate_1.6-0.1-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-8/adapters_256_slots_64_rate_1.6-0.1-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 33, 17280, 17280, 33, 17280, 1080, 17280, 33, 1080, 33, 17280, 1080, 1080, 1080, 1080, 17280, 33, 33, 33, 1080, 17280, 33, 17280, 17280, 1080, 1080, 1080, 33, 17280, 33, 1080, 1080, 33, 1080, 33, 33, 1080, 1080, 17280, 1080, 33, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 33, 17280, 17280, 1080, 33, 33, 17280, 1080, 33, 1080, 1080, 17280, 1080, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 1080, 33, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 33, 17280, 17280, 33, 17280, 33, 1080, 17280, 17280, 17280, 1080, 33, 17280, 1080, 33, 33, 33, 33, 33, 17280, 1080, 33, 17280, 33, 17280, 33, 33, 1080, 1080, 17280, 1080, 17280, 33, 1080, 33, 17280, 17280, 33, 17280, 1080, 33, 17280, 33, 33, 17280, 17280, 1080, 17280, 17280, 33, 17280, 1080, 1080, 33, 1080, 17280, 17280, 33, 17280, 1080, 33, 1080, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 1080, 17280, 17280, 1080, 33, 17280, 33, 1080, 1080, 33, 1080, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 1080, 17280, 1080, 33, 1080, 17280, 1080, 17280, 33, 17280, 33, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 33, 17280, 33, 17280, 1080, 1080, 33, 1080, 17280, 1080, 1080, 17280, 33, 17280, 17280, 1080, 33, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 33, 17280, 1080, 17280, 17280, 33, 17280, 1080, 1080, 17280, 33, 1080, 33, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 33, 33, 33, 33]
Prompts retrieved: 1580685 . Total input tokens: 352385458 . Total output tokens: 315982175
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 130.81970568466932,
    "estimated_duration": 3600.1428153673814,
    "input_throughput": 6259.816944984239,
    "output_throughput": 5526.065498034924,
    "total_throughput": 11785.882443019163,
    "itl": 154.55145699758933,
    "ttft": 1930308.64599401,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 414,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.267041925988168,
    "arrivals": 526966,
    "finished_requests": 91210,
    "scheduler_time": 160.408293386971
}
#Debug simulation 
Total elapsed time: 130.81987577164546. Arrivals time: 0.6225735233165324 Scheduler time: 129.9596179514192 Scheduler overhead time: 0.09178291587159038 Adapter cache time: 0.025017584208399057 Engine time: 0.09355562599375844 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-16/adapters_256_slots_64_rate_1.6-0.1-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-16/adapters_256_slots_64_rate_1.6-0.1-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 33, 17280, 17280, 33, 17280, 1080, 17280, 33, 1080, 33, 17280, 1080, 1080, 1080, 1080, 17280, 33, 33, 33, 1080, 17280, 33, 17280, 17280, 1080, 1080, 1080, 33, 17280, 33, 1080, 1080, 33, 1080, 33, 33, 1080, 1080, 17280, 1080, 33, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 33, 17280, 17280, 1080, 33, 33, 17280, 1080, 33, 1080, 1080, 17280, 1080, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 1080, 33, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 33, 17280, 17280, 33, 17280, 33, 1080, 17280, 17280, 17280, 1080, 33, 17280, 1080, 33, 33, 33, 33, 33, 17280, 1080, 33, 17280, 33, 17280, 33, 33, 1080, 1080, 17280, 1080, 17280, 33, 1080, 33, 17280, 17280, 33, 17280, 1080, 33, 17280, 33, 33, 17280, 17280, 1080, 17280, 17280, 33, 17280, 1080, 1080, 33, 1080, 17280, 17280, 33, 17280, 1080, 33, 1080, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 1080, 17280, 17280, 1080, 33, 17280, 33, 1080, 1080, 33, 1080, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 1080, 17280, 1080, 33, 1080, 17280, 1080, 17280, 33, 17280, 33, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 33, 17280, 33, 17280, 1080, 1080, 33, 1080, 17280, 1080, 1080, 17280, 33, 17280, 17280, 1080, 33, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 33, 17280, 1080, 17280, 17280, 33, 17280, 1080, 1080, 17280, 33, 1080, 33, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 33, 33, 33, 33]
Prompts retrieved: 1580685 . Total input tokens: 352385458 . Total output tokens: 315982175
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 129.2217446579598,
    "estimated_duration": 3600.005090602725,
    "input_throughput": 6259.64725961739,
    "output_throughput": 5525.907741610831,
    "total_throughput": 11785.55500122822,
    "itl": 154.5544388812225,
    "ttft": 1930319.4133738063,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 414,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3490187487052803,
    "arrivals": 526966,
    "finished_requests": 91203,
    "scheduler_time": 160.39838041931253
}
#Debug simulation 
Total elapsed time: 129.22192795481533. Arrivals time: 0.763781342189759 Scheduler time: 128.21975432662293 Scheduler overhead time: 0.0919860228896141 Adapter cache time: 0.02504179021343589 Engine time: 0.09365060087293386 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-32/adapters_256_slots_64_rate_1.6-0.1-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-32/adapters_256_slots_64_rate_1.6-0.1-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 33, 17280, 17280, 33, 17280, 1080, 17280, 33, 1080, 33, 17280, 1080, 1080, 1080, 1080, 17280, 33, 33, 33, 1080, 17280, 33, 17280, 17280, 1080, 1080, 1080, 33, 17280, 33, 1080, 1080, 33, 1080, 33, 33, 1080, 1080, 17280, 1080, 33, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 33, 17280, 17280, 1080, 33, 33, 17280, 1080, 33, 1080, 1080, 17280, 1080, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 1080, 33, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 33, 17280, 17280, 33, 17280, 33, 1080, 17280, 17280, 17280, 1080, 33, 17280, 1080, 33, 33, 33, 33, 33, 17280, 1080, 33, 17280, 33, 17280, 33, 33, 1080, 1080, 17280, 1080, 17280, 33, 1080, 33, 17280, 17280, 33, 17280, 1080, 33, 17280, 33, 33, 17280, 17280, 1080, 17280, 17280, 33, 17280, 1080, 1080, 33, 1080, 17280, 17280, 33, 17280, 1080, 33, 1080, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 1080, 17280, 17280, 1080, 33, 17280, 33, 1080, 1080, 33, 1080, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 1080, 17280, 1080, 33, 1080, 17280, 1080, 17280, 33, 17280, 33, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 33, 17280, 33, 17280, 1080, 1080, 33, 1080, 17280, 1080, 1080, 17280, 33, 17280, 17280, 1080, 33, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 33, 17280, 1080, 17280, 17280, 33, 17280, 1080, 1080, 17280, 33, 1080, 33, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 33, 33, 33, 33]
Prompts retrieved: 1580685 . Total input tokens: 352385458 . Total output tokens: 315982175
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 129.1702015120536,
    "estimated_duration": 3600.007824941692,
    "input_throughput": 6259.642505183996,
    "output_throughput": 5525.903544479714,
    "total_throughput": 11785.54604966371,
    "itl": 154.5545485821831,
    "ttft": 1930319.9411035285,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 414,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3517481219023542,
    "arrivals": 526966,
    "finished_requests": 91203,
    "scheduler_time": 160.39838538504432
}
#Debug simulation 
Total elapsed time: 129.17035845806822. Arrivals time: 0.7582104103639722 Scheduler time: 128.1710473233834 Scheduler overhead time: 0.0941982981748879 Adapter cache time: 0.02488782862201333 Engine time: 0.09472502861171961 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-16-16/adapters_256_slots_64_rate_1.6-0.1-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-16-16/adapters_256_slots_64_rate_1.6-0.1-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 33, 17280, 17280, 33, 17280, 1080, 17280, 33, 1080, 33, 17280, 1080, 1080, 1080, 1080, 17280, 33, 33, 33, 1080, 17280, 33, 17280, 17280, 1080, 1080, 1080, 33, 17280, 33, 1080, 1080, 33, 1080, 33, 33, 1080, 1080, 17280, 1080, 33, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 33, 17280, 17280, 1080, 33, 33, 17280, 1080, 33, 1080, 1080, 17280, 1080, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 1080, 33, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 33, 17280, 17280, 33, 17280, 33, 1080, 17280, 17280, 17280, 1080, 33, 17280, 1080, 33, 33, 33, 33, 33, 17280, 1080, 33, 17280, 33, 17280, 33, 33, 1080, 1080, 17280, 1080, 17280, 33, 1080, 33, 17280, 17280, 33, 17280, 1080, 33, 17280, 33, 33, 17280, 17280, 1080, 17280, 17280, 33, 17280, 1080, 1080, 33, 1080, 17280, 17280, 33, 17280, 1080, 33, 1080, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 1080, 17280, 17280, 1080, 33, 17280, 33, 1080, 1080, 33, 1080, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 1080, 17280, 1080, 33, 1080, 17280, 1080, 17280, 33, 17280, 33, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 33, 17280, 33, 17280, 1080, 1080, 33, 1080, 17280, 1080, 1080, 17280, 33, 17280, 17280, 1080, 33, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 33, 17280, 1080, 17280, 17280, 33, 17280, 1080, 1080, 17280, 33, 1080, 33, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 33, 33, 33, 33]
Prompts retrieved: 1580685 . Total input tokens: 352385458 . Total output tokens: 315982175
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 129.60064133210108,
    "estimated_duration": 3600.175401292996,
    "input_throughput": 6259.76028609777,
    "output_throughput": 5526.015480483225,
    "total_throughput": 11785.775766580995,
    "itl": 154.5520469958154,
    "ttft": 1930315.4473496547,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 415,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3005257888766921,
    "arrivals": 526966,
    "finished_requests": 91210,
    "scheduler_time": 160.40877830404958
}
#Debug simulation 
Total elapsed time: 129.60080656595528. Arrivals time: 0.6219089599326253 Scheduler time: 128.735668358393 Scheduler overhead time: 0.09400797262787819 Adapter cache time: 0.024604800157248974 Engine time: 0.0966199403628707 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-16-32/adapters_256_slots_64_rate_1.6-0.1-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 256,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-16-32/adapters_256_slots_64_rate_1.6-0.1-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 17280, 33, 17280, 17280, 33, 17280, 1080, 17280, 33, 1080, 33, 17280, 1080, 1080, 1080, 1080, 17280, 33, 33, 33, 1080, 17280, 33, 17280, 17280, 1080, 1080, 1080, 33, 17280, 33, 1080, 1080, 33, 1080, 33, 33, 1080, 1080, 17280, 1080, 33, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 33, 17280, 17280, 1080, 33, 33, 17280, 1080, 33, 1080, 1080, 17280, 1080, 33, 33, 17280, 17280, 17280, 17280, 17280, 17280, 33, 1080, 33, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 33, 17280, 17280, 33, 17280, 33, 1080, 17280, 17280, 17280, 1080, 33, 17280, 1080, 33, 33, 33, 33, 33, 17280, 1080, 33, 17280, 33, 17280, 33, 33, 1080, 1080, 17280, 1080, 17280, 33, 1080, 33, 17280, 17280, 33, 17280, 1080, 33, 17280, 33, 33, 17280, 17280, 1080, 17280, 17280, 33, 17280, 1080, 1080, 33, 1080, 17280, 17280, 33, 17280, 1080, 33, 1080, 17280, 33, 33, 33, 33, 33, 33, 17280, 33, 33, 33, 17280, 33, 1080, 17280, 17280, 1080, 33, 17280, 33, 1080, 1080, 33, 1080, 33, 17280, 33, 33, 17280, 33, 17280, 17280, 1080, 17280, 1080, 33, 1080, 17280, 1080, 17280, 33, 17280, 33, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 33, 17280, 33, 17280, 1080, 1080, 33, 1080, 17280, 1080, 1080, 17280, 33, 17280, 17280, 1080, 33, 17280, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 33, 17280, 1080, 17280, 17280, 33, 17280, 1080, 1080, 17280, 33, 1080, 33, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 33, 33, 33, 33]
Prompts retrieved: 1580685 . Total input tokens: 352385458 . Total output tokens: 315982175
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 132.72825984703377,
    "estimated_duration": 3600.0273118920945,
    "input_throughput": 6259.608621734658,
    "output_throughput": 5525.873632759893,
    "total_throughput": 11785.482254494551,
    "itl": 154.55461165686825,
    "ttft": 1930325.278231153,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 414,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3677188527770388,
    "arrivals": 526966,
    "finished_requests": 91203,
    "scheduler_time": 160.39872084695102
}
#Debug simulation 
Total elapsed time: 132.72842199681327. Arrivals time: 0.6796873630955815 Scheduler time: 131.79670968744904 Scheduler overhead time: 0.09908994985744357 Adapter cache time: 0.025066507048904896 Engine time: 0.09879965521395206 
